{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "    <img src=\"images/personal_logo.png\"/>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Unsupervised Learning - Final Project\n",
    "### Juan Carlos Garzon Pico\n",
    "### Viviane Alves\n",
    "\n",
    "---\n",
    "\n",
    "<br>\n",
    "\n",
    "<div align=\"center\">\n",
    "  \n",
    "[![GitHub](https://badges.aleen42.com/src/github.svg)](https://github.com/Juank0621)\n",
    "[![LinkedIn](https://img.shields.io/badge/LinkedIn-Profile-blue?logo=linkedin)](https://www.linkedin.com/in/juancarlosgarzon)\n",
    "![Python](https://badges.aleen42.com/src/python.svg)\n",
    "\n",
    "</div>\n",
    "\n",
    "### CIFAR10 AI System\n",
    "\n",
    "We are developing an AI system using deep learning techniques like Convolutional Autoencoders (CAE), Variational Autoencoders (VAE), and Generative Adversarial Networks (GANs) with the CIFAR10 dataset. These models will help in facial feature extraction, attribute classification, and image generation. By leveraging these approaches, we aim to enhance face recognition, noise reduction, and synthetic face generation for improved image analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "import seaborn as sns\n",
    "from PIL import Image\n",
    "from tqdm import tqdm   \n",
    "#from tqdm.rich import tqdm  # Import tqdm.rich for progress bars\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import CIFAR10\n",
    "import torchvision.transforms.functional as TF\n",
    "import torch.nn.functional as F\n",
    "from torchvision.utils import save_image\n",
    "from torchsummary import summary\n",
    "\n",
    "torch.set_float32_matmul_precision('medium')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PyTorch and GPU Information\n",
    "\n",
    "This code snippet displays the PyTorch version, CUDA version, cuDNN version, and the number of GPUs available for PyTorch.\n",
    "\n",
    "The first line prints the PyTorch version being used.\n",
    "The second and third lines retrieve and display the CUDA and cuDNN versions used by PyTorch.\n",
    "The final line shows the number of GPUs available for PyTorch, helping to confirm whether your system is utilizing the GPU for processing.\n",
    "This is useful for ensuring that your environment is correctly set up to use GPU acceleration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch Version: 2.6.0+cu124\n"
     ]
    }
   ],
   "source": [
    "print(\"PyTorch Version:\", torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA Version: 12.4\n",
      "cuDNN Version: 90100\n"
     ]
    }
   ],
   "source": [
    "# Get the CUDA version used by PyTorch\n",
    "cuda_version = torch.version.cuda\n",
    "print(\"CUDA Version:\", cuda_version)\n",
    "\n",
    "# Get the cuDNN version used by PyTorch\n",
    "cudnn_version = torch.backends.cudnn.version()\n",
    "print(\"cuDNN Version:\", cudnn_version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available: 1\n"
     ]
    }
   ],
   "source": [
    "# Get the number of GPUs available\n",
    "num_gpus = torch.cuda.device_count()\n",
    "print(\"Num GPUs Available:\", num_gpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's make sure that we have access to GPU. We can use `nvidia-smi` command to do that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Apr  4 07:58:54 2025       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 535.183.01             Driver Version: 535.183.01   CUDA Version: 12.2     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  NVIDIA GeForce RTX 4080        Off | 00000000:01:00.0  On |                  N/A |\n",
      "| 30%   27C    P8              10W / 320W |    470MiB / 16376MiB |     20%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|    0   N/A  N/A      4425      G   /usr/lib/xorg/Xorg                          157MiB |\n",
      "|    0   N/A  N/A      5149      G   /usr/bin/gnome-shell                        106MiB |\n",
      "|    0   N/A  N/A      8293      G   ...erProcess --variations-seed-version      137MiB |\n",
      "|    0   N/A  N/A      8435      G   ...17eb9633ccae6fd3ecfd91c4bbeee74e2c3       53MiB |\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Directory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we define the transformations to be applied to the images in the CIFAR10 dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define transformations for the CIFAR10 dataset\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((128, 128)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kwargs = {'num_workers': 8, 'pin_memory': True} # Adjusted for DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n"
     ]
    }
   ],
   "source": [
    "dummy_dataset = CIFAR10(root='./data', train=True, download=True)\n",
    "print(dummy_dataset.classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom Dataset class for loading CIFAR10 images of a specific class\n",
    "class OneClassDatasetCIFAR10(CIFAR10):\n",
    "    def __init__(self, root_dir, real_class=1, transform=None, train=True, download=True):\n",
    "        super().__init__(root=root_dir, transform=transform, train=train, download=download)\n",
    "        self.real_class = real_class\n",
    "        self.samples = []\n",
    "        for i in range(len(self.data)):\n",
    "            if self.targets[i] == self.real_class:\n",
    "                self.samples.append((self.data[i], self.targets[i]))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        data = self.samples[idx]\n",
    "        image = Image.fromarray(data[0])  # Convertir a objeto PIL\n",
    "\n",
    "        # Aplicar transformaciones si están definidas\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        label = 0  # Dummy label as autoencoder does not need labels\n",
    "\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variational autoencoder (VAE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAEEncoder(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, latent_dim):\n",
    "        super(VAEEncoder, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.BatchNorm1d(hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.BatchNorm1d(hidden_dim),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.mean = nn.Linear(hidden_dim, latent_dim)\n",
    "        self.log_var = nn.Linear(hidden_dim, latent_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h = self.encoder(x)\n",
    "        mean = self.mean(h)\n",
    "        log_var = self.log_var(h)\n",
    "        return mean, log_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAEDecoder(nn.Module):\n",
    "    def __init__(self, latent_dim, hidden_dim, output_dim):\n",
    "        super(VAEDecoder, self).__init__()\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(latent_dim, hidden_dim),\n",
    "            nn.BatchNorm1d(hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.BatchNorm1d(hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, output_dim),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, z):\n",
    "        return self.decoder(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, latent_dim):\n",
    "        super(VAE, self).__init__()\n",
    "        self.encoder = VAEEncoder(input_dim, hidden_dim, latent_dim)\n",
    "        self.decoder = VAEDecoder(latent_dim, hidden_dim, input_dim)\n",
    "        self.apply(self._init_weights)\n",
    "\n",
    "    def _init_weights(self, m):\n",
    "        if isinstance(m, nn.Linear):\n",
    "            nn.init.xavier_uniform_(m.weight)\n",
    "            if m.bias is not None:\n",
    "                nn.init.zeros_(m.bias)\n",
    "\n",
    "    def reparameterize(self, mean, log_var):\n",
    "        std = torch.exp(0.5 * log_var)\n",
    "        std = torch.clamp(std, min=1e-6, max=1e6)\n",
    "        epsilon = torch.randn_like(std)\n",
    "        return mean + epsilon * std\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean, log_var = self.encoder(x)\n",
    "        z = self.reparameterize(mean, log_var)\n",
    "        x_hat = self.decoder(z)\n",
    "        return x_hat, mean, log_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vae_loss_function(x, x_hat, mean, log_var, beta=0.1):\n",
    "    reconstruction_loss = nn.functional.mse_loss(x_hat, x, reduction='mean')  # Changed to 'mean'\n",
    "    kl_divergence = -0.5 * torch.sum(1 + log_var - mean.pow(2) - log_var.exp())\n",
    "    kl_divergence = torch.clamp(kl_divergence, min=-1e6, max=1e6)\n",
    "    return reconstruction_loss + beta * kl_divergence / x.size(0)  # Normalize KL by batch size\n",
    "\n",
    "# Function to train the VAE for one epoch with tqdm\n",
    "def train_vae_epoch(vae, train_loader, optimizer):\n",
    "    vae.train()\n",
    "    total_loss = 0\n",
    "    # Use standard tqdm to display progress\n",
    "    for inputs, _ in tqdm(train_loader, desc=\"Training VAE Epoch\", leave=False):  # Updated tqdm usage\n",
    "        inputs = inputs.view(inputs.size(0), -1).to(device)\n",
    "        inputs = torch.clamp(inputs, 0., 1.)  # Normalize inputs to range [0, 1]\n",
    "        optimizer.zero_grad()\n",
    "        x_hat, mean, log_var = vae(inputs)\n",
    "        loss = vae_loss_function(inputs, x_hat, mean, log_var, beta=0.1)\n",
    "        if torch.isnan(loss):\n",
    "            print(\"NaN detected in loss! Skipping batch.\")\n",
    "            continue\n",
    "        loss.backward()\n",
    "        \n",
    "        # Log gradients for debugging\n",
    "        for name, param in vae.named_parameters():\n",
    "            if param.grad is not None:\n",
    "                print(f\"Gradient for {name}: {param.grad.norm().item()}\")\n",
    "\n",
    "        torch.nn.utils.clip_grad_norm_(vae.parameters(), max_norm=1.0)  # Gradient clipping\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    return total_loss / len(train_loader)\n",
    "\n",
    "\n",
    "def evaluate_vae(vae, val_loader):\n",
    "    vae.eval()\n",
    "    total_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, _ in val_loader:\n",
    "            inputs = inputs.view(inputs.size(0), -1).to(device)\n",
    "            x_hat, mean, log_var = vae(inputs)\n",
    "            loss = vae_loss_function(inputs, x_hat, mean, log_var)\n",
    "            total_loss += loss.item()\n",
    "    return total_loss / len(val_loader)\n",
    "\n",
    "\n",
    "def calculate_mahalanobis_distance(mean, covariance, x):\n",
    "    diff = x - mean\n",
    "    inv_covariance = torch.linalg.inv(covariance)\n",
    "    distance = torch.sqrt(torch.mm(torch.mm(diff.unsqueeze(0), inv_covariance), diff.unsqueeze(1)))\n",
    "    return distance.item()\n",
    "\n",
    "\n",
    "def test_vae(vae, test_loader, threshold):\n",
    "    vae.eval()\n",
    "    anomalies = []\n",
    "    with torch.no_grad():\n",
    "        for inputs, _ in test_loader:\n",
    "            inputs = inputs.view(inputs.size(0), -1).to(device)\n",
    "            x_hat, mean, log_var = vae(inputs)\n",
    "            z = vae.reparameterize(mean, log_var)\n",
    "            distances = [calculate_mahalanobis_distance(mean[i], torch.eye(mean.size(1)).to(device), z[i]) for i in range(z.size(0))]\n",
    "            anomalies.extend([d > threshold for d in distances])\n",
    "    return anomalies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main_vae():\n",
    "    input_dim = 128 * 128 * 3\n",
    "    hidden_dim = 512\n",
    "    latent_dim = 128\n",
    "    num_epochs = 3\n",
    "    learning_rate = 1e-4\n",
    "\n",
    "    vae = VAE(input_dim, hidden_dim, latent_dim).to(device)\n",
    "    optimizer = torch.optim.Adam(vae.parameters(), lr=learning_rate)\n",
    "\n",
    "    all_train_losses = []\n",
    "    all_val_losses = []\n",
    "\n",
    "    for real_class in range(10):\n",
    "        print(f\"Training VAE for class {real_class}...\")\n",
    "\n",
    "        train_dataset = OneClassDatasetCIFAR10(root_dir='data', real_class=real_class, transform=transform, train=True, download=True)\n",
    "        val_dataset = OneClassDatasetCIFAR10(root_dir='data', real_class=real_class, transform=transform, train=False, download=True)\n",
    "\n",
    "        train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True, **kwargs)\n",
    "        val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False, **kwargs)\n",
    "\n",
    "        train_losses = []\n",
    "        val_losses = []\n",
    "\n",
    "        for epoch in range(num_epochs):\n",
    "            train_loss = train_vae_epoch(vae, train_loader, optimizer)\n",
    "            val_loss = evaluate_vae(vae, val_loader)\n",
    "            train_losses.append(train_loss)\n",
    "            val_losses.append(val_loss)\n",
    "            print(f\"Epoch {epoch + 1}/{num_epochs}, Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}\")\n",
    "\n",
    "        all_train_losses.append(train_losses)\n",
    "        all_val_losses.append(val_losses)\n",
    "\n",
    "        # Save the trained model\n",
    "        torch.save(vae.state_dict(), f'models/vae/vae_class_{real_class}_weights.pth')\n",
    "\n",
    "    return all_train_losses, all_val_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training VAE for class 0...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training VAE Epoch:  11%|█▏        | 9/79 [00:00<00:03, 20.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient for encoder.encoder.0.weight: 69.01309967041016\n",
      "Gradient for encoder.encoder.0.bias: 6.857793977133042e-08\n",
      "Gradient for encoder.encoder.1.weight: 0.38031458854675293\n",
      "Gradient for encoder.encoder.1.bias: 0.23685623705387115\n",
      "Gradient for encoder.encoder.3.weight: 7.928630828857422\n",
      "Gradient for encoder.encoder.3.bias: 9.961159008753384e-08\n",
      "Gradient for encoder.encoder.4.weight: 1.0521678924560547\n",
      "Gradient for encoder.encoder.4.bias: 0.8537461161613464\n",
      "Gradient for encoder.mean.weight: 6.057049751281738\n",
      "Gradient for encoder.mean.bias: 0.5718256831169128\n",
      "Gradient for encoder.log_var.weight: 8.026944160461426\n",
      "Gradient for encoder.log_var.bias: 0.6032436490058899\n",
      "Gradient for decoder.decoder.0.weight: 0.00027033156948164105\n",
      "Gradient for decoder.decoder.0.bias: 1.6926044984003075e-12\n",
      "Gradient for decoder.decoder.1.weight: 1.3455878615786787e-05\n",
      "Gradient for decoder.decoder.1.bias: 1.0267544894304592e-05\n",
      "Gradient for decoder.decoder.3.weight: 0.00030052129295654595\n",
      "Gradient for decoder.decoder.3.bias: 6.157038420773198e-12\n",
      "Gradient for decoder.decoder.4.weight: 6.210801802808419e-05\n",
      "Gradient for decoder.decoder.4.bias: 5.777403566753492e-05\n",
      "Gradient for decoder.decoder.6.weight: 0.0044100540690124035\n",
      "Gradient for decoder.decoder.6.bias: 0.0005183062166906893\n",
      "Gradient for encoder.encoder.0.weight: 37.60350799560547\n",
      "Gradient for encoder.encoder.0.bias: 6.308093958296013e-08\n",
      "Gradient for encoder.encoder.1.weight: 0.4459332525730133\n",
      "Gradient for encoder.encoder.1.bias: 0.30880242586135864\n",
      "Gradient for encoder.encoder.3.weight: 9.337259292602539\n",
      "Gradient for encoder.encoder.3.bias: 1.0490217050573847e-07\n",
      "Gradient for encoder.encoder.4.weight: 1.0351933240890503\n",
      "Gradient for encoder.encoder.4.bias: 0.9732846617698669\n",
      "Gradient for encoder.mean.weight: 6.416414737701416\n",
      "Gradient for encoder.mean.bias: 0.5642406940460205\n",
      "Gradient for encoder.log_var.weight: 8.548012733459473\n",
      "Gradient for encoder.log_var.bias: 0.675527036190033\n",
      "Gradient for decoder.decoder.0.weight: 0.0004191767075099051\n",
      "Gradient for decoder.decoder.0.bias: 1.9648113431386394e-12\n",
      "Gradient for decoder.decoder.1.weight: 2.3477754439227283e-05\n",
      "Gradient for decoder.decoder.1.bias: 1.6407315342803486e-05\n",
      "Gradient for decoder.decoder.3.weight: 0.00043628033017739654\n",
      "Gradient for decoder.decoder.3.bias: 4.130305906319132e-12\n",
      "Gradient for decoder.decoder.4.weight: 3.514409399940632e-05\n",
      "Gradient for decoder.decoder.4.bias: 4.174803689238615e-05\n",
      "Gradient for decoder.decoder.6.weight: 0.004729832522571087\n",
      "Gradient for decoder.decoder.6.bias: 0.0005002436228096485\n",
      "Gradient for encoder.encoder.0.weight: 18.2949275970459\n",
      "Gradient for encoder.encoder.0.bias: 2.5606496478758345e-08\n",
      "Gradient for encoder.encoder.1.weight: 0.3079110085964203\n",
      "Gradient for encoder.encoder.1.bias: 0.21202777326107025\n",
      "Gradient for encoder.encoder.3.weight: 6.745019435882568\n",
      "Gradient for encoder.encoder.3.bias: 7.945522639829505e-08\n",
      "Gradient for encoder.encoder.4.weight: 0.7759161591529846\n",
      "Gradient for encoder.encoder.4.bias: 0.7369285821914673\n",
      "Gradient for encoder.mean.weight: 6.4128193855285645\n",
      "Gradient for encoder.mean.bias: 0.5465899109840393\n",
      "Gradient for encoder.log_var.weight: 5.097615718841553\n",
      "Gradient for encoder.log_var.bias: 0.45274996757507324\n",
      "Gradient for decoder.decoder.0.weight: 0.0009242648375220597\n",
      "Gradient for decoder.decoder.0.bias: 4.676938090281135e-12\n",
      "Gradient for decoder.decoder.1.weight: 5.438148946268484e-05\n",
      "Gradient for decoder.decoder.1.bias: 3.055254273931496e-05\n",
      "Gradient for decoder.decoder.3.weight: 0.0009141417685896158\n",
      "Gradient for decoder.decoder.3.bias: 9.247880239371398e-12\n",
      "Gradient for decoder.decoder.4.weight: 6.38754790998064e-05\n",
      "Gradient for decoder.decoder.4.bias: 0.0001030963976518251\n",
      "Gradient for decoder.decoder.6.weight: 0.004733059089630842\n",
      "Gradient for decoder.decoder.6.bias: 0.000514413055498153\n",
      "Gradient for encoder.encoder.0.weight: 12.289240837097168\n",
      "Gradient for encoder.encoder.0.bias: 1.7995041901031072e-08\n",
      "Gradient for encoder.encoder.1.weight: 0.2419949173927307\n",
      "Gradient for encoder.encoder.1.bias: 0.16495779156684875\n",
      "Gradient for encoder.encoder.3.weight: 5.494020462036133\n",
      "Gradient for encoder.encoder.3.bias: 8.173820731371961e-08\n",
      "Gradient for encoder.encoder.4.weight: 0.6721466779708862\n",
      "Gradient for encoder.encoder.4.bias: 0.6553560495376587\n",
      "Gradient for encoder.mean.weight: 6.099498271942139\n",
      "Gradient for encoder.mean.bias: 0.5296628475189209\n",
      "Gradient for encoder.log_var.weight: 4.549442768096924\n",
      "Gradient for encoder.log_var.bias: 0.40939533710479736\n",
      "Gradient for decoder.decoder.0.weight: 0.0012320163659751415\n",
      "Gradient for decoder.decoder.0.bias: 6.538460311372729e-12\n",
      "Gradient for decoder.decoder.1.weight: 7.649619510630146e-05\n",
      "Gradient for decoder.decoder.1.bias: 4.336402707849629e-05\n",
      "Gradient for decoder.decoder.3.weight: 0.0012237423798069358\n",
      "Gradient for decoder.decoder.3.bias: 1.5444675052767032e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0001131349490606226\n",
      "Gradient for decoder.decoder.4.bias: 0.00017084616411011666\n",
      "Gradient for decoder.decoder.6.weight: 0.004466896411031485\n",
      "Gradient for decoder.decoder.6.bias: 0.0004896107129752636\n",
      "Gradient for encoder.encoder.0.weight: 8.95125961303711\n",
      "Gradient for encoder.encoder.0.bias: 1.4152345073625838e-08\n",
      "Gradient for encoder.encoder.1.weight: 0.2108975052833557\n",
      "Gradient for encoder.encoder.1.bias: 0.1528625339269638\n",
      "Gradient for encoder.encoder.3.weight: 4.958349704742432\n",
      "Gradient for encoder.encoder.3.bias: 6.685323228339257e-08\n",
      "Gradient for encoder.encoder.4.weight: 0.6266382932662964\n",
      "Gradient for encoder.encoder.4.bias: 0.6168774366378784\n",
      "Gradient for encoder.mean.weight: 5.692738056182861\n",
      "Gradient for encoder.mean.bias: 0.5110912322998047\n",
      "Gradient for encoder.log_var.weight: 4.444599151611328\n",
      "Gradient for encoder.log_var.bias: 0.38737067580223083\n",
      "Gradient for decoder.decoder.0.weight: 0.001520163961686194\n",
      "Gradient for decoder.decoder.0.bias: 8.499730433375596e-12\n",
      "Gradient for decoder.decoder.1.weight: 9.268071153201163e-05\n",
      "Gradient for decoder.decoder.1.bias: 5.3646966989617795e-05\n",
      "Gradient for decoder.decoder.3.weight: 0.0014221399324014783\n",
      "Gradient for decoder.decoder.3.bias: 2.3982585015125402e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00019383590552024543\n",
      "Gradient for decoder.decoder.4.bias: 0.00027509595383889973\n",
      "Gradient for decoder.decoder.6.weight: 0.004857562016695738\n",
      "Gradient for decoder.decoder.6.bias: 0.0005290165427140892\n",
      "Gradient for encoder.encoder.0.weight: 6.757007598876953\n",
      "Gradient for encoder.encoder.0.bias: 1.1184990711399223e-08\n",
      "Gradient for encoder.encoder.1.weight: 0.19655224680900574\n",
      "Gradient for encoder.encoder.1.bias: 0.14007465541362762\n",
      "Gradient for encoder.encoder.3.weight: 4.175405502319336\n",
      "Gradient for encoder.encoder.3.bias: 6.469414159937514e-08\n",
      "Gradient for encoder.encoder.4.weight: 0.5486963987350464\n",
      "Gradient for encoder.encoder.4.bias: 0.5509970784187317\n",
      "Gradient for encoder.mean.weight: 5.342503070831299\n",
      "Gradient for encoder.mean.bias: 0.4865383505821228\n",
      "Gradient for encoder.log_var.weight: 3.7243926525115967\n",
      "Gradient for encoder.log_var.bias: 0.34467950463294983\n",
      "Gradient for decoder.decoder.0.weight: 0.0017342433566227555\n",
      "Gradient for decoder.decoder.0.bias: 1.0256339180725327e-11\n",
      "Gradient for decoder.decoder.1.weight: 9.740899258758873e-05\n",
      "Gradient for decoder.decoder.1.bias: 6.073091208236292e-05\n",
      "Gradient for decoder.decoder.3.weight: 0.0016038273461163044\n",
      "Gradient for decoder.decoder.3.bias: 3.481644833547293e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00030122516909614205\n",
      "Gradient for decoder.decoder.4.bias: 0.00040772571810521185\n",
      "Gradient for decoder.decoder.6.weight: 0.005337619688361883\n",
      "Gradient for decoder.decoder.6.bias: 0.0005819366197101772\n",
      "Gradient for encoder.encoder.0.weight: 5.773005962371826\n",
      "Gradient for encoder.encoder.0.bias: 9.564652181381916e-09\n",
      "Gradient for encoder.encoder.1.weight: 0.1759333312511444\n",
      "Gradient for encoder.encoder.1.bias: 0.1293307989835739\n",
      "Gradient for encoder.encoder.3.weight: 4.024406433105469\n",
      "Gradient for encoder.encoder.3.bias: 5.6873659559641965e-08\n",
      "Gradient for encoder.encoder.4.weight: 0.5277630090713501\n",
      "Gradient for encoder.encoder.4.bias: 0.5371009111404419\n",
      "Gradient for encoder.mean.weight: 5.19697904586792\n",
      "Gradient for encoder.mean.bias: 0.47808441519737244\n",
      "Gradient for encoder.log_var.weight: 3.7347147464752197\n",
      "Gradient for encoder.log_var.bias: 0.3400888442993164\n",
      "Gradient for decoder.decoder.0.weight: 0.002267390489578247\n",
      "Gradient for decoder.decoder.0.bias: 1.2418018870141712e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.00012510940723586828\n",
      "Gradient for decoder.decoder.1.bias: 8.235154382418841e-05\n",
      "Gradient for decoder.decoder.3.weight: 0.002122066216543317\n",
      "Gradient for decoder.decoder.3.bias: 3.66451417821434e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0003126423107460141\n",
      "Gradient for decoder.decoder.4.bias: 0.0004121114907320589\n",
      "Gradient for decoder.decoder.6.weight: 0.0045073432847857475\n",
      "Gradient for decoder.decoder.6.bias: 0.0004721761797554791\n",
      "Gradient for encoder.encoder.0.weight: 4.489226341247559\n",
      "Gradient for encoder.encoder.0.bias: 8.153215880213338e-09\n",
      "Gradient for encoder.encoder.1.weight: 0.1492009460926056\n",
      "Gradient for encoder.encoder.1.bias: 0.1098821610212326\n",
      "Gradient for encoder.encoder.3.weight: 3.3933804035186768\n",
      "Gradient for encoder.encoder.3.bias: 4.817986720695444e-08\n",
      "Gradient for encoder.encoder.4.weight: 0.4903603792190552\n",
      "Gradient for encoder.encoder.4.bias: 0.5044500827789307\n",
      "Gradient for encoder.mean.weight: 4.912590503692627\n",
      "Gradient for encoder.mean.bias: 0.4567822813987732\n",
      "Gradient for encoder.log_var.weight: 3.4352524280548096\n",
      "Gradient for encoder.log_var.bias: 0.31974658370018005\n",
      "Gradient for decoder.decoder.0.weight: 0.0022737036924809217\n",
      "Gradient for decoder.decoder.0.bias: 1.4203044122751418e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.00011939569230889902\n",
      "Gradient for decoder.decoder.1.bias: 7.754264515824616e-05\n",
      "Gradient for decoder.decoder.3.weight: 0.0020557469688355923\n",
      "Gradient for decoder.decoder.3.bias: 4.3966705276510254e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.000388457061490044\n",
      "Gradient for decoder.decoder.4.bias: 0.0005054434295743704\n",
      "Gradient for decoder.decoder.6.weight: 0.004550796467810869\n",
      "Gradient for decoder.decoder.6.bias: 0.00047651215572841465\n",
      "Gradient for encoder.encoder.0.weight: 3.7288169860839844\n",
      "Gradient for encoder.encoder.0.bias: 5.659718915751455e-09\n",
      "Gradient for encoder.encoder.1.weight: 0.14799028635025024\n",
      "Gradient for encoder.encoder.1.bias: 0.11007732897996902\n",
      "Gradient for encoder.encoder.3.weight: 3.165607213973999\n",
      "Gradient for encoder.encoder.3.bias: 4.6291713573509696e-08\n",
      "Gradient for encoder.encoder.4.weight: 0.4465496242046356\n",
      "Gradient for encoder.encoder.4.bias: 0.47719457745552063\n",
      "Gradient for encoder.mean.weight: 4.750725746154785\n",
      "Gradient for encoder.mean.bias: 0.44566476345062256\n",
      "Gradient for encoder.log_var.weight: 3.1488025188446045\n",
      "Gradient for encoder.log_var.bias: 0.2987796366214752\n",
      "Gradient for decoder.decoder.0.weight: 0.0031434758566319942\n",
      "Gradient for decoder.decoder.0.bias: 2.0421412824656038e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0001769733353285119\n",
      "Gradient for decoder.decoder.1.bias: 0.00012234061432536691\n",
      "Gradient for decoder.decoder.3.weight: 0.0028839425649493933\n",
      "Gradient for decoder.decoder.3.bias: 5.136096062341444e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0004390858521219343\n",
      "Gradient for decoder.decoder.4.bias: 0.0005629475344903767\n",
      "Gradient for decoder.decoder.6.weight: 0.004320900421589613\n",
      "Gradient for decoder.decoder.6.bias: 0.0004476118483580649\n",
      "Gradient for encoder.encoder.0.weight: 3.2999680042266846\n",
      "Gradient for encoder.encoder.0.bias: 5.371366906814501e-09\n",
      "Gradient for encoder.encoder.1.weight: 0.1367661952972412\n",
      "Gradient for encoder.encoder.1.bias: 0.09257729351520538\n",
      "Gradient for encoder.encoder.3.weight: 3.0276358127593994\n",
      "Gradient for encoder.encoder.3.bias: 4.3635580482259684e-08\n",
      "Gradient for encoder.encoder.4.weight: 0.427685022354126\n",
      "Gradient for encoder.encoder.4.bias: 0.44340384006500244\n",
      "Gradient for encoder.mean.weight: 4.550600051879883\n",
      "Gradient for encoder.mean.bias: 0.4228503704071045\n",
      "Gradient for encoder.log_var.weight: 3.027942657470703\n",
      "Gradient for encoder.log_var.bias: 0.27633538842201233\n",
      "Gradient for decoder.decoder.0.weight: 0.0032082318793982267\n",
      "Gradient for decoder.decoder.0.bias: 2.101304373558488e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.00018281069060321897\n",
      "Gradient for decoder.decoder.1.bias: 0.00010997702338499948\n",
      "Gradient for decoder.decoder.3.weight: 0.002927362686023116\n",
      "Gradient for decoder.decoder.3.bias: 7.139572266723349e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0006478410796262324\n",
      "Gradient for decoder.decoder.4.bias: 0.0008385219844058156\n",
      "Gradient for decoder.decoder.6.weight: 0.005280959419906139\n",
      "Gradient for decoder.decoder.6.bias: 0.0005684400675818324\n",
      "Gradient for encoder.encoder.0.weight: 3.227113723754883\n",
      "Gradient for encoder.encoder.0.bias: 5.0343382795858815e-09\n",
      "Gradient for encoder.encoder.1.weight: 0.1281903237104416\n",
      "Gradient for encoder.encoder.1.bias: 0.09874749183654785\n",
      "Gradient for encoder.encoder.3.weight: 2.8026926517486572\n",
      "Gradient for encoder.encoder.3.bias: 4.855439428297359e-08\n",
      "Gradient for encoder.encoder.4.weight: 0.40819576382637024\n",
      "Gradient for encoder.encoder.4.bias: 0.43099695444107056\n",
      "Gradient for encoder.mean.weight: 4.397001266479492\n",
      "Gradient for encoder.mean.bias: 0.41280078887939453\n",
      "Gradient for encoder.log_var.weight: 2.945077657699585\n",
      "Gradient for encoder.log_var.bias: 0.27651268243789673\n",
      "Gradient for decoder.decoder.0.weight: 0.0034556982573121786\n",
      "Gradient for decoder.decoder.0.bias: 2.4059846129298457e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.00020483438856899738\n",
      "Gradient for decoder.decoder.1.bias: 0.00013430773105937988\n",
      "Gradient for decoder.decoder.3.weight: 0.003376961685717106\n",
      "Gradient for decoder.decoder.3.bias: 6.990889811486767e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0006142251077108085\n",
      "Gradient for decoder.decoder.4.bias: 0.0007926396210677922\n",
      "Gradient for decoder.decoder.6.weight: 0.004477979615330696\n",
      "Gradient for decoder.decoder.6.bias: 0.0004655246448237449\n",
      "Gradient for encoder.encoder.0.weight: 2.763664960861206\n",
      "Gradient for encoder.encoder.0.bias: 5.025274862902052e-09\n",
      "Gradient for encoder.encoder.1.weight: 0.12994396686553955\n",
      "Gradient for encoder.encoder.1.bias: 0.09345962107181549\n",
      "Gradient for encoder.encoder.3.weight: 2.80416202545166\n",
      "Gradient for encoder.encoder.3.bias: 4.277124787677167e-08\n",
      "Gradient for encoder.encoder.4.weight: 0.37990760803222656\n",
      "Gradient for encoder.encoder.4.bias: 0.40056848526000977\n",
      "Gradient for encoder.mean.weight: 4.196008682250977\n",
      "Gradient for encoder.mean.bias: 0.39038825035095215\n",
      "Gradient for encoder.log_var.weight: 2.757568120956421\n",
      "Gradient for encoder.log_var.bias: 0.25640588998794556\n",
      "Gradient for decoder.decoder.0.weight: 0.004205309320241213\n",
      "Gradient for decoder.decoder.0.bias: 3.183958305341683e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.00023946657893247902\n",
      "Gradient for decoder.decoder.1.bias: 0.00014476377691607922\n",
      "Gradient for decoder.decoder.3.weight: 0.003864084370434284\n",
      "Gradient for decoder.decoder.3.bias: 7.53594131541746e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0006230555009096861\n",
      "Gradient for decoder.decoder.4.bias: 0.0007891382556408644\n",
      "Gradient for decoder.decoder.6.weight: 0.004255201201885939\n",
      "Gradient for decoder.decoder.6.bias: 0.0004397854791022837\n",
      "Gradient for encoder.encoder.0.weight: 2.625979423522949\n",
      "Gradient for encoder.encoder.0.bias: 4.065592307256338e-09\n",
      "Gradient for encoder.encoder.1.weight: 0.11940132081508636\n",
      "Gradient for encoder.encoder.1.bias: 0.09034696221351624\n",
      "Gradient for encoder.encoder.3.weight: 2.5391383171081543\n",
      "Gradient for encoder.encoder.3.bias: 4.541565701288164e-08\n",
      "Gradient for encoder.encoder.4.weight: 0.36785888671875\n",
      "Gradient for encoder.encoder.4.bias: 0.4025615453720093\n",
      "Gradient for encoder.mean.weight: 4.1297287940979\n",
      "Gradient for encoder.mean.bias: 0.3916299045085907\n",
      "Gradient for encoder.log_var.weight: 2.680283308029175\n",
      "Gradient for encoder.log_var.bias: 0.2530076801776886\n",
      "Gradient for decoder.decoder.0.weight: 0.004730298649519682\n",
      "Gradient for decoder.decoder.0.bias: 3.608003479316224e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0002826527925208211\n",
      "Gradient for decoder.decoder.1.bias: 0.00017217760614585131\n",
      "Gradient for decoder.decoder.3.weight: 0.004472759552299976\n",
      "Gradient for decoder.decoder.3.bias: 8.159124070816759e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0007321403827518225\n",
      "Gradient for decoder.decoder.4.bias: 0.0009215297759510577\n",
      "Gradient for decoder.decoder.6.weight: 0.004315460100769997\n",
      "Gradient for decoder.decoder.6.bias: 0.0004428020620252937\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training VAE Epoch:  32%|███▏      | 25/79 [00:00<00:01, 46.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient for encoder.encoder.0.weight: 2.044830560684204\n",
      "Gradient for encoder.encoder.0.bias: 3.4615439403751225e-09\n",
      "Gradient for encoder.encoder.1.weight: 0.10282322764396667\n",
      "Gradient for encoder.encoder.1.bias: 0.07091552019119263\n",
      "Gradient for encoder.encoder.3.weight: 2.191467761993408\n",
      "Gradient for encoder.encoder.3.bias: 3.451970087553491e-08\n",
      "Gradient for encoder.encoder.4.weight: 0.3204665184020996\n",
      "Gradient for encoder.encoder.4.bias: 0.3491657078266144\n",
      "Gradient for encoder.mean.weight: 3.76589035987854\n",
      "Gradient for encoder.mean.bias: 0.3546150028705597\n",
      "Gradient for encoder.log_var.weight: 2.3035528659820557\n",
      "Gradient for encoder.log_var.bias: 0.22208508849143982\n",
      "Gradient for decoder.decoder.0.weight: 0.005136181600391865\n",
      "Gradient for decoder.decoder.0.bias: 3.843075510601146e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0002825072733685374\n",
      "Gradient for decoder.decoder.1.bias: 0.0001806214131647721\n",
      "Gradient for decoder.decoder.3.weight: 0.00457135122269392\n",
      "Gradient for decoder.decoder.3.bias: 9.105276255194639e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0008582809823565185\n",
      "Gradient for decoder.decoder.4.bias: 0.0010872861603274941\n",
      "Gradient for decoder.decoder.6.weight: 0.004469056148082018\n",
      "Gradient for decoder.decoder.6.bias: 0.00046371243661269546\n",
      "Gradient for encoder.encoder.0.weight: 1.8704421520233154\n",
      "Gradient for encoder.encoder.0.bias: 2.650918595747953e-09\n",
      "Gradient for encoder.encoder.1.weight: 0.0989208072423935\n",
      "Gradient for encoder.encoder.1.bias: 0.07246154546737671\n",
      "Gradient for encoder.encoder.3.weight: 2.1535332202911377\n",
      "Gradient for encoder.encoder.3.bias: 3.1256430332859964e-08\n",
      "Gradient for encoder.encoder.4.weight: 0.31336843967437744\n",
      "Gradient for encoder.encoder.4.bias: 0.3434751629829407\n",
      "Gradient for encoder.mean.weight: 3.6724936962127686\n",
      "Gradient for encoder.mean.bias: 0.3437372148036957\n",
      "Gradient for encoder.log_var.weight: 2.3911373615264893\n",
      "Gradient for encoder.log_var.bias: 0.22442762553691864\n",
      "Gradient for decoder.decoder.0.weight: 0.00602962588891387\n",
      "Gradient for decoder.decoder.0.bias: 4.4713410057850567e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0003520408645272255\n",
      "Gradient for decoder.decoder.1.bias: 0.00022705260198563337\n",
      "Gradient for decoder.decoder.3.weight: 0.005481394473463297\n",
      "Gradient for decoder.decoder.3.bias: 9.097896741527833e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0007643694407306612\n",
      "Gradient for decoder.decoder.4.bias: 0.0009312526090070605\n",
      "Gradient for decoder.decoder.6.weight: 0.00376448524184525\n",
      "Gradient for decoder.decoder.6.bias: 0.0003680543741211295\n",
      "Gradient for encoder.encoder.0.weight: 1.6528706550598145\n",
      "Gradient for encoder.encoder.0.bias: 2.7108557620891816e-09\n",
      "Gradient for encoder.encoder.1.weight: 0.08826290816068649\n",
      "Gradient for encoder.encoder.1.bias: 0.06017785891890526\n",
      "Gradient for encoder.encoder.3.weight: 2.023898124694824\n",
      "Gradient for encoder.encoder.3.bias: 2.9043020433050515e-08\n",
      "Gradient for encoder.encoder.4.weight: 0.2742530107498169\n",
      "Gradient for encoder.encoder.4.bias: 0.2992814779281616\n",
      "Gradient for encoder.mean.weight: 3.3568642139434814\n",
      "Gradient for encoder.mean.bias: 0.31430864334106445\n",
      "Gradient for encoder.log_var.weight: 1.9896148443222046\n",
      "Gradient for encoder.log_var.bias: 0.19015538692474365\n",
      "Gradient for decoder.decoder.0.weight: 0.005909349769353867\n",
      "Gradient for decoder.decoder.0.bias: 4.47524517444009e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.00036314708995632827\n",
      "Gradient for decoder.decoder.1.bias: 0.00020926116849295795\n",
      "Gradient for decoder.decoder.3.weight: 0.005511661525815725\n",
      "Gradient for decoder.decoder.3.bias: 1.047947978394248e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0009408806799910963\n",
      "Gradient for decoder.decoder.4.bias: 0.0011909693712368608\n",
      "Gradient for decoder.decoder.6.weight: 0.004228623118251562\n",
      "Gradient for decoder.decoder.6.bias: 0.00043647963320836425\n",
      "Gradient for encoder.encoder.0.weight: 1.6483596563339233\n",
      "Gradient for encoder.encoder.0.bias: 2.5321620356066887e-09\n",
      "Gradient for encoder.encoder.1.weight: 0.09184027463197708\n",
      "Gradient for encoder.encoder.1.bias: 0.0679493248462677\n",
      "Gradient for encoder.encoder.3.weight: 1.970071792602539\n",
      "Gradient for encoder.encoder.3.bias: 2.5321872598738082e-08\n",
      "Gradient for encoder.encoder.4.weight: 0.2704683244228363\n",
      "Gradient for encoder.encoder.4.bias: 0.3004928529262543\n",
      "Gradient for encoder.mean.weight: 3.3038852214813232\n",
      "Gradient for encoder.mean.bias: 0.31337907910346985\n",
      "Gradient for encoder.log_var.weight: 2.0806355476379395\n",
      "Gradient for encoder.log_var.bias: 0.19855910539627075\n",
      "Gradient for decoder.decoder.0.weight: 0.00670037092640996\n",
      "Gradient for decoder.decoder.0.bias: 5.394691984794697e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0003773945791181177\n",
      "Gradient for decoder.decoder.1.bias: 0.0002460016403347254\n",
      "Gradient for decoder.decoder.3.weight: 0.005935599096119404\n",
      "Gradient for decoder.decoder.3.bias: 9.978071840999192e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0008875785279087722\n",
      "Gradient for decoder.decoder.4.bias: 0.0011206603376194835\n",
      "Gradient for decoder.decoder.6.weight: 0.003650778206065297\n",
      "Gradient for decoder.decoder.6.bias: 0.0003710808523464948\n",
      "Gradient for encoder.encoder.0.weight: 1.6548347473144531\n",
      "Gradient for encoder.encoder.0.bias: 2.6492654736642862e-09\n",
      "Gradient for encoder.encoder.1.weight: 0.07929179817438126\n",
      "Gradient for encoder.encoder.1.bias: 0.05711578577756882\n",
      "Gradient for encoder.encoder.3.weight: 1.7155333757400513\n",
      "Gradient for encoder.encoder.3.bias: 2.7171410010851105e-08\n",
      "Gradient for encoder.encoder.4.weight: 0.25271812081336975\n",
      "Gradient for encoder.encoder.4.bias: 0.2778826355934143\n",
      "Gradient for encoder.mean.weight: 3.0033326148986816\n",
      "Gradient for encoder.mean.bias: 0.28904294967651367\n",
      "Gradient for encoder.log_var.weight: 1.9090843200683594\n",
      "Gradient for encoder.log_var.bias: 0.18355944752693176\n",
      "Gradient for decoder.decoder.0.weight: 0.0061772484332323074\n",
      "Gradient for decoder.decoder.0.bias: 4.838854317235075e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.00034427898935973644\n",
      "Gradient for decoder.decoder.1.bias: 0.0002273988357046619\n",
      "Gradient for decoder.decoder.3.weight: 0.005632359534502029\n",
      "Gradient for decoder.decoder.3.bias: 1.4015842653147814e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0011279190657660365\n",
      "Gradient for decoder.decoder.4.bias: 0.0014383160741999745\n",
      "Gradient for decoder.decoder.6.weight: 0.004294335842132568\n",
      "Gradient for decoder.decoder.6.bias: 0.00044810588588006794\n",
      "Gradient for encoder.encoder.0.weight: 1.3756678104400635\n",
      "Gradient for encoder.encoder.0.bias: 2.1386898918507313e-09\n",
      "Gradient for encoder.encoder.1.weight: 0.08507715165615082\n",
      "Gradient for encoder.encoder.1.bias: 0.05664519965648651\n",
      "Gradient for encoder.encoder.3.weight: 1.732675313949585\n",
      "Gradient for encoder.encoder.3.bias: 2.925237652107171e-08\n",
      "Gradient for encoder.encoder.4.weight: 0.2337021380662918\n",
      "Gradient for encoder.encoder.4.bias: 0.2604823708534241\n",
      "Gradient for encoder.mean.weight: 2.934514045715332\n",
      "Gradient for encoder.mean.bias: 0.2740708887577057\n",
      "Gradient for encoder.log_var.weight: 1.8165295124053955\n",
      "Gradient for encoder.log_var.bias: 0.17044170200824738\n",
      "Gradient for decoder.decoder.0.weight: 0.008011963218450546\n",
      "Gradient for decoder.decoder.0.bias: 5.73263554681791e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0004583932750392705\n",
      "Gradient for decoder.decoder.1.bias: 0.00029647661722265184\n",
      "Gradient for decoder.decoder.3.weight: 0.007110892329365015\n",
      "Gradient for decoder.decoder.3.bias: 1.1487436002433071e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.000982883502729237\n",
      "Gradient for decoder.decoder.4.bias: 0.0012580293696373701\n",
      "Gradient for decoder.decoder.6.weight: 0.0035999338142573833\n",
      "Gradient for decoder.decoder.6.bias: 0.00036506750620901585\n",
      "Gradient for encoder.encoder.0.weight: 1.3062186241149902\n",
      "Gradient for encoder.encoder.0.bias: 2.1850325993000297e-09\n",
      "Gradient for encoder.encoder.1.weight: 0.07297911494970322\n",
      "Gradient for encoder.encoder.1.bias: 0.05907576158642769\n",
      "Gradient for encoder.encoder.3.weight: 1.6064180135726929\n",
      "Gradient for encoder.encoder.3.bias: 2.5118630730958103e-08\n",
      "Gradient for encoder.encoder.4.weight: 0.2285456508398056\n",
      "Gradient for encoder.encoder.4.bias: 0.25786909461021423\n",
      "Gradient for encoder.mean.weight: 2.7940638065338135\n",
      "Gradient for encoder.mean.bias: 0.26255980134010315\n",
      "Gradient for encoder.log_var.weight: 1.7899712324142456\n",
      "Gradient for encoder.log_var.bias: 0.1703399270772934\n",
      "Gradient for decoder.decoder.0.weight: 0.007377292029559612\n",
      "Gradient for decoder.decoder.0.bias: 5.541755249138802e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.00039345413097180426\n",
      "Gradient for decoder.decoder.1.bias: 0.0002743724035099149\n",
      "Gradient for decoder.decoder.3.weight: 0.00656953826546669\n",
      "Gradient for decoder.decoder.3.bias: 1.4366961786915766e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0012053665705025196\n",
      "Gradient for decoder.decoder.4.bias: 0.0015036853728815913\n",
      "Gradient for decoder.decoder.6.weight: 0.003992053214460611\n",
      "Gradient for decoder.decoder.6.bias: 0.00040592343430034816\n",
      "Gradient for encoder.encoder.0.weight: 1.1023192405700684\n",
      "Gradient for encoder.encoder.0.bias: 1.993543552458732e-09\n",
      "Gradient for encoder.encoder.1.weight: 0.07708480209112167\n",
      "Gradient for encoder.encoder.1.bias: 0.06026032939553261\n",
      "Gradient for encoder.encoder.3.weight: 1.5786495208740234\n",
      "Gradient for encoder.encoder.3.bias: 2.1622270196530735e-08\n",
      "Gradient for encoder.encoder.4.weight: 0.20958289504051208\n",
      "Gradient for encoder.encoder.4.bias: 0.2360285222530365\n",
      "Gradient for encoder.mean.weight: 2.634920835494995\n",
      "Gradient for encoder.mean.bias: 0.24371835589408875\n",
      "Gradient for encoder.log_var.weight: 1.666008710861206\n",
      "Gradient for encoder.log_var.bias: 0.15418356657028198\n",
      "Gradient for decoder.decoder.0.weight: 0.007941474206745625\n",
      "Gradient for decoder.decoder.0.bias: 6.673272351376269e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0004517802444752306\n",
      "Gradient for decoder.decoder.1.bias: 0.00029819997143931687\n",
      "Gradient for decoder.decoder.3.weight: 0.007241961546242237\n",
      "Gradient for decoder.decoder.3.bias: 1.2767702173288598e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.00112173764500767\n",
      "Gradient for decoder.decoder.4.bias: 0.0013591169845312834\n",
      "Gradient for decoder.decoder.6.weight: 0.0035598576068878174\n",
      "Gradient for decoder.decoder.6.bias: 0.0003464921610429883\n",
      "Gradient for encoder.encoder.0.weight: 0.9602127075195312\n",
      "Gradient for encoder.encoder.0.bias: 1.60503865753725e-09\n",
      "Gradient for encoder.encoder.1.weight: 0.07024162262678146\n",
      "Gradient for encoder.encoder.1.bias: 0.047591403126716614\n",
      "Gradient for encoder.encoder.3.weight: 1.488115668296814\n",
      "Gradient for encoder.encoder.3.bias: 1.9512970794721696e-08\n",
      "Gradient for encoder.encoder.4.weight: 0.18599577248096466\n",
      "Gradient for encoder.encoder.4.bias: 0.2115481197834015\n",
      "Gradient for encoder.mean.weight: 2.4181108474731445\n",
      "Gradient for encoder.mean.bias: 0.22396674752235413\n",
      "Gradient for encoder.log_var.weight: 1.4377548694610596\n",
      "Gradient for encoder.log_var.bias: 0.13688123226165771\n",
      "Gradient for decoder.decoder.0.weight: 0.008697033859789371\n",
      "Gradient for decoder.decoder.0.bias: 6.543257602409369e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.00046742582344450057\n",
      "Gradient for decoder.decoder.1.bias: 0.0003123008937109262\n",
      "Gradient for decoder.decoder.3.weight: 0.007511903531849384\n",
      "Gradient for decoder.decoder.3.bias: 1.3526865738633376e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0011098213726654649\n",
      "Gradient for decoder.decoder.4.bias: 0.001417379709891975\n",
      "Gradient for decoder.decoder.6.weight: 0.0033501447178423405\n",
      "Gradient for decoder.decoder.6.bias: 0.00034379956196062267\n",
      "Gradient for encoder.encoder.0.weight: 0.9936783909797668\n",
      "Gradient for encoder.encoder.0.bias: 1.7923739159542151e-09\n",
      "Gradient for encoder.encoder.1.weight: 0.0601908378303051\n",
      "Gradient for encoder.encoder.1.bias: 0.04839158430695534\n",
      "Gradient for encoder.encoder.3.weight: 1.365211009979248\n",
      "Gradient for encoder.encoder.3.bias: 1.759626577779727e-08\n",
      "Gradient for encoder.encoder.4.weight: 0.1793687492609024\n",
      "Gradient for encoder.encoder.4.bias: 0.20140688121318817\n",
      "Gradient for encoder.mean.weight: 2.292835235595703\n",
      "Gradient for encoder.mean.bias: 0.2161443829536438\n",
      "Gradient for encoder.log_var.weight: 1.3997691869735718\n",
      "Gradient for encoder.log_var.bias: 0.1311681568622589\n",
      "Gradient for decoder.decoder.0.weight: 0.008068221621215343\n",
      "Gradient for decoder.decoder.0.bias: 6.051339984658455e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0004599672101903707\n",
      "Gradient for decoder.decoder.1.bias: 0.00029328095843084157\n",
      "Gradient for decoder.decoder.3.weight: 0.006997937336564064\n",
      "Gradient for decoder.decoder.3.bias: 1.396408544351857e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.001258333446457982\n",
      "Gradient for decoder.decoder.4.bias: 0.0015879715792834759\n",
      "Gradient for decoder.decoder.6.weight: 0.0035840298514813185\n",
      "Gradient for decoder.decoder.6.bias: 0.0003718243387993425\n",
      "Gradient for encoder.encoder.0.weight: 1.112775444984436\n",
      "Gradient for encoder.encoder.0.bias: 2.2838584357032232e-09\n",
      "Gradient for encoder.encoder.1.weight: 0.06836497783660889\n",
      "Gradient for encoder.encoder.1.bias: 0.047240786254405975\n",
      "Gradient for encoder.encoder.3.weight: 1.5180774927139282\n",
      "Gradient for encoder.encoder.3.bias: 1.5767833261293163e-08\n",
      "Gradient for encoder.encoder.4.weight: 0.17631365358829498\n",
      "Gradient for encoder.encoder.4.bias: 0.19264593720436096\n",
      "Gradient for encoder.mean.weight: 2.167872190475464\n",
      "Gradient for encoder.mean.bias: 0.201569601893425\n",
      "Gradient for encoder.log_var.weight: 1.3893420696258545\n",
      "Gradient for encoder.log_var.bias: 0.1279812902212143\n",
      "Gradient for decoder.decoder.0.weight: 0.007244092412292957\n",
      "Gradient for decoder.decoder.0.bias: 6.37516844870234e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0003732508048415184\n",
      "Gradient for decoder.decoder.1.bias: 0.0002540647401474416\n",
      "Gradient for decoder.decoder.3.weight: 0.006208721082657576\n",
      "Gradient for decoder.decoder.3.bias: 1.5948176113056434e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0013800382148474455\n",
      "Gradient for decoder.decoder.4.bias: 0.0017590979114174843\n",
      "Gradient for decoder.decoder.6.weight: 0.003706445684656501\n",
      "Gradient for decoder.decoder.6.bias: 0.00039006953011266887\n",
      "Gradient for encoder.encoder.0.weight: 0.9724747538566589\n",
      "Gradient for encoder.encoder.0.bias: 1.8084314046262762e-09\n",
      "Gradient for encoder.encoder.1.weight: 0.06441709399223328\n",
      "Gradient for encoder.encoder.1.bias: 0.0444403700530529\n",
      "Gradient for encoder.encoder.3.weight: 1.353712797164917\n",
      "Gradient for encoder.encoder.3.bias: 1.4433618744646992e-08\n",
      "Gradient for encoder.encoder.4.weight: 0.1569707989692688\n",
      "Gradient for encoder.encoder.4.bias: 0.17045196890830994\n",
      "Gradient for encoder.mean.weight: 2.0363707542419434\n",
      "Gradient for encoder.mean.bias: 0.18726381659507751\n",
      "Gradient for encoder.log_var.weight: 1.2344235181808472\n",
      "Gradient for encoder.log_var.bias: 0.11249696463346481\n",
      "Gradient for decoder.decoder.0.weight: 0.009641711600124836\n",
      "Gradient for decoder.decoder.0.bias: 7.500359361367614e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005036047659814358\n",
      "Gradient for decoder.decoder.1.bias: 0.00031549707637168467\n",
      "Gradient for decoder.decoder.3.weight: 0.007986413314938545\n",
      "Gradient for decoder.decoder.3.bias: 1.6077497666522333e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0013740035938099027\n",
      "Gradient for decoder.decoder.4.bias: 0.00173904187977314\n",
      "Gradient for decoder.decoder.6.weight: 0.0034775910899043083\n",
      "Gradient for decoder.decoder.6.bias: 0.0003572191344574094\n",
      "Gradient for encoder.encoder.0.weight: 0.9374622106552124\n",
      "Gradient for encoder.encoder.0.bias: 1.6008212533336064e-09\n",
      "Gradient for encoder.encoder.1.weight: 0.05899006500840187\n",
      "Gradient for encoder.encoder.1.bias: 0.04350143298506737\n",
      "Gradient for encoder.encoder.3.weight: 1.2870194911956787\n",
      "Gradient for encoder.encoder.3.bias: 1.8324415762549506e-08\n",
      "Gradient for encoder.encoder.4.weight: 0.15666987001895905\n",
      "Gradient for encoder.encoder.4.bias: 0.1677376925945282\n",
      "Gradient for encoder.mean.weight: 1.9942041635513306\n",
      "Gradient for encoder.mean.bias: 0.1799333542585373\n",
      "Gradient for encoder.log_var.weight: 1.246390700340271\n",
      "Gradient for encoder.log_var.bias: 0.11262007057666779\n",
      "Gradient for decoder.decoder.0.weight: 0.009290824644267559\n",
      "Gradient for decoder.decoder.0.bias: 7.440256050150751e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005063258577138186\n",
      "Gradient for decoder.decoder.1.bias: 0.0003424431197345257\n",
      "Gradient for decoder.decoder.3.weight: 0.007867634296417236\n",
      "Gradient for decoder.decoder.3.bias: 1.5962187127627203e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.001357083790935576\n",
      "Gradient for decoder.decoder.4.bias: 0.0017278098966926336\n",
      "Gradient for decoder.decoder.6.weight: 0.003313223132863641\n",
      "Gradient for decoder.decoder.6.bias: 0.00033882525167427957\n",
      "Gradient for encoder.encoder.0.weight: 0.8875212669372559\n",
      "Gradient for encoder.encoder.0.bias: 1.3884787763984718e-09\n",
      "Gradient for encoder.encoder.1.weight: 0.06328478455543518\n",
      "Gradient for encoder.encoder.1.bias: 0.04631940275430679\n",
      "Gradient for encoder.encoder.3.weight: 1.3484910726547241\n",
      "Gradient for encoder.encoder.3.bias: 1.4855704222327404e-08\n",
      "Gradient for encoder.encoder.4.weight: 0.14350184798240662\n",
      "Gradient for encoder.encoder.4.bias: 0.16221773624420166\n",
      "Gradient for encoder.mean.weight: 1.8868889808654785\n",
      "Gradient for encoder.mean.bias: 0.17112813889980316\n",
      "Gradient for encoder.log_var.weight: 1.2140302658081055\n",
      "Gradient for encoder.log_var.bias: 0.10943011939525604\n",
      "Gradient for decoder.decoder.0.weight: 0.010713203810155392\n",
      "Gradient for decoder.decoder.0.bias: 8.819710239915679e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005481003317981958\n",
      "Gradient for decoder.decoder.1.bias: 0.0003901398740708828\n",
      "Gradient for decoder.decoder.3.weight: 0.008816711604595184\n",
      "Gradient for decoder.decoder.3.bias: 1.117407416595384e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0009199703927151859\n",
      "Gradient for decoder.decoder.4.bias: 0.001087121432647109\n",
      "Gradient for decoder.decoder.6.weight: 0.002463485114276409\n",
      "Gradient for decoder.decoder.6.bias: 0.00022668633027933538\n",
      "Gradient for encoder.encoder.0.weight: 0.7574041485786438\n",
      "Gradient for encoder.encoder.0.bias: 1.23294341403124e-09\n",
      "Gradient for encoder.encoder.1.weight: 0.05002245679497719\n",
      "Gradient for encoder.encoder.1.bias: 0.03843473643064499\n",
      "Gradient for encoder.encoder.3.weight: 1.091357707977295\n",
      "Gradient for encoder.encoder.3.bias: 1.484600264944902e-08\n",
      "Gradient for encoder.encoder.4.weight: 0.12815119326114655\n",
      "Gradient for encoder.encoder.4.bias: 0.14754392206668854\n",
      "Gradient for encoder.mean.weight: 1.7034624814987183\n",
      "Gradient for encoder.mean.bias: 0.1591344028711319\n",
      "Gradient for encoder.log_var.weight: 1.0574729442596436\n",
      "Gradient for encoder.log_var.bias: 0.09858221560716629\n",
      "Gradient for decoder.decoder.0.weight: 0.010845275595784187\n",
      "Gradient for decoder.decoder.0.bias: 8.917730442981053e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0006218196358531713\n",
      "Gradient for decoder.decoder.1.bias: 0.00041509000584483147\n",
      "Gradient for decoder.decoder.3.weight: 0.009263496845960617\n",
      "Gradient for decoder.decoder.3.bias: 1.1392249643638053e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0008914197678677738\n",
      "Gradient for decoder.decoder.4.bias: 0.001074605155736208\n",
      "Gradient for decoder.decoder.6.weight: 0.0023105142172425985\n",
      "Gradient for decoder.decoder.6.bias: 0.00021249294513836503\n",
      "Gradient for encoder.encoder.0.weight: 0.7562955021858215\n",
      "Gradient for encoder.encoder.0.bias: 1.3007466215242403e-09\n",
      "Gradient for encoder.encoder.1.weight: 0.05213722214102745\n",
      "Gradient for encoder.encoder.1.bias: 0.04079539701342583\n",
      "Gradient for encoder.encoder.3.weight: 1.0722180604934692\n",
      "Gradient for encoder.encoder.3.bias: 1.1822865353394718e-08\n",
      "Gradient for encoder.encoder.4.weight: 0.1243334412574768\n",
      "Gradient for encoder.encoder.4.bias: 0.14070500433444977\n",
      "Gradient for encoder.mean.weight: 1.5764939785003662\n",
      "Gradient for encoder.mean.bias: 0.1485353261232376\n",
      "Gradient for encoder.log_var.weight: 1.0368894338607788\n",
      "Gradient for encoder.log_var.bias: 0.09473314136266708\n",
      "Gradient for decoder.decoder.0.weight: 0.011071152053773403\n",
      "Gradient for decoder.decoder.0.bias: 8.330191397787345e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0006025563925504684\n",
      "Gradient for decoder.decoder.1.bias: 0.0004086485714651644\n",
      "Gradient for decoder.decoder.3.weight: 0.009248364716768265\n",
      "Gradient for decoder.decoder.3.bias: 1.2516285230468327e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0009980164468288422\n",
      "Gradient for decoder.decoder.4.bias: 0.001247977721504867\n",
      "Gradient for decoder.decoder.6.weight: 0.0024213725700974464\n",
      "Gradient for decoder.decoder.6.bias: 0.00023485394194722176\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training VAE Epoch:  52%|█████▏    | 41/79 [00:00<00:00, 61.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient for encoder.encoder.0.weight: 0.7488377094268799\n",
      "Gradient for encoder.encoder.0.bias: 1.10202313940988e-09\n",
      "Gradient for encoder.encoder.1.weight: 0.05389483645558357\n",
      "Gradient for encoder.encoder.1.bias: 0.03775711730122566\n",
      "Gradient for encoder.encoder.3.weight: 1.229591965675354\n",
      "Gradient for encoder.encoder.3.bias: 1.1002565969420175e-08\n",
      "Gradient for encoder.encoder.4.weight: 0.11439676582813263\n",
      "Gradient for encoder.encoder.4.bias: 0.12488323450088501\n",
      "Gradient for encoder.mean.weight: 1.4633296728134155\n",
      "Gradient for encoder.mean.bias: 0.13206690549850464\n",
      "Gradient for encoder.log_var.weight: 0.9171082973480225\n",
      "Gradient for encoder.log_var.bias: 0.0789145827293396\n",
      "Gradient for decoder.decoder.0.weight: 0.011190352961421013\n",
      "Gradient for decoder.decoder.0.bias: 9.090199426520229e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0006588204414583743\n",
      "Gradient for decoder.decoder.1.bias: 0.0004019183397758752\n",
      "Gradient for decoder.decoder.3.weight: 0.009400146082043648\n",
      "Gradient for decoder.decoder.3.bias: 1.8754425790135087e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0016241680132225156\n",
      "Gradient for decoder.decoder.4.bias: 0.002111960668116808\n",
      "Gradient for decoder.decoder.6.weight: 0.003294349415227771\n",
      "Gradient for decoder.decoder.6.bias: 0.000353441690094769\n",
      "Gradient for encoder.encoder.0.weight: 0.8022623658180237\n",
      "Gradient for encoder.encoder.0.bias: 1.214679468120039e-09\n",
      "Gradient for encoder.encoder.1.weight: 0.05206959694623947\n",
      "Gradient for encoder.encoder.1.bias: 0.04134603217244148\n",
      "Gradient for encoder.encoder.3.weight: 1.1302855014801025\n",
      "Gradient for encoder.encoder.3.bias: 1.3375239582558152e-08\n",
      "Gradient for encoder.encoder.4.weight: 0.11817050725221634\n",
      "Gradient for encoder.encoder.4.bias: 0.13363692164421082\n",
      "Gradient for encoder.mean.weight: 1.489490270614624\n",
      "Gradient for encoder.mean.bias: 0.1370246708393097\n",
      "Gradient for encoder.log_var.weight: 0.9905131459236145\n",
      "Gradient for encoder.log_var.bias: 0.08855902403593063\n",
      "Gradient for decoder.decoder.0.weight: 0.010447703301906586\n",
      "Gradient for decoder.decoder.0.bias: 9.170765535859715e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.000568072369787842\n",
      "Gradient for decoder.decoder.1.bias: 0.0003651462320704013\n",
      "Gradient for decoder.decoder.3.weight: 0.008657120168209076\n",
      "Gradient for decoder.decoder.3.bias: 1.3742537663397059e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0010877911699935794\n",
      "Gradient for decoder.decoder.4.bias: 0.0013222593115642667\n",
      "Gradient for decoder.decoder.6.weight: 0.002533947117626667\n",
      "Gradient for decoder.decoder.6.bias: 0.00025204941630363464\n",
      "Gradient for encoder.encoder.0.weight: 0.6372777223587036\n",
      "Gradient for encoder.encoder.0.bias: 1.0585147203201473e-09\n",
      "Gradient for encoder.encoder.1.weight: 0.041694629937410355\n",
      "Gradient for encoder.encoder.1.bias: 0.035189270973205566\n",
      "Gradient for encoder.encoder.3.weight: 0.8911816477775574\n",
      "Gradient for encoder.encoder.3.bias: 1.0002296768618635e-08\n",
      "Gradient for encoder.encoder.4.weight: 0.10358228534460068\n",
      "Gradient for encoder.encoder.4.bias: 0.11555706709623337\n",
      "Gradient for encoder.mean.weight: 1.3197247982025146\n",
      "Gradient for encoder.mean.bias: 0.12129891663789749\n",
      "Gradient for encoder.log_var.weight: 0.8658744096755981\n",
      "Gradient for encoder.log_var.bias: 0.07661597430706024\n",
      "Gradient for decoder.decoder.0.weight: 0.011356308124959469\n",
      "Gradient for decoder.decoder.0.bias: 9.707058767904897e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0006088038790039718\n",
      "Gradient for decoder.decoder.1.bias: 0.00042350258445367217\n",
      "Gradient for decoder.decoder.3.weight: 0.009221958927810192\n",
      "Gradient for decoder.decoder.3.bias: 1.671444094242247e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0013904626248404384\n",
      "Gradient for decoder.decoder.4.bias: 0.0017719671595841646\n",
      "Gradient for decoder.decoder.6.weight: 0.0027398644015192986\n",
      "Gradient for decoder.decoder.6.bias: 0.0002816254855133593\n",
      "Gradient for encoder.encoder.0.weight: 0.7710255980491638\n",
      "Gradient for encoder.encoder.0.bias: 9.575442661002853e-10\n",
      "Gradient for encoder.encoder.1.weight: 0.05857102945446968\n",
      "Gradient for encoder.encoder.1.bias: 0.04434831067919731\n",
      "Gradient for encoder.encoder.3.weight: 1.2388230562210083\n",
      "Gradient for encoder.encoder.3.bias: 1.1144853040434555e-08\n",
      "Gradient for encoder.encoder.4.weight: 0.10482803732156754\n",
      "Gradient for encoder.encoder.4.bias: 0.11485014110803604\n",
      "Gradient for encoder.mean.weight: 1.3445261716842651\n",
      "Gradient for encoder.mean.bias: 0.11517833173274994\n",
      "Gradient for encoder.log_var.weight: 0.8958685994148254\n",
      "Gradient for encoder.log_var.bias: 0.07418392598628998\n",
      "Gradient for decoder.decoder.0.weight: 0.015537764877080917\n",
      "Gradient for decoder.decoder.0.bias: 1.2942076577093786e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0008651661337353289\n",
      "Gradient for decoder.decoder.1.bias: 0.0005846123676747084\n",
      "Gradient for decoder.decoder.3.weight: 0.012637204490602016\n",
      "Gradient for decoder.decoder.3.bias: 1.4436979389742532e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.001055715256370604\n",
      "Gradient for decoder.decoder.4.bias: 0.0012388153700158\n",
      "Gradient for decoder.decoder.6.weight: 0.002216305583715439\n",
      "Gradient for decoder.decoder.6.bias: 0.00019416416762396693\n",
      "Gradient for encoder.encoder.0.weight: 0.49478766322135925\n",
      "Gradient for encoder.encoder.0.bias: 9.089420327512698e-10\n",
      "Gradient for encoder.encoder.1.weight: 0.03289620578289032\n",
      "Gradient for encoder.encoder.1.bias: 0.027753693982958794\n",
      "Gradient for encoder.encoder.3.weight: 0.7416222095489502\n",
      "Gradient for encoder.encoder.3.bias: 9.586769600389289e-09\n",
      "Gradient for encoder.encoder.4.weight: 0.08631351590156555\n",
      "Gradient for encoder.encoder.4.bias: 0.10122818499803543\n",
      "Gradient for encoder.mean.weight: 1.1303274631500244\n",
      "Gradient for encoder.mean.bias: 0.10878199338912964\n",
      "Gradient for encoder.log_var.weight: 0.7407261729240417\n",
      "Gradient for encoder.log_var.bias: 0.06505174189805984\n",
      "Gradient for decoder.decoder.0.weight: 0.012362397275865078\n",
      "Gradient for decoder.decoder.0.bias: 1.0113567622260788e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0006776701775379479\n",
      "Gradient for decoder.decoder.1.bias: 0.0004166715661995113\n",
      "Gradient for decoder.decoder.3.weight: 0.01007061917334795\n",
      "Gradient for decoder.decoder.3.bias: 1.237402263987164e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0009541577310301363\n",
      "Gradient for decoder.decoder.4.bias: 0.001147537142969668\n",
      "Gradient for decoder.decoder.6.weight: 0.0020947318989783525\n",
      "Gradient for decoder.decoder.6.bias: 0.00019645436259452254\n",
      "Gradient for encoder.encoder.0.weight: 0.5696094632148743\n",
      "Gradient for encoder.encoder.0.bias: 9.96192794922024e-10\n",
      "Gradient for encoder.encoder.1.weight: 0.04790981486439705\n",
      "Gradient for encoder.encoder.1.bias: 0.039836205542087555\n",
      "Gradient for encoder.encoder.3.weight: 0.9883666038513184\n",
      "Gradient for encoder.encoder.3.bias: 9.221595931308002e-09\n",
      "Gradient for encoder.encoder.4.weight: 0.0959489569067955\n",
      "Gradient for encoder.encoder.4.bias: 0.10871024429798126\n",
      "Gradient for encoder.mean.weight: 1.2130969762802124\n",
      "Gradient for encoder.mean.bias: 0.10766127705574036\n",
      "Gradient for encoder.log_var.weight: 0.8326451182365417\n",
      "Gradient for encoder.log_var.bias: 0.07259790599346161\n",
      "Gradient for decoder.decoder.0.weight: 0.013455286622047424\n",
      "Gradient for decoder.decoder.0.bias: 1.1017105283617212e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.000759238435421139\n",
      "Gradient for decoder.decoder.1.bias: 0.0004693755181506276\n",
      "Gradient for decoder.decoder.3.weight: 0.010677340440452099\n",
      "Gradient for decoder.decoder.3.bias: 1.050478662389942e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0006247421842999756\n",
      "Gradient for decoder.decoder.4.bias: 0.0007025848026387393\n",
      "Gradient for decoder.decoder.6.weight: 0.0018304530531167984\n",
      "Gradient for decoder.decoder.6.bias: 0.0001611340994713828\n",
      "Gradient for encoder.encoder.0.weight: 0.6760671734809875\n",
      "Gradient for encoder.encoder.0.bias: 1.0709790831953114e-09\n",
      "Gradient for encoder.encoder.1.weight: 0.0522506907582283\n",
      "Gradient for encoder.encoder.1.bias: 0.04102298989892006\n",
      "Gradient for encoder.encoder.3.weight: 1.062212347984314\n",
      "Gradient for encoder.encoder.3.bias: 1.0129229011113239e-08\n",
      "Gradient for encoder.encoder.4.weight: 0.08607865124940872\n",
      "Gradient for encoder.encoder.4.bias: 0.09347961843013763\n",
      "Gradient for encoder.mean.weight: 1.1030827760696411\n",
      "Gradient for encoder.mean.bias: 0.092010498046875\n",
      "Gradient for encoder.log_var.weight: 0.7192250490188599\n",
      "Gradient for encoder.log_var.bias: 0.0591709204018116\n",
      "Gradient for decoder.decoder.0.weight: 0.013568202964961529\n",
      "Gradient for decoder.decoder.0.bias: 1.1366756841324488e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0007874476141296327\n",
      "Gradient for decoder.decoder.1.bias: 0.0005007808213122189\n",
      "Gradient for decoder.decoder.3.weight: 0.011130273342132568\n",
      "Gradient for decoder.decoder.3.bias: 1.5504346417838377e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0012542244512587786\n",
      "Gradient for decoder.decoder.4.bias: 0.0015107989311218262\n",
      "Gradient for decoder.decoder.6.weight: 0.0023250554222613573\n",
      "Gradient for decoder.decoder.6.bias: 0.00022089785488788038\n",
      "Gradient for encoder.encoder.0.weight: 0.5845466256141663\n",
      "Gradient for encoder.encoder.0.bias: 8.023557929170977e-10\n",
      "Gradient for encoder.encoder.1.weight: 0.04367559775710106\n",
      "Gradient for encoder.encoder.1.bias: 0.03085584007203579\n",
      "Gradient for encoder.encoder.3.weight: 0.9444151520729065\n",
      "Gradient for encoder.encoder.3.bias: 6.77320510789059e-09\n",
      "Gradient for encoder.encoder.4.weight: 0.07413565367460251\n",
      "Gradient for encoder.encoder.4.bias: 0.07553021609783173\n",
      "Gradient for encoder.mean.weight: 0.9074310660362244\n",
      "Gradient for encoder.mean.bias: 0.0777466669678688\n",
      "Gradient for encoder.log_var.weight: 0.598106861114502\n",
      "Gradient for encoder.log_var.bias: 0.04804003983736038\n",
      "Gradient for decoder.decoder.0.weight: 0.013458264991641045\n",
      "Gradient for decoder.decoder.0.bias: 1.1103334224271677e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0007479971973225474\n",
      "Gradient for decoder.decoder.1.bias: 0.00046238009235821664\n",
      "Gradient for decoder.decoder.3.weight: 0.010816061869263649\n",
      "Gradient for decoder.decoder.3.bias: 1.5843418244010365e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0013859693426638842\n",
      "Gradient for decoder.decoder.4.bias: 0.001722165266983211\n",
      "Gradient for decoder.decoder.6.weight: 0.0024099533911794424\n",
      "Gradient for decoder.decoder.6.bias: 0.00023747383966110647\n",
      "Gradient for encoder.encoder.0.weight: 0.4944920539855957\n",
      "Gradient for encoder.encoder.0.bias: 8.232720616341282e-10\n",
      "Gradient for encoder.encoder.1.weight: 0.03824801743030548\n",
      "Gradient for encoder.encoder.1.bias: 0.030145378783345222\n",
      "Gradient for encoder.encoder.3.weight: 0.8523657917976379\n",
      "Gradient for encoder.encoder.3.bias: 6.499906834989133e-09\n",
      "Gradient for encoder.encoder.4.weight: 0.07034076005220413\n",
      "Gradient for encoder.encoder.4.bias: 0.07605384290218353\n",
      "Gradient for encoder.mean.weight: 0.8964467644691467\n",
      "Gradient for encoder.mean.bias: 0.07860833406448364\n",
      "Gradient for encoder.log_var.weight: 0.5398429036140442\n",
      "Gradient for encoder.log_var.bias: 0.04410155117511749\n",
      "Gradient for decoder.decoder.0.weight: 0.013124684803187847\n",
      "Gradient for decoder.decoder.0.bias: 1.1326439092185225e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0007051744614727795\n",
      "Gradient for decoder.decoder.1.bias: 0.00046490071690641344\n",
      "Gradient for decoder.decoder.3.weight: 0.010146036744117737\n",
      "Gradient for decoder.decoder.3.bias: 1.2372705637808679e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.00095117132877931\n",
      "Gradient for decoder.decoder.4.bias: 0.0011479896493256092\n",
      "Gradient for decoder.decoder.6.weight: 0.0019337706035003066\n",
      "Gradient for decoder.decoder.6.bias: 0.00018029917555395514\n",
      "Gradient for encoder.encoder.0.weight: 0.4288535714149475\n",
      "Gradient for encoder.encoder.0.bias: 6.998341350872295e-10\n",
      "Gradient for encoder.encoder.1.weight: 0.03575948253273964\n",
      "Gradient for encoder.encoder.1.bias: 0.027594298124313354\n",
      "Gradient for encoder.encoder.3.weight: 0.7899224758148193\n",
      "Gradient for encoder.encoder.3.bias: 6.736597946144229e-09\n",
      "Gradient for encoder.encoder.4.weight: 0.06522652506828308\n",
      "Gradient for encoder.encoder.4.bias: 0.068614661693573\n",
      "Gradient for encoder.mean.weight: 0.8332762718200684\n",
      "Gradient for encoder.mean.bias: 0.07154793292284012\n",
      "Gradient for encoder.log_var.weight: 0.5302411913871765\n",
      "Gradient for encoder.log_var.bias: 0.042715221643447876\n",
      "Gradient for decoder.decoder.0.weight: 0.013415728695690632\n",
      "Gradient for decoder.decoder.0.bias: 1.1076178862978736e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0007257686229422688\n",
      "Gradient for decoder.decoder.1.bias: 0.0004732579691335559\n",
      "Gradient for decoder.decoder.3.weight: 0.01067725382745266\n",
      "Gradient for decoder.decoder.3.bias: 1.6762738419551226e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0013776796404272318\n",
      "Gradient for decoder.decoder.4.bias: 0.0017032927135005593\n",
      "Gradient for decoder.decoder.6.weight: 0.0022417183499783278\n",
      "Gradient for decoder.decoder.6.bias: 0.0002153148379875347\n",
      "Gradient for encoder.encoder.0.weight: 0.46296486258506775\n",
      "Gradient for encoder.encoder.0.bias: 7.972134619116389e-10\n",
      "Gradient for encoder.encoder.1.weight: 0.036681946367025375\n",
      "Gradient for encoder.encoder.1.bias: 0.028655320405960083\n",
      "Gradient for encoder.encoder.3.weight: 0.7706337571144104\n",
      "Gradient for encoder.encoder.3.bias: 5.800437907765854e-09\n",
      "Gradient for encoder.encoder.4.weight: 0.061067402362823486\n",
      "Gradient for encoder.encoder.4.bias: 0.06284527480602264\n",
      "Gradient for encoder.mean.weight: 0.7702184319496155\n",
      "Gradient for encoder.mean.bias: 0.0659160315990448\n",
      "Gradient for encoder.log_var.weight: 0.4973701536655426\n",
      "Gradient for encoder.log_var.bias: 0.03799864277243614\n",
      "Gradient for decoder.decoder.0.weight: 0.014278877526521683\n",
      "Gradient for decoder.decoder.0.bias: 1.2396005055759218e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0007643114076927304\n",
      "Gradient for decoder.decoder.1.bias: 0.0005342673975974321\n",
      "Gradient for decoder.decoder.3.weight: 0.01145967561751604\n",
      "Gradient for decoder.decoder.3.bias: 1.633201490713887e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0014554630033671856\n",
      "Gradient for decoder.decoder.4.bias: 0.001774596981704235\n",
      "Gradient for decoder.decoder.6.weight: 0.002342415740713477\n",
      "Gradient for decoder.decoder.6.bias: 0.0002280635089846328\n",
      "Gradient for encoder.encoder.0.weight: 0.4895790219306946\n",
      "Gradient for encoder.encoder.0.bias: 8.073362534055661e-10\n",
      "Gradient for encoder.encoder.1.weight: 0.03829982876777649\n",
      "Gradient for encoder.encoder.1.bias: 0.030136391520500183\n",
      "Gradient for encoder.encoder.3.weight: 0.8184219598770142\n",
      "Gradient for encoder.encoder.3.bias: 6.539673247374367e-09\n",
      "Gradient for encoder.encoder.4.weight: 0.06436113268136978\n",
      "Gradient for encoder.encoder.4.bias: 0.0592501163482666\n",
      "Gradient for encoder.mean.weight: 0.7407355904579163\n",
      "Gradient for encoder.mean.bias: 0.05752435326576233\n",
      "Gradient for encoder.log_var.weight: 0.4738128185272217\n",
      "Gradient for encoder.log_var.bias: 0.03579140827059746\n",
      "Gradient for decoder.decoder.0.weight: 0.014231869950890541\n",
      "Gradient for decoder.decoder.0.bias: 1.1348828127255572e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0008345217211171985\n",
      "Gradient for decoder.decoder.1.bias: 0.0004984985571354628\n",
      "Gradient for decoder.decoder.3.weight: 0.011832999996840954\n",
      "Gradient for decoder.decoder.3.bias: 1.4066531273115856e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.001178825506940484\n",
      "Gradient for decoder.decoder.4.bias: 0.0015588082605972886\n",
      "Gradient for decoder.decoder.6.weight: 0.001910609076730907\n",
      "Gradient for decoder.decoder.6.bias: 0.0001938090135809034\n",
      "Gradient for encoder.encoder.0.weight: 0.3964231014251709\n",
      "Gradient for encoder.encoder.0.bias: 6.368918170629456e-10\n",
      "Gradient for encoder.encoder.1.weight: 0.03107265755534172\n",
      "Gradient for encoder.encoder.1.bias: 0.023727647960186005\n",
      "Gradient for encoder.encoder.3.weight: 0.7067751288414001\n",
      "Gradient for encoder.encoder.3.bias: 5.232464683757598e-09\n",
      "Gradient for encoder.encoder.4.weight: 0.05418064072728157\n",
      "Gradient for encoder.encoder.4.bias: 0.053250402212142944\n",
      "Gradient for encoder.mean.weight: 0.664330244064331\n",
      "Gradient for encoder.mean.bias: 0.05223937705159187\n",
      "Gradient for encoder.log_var.weight: 0.43179237842559814\n",
      "Gradient for encoder.log_var.bias: 0.0315701998770237\n",
      "Gradient for decoder.decoder.0.weight: 0.014074811711907387\n",
      "Gradient for decoder.decoder.0.bias: 1.2580640695869505e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0007738852873444557\n",
      "Gradient for decoder.decoder.1.bias: 0.0005089170299470425\n",
      "Gradient for decoder.decoder.3.weight: 0.011488323099911213\n",
      "Gradient for decoder.decoder.3.bias: 1.7609294578058154e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.00127903011161834\n",
      "Gradient for decoder.decoder.4.bias: 0.001610838226042688\n",
      "Gradient for decoder.decoder.6.weight: 0.002002722816541791\n",
      "Gradient for decoder.decoder.6.bias: 0.0001961038651643321\n",
      "Gradient for encoder.encoder.0.weight: 0.5654928684234619\n",
      "Gradient for encoder.encoder.0.bias: 9.693502667218468e-10\n",
      "Gradient for encoder.encoder.1.weight: 0.05237824097275734\n",
      "Gradient for encoder.encoder.1.bias: 0.044368959963321686\n",
      "Gradient for encoder.encoder.3.weight: 1.1145542860031128\n",
      "Gradient for encoder.encoder.3.bias: 7.51890638639452e-09\n",
      "Gradient for encoder.encoder.4.weight: 0.06935146450996399\n",
      "Gradient for encoder.encoder.4.bias: 0.06850159913301468\n",
      "Gradient for encoder.mean.weight: 0.8215693831443787\n",
      "Gradient for encoder.mean.bias: 0.05467225983738899\n",
      "Gradient for encoder.log_var.weight: 0.5182340741157532\n",
      "Gradient for encoder.log_var.bias: 0.03556095436215401\n",
      "Gradient for decoder.decoder.0.weight: 0.016651038080453873\n",
      "Gradient for decoder.decoder.0.bias: 1.4737099041095547e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0009093579137697816\n",
      "Gradient for decoder.decoder.1.bias: 0.0005841056117787957\n",
      "Gradient for decoder.decoder.3.weight: 0.013071085326373577\n",
      "Gradient for decoder.decoder.3.bias: 1.3431573908651018e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0006639814237132668\n",
      "Gradient for decoder.decoder.4.bias: 0.0006993406568653882\n",
      "Gradient for decoder.decoder.6.weight: 0.001465560169890523\n",
      "Gradient for decoder.decoder.6.bias: 0.00011241742322454229\n",
      "Gradient for encoder.encoder.0.weight: 0.4523656964302063\n",
      "Gradient for encoder.encoder.0.bias: 6.945266584068577e-10\n",
      "Gradient for encoder.encoder.1.weight: 0.035922881215810776\n",
      "Gradient for encoder.encoder.1.bias: 0.028326183557510376\n",
      "Gradient for encoder.encoder.3.weight: 0.7425643801689148\n",
      "Gradient for encoder.encoder.3.bias: 6.189246448684571e-09\n",
      "Gradient for encoder.encoder.4.weight: 0.05165938287973404\n",
      "Gradient for encoder.encoder.4.bias: 0.05268219858407974\n",
      "Gradient for encoder.mean.weight: 0.6027843356132507\n",
      "Gradient for encoder.mean.bias: 0.04855562746524811\n",
      "Gradient for encoder.log_var.weight: 0.40273159742355347\n",
      "Gradient for encoder.log_var.bias: 0.029065951704978943\n",
      "Gradient for decoder.decoder.0.weight: 0.015988683328032494\n",
      "Gradient for decoder.decoder.0.bias: 1.2900926160686055e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0008799011702649295\n",
      "Gradient for decoder.decoder.1.bias: 0.0006093481206335127\n",
      "Gradient for decoder.decoder.3.weight: 0.013095129281282425\n",
      "Gradient for decoder.decoder.3.bias: 1.2525958048570374e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0007118161302059889\n",
      "Gradient for decoder.decoder.4.bias: 0.0007800292805768549\n",
      "Gradient for decoder.decoder.6.weight: 0.001480251201428473\n",
      "Gradient for decoder.decoder.6.bias: 0.0001132270772359334\n",
      "Gradient for encoder.encoder.0.weight: 0.31995895504951477\n",
      "Gradient for encoder.encoder.0.bias: 4.1921441318315544e-10\n",
      "Gradient for encoder.encoder.1.weight: 0.027177229523658752\n",
      "Gradient for encoder.encoder.1.bias: 0.020724430680274963\n",
      "Gradient for encoder.encoder.3.weight: 0.6064597964286804\n",
      "Gradient for encoder.encoder.3.bias: 4.192197256003283e-09\n",
      "Gradient for encoder.encoder.4.weight: 0.04281250387430191\n",
      "Gradient for encoder.encoder.4.bias: 0.04302098602056503\n",
      "Gradient for encoder.mean.weight: 0.49598369002342224\n",
      "Gradient for encoder.mean.bias: 0.04024078696966171\n",
      "Gradient for encoder.log_var.weight: 0.35289984941482544\n",
      "Gradient for encoder.log_var.bias: 0.023584619164466858\n",
      "Gradient for decoder.decoder.0.weight: 0.018050532788038254\n",
      "Gradient for decoder.decoder.0.bias: 1.5062524838516111e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0010338653810322285\n",
      "Gradient for decoder.decoder.1.bias: 0.0006224815733730793\n",
      "Gradient for decoder.decoder.3.weight: 0.014604114927351475\n",
      "Gradient for decoder.decoder.3.bias: 1.3250325836544619e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0008052303455770016\n",
      "Gradient for decoder.decoder.4.bias: 0.000910667993593961\n",
      "Gradient for decoder.decoder.6.weight: 0.0014367186231538653\n",
      "Gradient for decoder.decoder.6.bias: 0.00010376654972787946\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training VAE Epoch:  72%|███████▏  | 57/79 [00:01<00:00, 69.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient for encoder.encoder.0.weight: 0.37584951519966125\n",
      "Gradient for encoder.encoder.0.bias: 6.205775338052888e-10\n",
      "Gradient for encoder.encoder.1.weight: 0.03454049676656723\n",
      "Gradient for encoder.encoder.1.bias: 0.029367147013545036\n",
      "Gradient for encoder.encoder.3.weight: 0.7568774223327637\n",
      "Gradient for encoder.encoder.3.bias: 4.819927124088963e-09\n",
      "Gradient for encoder.encoder.4.weight: 0.05196542665362358\n",
      "Gradient for encoder.encoder.4.bias: 0.05039549246430397\n",
      "Gradient for encoder.mean.weight: 0.5983079075813293\n",
      "Gradient for encoder.mean.bias: 0.04185786098241806\n",
      "Gradient for encoder.log_var.weight: 0.3926016688346863\n",
      "Gradient for encoder.log_var.bias: 0.02614610828459263\n",
      "Gradient for decoder.decoder.0.weight: 0.01694711670279503\n",
      "Gradient for decoder.decoder.0.bias: 1.338879701551221e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0009266980341635644\n",
      "Gradient for decoder.decoder.1.bias: 0.0006100567406974733\n",
      "Gradient for decoder.decoder.3.weight: 0.013456116430461407\n",
      "Gradient for decoder.decoder.3.bias: 1.210328642864411e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0008368010749109089\n",
      "Gradient for decoder.decoder.4.bias: 0.0009884589817374945\n",
      "Gradient for decoder.decoder.6.weight: 0.001513914205133915\n",
      "Gradient for decoder.decoder.6.bias: 0.00012851061183027923\n",
      "Gradient for encoder.encoder.0.weight: 0.3051406741142273\n",
      "Gradient for encoder.encoder.0.bias: 5.105158518148301e-10\n",
      "Gradient for encoder.encoder.1.weight: 0.02656240575015545\n",
      "Gradient for encoder.encoder.1.bias: 0.02211814559996128\n",
      "Gradient for encoder.encoder.3.weight: 0.6051190495491028\n",
      "Gradient for encoder.encoder.3.bias: 4.789727725551529e-09\n",
      "Gradient for encoder.encoder.4.weight: 0.04237476736307144\n",
      "Gradient for encoder.encoder.4.bias: 0.041013382375240326\n",
      "Gradient for encoder.mean.weight: 0.4723265469074249\n",
      "Gradient for encoder.mean.bias: 0.03746255859732628\n",
      "Gradient for encoder.log_var.weight: 0.3217688500881195\n",
      "Gradient for encoder.log_var.bias: 0.020725658163428307\n",
      "Gradient for decoder.decoder.0.weight: 0.017069753259420395\n",
      "Gradient for decoder.decoder.0.bias: 1.4996466568550915e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.000863224791828543\n",
      "Gradient for decoder.decoder.1.bias: 0.0005749014671891928\n",
      "Gradient for decoder.decoder.3.weight: 0.012835717760026455\n",
      "Gradient for decoder.decoder.3.bias: 1.2867763798940501e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0008458082447759807\n",
      "Gradient for decoder.decoder.4.bias: 0.0009968169033527374\n",
      "Gradient for decoder.decoder.6.weight: 0.0014500933466479182\n",
      "Gradient for decoder.decoder.6.bias: 0.00012145307846367359\n",
      "Gradient for encoder.encoder.0.weight: 0.33380070328712463\n",
      "Gradient for encoder.encoder.0.bias: 4.962060207169827e-10\n",
      "Gradient for encoder.encoder.1.weight: 0.031961433589458466\n",
      "Gradient for encoder.encoder.1.bias: 0.02555868774652481\n",
      "Gradient for encoder.encoder.3.weight: 0.7211418747901917\n",
      "Gradient for encoder.encoder.3.bias: 6.37468877684455e-09\n",
      "Gradient for encoder.encoder.4.weight: 0.04245668649673462\n",
      "Gradient for encoder.encoder.4.bias: 0.03964397683739662\n",
      "Gradient for encoder.mean.weight: 0.5083706378936768\n",
      "Gradient for encoder.mean.bias: 0.03353789448738098\n",
      "Gradient for encoder.log_var.weight: 0.31492605805397034\n",
      "Gradient for encoder.log_var.bias: 0.01952308416366577\n",
      "Gradient for decoder.decoder.0.weight: 0.01632496900856495\n",
      "Gradient for decoder.decoder.0.bias: 1.3676644539106775e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0009384113363921642\n",
      "Gradient for decoder.decoder.1.bias: 0.0005999180721119046\n",
      "Gradient for decoder.decoder.3.weight: 0.013315764255821705\n",
      "Gradient for decoder.decoder.3.bias: 1.371051883136687e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0009619650081731379\n",
      "Gradient for decoder.decoder.4.bias: 0.0011676960857585073\n",
      "Gradient for decoder.decoder.6.weight: 0.0015368676977232099\n",
      "Gradient for decoder.decoder.6.bias: 0.00013209835742600262\n",
      "Gradient for encoder.encoder.0.weight: 0.28323864936828613\n",
      "Gradient for encoder.encoder.0.bias: 4.278539467161835e-10\n",
      "Gradient for encoder.encoder.1.weight: 0.026897137984633446\n",
      "Gradient for encoder.encoder.1.bias: 0.0195153821259737\n",
      "Gradient for encoder.encoder.3.weight: 0.5791882276535034\n",
      "Gradient for encoder.encoder.3.bias: 3.431076978088754e-09\n",
      "Gradient for encoder.encoder.4.weight: 0.03628689795732498\n",
      "Gradient for encoder.encoder.4.bias: 0.03595639020204544\n",
      "Gradient for encoder.mean.weight: 0.45051026344299316\n",
      "Gradient for encoder.mean.bias: 0.028328442946076393\n",
      "Gradient for encoder.log_var.weight: 0.27161023020744324\n",
      "Gradient for encoder.log_var.bias: 0.01663273386657238\n",
      "Gradient for decoder.decoder.0.weight: 0.017823226749897003\n",
      "Gradient for decoder.decoder.0.bias: 1.3278894650525785e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0009714454063214362\n",
      "Gradient for decoder.decoder.1.bias: 0.0006441930891014636\n",
      "Gradient for decoder.decoder.3.weight: 0.013997555710375309\n",
      "Gradient for decoder.decoder.3.bias: 1.4288178973309584e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0010261937277391553\n",
      "Gradient for decoder.decoder.4.bias: 0.0012227189727127552\n",
      "Gradient for decoder.decoder.6.weight: 0.0015689420979470015\n",
      "Gradient for decoder.decoder.6.bias: 0.00013600214151665568\n",
      "Gradient for encoder.encoder.0.weight: 0.32766345143318176\n",
      "Gradient for encoder.encoder.0.bias: 4.81957307396641e-10\n",
      "Gradient for encoder.encoder.1.weight: 0.029743660241365433\n",
      "Gradient for encoder.encoder.1.bias: 0.025266919285058975\n",
      "Gradient for encoder.encoder.3.weight: 0.630733072757721\n",
      "Gradient for encoder.encoder.3.bias: 4.592475288944797e-09\n",
      "Gradient for encoder.encoder.4.weight: 0.038211289793252945\n",
      "Gradient for encoder.encoder.4.bias: 0.03586496412754059\n",
      "Gradient for encoder.mean.weight: 0.46581292152404785\n",
      "Gradient for encoder.mean.bias: 0.02863612212240696\n",
      "Gradient for encoder.log_var.weight: 0.2824825644493103\n",
      "Gradient for encoder.log_var.bias: 0.01551364827901125\n",
      "Gradient for decoder.decoder.0.weight: 0.01972021907567978\n",
      "Gradient for decoder.decoder.0.bias: 1.582749487027968e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.001071469159796834\n",
      "Gradient for decoder.decoder.1.bias: 0.0007176925428211689\n",
      "Gradient for decoder.decoder.3.weight: 0.015490727499127388\n",
      "Gradient for decoder.decoder.3.bias: 1.2710331398491093e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0005863407859578729\n",
      "Gradient for decoder.decoder.4.bias: 0.0005379082285799086\n",
      "Gradient for decoder.decoder.6.weight: 0.0012828997569158673\n",
      "Gradient for decoder.decoder.6.bias: 7.822531188139692e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.26957881450653076\n",
      "Gradient for encoder.encoder.0.bias: 4.545817888779169e-10\n",
      "Gradient for encoder.encoder.1.weight: 0.023799125105142593\n",
      "Gradient for encoder.encoder.1.bias: 0.019283639267086983\n",
      "Gradient for encoder.encoder.3.weight: 0.5519407391548157\n",
      "Gradient for encoder.encoder.3.bias: 3.5108314033749366e-09\n",
      "Gradient for encoder.encoder.4.weight: 0.03167913854122162\n",
      "Gradient for encoder.encoder.4.bias: 0.03274941444396973\n",
      "Gradient for encoder.mean.weight: 0.38457366824150085\n",
      "Gradient for encoder.mean.bias: 0.027395999059081078\n",
      "Gradient for encoder.log_var.weight: 0.2558125853538513\n",
      "Gradient for encoder.log_var.bias: 0.01569506525993347\n",
      "Gradient for decoder.decoder.0.weight: 0.016349872574210167\n",
      "Gradient for decoder.decoder.0.bias: 1.3564339929050817e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0009224335663020611\n",
      "Gradient for decoder.decoder.1.bias: 0.0005687106749974191\n",
      "Gradient for decoder.decoder.3.weight: 0.012286918237805367\n",
      "Gradient for decoder.decoder.3.bias: 1.1119880710674934e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0005559019627980888\n",
      "Gradient for decoder.decoder.4.bias: 0.000646963540930301\n",
      "Gradient for decoder.decoder.6.weight: 0.0014949627220630646\n",
      "Gradient for decoder.decoder.6.bias: 0.0001295488909818232\n",
      "Gradient for encoder.encoder.0.weight: 0.2591775953769684\n",
      "Gradient for encoder.encoder.0.bias: 3.67917862842404e-10\n",
      "Gradient for encoder.encoder.1.weight: 0.02499401941895485\n",
      "Gradient for encoder.encoder.1.bias: 0.020197970792651176\n",
      "Gradient for encoder.encoder.3.weight: 0.5582422614097595\n",
      "Gradient for encoder.encoder.3.bias: 4.189749880367799e-09\n",
      "Gradient for encoder.encoder.4.weight: 0.03332352265715599\n",
      "Gradient for encoder.encoder.4.bias: 0.03136000037193298\n",
      "Gradient for encoder.mean.weight: 0.4008232057094574\n",
      "Gradient for encoder.mean.bias: 0.02383950538933277\n",
      "Gradient for encoder.log_var.weight: 0.24433527886867523\n",
      "Gradient for encoder.log_var.bias: 0.014244252815842628\n",
      "Gradient for decoder.decoder.0.weight: 0.019299320876598358\n",
      "Gradient for decoder.decoder.0.bias: 1.5463649805091961e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0011105505982413888\n",
      "Gradient for decoder.decoder.1.bias: 0.0007143129478208721\n",
      "Gradient for decoder.decoder.3.weight: 0.015144596807658672\n",
      "Gradient for decoder.decoder.3.bias: 1.2618284195298202e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0005320122581906617\n",
      "Gradient for decoder.decoder.4.bias: 0.000466222147224471\n",
      "Gradient for decoder.decoder.6.weight: 0.0012829655315726995\n",
      "Gradient for decoder.decoder.6.bias: 8.73211829457432e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.2789542078971863\n",
      "Gradient for encoder.encoder.0.bias: 4.710903889204587e-10\n",
      "Gradient for encoder.encoder.1.weight: 0.028395099565386772\n",
      "Gradient for encoder.encoder.1.bias: 0.02063753642141819\n",
      "Gradient for encoder.encoder.3.weight: 0.5935000777244568\n",
      "Gradient for encoder.encoder.3.bias: 3.6212017828773924e-09\n",
      "Gradient for encoder.encoder.4.weight: 0.03455733880400658\n",
      "Gradient for encoder.encoder.4.bias: 0.03130781650543213\n",
      "Gradient for encoder.mean.weight: 0.4468023478984833\n",
      "Gradient for encoder.mean.bias: 0.02473730407655239\n",
      "Gradient for encoder.log_var.weight: 0.23778381943702698\n",
      "Gradient for encoder.log_var.bias: 0.01363212801516056\n",
      "Gradient for decoder.decoder.0.weight: 0.0182765144854784\n",
      "Gradient for decoder.decoder.0.bias: 1.4980285067967003e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.001095771323889494\n",
      "Gradient for decoder.decoder.1.bias: 0.0006590810953639448\n",
      "Gradient for decoder.decoder.3.weight: 0.014136206358671188\n",
      "Gradient for decoder.decoder.3.bias: 1.0905595870802642e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0005031257169321179\n",
      "Gradient for decoder.decoder.4.bias: 0.00043298478703945875\n",
      "Gradient for decoder.decoder.6.weight: 0.001337136491201818\n",
      "Gradient for decoder.decoder.6.bias: 9.856803808361292e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.3307419419288635\n",
      "Gradient for encoder.encoder.0.bias: 5.306434180951669e-10\n",
      "Gradient for encoder.encoder.1.weight: 0.029025107622146606\n",
      "Gradient for encoder.encoder.1.bias: 0.02222982794046402\n",
      "Gradient for encoder.encoder.3.weight: 0.6415380835533142\n",
      "Gradient for encoder.encoder.3.bias: 4.229391503685065e-09\n",
      "Gradient for encoder.encoder.4.weight: 0.0385066494345665\n",
      "Gradient for encoder.encoder.4.bias: 0.035765256732702255\n",
      "Gradient for encoder.mean.weight: 0.448242723941803\n",
      "Gradient for encoder.mean.bias: 0.026332303881645203\n",
      "Gradient for encoder.log_var.weight: 0.26370570063591003\n",
      "Gradient for encoder.log_var.bias: 0.013372617773711681\n",
      "Gradient for decoder.decoder.0.weight: 0.01459961012005806\n",
      "Gradient for decoder.decoder.0.bias: 1.1210571360109611e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0007704257732257247\n",
      "Gradient for decoder.decoder.1.bias: 0.0005054273060522974\n",
      "Gradient for decoder.decoder.3.weight: 0.010952039621770382\n",
      "Gradient for decoder.decoder.3.bias: 1.3737740112151897e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0009386774036101997\n",
      "Gradient for decoder.decoder.4.bias: 0.0012297967914491892\n",
      "Gradient for decoder.decoder.6.weight: 0.0013672844506800175\n",
      "Gradient for decoder.decoder.6.bias: 0.00012269752915017307\n",
      "Gradient for encoder.encoder.0.weight: 0.3450460135936737\n",
      "Gradient for encoder.encoder.0.bias: 5.751517040408771e-10\n",
      "Gradient for encoder.encoder.1.weight: 0.030353354290127754\n",
      "Gradient for encoder.encoder.1.bias: 0.022629452869296074\n",
      "Gradient for encoder.encoder.3.weight: 0.6370452046394348\n",
      "Gradient for encoder.encoder.3.bias: 3.6870066999483697e-09\n",
      "Gradient for encoder.encoder.4.weight: 0.035681791603565216\n",
      "Gradient for encoder.encoder.4.bias: 0.031392037868499756\n",
      "Gradient for encoder.mean.weight: 0.4850718379020691\n",
      "Gradient for encoder.mean.bias: 0.023513615131378174\n",
      "Gradient for encoder.log_var.weight: 0.28225958347320557\n",
      "Gradient for encoder.log_var.bias: 0.011749944649636745\n",
      "Gradient for decoder.decoder.0.weight: 0.015039266087114811\n",
      "Gradient for decoder.decoder.0.bias: 1.218535133906684e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0008185534970834851\n",
      "Gradient for decoder.decoder.1.bias: 0.0005342119256965816\n",
      "Gradient for decoder.decoder.3.weight: 0.011833504773676395\n",
      "Gradient for decoder.decoder.3.bias: 1.1719536452403645e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0008230871753767133\n",
      "Gradient for decoder.decoder.4.bias: 0.00101325917057693\n",
      "Gradient for decoder.decoder.6.weight: 0.0012829842744395137\n",
      "Gradient for decoder.decoder.6.bias: 0.00010668217873899266\n",
      "Gradient for encoder.encoder.0.weight: 0.2510918378829956\n",
      "Gradient for encoder.encoder.0.bias: 3.881161503294095e-10\n",
      "Gradient for encoder.encoder.1.weight: 0.03072780929505825\n",
      "Gradient for encoder.encoder.1.bias: 0.02220110222697258\n",
      "Gradient for encoder.encoder.3.weight: 0.6368886232376099\n",
      "Gradient for encoder.encoder.3.bias: 3.4587914754524718e-09\n",
      "Gradient for encoder.encoder.4.weight: 0.03758018836379051\n",
      "Gradient for encoder.encoder.4.bias: 0.030032766982913017\n",
      "Gradient for encoder.mean.weight: 0.4302525818347931\n",
      "Gradient for encoder.mean.bias: 0.02205057442188263\n",
      "Gradient for encoder.log_var.weight: 0.24409864842891693\n",
      "Gradient for encoder.log_var.bias: 0.013159029185771942\n",
      "Gradient for decoder.decoder.0.weight: 0.01837019808590412\n",
      "Gradient for decoder.decoder.0.bias: 1.4991173580281014e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0010542768286541104\n",
      "Gradient for decoder.decoder.1.bias: 0.0006918713334016502\n",
      "Gradient for decoder.decoder.3.weight: 0.015289012342691422\n",
      "Gradient for decoder.decoder.3.bias: 1.363051616021238e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0008026938303373754\n",
      "Gradient for decoder.decoder.4.bias: 0.0009828804759308696\n",
      "Gradient for decoder.decoder.6.weight: 0.001265917788259685\n",
      "Gradient for decoder.decoder.6.bias: 9.90999978967011e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.27117058634757996\n",
      "Gradient for encoder.encoder.0.bias: 4.509841944333459e-10\n",
      "Gradient for encoder.encoder.1.weight: 0.023165864869952202\n",
      "Gradient for encoder.encoder.1.bias: 0.019430983811616898\n",
      "Gradient for encoder.encoder.3.weight: 0.4952690005302429\n",
      "Gradient for encoder.encoder.3.bias: 3.50642270774415e-09\n",
      "Gradient for encoder.encoder.4.weight: 0.029802588745951653\n",
      "Gradient for encoder.encoder.4.bias: 0.0267490241676569\n",
      "Gradient for encoder.mean.weight: 0.34839630126953125\n",
      "Gradient for encoder.mean.bias: 0.019831713289022446\n",
      "Gradient for encoder.log_var.weight: 0.21898290514945984\n",
      "Gradient for encoder.log_var.bias: 0.012564368546009064\n",
      "Gradient for decoder.decoder.0.weight: 0.016012201085686684\n",
      "Gradient for decoder.decoder.0.bias: 1.381238873277013e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0009019323042593896\n",
      "Gradient for decoder.decoder.1.bias: 0.0005630698287859559\n",
      "Gradient for decoder.decoder.3.weight: 0.013136996887624264\n",
      "Gradient for decoder.decoder.3.bias: 1.145315786654777e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0005943321157246828\n",
      "Gradient for decoder.decoder.4.bias: 0.0006693603936582804\n",
      "Gradient for decoder.decoder.6.weight: 0.001267007552087307\n",
      "Gradient for decoder.decoder.6.bias: 9.114581189351156e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.22302748262882233\n",
      "Gradient for encoder.encoder.0.bias: 3.367060241732389e-10\n",
      "Gradient for encoder.encoder.1.weight: 0.02466389909386635\n",
      "Gradient for encoder.encoder.1.bias: 0.019259143620729446\n",
      "Gradient for encoder.encoder.3.weight: 0.5274403691291809\n",
      "Gradient for encoder.encoder.3.bias: 3.2186677767498395e-09\n",
      "Gradient for encoder.encoder.4.weight: 0.029739009216427803\n",
      "Gradient for encoder.encoder.4.bias: 0.02996120974421501\n",
      "Gradient for encoder.mean.weight: 0.38471782207489014\n",
      "Gradient for encoder.mean.bias: 0.023377494886517525\n",
      "Gradient for encoder.log_var.weight: 0.21210697293281555\n",
      "Gradient for encoder.log_var.bias: 0.013228879310190678\n",
      "Gradient for decoder.decoder.0.weight: 0.018437545746564865\n",
      "Gradient for decoder.decoder.0.bias: 1.7175523503443202e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.001068596262484789\n",
      "Gradient for decoder.decoder.1.bias: 0.0007164573180489242\n",
      "Gradient for decoder.decoder.3.weight: 0.014492293819785118\n",
      "Gradient for decoder.decoder.3.bias: 1.1434143909472283e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0005018137744627893\n",
      "Gradient for decoder.decoder.4.bias: 0.00043515252764336765\n",
      "Gradient for decoder.decoder.6.weight: 0.0011858590878546238\n",
      "Gradient for decoder.decoder.6.bias: 8.013316983124241e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.19585292041301727\n",
      "Gradient for encoder.encoder.0.bias: 3.1880773021519815e-10\n",
      "Gradient for encoder.encoder.1.weight: 0.02186843566596508\n",
      "Gradient for encoder.encoder.1.bias: 0.016285432502627373\n",
      "Gradient for encoder.encoder.3.weight: 0.4535576105117798\n",
      "Gradient for encoder.encoder.3.bias: 3.034786422162483e-09\n",
      "Gradient for encoder.encoder.4.weight: 0.026078414171934128\n",
      "Gradient for encoder.encoder.4.bias: 0.02484790049493313\n",
      "Gradient for encoder.mean.weight: 0.33004921674728394\n",
      "Gradient for encoder.mean.bias: 0.019004253670573235\n",
      "Gradient for encoder.log_var.weight: 0.19378985464572906\n",
      "Gradient for encoder.log_var.bias: 0.011917593888938427\n",
      "Gradient for decoder.decoder.0.weight: 0.02041444554924965\n",
      "Gradient for decoder.decoder.0.bias: 1.6408582825810925e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0011243628105148673\n",
      "Gradient for decoder.decoder.1.bias: 0.0007532263407483697\n",
      "Gradient for decoder.decoder.3.weight: 0.01566264219582081\n",
      "Gradient for decoder.decoder.3.bias: 1.1544896982851327e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.000538294785656035\n",
      "Gradient for decoder.decoder.4.bias: 0.0004915092722512782\n",
      "Gradient for decoder.decoder.6.weight: 0.0012293156469240785\n",
      "Gradient for decoder.decoder.6.bias: 7.500172796426341e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.24784205853939056\n",
      "Gradient for encoder.encoder.0.bias: 4.28473617697378e-10\n",
      "Gradient for encoder.encoder.1.weight: 0.023534057661890984\n",
      "Gradient for encoder.encoder.1.bias: 0.018002286553382874\n",
      "Gradient for encoder.encoder.3.weight: 0.5115078687667847\n",
      "Gradient for encoder.encoder.3.bias: 2.7282187620158993e-09\n",
      "Gradient for encoder.encoder.4.weight: 0.030473880469799042\n",
      "Gradient for encoder.encoder.4.bias: 0.02527577057480812\n",
      "Gradient for encoder.mean.weight: 0.37355726957321167\n",
      "Gradient for encoder.mean.bias: 0.01750321500003338\n",
      "Gradient for encoder.log_var.weight: 0.20017488300800323\n",
      "Gradient for encoder.log_var.bias: 0.011623448692262173\n",
      "Gradient for decoder.decoder.0.weight: 0.01584489457309246\n",
      "Gradient for decoder.decoder.0.bias: 1.2545367522598383e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0008400679798796773\n",
      "Gradient for decoder.decoder.1.bias: 0.0005436574574559927\n",
      "Gradient for decoder.decoder.3.weight: 0.012222384102642536\n",
      "Gradient for decoder.decoder.3.bias: 1.139963262675181e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0006808387115597725\n",
      "Gradient for decoder.decoder.4.bias: 0.0008152778027579188\n",
      "Gradient for decoder.decoder.6.weight: 0.001129245851188898\n",
      "Gradient for decoder.decoder.6.bias: 8.415847696596757e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.2281418889760971\n",
      "Gradient for encoder.encoder.0.bias: 3.7983247103134943e-10\n",
      "Gradient for encoder.encoder.1.weight: 0.0230453759431839\n",
      "Gradient for encoder.encoder.1.bias: 0.01738004758954048\n",
      "Gradient for encoder.encoder.3.weight: 0.5157478451728821\n",
      "Gradient for encoder.encoder.3.bias: 2.9444577887005607e-09\n",
      "Gradient for encoder.encoder.4.weight: 0.03642227128148079\n",
      "Gradient for encoder.encoder.4.bias: 0.027416281402111053\n",
      "Gradient for encoder.mean.weight: 0.43220606446266174\n",
      "Gradient for encoder.mean.bias: 0.018931902945041656\n",
      "Gradient for encoder.log_var.weight: 0.22558699548244476\n",
      "Gradient for encoder.log_var.bias: 0.011376471258699894\n",
      "Gradient for decoder.decoder.0.weight: 0.01768658123910427\n",
      "Gradient for decoder.decoder.0.bias: 1.4549890459125692e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0009339844109490514\n",
      "Gradient for decoder.decoder.1.bias: 0.000655968498904258\n",
      "Gradient for decoder.decoder.3.weight: 0.014104289934039116\n",
      "Gradient for decoder.decoder.3.bias: 1.1775305730488128e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.000663439801428467\n",
      "Gradient for decoder.decoder.4.bias: 0.0007502590888179839\n",
      "Gradient for decoder.decoder.6.weight: 0.0011224879417568445\n",
      "Gradient for decoder.decoder.6.bias: 7.275628013303503e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training VAE Epoch:  92%|█████████▏| 73/79 [00:01<00:00, 74.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient for encoder.encoder.0.weight: 0.21138714253902435\n",
      "Gradient for encoder.encoder.0.bias: 3.3982228142548365e-10\n",
      "Gradient for encoder.encoder.1.weight: 0.021551696583628654\n",
      "Gradient for encoder.encoder.1.bias: 0.016074124723672867\n",
      "Gradient for encoder.encoder.3.weight: 0.4748550355434418\n",
      "Gradient for encoder.encoder.3.bias: 2.669149345990718e-09\n",
      "Gradient for encoder.encoder.4.weight: 0.026683740317821503\n",
      "Gradient for encoder.encoder.4.bias: 0.025525689125061035\n",
      "Gradient for encoder.mean.weight: 0.34650105237960815\n",
      "Gradient for encoder.mean.bias: 0.021359464153647423\n",
      "Gradient for encoder.log_var.weight: 0.20149143040180206\n",
      "Gradient for encoder.log_var.bias: 0.012724008411169052\n",
      "Gradient for decoder.decoder.0.weight: 0.01637527160346508\n",
      "Gradient for decoder.decoder.0.bias: 1.3903342366283766e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0008685918874107301\n",
      "Gradient for decoder.decoder.1.bias: 0.0005686196964234114\n",
      "Gradient for decoder.decoder.3.weight: 0.012663489207625389\n",
      "Gradient for decoder.decoder.3.bias: 1.0976863168421502e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0004662620194721967\n",
      "Gradient for decoder.decoder.4.bias: 0.0004648811591323465\n",
      "Gradient for decoder.decoder.6.weight: 0.001025920151732862\n",
      "Gradient for decoder.decoder.6.bias: 5.84525078011211e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.1985541582107544\n",
      "Gradient for encoder.encoder.0.bias: 3.4068042831236767e-10\n",
      "Gradient for encoder.encoder.1.weight: 0.020138904452323914\n",
      "Gradient for encoder.encoder.1.bias: 0.016500039026141167\n",
      "Gradient for encoder.encoder.3.weight: 0.4436753988265991\n",
      "Gradient for encoder.encoder.3.bias: 2.7004518621254192e-09\n",
      "Gradient for encoder.encoder.4.weight: 0.024252811446785927\n",
      "Gradient for encoder.encoder.4.bias: 0.02297806926071644\n",
      "Gradient for encoder.mean.weight: 0.29390981793403625\n",
      "Gradient for encoder.mean.bias: 0.01642976701259613\n",
      "Gradient for encoder.log_var.weight: 0.18289192020893097\n",
      "Gradient for encoder.log_var.bias: 0.01104020420461893\n",
      "Gradient for decoder.decoder.0.weight: 0.0183381587266922\n",
      "Gradient for decoder.decoder.0.bias: 1.6119398871250468e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0010838243179023266\n",
      "Gradient for decoder.decoder.1.bias: 0.0006781485280953348\n",
      "Gradient for decoder.decoder.3.weight: 0.01492967177182436\n",
      "Gradient for decoder.decoder.3.bias: 1.168541374774179e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0005497561069205403\n",
      "Gradient for decoder.decoder.4.bias: 0.0005440720124170184\n",
      "Gradient for decoder.decoder.6.weight: 0.0010956424521282315\n",
      "Gradient for decoder.decoder.6.bias: 6.26163964625448e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.20707619190216064\n",
      "Gradient for encoder.encoder.0.bias: 3.7043904055344967e-10\n",
      "Gradient for encoder.encoder.1.weight: 0.020295830443501472\n",
      "Gradient for encoder.encoder.1.bias: 0.015454224310815334\n",
      "Gradient for encoder.encoder.3.weight: 0.4194103181362152\n",
      "Gradient for encoder.encoder.3.bias: 2.5692508121011315e-09\n",
      "Gradient for encoder.encoder.4.weight: 0.02654840797185898\n",
      "Gradient for encoder.encoder.4.bias: 0.026818636804819107\n",
      "Gradient for encoder.mean.weight: 0.3337186872959137\n",
      "Gradient for encoder.mean.bias: 0.02130352333188057\n",
      "Gradient for encoder.log_var.weight: 0.19596759974956512\n",
      "Gradient for encoder.log_var.bias: 0.013226091861724854\n",
      "Gradient for decoder.decoder.0.weight: 0.016736416146159172\n",
      "Gradient for decoder.decoder.0.bias: 1.4452750107807333e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0009339522221125662\n",
      "Gradient for decoder.decoder.1.bias: 0.0006189157720655203\n",
      "Gradient for decoder.decoder.3.weight: 0.0129649443551898\n",
      "Gradient for decoder.decoder.3.bias: 1.0329298527622655e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.00046915141865611076\n",
      "Gradient for decoder.decoder.4.bias: 0.0004395793948788196\n",
      "Gradient for decoder.decoder.6.weight: 0.0010959987994283438\n",
      "Gradient for decoder.decoder.6.bias: 6.724065315211192e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.19344280660152435\n",
      "Gradient for encoder.encoder.0.bias: 3.179289054244805e-10\n",
      "Gradient for encoder.encoder.1.weight: 0.01947673037648201\n",
      "Gradient for encoder.encoder.1.bias: 0.015868641436100006\n",
      "Gradient for encoder.encoder.3.weight: 0.4338721036911011\n",
      "Gradient for encoder.encoder.3.bias: 2.6222313209700587e-09\n",
      "Gradient for encoder.encoder.4.weight: 0.025934061035513878\n",
      "Gradient for encoder.encoder.4.bias: 0.021467119455337524\n",
      "Gradient for encoder.mean.weight: 0.31844696402549744\n",
      "Gradient for encoder.mean.bias: 0.014467546716332436\n",
      "Gradient for encoder.log_var.weight: 0.1808701604604721\n",
      "Gradient for encoder.log_var.bias: 0.009601173922419548\n",
      "Gradient for decoder.decoder.0.weight: 0.01655067875981331\n",
      "Gradient for decoder.decoder.0.bias: 1.36629443869829e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0009132966515608132\n",
      "Gradient for decoder.decoder.1.bias: 0.000582479580771178\n",
      "Gradient for decoder.decoder.3.weight: 0.012866051867604256\n",
      "Gradient for decoder.decoder.3.bias: 9.208523527037826e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00045829080045223236\n",
      "Gradient for decoder.decoder.4.bias: 0.0004003348294645548\n",
      "Gradient for decoder.decoder.6.weight: 0.001096317544579506\n",
      "Gradient for decoder.decoder.6.bias: 7.023331272648647e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.1838960349559784\n",
      "Gradient for encoder.encoder.0.bias: 2.7079821718345443e-10\n",
      "Gradient for encoder.encoder.1.weight: 0.020720478147268295\n",
      "Gradient for encoder.encoder.1.bias: 0.016654441133141518\n",
      "Gradient for encoder.encoder.3.weight: 0.4482327997684479\n",
      "Gradient for encoder.encoder.3.bias: 2.339600735368208e-09\n",
      "Gradient for encoder.encoder.4.weight: 0.02641908824443817\n",
      "Gradient for encoder.encoder.4.bias: 0.024715639650821686\n",
      "Gradient for encoder.mean.weight: 0.3155401051044464\n",
      "Gradient for encoder.mean.bias: 0.017359638586640358\n",
      "Gradient for encoder.log_var.weight: 0.1904735267162323\n",
      "Gradient for encoder.log_var.bias: 0.012245667167007923\n",
      "Gradient for decoder.decoder.0.weight: 0.021124912425875664\n",
      "Gradient for decoder.decoder.0.bias: 1.8677913382614264e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.001125827431678772\n",
      "Gradient for decoder.decoder.1.bias: 0.0007509159040637314\n",
      "Gradient for decoder.decoder.3.weight: 0.016703592613339424\n",
      "Gradient for decoder.decoder.3.bias: 1.3308727730976244e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0006416651303879917\n",
      "Gradient for decoder.decoder.4.bias: 0.0006391688366420567\n",
      "Gradient for decoder.decoder.6.weight: 0.0011685986537486315\n",
      "Gradient for decoder.decoder.6.bias: 7.17539296601899e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.22010977566242218\n",
      "Gradient for encoder.encoder.0.bias: 3.2492167290065765e-10\n",
      "Gradient for encoder.encoder.1.weight: 0.020021285861730576\n",
      "Gradient for encoder.encoder.1.bias: 0.015916263684630394\n",
      "Gradient for encoder.encoder.3.weight: 0.4617154598236084\n",
      "Gradient for encoder.encoder.3.bias: 2.389406450475917e-09\n",
      "Gradient for encoder.encoder.4.weight: 0.027610743418335915\n",
      "Gradient for encoder.encoder.4.bias: 0.02423970215022564\n",
      "Gradient for encoder.mean.weight: 0.33518990874290466\n",
      "Gradient for encoder.mean.bias: 0.017951177433133125\n",
      "Gradient for encoder.log_var.weight: 0.18634715676307678\n",
      "Gradient for encoder.log_var.bias: 0.012033665552735329\n",
      "Gradient for decoder.decoder.0.weight: 0.01586219109594822\n",
      "Gradient for decoder.decoder.0.bias: 1.2427463225161972e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0007957666530273855\n",
      "Gradient for decoder.decoder.1.bias: 0.0005897751543670893\n",
      "Gradient for decoder.decoder.3.weight: 0.012692569755017757\n",
      "Gradient for decoder.decoder.3.bias: 1.3281357957861673e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0008540460839867592\n",
      "Gradient for decoder.decoder.4.bias: 0.0010191859910264611\n",
      "Gradient for decoder.decoder.6.weight: 0.00126445887144655\n",
      "Gradient for decoder.decoder.6.bias: 9.844094165600836e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.22751805186271667\n",
      "Gradient for encoder.encoder.0.bias: 3.6273775649853235e-10\n",
      "Gradient for encoder.encoder.1.weight: 0.02350669726729393\n",
      "Gradient for encoder.encoder.1.bias: 0.01930309645831585\n",
      "Gradient for encoder.encoder.3.weight: 0.5351355671882629\n",
      "Gradient for encoder.encoder.3.bias: 2.619650496527015e-09\n",
      "Gradient for encoder.encoder.4.weight: 0.031041666865348816\n",
      "Gradient for encoder.encoder.4.bias: 0.0278524998575449\n",
      "Gradient for encoder.mean.weight: 0.3889070153236389\n",
      "Gradient for encoder.mean.bias: 0.0163258109241724\n",
      "Gradient for encoder.log_var.weight: 0.22454094886779785\n",
      "Gradient for encoder.log_var.bias: 0.00975171010941267\n",
      "Gradient for decoder.decoder.0.weight: 0.015212900005280972\n",
      "Gradient for decoder.decoder.0.bias: 1.3492329475894849e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.000831497076433152\n",
      "Gradient for decoder.decoder.1.bias: 0.000554836995434016\n",
      "Gradient for decoder.decoder.3.weight: 0.011979314498603344\n",
      "Gradient for decoder.decoder.3.bias: 1.0129191235774826e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.00039984285831451416\n",
      "Gradient for decoder.decoder.4.bias: 0.00038138634408824146\n",
      "Gradient for decoder.decoder.6.weight: 0.0010180782992392778\n",
      "Gradient for decoder.decoder.6.bias: 5.332016371539794e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.17354032397270203\n",
      "Gradient for encoder.encoder.0.bias: 2.619289507510558e-10\n",
      "Gradient for encoder.encoder.1.weight: 0.016555456444621086\n",
      "Gradient for encoder.encoder.1.bias: 0.014972205273807049\n",
      "Gradient for encoder.encoder.3.weight: 0.3560749590396881\n",
      "Gradient for encoder.encoder.3.bias: 2.5657018731806147e-09\n",
      "Gradient for encoder.encoder.4.weight: 0.024661310017108917\n",
      "Gradient for encoder.encoder.4.bias: 0.022853048518300056\n",
      "Gradient for encoder.mean.weight: 0.2865108549594879\n",
      "Gradient for encoder.mean.bias: 0.016928479075431824\n",
      "Gradient for encoder.log_var.weight: 0.1643638163805008\n",
      "Gradient for encoder.log_var.bias: 0.009589522145688534\n",
      "Gradient for decoder.decoder.0.weight: 0.01950782537460327\n",
      "Gradient for decoder.decoder.0.bias: 1.7038800925739395e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0011726042721420527\n",
      "Gradient for decoder.decoder.1.bias: 0.0007421517511829734\n",
      "Gradient for decoder.decoder.3.weight: 0.016039367765188217\n",
      "Gradient for decoder.decoder.3.bias: 1.240854780037992e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0005833818577229977\n",
      "Gradient for decoder.decoder.4.bias: 0.0005138207925483584\n",
      "Gradient for decoder.decoder.6.weight: 0.0010322299785912037\n",
      "Gradient for decoder.decoder.6.bias: 5.69602707400918e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.17342042922973633\n",
      "Gradient for encoder.encoder.0.bias: 2.702723322922651e-10\n",
      "Gradient for encoder.encoder.1.weight: 0.019852979108691216\n",
      "Gradient for encoder.encoder.1.bias: 0.015624873340129852\n",
      "Gradient for encoder.encoder.3.weight: 0.4421914517879486\n",
      "Gradient for encoder.encoder.3.bias: 2.7652293788094084e-09\n",
      "Gradient for encoder.encoder.4.weight: 0.029966730624437332\n",
      "Gradient for encoder.encoder.4.bias: 0.027369238436222076\n",
      "Gradient for encoder.mean.weight: 0.356703519821167\n",
      "Gradient for encoder.mean.bias: 0.019215812906622887\n",
      "Gradient for encoder.log_var.weight: 0.1898423135280609\n",
      "Gradient for encoder.log_var.bias: 0.00923155527561903\n",
      "Gradient for decoder.decoder.0.weight: 0.018506795167922974\n",
      "Gradient for decoder.decoder.0.bias: 1.4744586107617863e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0009784644935280085\n",
      "Gradient for decoder.decoder.1.bias: 0.0006739561795257032\n",
      "Gradient for decoder.decoder.3.weight: 0.014630695804953575\n",
      "Gradient for decoder.decoder.3.bias: 1.1123663101741954e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0005377457127906382\n",
      "Gradient for decoder.decoder.4.bias: 0.0004685622116085142\n",
      "Gradient for decoder.decoder.6.weight: 0.0010840916074812412\n",
      "Gradient for decoder.decoder.6.bias: 5.8604036894394085e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.1669788956642151\n",
      "Gradient for encoder.encoder.0.bias: 2.6333621394591944e-10\n",
      "Gradient for encoder.encoder.1.weight: 0.01685585454106331\n",
      "Gradient for encoder.encoder.1.bias: 0.014129954390227795\n",
      "Gradient for encoder.encoder.3.weight: 0.38084954023361206\n",
      "Gradient for encoder.encoder.3.bias: 2.424244360810235e-09\n",
      "Gradient for encoder.encoder.4.weight: 0.025549231097102165\n",
      "Gradient for encoder.encoder.4.bias: 0.022722017019987106\n",
      "Gradient for encoder.mean.weight: 0.3185809850692749\n",
      "Gradient for encoder.mean.bias: 0.016814859583973885\n",
      "Gradient for encoder.log_var.weight: 0.1662287563085556\n",
      "Gradient for encoder.log_var.bias: 0.008905535563826561\n",
      "Gradient for decoder.decoder.0.weight: 0.01664627343416214\n",
      "Gradient for decoder.decoder.0.bias: 1.475926603156097e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0009091129759326577\n",
      "Gradient for decoder.decoder.1.bias: 0.0006255503394640982\n",
      "Gradient for decoder.decoder.3.weight: 0.013532779179513454\n",
      "Gradient for decoder.decoder.3.bias: 1.189642412358083e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0005082552670501173\n",
      "Gradient for decoder.decoder.4.bias: 0.00041958127985708416\n",
      "Gradient for decoder.decoder.6.weight: 0.001040597795508802\n",
      "Gradient for decoder.decoder.6.bias: 5.287136809783988e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.15558502078056335\n",
      "Gradient for encoder.encoder.0.bias: 2.4086116434673954e-10\n",
      "Gradient for encoder.encoder.1.weight: 0.016898637637495995\n",
      "Gradient for encoder.encoder.1.bias: 0.014592096209526062\n",
      "Gradient for encoder.encoder.3.weight: 0.37138330936431885\n",
      "Gradient for encoder.encoder.3.bias: 1.9432435660604597e-09\n",
      "Gradient for encoder.encoder.4.weight: 0.02220250479876995\n",
      "Gradient for encoder.encoder.4.bias: 0.020956899970769882\n",
      "Gradient for encoder.mean.weight: 0.30435776710510254\n",
      "Gradient for encoder.mean.bias: 0.015522305853664875\n",
      "Gradient for encoder.log_var.weight: 0.1675359159708023\n",
      "Gradient for encoder.log_var.bias: 0.00875585526227951\n",
      "Gradient for decoder.decoder.0.weight: 0.019722826778888702\n",
      "Gradient for decoder.decoder.0.bias: 1.6798344659729736e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.001125569804571569\n",
      "Gradient for decoder.decoder.1.bias: 0.0007077599875628948\n",
      "Gradient for decoder.decoder.3.weight: 0.015490693040192127\n",
      "Gradient for decoder.decoder.3.bias: 1.2743417432403703e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0006300603854469955\n",
      "Gradient for decoder.decoder.4.bias: 0.0005506887100636959\n",
      "Gradient for decoder.decoder.6.weight: 0.0011776004685088992\n",
      "Gradient for decoder.decoder.6.bias: 7.557270873803645e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.15768884122371674\n",
      "Gradient for encoder.encoder.0.bias: 2.7274305036684154e-10\n",
      "Gradient for encoder.encoder.1.weight: 0.016831718385219574\n",
      "Gradient for encoder.encoder.1.bias: 0.013150929473340511\n",
      "Gradient for encoder.encoder.3.weight: 0.3735705018043518\n",
      "Gradient for encoder.encoder.3.bias: 2.2944546262948506e-09\n",
      "Gradient for encoder.encoder.4.weight: 0.027683254331350327\n",
      "Gradient for encoder.encoder.4.bias: 0.02216584049165249\n",
      "Gradient for encoder.mean.weight: 0.3037315607070923\n",
      "Gradient for encoder.mean.bias: 0.014494068920612335\n",
      "Gradient for encoder.log_var.weight: 0.18596316874027252\n",
      "Gradient for encoder.log_var.bias: 0.007860807701945305\n",
      "Gradient for decoder.decoder.0.weight: 0.018827645108103752\n",
      "Gradient for decoder.decoder.0.bias: 1.4831737227272157e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0009636419708840549\n",
      "Gradient for decoder.decoder.1.bias: 0.0006419111741706729\n",
      "Gradient for decoder.decoder.3.weight: 0.01481863297522068\n",
      "Gradient for decoder.decoder.3.bias: 1.0058124472189789e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0005231511895544827\n",
      "Gradient for decoder.decoder.4.bias: 0.0004568797303363681\n",
      "Gradient for decoder.decoder.6.weight: 0.0011306240921840072\n",
      "Gradient for decoder.decoder.6.bias: 6.674305041087791e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.1448686569929123\n",
      "Gradient for encoder.encoder.0.bias: 2.437752222306244e-10\n",
      "Gradient for encoder.encoder.1.weight: 0.020842839032411575\n",
      "Gradient for encoder.encoder.1.bias: 0.015225127339363098\n",
      "Gradient for encoder.encoder.3.weight: 0.44489431381225586\n",
      "Gradient for encoder.encoder.3.bias: 2.269138876798138e-09\n",
      "Gradient for encoder.encoder.4.weight: 0.025336721912026405\n",
      "Gradient for encoder.encoder.4.bias: 0.023272136226296425\n",
      "Gradient for encoder.mean.weight: 0.30517134070396423\n",
      "Gradient for encoder.mean.bias: 0.015394622460007668\n",
      "Gradient for encoder.log_var.weight: 0.16941222548484802\n",
      "Gradient for encoder.log_var.bias: 0.008911351673305035\n",
      "Gradient for decoder.decoder.0.weight: 0.02038462460041046\n",
      "Gradient for decoder.decoder.0.bias: 1.798059340307745e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0010536881163716316\n",
      "Gradient for decoder.decoder.1.bias: 0.000769578036852181\n",
      "Gradient for decoder.decoder.3.weight: 0.015603515319526196\n",
      "Gradient for decoder.decoder.3.bias: 1.4620679666954572e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0006808058242313564\n",
      "Gradient for decoder.decoder.4.bias: 0.0007256322423927486\n",
      "Gradient for decoder.decoder.6.weight: 0.0011252963449805975\n",
      "Gradient for decoder.decoder.6.bias: 7.944962271722034e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.2071719914674759\n",
      "Gradient for encoder.encoder.0.bias: 3.3434857660274986e-10\n",
      "Gradient for encoder.encoder.1.weight: 0.022247273474931717\n",
      "Gradient for encoder.encoder.1.bias: 0.016864290460944176\n",
      "Gradient for encoder.encoder.3.weight: 0.5083871483802795\n",
      "Gradient for encoder.encoder.3.bias: 2.5884729915048865e-09\n",
      "Gradient for encoder.encoder.4.weight: 0.03271256014704704\n",
      "Gradient for encoder.encoder.4.bias: 0.02900839038193226\n",
      "Gradient for encoder.mean.weight: 0.4167218506336212\n",
      "Gradient for encoder.mean.bias: 0.019400974735617638\n",
      "Gradient for encoder.log_var.weight: 0.2123754769563675\n",
      "Gradient for encoder.log_var.bias: 0.010091722011566162\n",
      "Gradient for decoder.decoder.0.weight: 0.01594582200050354\n",
      "Gradient for decoder.decoder.0.bias: 1.2605148869138105e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0009006860782392323\n",
      "Gradient for decoder.decoder.1.bias: 0.0005986616015434265\n",
      "Gradient for decoder.decoder.3.weight: 0.012515580281615257\n",
      "Gradient for decoder.decoder.3.bias: 9.494867392323414e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00047771967365406454\n",
      "Gradient for decoder.decoder.4.bias: 0.0004043469962198287\n",
      "Gradient for decoder.decoder.6.weight: 0.0011813653400167823\n",
      "Gradient for decoder.decoder.6.bias: 7.513442687923089e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.14168371260166168\n",
      "Gradient for encoder.encoder.0.bias: 2.305401980429167e-10\n",
      "Gradient for encoder.encoder.1.weight: 0.01854882948100567\n",
      "Gradient for encoder.encoder.1.bias: 0.014724805019795895\n",
      "Gradient for encoder.encoder.3.weight: 0.41012534499168396\n",
      "Gradient for encoder.encoder.3.bias: 2.1287429596839047e-09\n",
      "Gradient for encoder.encoder.4.weight: 0.02381003275513649\n",
      "Gradient for encoder.encoder.4.bias: 0.021588264033198357\n",
      "Gradient for encoder.mean.weight: 0.2900654971599579\n",
      "Gradient for encoder.mean.bias: 0.013540413230657578\n",
      "Gradient for encoder.log_var.weight: 0.15638194978237152\n",
      "Gradient for encoder.log_var.bias: 0.007216119673103094\n",
      "Gradient for decoder.decoder.0.weight: 0.01876656338572502\n",
      "Gradient for decoder.decoder.0.bias: 1.5324259916571492e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0009821379790082574\n",
      "Gradient for decoder.decoder.1.bias: 0.0006718419608660042\n",
      "Gradient for decoder.decoder.3.weight: 0.014518051408231258\n",
      "Gradient for decoder.decoder.3.bias: 1.1402428307105694e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0005415618070401251\n",
      "Gradient for decoder.decoder.4.bias: 0.00048508457257412374\n",
      "Gradient for decoder.decoder.6.weight: 0.001130462042056024\n",
      "Gradient for decoder.decoder.6.bias: 6.66342384647578e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.14335936307907104\n",
      "Gradient for encoder.encoder.0.bias: 2.3545332350494164e-10\n",
      "Gradient for encoder.encoder.1.weight: 0.01836790144443512\n",
      "Gradient for encoder.encoder.1.bias: 0.015004737302660942\n",
      "Gradient for encoder.encoder.3.weight: 0.4036324918270111\n",
      "Gradient for encoder.encoder.3.bias: 2.2628279250369587e-09\n",
      "Gradient for encoder.encoder.4.weight: 0.025534482672810555\n",
      "Gradient for encoder.encoder.4.bias: 0.02016672119498253\n",
      "Gradient for encoder.mean.weight: 0.3054359555244446\n",
      "Gradient for encoder.mean.bias: 0.011086726561188698\n",
      "Gradient for encoder.log_var.weight: 0.14999830722808838\n",
      "Gradient for encoder.log_var.bias: 0.006529310718178749\n",
      "Gradient for decoder.decoder.0.weight: 0.018090838566422462\n",
      "Gradient for decoder.decoder.0.bias: 1.5181957080390163e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0009990709368139505\n",
      "Gradient for decoder.decoder.1.bias: 0.0006452063098549843\n",
      "Gradient for decoder.decoder.3.weight: 0.014210476540029049\n",
      "Gradient for decoder.decoder.3.bias: 1.0852163612184995e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0005324591766111553\n",
      "Gradient for decoder.decoder.4.bias: 0.0004605235590133816\n",
      "Gradient for decoder.decoder.6.weight: 0.0011835177429020405\n",
      "Gradient for decoder.decoder.6.bias: 6.625661626458168e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient for encoder.encoder.0.weight: 0.15813226997852325\n",
      "Gradient for encoder.encoder.0.bias: 2.727038872496479e-10\n",
      "Gradient for encoder.encoder.1.weight: 0.01659572683274746\n",
      "Gradient for encoder.encoder.1.bias: 0.012513403780758381\n",
      "Gradient for encoder.encoder.3.weight: 0.36134523153305054\n",
      "Gradient for encoder.encoder.3.bias: 1.9623591640538507e-09\n",
      "Gradient for encoder.encoder.4.weight: 0.02041625790297985\n",
      "Gradient for encoder.encoder.4.bias: 0.02059277519583702\n",
      "Gradient for encoder.mean.weight: 0.27661746740341187\n",
      "Gradient for encoder.mean.bias: 0.01406900305300951\n",
      "Gradient for encoder.log_var.weight: 0.15508835017681122\n",
      "Gradient for encoder.log_var.bias: 0.00917771179229021\n",
      "Gradient for decoder.decoder.0.weight: 0.01592557318508625\n",
      "Gradient for decoder.decoder.0.bias: 1.3384576780239854e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0008624983602203429\n",
      "Gradient for decoder.decoder.1.bias: 0.0006312723853625357\n",
      "Gradient for decoder.decoder.3.weight: 0.012905796058475971\n",
      "Gradient for decoder.decoder.3.bias: 9.987426163871049e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0005168882198631763\n",
      "Gradient for decoder.decoder.4.bias: 0.0005320485797710717\n",
      "Gradient for decoder.decoder.6.weight: 0.0010654269717633724\n",
      "Gradient for decoder.decoder.6.bias: 6.428798224078491e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.5497927069664001\n",
      "Gradient for encoder.encoder.0.bias: 5.882451747929451e-10\n",
      "Gradient for encoder.encoder.1.weight: 0.044205863028764725\n",
      "Gradient for encoder.encoder.1.bias: 0.03434695675969124\n",
      "Gradient for encoder.encoder.3.weight: 0.9846715927124023\n",
      "Gradient for encoder.encoder.3.bias: 6.151138709498127e-09\n",
      "Gradient for encoder.encoder.4.weight: 0.06864181160926819\n",
      "Gradient for encoder.encoder.4.bias: 0.06610623002052307\n",
      "Gradient for encoder.mean.weight: 0.8725996017456055\n",
      "Gradient for encoder.mean.bias: 0.040228504687547684\n",
      "Gradient for encoder.log_var.weight: 0.4635433852672577\n",
      "Gradient for encoder.log_var.bias: 0.02138788439333439\n",
      "Gradient for decoder.decoder.0.weight: 0.06740211695432663\n",
      "Gradient for decoder.decoder.0.bias: 4.3432724083913854e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0032553747296333313\n",
      "Gradient for decoder.decoder.1.bias: 0.002339811995625496\n",
      "Gradient for decoder.decoder.3.weight: 0.052698057144880295\n",
      "Gradient for decoder.decoder.3.bias: 3.641121848474427e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.001895539229735732\n",
      "Gradient for decoder.decoder.4.bias: 0.0018554945709183812\n",
      "Gradient for decoder.decoder.6.weight: 0.0036153863184154034\n",
      "Gradient for decoder.decoder.6.bias: 0.00021281155932229012\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3, Train Loss: 1.2971, Val Loss: 0.7051\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training VAE Epoch:   1%|▏         | 1/79 [00:00<00:14,  5.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient for encoder.encoder.0.weight: 0.15590079128742218\n",
      "Gradient for encoder.encoder.0.bias: 3.061032816109588e-10\n",
      "Gradient for encoder.encoder.1.weight: 0.022775694727897644\n",
      "Gradient for encoder.encoder.1.bias: 0.016120174899697304\n",
      "Gradient for encoder.encoder.3.weight: 0.49209898710250854\n",
      "Gradient for encoder.encoder.3.bias: 2.0818466950345282e-09\n",
      "Gradient for encoder.encoder.4.weight: 0.029424428939819336\n",
      "Gradient for encoder.encoder.4.bias: 0.02437019906938076\n",
      "Gradient for encoder.mean.weight: 0.362394243478775\n",
      "Gradient for encoder.mean.bias: 0.013744639232754707\n",
      "Gradient for encoder.log_var.weight: 0.2013082653284073\n",
      "Gradient for encoder.log_var.bias: 0.006968790199607611\n",
      "Gradient for decoder.decoder.0.weight: 0.016278397291898727\n",
      "Gradient for decoder.decoder.0.bias: 1.4473405807180484e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0008301309426315129\n",
      "Gradient for decoder.decoder.1.bias: 0.0005689835525117815\n",
      "Gradient for decoder.decoder.3.weight: 0.012818553484976292\n",
      "Gradient for decoder.decoder.3.bias: 9.904525116732898e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00043162881047464907\n",
      "Gradient for decoder.decoder.4.bias: 0.00038922339444980025\n",
      "Gradient for decoder.decoder.6.weight: 0.0010397916194051504\n",
      "Gradient for decoder.decoder.6.bias: 5.258584496914409e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.1618005335330963\n",
      "Gradient for encoder.encoder.0.bias: 2.84551215923301e-10\n",
      "Gradient for encoder.encoder.1.weight: 0.019226768985390663\n",
      "Gradient for encoder.encoder.1.bias: 0.01470961794257164\n",
      "Gradient for encoder.encoder.3.weight: 0.45602864027023315\n",
      "Gradient for encoder.encoder.3.bias: 2.3465449583426334e-09\n",
      "Gradient for encoder.encoder.4.weight: 0.03165619075298309\n",
      "Gradient for encoder.encoder.4.bias: 0.029984567314386368\n",
      "Gradient for encoder.mean.weight: 0.37554895877838135\n",
      "Gradient for encoder.mean.bias: 0.019421735778450966\n",
      "Gradient for encoder.log_var.weight: 0.20667745172977448\n",
      "Gradient for encoder.log_var.bias: 0.011052506975829601\n",
      "Gradient for decoder.decoder.0.weight: 0.017758630216121674\n",
      "Gradient for decoder.decoder.0.bias: 1.5202276937298365e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0009253608295693994\n",
      "Gradient for decoder.decoder.1.bias: 0.0005875222268514335\n",
      "Gradient for decoder.decoder.3.weight: 0.01397568266838789\n",
      "Gradient for decoder.decoder.3.bias: 1.1824922985237407e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0005996315157972276\n",
      "Gradient for decoder.decoder.4.bias: 0.0006513610132969916\n",
      "Gradient for decoder.decoder.6.weight: 0.0010998660000041127\n",
      "Gradient for decoder.decoder.6.bias: 7.261908467626199e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training VAE Epoch:  11%|█▏        | 9/79 [00:00<00:01, 37.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient for encoder.encoder.0.weight: 0.14564301073551178\n",
      "Gradient for encoder.encoder.0.bias: 2.439158042211176e-10\n",
      "Gradient for encoder.encoder.1.weight: 0.019187811762094498\n",
      "Gradient for encoder.encoder.1.bias: 0.014695648103952408\n",
      "Gradient for encoder.encoder.3.weight: 0.44416192173957825\n",
      "Gradient for encoder.encoder.3.bias: 1.7607141300501894e-09\n",
      "Gradient for encoder.encoder.4.weight: 0.024973317980766296\n",
      "Gradient for encoder.encoder.4.bias: 0.020234405994415283\n",
      "Gradient for encoder.mean.weight: 0.3051629960536957\n",
      "Gradient for encoder.mean.bias: 0.010529283434152603\n",
      "Gradient for encoder.log_var.weight: 0.14244885742664337\n",
      "Gradient for encoder.log_var.bias: 0.006467439234256744\n",
      "Gradient for decoder.decoder.0.weight: 0.01622268185019493\n",
      "Gradient for decoder.decoder.0.bias: 1.3725499903305405e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0008652126998640597\n",
      "Gradient for decoder.decoder.1.bias: 0.0005780913634225726\n",
      "Gradient for decoder.decoder.3.weight: 0.012606636621057987\n",
      "Gradient for decoder.decoder.3.bias: 9.689747615393429e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0004494047025218606\n",
      "Gradient for decoder.decoder.4.bias: 0.0004057762853335589\n",
      "Gradient for decoder.decoder.6.weight: 0.0009681835654191673\n",
      "Gradient for decoder.decoder.6.bias: 4.2005071009043604e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.1660865992307663\n",
      "Gradient for encoder.encoder.0.bias: 2.6785787476946155e-10\n",
      "Gradient for encoder.encoder.1.weight: 0.01505359448492527\n",
      "Gradient for encoder.encoder.1.bias: 0.01231981161981821\n",
      "Gradient for encoder.encoder.3.weight: 0.36516696214675903\n",
      "Gradient for encoder.encoder.3.bias: 1.8907360122000227e-09\n",
      "Gradient for encoder.encoder.4.weight: 0.020434614270925522\n",
      "Gradient for encoder.encoder.4.bias: 0.018465949222445488\n",
      "Gradient for encoder.mean.weight: 0.26454293727874756\n",
      "Gradient for encoder.mean.bias: 0.012308062054216862\n",
      "Gradient for encoder.log_var.weight: 0.16976602375507355\n",
      "Gradient for encoder.log_var.bias: 0.007786446250975132\n",
      "Gradient for decoder.decoder.0.weight: 0.014483564533293247\n",
      "Gradient for decoder.decoder.0.bias: 1.1592401344406866e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0007893634028732777\n",
      "Gradient for decoder.decoder.1.bias: 0.0005216611898504198\n",
      "Gradient for decoder.decoder.3.weight: 0.011329148896038532\n",
      "Gradient for decoder.decoder.3.bias: 1.1838331703817317e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0007691081264056265\n",
      "Gradient for decoder.decoder.4.bias: 0.0009287316352128983\n",
      "Gradient for decoder.decoder.6.weight: 0.0013376666465774179\n",
      "Gradient for decoder.decoder.6.bias: 0.00011194349644938484\n",
      "Gradient for encoder.encoder.0.weight: 0.15636412799358368\n",
      "Gradient for encoder.encoder.0.bias: 2.3522145342624867e-10\n",
      "Gradient for encoder.encoder.1.weight: 0.01628359779715538\n",
      "Gradient for encoder.encoder.1.bias: 0.01239852700382471\n",
      "Gradient for encoder.encoder.3.weight: 0.35282614827156067\n",
      "Gradient for encoder.encoder.3.bias: 2.117113817590166e-09\n",
      "Gradient for encoder.encoder.4.weight: 0.021002642810344696\n",
      "Gradient for encoder.encoder.4.bias: 0.01962035894393921\n",
      "Gradient for encoder.mean.weight: 0.2724011540412903\n",
      "Gradient for encoder.mean.bias: 0.012934650294482708\n",
      "Gradient for encoder.log_var.weight: 0.1574525088071823\n",
      "Gradient for encoder.log_var.bias: 0.008084552362561226\n",
      "Gradient for decoder.decoder.0.weight: 0.015131144784390926\n",
      "Gradient for decoder.decoder.0.bias: 1.1848411141102133e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0007590087479911745\n",
      "Gradient for decoder.decoder.1.bias: 0.000517080130521208\n",
      "Gradient for decoder.decoder.3.weight: 0.011506517417728901\n",
      "Gradient for decoder.decoder.3.bias: 8.422445380018573e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0004279827408026904\n",
      "Gradient for decoder.decoder.4.bias: 0.00038607505848631263\n",
      "Gradient for decoder.decoder.6.weight: 0.0010332862148061395\n",
      "Gradient for decoder.decoder.6.bias: 5.4331434512278065e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.17016257345676422\n",
      "Gradient for encoder.encoder.0.bias: 2.5217800070365115e-10\n",
      "Gradient for encoder.encoder.1.weight: 0.02186010032892227\n",
      "Gradient for encoder.encoder.1.bias: 0.01570669747889042\n",
      "Gradient for encoder.encoder.3.weight: 0.4725532829761505\n",
      "Gradient for encoder.encoder.3.bias: 2.2868467119963043e-09\n",
      "Gradient for encoder.encoder.4.weight: 0.02848326973617077\n",
      "Gradient for encoder.encoder.4.bias: 0.025006597861647606\n",
      "Gradient for encoder.mean.weight: 0.37060487270355225\n",
      "Gradient for encoder.mean.bias: 0.014142639935016632\n",
      "Gradient for encoder.log_var.weight: 0.18289558589458466\n",
      "Gradient for encoder.log_var.bias: 0.008888299576938152\n",
      "Gradient for decoder.decoder.0.weight: 0.020274141803383827\n",
      "Gradient for decoder.decoder.0.bias: 2.0145718426789472e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0010994547046720982\n",
      "Gradient for decoder.decoder.1.bias: 0.0007050011190585792\n",
      "Gradient for decoder.decoder.3.weight: 0.016052132472395897\n",
      "Gradient for decoder.decoder.3.bias: 1.5960287258476313e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0010118766222149134\n",
      "Gradient for decoder.decoder.4.bias: 0.0011114079970866442\n",
      "Gradient for decoder.decoder.6.weight: 0.0013891387498006225\n",
      "Gradient for decoder.decoder.6.bias: 0.00010100356303155422\n",
      "Gradient for encoder.encoder.0.weight: 0.1313091367483139\n",
      "Gradient for encoder.encoder.0.bias: 2.3843726992822667e-10\n",
      "Gradient for encoder.encoder.1.weight: 0.018951214849948883\n",
      "Gradient for encoder.encoder.1.bias: 0.014344788156449795\n",
      "Gradient for encoder.encoder.3.weight: 0.41699329018592834\n",
      "Gradient for encoder.encoder.3.bias: 2.020653422363239e-09\n",
      "Gradient for encoder.encoder.4.weight: 0.022720038890838623\n",
      "Gradient for encoder.encoder.4.bias: 0.020446784794330597\n",
      "Gradient for encoder.mean.weight: 0.2732354700565338\n",
      "Gradient for encoder.mean.bias: 0.014242088422179222\n",
      "Gradient for encoder.log_var.weight: 0.13762617111206055\n",
      "Gradient for encoder.log_var.bias: 0.009086595848202705\n",
      "Gradient for decoder.decoder.0.weight: 0.016565367579460144\n",
      "Gradient for decoder.decoder.0.bias: 1.36725339383581e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0009532857802696526\n",
      "Gradient for decoder.decoder.1.bias: 0.0006165740196593106\n",
      "Gradient for decoder.decoder.3.weight: 0.012910209596157074\n",
      "Gradient for decoder.decoder.3.bias: 1.2344998634450377e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0007496185135096312\n",
      "Gradient for decoder.decoder.4.bias: 0.0008662348845973611\n",
      "Gradient for decoder.decoder.6.weight: 0.0012023004237562418\n",
      "Gradient for decoder.decoder.6.bias: 8.860274829203263e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.11826866865158081\n",
      "Gradient for encoder.encoder.0.bias: 1.8931821388346037e-10\n",
      "Gradient for encoder.encoder.1.weight: 0.014072994701564312\n",
      "Gradient for encoder.encoder.1.bias: 0.010597181506454945\n",
      "Gradient for encoder.encoder.3.weight: 0.3148217499256134\n",
      "Gradient for encoder.encoder.3.bias: 1.5802532615794007e-09\n",
      "Gradient for encoder.encoder.4.weight: 0.020451977849006653\n",
      "Gradient for encoder.encoder.4.bias: 0.019996540620923042\n",
      "Gradient for encoder.mean.weight: 0.2637401223182678\n",
      "Gradient for encoder.mean.bias: 0.014360548928380013\n",
      "Gradient for encoder.log_var.weight: 0.13587428629398346\n",
      "Gradient for encoder.log_var.bias: 0.008351573720574379\n",
      "Gradient for decoder.decoder.0.weight: 0.017213478684425354\n",
      "Gradient for decoder.decoder.0.bias: 1.526014453689939e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0009438164997845888\n",
      "Gradient for decoder.decoder.1.bias: 0.000599398510530591\n",
      "Gradient for decoder.decoder.3.weight: 0.01379753090441227\n",
      "Gradient for decoder.decoder.3.bias: 1.191944043466009e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.000602291023824364\n",
      "Gradient for decoder.decoder.4.bias: 0.0006705663981847465\n",
      "Gradient for decoder.decoder.6.weight: 0.001104682800360024\n",
      "Gradient for decoder.decoder.6.bias: 7.853869465179741e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.1541050672531128\n",
      "Gradient for encoder.encoder.0.bias: 2.827718614817343e-10\n",
      "Gradient for encoder.encoder.1.weight: 0.016664795577526093\n",
      "Gradient for encoder.encoder.1.bias: 0.011802371591329575\n",
      "Gradient for encoder.encoder.3.weight: 0.384396493434906\n",
      "Gradient for encoder.encoder.3.bias: 2.2975450431061972e-09\n",
      "Gradient for encoder.encoder.4.weight: 0.029953913763165474\n",
      "Gradient for encoder.encoder.4.bias: 0.02269967831671238\n",
      "Gradient for encoder.mean.weight: 0.3395541310310364\n",
      "Gradient for encoder.mean.bias: 0.013371658511459827\n",
      "Gradient for encoder.log_var.weight: 0.22422167658805847\n",
      "Gradient for encoder.log_var.bias: 0.007586461957544088\n",
      "Gradient for decoder.decoder.0.weight: 0.01673167571425438\n",
      "Gradient for decoder.decoder.0.bias: 1.5480211557061807e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0009000168065540493\n",
      "Gradient for decoder.decoder.1.bias: 0.000577382801566273\n",
      "Gradient for decoder.decoder.3.weight: 0.013020896352827549\n",
      "Gradient for decoder.decoder.3.bias: 1.2638008695109448e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0006590841803699732\n",
      "Gradient for decoder.decoder.4.bias: 0.0007790492381900549\n",
      "Gradient for decoder.decoder.6.weight: 0.0013696389505639672\n",
      "Gradient for decoder.decoder.6.bias: 0.00012418878031894565\n",
      "Gradient for encoder.encoder.0.weight: 0.1436482071876526\n",
      "Gradient for encoder.encoder.0.bias: 2.1190793564329624e-10\n",
      "Gradient for encoder.encoder.1.weight: 0.016612974926829338\n",
      "Gradient for encoder.encoder.1.bias: 0.012737544253468513\n",
      "Gradient for encoder.encoder.3.weight: 0.36982327699661255\n",
      "Gradient for encoder.encoder.3.bias: 1.9506547488390424e-09\n",
      "Gradient for encoder.encoder.4.weight: 0.021463170647621155\n",
      "Gradient for encoder.encoder.4.bias: 0.018102005124092102\n",
      "Gradient for encoder.mean.weight: 0.26134219765663147\n",
      "Gradient for encoder.mean.bias: 0.011411695741117\n",
      "Gradient for encoder.log_var.weight: 0.1507585644721985\n",
      "Gradient for encoder.log_var.bias: 0.006213452201336622\n",
      "Gradient for decoder.decoder.0.weight: 0.017838891595602036\n",
      "Gradient for decoder.decoder.0.bias: 1.533933258190956e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0009018579148687422\n",
      "Gradient for decoder.decoder.1.bias: 0.0006282332469709218\n",
      "Gradient for decoder.decoder.3.weight: 0.013208643533289433\n",
      "Gradient for decoder.decoder.3.bias: 1.180459202609896e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0005653597181662917\n",
      "Gradient for decoder.decoder.4.bias: 0.0006040639709681273\n",
      "Gradient for decoder.decoder.6.weight: 0.0010431078262627125\n",
      "Gradient for decoder.decoder.6.bias: 5.989247438265011e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.11707355082035065\n",
      "Gradient for encoder.encoder.0.bias: 1.92103610796579e-10\n",
      "Gradient for encoder.encoder.1.weight: 0.015158706344664097\n",
      "Gradient for encoder.encoder.1.bias: 0.010029875673353672\n",
      "Gradient for encoder.encoder.3.weight: 0.3366272449493408\n",
      "Gradient for encoder.encoder.3.bias: 1.7773791327613253e-09\n",
      "Gradient for encoder.encoder.4.weight: 0.021528253331780434\n",
      "Gradient for encoder.encoder.4.bias: 0.020543953403830528\n",
      "Gradient for encoder.mean.weight: 0.2554546892642975\n",
      "Gradient for encoder.mean.bias: 0.014787036925554276\n",
      "Gradient for encoder.log_var.weight: 0.14971686899662018\n",
      "Gradient for encoder.log_var.bias: 0.00919062364846468\n",
      "Gradient for decoder.decoder.0.weight: 0.017004288733005524\n",
      "Gradient for decoder.decoder.0.bias: 1.308877173311629e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0008774151210673153\n",
      "Gradient for decoder.decoder.1.bias: 0.0005978603730909526\n",
      "Gradient for decoder.decoder.3.weight: 0.013013696298003197\n",
      "Gradient for decoder.decoder.3.bias: 1.2276483996043197e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0007779755396768451\n",
      "Gradient for decoder.decoder.4.bias: 0.0009379975381307304\n",
      "Gradient for decoder.decoder.6.weight: 0.0012490511871874332\n",
      "Gradient for decoder.decoder.6.bias: 9.920251613948494e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.11554794758558273\n",
      "Gradient for encoder.encoder.0.bias: 1.9512741422644808e-10\n",
      "Gradient for encoder.encoder.1.weight: 0.013116274029016495\n",
      "Gradient for encoder.encoder.1.bias: 0.010904966853559017\n",
      "Gradient for encoder.encoder.3.weight: 0.2945161461830139\n",
      "Gradient for encoder.encoder.3.bias: 1.7729959722601052e-09\n",
      "Gradient for encoder.encoder.4.weight: 0.016756311058998108\n",
      "Gradient for encoder.encoder.4.bias: 0.017039796337485313\n",
      "Gradient for encoder.mean.weight: 0.22068382799625397\n",
      "Gradient for encoder.mean.bias: 0.011381802149116993\n",
      "Gradient for encoder.log_var.weight: 0.11180835962295532\n",
      "Gradient for encoder.log_var.bias: 0.006285178475081921\n",
      "Gradient for decoder.decoder.0.weight: 0.016612807288765907\n",
      "Gradient for decoder.decoder.0.bias: 1.279429062694959e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.000909138994757086\n",
      "Gradient for decoder.decoder.1.bias: 0.000573336030356586\n",
      "Gradient for decoder.decoder.3.weight: 0.012913314625620842\n",
      "Gradient for decoder.decoder.3.bias: 9.796467803635522e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0004701761936303228\n",
      "Gradient for decoder.decoder.4.bias: 0.00046522743650712073\n",
      "Gradient for decoder.decoder.6.weight: 0.0009832545183598995\n",
      "Gradient for decoder.decoder.6.bias: 4.978142897016369e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.11558877676725388\n",
      "Gradient for encoder.encoder.0.bias: 1.8520590616688537e-10\n",
      "Gradient for encoder.encoder.1.weight: 0.01467191707342863\n",
      "Gradient for encoder.encoder.1.bias: 0.010701407678425312\n",
      "Gradient for encoder.encoder.3.weight: 0.3351480960845947\n",
      "Gradient for encoder.encoder.3.bias: 1.6395280688641378e-09\n",
      "Gradient for encoder.encoder.4.weight: 0.022375252097845078\n",
      "Gradient for encoder.encoder.4.bias: 0.01974141038954258\n",
      "Gradient for encoder.mean.weight: 0.2718348205089569\n",
      "Gradient for encoder.mean.bias: 0.01149311475455761\n",
      "Gradient for encoder.log_var.weight: 0.1456621289253235\n",
      "Gradient for encoder.log_var.bias: 0.007563173305243254\n",
      "Gradient for decoder.decoder.0.weight: 0.019086671993136406\n",
      "Gradient for decoder.decoder.0.bias: 1.507321489846447e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0009732352336868644\n",
      "Gradient for decoder.decoder.1.bias: 0.0006704728002659976\n",
      "Gradient for decoder.decoder.3.weight: 0.014500519260764122\n",
      "Gradient for decoder.decoder.3.bias: 1.1081079109853675e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0006288486765697598\n",
      "Gradient for decoder.decoder.4.bias: 0.0006737730582244694\n",
      "Gradient for decoder.decoder.6.weight: 0.0011191786034032702\n",
      "Gradient for decoder.decoder.6.bias: 6.954627315280959e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.14190049469470978\n",
      "Gradient for encoder.encoder.0.bias: 2.5243709900202305e-10\n",
      "Gradient for encoder.encoder.1.weight: 0.020948657765984535\n",
      "Gradient for encoder.encoder.1.bias: 0.014497583732008934\n",
      "Gradient for encoder.encoder.3.weight: 0.45746493339538574\n",
      "Gradient for encoder.encoder.3.bias: 1.7856054412845879e-09\n",
      "Gradient for encoder.encoder.4.weight: 0.03143243491649628\n",
      "Gradient for encoder.encoder.4.bias: 0.023409217596054077\n",
      "Gradient for encoder.mean.weight: 0.3708520531654358\n",
      "Gradient for encoder.mean.bias: 0.010453199967741966\n",
      "Gradient for encoder.log_var.weight: 0.189797043800354\n",
      "Gradient for encoder.log_var.bias: 0.00656181899830699\n",
      "Gradient for decoder.decoder.0.weight: 0.017374945804476738\n",
      "Gradient for decoder.decoder.0.bias: 1.5355337834588312e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0009085069177672267\n",
      "Gradient for decoder.decoder.1.bias: 0.0006005169707350433\n",
      "Gradient for decoder.decoder.3.weight: 0.013637306168675423\n",
      "Gradient for decoder.decoder.3.bias: 1.111610803405938e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0004942781524732709\n",
      "Gradient for decoder.decoder.4.bias: 0.00042418192606419325\n",
      "Gradient for decoder.decoder.6.weight: 0.001103062299080193\n",
      "Gradient for decoder.decoder.6.bias: 6.879755528643727e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.1261502206325531\n",
      "Gradient for encoder.encoder.0.bias: 2.2772878027765842e-10\n",
      "Gradient for encoder.encoder.1.weight: 0.015162433497607708\n",
      "Gradient for encoder.encoder.1.bias: 0.011095519177615643\n",
      "Gradient for encoder.encoder.3.weight: 0.3413461446762085\n",
      "Gradient for encoder.encoder.3.bias: 1.5592590552060415e-09\n",
      "Gradient for encoder.encoder.4.weight: 0.021689876914024353\n",
      "Gradient for encoder.encoder.4.bias: 0.018702248111367226\n",
      "Gradient for encoder.mean.weight: 0.27563127875328064\n",
      "Gradient for encoder.mean.bias: 0.012653621844947338\n",
      "Gradient for encoder.log_var.weight: 0.150846466422081\n",
      "Gradient for encoder.log_var.bias: 0.007316199131309986\n",
      "Gradient for decoder.decoder.0.weight: 0.015569721348583698\n",
      "Gradient for decoder.decoder.0.bias: 1.2157115591993062e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0007457645260728896\n",
      "Gradient for decoder.decoder.1.bias: 0.0005165209877304733\n",
      "Gradient for decoder.decoder.3.weight: 0.012271257117390633\n",
      "Gradient for decoder.decoder.3.bias: 9.346662332987421e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0004334058321546763\n",
      "Gradient for decoder.decoder.4.bias: 0.00039954122621566057\n",
      "Gradient for decoder.decoder.6.weight: 0.0009857990080490708\n",
      "Gradient for decoder.decoder.6.bias: 5.058734677731991e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.09930498898029327\n",
      "Gradient for encoder.encoder.0.bias: 1.4441066398251934e-10\n",
      "Gradient for encoder.encoder.1.weight: 0.012098020873963833\n",
      "Gradient for encoder.encoder.1.bias: 0.009525745175778866\n",
      "Gradient for encoder.encoder.3.weight: 0.263325035572052\n",
      "Gradient for encoder.encoder.3.bias: 1.4824942384805695e-09\n",
      "Gradient for encoder.encoder.4.weight: 0.018568996340036392\n",
      "Gradient for encoder.encoder.4.bias: 0.01748557761311531\n",
      "Gradient for encoder.mean.weight: 0.23453335464000702\n",
      "Gradient for encoder.mean.bias: 0.01061638817191124\n",
      "Gradient for encoder.log_var.weight: 0.13100431859493256\n",
      "Gradient for encoder.log_var.bias: 0.006221011281013489\n",
      "Gradient for decoder.decoder.0.weight: 0.020264873281121254\n",
      "Gradient for decoder.decoder.0.bias: 1.7215731618058783e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0010948897106572986\n",
      "Gradient for decoder.decoder.1.bias: 0.0007425940711982548\n",
      "Gradient for decoder.decoder.3.weight: 0.015997666865587234\n",
      "Gradient for decoder.decoder.3.bias: 1.2777515157047503e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0006306946743279696\n",
      "Gradient for decoder.decoder.4.bias: 0.0004971642629243433\n",
      "Gradient for decoder.decoder.6.weight: 0.0010713544907048345\n",
      "Gradient for decoder.decoder.6.bias: 5.7210483646485955e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training VAE Epoch:  22%|██▏       | 17/79 [00:00<00:01, 53.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient for encoder.encoder.0.weight: 0.10870411247015\n",
      "Gradient for encoder.encoder.0.bias: 2.052632785964903e-10\n",
      "Gradient for encoder.encoder.1.weight: 0.01589171215891838\n",
      "Gradient for encoder.encoder.1.bias: 0.011061129160225391\n",
      "Gradient for encoder.encoder.3.weight: 0.33566826581954956\n",
      "Gradient for encoder.encoder.3.bias: 1.668904681118022e-09\n",
      "Gradient for encoder.encoder.4.weight: 0.021547850221395493\n",
      "Gradient for encoder.encoder.4.bias: 0.019102754071354866\n",
      "Gradient for encoder.mean.weight: 0.2688846290111542\n",
      "Gradient for encoder.mean.bias: 0.011391502805054188\n",
      "Gradient for encoder.log_var.weight: 0.1478140503168106\n",
      "Gradient for encoder.log_var.bias: 0.006378838326781988\n",
      "Gradient for decoder.decoder.0.weight: 0.0192886795848608\n",
      "Gradient for decoder.decoder.0.bias: 1.44936090906711e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0009972945554181933\n",
      "Gradient for decoder.decoder.1.bias: 0.000688240397721529\n",
      "Gradient for decoder.decoder.3.weight: 0.01558669749647379\n",
      "Gradient for decoder.decoder.3.bias: 1.1005801825447747e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0005949264741502702\n",
      "Gradient for decoder.decoder.4.bias: 0.0005505010485649109\n",
      "Gradient for decoder.decoder.6.weight: 0.0011320733465254307\n",
      "Gradient for decoder.decoder.6.bias: 7.519469363614917e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.1187567189335823\n",
      "Gradient for encoder.encoder.0.bias: 1.772727797888507e-10\n",
      "Gradient for encoder.encoder.1.weight: 0.012821265496313572\n",
      "Gradient for encoder.encoder.1.bias: 0.00962543860077858\n",
      "Gradient for encoder.encoder.3.weight: 0.2848268449306488\n",
      "Gradient for encoder.encoder.3.bias: 1.7740481306205425e-09\n",
      "Gradient for encoder.encoder.4.weight: 0.021555395796895027\n",
      "Gradient for encoder.encoder.4.bias: 0.018648553639650345\n",
      "Gradient for encoder.mean.weight: 0.25925347208976746\n",
      "Gradient for encoder.mean.bias: 0.011596057564020157\n",
      "Gradient for encoder.log_var.weight: 0.15834026038646698\n",
      "Gradient for encoder.log_var.bias: 0.007141676731407642\n",
      "Gradient for decoder.decoder.0.weight: 0.016187164932489395\n",
      "Gradient for decoder.decoder.0.bias: 1.36681291285079e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0008992638322524726\n",
      "Gradient for decoder.decoder.1.bias: 0.0005786046385765076\n",
      "Gradient for decoder.decoder.3.weight: 0.012638850137591362\n",
      "Gradient for decoder.decoder.3.bias: 9.94024168532448e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0004718398558907211\n",
      "Gradient for decoder.decoder.4.bias: 0.0004750267544295639\n",
      "Gradient for decoder.decoder.6.weight: 0.0010076825274154544\n",
      "Gradient for decoder.decoder.6.bias: 4.187637387076393e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training VAE Epoch:  32%|███▏      | 25/79 [00:00<00:00, 61.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient for encoder.encoder.0.weight: 0.1040998175740242\n",
      "Gradient for encoder.encoder.0.bias: 1.9432269682262415e-10\n",
      "Gradient for encoder.encoder.1.weight: 0.014590034261345863\n",
      "Gradient for encoder.encoder.1.bias: 0.010088241659104824\n",
      "Gradient for encoder.encoder.3.weight: 0.3341014087200165\n",
      "Gradient for encoder.encoder.3.bias: 1.529836035629728e-09\n",
      "Gradient for encoder.encoder.4.weight: 0.02170761302113533\n",
      "Gradient for encoder.encoder.4.bias: 0.02158713899552822\n",
      "Gradient for encoder.mean.weight: 0.2808654010295868\n",
      "Gradient for encoder.mean.bias: 0.0161660797894001\n",
      "Gradient for encoder.log_var.weight: 0.12114772945642471\n",
      "Gradient for encoder.log_var.bias: 0.007980276830494404\n",
      "Gradient for decoder.decoder.0.weight: 0.017080646008253098\n",
      "Gradient for decoder.decoder.0.bias: 1.307758484836441e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0009485921473242342\n",
      "Gradient for decoder.decoder.1.bias: 0.0005882575642317533\n",
      "Gradient for decoder.decoder.3.weight: 0.013670867308974266\n",
      "Gradient for decoder.decoder.3.bias: 1.1925553600189431e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0006884525646455586\n",
      "Gradient for decoder.decoder.4.bias: 0.0008198803407140076\n",
      "Gradient for decoder.decoder.6.weight: 0.0010729517089203\n",
      "Gradient for decoder.decoder.6.bias: 7.715449464740232e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.120017409324646\n",
      "Gradient for encoder.encoder.0.bias: 1.756904621785793e-10\n",
      "Gradient for encoder.encoder.1.weight: 0.015283034183084965\n",
      "Gradient for encoder.encoder.1.bias: 0.01159494835883379\n",
      "Gradient for encoder.encoder.3.weight: 0.341657429933548\n",
      "Gradient for encoder.encoder.3.bias: 1.744145272652986e-09\n",
      "Gradient for encoder.encoder.4.weight: 0.02060285024344921\n",
      "Gradient for encoder.encoder.4.bias: 0.018251722678542137\n",
      "Gradient for encoder.mean.weight: 0.2655428946018219\n",
      "Gradient for encoder.mean.bias: 0.010112760588526726\n",
      "Gradient for encoder.log_var.weight: 0.1327008754014969\n",
      "Gradient for encoder.log_var.bias: 0.005301350262016058\n",
      "Gradient for decoder.decoder.0.weight: 0.02025132067501545\n",
      "Gradient for decoder.decoder.0.bias: 1.4749210186515427e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0010803720215335488\n",
      "Gradient for decoder.decoder.1.bias: 0.0006617094622924924\n",
      "Gradient for decoder.decoder.3.weight: 0.015352597460150719\n",
      "Gradient for decoder.decoder.3.bias: 1.1512710923478053e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0005353823071345687\n",
      "Gradient for decoder.decoder.4.bias: 0.0004782969190273434\n",
      "Gradient for decoder.decoder.6.weight: 0.0010476416209712625\n",
      "Gradient for decoder.decoder.6.bias: 5.335801324690692e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.09184244275093079\n",
      "Gradient for encoder.encoder.0.bias: 1.4801385117557686e-10\n",
      "Gradient for encoder.encoder.1.weight: 0.013791347853839397\n",
      "Gradient for encoder.encoder.1.bias: 0.010459600016474724\n",
      "Gradient for encoder.encoder.3.weight: 0.31017646193504333\n",
      "Gradient for encoder.encoder.3.bias: 1.270014204912684e-09\n",
      "Gradient for encoder.encoder.4.weight: 0.019594809040427208\n",
      "Gradient for encoder.encoder.4.bias: 0.017691094428300858\n",
      "Gradient for encoder.mean.weight: 0.2424967736005783\n",
      "Gradient for encoder.mean.bias: 0.012659231200814247\n",
      "Gradient for encoder.log_var.weight: 0.12438386678695679\n",
      "Gradient for encoder.log_var.bias: 0.0069217318668961525\n",
      "Gradient for decoder.decoder.0.weight: 0.01857650652527809\n",
      "Gradient for decoder.decoder.0.bias: 1.6223143661786565e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.001015324960462749\n",
      "Gradient for decoder.decoder.1.bias: 0.0006809358601458371\n",
      "Gradient for decoder.decoder.3.weight: 0.01484021544456482\n",
      "Gradient for decoder.decoder.3.bias: 1.1784036246798024e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0006059309816919267\n",
      "Gradient for decoder.decoder.4.bias: 0.000574957812204957\n",
      "Gradient for decoder.decoder.6.weight: 0.0013943106168881059\n",
      "Gradient for decoder.decoder.6.bias: 0.000113133923150599\n",
      "Gradient for encoder.encoder.0.weight: 0.09429945796728134\n",
      "Gradient for encoder.encoder.0.bias: 1.5961393318164596e-10\n",
      "Gradient for encoder.encoder.1.weight: 0.013747166842222214\n",
      "Gradient for encoder.encoder.1.bias: 0.010080421343445778\n",
      "Gradient for encoder.encoder.3.weight: 0.3047378659248352\n",
      "Gradient for encoder.encoder.3.bias: 1.3982409674540008e-09\n",
      "Gradient for encoder.encoder.4.weight: 0.017580201849341393\n",
      "Gradient for encoder.encoder.4.bias: 0.018055517226457596\n",
      "Gradient for encoder.mean.weight: 0.23349659144878387\n",
      "Gradient for encoder.mean.bias: 0.012177501805126667\n",
      "Gradient for encoder.log_var.weight: 0.12240532040596008\n",
      "Gradient for encoder.log_var.bias: 0.006831502541899681\n",
      "Gradient for decoder.decoder.0.weight: 0.020255934447050095\n",
      "Gradient for decoder.decoder.0.bias: 1.5791540297627193e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0011743123177438974\n",
      "Gradient for decoder.decoder.1.bias: 0.000762113428208977\n",
      "Gradient for decoder.decoder.3.weight: 0.016087746247649193\n",
      "Gradient for decoder.decoder.3.bias: 1.16961218488143e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0007292834925465286\n",
      "Gradient for decoder.decoder.4.bias: 0.0007667461177334189\n",
      "Gradient for decoder.decoder.6.weight: 0.0012881937436759472\n",
      "Gradient for decoder.decoder.6.bias: 9.530485840514302e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.10402372479438782\n",
      "Gradient for encoder.encoder.0.bias: 1.8179545369090278e-10\n",
      "Gradient for encoder.encoder.1.weight: 0.012717807665467262\n",
      "Gradient for encoder.encoder.1.bias: 0.010016967542469501\n",
      "Gradient for encoder.encoder.3.weight: 0.2734294533729553\n",
      "Gradient for encoder.encoder.3.bias: 1.4381581481259786e-09\n",
      "Gradient for encoder.encoder.4.weight: 0.01786138117313385\n",
      "Gradient for encoder.encoder.4.bias: 0.016010232269763947\n",
      "Gradient for encoder.mean.weight: 0.22382451593875885\n",
      "Gradient for encoder.mean.bias: 0.010614343918859959\n",
      "Gradient for encoder.log_var.weight: 0.1097181960940361\n",
      "Gradient for encoder.log_var.bias: 0.006412277929484844\n",
      "Gradient for decoder.decoder.0.weight: 0.01663167215883732\n",
      "Gradient for decoder.decoder.0.bias: 1.4968598582854042e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0008981479331851006\n",
      "Gradient for decoder.decoder.1.bias: 0.0005989300552755594\n",
      "Gradient for decoder.decoder.3.weight: 0.012807907536625862\n",
      "Gradient for decoder.decoder.3.bias: 1.170855218335376e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.00044237764086574316\n",
      "Gradient for decoder.decoder.4.bias: 0.0004070199211128056\n",
      "Gradient for decoder.decoder.6.weight: 0.0009959746384993196\n",
      "Gradient for decoder.decoder.6.bias: 5.6555072660557926e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.11342570185661316\n",
      "Gradient for encoder.encoder.0.bias: 1.7549639519387483e-10\n",
      "Gradient for encoder.encoder.1.weight: 0.013264684937894344\n",
      "Gradient for encoder.encoder.1.bias: 0.010673806071281433\n",
      "Gradient for encoder.encoder.3.weight: 0.2920956611633301\n",
      "Gradient for encoder.encoder.3.bias: 1.6851444684107264e-09\n",
      "Gradient for encoder.encoder.4.weight: 0.01960665173828602\n",
      "Gradient for encoder.encoder.4.bias: 0.020440276712179184\n",
      "Gradient for encoder.mean.weight: 0.26075080037117004\n",
      "Gradient for encoder.mean.bias: 0.016315434128046036\n",
      "Gradient for encoder.log_var.weight: 0.14154203236103058\n",
      "Gradient for encoder.log_var.bias: 0.007962933741509914\n",
      "Gradient for decoder.decoder.0.weight: 0.017229750752449036\n",
      "Gradient for decoder.decoder.0.bias: 1.449009107146182e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0009330676984973252\n",
      "Gradient for decoder.decoder.1.bias: 0.0006545878713950515\n",
      "Gradient for decoder.decoder.3.weight: 0.013787808828055859\n",
      "Gradient for decoder.decoder.3.bias: 9.889356694658957e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0005679900059476495\n",
      "Gradient for decoder.decoder.4.bias: 0.0005784797831438482\n",
      "Gradient for decoder.decoder.6.weight: 0.0010304226307198405\n",
      "Gradient for decoder.decoder.6.bias: 5.478167804540135e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.08575484156608582\n",
      "Gradient for encoder.encoder.0.bias: 1.3691812961180716e-10\n",
      "Gradient for encoder.encoder.1.weight: 0.01155097782611847\n",
      "Gradient for encoder.encoder.1.bias: 0.008271520026028156\n",
      "Gradient for encoder.encoder.3.weight: 0.2583891749382019\n",
      "Gradient for encoder.encoder.3.bias: 1.4193312081189902e-09\n",
      "Gradient for encoder.encoder.4.weight: 0.01668400503695011\n",
      "Gradient for encoder.encoder.4.bias: 0.016436519101262093\n",
      "Gradient for encoder.mean.weight: 0.21542233228683472\n",
      "Gradient for encoder.mean.bias: 0.01331833191215992\n",
      "Gradient for encoder.log_var.weight: 0.11837738752365112\n",
      "Gradient for encoder.log_var.bias: 0.0070042684674263\n",
      "Gradient for decoder.decoder.0.weight: 0.02045303024351597\n",
      "Gradient for decoder.decoder.0.bias: 1.790970011184001e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0011020717211067677\n",
      "Gradient for decoder.decoder.1.bias: 0.0007526167901232839\n",
      "Gradient for decoder.decoder.3.weight: 0.015570553950965405\n",
      "Gradient for decoder.decoder.3.bias: 1.2371488555817933e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0005459006642922759\n",
      "Gradient for decoder.decoder.4.bias: 0.0004709759959951043\n",
      "Gradient for decoder.decoder.6.weight: 0.001030457322485745\n",
      "Gradient for decoder.decoder.6.bias: 4.615191573975608e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.10205699503421783\n",
      "Gradient for encoder.encoder.0.bias: 1.6781455391967626e-10\n",
      "Gradient for encoder.encoder.1.weight: 0.012407713569700718\n",
      "Gradient for encoder.encoder.1.bias: 0.009265027940273285\n",
      "Gradient for encoder.encoder.3.weight: 0.2768543064594269\n",
      "Gradient for encoder.encoder.3.bias: 1.441555985692844e-09\n",
      "Gradient for encoder.encoder.4.weight: 0.019535372033715248\n",
      "Gradient for encoder.encoder.4.bias: 0.01678580418229103\n",
      "Gradient for encoder.mean.weight: 0.2369290143251419\n",
      "Gradient for encoder.mean.bias: 0.00984544213861227\n",
      "Gradient for encoder.log_var.weight: 0.1351662576198578\n",
      "Gradient for encoder.log_var.bias: 0.006875607650727034\n",
      "Gradient for decoder.decoder.0.weight: 0.018561385571956635\n",
      "Gradient for decoder.decoder.0.bias: 1.5505954853445303e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0010013636201620102\n",
      "Gradient for decoder.decoder.1.bias: 0.0006241395603865385\n",
      "Gradient for decoder.decoder.3.weight: 0.01438695378601551\n",
      "Gradient for decoder.decoder.3.bias: 1.0508083986282557e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0005696025909855962\n",
      "Gradient for decoder.decoder.4.bias: 0.0004661136190406978\n",
      "Gradient for decoder.decoder.6.weight: 0.0010181521065533161\n",
      "Gradient for decoder.decoder.6.bias: 4.2207866499666125e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.08648096024990082\n",
      "Gradient for encoder.encoder.0.bias: 1.376372488204325e-10\n",
      "Gradient for encoder.encoder.1.weight: 0.009837714955210686\n",
      "Gradient for encoder.encoder.1.bias: 0.007202825043350458\n",
      "Gradient for encoder.encoder.3.weight: 0.22323691844940186\n",
      "Gradient for encoder.encoder.3.bias: 1.5422104704398976e-09\n",
      "Gradient for encoder.encoder.4.weight: 0.017301157116889954\n",
      "Gradient for encoder.encoder.4.bias: 0.01718560792505741\n",
      "Gradient for encoder.mean.weight: 0.216371089220047\n",
      "Gradient for encoder.mean.bias: 0.014089272357523441\n",
      "Gradient for encoder.log_var.weight: 0.14081606268882751\n",
      "Gradient for encoder.log_var.bias: 0.008213100954890251\n",
      "Gradient for decoder.decoder.0.weight: 0.01887335255742073\n",
      "Gradient for decoder.decoder.0.bias: 1.8214016406226108e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0009384086588397622\n",
      "Gradient for decoder.decoder.1.bias: 0.0006672907620668411\n",
      "Gradient for decoder.decoder.3.weight: 0.014786481857299805\n",
      "Gradient for decoder.decoder.3.bias: 1.2820856876150089e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0006210719584487379\n",
      "Gradient for decoder.decoder.4.bias: 0.0005823928513564169\n",
      "Gradient for decoder.decoder.6.weight: 0.0011245443020015955\n",
      "Gradient for decoder.decoder.6.bias: 6.792534259147942e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.09549528360366821\n",
      "Gradient for encoder.encoder.0.bias: 1.6821334603012161e-10\n",
      "Gradient for encoder.encoder.1.weight: 0.012969261966645718\n",
      "Gradient for encoder.encoder.1.bias: 0.008990274742245674\n",
      "Gradient for encoder.encoder.3.weight: 0.28784865140914917\n",
      "Gradient for encoder.encoder.3.bias: 1.2866685494827834e-09\n",
      "Gradient for encoder.encoder.4.weight: 0.018778743222355843\n",
      "Gradient for encoder.encoder.4.bias: 0.017400404438376427\n",
      "Gradient for encoder.mean.weight: 0.2443767786026001\n",
      "Gradient for encoder.mean.bias: 0.011217639781534672\n",
      "Gradient for encoder.log_var.weight: 0.13864564895629883\n",
      "Gradient for encoder.log_var.bias: 0.006941884756088257\n",
      "Gradient for decoder.decoder.0.weight: 0.018069667741656303\n",
      "Gradient for decoder.decoder.0.bias: 1.5174621281754952e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0009767130250111222\n",
      "Gradient for decoder.decoder.1.bias: 0.0006675003678537905\n",
      "Gradient for decoder.decoder.3.weight: 0.014877491630613804\n",
      "Gradient for decoder.decoder.3.bias: 1.1236314656493107e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0004985997802577913\n",
      "Gradient for decoder.decoder.4.bias: 0.0004865002410952002\n",
      "Gradient for decoder.decoder.6.weight: 0.0009714169427752495\n",
      "Gradient for decoder.decoder.6.bias: 4.476190224522725e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.09297793358564377\n",
      "Gradient for encoder.encoder.0.bias: 1.4862154562589325e-10\n",
      "Gradient for encoder.encoder.1.weight: 0.010147794149816036\n",
      "Gradient for encoder.encoder.1.bias: 0.008070486597716808\n",
      "Gradient for encoder.encoder.3.weight: 0.23058471083641052\n",
      "Gradient for encoder.encoder.3.bias: 1.260226589749891e-09\n",
      "Gradient for encoder.encoder.4.weight: 0.012970410287380219\n",
      "Gradient for encoder.encoder.4.bias: 0.013390731066465378\n",
      "Gradient for encoder.mean.weight: 0.1717439442873001\n",
      "Gradient for encoder.mean.bias: 0.01039395947009325\n",
      "Gradient for encoder.log_var.weight: 0.09054774045944214\n",
      "Gradient for encoder.log_var.bias: 0.005627410486340523\n",
      "Gradient for decoder.decoder.0.weight: 0.0189619529992342\n",
      "Gradient for decoder.decoder.0.bias: 1.7064889779039305e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0010846995282918215\n",
      "Gradient for decoder.decoder.1.bias: 0.0007161349640227854\n",
      "Gradient for decoder.decoder.3.weight: 0.015105358324944973\n",
      "Gradient for decoder.decoder.3.bias: 1.4326562158828438e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0005450188182294369\n",
      "Gradient for decoder.decoder.4.bias: 0.0004936342011205852\n",
      "Gradient for decoder.decoder.6.weight: 0.0010554001200944185\n",
      "Gradient for decoder.decoder.6.bias: 5.319754927768372e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.07801127433776855\n",
      "Gradient for encoder.encoder.0.bias: 1.2431591867034797e-10\n",
      "Gradient for encoder.encoder.1.weight: 0.010105106048285961\n",
      "Gradient for encoder.encoder.1.bias: 0.0082155866548419\n",
      "Gradient for encoder.encoder.3.weight: 0.22073905169963837\n",
      "Gradient for encoder.encoder.3.bias: 1.3958930678015236e-09\n",
      "Gradient for encoder.encoder.4.weight: 0.016663791611790657\n",
      "Gradient for encoder.encoder.4.bias: 0.01931551657617092\n",
      "Gradient for encoder.mean.weight: 0.2309984713792801\n",
      "Gradient for encoder.mean.bias: 0.016859957948327065\n",
      "Gradient for encoder.log_var.weight: 0.12931545078754425\n",
      "Gradient for encoder.log_var.bias: 0.008898130618035793\n",
      "Gradient for decoder.decoder.0.weight: 0.020158233121037483\n",
      "Gradient for decoder.decoder.0.bias: 2.1049559317809496e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0010624330025166273\n",
      "Gradient for decoder.decoder.1.bias: 0.0006834186497144401\n",
      "Gradient for decoder.decoder.3.weight: 0.01569892279803753\n",
      "Gradient for decoder.decoder.3.bias: 1.730049159487379e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0006542091723531485\n",
      "Gradient for decoder.decoder.4.bias: 0.0006271848105825484\n",
      "Gradient for decoder.decoder.6.weight: 0.001054969965480268\n",
      "Gradient for decoder.decoder.6.bias: 5.2733459597220644e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.08198487013578415\n",
      "Gradient for encoder.encoder.0.bias: 1.309230640567094e-10\n",
      "Gradient for encoder.encoder.1.weight: 0.010272729210555553\n",
      "Gradient for encoder.encoder.1.bias: 0.007540620863437653\n",
      "Gradient for encoder.encoder.3.weight: 0.22805172204971313\n",
      "Gradient for encoder.encoder.3.bias: 1.311574293616502e-09\n",
      "Gradient for encoder.encoder.4.weight: 0.016691841185092926\n",
      "Gradient for encoder.encoder.4.bias: 0.012868653051555157\n",
      "Gradient for encoder.mean.weight: 0.17933639883995056\n",
      "Gradient for encoder.mean.bias: 0.00878902804106474\n",
      "Gradient for encoder.log_var.weight: 0.10021837800741196\n",
      "Gradient for encoder.log_var.bias: 0.00455793272703886\n",
      "Gradient for decoder.decoder.0.weight: 0.020769376307725906\n",
      "Gradient for decoder.decoder.0.bias: 1.7344721492396076e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0010993733303621411\n",
      "Gradient for decoder.decoder.1.bias: 0.0007273244555108249\n",
      "Gradient for decoder.decoder.3.weight: 0.01667972467839718\n",
      "Gradient for decoder.decoder.3.bias: 1.1806633448685488e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0006348371389321983\n",
      "Gradient for decoder.decoder.4.bias: 0.0005410508601926267\n",
      "Gradient for decoder.decoder.6.weight: 0.001082765287719667\n",
      "Gradient for decoder.decoder.6.bias: 4.797317524207756e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.09100804477930069\n",
      "Gradient for encoder.encoder.0.bias: 1.470339544562549e-10\n",
      "Gradient for encoder.encoder.1.weight: 0.011963875032961369\n",
      "Gradient for encoder.encoder.1.bias: 0.009014700539410114\n",
      "Gradient for encoder.encoder.3.weight: 0.25712886452674866\n",
      "Gradient for encoder.encoder.3.bias: 1.3103530482894143e-09\n",
      "Gradient for encoder.encoder.4.weight: 0.018518969416618347\n",
      "Gradient for encoder.encoder.4.bias: 0.01644233427941799\n",
      "Gradient for encoder.mean.weight: 0.21887223422527313\n",
      "Gradient for encoder.mean.bias: 0.010914681479334831\n",
      "Gradient for encoder.log_var.weight: 0.11525611579418182\n",
      "Gradient for encoder.log_var.bias: 0.00590644171461463\n",
      "Gradient for decoder.decoder.0.weight: 0.017491238191723824\n",
      "Gradient for decoder.decoder.0.bias: 1.6463110041886608e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0008955718367360532\n",
      "Gradient for decoder.decoder.1.bias: 0.0006103432970121503\n",
      "Gradient for decoder.decoder.3.weight: 0.013249272480607033\n",
      "Gradient for decoder.decoder.3.bias: 1.145191649842836e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0005214156117290258\n",
      "Gradient for decoder.decoder.4.bias: 0.0005449885502457619\n",
      "Gradient for decoder.decoder.6.weight: 0.001102740759961307\n",
      "Gradient for decoder.decoder.6.bias: 7.524602551711723e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training VAE Epoch:  42%|████▏     | 33/79 [00:00<00:00, 67.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient for encoder.encoder.0.weight: 0.0748811811208725\n",
      "Gradient for encoder.encoder.0.bias: 1.1841595759509715e-10\n",
      "Gradient for encoder.encoder.1.weight: 0.009645717218518257\n",
      "Gradient for encoder.encoder.1.bias: 0.0075540500693023205\n",
      "Gradient for encoder.encoder.3.weight: 0.20890432596206665\n",
      "Gradient for encoder.encoder.3.bias: 1.5202230585487087e-09\n",
      "Gradient for encoder.encoder.4.weight: 0.016756663098931313\n",
      "Gradient for encoder.encoder.4.bias: 0.01773836649954319\n",
      "Gradient for encoder.mean.weight: 0.21033719182014465\n",
      "Gradient for encoder.mean.bias: 0.012197946198284626\n",
      "Gradient for encoder.log_var.weight: 0.12890049815177917\n",
      "Gradient for encoder.log_var.bias: 0.007847693748772144\n",
      "Gradient for decoder.decoder.0.weight: 0.020840350538492203\n",
      "Gradient for decoder.decoder.0.bias: 1.9133546136362867e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0010458523174747825\n",
      "Gradient for decoder.decoder.1.bias: 0.0006689292495138943\n",
      "Gradient for decoder.decoder.3.weight: 0.015935005620121956\n",
      "Gradient for decoder.decoder.3.bias: 1.5058816693613863e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.000808682874776423\n",
      "Gradient for decoder.decoder.4.bias: 0.0008809970458969474\n",
      "Gradient for decoder.decoder.6.weight: 0.001243456150405109\n",
      "Gradient for decoder.decoder.6.bias: 9.469181532040238e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.08466816693544388\n",
      "Gradient for encoder.encoder.0.bias: 1.4013672167134672e-10\n",
      "Gradient for encoder.encoder.1.weight: 0.010897569358348846\n",
      "Gradient for encoder.encoder.1.bias: 0.009060676209628582\n",
      "Gradient for encoder.encoder.3.weight: 0.23928037285804749\n",
      "Gradient for encoder.encoder.3.bias: 1.3088917727444027e-09\n",
      "Gradient for encoder.encoder.4.weight: 0.014630292542278767\n",
      "Gradient for encoder.encoder.4.bias: 0.013273470103740692\n",
      "Gradient for encoder.mean.weight: 0.1845446527004242\n",
      "Gradient for encoder.mean.bias: 0.007958824746310711\n",
      "Gradient for encoder.log_var.weight: 0.10217219591140747\n",
      "Gradient for encoder.log_var.bias: 0.004718742799013853\n",
      "Gradient for decoder.decoder.0.weight: 0.01800825446844101\n",
      "Gradient for decoder.decoder.0.bias: 1.6314104234194104e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0009667398408055305\n",
      "Gradient for decoder.decoder.1.bias: 0.0006599814514629543\n",
      "Gradient for decoder.decoder.3.weight: 0.014329279772937298\n",
      "Gradient for decoder.decoder.3.bias: 1.207881294984503e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0005875267088413239\n",
      "Gradient for decoder.decoder.4.bias: 0.0005226630601100624\n",
      "Gradient for decoder.decoder.6.weight: 0.0010421409970149398\n",
      "Gradient for decoder.decoder.6.bias: 4.4196636736160144e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training VAE Epoch:  52%|█████▏    | 41/79 [00:00<00:00, 70.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient for encoder.encoder.0.weight: 0.09914630651473999\n",
      "Gradient for encoder.encoder.0.bias: 1.8573229065843577e-10\n",
      "Gradient for encoder.encoder.1.weight: 0.014408646151423454\n",
      "Gradient for encoder.encoder.1.bias: 0.009348036721348763\n",
      "Gradient for encoder.encoder.3.weight: 0.30359768867492676\n",
      "Gradient for encoder.encoder.3.bias: 1.497857171628425e-09\n",
      "Gradient for encoder.encoder.4.weight: 0.017085237428545952\n",
      "Gradient for encoder.encoder.4.bias: 0.015218463726341724\n",
      "Gradient for encoder.mean.weight: 0.2134106159210205\n",
      "Gradient for encoder.mean.bias: 0.008836901746690273\n",
      "Gradient for encoder.log_var.weight: 0.11121196299791336\n",
      "Gradient for encoder.log_var.bias: 0.0047180745750665665\n",
      "Gradient for decoder.decoder.0.weight: 0.01733282394707203\n",
      "Gradient for decoder.decoder.0.bias: 1.5303874834060593e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0009068885119631886\n",
      "Gradient for decoder.decoder.1.bias: 0.0006026030168868601\n",
      "Gradient for decoder.decoder.3.weight: 0.013771436177194118\n",
      "Gradient for decoder.decoder.3.bias: 1.1593015436517362e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0004886618116870522\n",
      "Gradient for decoder.decoder.4.bias: 0.0004347182693891227\n",
      "Gradient for decoder.decoder.6.weight: 0.001042453572154045\n",
      "Gradient for decoder.decoder.6.bias: 5.195556514081545e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.07676191627979279\n",
      "Gradient for encoder.encoder.0.bias: 1.3770287687897564e-10\n",
      "Gradient for encoder.encoder.1.weight: 0.01087964791804552\n",
      "Gradient for encoder.encoder.1.bias: 0.007950925268232822\n",
      "Gradient for encoder.encoder.3.weight: 0.2379390299320221\n",
      "Gradient for encoder.encoder.3.bias: 1.400664917383665e-09\n",
      "Gradient for encoder.encoder.4.weight: 0.016431136056780815\n",
      "Gradient for encoder.encoder.4.bias: 0.016659390181303024\n",
      "Gradient for encoder.mean.weight: 0.20701320469379425\n",
      "Gradient for encoder.mean.bias: 0.01069281529635191\n",
      "Gradient for encoder.log_var.weight: 0.11515629291534424\n",
      "Gradient for encoder.log_var.bias: 0.006769915111362934\n",
      "Gradient for decoder.decoder.0.weight: 0.01780521683394909\n",
      "Gradient for decoder.decoder.0.bias: 1.6923618062492096e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0009836920071393251\n",
      "Gradient for decoder.decoder.1.bias: 0.0006634080200456083\n",
      "Gradient for decoder.decoder.3.weight: 0.014247690327465534\n",
      "Gradient for decoder.decoder.3.bias: 1.2026971085710159e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0005401509115472436\n",
      "Gradient for decoder.decoder.4.bias: 0.0004772215033881366\n",
      "Gradient for decoder.decoder.6.weight: 0.0011394380126148462\n",
      "Gradient for decoder.decoder.6.bias: 7.524663669755682e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.07350993156433105\n",
      "Gradient for encoder.encoder.0.bias: 1.226656276553939e-10\n",
      "Gradient for encoder.encoder.1.weight: 0.00953034870326519\n",
      "Gradient for encoder.encoder.1.bias: 0.0074519501067698\n",
      "Gradient for encoder.encoder.3.weight: 0.21097157895565033\n",
      "Gradient for encoder.encoder.3.bias: 1.2442379349053567e-09\n",
      "Gradient for encoder.encoder.4.weight: 0.017919640988111496\n",
      "Gradient for encoder.encoder.4.bias: 0.015760349109768867\n",
      "Gradient for encoder.mean.weight: 0.21728472411632538\n",
      "Gradient for encoder.mean.bias: 0.010890187695622444\n",
      "Gradient for encoder.log_var.weight: 0.12441053986549377\n",
      "Gradient for encoder.log_var.bias: 0.006753931287676096\n",
      "Gradient for decoder.decoder.0.weight: 0.018715081736445427\n",
      "Gradient for decoder.decoder.0.bias: 1.5124895780260772e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0010314719984307885\n",
      "Gradient for decoder.decoder.1.bias: 0.0006674964679405093\n",
      "Gradient for decoder.decoder.3.weight: 0.014683316461741924\n",
      "Gradient for decoder.decoder.3.bias: 1.0784202003621957e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0006016681436449289\n",
      "Gradient for decoder.decoder.4.bias: 0.0005413980106823146\n",
      "Gradient for decoder.decoder.6.weight: 0.0010823545744642615\n",
      "Gradient for decoder.decoder.6.bias: 5.022156983613968e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.08873007446527481\n",
      "Gradient for encoder.encoder.0.bias: 1.4316475782649718e-10\n",
      "Gradient for encoder.encoder.1.weight: 0.012719271704554558\n",
      "Gradient for encoder.encoder.1.bias: 0.009151079691946507\n",
      "Gradient for encoder.encoder.3.weight: 0.27983981370925903\n",
      "Gradient for encoder.encoder.3.bias: 1.364998558628372e-09\n",
      "Gradient for encoder.encoder.4.weight: 0.021059520542621613\n",
      "Gradient for encoder.encoder.4.bias: 0.020736562088131905\n",
      "Gradient for encoder.mean.weight: 0.26552680134773254\n",
      "Gradient for encoder.mean.bias: 0.01382486429065466\n",
      "Gradient for encoder.log_var.weight: 0.15157124400138855\n",
      "Gradient for encoder.log_var.bias: 0.008129254914820194\n",
      "Gradient for decoder.decoder.0.weight: 0.016439959406852722\n",
      "Gradient for decoder.decoder.0.bias: 1.4307861839757408e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0008942367858253419\n",
      "Gradient for decoder.decoder.1.bias: 0.0005942266434431076\n",
      "Gradient for decoder.decoder.3.weight: 0.013038155622780323\n",
      "Gradient for decoder.decoder.3.bias: 1.0332332212037443e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0004841026966460049\n",
      "Gradient for decoder.decoder.4.bias: 0.00044834648724645376\n",
      "Gradient for decoder.decoder.6.weight: 0.001071270788088441\n",
      "Gradient for decoder.decoder.6.bias: 5.594073445536196e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.08209459483623505\n",
      "Gradient for encoder.encoder.0.bias: 1.4450225738205091e-10\n",
      "Gradient for encoder.encoder.1.weight: 0.011634188704192638\n",
      "Gradient for encoder.encoder.1.bias: 0.00888159777969122\n",
      "Gradient for encoder.encoder.3.weight: 0.2577398419380188\n",
      "Gradient for encoder.encoder.3.bias: 1.1875559424723292e-09\n",
      "Gradient for encoder.encoder.4.weight: 0.016445361077785492\n",
      "Gradient for encoder.encoder.4.bias: 0.01519260834902525\n",
      "Gradient for encoder.mean.weight: 0.21073439717292786\n",
      "Gradient for encoder.mean.bias: 0.010871595703065395\n",
      "Gradient for encoder.log_var.weight: 0.1129462793469429\n",
      "Gradient for encoder.log_var.bias: 0.006529602222144604\n",
      "Gradient for decoder.decoder.0.weight: 0.02014119178056717\n",
      "Gradient for decoder.decoder.0.bias: 1.540743921335519e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0009852312505245209\n",
      "Gradient for decoder.decoder.1.bias: 0.0006907942006364465\n",
      "Gradient for decoder.decoder.3.weight: 0.01496551837772131\n",
      "Gradient for decoder.decoder.3.bias: 1.3933917908381943e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0009004673338495195\n",
      "Gradient for decoder.decoder.4.bias: 0.0009265820845030248\n",
      "Gradient for decoder.decoder.6.weight: 0.001324958517216146\n",
      "Gradient for decoder.decoder.6.bias: 9.725330892251804e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.07770346850156784\n",
      "Gradient for encoder.encoder.0.bias: 1.466120003179583e-10\n",
      "Gradient for encoder.encoder.1.weight: 0.010785602033138275\n",
      "Gradient for encoder.encoder.1.bias: 0.007822409272193909\n",
      "Gradient for encoder.encoder.3.weight: 0.23387594521045685\n",
      "Gradient for encoder.encoder.3.bias: 1.105815772284302e-09\n",
      "Gradient for encoder.encoder.4.weight: 0.013838970102369785\n",
      "Gradient for encoder.encoder.4.bias: 0.013522522523999214\n",
      "Gradient for encoder.mean.weight: 0.1872028112411499\n",
      "Gradient for encoder.mean.bias: 0.008854429237544537\n",
      "Gradient for encoder.log_var.weight: 0.09476730972528458\n",
      "Gradient for encoder.log_var.bias: 0.00525007164105773\n",
      "Gradient for decoder.decoder.0.weight: 0.017359310761094093\n",
      "Gradient for decoder.decoder.0.bias: 1.414911660058138e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0009414693340659142\n",
      "Gradient for decoder.decoder.1.bias: 0.0006355493096634746\n",
      "Gradient for decoder.decoder.3.weight: 0.01372914481908083\n",
      "Gradient for decoder.decoder.3.bias: 1.0166413544343555e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0005458385567180812\n",
      "Gradient for decoder.decoder.4.bias: 0.0005164769245311618\n",
      "Gradient for decoder.decoder.6.weight: 0.0010357931023463607\n",
      "Gradient for decoder.decoder.6.bias: 5.016399882151745e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.1116316020488739\n",
      "Gradient for encoder.encoder.0.bias: 1.8347590113876322e-10\n",
      "Gradient for encoder.encoder.1.weight: 0.013296933844685555\n",
      "Gradient for encoder.encoder.1.bias: 0.009076457470655441\n",
      "Gradient for encoder.encoder.3.weight: 0.2943083941936493\n",
      "Gradient for encoder.encoder.3.bias: 1.3802078369096193e-09\n",
      "Gradient for encoder.encoder.4.weight: 0.02088106796145439\n",
      "Gradient for encoder.encoder.4.bias: 0.018762342631816864\n",
      "Gradient for encoder.mean.weight: 0.2542076110839844\n",
      "Gradient for encoder.mean.bias: 0.010561197064816952\n",
      "Gradient for encoder.log_var.weight: 0.1414375603199005\n",
      "Gradient for encoder.log_var.bias: 0.006765967700630426\n",
      "Gradient for decoder.decoder.0.weight: 0.015080939047038555\n",
      "Gradient for decoder.decoder.0.bias: 1.3099969720098414e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0008299270994029939\n",
      "Gradient for decoder.decoder.1.bias: 0.000568039424251765\n",
      "Gradient for decoder.decoder.3.weight: 0.012095247395336628\n",
      "Gradient for decoder.decoder.3.bias: 9.922099947212715e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0006223272648639977\n",
      "Gradient for decoder.decoder.4.bias: 0.0007020554621703923\n",
      "Gradient for decoder.decoder.6.weight: 0.0012024417519569397\n",
      "Gradient for decoder.decoder.6.bias: 8.961009734775871e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.07574137300252914\n",
      "Gradient for encoder.encoder.0.bias: 1.402450100496111e-10\n",
      "Gradient for encoder.encoder.1.weight: 0.009524770081043243\n",
      "Gradient for encoder.encoder.1.bias: 0.0071050506085157394\n",
      "Gradient for encoder.encoder.3.weight: 0.21587742865085602\n",
      "Gradient for encoder.encoder.3.bias: 1.6427211813052622e-09\n",
      "Gradient for encoder.encoder.4.weight: 0.017991548404097557\n",
      "Gradient for encoder.encoder.4.bias: 0.01920168846845627\n",
      "Gradient for encoder.mean.weight: 0.21662300825119019\n",
      "Gradient for encoder.mean.bias: 0.013215288519859314\n",
      "Gradient for encoder.log_var.weight: 0.1196710616350174\n",
      "Gradient for encoder.log_var.bias: 0.00905466079711914\n",
      "Gradient for decoder.decoder.0.weight: 0.01742994599044323\n",
      "Gradient for decoder.decoder.0.bias: 1.4616666210720552e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0009161202469840646\n",
      "Gradient for decoder.decoder.1.bias: 0.0006404964369721711\n",
      "Gradient for decoder.decoder.3.weight: 0.013895198702812195\n",
      "Gradient for decoder.decoder.3.bias: 1.1332040167344459e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0005960601265542209\n",
      "Gradient for decoder.decoder.4.bias: 0.0006269143777899444\n",
      "Gradient for decoder.decoder.6.weight: 0.0011397568741813302\n",
      "Gradient for decoder.decoder.6.bias: 7.58334863348864e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.06280416995286942\n",
      "Gradient for encoder.encoder.0.bias: 9.433329117847222e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.007281338796019554\n",
      "Gradient for encoder.encoder.1.bias: 0.006001133471727371\n",
      "Gradient for encoder.encoder.3.weight: 0.16404159367084503\n",
      "Gradient for encoder.encoder.3.bias: 1.0668516070566625e-09\n",
      "Gradient for encoder.encoder.4.weight: 0.012807822786271572\n",
      "Gradient for encoder.encoder.4.bias: 0.012299097143113613\n",
      "Gradient for encoder.mean.weight: 0.16589555144309998\n",
      "Gradient for encoder.mean.bias: 0.009958099573850632\n",
      "Gradient for encoder.log_var.weight: 0.09250176697969437\n",
      "Gradient for encoder.log_var.bias: 0.0048503512516617775\n",
      "Gradient for decoder.decoder.0.weight: 0.01900431513786316\n",
      "Gradient for decoder.decoder.0.bias: 1.5830715904829873e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0009933748515322804\n",
      "Gradient for decoder.decoder.1.bias: 0.0006359901744872332\n",
      "Gradient for decoder.decoder.3.weight: 0.014846503734588623\n",
      "Gradient for decoder.decoder.3.bias: 1.1390218629392379e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0005236846045590937\n",
      "Gradient for decoder.decoder.4.bias: 0.0004396829172037542\n",
      "Gradient for decoder.decoder.6.weight: 0.001018838956952095\n",
      "Gradient for decoder.decoder.6.bias: 4.33437162428163e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.0773157924413681\n",
      "Gradient for encoder.encoder.0.bias: 1.334526655849544e-10\n",
      "Gradient for encoder.encoder.1.weight: 0.009492170996963978\n",
      "Gradient for encoder.encoder.1.bias: 0.006936395075172186\n",
      "Gradient for encoder.encoder.3.weight: 0.21859446167945862\n",
      "Gradient for encoder.encoder.3.bias: 1.183461995069024e-09\n",
      "Gradient for encoder.encoder.4.weight: 0.01512452308088541\n",
      "Gradient for encoder.encoder.4.bias: 0.013020087964832783\n",
      "Gradient for encoder.mean.weight: 0.1991880238056183\n",
      "Gradient for encoder.mean.bias: 0.007949724793434143\n",
      "Gradient for encoder.log_var.weight: 0.09768330305814743\n",
      "Gradient for encoder.log_var.bias: 0.004645040724426508\n",
      "Gradient for decoder.decoder.0.weight: 0.01825064793229103\n",
      "Gradient for decoder.decoder.0.bias: 1.535828408893991e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0009462276357226074\n",
      "Gradient for decoder.decoder.1.bias: 0.0006362293497659266\n",
      "Gradient for decoder.decoder.3.weight: 0.013955830596387386\n",
      "Gradient for decoder.decoder.3.bias: 1.0624587321039769e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.000521316600497812\n",
      "Gradient for decoder.decoder.4.bias: 0.0005093019572086632\n",
      "Gradient for decoder.decoder.6.weight: 0.001032887026667595\n",
      "Gradient for decoder.decoder.6.bias: 5.502362546394579e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.09090711921453476\n",
      "Gradient for encoder.encoder.0.bias: 1.5359315208574031e-10\n",
      "Gradient for encoder.encoder.1.weight: 0.011013821698725224\n",
      "Gradient for encoder.encoder.1.bias: 0.007878221571445465\n",
      "Gradient for encoder.encoder.3.weight: 0.24248690903186798\n",
      "Gradient for encoder.encoder.3.bias: 1.221845402632482e-09\n",
      "Gradient for encoder.encoder.4.weight: 0.017303261905908585\n",
      "Gradient for encoder.encoder.4.bias: 0.015159083530306816\n",
      "Gradient for encoder.mean.weight: 0.23007003962993622\n",
      "Gradient for encoder.mean.bias: 0.011680306866765022\n",
      "Gradient for encoder.log_var.weight: 0.12088387459516525\n",
      "Gradient for encoder.log_var.bias: 0.00623364420607686\n",
      "Gradient for decoder.decoder.0.weight: 0.01637718826532364\n",
      "Gradient for decoder.decoder.0.bias: 1.255423959234392e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0009072823449969292\n",
      "Gradient for decoder.decoder.1.bias: 0.000574591918848455\n",
      "Gradient for decoder.decoder.3.weight: 0.013197812251746655\n",
      "Gradient for decoder.decoder.3.bias: 1.1028560703563173e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0006457168492488563\n",
      "Gradient for decoder.decoder.4.bias: 0.0007296919939108193\n",
      "Gradient for decoder.decoder.6.weight: 0.0010940178763121367\n",
      "Gradient for decoder.decoder.6.bias: 7.527218986069784e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.09975925087928772\n",
      "Gradient for encoder.encoder.0.bias: 1.4041152962551706e-10\n",
      "Gradient for encoder.encoder.1.weight: 0.011236093938350677\n",
      "Gradient for encoder.encoder.1.bias: 0.008648674935102463\n",
      "Gradient for encoder.encoder.3.weight: 0.26554086804389954\n",
      "Gradient for encoder.encoder.3.bias: 1.8362529274895678e-09\n",
      "Gradient for encoder.encoder.4.weight: 0.025538524612784386\n",
      "Gradient for encoder.encoder.4.bias: 0.025544866919517517\n",
      "Gradient for encoder.mean.weight: 0.3217047452926636\n",
      "Gradient for encoder.mean.bias: 0.017609981819987297\n",
      "Gradient for encoder.log_var.weight: 0.19480934739112854\n",
      "Gradient for encoder.log_var.bias: 0.010748746804893017\n",
      "Gradient for decoder.decoder.0.weight: 0.018625369295477867\n",
      "Gradient for decoder.decoder.0.bias: 1.5244862316965424e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0009908119682222605\n",
      "Gradient for decoder.decoder.1.bias: 0.0006611400749534369\n",
      "Gradient for decoder.decoder.3.weight: 0.014843134209513664\n",
      "Gradient for decoder.decoder.3.bias: 1.4014212013080396e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0006746189901605248\n",
      "Gradient for decoder.decoder.4.bias: 0.000779688183683902\n",
      "Gradient for decoder.decoder.6.weight: 0.0011975562665611506\n",
      "Gradient for decoder.decoder.6.bias: 9.547435911372304e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.06354961544275284\n",
      "Gradient for encoder.encoder.0.bias: 1.0272661193910793e-10\n",
      "Gradient for encoder.encoder.1.weight: 0.008284247480332851\n",
      "Gradient for encoder.encoder.1.bias: 0.006356057710945606\n",
      "Gradient for encoder.encoder.3.weight: 0.19172580540180206\n",
      "Gradient for encoder.encoder.3.bias: 1.1160200541482368e-09\n",
      "Gradient for encoder.encoder.4.weight: 0.01709451526403427\n",
      "Gradient for encoder.encoder.4.bias: 0.015303324908018112\n",
      "Gradient for encoder.mean.weight: 0.20464715361595154\n",
      "Gradient for encoder.mean.bias: 0.010927448980510235\n",
      "Gradient for encoder.log_var.weight: 0.09883373230695724\n",
      "Gradient for encoder.log_var.bias: 0.0047140661627054214\n",
      "Gradient for decoder.decoder.0.weight: 0.0191391259431839\n",
      "Gradient for decoder.decoder.0.bias: 1.5582231338573393e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0009955918649211526\n",
      "Gradient for decoder.decoder.1.bias: 0.0006866606418043375\n",
      "Gradient for decoder.decoder.3.weight: 0.014830506406724453\n",
      "Gradient for decoder.decoder.3.bias: 1.1053735704535939e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0005807236884720623\n",
      "Gradient for decoder.decoder.4.bias: 0.0005460858810693026\n",
      "Gradient for decoder.decoder.6.weight: 0.0010924548842012882\n",
      "Gradient for decoder.decoder.6.bias: 7.009346154518425e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.08534957468509674\n",
      "Gradient for encoder.encoder.0.bias: 1.505623681286039e-10\n",
      "Gradient for encoder.encoder.1.weight: 0.010133774019777775\n",
      "Gradient for encoder.encoder.1.bias: 0.008191552013158798\n",
      "Gradient for encoder.encoder.3.weight: 0.22618891298770905\n",
      "Gradient for encoder.encoder.3.bias: 1.4497812950153843e-09\n",
      "Gradient for encoder.encoder.4.weight: 0.020677413791418076\n",
      "Gradient for encoder.encoder.4.bias: 0.021849652752280235\n",
      "Gradient for encoder.mean.weight: 0.2773308753967285\n",
      "Gradient for encoder.mean.bias: 0.01839432865381241\n",
      "Gradient for encoder.log_var.weight: 0.15544536709785461\n",
      "Gradient for encoder.log_var.bias: 0.009709102101624012\n",
      "Gradient for decoder.decoder.0.weight: 0.01700148545205593\n",
      "Gradient for decoder.decoder.0.bias: 1.3831646938911035e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0009654026362113655\n",
      "Gradient for decoder.decoder.1.bias: 0.0006548351375386119\n",
      "Gradient for decoder.decoder.3.weight: 0.013881655409932137\n",
      "Gradient for decoder.decoder.3.bias: 1.029368257299268e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0004891269491054118\n",
      "Gradient for decoder.decoder.4.bias: 0.00043647020356729627\n",
      "Gradient for decoder.decoder.6.weight: 0.0010433127172291279\n",
      "Gradient for decoder.decoder.6.bias: 5.2735973440576345e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training VAE Epoch:  62%|██████▏   | 49/79 [00:00<00:00, 73.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient for encoder.encoder.0.weight: 0.08488816022872925\n",
      "Gradient for encoder.encoder.0.bias: 1.2185819020515964e-10\n",
      "Gradient for encoder.encoder.1.weight: 0.00862964615225792\n",
      "Gradient for encoder.encoder.1.bias: 0.00667097233235836\n",
      "Gradient for encoder.encoder.3.weight: 0.18298280239105225\n",
      "Gradient for encoder.encoder.3.bias: 1.1752298023637309e-09\n",
      "Gradient for encoder.encoder.4.weight: 0.01584380306303501\n",
      "Gradient for encoder.encoder.4.bias: 0.014948619529604912\n",
      "Gradient for encoder.mean.weight: 0.2028682380914688\n",
      "Gradient for encoder.mean.bias: 0.010679074563086033\n",
      "Gradient for encoder.log_var.weight: 0.12213964015245438\n",
      "Gradient for encoder.log_var.bias: 0.005617094226181507\n",
      "Gradient for decoder.decoder.0.weight: 0.018490321934223175\n",
      "Gradient for decoder.decoder.0.bias: 1.7570307708769661e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0010060425847768784\n",
      "Gradient for decoder.decoder.1.bias: 0.0006646311958320439\n",
      "Gradient for decoder.decoder.3.weight: 0.014377684332430363\n",
      "Gradient for decoder.decoder.3.bias: 1.2499805357446547e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.000524943636264652\n",
      "Gradient for decoder.decoder.4.bias: 0.0004687387845478952\n",
      "Gradient for decoder.decoder.6.weight: 0.0010127299465239048\n",
      "Gradient for decoder.decoder.6.bias: 4.391259062686004e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.07619240880012512\n",
      "Gradient for encoder.encoder.0.bias: 1.0983648712770133e-10\n",
      "Gradient for encoder.encoder.1.weight: 0.009261253289878368\n",
      "Gradient for encoder.encoder.1.bias: 0.007321776356548071\n",
      "Gradient for encoder.encoder.3.weight: 0.20855341851711273\n",
      "Gradient for encoder.encoder.3.bias: 1.0934094740733258e-09\n",
      "Gradient for encoder.encoder.4.weight: 0.012142757885158062\n",
      "Gradient for encoder.encoder.4.bias: 0.010467561893165112\n",
      "Gradient for encoder.mean.weight: 0.16218821704387665\n",
      "Gradient for encoder.mean.bias: 0.007570547983050346\n",
      "Gradient for encoder.log_var.weight: 0.07856303453445435\n",
      "Gradient for encoder.log_var.bias: 0.00459799962118268\n",
      "Gradient for decoder.decoder.0.weight: 0.01841246895492077\n",
      "Gradient for decoder.decoder.0.bias: 1.8781809441037467e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0010182455880567431\n",
      "Gradient for decoder.decoder.1.bias: 0.0006745993159711361\n",
      "Gradient for decoder.decoder.3.weight: 0.014581928960978985\n",
      "Gradient for decoder.decoder.3.bias: 1.3711612401046125e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0005236777360551059\n",
      "Gradient for decoder.decoder.4.bias: 0.0005043023847974837\n",
      "Gradient for decoder.decoder.6.weight: 0.00102936290204525\n",
      "Gradient for decoder.decoder.6.bias: 5.329882333171554e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training VAE Epoch:  72%|███████▏  | 57/79 [00:00<00:00, 75.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient for encoder.encoder.0.weight: 0.07839636504650116\n",
      "Gradient for encoder.encoder.0.bias: 1.3148004907037603e-10\n",
      "Gradient for encoder.encoder.1.weight: 0.01099494006484747\n",
      "Gradient for encoder.encoder.1.bias: 0.007760764565318823\n",
      "Gradient for encoder.encoder.3.weight: 0.2422853410243988\n",
      "Gradient for encoder.encoder.3.bias: 1.0707236208773452e-09\n",
      "Gradient for encoder.encoder.4.weight: 0.01656579039990902\n",
      "Gradient for encoder.encoder.4.bias: 0.014539315365254879\n",
      "Gradient for encoder.mean.weight: 0.21083545684814453\n",
      "Gradient for encoder.mean.bias: 0.00890722218900919\n",
      "Gradient for encoder.log_var.weight: 0.10767815262079239\n",
      "Gradient for encoder.log_var.bias: 0.0052136327140033245\n",
      "Gradient for decoder.decoder.0.weight: 0.015425564721226692\n",
      "Gradient for decoder.decoder.0.bias: 1.2126544213231227e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0008331909193657339\n",
      "Gradient for decoder.decoder.1.bias: 0.0005491137853823602\n",
      "Gradient for decoder.decoder.3.weight: 0.011562757194042206\n",
      "Gradient for decoder.decoder.3.bias: 1.2390906356518627e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0008471017936244607\n",
      "Gradient for decoder.decoder.4.bias: 0.0010898561449721456\n",
      "Gradient for decoder.decoder.6.weight: 0.0012930051889270544\n",
      "Gradient for decoder.decoder.6.bias: 0.00011301900667604059\n",
      "Gradient for encoder.encoder.0.weight: 0.09564024209976196\n",
      "Gradient for encoder.encoder.0.bias: 1.6127722768377595e-10\n",
      "Gradient for encoder.encoder.1.weight: 0.01230862457305193\n",
      "Gradient for encoder.encoder.1.bias: 0.009462237358093262\n",
      "Gradient for encoder.encoder.3.weight: 0.28866133093833923\n",
      "Gradient for encoder.encoder.3.bias: 1.5262838770624398e-09\n",
      "Gradient for encoder.encoder.4.weight: 0.02442340739071369\n",
      "Gradient for encoder.encoder.4.bias: 0.022517185658216476\n",
      "Gradient for encoder.mean.weight: 0.29333242774009705\n",
      "Gradient for encoder.mean.bias: 0.016717778518795967\n",
      "Gradient for encoder.log_var.weight: 0.15087585151195526\n",
      "Gradient for encoder.log_var.bias: 0.00813288614153862\n",
      "Gradient for decoder.decoder.0.weight: 0.018761763349175453\n",
      "Gradient for decoder.decoder.0.bias: 1.5141875253643633e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0009857206605374813\n",
      "Gradient for decoder.decoder.1.bias: 0.0006550189573317766\n",
      "Gradient for decoder.decoder.3.weight: 0.014478285796940327\n",
      "Gradient for decoder.decoder.3.bias: 1.0781037174112384e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0005321754142642021\n",
      "Gradient for decoder.decoder.4.bias: 0.00046914166887290776\n",
      "Gradient for decoder.decoder.6.weight: 0.0010975940385833383\n",
      "Gradient for decoder.decoder.6.bias: 6.216465408215299e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.13739457726478577\n",
      "Gradient for encoder.encoder.0.bias: 2.478878213807434e-10\n",
      "Gradient for encoder.encoder.1.weight: 0.020245060324668884\n",
      "Gradient for encoder.encoder.1.bias: 0.013731186278164387\n",
      "Gradient for encoder.encoder.3.weight: 0.4549458622932434\n",
      "Gradient for encoder.encoder.3.bias: 2.010603905588937e-09\n",
      "Gradient for encoder.encoder.4.weight: 0.03765786811709404\n",
      "Gradient for encoder.encoder.4.bias: 0.02955750748515129\n",
      "Gradient for encoder.mean.weight: 0.46264100074768066\n",
      "Gradient for encoder.mean.bias: 0.015871917828917503\n",
      "Gradient for encoder.log_var.weight: 0.25198855996131897\n",
      "Gradient for encoder.log_var.bias: 0.008039349690079689\n",
      "Gradient for decoder.decoder.0.weight: 0.01543534267693758\n",
      "Gradient for decoder.decoder.0.bias: 1.377635366894836e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0008159686694853008\n",
      "Gradient for decoder.decoder.1.bias: 0.0005588287604041398\n",
      "Gradient for decoder.decoder.3.weight: 0.012262566015124321\n",
      "Gradient for decoder.decoder.3.bias: 1.0595247595945878e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.00046632238081656396\n",
      "Gradient for decoder.decoder.4.bias: 0.00044310023076832294\n",
      "Gradient for decoder.decoder.6.weight: 0.0010674373479560018\n",
      "Gradient for decoder.decoder.6.bias: 6.730847235303372e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.06756576895713806\n",
      "Gradient for encoder.encoder.0.bias: 1.257972614965297e-10\n",
      "Gradient for encoder.encoder.1.weight: 0.008033140562474728\n",
      "Gradient for encoder.encoder.1.bias: 0.006494163069874048\n",
      "Gradient for encoder.encoder.3.weight: 0.17617502808570862\n",
      "Gradient for encoder.encoder.3.bias: 1.0127217953126433e-09\n",
      "Gradient for encoder.encoder.4.weight: 0.013980776071548462\n",
      "Gradient for encoder.encoder.4.bias: 0.01232833694666624\n",
      "Gradient for encoder.mean.weight: 0.16456203162670135\n",
      "Gradient for encoder.mean.bias: 0.008453578688204288\n",
      "Gradient for encoder.log_var.weight: 0.09727028757333755\n",
      "Gradient for encoder.log_var.bias: 0.005216152407228947\n",
      "Gradient for decoder.decoder.0.weight: 0.01795230433344841\n",
      "Gradient for decoder.decoder.0.bias: 1.4696485695075978e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0009394499356858432\n",
      "Gradient for decoder.decoder.1.bias: 0.0006405110470950603\n",
      "Gradient for decoder.decoder.3.weight: 0.013825715519487858\n",
      "Gradient for decoder.decoder.3.bias: 1.0342803696827829e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0004845834628213197\n",
      "Gradient for decoder.decoder.4.bias: 0.0004415395960677415\n",
      "Gradient for decoder.decoder.6.weight: 0.0009515615529380739\n",
      "Gradient for decoder.decoder.6.bias: 4.422252459335141e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.07389745861291885\n",
      "Gradient for encoder.encoder.0.bias: 1.3014531119459605e-10\n",
      "Gradient for encoder.encoder.1.weight: 0.01226766686886549\n",
      "Gradient for encoder.encoder.1.bias: 0.00853997003287077\n",
      "Gradient for encoder.encoder.3.weight: 0.26686838269233704\n",
      "Gradient for encoder.encoder.3.bias: 2.0089050423166555e-09\n",
      "Gradient for encoder.encoder.4.weight: 0.019968634471297264\n",
      "Gradient for encoder.encoder.4.bias: 0.018782898783683777\n",
      "Gradient for encoder.mean.weight: 0.23838156461715698\n",
      "Gradient for encoder.mean.bias: 0.009329505264759064\n",
      "Gradient for encoder.log_var.weight: 0.1350778490304947\n",
      "Gradient for encoder.log_var.bias: 0.006455914583057165\n",
      "Gradient for decoder.decoder.0.weight: 0.019949067384004593\n",
      "Gradient for decoder.decoder.0.bias: 1.6703877170343162e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.00104001653380692\n",
      "Gradient for decoder.decoder.1.bias: 0.000745125231333077\n",
      "Gradient for decoder.decoder.3.weight: 0.015367581509053707\n",
      "Gradient for decoder.decoder.3.bias: 1.199833010723239e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0005624286714009941\n",
      "Gradient for decoder.decoder.4.bias: 0.000491020386107266\n",
      "Gradient for decoder.decoder.6.weight: 0.0009629995911382139\n",
      "Gradient for decoder.decoder.6.bias: 3.581888449843973e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.10954135656356812\n",
      "Gradient for encoder.encoder.0.bias: 1.707615715496047e-10\n",
      "Gradient for encoder.encoder.1.weight: 0.013057275675237179\n",
      "Gradient for encoder.encoder.1.bias: 0.009631762281060219\n",
      "Gradient for encoder.encoder.3.weight: 0.29364684224128723\n",
      "Gradient for encoder.encoder.3.bias: 1.9398820327864996e-09\n",
      "Gradient for encoder.encoder.4.weight: 0.023207735270261765\n",
      "Gradient for encoder.encoder.4.bias: 0.020333612337708473\n",
      "Gradient for encoder.mean.weight: 0.2811357378959656\n",
      "Gradient for encoder.mean.bias: 0.010745750740170479\n",
      "Gradient for encoder.log_var.weight: 0.1513279676437378\n",
      "Gradient for encoder.log_var.bias: 0.0062903729267418385\n",
      "Gradient for decoder.decoder.0.weight: 0.017973002046346664\n",
      "Gradient for decoder.decoder.0.bias: 1.6475089348322314e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0009393687359988689\n",
      "Gradient for decoder.decoder.1.bias: 0.0006093883421272039\n",
      "Gradient for decoder.decoder.3.weight: 0.014646423049271107\n",
      "Gradient for decoder.decoder.3.bias: 1.2188379472366506e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0005874421913176775\n",
      "Gradient for decoder.decoder.4.bias: 0.0005688972305506468\n",
      "Gradient for decoder.decoder.6.weight: 0.001197352074086666\n",
      "Gradient for decoder.decoder.6.bias: 8.33186277304776e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.06769543886184692\n",
      "Gradient for encoder.encoder.0.bias: 1.1679981981593812e-10\n",
      "Gradient for encoder.encoder.1.weight: 0.01033694762736559\n",
      "Gradient for encoder.encoder.1.bias: 0.007962251082062721\n",
      "Gradient for encoder.encoder.3.weight: 0.22094880044460297\n",
      "Gradient for encoder.encoder.3.bias: 1.1217067275026693e-09\n",
      "Gradient for encoder.encoder.4.weight: 0.01399010606110096\n",
      "Gradient for encoder.encoder.4.bias: 0.014661962166428566\n",
      "Gradient for encoder.mean.weight: 0.1857195645570755\n",
      "Gradient for encoder.mean.bias: 0.01042882353067398\n",
      "Gradient for encoder.log_var.weight: 0.09307152032852173\n",
      "Gradient for encoder.log_var.bias: 0.006357982754707336\n",
      "Gradient for decoder.decoder.0.weight: 0.01992623694241047\n",
      "Gradient for decoder.decoder.0.bias: 1.4731479924812163e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0010020501213148236\n",
      "Gradient for decoder.decoder.1.bias: 0.0007124633993953466\n",
      "Gradient for decoder.decoder.3.weight: 0.01520141214132309\n",
      "Gradient for decoder.decoder.3.bias: 1.0945911538273734e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0005708836833946407\n",
      "Gradient for decoder.decoder.4.bias: 0.0005094280350022018\n",
      "Gradient for decoder.decoder.6.weight: 0.0010412107221782207\n",
      "Gradient for decoder.decoder.6.bias: 4.460176205611788e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.0632638931274414\n",
      "Gradient for encoder.encoder.0.bias: 1.1998911586541539e-10\n",
      "Gradient for encoder.encoder.1.weight: 0.008934952318668365\n",
      "Gradient for encoder.encoder.1.bias: 0.006933019030839205\n",
      "Gradient for encoder.encoder.3.weight: 0.20320408046245575\n",
      "Gradient for encoder.encoder.3.bias: 8.853529021024542e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.013102751225233078\n",
      "Gradient for encoder.encoder.4.bias: 0.012330257333815098\n",
      "Gradient for encoder.mean.weight: 0.161131352186203\n",
      "Gradient for encoder.mean.bias: 0.008893336169421673\n",
      "Gradient for encoder.log_var.weight: 0.08805292099714279\n",
      "Gradient for encoder.log_var.bias: 0.00575792184099555\n",
      "Gradient for decoder.decoder.0.weight: 0.0179368294775486\n",
      "Gradient for decoder.decoder.0.bias: 1.5083308213537094e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.000986871775239706\n",
      "Gradient for decoder.decoder.1.bias: 0.0006331477779895067\n",
      "Gradient for decoder.decoder.3.weight: 0.01413115207105875\n",
      "Gradient for decoder.decoder.3.bias: 1.0899538216424531e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.000558216474018991\n",
      "Gradient for decoder.decoder.4.bias: 0.0005925641162320971\n",
      "Gradient for decoder.decoder.6.weight: 0.00100234046112746\n",
      "Gradient for decoder.decoder.6.bias: 5.827642962685786e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.06967632472515106\n",
      "Gradient for encoder.encoder.0.bias: 1.047788106278702e-10\n",
      "Gradient for encoder.encoder.1.weight: 0.008688454516232014\n",
      "Gradient for encoder.encoder.1.bias: 0.007450890261679888\n",
      "Gradient for encoder.encoder.3.weight: 0.19304750859737396\n",
      "Gradient for encoder.encoder.3.bias: 1.0433134356446772e-09\n",
      "Gradient for encoder.encoder.4.weight: 0.014326349832117558\n",
      "Gradient for encoder.encoder.4.bias: 0.017365146428346634\n",
      "Gradient for encoder.mean.weight: 0.1835692971944809\n",
      "Gradient for encoder.mean.bias: 0.013776645064353943\n",
      "Gradient for encoder.log_var.weight: 0.10192932188510895\n",
      "Gradient for encoder.log_var.bias: 0.007456176448613405\n",
      "Gradient for decoder.decoder.0.weight: 0.018405288457870483\n",
      "Gradient for decoder.decoder.0.bias: 1.4524383085134929e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0009848137851804495\n",
      "Gradient for decoder.decoder.1.bias: 0.0006776374648325145\n",
      "Gradient for decoder.decoder.3.weight: 0.014351642690598965\n",
      "Gradient for decoder.decoder.3.bias: 1.038102173667177e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0005218394799157977\n",
      "Gradient for decoder.decoder.4.bias: 0.0004633144708350301\n",
      "Gradient for decoder.decoder.6.weight: 0.0012202999787405133\n",
      "Gradient for decoder.decoder.6.bias: 8.823691314319149e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.059239745140075684\n",
      "Gradient for encoder.encoder.0.bias: 1.0039036962838921e-10\n",
      "Gradient for encoder.encoder.1.weight: 0.008054986596107483\n",
      "Gradient for encoder.encoder.1.bias: 0.006350183393806219\n",
      "Gradient for encoder.encoder.3.weight: 0.1741744726896286\n",
      "Gradient for encoder.encoder.3.bias: 8.572854648392081e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.012384939007461071\n",
      "Gradient for encoder.encoder.4.bias: 0.012488985434174538\n",
      "Gradient for encoder.mean.weight: 0.16328001022338867\n",
      "Gradient for encoder.mean.bias: 0.01008072029799223\n",
      "Gradient for encoder.log_var.weight: 0.08595864474773407\n",
      "Gradient for encoder.log_var.bias: 0.005156374536454678\n",
      "Gradient for decoder.decoder.0.weight: 0.017578793689608574\n",
      "Gradient for decoder.decoder.0.bias: 1.4363070455214455e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0009300477686338127\n",
      "Gradient for decoder.decoder.1.bias: 0.0005882089026272297\n",
      "Gradient for decoder.decoder.3.weight: 0.013343805447220802\n",
      "Gradient for decoder.decoder.3.bias: 1.0506404773957811e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0005180328735150397\n",
      "Gradient for decoder.decoder.4.bias: 0.0005292070563882589\n",
      "Gradient for decoder.decoder.6.weight: 0.001027638209052384\n",
      "Gradient for decoder.decoder.6.bias: 5.3299580031307414e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.07934344559907913\n",
      "Gradient for encoder.encoder.0.bias: 1.1791179144182706e-10\n",
      "Gradient for encoder.encoder.1.weight: 0.008803201839327812\n",
      "Gradient for encoder.encoder.1.bias: 0.007386944722384214\n",
      "Gradient for encoder.encoder.3.weight: 0.19497188925743103\n",
      "Gradient for encoder.encoder.3.bias: 1.2482708200423076e-09\n",
      "Gradient for encoder.encoder.4.weight: 0.015350786969065666\n",
      "Gradient for encoder.encoder.4.bias: 0.014323723502457142\n",
      "Gradient for encoder.mean.weight: 0.18259912729263306\n",
      "Gradient for encoder.mean.bias: 0.010069689713418484\n",
      "Gradient for encoder.log_var.weight: 0.09516804665327072\n",
      "Gradient for encoder.log_var.bias: 0.006218107417225838\n",
      "Gradient for decoder.decoder.0.weight: 0.019784508273005486\n",
      "Gradient for decoder.decoder.0.bias: 1.5570038314205448e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.001017336966469884\n",
      "Gradient for decoder.decoder.1.bias: 0.0007030029082670808\n",
      "Gradient for decoder.decoder.3.weight: 0.015521466732025146\n",
      "Gradient for decoder.decoder.3.bias: 1.0738737676874166e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0005661549512296915\n",
      "Gradient for decoder.decoder.4.bias: 0.0005075337248854339\n",
      "Gradient for decoder.decoder.6.weight: 0.0010665575973689556\n",
      "Gradient for decoder.decoder.6.bias: 5.558642078540288e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.06612268090248108\n",
      "Gradient for encoder.encoder.0.bias: 1.2196134380193513e-10\n",
      "Gradient for encoder.encoder.1.weight: 0.011053559370338917\n",
      "Gradient for encoder.encoder.1.bias: 0.008759886026382446\n",
      "Gradient for encoder.encoder.3.weight: 0.24223926663398743\n",
      "Gradient for encoder.encoder.3.bias: 1.3728225223275103e-09\n",
      "Gradient for encoder.encoder.4.weight: 0.015338665805757046\n",
      "Gradient for encoder.encoder.4.bias: 0.016003772616386414\n",
      "Gradient for encoder.mean.weight: 0.1987116038799286\n",
      "Gradient for encoder.mean.bias: 0.011613141745328903\n",
      "Gradient for encoder.log_var.weight: 0.10470125079154968\n",
      "Gradient for encoder.log_var.bias: 0.006245230324566364\n",
      "Gradient for decoder.decoder.0.weight: 0.01895529218018055\n",
      "Gradient for decoder.decoder.0.bias: 1.631901558329929e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0010900666238740087\n",
      "Gradient for decoder.decoder.1.bias: 0.0007039004121907055\n",
      "Gradient for decoder.decoder.3.weight: 0.0151139535009861\n",
      "Gradient for decoder.decoder.3.bias: 1.164857932334229e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0006231668521650136\n",
      "Gradient for decoder.decoder.4.bias: 0.0006331965560093522\n",
      "Gradient for decoder.decoder.6.weight: 0.0010909787379205227\n",
      "Gradient for decoder.decoder.6.bias: 6.010293873259798e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.07836373150348663\n",
      "Gradient for encoder.encoder.0.bias: 1.2386215664239586e-10\n",
      "Gradient for encoder.encoder.1.weight: 0.009774154983460903\n",
      "Gradient for encoder.encoder.1.bias: 0.00840122252702713\n",
      "Gradient for encoder.encoder.3.weight: 0.21386103332042694\n",
      "Gradient for encoder.encoder.3.bias: 1.6755383747124597e-09\n",
      "Gradient for encoder.encoder.4.weight: 0.026575084775686264\n",
      "Gradient for encoder.encoder.4.bias: 0.029587745666503906\n",
      "Gradient for encoder.mean.weight: 0.34023070335388184\n",
      "Gradient for encoder.mean.bias: 0.021123843267560005\n",
      "Gradient for encoder.log_var.weight: 0.20079436898231506\n",
      "Gradient for encoder.log_var.bias: 0.012179209850728512\n",
      "Gradient for decoder.decoder.0.weight: 0.019911164417862892\n",
      "Gradient for decoder.decoder.0.bias: 1.7104954952440465e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.001140571548603475\n",
      "Gradient for decoder.decoder.1.bias: 0.0007045944803394377\n",
      "Gradient for decoder.decoder.3.weight: 0.015642834827303886\n",
      "Gradient for decoder.decoder.3.bias: 1.2743173183338286e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0005928532918915153\n",
      "Gradient for decoder.decoder.4.bias: 0.0006196568137966096\n",
      "Gradient for decoder.decoder.6.weight: 0.0010665023000910878\n",
      "Gradient for decoder.decoder.6.bias: 5.740777123719454e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.06329970061779022\n",
      "Gradient for encoder.encoder.0.bias: 1.0649464643464057e-10\n",
      "Gradient for encoder.encoder.1.weight: 0.006852539721876383\n",
      "Gradient for encoder.encoder.1.bias: 0.005677811335772276\n",
      "Gradient for encoder.encoder.3.weight: 0.15031985938549042\n",
      "Gradient for encoder.encoder.3.bias: 1.0547491768875261e-09\n",
      "Gradient for encoder.encoder.4.weight: 0.011449088342487812\n",
      "Gradient for encoder.encoder.4.bias: 0.01190897822380066\n",
      "Gradient for encoder.mean.weight: 0.14884601533412933\n",
      "Gradient for encoder.mean.bias: 0.009042550809681416\n",
      "Gradient for encoder.log_var.weight: 0.08540961891412735\n",
      "Gradient for encoder.log_var.bias: 0.004847546573728323\n",
      "Gradient for decoder.decoder.0.weight: 0.01820029877126217\n",
      "Gradient for decoder.decoder.0.bias: 1.5287782151318652e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.000941820559091866\n",
      "Gradient for decoder.decoder.1.bias: 0.0006522157345898449\n",
      "Gradient for decoder.decoder.3.weight: 0.014274753630161285\n",
      "Gradient for decoder.decoder.3.bias: 1.1239437158749865e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0005470109754242003\n",
      "Gradient for decoder.decoder.4.bias: 0.0005723246722482145\n",
      "Gradient for decoder.decoder.6.weight: 0.0010315264808014035\n",
      "Gradient for decoder.decoder.6.bias: 6.252893945202231e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training VAE Epoch:  82%|████████▏ | 65/79 [00:01<00:00, 76.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient for encoder.encoder.0.weight: 0.07381445169448853\n",
      "Gradient for encoder.encoder.0.bias: 1.2078835154305523e-10\n",
      "Gradient for encoder.encoder.1.weight: 0.009907116182148457\n",
      "Gradient for encoder.encoder.1.bias: 0.007799605373293161\n",
      "Gradient for encoder.encoder.3.weight: 0.21739274263381958\n",
      "Gradient for encoder.encoder.3.bias: 1.2588196041107835e-09\n",
      "Gradient for encoder.encoder.4.weight: 0.01559187937527895\n",
      "Gradient for encoder.encoder.4.bias: 0.01594145968556404\n",
      "Gradient for encoder.mean.weight: 0.20473706722259521\n",
      "Gradient for encoder.mean.bias: 0.011220837943255901\n",
      "Gradient for encoder.log_var.weight: 0.10777853429317474\n",
      "Gradient for encoder.log_var.bias: 0.006800324656069279\n",
      "Gradient for decoder.decoder.0.weight: 0.017748622223734856\n",
      "Gradient for decoder.decoder.0.bias: 1.471588129131618e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0009279123041778803\n",
      "Gradient for decoder.decoder.1.bias: 0.0006279379012994468\n",
      "Gradient for decoder.decoder.3.weight: 0.014113426208496094\n",
      "Gradient for decoder.decoder.3.bias: 1.2978361441096098e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0009391875937581062\n",
      "Gradient for decoder.decoder.4.bias: 0.0011299847392365336\n",
      "Gradient for decoder.decoder.6.weight: 0.0013140678638592362\n",
      "Gradient for decoder.decoder.6.bias: 0.00011164954048581421\n",
      "Gradient for encoder.encoder.0.weight: 0.06864514201879501\n",
      "Gradient for encoder.encoder.0.bias: 1.2113610114994344e-10\n",
      "Gradient for encoder.encoder.1.weight: 0.0075119840912520885\n",
      "Gradient for encoder.encoder.1.bias: 0.006291170138865709\n",
      "Gradient for encoder.encoder.3.weight: 0.16822513937950134\n",
      "Gradient for encoder.encoder.3.bias: 1.1034611002713746e-09\n",
      "Gradient for encoder.encoder.4.weight: 0.012577221728861332\n",
      "Gradient for encoder.encoder.4.bias: 0.012760440818965435\n",
      "Gradient for encoder.mean.weight: 0.16288317739963531\n",
      "Gradient for encoder.mean.bias: 0.009778400883078575\n",
      "Gradient for encoder.log_var.weight: 0.08651124686002731\n",
      "Gradient for encoder.log_var.bias: 0.0058043538592755795\n",
      "Gradient for decoder.decoder.0.weight: 0.0192152950912714\n",
      "Gradient for decoder.decoder.0.bias: 1.5629522676086083e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0010675773955881596\n",
      "Gradient for decoder.decoder.1.bias: 0.0006987564847804606\n",
      "Gradient for decoder.decoder.3.weight: 0.01508587971329689\n",
      "Gradient for decoder.decoder.3.bias: 1.2244247282744425e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0008389815920963883\n",
      "Gradient for decoder.decoder.4.bias: 0.000853963487315923\n",
      "Gradient for decoder.decoder.6.weight: 0.0012105369241908193\n",
      "Gradient for decoder.decoder.6.bias: 7.773716060910374e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training VAE Epoch:  94%|█████████▎| 74/79 [00:01<00:00, 77.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient for encoder.encoder.0.weight: 0.05625304952263832\n",
      "Gradient for encoder.encoder.0.bias: 9.7928588849161e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.007032443303614855\n",
      "Gradient for encoder.encoder.1.bias: 0.005764964502304792\n",
      "Gradient for encoder.encoder.3.weight: 0.15420305728912354\n",
      "Gradient for encoder.encoder.3.bias: 1.234089830326468e-09\n",
      "Gradient for encoder.encoder.4.weight: 0.013536442071199417\n",
      "Gradient for encoder.encoder.4.bias: 0.0122105423361063\n",
      "Gradient for encoder.mean.weight: 0.16760623455047607\n",
      "Gradient for encoder.mean.bias: 0.009135391563177109\n",
      "Gradient for encoder.log_var.weight: 0.0837426409125328\n",
      "Gradient for encoder.log_var.bias: 0.005513036623597145\n",
      "Gradient for decoder.decoder.0.weight: 0.02046908065676689\n",
      "Gradient for decoder.decoder.0.bias: 1.829992268831404e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0011325892992317677\n",
      "Gradient for decoder.decoder.1.bias: 0.0007364169578067958\n",
      "Gradient for decoder.decoder.3.weight: 0.016000639647245407\n",
      "Gradient for decoder.decoder.3.bias: 1.2250847558625821e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0007159421220421791\n",
      "Gradient for decoder.decoder.4.bias: 0.0005881731049157679\n",
      "Gradient for decoder.decoder.6.weight: 0.0011022078106179833\n",
      "Gradient for decoder.decoder.6.bias: 5.2222141675883904e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.05995588377118111\n",
      "Gradient for encoder.encoder.0.bias: 9.618342927675272e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.008820131421089172\n",
      "Gradient for encoder.encoder.1.bias: 0.006707353517413139\n",
      "Gradient for encoder.encoder.3.weight: 0.18487653136253357\n",
      "Gradient for encoder.encoder.3.bias: 1.0529624949739969e-09\n",
      "Gradient for encoder.encoder.4.weight: 0.01330539956688881\n",
      "Gradient for encoder.encoder.4.bias: 0.011808518320322037\n",
      "Gradient for encoder.mean.weight: 0.16866347193717957\n",
      "Gradient for encoder.mean.bias: 0.008589614182710648\n",
      "Gradient for encoder.log_var.weight: 0.07735691964626312\n",
      "Gradient for encoder.log_var.bias: 0.004118377808481455\n",
      "Gradient for decoder.decoder.0.weight: 0.01908167079091072\n",
      "Gradient for decoder.decoder.0.bias: 1.6255469192927308e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0010339448926970363\n",
      "Gradient for decoder.decoder.1.bias: 0.0007194507052190602\n",
      "Gradient for decoder.decoder.3.weight: 0.01503544021397829\n",
      "Gradient for decoder.decoder.3.bias: 1.1218563578108132e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0006140944897197187\n",
      "Gradient for decoder.decoder.4.bias: 0.0006260337540879846\n",
      "Gradient for decoder.decoder.6.weight: 0.0010501263896003366\n",
      "Gradient for decoder.decoder.6.bias: 5.7555142120691016e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.07069330662488937\n",
      "Gradient for encoder.encoder.0.bias: 1.1990862469613006e-10\n",
      "Gradient for encoder.encoder.1.weight: 0.010724565014243126\n",
      "Gradient for encoder.encoder.1.bias: 0.00805150717496872\n",
      "Gradient for encoder.encoder.3.weight: 0.23099596798419952\n",
      "Gradient for encoder.encoder.3.bias: 1.08950215516046e-09\n",
      "Gradient for encoder.encoder.4.weight: 0.016385864466428757\n",
      "Gradient for encoder.encoder.4.bias: 0.01512819528579712\n",
      "Gradient for encoder.mean.weight: 0.2220592498779297\n",
      "Gradient for encoder.mean.bias: 0.010392079129815102\n",
      "Gradient for encoder.log_var.weight: 0.10798055678606033\n",
      "Gradient for encoder.log_var.bias: 0.005001595709472895\n",
      "Gradient for decoder.decoder.0.weight: 0.017452456057071686\n",
      "Gradient for decoder.decoder.0.bias: 1.4629636391205736e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0009372665663249791\n",
      "Gradient for decoder.decoder.1.bias: 0.0006690458976663649\n",
      "Gradient for decoder.decoder.3.weight: 0.01344472635537386\n",
      "Gradient for decoder.decoder.3.bias: 1.0019435975339164e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.00047856030869297683\n",
      "Gradient for decoder.decoder.4.bias: 0.00045143975876271725\n",
      "Gradient for decoder.decoder.6.weight: 0.0009900423465296626\n",
      "Gradient for decoder.decoder.6.bias: 4.772102693095803e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.07168058305978775\n",
      "Gradient for encoder.encoder.0.bias: 1.2960159334607368e-10\n",
      "Gradient for encoder.encoder.1.weight: 0.007806079927831888\n",
      "Gradient for encoder.encoder.1.bias: 0.006192699074745178\n",
      "Gradient for encoder.encoder.3.weight: 0.17014962434768677\n",
      "Gradient for encoder.encoder.3.bias: 9.63924939867411e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.011229058727622032\n",
      "Gradient for encoder.encoder.4.bias: 0.011286641471087933\n",
      "Gradient for encoder.mean.weight: 0.14995013177394867\n",
      "Gradient for encoder.mean.bias: 0.007985652424395084\n",
      "Gradient for encoder.log_var.weight: 0.07216297835111618\n",
      "Gradient for encoder.log_var.bias: 0.005046322476118803\n",
      "Gradient for decoder.decoder.0.weight: 0.015270610339939594\n",
      "Gradient for decoder.decoder.0.bias: 1.3739180626526348e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0007437137537635863\n",
      "Gradient for decoder.decoder.1.bias: 0.0005096406093798578\n",
      "Gradient for decoder.decoder.3.weight: 0.01126148272305727\n",
      "Gradient for decoder.decoder.3.bias: 1.0555625123975787e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0004894062294624746\n",
      "Gradient for decoder.decoder.4.bias: 0.0005183658795431256\n",
      "Gradient for decoder.decoder.6.weight: 0.0010117929195985198\n",
      "Gradient for decoder.decoder.6.bias: 6.062098691472784e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.07834433019161224\n",
      "Gradient for encoder.encoder.0.bias: 1.215029465928552e-10\n",
      "Gradient for encoder.encoder.1.weight: 0.011303011327981949\n",
      "Gradient for encoder.encoder.1.bias: 0.008963570930063725\n",
      "Gradient for encoder.encoder.3.weight: 0.25023218989372253\n",
      "Gradient for encoder.encoder.3.bias: 1.6073409270234151e-09\n",
      "Gradient for encoder.encoder.4.weight: 0.02251334860920906\n",
      "Gradient for encoder.encoder.4.bias: 0.017495103180408478\n",
      "Gradient for encoder.mean.weight: 0.26851940155029297\n",
      "Gradient for encoder.mean.bias: 0.009037882089614868\n",
      "Gradient for encoder.log_var.weight: 0.1403118520975113\n",
      "Gradient for encoder.log_var.bias: 0.004535069223493338\n",
      "Gradient for decoder.decoder.0.weight: 0.020093506202101707\n",
      "Gradient for decoder.decoder.0.bias: 1.7745507840949415e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.001053310465067625\n",
      "Gradient for decoder.decoder.1.bias: 0.000725440273527056\n",
      "Gradient for decoder.decoder.3.weight: 0.015844153240323067\n",
      "Gradient for decoder.decoder.3.bias: 1.285491990632437e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0006534738349728286\n",
      "Gradient for decoder.decoder.4.bias: 0.0006926304195076227\n",
      "Gradient for decoder.decoder.6.weight: 0.0010798784205690026\n",
      "Gradient for decoder.decoder.6.bias: 6.304465932771564e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.08777996152639389\n",
      "Gradient for encoder.encoder.0.bias: 1.38143912975508e-10\n",
      "Gradient for encoder.encoder.1.weight: 0.012514336034655571\n",
      "Gradient for encoder.encoder.1.bias: 0.0092014716938138\n",
      "Gradient for encoder.encoder.3.weight: 0.2716098427772522\n",
      "Gradient for encoder.encoder.3.bias: 1.5487385818246935e-09\n",
      "Gradient for encoder.encoder.4.weight: 0.021724626421928406\n",
      "Gradient for encoder.encoder.4.bias: 0.021053792908787727\n",
      "Gradient for encoder.mean.weight: 0.2638348937034607\n",
      "Gradient for encoder.mean.bias: 0.014155280776321888\n",
      "Gradient for encoder.log_var.weight: 0.13814477622509003\n",
      "Gradient for encoder.log_var.bias: 0.008701016195118427\n",
      "Gradient for decoder.decoder.0.weight: 0.018694894388318062\n",
      "Gradient for decoder.decoder.0.bias: 1.4243395352053767e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.001040702685713768\n",
      "Gradient for decoder.decoder.1.bias: 0.0007215727819129825\n",
      "Gradient for decoder.decoder.3.weight: 0.015004264190793037\n",
      "Gradient for decoder.decoder.3.bias: 9.730816152853095e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0005184141919016838\n",
      "Gradient for decoder.decoder.4.bias: 0.00044484148384071887\n",
      "Gradient for decoder.decoder.6.weight: 0.0010260777780786157\n",
      "Gradient for decoder.decoder.6.bias: 5.760157364420593e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.06346445530653\n",
      "Gradient for encoder.encoder.0.bias: 1.0361237562372949e-10\n",
      "Gradient for encoder.encoder.1.weight: 0.0075918808579444885\n",
      "Gradient for encoder.encoder.1.bias: 0.006457034032791853\n",
      "Gradient for encoder.encoder.3.weight: 0.17011764645576477\n",
      "Gradient for encoder.encoder.3.bias: 1.0988193688277192e-09\n",
      "Gradient for encoder.encoder.4.weight: 0.01291700080037117\n",
      "Gradient for encoder.encoder.4.bias: 0.012894083745777607\n",
      "Gradient for encoder.mean.weight: 0.16171415150165558\n",
      "Gradient for encoder.mean.bias: 0.01055943127721548\n",
      "Gradient for encoder.log_var.weight: 0.09359490126371384\n",
      "Gradient for encoder.log_var.bias: 0.006764140911400318\n",
      "Gradient for decoder.decoder.0.weight: 0.01922513358294964\n",
      "Gradient for decoder.decoder.0.bias: 1.5822462784420566e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.001018889481201768\n",
      "Gradient for decoder.decoder.1.bias: 0.0007074539898894727\n",
      "Gradient for decoder.decoder.3.weight: 0.014740674756467342\n",
      "Gradient for decoder.decoder.3.bias: 1.0970479386029908e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0005320454947650433\n",
      "Gradient for decoder.decoder.4.bias: 0.00047302868915721774\n",
      "Gradient for decoder.decoder.6.weight: 0.0010903534712269902\n",
      "Gradient for decoder.decoder.6.bias: 5.675457578036003e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.06458896398544312\n",
      "Gradient for encoder.encoder.0.bias: 9.323084665391335e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.007670584600418806\n",
      "Gradient for encoder.encoder.1.bias: 0.006102275103330612\n",
      "Gradient for encoder.encoder.3.weight: 0.1646672785282135\n",
      "Gradient for encoder.encoder.3.bias: 9.83435888279871e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.01119624450802803\n",
      "Gradient for encoder.encoder.4.bias: 0.01092361006885767\n",
      "Gradient for encoder.mean.weight: 0.15007835626602173\n",
      "Gradient for encoder.mean.bias: 0.007613498251885176\n",
      "Gradient for encoder.log_var.weight: 0.08253957331180573\n",
      "Gradient for encoder.log_var.bias: 0.005325136240571737\n",
      "Gradient for decoder.decoder.0.weight: 0.01815319061279297\n",
      "Gradient for decoder.decoder.0.bias: 1.5345483217465983e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0009858310222625732\n",
      "Gradient for decoder.decoder.1.bias: 0.0006631230935454369\n",
      "Gradient for decoder.decoder.3.weight: 0.014365090057253838\n",
      "Gradient for decoder.decoder.3.bias: 1.0508483666571422e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0005151397199369967\n",
      "Gradient for decoder.decoder.4.bias: 0.0004585578863043338\n",
      "Gradient for decoder.decoder.6.weight: 0.001036385539919138\n",
      "Gradient for decoder.decoder.6.bias: 4.5884928113082424e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.08014698326587677\n",
      "Gradient for encoder.encoder.0.bias: 1.3025204526062595e-10\n",
      "Gradient for encoder.encoder.1.weight: 0.009637675248086452\n",
      "Gradient for encoder.encoder.1.bias: 0.007295838091522455\n",
      "Gradient for encoder.encoder.3.weight: 0.20784641802310944\n",
      "Gradient for encoder.encoder.3.bias: 1.1290642865091627e-09\n",
      "Gradient for encoder.encoder.4.weight: 0.015017746016383171\n",
      "Gradient for encoder.encoder.4.bias: 0.015261356718838215\n",
      "Gradient for encoder.mean.weight: 0.19827061891555786\n",
      "Gradient for encoder.mean.bias: 0.011139458045363426\n",
      "Gradient for encoder.log_var.weight: 0.10897354781627655\n",
      "Gradient for encoder.log_var.bias: 0.006599180866032839\n",
      "Gradient for decoder.decoder.0.weight: 0.017522864043712616\n",
      "Gradient for decoder.decoder.0.bias: 1.6735567098802306e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0009267072891816497\n",
      "Gradient for decoder.decoder.1.bias: 0.0006052799872122705\n",
      "Gradient for decoder.decoder.3.weight: 0.013762015849351883\n",
      "Gradient for decoder.decoder.3.bias: 1.2246136049665068e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0005070776678621769\n",
      "Gradient for decoder.decoder.4.bias: 0.000505093252286315\n",
      "Gradient for decoder.decoder.6.weight: 0.0011789045529440045\n",
      "Gradient for decoder.decoder.6.bias: 8.537535177310929e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.06530795246362686\n",
      "Gradient for encoder.encoder.0.bias: 1.1090774826305605e-10\n",
      "Gradient for encoder.encoder.1.weight: 0.008079245686531067\n",
      "Gradient for encoder.encoder.1.bias: 0.006492833141237497\n",
      "Gradient for encoder.encoder.3.weight: 0.17221331596374512\n",
      "Gradient for encoder.encoder.3.bias: 1.0411320694458936e-09\n",
      "Gradient for encoder.encoder.4.weight: 0.014752686023712158\n",
      "Gradient for encoder.encoder.4.bias: 0.012574778869748116\n",
      "Gradient for encoder.mean.weight: 0.17386426031589508\n",
      "Gradient for encoder.mean.bias: 0.007938586175441742\n",
      "Gradient for encoder.log_var.weight: 0.100606270134449\n",
      "Gradient for encoder.log_var.bias: 0.004362188745290041\n",
      "Gradient for decoder.decoder.0.weight: 0.019696736708283424\n",
      "Gradient for decoder.decoder.0.bias: 1.7261556073400186e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.001012875116430223\n",
      "Gradient for decoder.decoder.1.bias: 0.0007157743675634265\n",
      "Gradient for decoder.decoder.3.weight: 0.014993435703217983\n",
      "Gradient for decoder.decoder.3.bias: 1.2322688702770535e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0006105851498432457\n",
      "Gradient for decoder.decoder.4.bias: 0.0006324125570245087\n",
      "Gradient for decoder.decoder.6.weight: 0.0011030000168830156\n",
      "Gradient for decoder.decoder.6.bias: 6.942525942577049e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.057048626244068146\n",
      "Gradient for encoder.encoder.0.bias: 9.694689495631792e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.006510238628834486\n",
      "Gradient for encoder.encoder.1.bias: 0.0053897094912827015\n",
      "Gradient for encoder.encoder.3.weight: 0.1372087150812149\n",
      "Gradient for encoder.encoder.3.bias: 1.0226907098953575e-09\n",
      "Gradient for encoder.encoder.4.weight: 0.011347845196723938\n",
      "Gradient for encoder.encoder.4.bias: 0.011047964915633202\n",
      "Gradient for encoder.mean.weight: 0.14370785653591156\n",
      "Gradient for encoder.mean.bias: 0.008393000811338425\n",
      "Gradient for encoder.log_var.weight: 0.08094514161348343\n",
      "Gradient for encoder.log_var.bias: 0.005666152574121952\n",
      "Gradient for decoder.decoder.0.weight: 0.019679758697748184\n",
      "Gradient for decoder.decoder.0.bias: 1.5794388019685357e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.000981910852715373\n",
      "Gradient for decoder.decoder.1.bias: 0.0007388602825812995\n",
      "Gradient for decoder.decoder.3.weight: 0.015065456740558147\n",
      "Gradient for decoder.decoder.3.bias: 1.2397761983695688e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0006043789908289909\n",
      "Gradient for decoder.decoder.4.bias: 0.0005698205786757171\n",
      "Gradient for decoder.decoder.6.weight: 0.0010215118527412415\n",
      "Gradient for decoder.decoder.6.bias: 4.933459058520384e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.08446900546550751\n",
      "Gradient for encoder.encoder.0.bias: 1.3330915538123378e-10\n",
      "Gradient for encoder.encoder.1.weight: 0.010511958971619606\n",
      "Gradient for encoder.encoder.1.bias: 0.007556882221251726\n",
      "Gradient for encoder.encoder.3.weight: 0.22645021975040436\n",
      "Gradient for encoder.encoder.3.bias: 1.32138378017288e-09\n",
      "Gradient for encoder.encoder.4.weight: 0.019701499491930008\n",
      "Gradient for encoder.encoder.4.bias: 0.015335896983742714\n",
      "Gradient for encoder.mean.weight: 0.22263272106647491\n",
      "Gradient for encoder.mean.bias: 0.009317779913544655\n",
      "Gradient for encoder.log_var.weight: 0.12933795154094696\n",
      "Gradient for encoder.log_var.bias: 0.0056606922298669815\n",
      "Gradient for decoder.decoder.0.weight: 0.019949426874518394\n",
      "Gradient for decoder.decoder.0.bias: 1.8897242104465306e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0010507662082090974\n",
      "Gradient for decoder.decoder.1.bias: 0.0007318695425055921\n",
      "Gradient for decoder.decoder.3.weight: 0.015291430056095123\n",
      "Gradient for decoder.decoder.3.bias: 1.5499297678633894e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0006791998166590929\n",
      "Gradient for decoder.decoder.4.bias: 0.000754989858251065\n",
      "Gradient for decoder.decoder.6.weight: 0.0012548193335533142\n",
      "Gradient for decoder.decoder.6.bias: 9.639946074457839e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.08868956565856934\n",
      "Gradient for encoder.encoder.0.bias: 1.1161276070037474e-10\n",
      "Gradient for encoder.encoder.1.weight: 0.015317198820412159\n",
      "Gradient for encoder.encoder.1.bias: 0.011232184246182442\n",
      "Gradient for encoder.encoder.3.weight: 0.31450995802879333\n",
      "Gradient for encoder.encoder.3.bias: 3.5297866851635717e-09\n",
      "Gradient for encoder.encoder.4.weight: 0.031734805554151535\n",
      "Gradient for encoder.encoder.4.bias: 0.03319186717271805\n",
      "Gradient for encoder.mean.weight: 0.3867388367652893\n",
      "Gradient for encoder.mean.bias: 0.025949673727154732\n",
      "Gradient for encoder.log_var.weight: 0.21749460697174072\n",
      "Gradient for encoder.log_var.bias: 0.014598412439227104\n",
      "Gradient for decoder.decoder.0.weight: 0.07548313587903976\n",
      "Gradient for decoder.decoder.0.bias: 4.626461991286135e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0035842040088027716\n",
      "Gradient for decoder.decoder.1.bias: 0.002615774981677532\n",
      "Gradient for decoder.decoder.3.weight: 0.059418655931949615\n",
      "Gradient for decoder.decoder.3.bias: 3.3749048000686344e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.002017972059547901\n",
      "Gradient for decoder.decoder.4.bias: 0.001695912447758019\n",
      "Gradient for decoder.decoder.6.weight: 0.0028290655463933945\n",
      "Gradient for decoder.decoder.6.bias: 0.00010795904381666332\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/3, Train Loss: 0.1295, Val Loss: 0.3636\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training VAE Epoch:   1%|▏         | 1/79 [00:00<00:14,  5.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient for encoder.encoder.0.weight: 0.0757203996181488\n",
      "Gradient for encoder.encoder.0.bias: 1.2394316128983007e-10\n",
      "Gradient for encoder.encoder.1.weight: 0.012562472373247147\n",
      "Gradient for encoder.encoder.1.bias: 0.008794283494353294\n",
      "Gradient for encoder.encoder.3.weight: 0.27961575984954834\n",
      "Gradient for encoder.encoder.3.bias: 1.12140108310399e-09\n",
      "Gradient for encoder.encoder.4.weight: 0.0209676343947649\n",
      "Gradient for encoder.encoder.4.bias: 0.016591720283031464\n",
      "Gradient for encoder.mean.weight: 0.25919485092163086\n",
      "Gradient for encoder.mean.bias: 0.008945452980697155\n",
      "Gradient for encoder.log_var.weight: 0.13094571232795715\n",
      "Gradient for encoder.log_var.bias: 0.005085061304271221\n",
      "Gradient for decoder.decoder.0.weight: 0.01841452717781067\n",
      "Gradient for decoder.decoder.0.bias: 1.527465515183124e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.000977777410298586\n",
      "Gradient for decoder.decoder.1.bias: 0.000652370392344892\n",
      "Gradient for decoder.decoder.3.weight: 0.01442198920994997\n",
      "Gradient for decoder.decoder.3.bias: 1.0781176645879853e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0005573958624154329\n",
      "Gradient for decoder.decoder.4.bias: 0.0005222226609475911\n",
      "Gradient for decoder.decoder.6.weight: 0.0010708122281357646\n",
      "Gradient for decoder.decoder.6.bias: 6.074544944567606e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.07648786157369614\n",
      "Gradient for encoder.encoder.0.bias: 1.330916626907097e-10\n",
      "Gradient for encoder.encoder.1.weight: 0.010828257538378239\n",
      "Gradient for encoder.encoder.1.bias: 0.008148197084665298\n",
      "Gradient for encoder.encoder.3.weight: 0.24498282372951508\n",
      "Gradient for encoder.encoder.3.bias: 1.2904297630456085e-09\n",
      "Gradient for encoder.encoder.4.weight: 0.022735916078090668\n",
      "Gradient for encoder.encoder.4.bias: 0.017176553606987\n",
      "Gradient for encoder.mean.weight: 0.2679234445095062\n",
      "Gradient for encoder.mean.bias: 0.012598934583365917\n",
      "Gradient for encoder.log_var.weight: 0.14175072312355042\n",
      "Gradient for encoder.log_var.bias: 0.007255458272993565\n",
      "Gradient for decoder.decoder.0.weight: 0.017664553597569466\n",
      "Gradient for decoder.decoder.0.bias: 1.5563408894969655e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0009447164484299719\n",
      "Gradient for decoder.decoder.1.bias: 0.0006527425721287727\n",
      "Gradient for decoder.decoder.3.weight: 0.013667861931025982\n",
      "Gradient for decoder.decoder.3.bias: 1.1358401719174793e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0005032875342294574\n",
      "Gradient for decoder.decoder.4.bias: 0.0004451519052963704\n",
      "Gradient for decoder.decoder.6.weight: 0.0010092693846672773\n",
      "Gradient for decoder.decoder.6.bias: 4.828761666431092e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training VAE Epoch:  11%|█▏        | 9/79 [00:00<00:01, 37.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient for encoder.encoder.0.weight: 0.07158888876438141\n",
      "Gradient for encoder.encoder.0.bias: 1.1900080920668188e-10\n",
      "Gradient for encoder.encoder.1.weight: 0.009730651043355465\n",
      "Gradient for encoder.encoder.1.bias: 0.007421074900776148\n",
      "Gradient for encoder.encoder.3.weight: 0.21244211494922638\n",
      "Gradient for encoder.encoder.3.bias: 1.1867226090700456e-09\n",
      "Gradient for encoder.encoder.4.weight: 0.017875075340270996\n",
      "Gradient for encoder.encoder.4.bias: 0.01465730182826519\n",
      "Gradient for encoder.mean.weight: 0.21921613812446594\n",
      "Gradient for encoder.mean.bias: 0.009584298357367516\n",
      "Gradient for encoder.log_var.weight: 0.11534126847982407\n",
      "Gradient for encoder.log_var.bias: 0.00537350308150053\n",
      "Gradient for decoder.decoder.0.weight: 0.01742398738861084\n",
      "Gradient for decoder.decoder.0.bias: 1.4932120817601202e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0009765741415321827\n",
      "Gradient for decoder.decoder.1.bias: 0.0006091570248827338\n",
      "Gradient for decoder.decoder.3.weight: 0.013628431595861912\n",
      "Gradient for decoder.decoder.3.bias: 1.1139848071772818e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.000595953140873462\n",
      "Gradient for decoder.decoder.4.bias: 0.0005601196317002177\n",
      "Gradient for decoder.decoder.6.weight: 0.0011671019019559026\n",
      "Gradient for decoder.decoder.6.bias: 7.46476580388844e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.06525290757417679\n",
      "Gradient for encoder.encoder.0.bias: 1.1172437974771299e-10\n",
      "Gradient for encoder.encoder.1.weight: 0.008435457944869995\n",
      "Gradient for encoder.encoder.1.bias: 0.006437873002141714\n",
      "Gradient for encoder.encoder.3.weight: 0.17897270619869232\n",
      "Gradient for encoder.encoder.3.bias: 8.080490720985267e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.010968921706080437\n",
      "Gradient for encoder.encoder.4.bias: 0.009117328561842442\n",
      "Gradient for encoder.mean.weight: 0.15313906967639923\n",
      "Gradient for encoder.mean.bias: 0.007022893521934748\n",
      "Gradient for encoder.log_var.weight: 0.07262392342090607\n",
      "Gradient for encoder.log_var.bias: 0.0036139690782874823\n",
      "Gradient for decoder.decoder.0.weight: 0.018022779375314713\n",
      "Gradient for decoder.decoder.0.bias: 1.3228712569812728e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0009838651167228818\n",
      "Gradient for decoder.decoder.1.bias: 0.0006786612793803215\n",
      "Gradient for decoder.decoder.3.weight: 0.014151697047054768\n",
      "Gradient for decoder.decoder.3.bias: 1.2041433128384682e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0007006097584962845\n",
      "Gradient for decoder.decoder.4.bias: 0.0007876056479290128\n",
      "Gradient for decoder.decoder.6.weight: 0.0011547728208824992\n",
      "Gradient for decoder.decoder.6.bias: 8.51324075483717e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.08974584937095642\n",
      "Gradient for encoder.encoder.0.bias: 1.3609739724085301e-10\n",
      "Gradient for encoder.encoder.1.weight: 0.012194107286632061\n",
      "Gradient for encoder.encoder.1.bias: 0.009146311320364475\n",
      "Gradient for encoder.encoder.3.weight: 0.27302083373069763\n",
      "Gradient for encoder.encoder.3.bias: 1.487204914774054e-09\n",
      "Gradient for encoder.encoder.4.weight: 0.021260404959321022\n",
      "Gradient for encoder.encoder.4.bias: 0.020931484177708626\n",
      "Gradient for encoder.mean.weight: 0.26155638694763184\n",
      "Gradient for encoder.mean.bias: 0.014555459842085838\n",
      "Gradient for encoder.log_var.weight: 0.14998851716518402\n",
      "Gradient for encoder.log_var.bias: 0.009116733446717262\n",
      "Gradient for decoder.decoder.0.weight: 0.0204255860298872\n",
      "Gradient for decoder.decoder.0.bias: 1.7150397768617154e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0010211848421022296\n",
      "Gradient for decoder.decoder.1.bias: 0.0007016398594714701\n",
      "Gradient for decoder.decoder.3.weight: 0.01547996699810028\n",
      "Gradient for decoder.decoder.3.bias: 1.4028965489298884e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0009227085392922163\n",
      "Gradient for decoder.decoder.4.bias: 0.0010204169666394591\n",
      "Gradient for decoder.decoder.6.weight: 0.0014462495455518365\n",
      "Gradient for decoder.decoder.6.bias: 0.00012067189527442679\n",
      "Gradient for encoder.encoder.0.weight: 0.06322183459997177\n",
      "Gradient for encoder.encoder.0.bias: 1.0409971495928261e-10\n",
      "Gradient for encoder.encoder.1.weight: 0.009490127675235271\n",
      "Gradient for encoder.encoder.1.bias: 0.006979702040553093\n",
      "Gradient for encoder.encoder.3.weight: 0.2228633463382721\n",
      "Gradient for encoder.encoder.3.bias: 1.2246619274236537e-09\n",
      "Gradient for encoder.encoder.4.weight: 0.016395926475524902\n",
      "Gradient for encoder.encoder.4.bias: 0.01512240432202816\n",
      "Gradient for encoder.mean.weight: 0.2086816430091858\n",
      "Gradient for encoder.mean.bias: 0.009231395088136196\n",
      "Gradient for encoder.log_var.weight: 0.10145918279886246\n",
      "Gradient for encoder.log_var.bias: 0.004809054546058178\n",
      "Gradient for decoder.decoder.0.weight: 0.018090881407260895\n",
      "Gradient for decoder.decoder.0.bias: 1.5494311389474547e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0010145636042580009\n",
      "Gradient for decoder.decoder.1.bias: 0.0006667973357252777\n",
      "Gradient for decoder.decoder.3.weight: 0.014711380936205387\n",
      "Gradient for decoder.decoder.3.bias: 1.1097395918868713e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0005570240900851786\n",
      "Gradient for decoder.decoder.4.bias: 0.0005071458872407675\n",
      "Gradient for decoder.decoder.6.weight: 0.0010633309138938785\n",
      "Gradient for decoder.decoder.6.bias: 5.788141061202623e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.0722866803407669\n",
      "Gradient for encoder.encoder.0.bias: 1.3325916758955003e-10\n",
      "Gradient for encoder.encoder.1.weight: 0.010913263075053692\n",
      "Gradient for encoder.encoder.1.bias: 0.0082783168181777\n",
      "Gradient for encoder.encoder.3.weight: 0.2477087676525116\n",
      "Gradient for encoder.encoder.3.bias: 1.4173989759669325e-09\n",
      "Gradient for encoder.encoder.4.weight: 0.017779957503080368\n",
      "Gradient for encoder.encoder.4.bias: 0.018864037469029427\n",
      "Gradient for encoder.mean.weight: 0.2322249710559845\n",
      "Gradient for encoder.mean.bias: 0.0133583415299654\n",
      "Gradient for encoder.log_var.weight: 0.1268415004014969\n",
      "Gradient for encoder.log_var.bias: 0.007274484261870384\n",
      "Gradient for decoder.decoder.0.weight: 0.017760399729013443\n",
      "Gradient for decoder.decoder.0.bias: 1.4364852363168978e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0008677465375512838\n",
      "Gradient for decoder.decoder.1.bias: 0.0006275441264733672\n",
      "Gradient for decoder.decoder.3.weight: 0.013718153350055218\n",
      "Gradient for decoder.decoder.3.bias: 1.0570957997835251e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0005273553542792797\n",
      "Gradient for decoder.decoder.4.bias: 0.0004824626084882766\n",
      "Gradient for decoder.decoder.6.weight: 0.00112086720764637\n",
      "Gradient for decoder.decoder.6.bias: 7.166242721723393e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.05767121538519859\n",
      "Gradient for encoder.encoder.0.bias: 8.964286257739928e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.007657115813344717\n",
      "Gradient for encoder.encoder.1.bias: 0.006661778781563044\n",
      "Gradient for encoder.encoder.3.weight: 0.1712622046470642\n",
      "Gradient for encoder.encoder.3.bias: 1.0543064199453056e-09\n",
      "Gradient for encoder.encoder.4.weight: 0.016659852117300034\n",
      "Gradient for encoder.encoder.4.bias: 0.01570172980427742\n",
      "Gradient for encoder.mean.weight: 0.20055025815963745\n",
      "Gradient for encoder.mean.bias: 0.011688054539263248\n",
      "Gradient for encoder.log_var.weight: 0.1273491531610489\n",
      "Gradient for encoder.log_var.bias: 0.0059359692968428135\n",
      "Gradient for decoder.decoder.0.weight: 0.019580524414777756\n",
      "Gradient for decoder.decoder.0.bias: 1.6973045191548408e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0010038424516096711\n",
      "Gradient for decoder.decoder.1.bias: 0.0007289783097803593\n",
      "Gradient for decoder.decoder.3.weight: 0.015325408428907394\n",
      "Gradient for decoder.decoder.3.bias: 1.3689858968657376e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0007434156141243875\n",
      "Gradient for decoder.decoder.4.bias: 0.0007792834658175707\n",
      "Gradient for decoder.decoder.6.weight: 0.0013004625216126442\n",
      "Gradient for decoder.decoder.6.bias: 9.087552462005988e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.09902872890233994\n",
      "Gradient for encoder.encoder.0.bias: 1.808732885688613e-10\n",
      "Gradient for encoder.encoder.1.weight: 0.015599087812006474\n",
      "Gradient for encoder.encoder.1.bias: 0.010486396960914135\n",
      "Gradient for encoder.encoder.3.weight: 0.33198100328445435\n",
      "Gradient for encoder.encoder.3.bias: 1.3652570185485047e-09\n",
      "Gradient for encoder.encoder.4.weight: 0.020615234971046448\n",
      "Gradient for encoder.encoder.4.bias: 0.01804385893046856\n",
      "Gradient for encoder.mean.weight: 0.27707523107528687\n",
      "Gradient for encoder.mean.bias: 0.00939306803047657\n",
      "Gradient for encoder.log_var.weight: 0.13338710367679596\n",
      "Gradient for encoder.log_var.bias: 0.005003859754651785\n",
      "Gradient for decoder.decoder.0.weight: 0.01787979155778885\n",
      "Gradient for decoder.decoder.0.bias: 1.5851944756839487e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0009694754262454808\n",
      "Gradient for decoder.decoder.1.bias: 0.0006519481539726257\n",
      "Gradient for decoder.decoder.3.weight: 0.01354826707392931\n",
      "Gradient for decoder.decoder.3.bias: 1.251763831477959e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0005786390975117683\n",
      "Gradient for decoder.decoder.4.bias: 0.0005361942457966506\n",
      "Gradient for decoder.decoder.6.weight: 0.00107085844501853\n",
      "Gradient for decoder.decoder.6.bias: 6.610829586861655e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.0825950875878334\n",
      "Gradient for encoder.encoder.0.bias: 1.206630906303019e-10\n",
      "Gradient for encoder.encoder.1.weight: 0.011741524562239647\n",
      "Gradient for encoder.encoder.1.bias: 0.00899359118193388\n",
      "Gradient for encoder.encoder.3.weight: 0.25802260637283325\n",
      "Gradient for encoder.encoder.3.bias: 1.2227302503831083e-09\n",
      "Gradient for encoder.encoder.4.weight: 0.018840277567505836\n",
      "Gradient for encoder.encoder.4.bias: 0.01693265326321125\n",
      "Gradient for encoder.mean.weight: 0.23546993732452393\n",
      "Gradient for encoder.mean.bias: 0.0098820636048913\n",
      "Gradient for encoder.log_var.weight: 0.11937537789344788\n",
      "Gradient for encoder.log_var.bias: 0.006228255107998848\n",
      "Gradient for decoder.decoder.0.weight: 0.020286036655306816\n",
      "Gradient for decoder.decoder.0.bias: 1.8119036826469426e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0010837098816409707\n",
      "Gradient for decoder.decoder.1.bias: 0.0008030212484300137\n",
      "Gradient for decoder.decoder.3.weight: 0.016192838549613953\n",
      "Gradient for decoder.decoder.3.bias: 1.3244277896617973e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0006081796018406749\n",
      "Gradient for decoder.decoder.4.bias: 0.0005538546829484403\n",
      "Gradient for decoder.decoder.6.weight: 0.001160455052740872\n",
      "Gradient for decoder.decoder.6.bias: 7.146273856051266e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.06310269981622696\n",
      "Gradient for encoder.encoder.0.bias: 1.0702046193689085e-10\n",
      "Gradient for encoder.encoder.1.weight: 0.008037708699703217\n",
      "Gradient for encoder.encoder.1.bias: 0.006618966814130545\n",
      "Gradient for encoder.encoder.3.weight: 0.18194682896137238\n",
      "Gradient for encoder.encoder.3.bias: 9.263617650745459e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.011578989215195179\n",
      "Gradient for encoder.encoder.4.bias: 0.011012420989573002\n",
      "Gradient for encoder.mean.weight: 0.15591885149478912\n",
      "Gradient for encoder.mean.bias: 0.00831554550677538\n",
      "Gradient for encoder.log_var.weight: 0.07737860083580017\n",
      "Gradient for encoder.log_var.bias: 0.0038782639894634485\n",
      "Gradient for decoder.decoder.0.weight: 0.017774051055312157\n",
      "Gradient for decoder.decoder.0.bias: 1.6193443808099062e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.001002578646875918\n",
      "Gradient for decoder.decoder.1.bias: 0.0006524125928990543\n",
      "Gradient for decoder.decoder.3.weight: 0.014383729547262192\n",
      "Gradient for decoder.decoder.3.bias: 1.2681444783169127e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0005407530115917325\n",
      "Gradient for decoder.decoder.4.bias: 0.00048105386667884886\n",
      "Gradient for decoder.decoder.6.weight: 0.0010723995510488749\n",
      "Gradient for decoder.decoder.6.bias: 5.2480841986835e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.059349145740270615\n",
      "Gradient for encoder.encoder.0.bias: 1.2304661456408184e-10\n",
      "Gradient for encoder.encoder.1.weight: 0.012023495510220528\n",
      "Gradient for encoder.encoder.1.bias: 0.009378552436828613\n",
      "Gradient for encoder.encoder.3.weight: 0.2692771553993225\n",
      "Gradient for encoder.encoder.3.bias: 1.1719396564302542e-09\n",
      "Gradient for encoder.encoder.4.weight: 0.01864134706556797\n",
      "Gradient for encoder.encoder.4.bias: 0.019977573305368423\n",
      "Gradient for encoder.mean.weight: 0.22917193174362183\n",
      "Gradient for encoder.mean.bias: 0.014102212153375149\n",
      "Gradient for encoder.log_var.weight: 0.13096126914024353\n",
      "Gradient for encoder.log_var.bias: 0.009014895185828209\n",
      "Gradient for decoder.decoder.0.weight: 0.018727486953139305\n",
      "Gradient for decoder.decoder.0.bias: 1.5969137123761357e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0010333557147532701\n",
      "Gradient for decoder.decoder.1.bias: 0.0006950164679437876\n",
      "Gradient for decoder.decoder.3.weight: 0.014834326691925526\n",
      "Gradient for decoder.decoder.3.bias: 1.3387541075715603e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0007519987411797047\n",
      "Gradient for decoder.decoder.4.bias: 0.0008500392432324588\n",
      "Gradient for decoder.decoder.6.weight: 0.0012238475028425455\n",
      "Gradient for decoder.decoder.6.bias: 8.760864147916436e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.05661020055413246\n",
      "Gradient for encoder.encoder.0.bias: 9.049572202712852e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.009291981346905231\n",
      "Gradient for encoder.encoder.1.bias: 0.006628393195569515\n",
      "Gradient for encoder.encoder.3.weight: 0.20517876744270325\n",
      "Gradient for encoder.encoder.3.bias: 1.1260510301980275e-09\n",
      "Gradient for encoder.encoder.4.weight: 0.02011154778301716\n",
      "Gradient for encoder.encoder.4.bias: 0.015813447535037994\n",
      "Gradient for encoder.mean.weight: 0.23367995023727417\n",
      "Gradient for encoder.mean.bias: 0.012888685800135136\n",
      "Gradient for encoder.log_var.weight: 0.13308638334274292\n",
      "Gradient for encoder.log_var.bias: 0.006317877676337957\n",
      "Gradient for decoder.decoder.0.weight: 0.019635768607258797\n",
      "Gradient for decoder.decoder.0.bias: 1.7203789781650158e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.001033584587275982\n",
      "Gradient for decoder.decoder.1.bias: 0.0006990862893871963\n",
      "Gradient for decoder.decoder.3.weight: 0.015440914779901505\n",
      "Gradient for decoder.decoder.3.bias: 1.1665954313677673e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0005768132978118956\n",
      "Gradient for decoder.decoder.4.bias: 0.000583066139370203\n",
      "Gradient for decoder.decoder.6.weight: 0.0010919568594545126\n",
      "Gradient for decoder.decoder.6.bias: 6.565677176695317e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.07397183030843735\n",
      "Gradient for encoder.encoder.0.bias: 1.1697917634556632e-10\n",
      "Gradient for encoder.encoder.1.weight: 0.011450156569480896\n",
      "Gradient for encoder.encoder.1.bias: 0.008601945824921131\n",
      "Gradient for encoder.encoder.3.weight: 0.2513311207294464\n",
      "Gradient for encoder.encoder.3.bias: 1.1877312466879175e-09\n",
      "Gradient for encoder.encoder.4.weight: 0.016568873077630997\n",
      "Gradient for encoder.encoder.4.bias: 0.018089648336172104\n",
      "Gradient for encoder.mean.weight: 0.2293560802936554\n",
      "Gradient for encoder.mean.bias: 0.012089871801435947\n",
      "Gradient for encoder.log_var.weight: 0.12099442631006241\n",
      "Gradient for encoder.log_var.bias: 0.007631395012140274\n",
      "Gradient for decoder.decoder.0.weight: 0.020964933559298515\n",
      "Gradient for decoder.decoder.0.bias: 1.9441326326585795e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.001142730237916112\n",
      "Gradient for decoder.decoder.1.bias: 0.0007628168677911162\n",
      "Gradient for decoder.decoder.3.weight: 0.016793174669146538\n",
      "Gradient for decoder.decoder.3.bias: 1.5553090759734545e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0009594798902980983\n",
      "Gradient for decoder.decoder.4.bias: 0.0010963589884340763\n",
      "Gradient for decoder.decoder.6.weight: 0.0014842813834547997\n",
      "Gradient for decoder.decoder.6.bias: 0.00012968348164577037\n",
      "Gradient for encoder.encoder.0.weight: 0.07469788193702698\n",
      "Gradient for encoder.encoder.0.bias: 1.0591495736012035e-10\n",
      "Gradient for encoder.encoder.1.weight: 0.00997226033359766\n",
      "Gradient for encoder.encoder.1.bias: 0.006608203984797001\n",
      "Gradient for encoder.encoder.3.weight: 0.2217254638671875\n",
      "Gradient for encoder.encoder.3.bias: 1.0878075107356722e-09\n",
      "Gradient for encoder.encoder.4.weight: 0.017138289287686348\n",
      "Gradient for encoder.encoder.4.bias: 0.014606310054659843\n",
      "Gradient for encoder.mean.weight: 0.2086123824119568\n",
      "Gradient for encoder.mean.bias: 0.010487833991646767\n",
      "Gradient for encoder.log_var.weight: 0.11768466979265213\n",
      "Gradient for encoder.log_var.bias: 0.005634518340229988\n",
      "Gradient for decoder.decoder.0.weight: 0.01728895492851734\n",
      "Gradient for decoder.decoder.0.bias: 1.5726078772537733e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0009061907767318189\n",
      "Gradient for decoder.decoder.1.bias: 0.000658247503452003\n",
      "Gradient for decoder.decoder.3.weight: 0.013033619150519371\n",
      "Gradient for decoder.decoder.3.bias: 1.394062504322946e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0008543417206965387\n",
      "Gradient for decoder.decoder.4.bias: 0.0010887577664107084\n",
      "Gradient for decoder.decoder.6.weight: 0.0013027297100052238\n",
      "Gradient for decoder.decoder.6.bias: 0.00011884072591783479\n",
      "Gradient for encoder.encoder.0.weight: 0.06509905308485031\n",
      "Gradient for encoder.encoder.0.bias: 1.1173378888784669e-10\n",
      "Gradient for encoder.encoder.1.weight: 0.010751034133136272\n",
      "Gradient for encoder.encoder.1.bias: 0.007803541142493486\n",
      "Gradient for encoder.encoder.3.weight: 0.23250643908977509\n",
      "Gradient for encoder.encoder.3.bias: 1.298411933525756e-09\n",
      "Gradient for encoder.encoder.4.weight: 0.017267532646656036\n",
      "Gradient for encoder.encoder.4.bias: 0.014979497529566288\n",
      "Gradient for encoder.mean.weight: 0.22061458230018616\n",
      "Gradient for encoder.mean.bias: 0.008508607745170593\n",
      "Gradient for encoder.log_var.weight: 0.10988573729991913\n",
      "Gradient for encoder.log_var.bias: 0.005143080372363329\n",
      "Gradient for decoder.decoder.0.weight: 0.017666304484009743\n",
      "Gradient for decoder.decoder.0.bias: 1.4536755132965595e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0008285417570732534\n",
      "Gradient for decoder.decoder.1.bias: 0.0005963280564174056\n",
      "Gradient for decoder.decoder.3.weight: 0.013511045835912228\n",
      "Gradient for decoder.decoder.3.bias: 1.164831425759516e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.000675773888360709\n",
      "Gradient for decoder.decoder.4.bias: 0.000824526883661747\n",
      "Gradient for decoder.decoder.6.weight: 0.0011923389974981546\n",
      "Gradient for decoder.decoder.6.bias: 8.889261516742408e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training VAE Epoch:  22%|██▏       | 17/79 [00:00<00:01, 52.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient for encoder.encoder.0.weight: 0.05590822920203209\n",
      "Gradient for encoder.encoder.0.bias: 1.0370034692064323e-10\n",
      "Gradient for encoder.encoder.1.weight: 0.009878991171717644\n",
      "Gradient for encoder.encoder.1.bias: 0.00651601841673255\n",
      "Gradient for encoder.encoder.3.weight: 0.21360209584236145\n",
      "Gradient for encoder.encoder.3.bias: 1.0013240236972365e-09\n",
      "Gradient for encoder.encoder.4.weight: 0.015773829072713852\n",
      "Gradient for encoder.encoder.4.bias: 0.012695267796516418\n",
      "Gradient for encoder.mean.weight: 0.20331555604934692\n",
      "Gradient for encoder.mean.bias: 0.009281983599066734\n",
      "Gradient for encoder.log_var.weight: 0.0934503823518753\n",
      "Gradient for encoder.log_var.bias: 0.004635649733245373\n",
      "Gradient for decoder.decoder.0.weight: 0.019889649003744125\n",
      "Gradient for decoder.decoder.0.bias: 1.642949387647974e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0010913300793617964\n",
      "Gradient for decoder.decoder.1.bias: 0.0007270105998031795\n",
      "Gradient for decoder.decoder.3.weight: 0.01547593716531992\n",
      "Gradient for decoder.decoder.3.bias: 1.1891838902489127e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0005772425211034715\n",
      "Gradient for decoder.decoder.4.bias: 0.0005238892626948655\n",
      "Gradient for decoder.decoder.6.weight: 0.0010905785020440817\n",
      "Gradient for decoder.decoder.6.bias: 6.047147326171398e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.07666537165641785\n",
      "Gradient for encoder.encoder.0.bias: 1.5291369559466972e-10\n",
      "Gradient for encoder.encoder.1.weight: 0.011216463521122932\n",
      "Gradient for encoder.encoder.1.bias: 0.008067871443927288\n",
      "Gradient for encoder.encoder.3.weight: 0.25140586495399475\n",
      "Gradient for encoder.encoder.3.bias: 1.1924665699325487e-09\n",
      "Gradient for encoder.encoder.4.weight: 0.021131612360477448\n",
      "Gradient for encoder.encoder.4.bias: 0.016976678743958473\n",
      "Gradient for encoder.mean.weight: 0.2585686147212982\n",
      "Gradient for encoder.mean.bias: 0.009260467253625393\n",
      "Gradient for encoder.log_var.weight: 0.14629259705543518\n",
      "Gradient for encoder.log_var.bias: 0.0049082390032708645\n",
      "Gradient for decoder.decoder.0.weight: 0.014495189301669598\n",
      "Gradient for decoder.decoder.0.bias: 1.1726498938546825e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0007780252490192652\n",
      "Gradient for decoder.decoder.1.bias: 0.0005213042022660375\n",
      "Gradient for decoder.decoder.3.weight: 0.011618062853813171\n",
      "Gradient for decoder.decoder.3.bias: 8.83530332229654e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0004497788322623819\n",
      "Gradient for decoder.decoder.4.bias: 0.0004525163967628032\n",
      "Gradient for decoder.decoder.6.weight: 0.0011285932268947363\n",
      "Gradient for decoder.decoder.6.bias: 7.112613820936531e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training VAE Epoch:  32%|███▏      | 25/79 [00:00<00:00, 61.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient for encoder.encoder.0.weight: 0.10141714662313461\n",
      "Gradient for encoder.encoder.0.bias: 1.4121398494992832e-10\n",
      "Gradient for encoder.encoder.1.weight: 0.013035841286182404\n",
      "Gradient for encoder.encoder.1.bias: 0.0104542076587677\n",
      "Gradient for encoder.encoder.3.weight: 0.2859468460083008\n",
      "Gradient for encoder.encoder.3.bias: 1.3071527193986299e-09\n",
      "Gradient for encoder.encoder.4.weight: 0.018485859036445618\n",
      "Gradient for encoder.encoder.4.bias: 0.01761597767472267\n",
      "Gradient for encoder.mean.weight: 0.24753229320049286\n",
      "Gradient for encoder.mean.bias: 0.01200854778289795\n",
      "Gradient for encoder.log_var.weight: 0.1315930038690567\n",
      "Gradient for encoder.log_var.bias: 0.005880019161850214\n",
      "Gradient for decoder.decoder.0.weight: 0.016983594745397568\n",
      "Gradient for decoder.decoder.0.bias: 1.4727430386329843e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0009702963288873434\n",
      "Gradient for decoder.decoder.1.bias: 0.0006341652479022741\n",
      "Gradient for decoder.decoder.3.weight: 0.013195851817727089\n",
      "Gradient for decoder.decoder.3.bias: 1.2058558318539525e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0006210528663359582\n",
      "Gradient for decoder.decoder.4.bias: 0.000752024061512202\n",
      "Gradient for decoder.decoder.6.weight: 0.0011593939270824194\n",
      "Gradient for decoder.decoder.6.bias: 8.019289816729724e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.08390230685472488\n",
      "Gradient for encoder.encoder.0.bias: 1.3111370322782534e-10\n",
      "Gradient for encoder.encoder.1.weight: 0.011770776472985744\n",
      "Gradient for encoder.encoder.1.bias: 0.00861488375812769\n",
      "Gradient for encoder.encoder.3.weight: 0.2622232139110565\n",
      "Gradient for encoder.encoder.3.bias: 1.4629855105141587e-09\n",
      "Gradient for encoder.encoder.4.weight: 0.022736072540283203\n",
      "Gradient for encoder.encoder.4.bias: 0.02042088285088539\n",
      "Gradient for encoder.mean.weight: 0.2824804186820984\n",
      "Gradient for encoder.mean.bias: 0.011039414443075657\n",
      "Gradient for encoder.log_var.weight: 0.1449335515499115\n",
      "Gradient for encoder.log_var.bias: 0.006595693062990904\n",
      "Gradient for decoder.decoder.0.weight: 0.018482638522982597\n",
      "Gradient for decoder.decoder.0.bias: 1.5966328259509055e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0010477917967364192\n",
      "Gradient for decoder.decoder.1.bias: 0.0006529970560222864\n",
      "Gradient for decoder.decoder.3.weight: 0.014291171915829182\n",
      "Gradient for decoder.decoder.3.bias: 1.2775426549982427e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0007560457452200353\n",
      "Gradient for decoder.decoder.4.bias: 0.000759160378947854\n",
      "Gradient for decoder.decoder.6.weight: 0.0011615147814154625\n",
      "Gradient for decoder.decoder.6.bias: 7.496595208067447e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.05196266248822212\n",
      "Gradient for encoder.encoder.0.bias: 9.34382016204438e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.007097628898918629\n",
      "Gradient for encoder.encoder.1.bias: 0.0050788382068276405\n",
      "Gradient for encoder.encoder.3.weight: 0.16754445433616638\n",
      "Gradient for encoder.encoder.3.bias: 8.173930421406794e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.011273924261331558\n",
      "Gradient for encoder.encoder.4.bias: 0.011514239944517612\n",
      "Gradient for encoder.mean.weight: 0.15159103274345398\n",
      "Gradient for encoder.mean.bias: 0.008142340928316116\n",
      "Gradient for encoder.log_var.weight: 0.06960296630859375\n",
      "Gradient for encoder.log_var.bias: 0.004646915476769209\n",
      "Gradient for decoder.decoder.0.weight: 0.016548581421375275\n",
      "Gradient for decoder.decoder.0.bias: 1.440724484158551e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.000887608272023499\n",
      "Gradient for decoder.decoder.1.bias: 0.0006141113699413836\n",
      "Gradient for decoder.decoder.3.weight: 0.012943685054779053\n",
      "Gradient for decoder.decoder.3.bias: 1.1184768389238542e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0007091640145517886\n",
      "Gradient for decoder.decoder.4.bias: 0.0008328530821017921\n",
      "Gradient for decoder.decoder.6.weight: 0.0012387039605528116\n",
      "Gradient for decoder.decoder.6.bias: 9.782859706319869e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.06257403641939163\n",
      "Gradient for encoder.encoder.0.bias: 1.20439519468718e-10\n",
      "Gradient for encoder.encoder.1.weight: 0.009772547520697117\n",
      "Gradient for encoder.encoder.1.bias: 0.007322784513235092\n",
      "Gradient for encoder.encoder.3.weight: 0.20810934901237488\n",
      "Gradient for encoder.encoder.3.bias: 1.6001371339058323e-09\n",
      "Gradient for encoder.encoder.4.weight: 0.0210886150598526\n",
      "Gradient for encoder.encoder.4.bias: 0.023424241691827774\n",
      "Gradient for encoder.mean.weight: 0.2625741958618164\n",
      "Gradient for encoder.mean.bias: 0.018876096233725548\n",
      "Gradient for encoder.log_var.weight: 0.14957645535469055\n",
      "Gradient for encoder.log_var.bias: 0.011080581694841385\n",
      "Gradient for decoder.decoder.0.weight: 0.01709275133907795\n",
      "Gradient for decoder.decoder.0.bias: 1.567071888919358e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0008855119231157005\n",
      "Gradient for decoder.decoder.1.bias: 0.0006367222522385418\n",
      "Gradient for decoder.decoder.3.weight: 0.01311472523957491\n",
      "Gradient for decoder.decoder.3.bias: 1.2377776581473654e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0004834387800656259\n",
      "Gradient for decoder.decoder.4.bias: 0.00043592252768576145\n",
      "Gradient for decoder.decoder.6.weight: 0.0010472728172317147\n",
      "Gradient for decoder.decoder.6.bias: 5.26571566297207e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.06324250996112823\n",
      "Gradient for encoder.encoder.0.bias: 9.665300504391183e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.009513307362794876\n",
      "Gradient for encoder.encoder.1.bias: 0.00678036455065012\n",
      "Gradient for encoder.encoder.3.weight: 0.22047846019268036\n",
      "Gradient for encoder.encoder.3.bias: 1.043858999238978e-09\n",
      "Gradient for encoder.encoder.4.weight: 0.02067393809556961\n",
      "Gradient for encoder.encoder.4.bias: 0.015337828546762466\n",
      "Gradient for encoder.mean.weight: 0.23893941938877106\n",
      "Gradient for encoder.mean.bias: 0.007630891632288694\n",
      "Gradient for encoder.log_var.weight: 0.13206055760383606\n",
      "Gradient for encoder.log_var.bias: 0.004658651538193226\n",
      "Gradient for decoder.decoder.0.weight: 0.019744383171200752\n",
      "Gradient for decoder.decoder.0.bias: 1.4602440090438762e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0010130018927156925\n",
      "Gradient for decoder.decoder.1.bias: 0.0007254883530549705\n",
      "Gradient for decoder.decoder.3.weight: 0.015349021181464195\n",
      "Gradient for decoder.decoder.3.bias: 1.1450110304345174e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0005675707361660898\n",
      "Gradient for decoder.decoder.4.bias: 0.0005292001878842711\n",
      "Gradient for decoder.decoder.6.weight: 0.0010688409674912691\n",
      "Gradient for decoder.decoder.6.bias: 5.0805745559046045e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.0688922107219696\n",
      "Gradient for encoder.encoder.0.bias: 9.98529661733194e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.00998876802623272\n",
      "Gradient for encoder.encoder.1.bias: 0.007212511729449034\n",
      "Gradient for encoder.encoder.3.weight: 0.22473078966140747\n",
      "Gradient for encoder.encoder.3.bias: 1.2819297845467759e-09\n",
      "Gradient for encoder.encoder.4.weight: 0.020511938259005547\n",
      "Gradient for encoder.encoder.4.bias: 0.018630152568221092\n",
      "Gradient for encoder.mean.weight: 0.24188996851444244\n",
      "Gradient for encoder.mean.bias: 0.011567273177206516\n",
      "Gradient for encoder.log_var.weight: 0.14441360533237457\n",
      "Gradient for encoder.log_var.bias: 0.007530868519097567\n",
      "Gradient for decoder.decoder.0.weight: 0.01901187002658844\n",
      "Gradient for decoder.decoder.0.bias: 1.6753247400469462e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0010207718005403876\n",
      "Gradient for decoder.decoder.1.bias: 0.0006863431772217155\n",
      "Gradient for decoder.decoder.3.weight: 0.015429580584168434\n",
      "Gradient for decoder.decoder.3.bias: 1.222109774490221e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0006224614335224032\n",
      "Gradient for decoder.decoder.4.bias: 0.0005688009550794959\n",
      "Gradient for decoder.decoder.6.weight: 0.0011011426104232669\n",
      "Gradient for decoder.decoder.6.bias: 5.903227793169208e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.06406854093074799\n",
      "Gradient for encoder.encoder.0.bias: 1.0641769410124624e-10\n",
      "Gradient for encoder.encoder.1.weight: 0.009491023607552052\n",
      "Gradient for encoder.encoder.1.bias: 0.006962317042052746\n",
      "Gradient for encoder.encoder.3.weight: 0.20371729135513306\n",
      "Gradient for encoder.encoder.3.bias: 1.181146846995773e-09\n",
      "Gradient for encoder.encoder.4.weight: 0.01935763843357563\n",
      "Gradient for encoder.encoder.4.bias: 0.017701976001262665\n",
      "Gradient for encoder.mean.weight: 0.2242591232061386\n",
      "Gradient for encoder.mean.bias: 0.01391457486897707\n",
      "Gradient for encoder.log_var.weight: 0.12959514558315277\n",
      "Gradient for encoder.log_var.bias: 0.008142370730638504\n",
      "Gradient for decoder.decoder.0.weight: 0.01583159901201725\n",
      "Gradient for decoder.decoder.0.bias: 1.3040499236005587e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0008594003738835454\n",
      "Gradient for decoder.decoder.1.bias: 0.0006002121372148395\n",
      "Gradient for decoder.decoder.3.weight: 0.01233813725411892\n",
      "Gradient for decoder.decoder.3.bias: 1.360641460612655e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0010199040407314897\n",
      "Gradient for decoder.decoder.4.bias: 0.0012129477690905333\n",
      "Gradient for decoder.decoder.6.weight: 0.001676706364378333\n",
      "Gradient for decoder.decoder.6.bias: 0.00015097446157597005\n",
      "Gradient for encoder.encoder.0.weight: 0.07146401703357697\n",
      "Gradient for encoder.encoder.0.bias: 1.357974427351749e-10\n",
      "Gradient for encoder.encoder.1.weight: 0.009375040419399738\n",
      "Gradient for encoder.encoder.1.bias: 0.007074084598571062\n",
      "Gradient for encoder.encoder.3.weight: 0.20899507403373718\n",
      "Gradient for encoder.encoder.3.bias: 9.18876863487128e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.013968395069241524\n",
      "Gradient for encoder.encoder.4.bias: 0.011890490539371967\n",
      "Gradient for encoder.mean.weight: 0.18672369420528412\n",
      "Gradient for encoder.mean.bias: 0.007032154593616724\n",
      "Gradient for encoder.log_var.weight: 0.09453554451465607\n",
      "Gradient for encoder.log_var.bias: 0.0045876395888626575\n",
      "Gradient for decoder.decoder.0.weight: 0.015972694382071495\n",
      "Gradient for decoder.decoder.0.bias: 1.265193505517459e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.000817488064058125\n",
      "Gradient for decoder.decoder.1.bias: 0.0005537467077374458\n",
      "Gradient for decoder.decoder.3.weight: 0.0123264966532588\n",
      "Gradient for decoder.decoder.3.bias: 1.0505352837641979e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0005003350670449436\n",
      "Gradient for decoder.decoder.4.bias: 0.00048210506793111563\n",
      "Gradient for decoder.decoder.6.weight: 0.0009581278427504003\n",
      "Gradient for decoder.decoder.6.bias: 4.659627302316949e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.05719207972288132\n",
      "Gradient for encoder.encoder.0.bias: 8.786273791860921e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.007568905595690012\n",
      "Gradient for encoder.encoder.1.bias: 0.006111843045800924\n",
      "Gradient for encoder.encoder.3.weight: 0.17184676229953766\n",
      "Gradient for encoder.encoder.3.bias: 9.789759003453469e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.01032883208245039\n",
      "Gradient for encoder.encoder.4.bias: 0.009529847651720047\n",
      "Gradient for encoder.mean.weight: 0.13541412353515625\n",
      "Gradient for encoder.mean.bias: 0.006107334513217211\n",
      "Gradient for encoder.log_var.weight: 0.07337398082017899\n",
      "Gradient for encoder.log_var.bias: 0.004038385581225157\n",
      "Gradient for decoder.decoder.0.weight: 0.02093590423464775\n",
      "Gradient for decoder.decoder.0.bias: 1.7141321695390843e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0010710686910897493\n",
      "Gradient for decoder.decoder.1.bias: 0.000786727003287524\n",
      "Gradient for decoder.decoder.3.weight: 0.016484523192048073\n",
      "Gradient for decoder.decoder.3.bias: 1.3039240520651418e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0007507973932661116\n",
      "Gradient for decoder.decoder.4.bias: 0.0008187147905118763\n",
      "Gradient for decoder.decoder.6.weight: 0.001176153775304556\n",
      "Gradient for decoder.decoder.6.bias: 7.948384882183746e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.04636188969016075\n",
      "Gradient for encoder.encoder.0.bias: 7.858178691089179e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.007780378218740225\n",
      "Gradient for encoder.encoder.1.bias: 0.005289063323289156\n",
      "Gradient for encoder.encoder.3.weight: 0.16401492059230804\n",
      "Gradient for encoder.encoder.3.bias: 1.448162367800876e-09\n",
      "Gradient for encoder.encoder.4.weight: 0.014121679589152336\n",
      "Gradient for encoder.encoder.4.bias: 0.01317270565778017\n",
      "Gradient for encoder.mean.weight: 0.16892245411872864\n",
      "Gradient for encoder.mean.bias: 0.007795966230332851\n",
      "Gradient for encoder.log_var.weight: 0.08963163197040558\n",
      "Gradient for encoder.log_var.bias: 0.003828751854598522\n",
      "Gradient for decoder.decoder.0.weight: 0.020093845203518867\n",
      "Gradient for decoder.decoder.0.bias: 1.5176523926463403e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.001133330282755196\n",
      "Gradient for decoder.decoder.1.bias: 0.0007361754542216659\n",
      "Gradient for decoder.decoder.3.weight: 0.015104603953659534\n",
      "Gradient for decoder.decoder.3.bias: 1.2468613641569704e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.000751600950025022\n",
      "Gradient for decoder.decoder.4.bias: 0.0007776903221383691\n",
      "Gradient for decoder.decoder.6.weight: 0.0011478568194434047\n",
      "Gradient for decoder.decoder.6.bias: 7.252979412442073e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.07534176856279373\n",
      "Gradient for encoder.encoder.0.bias: 1.2421996764544474e-10\n",
      "Gradient for encoder.encoder.1.weight: 0.011375338770449162\n",
      "Gradient for encoder.encoder.1.bias: 0.00788817461580038\n",
      "Gradient for encoder.encoder.3.weight: 0.25287556648254395\n",
      "Gradient for encoder.encoder.3.bias: 1.3831668033148503e-09\n",
      "Gradient for encoder.encoder.4.weight: 0.023100880905985832\n",
      "Gradient for encoder.encoder.4.bias: 0.021683981642127037\n",
      "Gradient for encoder.mean.weight: 0.28991270065307617\n",
      "Gradient for encoder.mean.bias: 0.016110677272081375\n",
      "Gradient for encoder.log_var.weight: 0.15167613327503204\n",
      "Gradient for encoder.log_var.bias: 0.010176089592278004\n",
      "Gradient for decoder.decoder.0.weight: 0.01692345179617405\n",
      "Gradient for decoder.decoder.0.bias: 1.4612067111841043e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0008305590017698705\n",
      "Gradient for decoder.decoder.1.bias: 0.0005795658216811717\n",
      "Gradient for decoder.decoder.3.weight: 0.012702629901468754\n",
      "Gradient for decoder.decoder.3.bias: 9.733547301493672e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0004293911624699831\n",
      "Gradient for decoder.decoder.4.bias: 0.0003939762245863676\n",
      "Gradient for decoder.decoder.6.weight: 0.0010409450624138117\n",
      "Gradient for decoder.decoder.6.bias: 6.607161049032584e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.08564101904630661\n",
      "Gradient for encoder.encoder.0.bias: 1.2315361230808008e-10\n",
      "Gradient for encoder.encoder.1.weight: 0.011503568850457668\n",
      "Gradient for encoder.encoder.1.bias: 0.007961529307067394\n",
      "Gradient for encoder.encoder.3.weight: 0.23947319388389587\n",
      "Gradient for encoder.encoder.3.bias: 1.0070440037424078e-09\n",
      "Gradient for encoder.encoder.4.weight: 0.015008923597633839\n",
      "Gradient for encoder.encoder.4.bias: 0.013619240373373032\n",
      "Gradient for encoder.mean.weight: 0.1956922709941864\n",
      "Gradient for encoder.mean.bias: 0.008224296383559704\n",
      "Gradient for encoder.log_var.weight: 0.11305882781744003\n",
      "Gradient for encoder.log_var.bias: 0.00463841762393713\n",
      "Gradient for decoder.decoder.0.weight: 0.017105748876929283\n",
      "Gradient for decoder.decoder.0.bias: 1.681887962234896e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0009113840642385185\n",
      "Gradient for decoder.decoder.1.bias: 0.0006684721447527409\n",
      "Gradient for decoder.decoder.3.weight: 0.013368633575737476\n",
      "Gradient for decoder.decoder.3.bias: 1.4806478265683154e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0006521620671264827\n",
      "Gradient for decoder.decoder.4.bias: 0.0007540955557487905\n",
      "Gradient for decoder.decoder.6.weight: 0.0010846974328160286\n",
      "Gradient for decoder.decoder.6.bias: 7.909118721727282e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.05136224627494812\n",
      "Gradient for encoder.encoder.0.bias: 9.177262422221943e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.008793244138360023\n",
      "Gradient for encoder.encoder.1.bias: 0.006102353800088167\n",
      "Gradient for encoder.encoder.3.weight: 0.18356649577617645\n",
      "Gradient for encoder.encoder.3.bias: 8.959335495717369e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.014507359825074673\n",
      "Gradient for encoder.encoder.4.bias: 0.015179654583334923\n",
      "Gradient for encoder.mean.weight: 0.17899388074874878\n",
      "Gradient for encoder.mean.bias: 0.00977402739226818\n",
      "Gradient for encoder.log_var.weight: 0.09725321829319\n",
      "Gradient for encoder.log_var.bias: 0.006229954771697521\n",
      "Gradient for decoder.decoder.0.weight: 0.018368028104305267\n",
      "Gradient for decoder.decoder.0.bias: 1.456869624938406e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0009422756265848875\n",
      "Gradient for decoder.decoder.1.bias: 0.0006824439624324441\n",
      "Gradient for decoder.decoder.3.weight: 0.014142462983727455\n",
      "Gradient for decoder.decoder.3.bias: 1.1234842223206698e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0005877820658497512\n",
      "Gradient for decoder.decoder.4.bias: 0.0006029146024957299\n",
      "Gradient for decoder.decoder.6.weight: 0.0010981283849105239\n",
      "Gradient for decoder.decoder.6.bias: 6.450857472373173e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.08329537510871887\n",
      "Gradient for encoder.encoder.0.bias: 1.164594948255271e-10\n",
      "Gradient for encoder.encoder.1.weight: 0.011257587000727654\n",
      "Gradient for encoder.encoder.1.bias: 0.008048659190535545\n",
      "Gradient for encoder.encoder.3.weight: 0.239711195230484\n",
      "Gradient for encoder.encoder.3.bias: 1.1393209708998597e-09\n",
      "Gradient for encoder.encoder.4.weight: 0.016208749264478683\n",
      "Gradient for encoder.encoder.4.bias: 0.015198888257145882\n",
      "Gradient for encoder.mean.weight: 0.2177005112171173\n",
      "Gradient for encoder.mean.bias: 0.008688623085618019\n",
      "Gradient for encoder.log_var.weight: 0.1148231104016304\n",
      "Gradient for encoder.log_var.bias: 0.004259823355823755\n",
      "Gradient for decoder.decoder.0.weight: 0.021028602495789528\n",
      "Gradient for decoder.decoder.0.bias: 1.708437835645782e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0011872972827404737\n",
      "Gradient for decoder.decoder.1.bias: 0.0007882362697273493\n",
      "Gradient for decoder.decoder.3.weight: 0.016781872138381004\n",
      "Gradient for decoder.decoder.3.bias: 1.1256087728561681e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0006218968192115426\n",
      "Gradient for decoder.decoder.4.bias: 0.000559407752007246\n",
      "Gradient for decoder.decoder.6.weight: 0.0010556720662862062\n",
      "Gradient for decoder.decoder.6.bias: 5.407509161159396e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training VAE Epoch:  42%|████▏     | 33/79 [00:00<00:00, 67.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient for encoder.encoder.0.weight: 0.06184573471546173\n",
      "Gradient for encoder.encoder.0.bias: 1.1075490524703469e-10\n",
      "Gradient for encoder.encoder.1.weight: 0.009773415513336658\n",
      "Gradient for encoder.encoder.1.bias: 0.007347471080720425\n",
      "Gradient for encoder.encoder.3.weight: 0.20743347704410553\n",
      "Gradient for encoder.encoder.3.bias: 9.908134313008077e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.01569332554936409\n",
      "Gradient for encoder.encoder.4.bias: 0.016009531915187836\n",
      "Gradient for encoder.mean.weight: 0.20636232197284698\n",
      "Gradient for encoder.mean.bias: 0.010485383681952953\n",
      "Gradient for encoder.log_var.weight: 0.10967493802309036\n",
      "Gradient for encoder.log_var.bias: 0.004800124559551477\n",
      "Gradient for decoder.decoder.0.weight: 0.018185056746006012\n",
      "Gradient for decoder.decoder.0.bias: 1.6948571712749327e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0009992739651352167\n",
      "Gradient for decoder.decoder.1.bias: 0.0006914963014423847\n",
      "Gradient for decoder.decoder.3.weight: 0.01414873730391264\n",
      "Gradient for decoder.decoder.3.bias: 1.2413103878117226e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0005218257429078221\n",
      "Gradient for decoder.decoder.4.bias: 0.00046922857291065156\n",
      "Gradient for decoder.decoder.6.weight: 0.0010179085657000542\n",
      "Gradient for decoder.decoder.6.bias: 5.149123535375111e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.09418940544128418\n",
      "Gradient for encoder.encoder.0.bias: 1.6133264169049255e-10\n",
      "Gradient for encoder.encoder.1.weight: 0.011460350826382637\n",
      "Gradient for encoder.encoder.1.bias: 0.007970037870109081\n",
      "Gradient for encoder.encoder.3.weight: 0.24455396831035614\n",
      "Gradient for encoder.encoder.3.bias: 1.3376144636367826e-09\n",
      "Gradient for encoder.encoder.4.weight: 0.021517209708690643\n",
      "Gradient for encoder.encoder.4.bias: 0.019817868247628212\n",
      "Gradient for encoder.mean.weight: 0.2793201208114624\n",
      "Gradient for encoder.mean.bias: 0.013366395607590675\n",
      "Gradient for encoder.log_var.weight: 0.1506362408399582\n",
      "Gradient for encoder.log_var.bias: 0.00697779655456543\n",
      "Gradient for decoder.decoder.0.weight: 0.015662459656596184\n",
      "Gradient for decoder.decoder.0.bias: 1.361682155920363e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.000835461774840951\n",
      "Gradient for decoder.decoder.1.bias: 0.0005801506340503693\n",
      "Gradient for decoder.decoder.3.weight: 0.01256696879863739\n",
      "Gradient for decoder.decoder.3.bias: 1.1702898372600856e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0005388824502006173\n",
      "Gradient for decoder.decoder.4.bias: 0.0005720973713323474\n",
      "Gradient for decoder.decoder.6.weight: 0.0011156395776197314\n",
      "Gradient for decoder.decoder.6.bias: 7.491629366995767e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training VAE Epoch:  52%|█████▏    | 41/79 [00:00<00:00, 70.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient for encoder.encoder.0.weight: 0.07200180739164352\n",
      "Gradient for encoder.encoder.0.bias: 1.0438234998577656e-10\n",
      "Gradient for encoder.encoder.1.weight: 0.010387425310909748\n",
      "Gradient for encoder.encoder.1.bias: 0.0079212486743927\n",
      "Gradient for encoder.encoder.3.weight: 0.22529318928718567\n",
      "Gradient for encoder.encoder.3.bias: 1.1415528522462637e-09\n",
      "Gradient for encoder.encoder.4.weight: 0.017457250505685806\n",
      "Gradient for encoder.encoder.4.bias: 0.017740804702043533\n",
      "Gradient for encoder.mean.weight: 0.22625845670700073\n",
      "Gradient for encoder.mean.bias: 0.011028064414858818\n",
      "Gradient for encoder.log_var.weight: 0.11427722871303558\n",
      "Gradient for encoder.log_var.bias: 0.0055248793214559555\n",
      "Gradient for decoder.decoder.0.weight: 0.020641328766942024\n",
      "Gradient for decoder.decoder.0.bias: 1.8849538596654725e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.001066463883034885\n",
      "Gradient for decoder.decoder.1.bias: 0.0006908695213496685\n",
      "Gradient for decoder.decoder.3.weight: 0.015959888696670532\n",
      "Gradient for decoder.decoder.3.bias: 1.3143575117169348e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0005527405301108956\n",
      "Gradient for decoder.decoder.4.bias: 0.00046282325638458133\n",
      "Gradient for decoder.decoder.6.weight: 0.001089608995243907\n",
      "Gradient for decoder.decoder.6.bias: 6.313229823717847e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.0981871485710144\n",
      "Gradient for encoder.encoder.0.bias: 1.3827390621390379e-10\n",
      "Gradient for encoder.encoder.1.weight: 0.013416468165814877\n",
      "Gradient for encoder.encoder.1.bias: 0.009647130966186523\n",
      "Gradient for encoder.encoder.3.weight: 0.28709226846694946\n",
      "Gradient for encoder.encoder.3.bias: 1.1357386142663017e-09\n",
      "Gradient for encoder.encoder.4.weight: 0.018009208142757416\n",
      "Gradient for encoder.encoder.4.bias: 0.01645122841000557\n",
      "Gradient for encoder.mean.weight: 0.2399105578660965\n",
      "Gradient for encoder.mean.bias: 0.009084563702344894\n",
      "Gradient for encoder.log_var.weight: 0.12845304608345032\n",
      "Gradient for encoder.log_var.bias: 0.005146339535713196\n",
      "Gradient for decoder.decoder.0.weight: 0.018924487754702568\n",
      "Gradient for decoder.decoder.0.bias: 1.5995661739598432e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0009315114002674818\n",
      "Gradient for decoder.decoder.1.bias: 0.0006473393877968192\n",
      "Gradient for decoder.decoder.3.weight: 0.014353495091199875\n",
      "Gradient for decoder.decoder.3.bias: 1.2281535510805242e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.000668843335006386\n",
      "Gradient for decoder.decoder.4.bias: 0.0006551087717525661\n",
      "Gradient for decoder.decoder.6.weight: 0.0011837870115414262\n",
      "Gradient for decoder.decoder.6.bias: 7.194956560852006e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.06244582682847977\n",
      "Gradient for encoder.encoder.0.bias: 9.915968740559222e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.009341130033135414\n",
      "Gradient for encoder.encoder.1.bias: 0.006739339791238308\n",
      "Gradient for encoder.encoder.3.weight: 0.2080857902765274\n",
      "Gradient for encoder.encoder.3.bias: 9.054718641543502e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.014865637756884098\n",
      "Gradient for encoder.encoder.4.bias: 0.01255841925740242\n",
      "Gradient for encoder.mean.weight: 0.2022019475698471\n",
      "Gradient for encoder.mean.bias: 0.008518463931977749\n",
      "Gradient for encoder.log_var.weight: 0.10084972530603409\n",
      "Gradient for encoder.log_var.bias: 0.0043630036525428295\n",
      "Gradient for decoder.decoder.0.weight: 0.020402517169713974\n",
      "Gradient for decoder.decoder.0.bias: 1.4414271165552606e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0011981494026258588\n",
      "Gradient for decoder.decoder.1.bias: 0.0008236286812461913\n",
      "Gradient for decoder.decoder.3.weight: 0.01675470918416977\n",
      "Gradient for decoder.decoder.3.bias: 1.1697226520723802e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0006395277450792491\n",
      "Gradient for decoder.decoder.4.bias: 0.0005617048591375351\n",
      "Gradient for decoder.decoder.6.weight: 0.0010841054609045386\n",
      "Gradient for decoder.decoder.6.bias: 4.941940278513357e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.06852984428405762\n",
      "Gradient for encoder.encoder.0.bias: 1.0308374986944813e-10\n",
      "Gradient for encoder.encoder.1.weight: 0.011206019669771194\n",
      "Gradient for encoder.encoder.1.bias: 0.007613401859998703\n",
      "Gradient for encoder.encoder.3.weight: 0.25130826234817505\n",
      "Gradient for encoder.encoder.3.bias: 1.1933117827211959e-09\n",
      "Gradient for encoder.encoder.4.weight: 0.019832175225019455\n",
      "Gradient for encoder.encoder.4.bias: 0.017039982602000237\n",
      "Gradient for encoder.mean.weight: 0.25859829783439636\n",
      "Gradient for encoder.mean.bias: 0.0094693498685956\n",
      "Gradient for encoder.log_var.weight: 0.11908794194459915\n",
      "Gradient for encoder.log_var.bias: 0.004618949256837368\n",
      "Gradient for decoder.decoder.0.weight: 0.02112438529729843\n",
      "Gradient for decoder.decoder.0.bias: 1.7004815611176838e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0011788040865212679\n",
      "Gradient for decoder.decoder.1.bias: 0.0007804688066244125\n",
      "Gradient for decoder.decoder.3.weight: 0.01658608578145504\n",
      "Gradient for decoder.decoder.3.bias: 1.267050908637657e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0006220584036782384\n",
      "Gradient for decoder.decoder.4.bias: 0.0005911245243623853\n",
      "Gradient for decoder.decoder.6.weight: 0.0012003604788333178\n",
      "Gradient for decoder.decoder.6.bias: 7.956469198688865e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.07756029069423676\n",
      "Gradient for encoder.encoder.0.bias: 1.2460185661034018e-10\n",
      "Gradient for encoder.encoder.1.weight: 0.011490988545119762\n",
      "Gradient for encoder.encoder.1.bias: 0.0084909088909626\n",
      "Gradient for encoder.encoder.3.weight: 0.25172603130340576\n",
      "Gradient for encoder.encoder.3.bias: 1.0368151892592437e-09\n",
      "Gradient for encoder.encoder.4.weight: 0.018833190202713013\n",
      "Gradient for encoder.encoder.4.bias: 0.016489755362272263\n",
      "Gradient for encoder.mean.weight: 0.24592725932598114\n",
      "Gradient for encoder.mean.bias: 0.009632544592022896\n",
      "Gradient for encoder.log_var.weight: 0.12157116085290909\n",
      "Gradient for encoder.log_var.bias: 0.003931927960366011\n",
      "Gradient for decoder.decoder.0.weight: 0.015425239689648151\n",
      "Gradient for decoder.decoder.0.bias: 1.4314834040352054e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0008536208188161254\n",
      "Gradient for decoder.decoder.1.bias: 0.0005755996098741889\n",
      "Gradient for decoder.decoder.3.weight: 0.012210231274366379\n",
      "Gradient for decoder.decoder.3.bias: 1.045404735000588e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0004451025160960853\n",
      "Gradient for decoder.decoder.4.bias: 0.0004378579033073038\n",
      "Gradient for decoder.decoder.6.weight: 0.0010531278094276786\n",
      "Gradient for decoder.decoder.6.bias: 7.030956476228312e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.06638112664222717\n",
      "Gradient for encoder.encoder.0.bias: 9.59111401410695e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.00893619004637003\n",
      "Gradient for encoder.encoder.1.bias: 0.006614847108721733\n",
      "Gradient for encoder.encoder.3.weight: 0.189876526594162\n",
      "Gradient for encoder.encoder.3.bias: 1.1285338219479968e-09\n",
      "Gradient for encoder.encoder.4.weight: 0.01555715687572956\n",
      "Gradient for encoder.encoder.4.bias: 0.014624853618443012\n",
      "Gradient for encoder.mean.weight: 0.20016437768936157\n",
      "Gradient for encoder.mean.bias: 0.009997009299695492\n",
      "Gradient for encoder.log_var.weight: 0.1166766881942749\n",
      "Gradient for encoder.log_var.bias: 0.004825758282095194\n",
      "Gradient for decoder.decoder.0.weight: 0.019122842699289322\n",
      "Gradient for decoder.decoder.0.bias: 1.475157634933666e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0009552362025715411\n",
      "Gradient for decoder.decoder.1.bias: 0.0007018550531938672\n",
      "Gradient for decoder.decoder.3.weight: 0.014512169174849987\n",
      "Gradient for decoder.decoder.3.bias: 1.1408025218928586e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.000578187289647758\n",
      "Gradient for decoder.decoder.4.bias: 0.0005383971147239208\n",
      "Gradient for decoder.decoder.6.weight: 0.001090319943614304\n",
      "Gradient for decoder.decoder.6.bias: 6.0303937061689794e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.05427415668964386\n",
      "Gradient for encoder.encoder.0.bias: 8.703943121801672e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.008306063711643219\n",
      "Gradient for encoder.encoder.1.bias: 0.006254703737795353\n",
      "Gradient for encoder.encoder.3.weight: 0.1848745197057724\n",
      "Gradient for encoder.encoder.3.bias: 9.873757367273583e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.015360088087618351\n",
      "Gradient for encoder.encoder.4.bias: 0.0137491999194026\n",
      "Gradient for encoder.mean.weight: 0.19894713163375854\n",
      "Gradient for encoder.mean.bias: 0.007865050807595253\n",
      "Gradient for encoder.log_var.weight: 0.11198703199625015\n",
      "Gradient for encoder.log_var.bias: 0.003919263835996389\n",
      "Gradient for decoder.decoder.0.weight: 0.01934528537094593\n",
      "Gradient for decoder.decoder.0.bias: 1.4895526478930776e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0010550859151408076\n",
      "Gradient for decoder.decoder.1.bias: 0.0006997251766733825\n",
      "Gradient for decoder.decoder.3.weight: 0.015764862298965454\n",
      "Gradient for decoder.decoder.3.bias: 1.247654340952309e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0006165235536172986\n",
      "Gradient for decoder.decoder.4.bias: 0.000617878045886755\n",
      "Gradient for decoder.decoder.6.weight: 0.0010868784738704562\n",
      "Gradient for decoder.decoder.6.bias: 6.235965702217072e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.06962238997220993\n",
      "Gradient for encoder.encoder.0.bias: 1.3678086441260007e-10\n",
      "Gradient for encoder.encoder.1.weight: 0.011399590410292149\n",
      "Gradient for encoder.encoder.1.bias: 0.008329171687364578\n",
      "Gradient for encoder.encoder.3.weight: 0.2522842586040497\n",
      "Gradient for encoder.encoder.3.bias: 1.2563371454277217e-09\n",
      "Gradient for encoder.encoder.4.weight: 0.023207060992717743\n",
      "Gradient for encoder.encoder.4.bias: 0.020161764696240425\n",
      "Gradient for encoder.mean.weight: 0.2822291851043701\n",
      "Gradient for encoder.mean.bias: 0.011797568760812283\n",
      "Gradient for encoder.log_var.weight: 0.16613611578941345\n",
      "Gradient for encoder.log_var.bias: 0.0058677042834460735\n",
      "Gradient for decoder.decoder.0.weight: 0.016997339203953743\n",
      "Gradient for decoder.decoder.0.bias: 1.3560891298780575e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0008986075408756733\n",
      "Gradient for decoder.decoder.1.bias: 0.0006248541176319122\n",
      "Gradient for decoder.decoder.3.weight: 0.013137252070009708\n",
      "Gradient for decoder.decoder.3.bias: 9.79537978507139e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00045756527106277645\n",
      "Gradient for decoder.decoder.4.bias: 0.000399650598410517\n",
      "Gradient for decoder.decoder.6.weight: 0.0010460451012477279\n",
      "Gradient for decoder.decoder.6.bias: 6.0584236052818596e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.05996571481227875\n",
      "Gradient for encoder.encoder.0.bias: 9.556433422375221e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.008963525295257568\n",
      "Gradient for encoder.encoder.1.bias: 0.006753304973244667\n",
      "Gradient for encoder.encoder.3.weight: 0.1896228790283203\n",
      "Gradient for encoder.encoder.3.bias: 8.762446879195807e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.012108175083994865\n",
      "Gradient for encoder.encoder.4.bias: 0.01276810560375452\n",
      "Gradient for encoder.mean.weight: 0.17070519924163818\n",
      "Gradient for encoder.mean.bias: 0.008704458363354206\n",
      "Gradient for encoder.log_var.weight: 0.08624481409788132\n",
      "Gradient for encoder.log_var.bias: 0.00503186322748661\n",
      "Gradient for decoder.decoder.0.weight: 0.01671675778925419\n",
      "Gradient for decoder.decoder.0.bias: 1.445855241088978e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0009563484345562756\n",
      "Gradient for decoder.decoder.1.bias: 0.0006115296273492277\n",
      "Gradient for decoder.decoder.3.weight: 0.013368303887546062\n",
      "Gradient for decoder.decoder.3.bias: 1.2041577457377883e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0006376173696480691\n",
      "Gradient for decoder.decoder.4.bias: 0.0007065410609357059\n",
      "Gradient for decoder.decoder.6.weight: 0.0010860044276341796\n",
      "Gradient for decoder.decoder.6.bias: 7.652649946976453e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.05633160471916199\n",
      "Gradient for encoder.encoder.0.bias: 8.614666618944611e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.007212263066321611\n",
      "Gradient for encoder.encoder.1.bias: 0.005091387312859297\n",
      "Gradient for encoder.encoder.3.weight: 0.1580619513988495\n",
      "Gradient for encoder.encoder.3.bias: 8.160316866678841e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.012603373266756535\n",
      "Gradient for encoder.encoder.4.bias: 0.011372929438948631\n",
      "Gradient for encoder.mean.weight: 0.16271890699863434\n",
      "Gradient for encoder.mean.bias: 0.007292560301721096\n",
      "Gradient for encoder.log_var.weight: 0.08938701450824738\n",
      "Gradient for encoder.log_var.bias: 0.004197228699922562\n",
      "Gradient for decoder.decoder.0.weight: 0.016941945999860764\n",
      "Gradient for decoder.decoder.0.bias: 1.5270851250193118e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0009180590277537704\n",
      "Gradient for decoder.decoder.1.bias: 0.0006463562604039907\n",
      "Gradient for decoder.decoder.3.weight: 0.013709322549402714\n",
      "Gradient for decoder.decoder.3.bias: 1.1779453801263884e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0006689656875096262\n",
      "Gradient for decoder.decoder.4.bias: 0.0006910532247275114\n",
      "Gradient for decoder.decoder.6.weight: 0.001124309259466827\n",
      "Gradient for decoder.decoder.6.bias: 6.920012674527243e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.059388063848018646\n",
      "Gradient for encoder.encoder.0.bias: 8.589416677917683e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.009120897389948368\n",
      "Gradient for encoder.encoder.1.bias: 0.006912559736520052\n",
      "Gradient for encoder.encoder.3.weight: 0.19888663291931152\n",
      "Gradient for encoder.encoder.3.bias: 8.888360047976107e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.013469313271343708\n",
      "Gradient for encoder.encoder.4.bias: 0.012552520260214806\n",
      "Gradient for encoder.mean.weight: 0.19204898178577423\n",
      "Gradient for encoder.mean.bias: 0.008884389884769917\n",
      "Gradient for encoder.log_var.weight: 0.09771199524402618\n",
      "Gradient for encoder.log_var.bias: 0.004311064258217812\n",
      "Gradient for decoder.decoder.0.weight: 0.01915033534169197\n",
      "Gradient for decoder.decoder.0.bias: 1.669426402672869e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0010477518662810326\n",
      "Gradient for decoder.decoder.1.bias: 0.0007079660426825285\n",
      "Gradient for decoder.decoder.3.weight: 0.015421643853187561\n",
      "Gradient for decoder.decoder.3.bias: 1.281213884984922e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0007886883686296642\n",
      "Gradient for decoder.decoder.4.bias: 0.0007817705045454204\n",
      "Gradient for decoder.decoder.6.weight: 0.0013933939626440406\n",
      "Gradient for decoder.decoder.6.bias: 9.67369123827666e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.06537753343582153\n",
      "Gradient for encoder.encoder.0.bias: 9.268374956405978e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.010452719405293465\n",
      "Gradient for encoder.encoder.1.bias: 0.007710072677582502\n",
      "Gradient for encoder.encoder.3.weight: 0.2288757860660553\n",
      "Gradient for encoder.encoder.3.bias: 9.428762215435427e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.016812549903988838\n",
      "Gradient for encoder.encoder.4.bias: 0.014678074978291988\n",
      "Gradient for encoder.mean.weight: 0.23291489481925964\n",
      "Gradient for encoder.mean.bias: 0.008260536007583141\n",
      "Gradient for encoder.log_var.weight: 0.11561433970928192\n",
      "Gradient for encoder.log_var.bias: 0.0049417950212955475\n",
      "Gradient for decoder.decoder.0.weight: 0.020381730049848557\n",
      "Gradient for decoder.decoder.0.bias: 1.7608517421940917e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0010499529307708144\n",
      "Gradient for decoder.decoder.1.bias: 0.0007498527993448079\n",
      "Gradient for decoder.decoder.3.weight: 0.015923865139484406\n",
      "Gradient for decoder.decoder.3.bias: 1.3354817252064777e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0006280733505263925\n",
      "Gradient for decoder.decoder.4.bias: 0.0006544533534906805\n",
      "Gradient for decoder.decoder.6.weight: 0.0010700860293582082\n",
      "Gradient for decoder.decoder.6.bias: 6.834333908045664e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.06355348974466324\n",
      "Gradient for encoder.encoder.0.bias: 9.879047579985922e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.010301146656274796\n",
      "Gradient for encoder.encoder.1.bias: 0.007314971182495356\n",
      "Gradient for encoder.encoder.3.weight: 0.21956337988376617\n",
      "Gradient for encoder.encoder.3.bias: 1.0448641951654736e-09\n",
      "Gradient for encoder.encoder.4.weight: 0.017958512529730797\n",
      "Gradient for encoder.encoder.4.bias: 0.015423598699271679\n",
      "Gradient for encoder.mean.weight: 0.22450119256973267\n",
      "Gradient for encoder.mean.bias: 0.008516578935086727\n",
      "Gradient for encoder.log_var.weight: 0.12552306056022644\n",
      "Gradient for encoder.log_var.bias: 0.00508253276348114\n",
      "Gradient for decoder.decoder.0.weight: 0.019420817494392395\n",
      "Gradient for decoder.decoder.0.bias: 1.5946539921873892e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0009775049984455109\n",
      "Gradient for decoder.decoder.1.bias: 0.0007027348037809134\n",
      "Gradient for decoder.decoder.3.weight: 0.015151593834161758\n",
      "Gradient for decoder.decoder.3.bias: 1.1831453872179765e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0007038720650598407\n",
      "Gradient for decoder.decoder.4.bias: 0.0006139564793556929\n",
      "Gradient for decoder.decoder.6.weight: 0.0010720535647124052\n",
      "Gradient for decoder.decoder.6.bias: 5.1307732064742595e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.05426505208015442\n",
      "Gradient for encoder.encoder.0.bias: 9.52093126560527e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.009258264675736427\n",
      "Gradient for encoder.encoder.1.bias: 0.0072374530136585236\n",
      "Gradient for encoder.encoder.3.weight: 0.19523943960666656\n",
      "Gradient for encoder.encoder.3.bias: 9.93661597448181e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.01495648268610239\n",
      "Gradient for encoder.encoder.4.bias: 0.014222471974790096\n",
      "Gradient for encoder.mean.weight: 0.1990123838186264\n",
      "Gradient for encoder.mean.bias: 0.007870081812143326\n",
      "Gradient for encoder.log_var.weight: 0.09523727744817734\n",
      "Gradient for encoder.log_var.bias: 0.003939008805900812\n",
      "Gradient for decoder.decoder.0.weight: 0.019571194425225258\n",
      "Gradient for decoder.decoder.0.bias: 1.7272427932368828e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0010564655531197786\n",
      "Gradient for decoder.decoder.1.bias: 0.0007160118548199534\n",
      "Gradient for decoder.decoder.3.weight: 0.015155641362071037\n",
      "Gradient for decoder.decoder.3.bias: 1.3884006444531138e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0006439918652176857\n",
      "Gradient for decoder.decoder.4.bias: 0.000585509289521724\n",
      "Gradient for decoder.decoder.6.weight: 0.0011868427973240614\n",
      "Gradient for decoder.decoder.6.bias: 6.83902035234496e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training VAE Epoch:  62%|██████▏   | 49/79 [00:00<00:00, 73.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient for encoder.encoder.0.weight: 0.05303256958723068\n",
      "Gradient for encoder.encoder.0.bias: 6.940337193839241e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0082811014726758\n",
      "Gradient for encoder.encoder.1.bias: 0.006085655651986599\n",
      "Gradient for encoder.encoder.3.weight: 0.17660261690616608\n",
      "Gradient for encoder.encoder.3.bias: 1.01407193753289e-09\n",
      "Gradient for encoder.encoder.4.weight: 0.014808068983256817\n",
      "Gradient for encoder.encoder.4.bias: 0.015052549540996552\n",
      "Gradient for encoder.mean.weight: 0.19542676210403442\n",
      "Gradient for encoder.mean.bias: 0.010747029446065426\n",
      "Gradient for encoder.log_var.weight: 0.09783999621868134\n",
      "Gradient for encoder.log_var.bias: 0.005112088285386562\n",
      "Gradient for decoder.decoder.0.weight: 0.019757920876145363\n",
      "Gradient for decoder.decoder.0.bias: 1.8183768379920195e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0010883989743888378\n",
      "Gradient for decoder.decoder.1.bias: 0.0007168398587964475\n",
      "Gradient for decoder.decoder.3.weight: 0.01608164794743061\n",
      "Gradient for decoder.decoder.3.bias: 1.3867054726723893e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0006503869080916047\n",
      "Gradient for decoder.decoder.4.bias: 0.0006631166324950755\n",
      "Gradient for decoder.decoder.6.weight: 0.0012240475043654442\n",
      "Gradient for decoder.decoder.6.bias: 8.442729449598119e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.07621387392282486\n",
      "Gradient for encoder.encoder.0.bias: 1.4754357458013345e-10\n",
      "Gradient for encoder.encoder.1.weight: 0.010736306197941303\n",
      "Gradient for encoder.encoder.1.bias: 0.007430861704051495\n",
      "Gradient for encoder.encoder.3.weight: 0.23678095638751984\n",
      "Gradient for encoder.encoder.3.bias: 9.86319248497125e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.019102290272712708\n",
      "Gradient for encoder.encoder.4.bias: 0.016153128817677498\n",
      "Gradient for encoder.mean.weight: 0.2517564296722412\n",
      "Gradient for encoder.mean.bias: 0.010244273580610752\n",
      "Gradient for encoder.log_var.weight: 0.12442765384912491\n",
      "Gradient for encoder.log_var.bias: 0.005411166697740555\n",
      "Gradient for decoder.decoder.0.weight: 0.013620312325656414\n",
      "Gradient for decoder.decoder.0.bias: 1.1643380704029482e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0007781567983329296\n",
      "Gradient for decoder.decoder.1.bias: 0.0005263189086690545\n",
      "Gradient for decoder.decoder.3.weight: 0.011076248250901699\n",
      "Gradient for decoder.decoder.3.bias: 9.339482659465048e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0004480330098886043\n",
      "Gradient for decoder.decoder.4.bias: 0.0004577209474518895\n",
      "Gradient for decoder.decoder.6.weight: 0.00099541328381747\n",
      "Gradient for decoder.decoder.6.bias: 5.583434540312737e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training VAE Epoch:  72%|███████▏  | 57/79 [00:00<00:00, 73.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient for encoder.encoder.0.weight: 0.05146123468875885\n",
      "Gradient for encoder.encoder.0.bias: 7.14724598949168e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.007327503990381956\n",
      "Gradient for encoder.encoder.1.bias: 0.0057121929712593555\n",
      "Gradient for encoder.encoder.3.weight: 0.16267244517803192\n",
      "Gradient for encoder.encoder.3.bias: 8.747793045493779e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.014819779433310032\n",
      "Gradient for encoder.encoder.4.bias: 0.01427406631410122\n",
      "Gradient for encoder.mean.weight: 0.1824268400669098\n",
      "Gradient for encoder.mean.bias: 0.00986521877348423\n",
      "Gradient for encoder.log_var.weight: 0.10705340653657913\n",
      "Gradient for encoder.log_var.bias: 0.005257440730929375\n",
      "Gradient for decoder.decoder.0.weight: 0.021781807765364647\n",
      "Gradient for decoder.decoder.0.bias: 1.807795163566439e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0011626625200733542\n",
      "Gradient for decoder.decoder.1.bias: 0.0008251104736700654\n",
      "Gradient for decoder.decoder.3.weight: 0.01662619039416313\n",
      "Gradient for decoder.decoder.3.bias: 1.2409938354718264e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0006031296215951443\n",
      "Gradient for decoder.decoder.4.bias: 0.0005200689192861319\n",
      "Gradient for decoder.decoder.6.weight: 0.0010506458347663283\n",
      "Gradient for decoder.decoder.6.bias: 5.598588541033678e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.05924994871020317\n",
      "Gradient for encoder.encoder.0.bias: 8.210936791597234e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.007715091109275818\n",
      "Gradient for encoder.encoder.1.bias: 0.005949454847723246\n",
      "Gradient for encoder.encoder.3.weight: 0.16464218497276306\n",
      "Gradient for encoder.encoder.3.bias: 8.983082611102589e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.012718360871076584\n",
      "Gradient for encoder.encoder.4.bias: 0.01271918322890997\n",
      "Gradient for encoder.mean.weight: 0.16324111819267273\n",
      "Gradient for encoder.mean.bias: 0.009759815409779549\n",
      "Gradient for encoder.log_var.weight: 0.08433567732572556\n",
      "Gradient for encoder.log_var.bias: 0.005329083651304245\n",
      "Gradient for decoder.decoder.0.weight: 0.02010222151875496\n",
      "Gradient for decoder.decoder.0.bias: 1.7908143024047973e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0010235506342723966\n",
      "Gradient for decoder.decoder.1.bias: 0.0006910271476954222\n",
      "Gradient for decoder.decoder.3.weight: 0.01559818908572197\n",
      "Gradient for decoder.decoder.3.bias: 1.3394491071849757e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0007458634208887815\n",
      "Gradient for decoder.decoder.4.bias: 0.0007954245083965361\n",
      "Gradient for decoder.decoder.6.weight: 0.0011903161648660898\n",
      "Gradient for decoder.decoder.6.bias: 7.959060894791037e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.07868693023920059\n",
      "Gradient for encoder.encoder.0.bias: 1.143122679847508e-10\n",
      "Gradient for encoder.encoder.1.weight: 0.010150978341698647\n",
      "Gradient for encoder.encoder.1.bias: 0.00725101912394166\n",
      "Gradient for encoder.encoder.3.weight: 0.21532753109931946\n",
      "Gradient for encoder.encoder.3.bias: 1.1114725806393722e-09\n",
      "Gradient for encoder.encoder.4.weight: 0.01660930924117565\n",
      "Gradient for encoder.encoder.4.bias: 0.014076992869377136\n",
      "Gradient for encoder.mean.weight: 0.21019034087657928\n",
      "Gradient for encoder.mean.bias: 0.00863796565681696\n",
      "Gradient for encoder.log_var.weight: 0.11512944847345352\n",
      "Gradient for encoder.log_var.bias: 0.004544066730886698\n",
      "Gradient for decoder.decoder.0.weight: 0.016636889427900314\n",
      "Gradient for decoder.decoder.0.bias: 1.3911390095433518e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0008874615887179971\n",
      "Gradient for decoder.decoder.1.bias: 0.0006186904502101243\n",
      "Gradient for decoder.decoder.3.weight: 0.012700307182967663\n",
      "Gradient for decoder.decoder.3.bias: 1.0616257178908128e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0005003925762139261\n",
      "Gradient for decoder.decoder.4.bias: 0.0004754969268105924\n",
      "Gradient for decoder.decoder.6.weight: 0.0010489337146282196\n",
      "Gradient for decoder.decoder.6.bias: 5.549969500862062e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.060760024935007095\n",
      "Gradient for encoder.encoder.0.bias: 9.24962398340945e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.010717729106545448\n",
      "Gradient for encoder.encoder.1.bias: 0.008182233199477196\n",
      "Gradient for encoder.encoder.3.weight: 0.2282124012708664\n",
      "Gradient for encoder.encoder.3.bias: 1.4178466178904614e-09\n",
      "Gradient for encoder.encoder.4.weight: 0.020951543003320694\n",
      "Gradient for encoder.encoder.4.bias: 0.02734874002635479\n",
      "Gradient for encoder.mean.weight: 0.2640484571456909\n",
      "Gradient for encoder.mean.bias: 0.020272180438041687\n",
      "Gradient for encoder.log_var.weight: 0.14795194566249847\n",
      "Gradient for encoder.log_var.bias: 0.0134733309969306\n",
      "Gradient for decoder.decoder.0.weight: 0.018677767366170883\n",
      "Gradient for decoder.decoder.0.bias: 1.6476654762787035e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0010039771441370249\n",
      "Gradient for decoder.decoder.1.bias: 0.0006946176872588694\n",
      "Gradient for decoder.decoder.3.weight: 0.015001530759036541\n",
      "Gradient for decoder.decoder.3.bias: 1.1661505094906488e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0005477016675285995\n",
      "Gradient for decoder.decoder.4.bias: 0.0005182967870496213\n",
      "Gradient for decoder.decoder.6.weight: 0.0010562943061813712\n",
      "Gradient for decoder.decoder.6.bias: 6.102257611928508e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.0861356258392334\n",
      "Gradient for encoder.encoder.0.bias: 1.4698649242195216e-10\n",
      "Gradient for encoder.encoder.1.weight: 0.011535190045833588\n",
      "Gradient for encoder.encoder.1.bias: 0.008630302734673023\n",
      "Gradient for encoder.encoder.3.weight: 0.2479274570941925\n",
      "Gradient for encoder.encoder.3.bias: 1.161137297422954e-09\n",
      "Gradient for encoder.encoder.4.weight: 0.019380761310458183\n",
      "Gradient for encoder.encoder.4.bias: 0.017856847494840622\n",
      "Gradient for encoder.mean.weight: 0.26551002264022827\n",
      "Gradient for encoder.mean.bias: 0.01256572175770998\n",
      "Gradient for encoder.log_var.weight: 0.14408273994922638\n",
      "Gradient for encoder.log_var.bias: 0.006126393098384142\n",
      "Gradient for decoder.decoder.0.weight: 0.01328511256724596\n",
      "Gradient for decoder.decoder.0.bias: 1.2617400180214844e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0006961869657970965\n",
      "Gradient for decoder.decoder.1.bias: 0.0005316248862072825\n",
      "Gradient for decoder.decoder.3.weight: 0.010352786630392075\n",
      "Gradient for decoder.decoder.3.bias: 1.012415568046876e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0005968376062810421\n",
      "Gradient for decoder.decoder.4.bias: 0.0006578885950148106\n",
      "Gradient for decoder.decoder.6.weight: 0.0010964066023007035\n",
      "Gradient for decoder.decoder.6.bias: 7.41550320526585e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.05115148425102234\n",
      "Gradient for encoder.encoder.0.bias: 7.581626992880786e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0075083645060658455\n",
      "Gradient for encoder.encoder.1.bias: 0.005717129912227392\n",
      "Gradient for encoder.encoder.3.weight: 0.16724447906017303\n",
      "Gradient for encoder.encoder.3.bias: 8.446403576556349e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.012484152801334858\n",
      "Gradient for encoder.encoder.4.bias: 0.012815280817449093\n",
      "Gradient for encoder.mean.weight: 0.16336479783058167\n",
      "Gradient for encoder.mean.bias: 0.009246650151908398\n",
      "Gradient for encoder.log_var.weight: 0.07882584631443024\n",
      "Gradient for encoder.log_var.bias: 0.005164723843336105\n",
      "Gradient for decoder.decoder.0.weight: 0.01949380896985531\n",
      "Gradient for decoder.decoder.0.bias: 1.5720436064015075e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.001049047103151679\n",
      "Gradient for decoder.decoder.1.bias: 0.0006969505921006203\n",
      "Gradient for decoder.decoder.3.weight: 0.015399225056171417\n",
      "Gradient for decoder.decoder.3.bias: 1.2395681703303296e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0005660408642143011\n",
      "Gradient for decoder.decoder.4.bias: 0.0005071985651738942\n",
      "Gradient for decoder.decoder.6.weight: 0.0010104546090587974\n",
      "Gradient for decoder.decoder.6.bias: 3.90399873140268e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.06204911693930626\n",
      "Gradient for encoder.encoder.0.bias: 8.293283421112463e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.008060106076300144\n",
      "Gradient for encoder.encoder.1.bias: 0.0062699634581804276\n",
      "Gradient for encoder.encoder.3.weight: 0.18003380298614502\n",
      "Gradient for encoder.encoder.3.bias: 8.183234090353153e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.012636369094252586\n",
      "Gradient for encoder.encoder.4.bias: 0.012547391466796398\n",
      "Gradient for encoder.mean.weight: 0.16719982028007507\n",
      "Gradient for encoder.mean.bias: 0.008552834391593933\n",
      "Gradient for encoder.log_var.weight: 0.09792447090148926\n",
      "Gradient for encoder.log_var.bias: 0.005579112563282251\n",
      "Gradient for decoder.decoder.0.weight: 0.0164666548371315\n",
      "Gradient for decoder.decoder.0.bias: 1.3619302907663666e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0008353501325473189\n",
      "Gradient for decoder.decoder.1.bias: 0.0005564490566030145\n",
      "Gradient for decoder.decoder.3.weight: 0.012852245941758156\n",
      "Gradient for decoder.decoder.3.bias: 1.1932711763140702e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.000648485089186579\n",
      "Gradient for decoder.decoder.4.bias: 0.0007478274055756629\n",
      "Gradient for decoder.decoder.6.weight: 0.0011086942395195365\n",
      "Gradient for decoder.decoder.6.bias: 7.04622216289863e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.05325116589665413\n",
      "Gradient for encoder.encoder.0.bias: 6.924359002846714e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.005548762157559395\n",
      "Gradient for encoder.encoder.1.bias: 0.004944413434714079\n",
      "Gradient for encoder.encoder.3.weight: 0.12934036552906036\n",
      "Gradient for encoder.encoder.3.bias: 8.376108140417671e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.009959986433386803\n",
      "Gradient for encoder.encoder.4.bias: 0.010024837218225002\n",
      "Gradient for encoder.mean.weight: 0.12938855588436127\n",
      "Gradient for encoder.mean.bias: 0.006994200404733419\n",
      "Gradient for encoder.log_var.weight: 0.06933890283107758\n",
      "Gradient for encoder.log_var.bias: 0.004060405306518078\n",
      "Gradient for decoder.decoder.0.weight: 0.017623551189899445\n",
      "Gradient for decoder.decoder.0.bias: 1.5428489041902083e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0008683936903253198\n",
      "Gradient for decoder.decoder.1.bias: 0.0006426613545045257\n",
      "Gradient for decoder.decoder.3.weight: 0.01368358451873064\n",
      "Gradient for decoder.decoder.3.bias: 1.2261772153188133e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0005752017023041844\n",
      "Gradient for decoder.decoder.4.bias: 0.0005932216299697757\n",
      "Gradient for decoder.decoder.6.weight: 0.001267717219889164\n",
      "Gradient for decoder.decoder.6.bias: 8.795902249403298e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.06470618396997452\n",
      "Gradient for encoder.encoder.0.bias: 1.1822541556849586e-10\n",
      "Gradient for encoder.encoder.1.weight: 0.009334107860922813\n",
      "Gradient for encoder.encoder.1.bias: 0.007128911558538675\n",
      "Gradient for encoder.encoder.3.weight: 0.19440694153308868\n",
      "Gradient for encoder.encoder.3.bias: 1.1056204840542705e-09\n",
      "Gradient for encoder.encoder.4.weight: 0.016146523877978325\n",
      "Gradient for encoder.encoder.4.bias: 0.014483417384326458\n",
      "Gradient for encoder.mean.weight: 0.20990563929080963\n",
      "Gradient for encoder.mean.bias: 0.008515270426869392\n",
      "Gradient for encoder.log_var.weight: 0.10373181104660034\n",
      "Gradient for encoder.log_var.bias: 0.0045941779389977455\n",
      "Gradient for decoder.decoder.0.weight: 0.015389153733849525\n",
      "Gradient for decoder.decoder.0.bias: 1.619001183117419e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0008385186083614826\n",
      "Gradient for decoder.decoder.1.bias: 0.0005271330592222512\n",
      "Gradient for decoder.decoder.3.weight: 0.01187521405518055\n",
      "Gradient for decoder.decoder.3.bias: 1.14601744760634e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0003839077253360301\n",
      "Gradient for decoder.decoder.4.bias: 0.00033704706584103405\n",
      "Gradient for decoder.decoder.6.weight: 0.0010454580187797546\n",
      "Gradient for decoder.decoder.6.bias: 6.003534872434102e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.06763598322868347\n",
      "Gradient for encoder.encoder.0.bias: 1.0443706316420887e-10\n",
      "Gradient for encoder.encoder.1.weight: 0.010551037266850471\n",
      "Gradient for encoder.encoder.1.bias: 0.008101977407932281\n",
      "Gradient for encoder.encoder.3.weight: 0.2364974468946457\n",
      "Gradient for encoder.encoder.3.bias: 1.0486467250103715e-09\n",
      "Gradient for encoder.encoder.4.weight: 0.021897591650485992\n",
      "Gradient for encoder.encoder.4.bias: 0.01800648123025894\n",
      "Gradient for encoder.mean.weight: 0.2766801118850708\n",
      "Gradient for encoder.mean.bias: 0.010830160230398178\n",
      "Gradient for encoder.log_var.weight: 0.152568981051445\n",
      "Gradient for encoder.log_var.bias: 0.005899038165807724\n",
      "Gradient for decoder.decoder.0.weight: 0.018306398764252663\n",
      "Gradient for decoder.decoder.0.bias: 1.5683279674938433e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0009719035006128252\n",
      "Gradient for decoder.decoder.1.bias: 0.0006666897097602487\n",
      "Gradient for decoder.decoder.3.weight: 0.014190224930644035\n",
      "Gradient for decoder.decoder.3.bias: 9.948598889142346e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0005016347859054804\n",
      "Gradient for decoder.decoder.4.bias: 0.0004610363394021988\n",
      "Gradient for decoder.decoder.6.weight: 0.0010607122676447034\n",
      "Gradient for decoder.decoder.6.bias: 5.2113551646471024e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.05249219760298729\n",
      "Gradient for encoder.encoder.0.bias: 7.810136565256087e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0065901936031877995\n",
      "Gradient for encoder.encoder.1.bias: 0.005231930874288082\n",
      "Gradient for encoder.encoder.3.weight: 0.139421746134758\n",
      "Gradient for encoder.encoder.3.bias: 7.867865248201156e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.01033816672861576\n",
      "Gradient for encoder.encoder.4.bias: 0.01095765084028244\n",
      "Gradient for encoder.mean.weight: 0.1386331021785736\n",
      "Gradient for encoder.mean.bias: 0.006863136310130358\n",
      "Gradient for encoder.log_var.weight: 0.07530711591243744\n",
      "Gradient for encoder.log_var.bias: 0.0041291075758636\n",
      "Gradient for decoder.decoder.0.weight: 0.01669025607407093\n",
      "Gradient for decoder.decoder.0.bias: 1.4882557686224374e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0009192477446049452\n",
      "Gradient for decoder.decoder.1.bias: 0.0006419666460715234\n",
      "Gradient for decoder.decoder.3.weight: 0.012986838817596436\n",
      "Gradient for decoder.decoder.3.bias: 1.0484645096564549e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0005231335526332259\n",
      "Gradient for decoder.decoder.4.bias: 0.000543366651982069\n",
      "Gradient for decoder.decoder.6.weight: 0.0010493554873391986\n",
      "Gradient for decoder.decoder.6.bias: 6.237342313397676e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.044972941279411316\n",
      "Gradient for encoder.encoder.0.bias: 7.346846742084523e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.006267777644097805\n",
      "Gradient for encoder.encoder.1.bias: 0.004594685509800911\n",
      "Gradient for encoder.encoder.3.weight: 0.13968577980995178\n",
      "Gradient for encoder.encoder.3.bias: 9.013546575786791e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.01185554638504982\n",
      "Gradient for encoder.encoder.4.bias: 0.010407822206616402\n",
      "Gradient for encoder.mean.weight: 0.148798406124115\n",
      "Gradient for encoder.mean.bias: 0.0066988770850002766\n",
      "Gradient for encoder.log_var.weight: 0.08309070020914078\n",
      "Gradient for encoder.log_var.bias: 0.0036351759918034077\n",
      "Gradient for decoder.decoder.0.weight: 0.019034914672374725\n",
      "Gradient for decoder.decoder.0.bias: 1.5167003764027243e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0010909403208643198\n",
      "Gradient for decoder.decoder.1.bias: 0.0006673185271210968\n",
      "Gradient for decoder.decoder.3.weight: 0.015370744280517101\n",
      "Gradient for decoder.decoder.3.bias: 1.0839006775453797e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0005571027286350727\n",
      "Gradient for decoder.decoder.4.bias: 0.0004946023691445589\n",
      "Gradient for decoder.decoder.6.weight: 0.0010646154405549169\n",
      "Gradient for decoder.decoder.6.bias: 5.3582883992930874e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.05617862194776535\n",
      "Gradient for encoder.encoder.0.bias: 9.665795247526532e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.008176548406481743\n",
      "Gradient for encoder.encoder.1.bias: 0.0060113463550806046\n",
      "Gradient for encoder.encoder.3.weight: 0.17599119246006012\n",
      "Gradient for encoder.encoder.3.bias: 8.41031855269847e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.013069599866867065\n",
      "Gradient for encoder.encoder.4.bias: 0.012655451893806458\n",
      "Gradient for encoder.mean.weight: 0.17083700001239777\n",
      "Gradient for encoder.mean.bias: 0.00952726136893034\n",
      "Gradient for encoder.log_var.weight: 0.09465228766202927\n",
      "Gradient for encoder.log_var.bias: 0.004613919649273157\n",
      "Gradient for decoder.decoder.0.weight: 0.015020637772977352\n",
      "Gradient for decoder.decoder.0.bias: 1.1881168271443698e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0007674473454244435\n",
      "Gradient for decoder.decoder.1.bias: 0.0005532474024221301\n",
      "Gradient for decoder.decoder.3.weight: 0.012139894999563694\n",
      "Gradient for decoder.decoder.3.bias: 9.711584314509025e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0006241996306926012\n",
      "Gradient for decoder.decoder.4.bias: 0.0006628691335208714\n",
      "Gradient for decoder.decoder.6.weight: 0.0010520737851038575\n",
      "Gradient for decoder.decoder.6.bias: 6.233734166016802e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.04061655327677727\n",
      "Gradient for encoder.encoder.0.bias: 6.286809961508766e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.005158992018550634\n",
      "Gradient for encoder.encoder.1.bias: 0.004427479114383459\n",
      "Gradient for encoder.encoder.3.weight: 0.11325813084840775\n",
      "Gradient for encoder.encoder.3.bias: 6.734421353904452e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.009389531798660755\n",
      "Gradient for encoder.encoder.4.bias: 0.009542648680508137\n",
      "Gradient for encoder.mean.weight: 0.12655332684516907\n",
      "Gradient for encoder.mean.bias: 0.006563184317201376\n",
      "Gradient for encoder.log_var.weight: 0.07032430917024612\n",
      "Gradient for encoder.log_var.bias: 0.0037992126308381557\n",
      "Gradient for decoder.decoder.0.weight: 0.016731727868318558\n",
      "Gradient for decoder.decoder.0.bias: 1.49870296728416e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0008853776380419731\n",
      "Gradient for decoder.decoder.1.bias: 0.0006302057299762964\n",
      "Gradient for decoder.decoder.3.weight: 0.013545905239880085\n",
      "Gradient for decoder.decoder.3.bias: 1.1022893015022461e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0005067813326604664\n",
      "Gradient for decoder.decoder.4.bias: 0.0004649523471016437\n",
      "Gradient for decoder.decoder.6.weight: 0.000997690367512405\n",
      "Gradient for decoder.decoder.6.bias: 4.4689590140478685e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training VAE Epoch:  82%|████████▏ | 65/79 [00:01<00:00, 74.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient for encoder.encoder.0.weight: 0.06636301428079605\n",
      "Gradient for encoder.encoder.0.bias: 9.274844781081981e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.010757998563349247\n",
      "Gradient for encoder.encoder.1.bias: 0.007888400927186012\n",
      "Gradient for encoder.encoder.3.weight: 0.24433422088623047\n",
      "Gradient for encoder.encoder.3.bias: 1.2607404009656875e-09\n",
      "Gradient for encoder.encoder.4.weight: 0.02385788969695568\n",
      "Gradient for encoder.encoder.4.bias: 0.020549556240439415\n",
      "Gradient for encoder.mean.weight: 0.294200599193573\n",
      "Gradient for encoder.mean.bias: 0.01134067215025425\n",
      "Gradient for encoder.log_var.weight: 0.18382366001605988\n",
      "Gradient for encoder.log_var.bias: 0.007126744370907545\n",
      "Gradient for decoder.decoder.0.weight: 0.023022225126624107\n",
      "Gradient for decoder.decoder.0.bias: 2.0466703332111535e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0012171330163255334\n",
      "Gradient for decoder.decoder.1.bias: 0.0007710627978667617\n",
      "Gradient for decoder.decoder.3.weight: 0.018095023930072784\n",
      "Gradient for decoder.decoder.3.bias: 1.585001713211298e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0006194162997417152\n",
      "Gradient for decoder.decoder.4.bias: 0.0005391763406805694\n",
      "Gradient for decoder.decoder.6.weight: 0.0010825148783624172\n",
      "Gradient for decoder.decoder.6.bias: 5.8854078815784305e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.049049679189920425\n",
      "Gradient for encoder.encoder.0.bias: 7.964499199042407e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.005519120022654533\n",
      "Gradient for encoder.encoder.1.bias: 0.0042807720601558685\n",
      "Gradient for encoder.encoder.3.weight: 0.12401487678289413\n",
      "Gradient for encoder.encoder.3.bias: 9.28203847117004e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.013007156550884247\n",
      "Gradient for encoder.encoder.4.bias: 0.011961167678236961\n",
      "Gradient for encoder.mean.weight: 0.1568935066461563\n",
      "Gradient for encoder.mean.bias: 0.0073935491964221\n",
      "Gradient for encoder.log_var.weight: 0.09638342261314392\n",
      "Gradient for encoder.log_var.bias: 0.0036994796246290207\n",
      "Gradient for decoder.decoder.0.weight: 0.017668375745415688\n",
      "Gradient for decoder.decoder.0.bias: 1.5540255193791097e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.000997508061118424\n",
      "Gradient for decoder.decoder.1.bias: 0.0006521315663121641\n",
      "Gradient for decoder.decoder.3.weight: 0.014451186172664165\n",
      "Gradient for decoder.decoder.3.bias: 1.0554303264687093e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0005355782341212034\n",
      "Gradient for decoder.decoder.4.bias: 0.00047305860789492726\n",
      "Gradient for decoder.decoder.6.weight: 0.0010118902428075671\n",
      "Gradient for decoder.decoder.6.bias: 4.521594019024633e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training VAE Epoch:  92%|█████████▏| 73/79 [00:01<00:00, 76.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient for encoder.encoder.0.weight: 0.054002150893211365\n",
      "Gradient for encoder.encoder.0.bias: 9.509108778171793e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.007364755496382713\n",
      "Gradient for encoder.encoder.1.bias: 0.005359376780688763\n",
      "Gradient for encoder.encoder.3.weight: 0.15257152915000916\n",
      "Gradient for encoder.encoder.3.bias: 9.365125341886937e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.013494542799890041\n",
      "Gradient for encoder.encoder.4.bias: 0.015019089914858341\n",
      "Gradient for encoder.mean.weight: 0.16708984971046448\n",
      "Gradient for encoder.mean.bias: 0.010513397864997387\n",
      "Gradient for encoder.log_var.weight: 0.0988357812166214\n",
      "Gradient for encoder.log_var.bias: 0.00647752033546567\n",
      "Gradient for decoder.decoder.0.weight: 0.016500497236847878\n",
      "Gradient for decoder.decoder.0.bias: 1.423352824492241e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0008746756939217448\n",
      "Gradient for decoder.decoder.1.bias: 0.000618292426224798\n",
      "Gradient for decoder.decoder.3.weight: 0.01336434856057167\n",
      "Gradient for decoder.decoder.3.bias: 1.0585386039929645e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0004954650066792965\n",
      "Gradient for decoder.decoder.4.bias: 0.00046060909517109394\n",
      "Gradient for decoder.decoder.6.weight: 0.000986109604127705\n",
      "Gradient for decoder.decoder.6.bias: 5.549487468670122e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.06167750433087349\n",
      "Gradient for encoder.encoder.0.bias: 1.0362846691869265e-10\n",
      "Gradient for encoder.encoder.1.weight: 0.008347487077116966\n",
      "Gradient for encoder.encoder.1.bias: 0.006475050933659077\n",
      "Gradient for encoder.encoder.3.weight: 0.1854473352432251\n",
      "Gradient for encoder.encoder.3.bias: 1.1183401982250984e-09\n",
      "Gradient for encoder.encoder.4.weight: 0.017746493220329285\n",
      "Gradient for encoder.encoder.4.bias: 0.016545720398426056\n",
      "Gradient for encoder.mean.weight: 0.22815603017807007\n",
      "Gradient for encoder.mean.bias: 0.011596042662858963\n",
      "Gradient for encoder.log_var.weight: 0.11749685555696487\n",
      "Gradient for encoder.log_var.bias: 0.006645014975219965\n",
      "Gradient for decoder.decoder.0.weight: 0.017952319234609604\n",
      "Gradient for decoder.decoder.0.bias: 1.5225316840616898e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.00093748519429937\n",
      "Gradient for decoder.decoder.1.bias: 0.0006717530195601285\n",
      "Gradient for decoder.decoder.3.weight: 0.014057652093470097\n",
      "Gradient for decoder.decoder.3.bias: 1.1671978661365046e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0005051801563240588\n",
      "Gradient for decoder.decoder.4.bias: 0.00045182849862612784\n",
      "Gradient for decoder.decoder.6.weight: 0.0010356365237385035\n",
      "Gradient for decoder.decoder.6.bias: 5.8830722991842777e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.047738444060087204\n",
      "Gradient for encoder.encoder.0.bias: 8.02641147990002e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.006886892020702362\n",
      "Gradient for encoder.encoder.1.bias: 0.0051691546104848385\n",
      "Gradient for encoder.encoder.3.weight: 0.1518113613128662\n",
      "Gradient for encoder.encoder.3.bias: 7.906941212887375e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.013268867507576942\n",
      "Gradient for encoder.encoder.4.bias: 0.011908448301255703\n",
      "Gradient for encoder.mean.weight: 0.16977784037590027\n",
      "Gradient for encoder.mean.bias: 0.007664085831493139\n",
      "Gradient for encoder.log_var.weight: 0.08724472671747208\n",
      "Gradient for encoder.log_var.bias: 0.005205797962844372\n",
      "Gradient for decoder.decoder.0.weight: 0.016748087480664253\n",
      "Gradient for decoder.decoder.0.bias: 1.3701975665192379e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0009023539023473859\n",
      "Gradient for decoder.decoder.1.bias: 0.0005712422425858676\n",
      "Gradient for decoder.decoder.3.weight: 0.013560744002461433\n",
      "Gradient for decoder.decoder.3.bias: 1.2166723184492412e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0006774807698093355\n",
      "Gradient for decoder.decoder.4.bias: 0.0007697863038629293\n",
      "Gradient for decoder.decoder.6.weight: 0.0010810720268636942\n",
      "Gradient for decoder.decoder.6.bias: 7.815455319359899e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.048166677355766296\n",
      "Gradient for encoder.encoder.0.bias: 7.001964980046793e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.006470053922384977\n",
      "Gradient for encoder.encoder.1.bias: 0.00487976148724556\n",
      "Gradient for encoder.encoder.3.weight: 0.14899252355098724\n",
      "Gradient for encoder.encoder.3.bias: 1.0860543575574866e-09\n",
      "Gradient for encoder.encoder.4.weight: 0.015560263767838478\n",
      "Gradient for encoder.encoder.4.bias: 0.016987323760986328\n",
      "Gradient for encoder.mean.weight: 0.1938129961490631\n",
      "Gradient for encoder.mean.bias: 0.011178691871464252\n",
      "Gradient for encoder.log_var.weight: 0.13220615684986115\n",
      "Gradient for encoder.log_var.bias: 0.007346787955611944\n",
      "Gradient for decoder.decoder.0.weight: 0.02229112945497036\n",
      "Gradient for decoder.decoder.0.bias: 1.813207778367243e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0012128226226195693\n",
      "Gradient for decoder.decoder.1.bias: 0.0008194309775717556\n",
      "Gradient for decoder.decoder.3.weight: 0.0174664668738842\n",
      "Gradient for decoder.decoder.3.bias: 1.3509765528496587e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0007452032878063619\n",
      "Gradient for decoder.decoder.4.bias: 0.000756185851059854\n",
      "Gradient for decoder.decoder.6.weight: 0.001125072711147368\n",
      "Gradient for decoder.decoder.6.bias: 6.334148929454386e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.05531497672200203\n",
      "Gradient for encoder.encoder.0.bias: 8.883062341258352e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.00847018975764513\n",
      "Gradient for encoder.encoder.1.bias: 0.0064468695782125\n",
      "Gradient for encoder.encoder.3.weight: 0.18226833641529083\n",
      "Gradient for encoder.encoder.3.bias: 8.923832783835906e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.014194213785231113\n",
      "Gradient for encoder.encoder.4.bias: 0.013996372930705547\n",
      "Gradient for encoder.mean.weight: 0.19190613925457\n",
      "Gradient for encoder.mean.bias: 0.009939775802195072\n",
      "Gradient for encoder.log_var.weight: 0.10689501464366913\n",
      "Gradient for encoder.log_var.bias: 0.0052431197836995125\n",
      "Gradient for decoder.decoder.0.weight: 0.018203694373369217\n",
      "Gradient for decoder.decoder.0.bias: 1.5133704012182392e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.001005908357910812\n",
      "Gradient for decoder.decoder.1.bias: 0.0006492678076028824\n",
      "Gradient for decoder.decoder.3.weight: 0.01462617889046669\n",
      "Gradient for decoder.decoder.3.bias: 1.1971823532519466e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0006900168373249471\n",
      "Gradient for decoder.decoder.4.bias: 0.00078278046566993\n",
      "Gradient for decoder.decoder.6.weight: 0.0011088016908615828\n",
      "Gradient for decoder.decoder.6.bias: 7.49662722228095e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.03698515519499779\n",
      "Gradient for encoder.encoder.0.bias: 5.827260202151407e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.005860823672264814\n",
      "Gradient for encoder.encoder.1.bias: 0.004634948447346687\n",
      "Gradient for encoder.encoder.3.weight: 0.1203228011727333\n",
      "Gradient for encoder.encoder.3.bias: 7.313587513380071e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.010982031933963299\n",
      "Gradient for encoder.encoder.4.bias: 0.009763347916305065\n",
      "Gradient for encoder.mean.weight: 0.14774587750434875\n",
      "Gradient for encoder.mean.bias: 0.007622482255101204\n",
      "Gradient for encoder.log_var.weight: 0.07505756616592407\n",
      "Gradient for encoder.log_var.bias: 0.0035261514130979776\n",
      "Gradient for decoder.decoder.0.weight: 0.019592491909861565\n",
      "Gradient for decoder.decoder.0.bias: 1.921512116087598e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0010131209855899215\n",
      "Gradient for decoder.decoder.1.bias: 0.0007006659870967269\n",
      "Gradient for decoder.decoder.3.weight: 0.015427438542246819\n",
      "Gradient for decoder.decoder.3.bias: 1.2347102507082042e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0006038989522494376\n",
      "Gradient for decoder.decoder.4.bias: 0.0005916915833950043\n",
      "Gradient for decoder.decoder.6.weight: 0.0011246349895372987\n",
      "Gradient for decoder.decoder.6.bias: 6.978321471251547e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.06878172606229782\n",
      "Gradient for encoder.encoder.0.bias: 1.1107628705708805e-10\n",
      "Gradient for encoder.encoder.1.weight: 0.010319891385734081\n",
      "Gradient for encoder.encoder.1.bias: 0.007746520917862654\n",
      "Gradient for encoder.encoder.3.weight: 0.23598292469978333\n",
      "Gradient for encoder.encoder.3.bias: 1.2138303695508057e-09\n",
      "Gradient for encoder.encoder.4.weight: 0.025190340355038643\n",
      "Gradient for encoder.encoder.4.bias: 0.021932411938905716\n",
      "Gradient for encoder.mean.weight: 0.3143909275531769\n",
      "Gradient for encoder.mean.bias: 0.012249992229044437\n",
      "Gradient for encoder.log_var.weight: 0.17780336737632751\n",
      "Gradient for encoder.log_var.bias: 0.0075819590128958225\n",
      "Gradient for decoder.decoder.0.weight: 0.015351190231740475\n",
      "Gradient for decoder.decoder.0.bias: 1.268587179747982e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.000811667472589761\n",
      "Gradient for decoder.decoder.1.bias: 0.0005567141342908144\n",
      "Gradient for decoder.decoder.3.weight: 0.012187663465738297\n",
      "Gradient for decoder.decoder.3.bias: 9.576805320987702e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00045076219248585403\n",
      "Gradient for decoder.decoder.4.bias: 0.00039821170503273606\n",
      "Gradient for decoder.decoder.6.weight: 0.0009684207034297287\n",
      "Gradient for decoder.decoder.6.bias: 4.5059932745061815e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.04903727397322655\n",
      "Gradient for encoder.encoder.0.bias: 7.589258388396303e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.006757712922990322\n",
      "Gradient for encoder.encoder.1.bias: 0.005305441562086344\n",
      "Gradient for encoder.encoder.3.weight: 0.1495136320590973\n",
      "Gradient for encoder.encoder.3.bias: 8.09378231103608e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.013302583247423172\n",
      "Gradient for encoder.encoder.4.bias: 0.011099185794591904\n",
      "Gradient for encoder.mean.weight: 0.1716422587633133\n",
      "Gradient for encoder.mean.bias: 0.00806818064302206\n",
      "Gradient for encoder.log_var.weight: 0.10289951413869858\n",
      "Gradient for encoder.log_var.bias: 0.004788112826645374\n",
      "Gradient for decoder.decoder.0.weight: 0.018442241474986076\n",
      "Gradient for decoder.decoder.0.bias: 1.6655171686252856e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.001088712248019874\n",
      "Gradient for decoder.decoder.1.bias: 0.0007130186422728002\n",
      "Gradient for decoder.decoder.3.weight: 0.01510737556964159\n",
      "Gradient for decoder.decoder.3.bias: 1.4218001775923028e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0009544246131554246\n",
      "Gradient for decoder.decoder.4.bias: 0.0010041104396805167\n",
      "Gradient for decoder.decoder.6.weight: 0.0012961470056325197\n",
      "Gradient for decoder.decoder.6.bias: 8.820574294077232e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.07648800313472748\n",
      "Gradient for encoder.encoder.0.bias: 1.1068568284144931e-10\n",
      "Gradient for encoder.encoder.1.weight: 0.007962383329868317\n",
      "Gradient for encoder.encoder.1.bias: 0.00651065306738019\n",
      "Gradient for encoder.encoder.3.weight: 0.17863671481609344\n",
      "Gradient for encoder.encoder.3.bias: 1.113806935570949e-09\n",
      "Gradient for encoder.encoder.4.weight: 0.016878042370080948\n",
      "Gradient for encoder.encoder.4.bias: 0.013605019077658653\n",
      "Gradient for encoder.mean.weight: 0.21279284358024597\n",
      "Gradient for encoder.mean.bias: 0.008063482120633125\n",
      "Gradient for encoder.log_var.weight: 0.11559662967920303\n",
      "Gradient for encoder.log_var.bias: 0.005089762154966593\n",
      "Gradient for decoder.decoder.0.weight: 0.016156405210494995\n",
      "Gradient for decoder.decoder.0.bias: 1.4860557229212645e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0008933870121836662\n",
      "Gradient for decoder.decoder.1.bias: 0.0006068318034522235\n",
      "Gradient for decoder.decoder.3.weight: 0.012782606296241283\n",
      "Gradient for decoder.decoder.3.bias: 1.0681640988385865e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0004953416646458209\n",
      "Gradient for decoder.decoder.4.bias: 0.00042440250399522483\n",
      "Gradient for decoder.decoder.6.weight: 0.0010232424829155207\n",
      "Gradient for decoder.decoder.6.bias: 5.445552960736677e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.056568730622529984\n",
      "Gradient for encoder.encoder.0.bias: 8.592628691905801e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.006681791972368956\n",
      "Gradient for encoder.encoder.1.bias: 0.0051281871274113655\n",
      "Gradient for encoder.encoder.3.weight: 0.1443091183900833\n",
      "Gradient for encoder.encoder.3.bias: 8.922232397345908e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.01462558563798666\n",
      "Gradient for encoder.encoder.4.bias: 0.013663828372955322\n",
      "Gradient for encoder.mean.weight: 0.18464075028896332\n",
      "Gradient for encoder.mean.bias: 0.00995611771941185\n",
      "Gradient for encoder.log_var.weight: 0.11390417069196701\n",
      "Gradient for encoder.log_var.bias: 0.005564963910728693\n",
      "Gradient for decoder.decoder.0.weight: 0.016281628981232643\n",
      "Gradient for decoder.decoder.0.bias: 1.3327007553076697e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0009241178049705923\n",
      "Gradient for decoder.decoder.1.bias: 0.000577361963223666\n",
      "Gradient for decoder.decoder.3.weight: 0.013031168840825558\n",
      "Gradient for decoder.decoder.3.bias: 1.0783440806960698e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0005174181424081326\n",
      "Gradient for decoder.decoder.4.bias: 0.00043797478429041803\n",
      "Gradient for decoder.decoder.6.weight: 0.0010208631865680218\n",
      "Gradient for decoder.decoder.6.bias: 4.6457014832412824e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.055568795651197433\n",
      "Gradient for encoder.encoder.0.bias: 8.219645103446638e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.006480030715465546\n",
      "Gradient for encoder.encoder.1.bias: 0.005293356720358133\n",
      "Gradient for encoder.encoder.3.weight: 0.1524343341588974\n",
      "Gradient for encoder.encoder.3.bias: 9.534432132696224e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.016297077760100365\n",
      "Gradient for encoder.encoder.4.bias: 0.013792390003800392\n",
      "Gradient for encoder.mean.weight: 0.19087088108062744\n",
      "Gradient for encoder.mean.bias: 0.009349483996629715\n",
      "Gradient for encoder.log_var.weight: 0.09964605420827866\n",
      "Gradient for encoder.log_var.bias: 0.004940385930240154\n",
      "Gradient for decoder.decoder.0.weight: 0.016022702679038048\n",
      "Gradient for decoder.decoder.0.bias: 1.4409232140799588e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0008055205689743161\n",
      "Gradient for decoder.decoder.1.bias: 0.0005723839858546853\n",
      "Gradient for decoder.decoder.3.weight: 0.012237155809998512\n",
      "Gradient for decoder.decoder.3.bias: 9.837479442165176e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0005009819287806749\n",
      "Gradient for decoder.decoder.4.bias: 0.0005140510620549321\n",
      "Gradient for decoder.decoder.6.weight: 0.0010118918726220727\n",
      "Gradient for decoder.decoder.6.bias: 5.9093090385431424e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.04095301032066345\n",
      "Gradient for encoder.encoder.0.bias: 7.168478310948245e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0061464630998671055\n",
      "Gradient for encoder.encoder.1.bias: 0.004933895543217659\n",
      "Gradient for encoder.encoder.3.weight: 0.13531382381916046\n",
      "Gradient for encoder.encoder.3.bias: 7.443351490721284e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.011472075246274471\n",
      "Gradient for encoder.encoder.4.bias: 0.011583048850297928\n",
      "Gradient for encoder.mean.weight: 0.15165475010871887\n",
      "Gradient for encoder.mean.bias: 0.007738036569207907\n",
      "Gradient for encoder.log_var.weight: 0.0861140713095665\n",
      "Gradient for encoder.log_var.bias: 0.004428808111697435\n",
      "Gradient for decoder.decoder.0.weight: 0.017162194475531578\n",
      "Gradient for decoder.decoder.0.bias: 1.5036386025180093e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0008945968584157526\n",
      "Gradient for decoder.decoder.1.bias: 0.0006347743328660727\n",
      "Gradient for decoder.decoder.3.weight: 0.013823711313307285\n",
      "Gradient for decoder.decoder.3.bias: 1.1501424118653958e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0005172394448891282\n",
      "Gradient for decoder.decoder.4.bias: 0.0005412527825683355\n",
      "Gradient for decoder.decoder.6.weight: 0.0010025660740211606\n",
      "Gradient for decoder.decoder.6.bias: 5.504124783328734e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.341342955827713\n",
      "Gradient for encoder.encoder.0.bias: 6.421525533539807e-10\n",
      "Gradient for encoder.encoder.1.weight: 0.04127606377005577\n",
      "Gradient for encoder.encoder.1.bias: 0.027638278901576996\n",
      "Gradient for encoder.encoder.3.weight: 0.8687384724617004\n",
      "Gradient for encoder.encoder.3.bias: 3.5586023017231128e-09\n",
      "Gradient for encoder.encoder.4.weight: 0.05659398064017296\n",
      "Gradient for encoder.encoder.4.bias: 0.04615884646773338\n",
      "Gradient for encoder.mean.weight: 0.6691464781761169\n",
      "Gradient for encoder.mean.bias: 0.02113351598381996\n",
      "Gradient for encoder.log_var.weight: 0.37300989031791687\n",
      "Gradient for encoder.log_var.bias: 0.012739044614136219\n",
      "Gradient for decoder.decoder.0.weight: 0.044763967394828796\n",
      "Gradient for decoder.decoder.0.bias: 2.688446409937484e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0020746206864714622\n",
      "Gradient for decoder.decoder.1.bias: 0.001526693464256823\n",
      "Gradient for decoder.decoder.3.weight: 0.034123048186302185\n",
      "Gradient for decoder.decoder.3.bias: 2.0483170715124288e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0012537362053990364\n",
      "Gradient for decoder.decoder.4.bias: 0.001285782316699624\n",
      "Gradient for decoder.decoder.6.weight: 0.0028008820954710245\n",
      "Gradient for decoder.decoder.6.bias: 0.00019998490461148322\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/3, Train Loss: 0.1149, Val Loss: 0.3248\n",
      "Training VAE for class 1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training VAE Epoch:  11%|█▏        | 9/79 [00:00<00:02, 34.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient for encoder.encoder.0.weight: 0.10088410973548889\n",
      "Gradient for encoder.encoder.0.bias: 1.6105457245618737e-10\n",
      "Gradient for encoder.encoder.1.weight: 0.011488058604300022\n",
      "Gradient for encoder.encoder.1.bias: 0.008228939957916737\n",
      "Gradient for encoder.encoder.3.weight: 0.2680259644985199\n",
      "Gradient for encoder.encoder.3.bias: 1.5299396194379256e-09\n",
      "Gradient for encoder.encoder.4.weight: 0.02678694948554039\n",
      "Gradient for encoder.encoder.4.bias: 0.02445749193429947\n",
      "Gradient for encoder.mean.weight: 0.3118588924407959\n",
      "Gradient for encoder.mean.bias: 0.016103805974125862\n",
      "Gradient for encoder.log_var.weight: 0.17462532222270966\n",
      "Gradient for encoder.log_var.bias: 0.010182676836848259\n",
      "Gradient for decoder.decoder.0.weight: 0.013304413296282291\n",
      "Gradient for decoder.decoder.0.bias: 1.0864970728663437e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0006995925214141607\n",
      "Gradient for decoder.decoder.1.bias: 0.00046216160990297794\n",
      "Gradient for decoder.decoder.3.weight: 0.010418552905321121\n",
      "Gradient for decoder.decoder.3.bias: 1.74864470126046e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0013902082573622465\n",
      "Gradient for decoder.decoder.4.bias: 0.0017958531389012933\n",
      "Gradient for decoder.decoder.6.weight: 0.002276420360431075\n",
      "Gradient for decoder.decoder.6.bias: 0.00023398312623612583\n",
      "Gradient for encoder.encoder.0.weight: 0.08129160851240158\n",
      "Gradient for encoder.encoder.0.bias: 1.2942061311527198e-10\n",
      "Gradient for encoder.encoder.1.weight: 0.009399793110787868\n",
      "Gradient for encoder.encoder.1.bias: 0.007406937424093485\n",
      "Gradient for encoder.encoder.3.weight: 0.2147003710269928\n",
      "Gradient for encoder.encoder.3.bias: 1.3432901457832713e-09\n",
      "Gradient for encoder.encoder.4.weight: 0.019539309665560722\n",
      "Gradient for encoder.encoder.4.bias: 0.02495555393397808\n",
      "Gradient for encoder.mean.weight: 0.2569263279438019\n",
      "Gradient for encoder.mean.bias: 0.0185468140989542\n",
      "Gradient for encoder.log_var.weight: 0.15998663008213043\n",
      "Gradient for encoder.log_var.bias: 0.01377593632787466\n",
      "Gradient for decoder.decoder.0.weight: 0.015180561691522598\n",
      "Gradient for decoder.decoder.0.bias: 1.3763828965451808e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0007839303580112755\n",
      "Gradient for decoder.decoder.1.bias: 0.0005456968210637569\n",
      "Gradient for decoder.decoder.3.weight: 0.011680866591632366\n",
      "Gradient for decoder.decoder.3.bias: 1.1969145119472557e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0007543463143520057\n",
      "Gradient for decoder.decoder.4.bias: 0.0009312537731602788\n",
      "Gradient for decoder.decoder.6.weight: 0.001631874474696815\n",
      "Gradient for decoder.decoder.6.bias: 0.0001522456732345745\n",
      "Gradient for encoder.encoder.0.weight: 0.1065521165728569\n",
      "Gradient for encoder.encoder.0.bias: 1.502989815937994e-10\n",
      "Gradient for encoder.encoder.1.weight: 0.010679028928279877\n",
      "Gradient for encoder.encoder.1.bias: 0.008147369138896465\n",
      "Gradient for encoder.encoder.3.weight: 0.2460414618253708\n",
      "Gradient for encoder.encoder.3.bias: 1.3593453029869806e-09\n",
      "Gradient for encoder.encoder.4.weight: 0.019972193986177444\n",
      "Gradient for encoder.encoder.4.bias: 0.01857023872435093\n",
      "Gradient for encoder.mean.weight: 0.24885374307632446\n",
      "Gradient for encoder.mean.bias: 0.012134958058595657\n",
      "Gradient for encoder.log_var.weight: 0.1419355273246765\n",
      "Gradient for encoder.log_var.bias: 0.009594539180397987\n",
      "Gradient for decoder.decoder.0.weight: 0.014185816049575806\n",
      "Gradient for decoder.decoder.0.bias: 1.2949590011412937e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0007758272695355117\n",
      "Gradient for decoder.decoder.1.bias: 0.0005335929454304278\n",
      "Gradient for decoder.decoder.3.weight: 0.011279291473329067\n",
      "Gradient for decoder.decoder.3.bias: 1.6349467613085977e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0011805081740021706\n",
      "Gradient for decoder.decoder.4.bias: 0.0014120033010840416\n",
      "Gradient for decoder.decoder.6.weight: 0.0019193809712305665\n",
      "Gradient for decoder.decoder.6.bias: 0.00017557648243382573\n",
      "Gradient for encoder.encoder.0.weight: 0.10684545338153839\n",
      "Gradient for encoder.encoder.0.bias: 1.4760520583578796e-10\n",
      "Gradient for encoder.encoder.1.weight: 0.011812310665845871\n",
      "Gradient for encoder.encoder.1.bias: 0.009928952902555466\n",
      "Gradient for encoder.encoder.3.weight: 0.27779871225357056\n",
      "Gradient for encoder.encoder.3.bias: 1.4352985466814516e-09\n",
      "Gradient for encoder.encoder.4.weight: 0.025525059551000595\n",
      "Gradient for encoder.encoder.4.bias: 0.02145407535135746\n",
      "Gradient for encoder.mean.weight: 0.32010984420776367\n",
      "Gradient for encoder.mean.bias: 0.013220470398664474\n",
      "Gradient for encoder.log_var.weight: 0.18511272966861725\n",
      "Gradient for encoder.log_var.bias: 0.008722160011529922\n",
      "Gradient for decoder.decoder.0.weight: 0.014719056896865368\n",
      "Gradient for decoder.decoder.0.bias: 1.1946707512144883e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0007869830005802214\n",
      "Gradient for decoder.decoder.1.bias: 0.0005281674093566835\n",
      "Gradient for decoder.decoder.3.weight: 0.012050813995301723\n",
      "Gradient for decoder.decoder.3.bias: 1.4023593397638479e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.001033681444823742\n",
      "Gradient for decoder.decoder.4.bias: 0.0012776072835549712\n",
      "Gradient for decoder.decoder.6.weight: 0.001997973769903183\n",
      "Gradient for decoder.decoder.6.bias: 0.00019524880917742848\n",
      "Gradient for encoder.encoder.0.weight: 0.11311881244182587\n",
      "Gradient for encoder.encoder.0.bias: 1.9470822176792524e-10\n",
      "Gradient for encoder.encoder.1.weight: 0.009874341078102589\n",
      "Gradient for encoder.encoder.1.bias: 0.0082315718755126\n",
      "Gradient for encoder.encoder.3.weight: 0.23116552829742432\n",
      "Gradient for encoder.encoder.3.bias: 1.1935682442398843e-09\n",
      "Gradient for encoder.encoder.4.weight: 0.018128661438822746\n",
      "Gradient for encoder.encoder.4.bias: 0.017578421160578728\n",
      "Gradient for encoder.mean.weight: 0.24188533425331116\n",
      "Gradient for encoder.mean.bias: 0.01170819066464901\n",
      "Gradient for encoder.log_var.weight: 0.12764771282672882\n",
      "Gradient for encoder.log_var.bias: 0.0070265536196529865\n",
      "Gradient for decoder.decoder.0.weight: 0.010608692653477192\n",
      "Gradient for decoder.decoder.0.bias: 9.395823702407213e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005678728921338916\n",
      "Gradient for decoder.decoder.1.bias: 0.00043564505176618695\n",
      "Gradient for decoder.decoder.3.weight: 0.008789093233644962\n",
      "Gradient for decoder.decoder.3.bias: 1.61085145222728e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0014292136766016483\n",
      "Gradient for decoder.decoder.4.bias: 0.0018003371078521013\n",
      "Gradient for decoder.decoder.6.weight: 0.0020180174615234137\n",
      "Gradient for decoder.decoder.6.bias: 0.0002003877016250044\n",
      "Gradient for encoder.encoder.0.weight: 0.08340206742286682\n",
      "Gradient for encoder.encoder.0.bias: 1.692438827971543e-10\n",
      "Gradient for encoder.encoder.1.weight: 0.009981745854020119\n",
      "Gradient for encoder.encoder.1.bias: 0.008079376071691513\n",
      "Gradient for encoder.encoder.3.weight: 0.21597327291965485\n",
      "Gradient for encoder.encoder.3.bias: 1.1104052122234975e-09\n",
      "Gradient for encoder.encoder.4.weight: 0.016629528254270554\n",
      "Gradient for encoder.encoder.4.bias: 0.020000046119093895\n",
      "Gradient for encoder.mean.weight: 0.23717953264713287\n",
      "Gradient for encoder.mean.bias: 0.013339759781956673\n",
      "Gradient for encoder.log_var.weight: 0.14339061081409454\n",
      "Gradient for encoder.log_var.bias: 0.010483763180673122\n",
      "Gradient for decoder.decoder.0.weight: 0.012600024230778217\n",
      "Gradient for decoder.decoder.0.bias: 9.742524148537157e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0006579098990187049\n",
      "Gradient for decoder.decoder.1.bias: 0.0004466912942007184\n",
      "Gradient for decoder.decoder.3.weight: 0.00992819108068943\n",
      "Gradient for decoder.decoder.3.bias: 1.1810760702779532e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0009869243949651718\n",
      "Gradient for decoder.decoder.4.bias: 0.0012540011666715145\n",
      "Gradient for decoder.decoder.6.weight: 0.001676247688010335\n",
      "Gradient for decoder.decoder.6.bias: 0.0001590972678968683\n",
      "Gradient for encoder.encoder.0.weight: 0.09855283051729202\n",
      "Gradient for encoder.encoder.0.bias: 1.4182054142164446e-10\n",
      "Gradient for encoder.encoder.1.weight: 0.010005194693803787\n",
      "Gradient for encoder.encoder.1.bias: 0.007393617182970047\n",
      "Gradient for encoder.encoder.3.weight: 0.2174638956785202\n",
      "Gradient for encoder.encoder.3.bias: 1.0192511279427663e-09\n",
      "Gradient for encoder.encoder.4.weight: 0.0155114084482193\n",
      "Gradient for encoder.encoder.4.bias: 0.013102657161653042\n",
      "Gradient for encoder.mean.weight: 0.2209717482328415\n",
      "Gradient for encoder.mean.bias: 0.009523800574243069\n",
      "Gradient for encoder.log_var.weight: 0.12141137570142746\n",
      "Gradient for encoder.log_var.bias: 0.00571348425000906\n",
      "Gradient for decoder.decoder.0.weight: 0.01379748061299324\n",
      "Gradient for decoder.decoder.0.bias: 1.047496950290494e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0006843235460110009\n",
      "Gradient for decoder.decoder.1.bias: 0.0005073703941889107\n",
      "Gradient for decoder.decoder.3.weight: 0.01115642674267292\n",
      "Gradient for decoder.decoder.3.bias: 1.702719493179572e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0014535993104800582\n",
      "Gradient for decoder.decoder.4.bias: 0.0018582330085337162\n",
      "Gradient for decoder.decoder.6.weight: 0.0020376325119286776\n",
      "Gradient for decoder.decoder.6.bias: 0.0002034694334724918\n",
      "Gradient for encoder.encoder.0.weight: 0.09765923768281937\n",
      "Gradient for encoder.encoder.0.bias: 1.5171626455146026e-10\n",
      "Gradient for encoder.encoder.1.weight: 0.008017165586352348\n",
      "Gradient for encoder.encoder.1.bias: 0.006541307549923658\n",
      "Gradient for encoder.encoder.3.weight: 0.17406460642814636\n",
      "Gradient for encoder.encoder.3.bias: 9.622502794570664e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.013511482626199722\n",
      "Gradient for encoder.encoder.4.bias: 0.012216086499392986\n",
      "Gradient for encoder.mean.weight: 0.17872336506843567\n",
      "Gradient for encoder.mean.bias: 0.00915766041725874\n",
      "Gradient for encoder.log_var.weight: 0.09283047914505005\n",
      "Gradient for encoder.log_var.bias: 0.004839155822992325\n",
      "Gradient for decoder.decoder.0.weight: 0.013761043548583984\n",
      "Gradient for decoder.decoder.0.bias: 1.3050248381940577e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0007603664416819811\n",
      "Gradient for decoder.decoder.1.bias: 0.0005326188984327018\n",
      "Gradient for decoder.decoder.3.weight: 0.011194279417395592\n",
      "Gradient for decoder.decoder.3.bias: 1.5548583254254567e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0011586489854380488\n",
      "Gradient for decoder.decoder.4.bias: 0.001495967386290431\n",
      "Gradient for decoder.decoder.6.weight: 0.0019892153795808554\n",
      "Gradient for decoder.decoder.6.bias: 0.00020240545563865453\n",
      "Gradient for encoder.encoder.0.weight: 0.09165434539318085\n",
      "Gradient for encoder.encoder.0.bias: 1.6588343199064326e-10\n",
      "Gradient for encoder.encoder.1.weight: 0.009659613482654095\n",
      "Gradient for encoder.encoder.1.bias: 0.007421218790113926\n",
      "Gradient for encoder.encoder.3.weight: 0.21469008922576904\n",
      "Gradient for encoder.encoder.3.bias: 1.024436646623883e-09\n",
      "Gradient for encoder.encoder.4.weight: 0.016903091222047806\n",
      "Gradient for encoder.encoder.4.bias: 0.016549475491046906\n",
      "Gradient for encoder.mean.weight: 0.22895346581935883\n",
      "Gradient for encoder.mean.bias: 0.010697687976062298\n",
      "Gradient for encoder.log_var.weight: 0.13316792249679565\n",
      "Gradient for encoder.log_var.bias: 0.0067816381342709064\n",
      "Gradient for decoder.decoder.0.weight: 0.011102491989731789\n",
      "Gradient for decoder.decoder.0.bias: 9.844978304807128e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.000615019875112921\n",
      "Gradient for decoder.decoder.1.bias: 0.00039003402343951166\n",
      "Gradient for decoder.decoder.3.weight: 0.009020181372761726\n",
      "Gradient for decoder.decoder.3.bias: 1.7636199445281164e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0014718681341037154\n",
      "Gradient for decoder.decoder.4.bias: 0.0018924273317679763\n",
      "Gradient for decoder.decoder.6.weight: 0.001934567466378212\n",
      "Gradient for decoder.decoder.6.bias: 0.0001949546131072566\n",
      "Gradient for encoder.encoder.0.weight: 0.08938731253147125\n",
      "Gradient for encoder.encoder.0.bias: 1.2157402862200684e-10\n",
      "Gradient for encoder.encoder.1.weight: 0.010560620576143265\n",
      "Gradient for encoder.encoder.1.bias: 0.008142497390508652\n",
      "Gradient for encoder.encoder.3.weight: 0.23703846335411072\n",
      "Gradient for encoder.encoder.3.bias: 1.2143488437033056e-09\n",
      "Gradient for encoder.encoder.4.weight: 0.020882297307252884\n",
      "Gradient for encoder.encoder.4.bias: 0.01822558231651783\n",
      "Gradient for encoder.mean.weight: 0.26016002893447876\n",
      "Gradient for encoder.mean.bias: 0.01141541637480259\n",
      "Gradient for encoder.log_var.weight: 0.13719893991947174\n",
      "Gradient for encoder.log_var.bias: 0.006243355106562376\n",
      "Gradient for decoder.decoder.0.weight: 0.017532354220747948\n",
      "Gradient for decoder.decoder.0.bias: 1.3991159619752835e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0009673307649791241\n",
      "Gradient for decoder.decoder.1.bias: 0.0006345432484522462\n",
      "Gradient for decoder.decoder.3.weight: 0.014072551392018795\n",
      "Gradient for decoder.decoder.3.bias: 1.4515530444292324e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0010419640457257628\n",
      "Gradient for decoder.decoder.4.bias: 0.0012894098181277514\n",
      "Gradient for decoder.decoder.6.weight: 0.0015630075940862298\n",
      "Gradient for decoder.decoder.6.bias: 0.000144982201163657\n",
      "Gradient for encoder.encoder.0.weight: 0.08065614104270935\n",
      "Gradient for encoder.encoder.0.bias: 1.1349832185203468e-10\n",
      "Gradient for encoder.encoder.1.weight: 0.008726504631340504\n",
      "Gradient for encoder.encoder.1.bias: 0.007170429918915033\n",
      "Gradient for encoder.encoder.3.weight: 0.18557162582874298\n",
      "Gradient for encoder.encoder.3.bias: 1.0231415714656578e-09\n",
      "Gradient for encoder.encoder.4.weight: 0.015301862731575966\n",
      "Gradient for encoder.encoder.4.bias: 0.015111468732357025\n",
      "Gradient for encoder.mean.weight: 0.20170366764068604\n",
      "Gradient for encoder.mean.bias: 0.010120628401637077\n",
      "Gradient for encoder.log_var.weight: 0.105766162276268\n",
      "Gradient for encoder.log_var.bias: 0.005239216610789299\n",
      "Gradient for decoder.decoder.0.weight: 0.015275291167199612\n",
      "Gradient for decoder.decoder.0.bias: 1.1797982035766097e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0007286465843208134\n",
      "Gradient for decoder.decoder.1.bias: 0.0005289262626320124\n",
      "Gradient for decoder.decoder.3.weight: 0.011770243756473064\n",
      "Gradient for decoder.decoder.3.bias: 1.365049462354051e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0009334555361419916\n",
      "Gradient for decoder.decoder.4.bias: 0.0011668131919577718\n",
      "Gradient for decoder.decoder.6.weight: 0.001457748468965292\n",
      "Gradient for decoder.decoder.6.bias: 0.0001315604749834165\n",
      "Gradient for encoder.encoder.0.weight: 0.08195304870605469\n",
      "Gradient for encoder.encoder.0.bias: 1.2895319534411698e-10\n",
      "Gradient for encoder.encoder.1.weight: 0.00758971506729722\n",
      "Gradient for encoder.encoder.1.bias: 0.006254471372812986\n",
      "Gradient for encoder.encoder.3.weight: 0.15267908573150635\n",
      "Gradient for encoder.encoder.3.bias: 9.549452339996378e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.012841945514082909\n",
      "Gradient for encoder.encoder.4.bias: 0.014685110189020634\n",
      "Gradient for encoder.mean.weight: 0.16224761307239532\n",
      "Gradient for encoder.mean.bias: 0.011944945901632309\n",
      "Gradient for encoder.log_var.weight: 0.09102630615234375\n",
      "Gradient for encoder.log_var.bias: 0.00648570666089654\n",
      "Gradient for decoder.decoder.0.weight: 0.0114692822098732\n",
      "Gradient for decoder.decoder.0.bias: 1.0000184014202773e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0005772238364443183\n",
      "Gradient for decoder.decoder.1.bias: 0.00040559301851317286\n",
      "Gradient for decoder.decoder.3.weight: 0.009270379319787025\n",
      "Gradient for decoder.decoder.3.bias: 1.4714239549018515e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.001181135419756174\n",
      "Gradient for decoder.decoder.4.bias: 0.0014782402431592345\n",
      "Gradient for decoder.decoder.6.weight: 0.001795693184249103\n",
      "Gradient for decoder.decoder.6.bias: 0.00017666151688899845\n",
      "Gradient for encoder.encoder.0.weight: 0.07820205390453339\n",
      "Gradient for encoder.encoder.0.bias: 1.222020956648251e-10\n",
      "Gradient for encoder.encoder.1.weight: 0.007298481650650501\n",
      "Gradient for encoder.encoder.1.bias: 0.005508321803063154\n",
      "Gradient for encoder.encoder.3.weight: 0.16051416099071503\n",
      "Gradient for encoder.encoder.3.bias: 8.999177514290579e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.01387110911309719\n",
      "Gradient for encoder.encoder.4.bias: 0.013033297844231129\n",
      "Gradient for encoder.mean.weight: 0.1885804980993271\n",
      "Gradient for encoder.mean.bias: 0.009288085624575615\n",
      "Gradient for encoder.log_var.weight: 0.10741341859102249\n",
      "Gradient for encoder.log_var.bias: 0.005392700899392366\n",
      "Gradient for decoder.decoder.0.weight: 0.01438275445252657\n",
      "Gradient for decoder.decoder.0.bias: 1.2164709517481498e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0007980171358212829\n",
      "Gradient for decoder.decoder.1.bias: 0.0004962036618962884\n",
      "Gradient for decoder.decoder.3.weight: 0.011755094863474369\n",
      "Gradient for decoder.decoder.3.bias: 1.4033603445984255e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.000976758892647922\n",
      "Gradient for decoder.decoder.4.bias: 0.0012703333050012589\n",
      "Gradient for decoder.decoder.6.weight: 0.0014427016722038388\n",
      "Gradient for decoder.decoder.6.bias: 0.00013349304208531976\n",
      "Gradient for encoder.encoder.0.weight: 0.07034958153963089\n",
      "Gradient for encoder.encoder.0.bias: 1.0016536211576721e-10\n",
      "Gradient for encoder.encoder.1.weight: 0.007641854230314493\n",
      "Gradient for encoder.encoder.1.bias: 0.005785860121250153\n",
      "Gradient for encoder.encoder.3.weight: 0.17167599499225616\n",
      "Gradient for encoder.encoder.3.bias: 9.80324710297964e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.013013334013521671\n",
      "Gradient for encoder.encoder.4.bias: 0.013270789757370949\n",
      "Gradient for encoder.mean.weight: 0.1852542757987976\n",
      "Gradient for encoder.mean.bias: 0.009816942736506462\n",
      "Gradient for encoder.log_var.weight: 0.10277196019887924\n",
      "Gradient for encoder.log_var.bias: 0.004921757150441408\n",
      "Gradient for decoder.decoder.0.weight: 0.017591921612620354\n",
      "Gradient for decoder.decoder.0.bias: 1.468448418417978e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0009109101956710219\n",
      "Gradient for decoder.decoder.1.bias: 0.000598199141677469\n",
      "Gradient for decoder.decoder.3.weight: 0.013927732594311237\n",
      "Gradient for decoder.decoder.3.bias: 1.3999934544983716e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0009607072570361197\n",
      "Gradient for decoder.decoder.4.bias: 0.0011954917572438717\n",
      "Gradient for decoder.decoder.6.weight: 0.0013966906117275357\n",
      "Gradient for decoder.decoder.6.bias: 0.0001221828133566305\n",
      "Gradient for encoder.encoder.0.weight: 0.1049850583076477\n",
      "Gradient for encoder.encoder.0.bias: 1.676865868383004e-10\n",
      "Gradient for encoder.encoder.1.weight: 0.012762687169015408\n",
      "Gradient for encoder.encoder.1.bias: 0.009166480973362923\n",
      "Gradient for encoder.encoder.3.weight: 0.27516064047813416\n",
      "Gradient for encoder.encoder.3.bias: 1.0336146383238543e-09\n",
      "Gradient for encoder.encoder.4.weight: 0.018525993451476097\n",
      "Gradient for encoder.encoder.4.bias: 0.014432602562010288\n",
      "Gradient for encoder.mean.weight: 0.2250867635011673\n",
      "Gradient for encoder.mean.bias: 0.008383628912270069\n",
      "Gradient for encoder.log_var.weight: 0.12877359986305237\n",
      "Gradient for encoder.log_var.bias: 0.005429675802588463\n",
      "Gradient for decoder.decoder.0.weight: 0.01273974310606718\n",
      "Gradient for decoder.decoder.0.bias: 1.3403504695030932e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0006672203307971358\n",
      "Gradient for decoder.decoder.1.bias: 0.0004763376200571656\n",
      "Gradient for decoder.decoder.3.weight: 0.010331127792596817\n",
      "Gradient for decoder.decoder.3.bias: 1.6163841098926213e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0013165369164198637\n",
      "Gradient for decoder.decoder.4.bias: 0.0016614176565781236\n",
      "Gradient for decoder.decoder.6.weight: 0.0017347208922728896\n",
      "Gradient for decoder.decoder.6.bias: 0.000171848208992742\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training VAE Epoch:  32%|███▏      | 25/79 [00:00<00:00, 58.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient for encoder.encoder.0.weight: 0.09242180734872818\n",
      "Gradient for encoder.encoder.0.bias: 1.3426275369265994e-10\n",
      "Gradient for encoder.encoder.1.weight: 0.00911672506481409\n",
      "Gradient for encoder.encoder.1.bias: 0.006248159799724817\n",
      "Gradient for encoder.encoder.3.weight: 0.20248208940029144\n",
      "Gradient for encoder.encoder.3.bias: 1.1658803922287575e-09\n",
      "Gradient for encoder.encoder.4.weight: 0.017133036628365517\n",
      "Gradient for encoder.encoder.4.bias: 0.018559033051133156\n",
      "Gradient for encoder.mean.weight: 0.2335774302482605\n",
      "Gradient for encoder.mean.bias: 0.014159970916807652\n",
      "Gradient for encoder.log_var.weight: 0.13679704070091248\n",
      "Gradient for encoder.log_var.bias: 0.008835641667246819\n",
      "Gradient for decoder.decoder.0.weight: 0.013279154896736145\n",
      "Gradient for decoder.decoder.0.bias: 1.2386090764149316e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0007020562770776451\n",
      "Gradient for decoder.decoder.1.bias: 0.0004756560956593603\n",
      "Gradient for decoder.decoder.3.weight: 0.010633622296154499\n",
      "Gradient for decoder.decoder.3.bias: 1.7361911908153616e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.001451601623557508\n",
      "Gradient for decoder.decoder.4.bias: 0.0018760239472612739\n",
      "Gradient for decoder.decoder.6.weight: 0.001868893625214696\n",
      "Gradient for decoder.decoder.6.bias: 0.00019020070612896234\n",
      "Gradient for encoder.encoder.0.weight: 0.07375496625900269\n",
      "Gradient for encoder.encoder.0.bias: 1.1254112919356629e-10\n",
      "Gradient for encoder.encoder.1.weight: 0.007738079875707626\n",
      "Gradient for encoder.encoder.1.bias: 0.006094272714108229\n",
      "Gradient for encoder.encoder.3.weight: 0.16922913491725922\n",
      "Gradient for encoder.encoder.3.bias: 8.542682672363355e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.011979938484728336\n",
      "Gradient for encoder.encoder.4.bias: 0.010594549588859081\n",
      "Gradient for encoder.mean.weight: 0.16721689701080322\n",
      "Gradient for encoder.mean.bias: 0.0072594089433550835\n",
      "Gradient for encoder.log_var.weight: 0.09833280742168427\n",
      "Gradient for encoder.log_var.bias: 0.0041554090566933155\n",
      "Gradient for decoder.decoder.0.weight: 0.014873062260448933\n",
      "Gradient for decoder.decoder.0.bias: 1.2788087255799496e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0007739058346487582\n",
      "Gradient for decoder.decoder.1.bias: 0.0005424260743893683\n",
      "Gradient for decoder.decoder.3.weight: 0.011847462505102158\n",
      "Gradient for decoder.decoder.3.bias: 1.4470419307244242e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0010424460051581264\n",
      "Gradient for decoder.decoder.4.bias: 0.0012887632474303246\n",
      "Gradient for decoder.decoder.6.weight: 0.0013770759105682373\n",
      "Gradient for decoder.decoder.6.bias: 0.00012250443978700787\n",
      "Gradient for encoder.encoder.0.weight: 0.07858135551214218\n",
      "Gradient for encoder.encoder.0.bias: 1.0403271299974648e-10\n",
      "Gradient for encoder.encoder.1.weight: 0.007228700444102287\n",
      "Gradient for encoder.encoder.1.bias: 0.005243067163974047\n",
      "Gradient for encoder.encoder.3.weight: 0.15899279713630676\n",
      "Gradient for encoder.encoder.3.bias: 8.965472808597497e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.015186784788966179\n",
      "Gradient for encoder.encoder.4.bias: 0.01197773590683937\n",
      "Gradient for encoder.mean.weight: 0.1774248629808426\n",
      "Gradient for encoder.mean.bias: 0.008251992054283619\n",
      "Gradient for encoder.log_var.weight: 0.1112632006406784\n",
      "Gradient for encoder.log_var.bias: 0.005809977650642395\n",
      "Gradient for decoder.decoder.0.weight: 0.015257563441991806\n",
      "Gradient for decoder.decoder.0.bias: 1.4481239818397995e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0007965980912558734\n",
      "Gradient for decoder.decoder.1.bias: 0.0005477652885019779\n",
      "Gradient for decoder.decoder.3.weight: 0.012418774887919426\n",
      "Gradient for decoder.decoder.3.bias: 1.412940320300038e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0009416014072485268\n",
      "Gradient for decoder.decoder.4.bias: 0.001175501267425716\n",
      "Gradient for decoder.decoder.6.weight: 0.0013470578705891967\n",
      "Gradient for decoder.decoder.6.bias: 0.00012062757014064118\n",
      "Gradient for encoder.encoder.0.weight: 0.0742531567811966\n",
      "Gradient for encoder.encoder.0.bias: 9.01406865816412e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.006292995065450668\n",
      "Gradient for encoder.encoder.1.bias: 0.0060206023044884205\n",
      "Gradient for encoder.encoder.3.weight: 0.14098656177520752\n",
      "Gradient for encoder.encoder.3.bias: 1.2060844545302984e-09\n",
      "Gradient for encoder.encoder.4.weight: 0.017416128888726234\n",
      "Gradient for encoder.encoder.4.bias: 0.021554727107286453\n",
      "Gradient for encoder.mean.weight: 0.2291778028011322\n",
      "Gradient for encoder.mean.bias: 0.017455557361245155\n",
      "Gradient for encoder.log_var.weight: 0.14619407057762146\n",
      "Gradient for encoder.log_var.bias: 0.011390906758606434\n",
      "Gradient for decoder.decoder.0.weight: 0.017716338858008385\n",
      "Gradient for decoder.decoder.0.bias: 1.510134378657213e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0009573475108481944\n",
      "Gradient for decoder.decoder.1.bias: 0.0006527062505483627\n",
      "Gradient for decoder.decoder.3.weight: 0.014470916241407394\n",
      "Gradient for decoder.decoder.3.bias: 1.05279965301186e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0005060432595200837\n",
      "Gradient for decoder.decoder.4.bias: 0.00043263568659313023\n",
      "Gradient for decoder.decoder.6.weight: 0.0011762966169044375\n",
      "Gradient for decoder.decoder.6.bias: 8.48149647936225e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.09900354593992233\n",
      "Gradient for encoder.encoder.0.bias: 1.420830814113927e-10\n",
      "Gradient for encoder.encoder.1.weight: 0.009069491177797318\n",
      "Gradient for encoder.encoder.1.bias: 0.007030481472611427\n",
      "Gradient for encoder.encoder.3.weight: 0.2063143402338028\n",
      "Gradient for encoder.encoder.3.bias: 1.0958207674605092e-09\n",
      "Gradient for encoder.encoder.4.weight: 0.018451528623700142\n",
      "Gradient for encoder.encoder.4.bias: 0.015816256403923035\n",
      "Gradient for encoder.mean.weight: 0.23177769780158997\n",
      "Gradient for encoder.mean.bias: 0.009420251473784447\n",
      "Gradient for encoder.log_var.weight: 0.13849478960037231\n",
      "Gradient for encoder.log_var.bias: 0.005644798744469881\n",
      "Gradient for decoder.decoder.0.weight: 0.014546531252563\n",
      "Gradient for decoder.decoder.0.bias: 1.3535209064663434e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0008130872156471014\n",
      "Gradient for decoder.decoder.1.bias: 0.0005334734451025724\n",
      "Gradient for decoder.decoder.3.weight: 0.012032556347548962\n",
      "Gradient for decoder.decoder.3.bias: 1.4394284375551791e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0010041518835350871\n",
      "Gradient for decoder.decoder.4.bias: 0.0012823252473026514\n",
      "Gradient for decoder.decoder.6.weight: 0.0011880045058205724\n",
      "Gradient for decoder.decoder.6.bias: 9.979159949580207e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.0677957534790039\n",
      "Gradient for encoder.encoder.0.bias: 1.1166709917853623e-10\n",
      "Gradient for encoder.encoder.1.weight: 0.006892923731356859\n",
      "Gradient for encoder.encoder.1.bias: 0.005357462912797928\n",
      "Gradient for encoder.encoder.3.weight: 0.15167295932769775\n",
      "Gradient for encoder.encoder.3.bias: 7.609146090992169e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.013034329749643803\n",
      "Gradient for encoder.encoder.4.bias: 0.012384910136461258\n",
      "Gradient for encoder.mean.weight: 0.1692247986793518\n",
      "Gradient for encoder.mean.bias: 0.00883383397012949\n",
      "Gradient for encoder.log_var.weight: 0.08396600186824799\n",
      "Gradient for encoder.log_var.bias: 0.004324070177972317\n",
      "Gradient for decoder.decoder.0.weight: 0.014566213823854923\n",
      "Gradient for decoder.decoder.0.bias: 1.144648056894404e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0008000181405805051\n",
      "Gradient for decoder.decoder.1.bias: 0.00052230543224141\n",
      "Gradient for decoder.decoder.3.weight: 0.011743973009288311\n",
      "Gradient for decoder.decoder.3.bias: 1.5587348078938135e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0012029915815219283\n",
      "Gradient for decoder.decoder.4.bias: 0.0015493331011384726\n",
      "Gradient for decoder.decoder.6.weight: 0.0013957350747659802\n",
      "Gradient for decoder.decoder.6.bias: 0.00013313941599335521\n",
      "Gradient for encoder.encoder.0.weight: 0.07176870107650757\n",
      "Gradient for encoder.encoder.0.bias: 1.0427890495545711e-10\n",
      "Gradient for encoder.encoder.1.weight: 0.007639794144779444\n",
      "Gradient for encoder.encoder.1.bias: 0.005516513716429472\n",
      "Gradient for encoder.encoder.3.weight: 0.17070314288139343\n",
      "Gradient for encoder.encoder.3.bias: 7.593218831480897e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.013320984318852425\n",
      "Gradient for encoder.encoder.4.bias: 0.01101392786949873\n",
      "Gradient for encoder.mean.weight: 0.18302352726459503\n",
      "Gradient for encoder.mean.bias: 0.006669276859611273\n",
      "Gradient for encoder.log_var.weight: 0.09425811469554901\n",
      "Gradient for encoder.log_var.bias: 0.003343798452988267\n",
      "Gradient for decoder.decoder.0.weight: 0.014212106354534626\n",
      "Gradient for decoder.decoder.0.bias: 1.2428520712592928e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.000828452524729073\n",
      "Gradient for decoder.decoder.1.bias: 0.0005563758313655853\n",
      "Gradient for decoder.decoder.3.weight: 0.011920741759240627\n",
      "Gradient for decoder.decoder.3.bias: 1.1807990696333093e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0007854668074287474\n",
      "Gradient for decoder.decoder.4.bias: 0.0009881611913442612\n",
      "Gradient for decoder.decoder.6.weight: 0.0011480437824502587\n",
      "Gradient for decoder.decoder.6.bias: 9.756647341419011e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.0758085697889328\n",
      "Gradient for encoder.encoder.0.bias: 1.1428360341403376e-10\n",
      "Gradient for encoder.encoder.1.weight: 0.010006232187151909\n",
      "Gradient for encoder.encoder.1.bias: 0.006631898693740368\n",
      "Gradient for encoder.encoder.3.weight: 0.21992315351963043\n",
      "Gradient for encoder.encoder.3.bias: 1.0562276608894194e-09\n",
      "Gradient for encoder.encoder.4.weight: 0.02027757838368416\n",
      "Gradient for encoder.encoder.4.bias: 0.021795811131596565\n",
      "Gradient for encoder.mean.weight: 0.2582840621471405\n",
      "Gradient for encoder.mean.bias: 0.01751132309436798\n",
      "Gradient for encoder.log_var.weight: 0.14770834147930145\n",
      "Gradient for encoder.log_var.bias: 0.011638019233942032\n",
      "Gradient for decoder.decoder.0.weight: 0.01706133969128132\n",
      "Gradient for decoder.decoder.0.bias: 1.4691717287185213e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0009458670392632484\n",
      "Gradient for decoder.decoder.1.bias: 0.0006195367895998061\n",
      "Gradient for decoder.decoder.3.weight: 0.013941793702542782\n",
      "Gradient for decoder.decoder.3.bias: 1.5430198785360005e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0012300156522542238\n",
      "Gradient for decoder.decoder.4.bias: 0.001569656073115766\n",
      "Gradient for decoder.decoder.6.weight: 0.0013229497708380222\n",
      "Gradient for decoder.decoder.6.bias: 0.00012304671690799296\n",
      "Gradient for encoder.encoder.0.weight: 0.12193421274423599\n",
      "Gradient for encoder.encoder.0.bias: 1.7626256010316865e-10\n",
      "Gradient for encoder.encoder.1.weight: 0.011808253824710846\n",
      "Gradient for encoder.encoder.1.bias: 0.008687607012689114\n",
      "Gradient for encoder.encoder.3.weight: 0.2371145486831665\n",
      "Gradient for encoder.encoder.3.bias: 9.767727737752807e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.018510274589061737\n",
      "Gradient for encoder.encoder.4.bias: 0.016442948952317238\n",
      "Gradient for encoder.mean.weight: 0.2304510474205017\n",
      "Gradient for encoder.mean.bias: 0.011277148500084877\n",
      "Gradient for encoder.log_var.weight: 0.14460276067256927\n",
      "Gradient for encoder.log_var.bias: 0.0060120210982859135\n",
      "Gradient for decoder.decoder.0.weight: 0.014318687841296196\n",
      "Gradient for decoder.decoder.0.bias: 1.205472943688335e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0007958223577588797\n",
      "Gradient for decoder.decoder.1.bias: 0.0005369389546103776\n",
      "Gradient for decoder.decoder.3.weight: 0.012131145223975182\n",
      "Gradient for decoder.decoder.3.bias: 1.3853705682631556e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0009550192044116557\n",
      "Gradient for decoder.decoder.4.bias: 0.0012484915787354112\n",
      "Gradient for decoder.decoder.6.weight: 0.0011020423844456673\n",
      "Gradient for decoder.decoder.6.bias: 9.205060632666573e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.08352793008089066\n",
      "Gradient for encoder.encoder.0.bias: 1.1322017628989656e-10\n",
      "Gradient for encoder.encoder.1.weight: 0.00972524844110012\n",
      "Gradient for encoder.encoder.1.bias: 0.006890999153256416\n",
      "Gradient for encoder.encoder.3.weight: 0.21460944414138794\n",
      "Gradient for encoder.encoder.3.bias: 9.768796882525521e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.017855452373623848\n",
      "Gradient for encoder.encoder.4.bias: 0.015697676688432693\n",
      "Gradient for encoder.mean.weight: 0.2171039581298828\n",
      "Gradient for encoder.mean.bias: 0.00962182879447937\n",
      "Gradient for encoder.log_var.weight: 0.14264574646949768\n",
      "Gradient for encoder.log_var.bias: 0.005150092765688896\n",
      "Gradient for decoder.decoder.0.weight: 0.013756748288869858\n",
      "Gradient for decoder.decoder.0.bias: 1.1482848699673198e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0007097719935700297\n",
      "Gradient for decoder.decoder.1.bias: 0.0005130312056280673\n",
      "Gradient for decoder.decoder.3.weight: 0.011121430434286594\n",
      "Gradient for decoder.decoder.3.bias: 1.2047655928437706e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.000899252132512629\n",
      "Gradient for decoder.decoder.4.bias: 0.0011280376929789782\n",
      "Gradient for decoder.decoder.6.weight: 0.0012104505440220237\n",
      "Gradient for decoder.decoder.6.bias: 0.0001062658047885634\n",
      "Gradient for encoder.encoder.0.weight: 0.08430090546607971\n",
      "Gradient for encoder.encoder.0.bias: 1.1598046828487085e-10\n",
      "Gradient for encoder.encoder.1.weight: 0.008177733048796654\n",
      "Gradient for encoder.encoder.1.bias: 0.006594676058739424\n",
      "Gradient for encoder.encoder.3.weight: 0.18980862200260162\n",
      "Gradient for encoder.encoder.3.bias: 9.68003455170674e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.02109695039689541\n",
      "Gradient for encoder.encoder.4.bias: 0.014238727279007435\n",
      "Gradient for encoder.mean.weight: 0.25054001808166504\n",
      "Gradient for encoder.mean.bias: 0.009377849288284779\n",
      "Gradient for encoder.log_var.weight: 0.1409182995557785\n",
      "Gradient for encoder.log_var.bias: 0.005080032162368298\n",
      "Gradient for decoder.decoder.0.weight: 0.015891391783952713\n",
      "Gradient for decoder.decoder.0.bias: 1.2602389964921912e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0007948175189085305\n",
      "Gradient for decoder.decoder.1.bias: 0.0005771918222308159\n",
      "Gradient for decoder.decoder.3.weight: 0.012652169913053513\n",
      "Gradient for decoder.decoder.3.bias: 1.317888437268877e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0008793683373369277\n",
      "Gradient for decoder.decoder.4.bias: 0.0011057475348934531\n",
      "Gradient for decoder.decoder.6.weight: 0.001191941206343472\n",
      "Gradient for decoder.decoder.6.bias: 0.00010170372115680948\n",
      "Gradient for encoder.encoder.0.weight: 0.10271281749010086\n",
      "Gradient for encoder.encoder.0.bias: 1.4337514508966365e-10\n",
      "Gradient for encoder.encoder.1.weight: 0.0123140849173069\n",
      "Gradient for encoder.encoder.1.bias: 0.009155919775366783\n",
      "Gradient for encoder.encoder.3.weight: 0.2674691677093506\n",
      "Gradient for encoder.encoder.3.bias: 1.0872712730147782e-09\n",
      "Gradient for encoder.encoder.4.weight: 0.021265201270580292\n",
      "Gradient for encoder.encoder.4.bias: 0.017151841893792152\n",
      "Gradient for encoder.mean.weight: 0.26555126905441284\n",
      "Gradient for encoder.mean.bias: 0.009876388125121593\n",
      "Gradient for encoder.log_var.weight: 0.12358099967241287\n",
      "Gradient for encoder.log_var.bias: 0.0061372728087008\n",
      "Gradient for decoder.decoder.0.weight: 0.017938271164894104\n",
      "Gradient for decoder.decoder.0.bias: 1.5072740278121444e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0009220800711773336\n",
      "Gradient for decoder.decoder.1.bias: 0.0006835501990281045\n",
      "Gradient for decoder.decoder.3.weight: 0.014930038712918758\n",
      "Gradient for decoder.decoder.3.bias: 1.2337264543305082e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0006693679606541991\n",
      "Gradient for decoder.decoder.4.bias: 0.0008311283309012651\n",
      "Gradient for decoder.decoder.6.weight: 0.0010670098708942533\n",
      "Gradient for decoder.decoder.6.bias: 8.275200525531545e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.08431368321180344\n",
      "Gradient for encoder.encoder.0.bias: 1.2572592966719753e-10\n",
      "Gradient for encoder.encoder.1.weight: 0.007584582082927227\n",
      "Gradient for encoder.encoder.1.bias: 0.006423803046345711\n",
      "Gradient for encoder.encoder.3.weight: 0.1604984849691391\n",
      "Gradient for encoder.encoder.3.bias: 9.464528050173726e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.015239265747368336\n",
      "Gradient for encoder.encoder.4.bias: 0.014290903694927692\n",
      "Gradient for encoder.mean.weight: 0.20011819899082184\n",
      "Gradient for encoder.mean.bias: 0.00992909912019968\n",
      "Gradient for encoder.log_var.weight: 0.11056949943304062\n",
      "Gradient for encoder.log_var.bias: 0.005595346912741661\n",
      "Gradient for decoder.decoder.0.weight: 0.01325143501162529\n",
      "Gradient for decoder.decoder.0.bias: 1.120804629661798e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0006769424653612077\n",
      "Gradient for decoder.decoder.1.bias: 0.0004991781315766275\n",
      "Gradient for decoder.decoder.3.weight: 0.01069145742803812\n",
      "Gradient for decoder.decoder.3.bias: 1.2971504426140257e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0009052150417119265\n",
      "Gradient for decoder.decoder.4.bias: 0.0011327341198921204\n",
      "Gradient for decoder.decoder.6.weight: 0.001106667798012495\n",
      "Gradient for decoder.decoder.6.bias: 9.328872693004087e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.12811672687530518\n",
      "Gradient for encoder.encoder.0.bias: 1.6533201196988756e-10\n",
      "Gradient for encoder.encoder.1.weight: 0.01137146633118391\n",
      "Gradient for encoder.encoder.1.bias: 0.007911340333521366\n",
      "Gradient for encoder.encoder.3.weight: 0.2611802816390991\n",
      "Gradient for encoder.encoder.3.bias: 1.2439078656001357e-09\n",
      "Gradient for encoder.encoder.4.weight: 0.020691119134426117\n",
      "Gradient for encoder.encoder.4.bias: 0.016972273588180542\n",
      "Gradient for encoder.mean.weight: 0.2622237801551819\n",
      "Gradient for encoder.mean.bias: 0.010214258916676044\n",
      "Gradient for encoder.log_var.weight: 0.13027146458625793\n",
      "Gradient for encoder.log_var.bias: 0.006034800782799721\n",
      "Gradient for decoder.decoder.0.weight: 0.014125026762485504\n",
      "Gradient for decoder.decoder.0.bias: 1.2368636670423427e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0007364320335909724\n",
      "Gradient for decoder.decoder.1.bias: 0.0005232580588199198\n",
      "Gradient for decoder.decoder.3.weight: 0.011702542193233967\n",
      "Gradient for decoder.decoder.3.bias: 1.2947967698018203e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.00090367766097188\n",
      "Gradient for decoder.decoder.4.bias: 0.0011243651388213038\n",
      "Gradient for decoder.decoder.6.weight: 0.0010679762344807386\n",
      "Gradient for decoder.decoder.6.bias: 8.978857658803463e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.06691167503595352\n",
      "Gradient for encoder.encoder.0.bias: 1.0759352436773284e-10\n",
      "Gradient for encoder.encoder.1.weight: 0.008691300638020039\n",
      "Gradient for encoder.encoder.1.bias: 0.006159032229334116\n",
      "Gradient for encoder.encoder.3.weight: 0.19420795142650604\n",
      "Gradient for encoder.encoder.3.bias: 8.288940089862251e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.016429787501692772\n",
      "Gradient for encoder.encoder.4.bias: 0.013901208527386189\n",
      "Gradient for encoder.mean.weight: 0.20691263675689697\n",
      "Gradient for encoder.mean.bias: 0.008432515896856785\n",
      "Gradient for encoder.log_var.weight: 0.11280330270528793\n",
      "Gradient for encoder.log_var.bias: 0.0052453442476689816\n",
      "Gradient for decoder.decoder.0.weight: 0.01650199666619301\n",
      "Gradient for decoder.decoder.0.bias: 1.3524968645040047e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0009223581873811781\n",
      "Gradient for decoder.decoder.1.bias: 0.0006356605445034802\n",
      "Gradient for decoder.decoder.3.weight: 0.013692070730030537\n",
      "Gradient for decoder.decoder.3.bias: 1.2318261688459842e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0008901670225895941\n",
      "Gradient for decoder.decoder.4.bias: 0.0010886206291615963\n",
      "Gradient for decoder.decoder.6.weight: 0.0010944592067971826\n",
      "Gradient for decoder.decoder.6.bias: 8.899684326024726e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.0800105631351471\n",
      "Gradient for encoder.encoder.0.bias: 1.1130248805946152e-10\n",
      "Gradient for encoder.encoder.1.weight: 0.007332140114158392\n",
      "Gradient for encoder.encoder.1.bias: 0.006039984989911318\n",
      "Gradient for encoder.encoder.3.weight: 0.16468338668346405\n",
      "Gradient for encoder.encoder.3.bias: 9.32086519078723e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.01795107126235962\n",
      "Gradient for encoder.encoder.4.bias: 0.014082317240536213\n",
      "Gradient for encoder.mean.weight: 0.20120613276958466\n",
      "Gradient for encoder.mean.bias: 0.009329212829470634\n",
      "Gradient for encoder.log_var.weight: 0.13667534291744232\n",
      "Gradient for encoder.log_var.bias: 0.004936920944601297\n",
      "Gradient for decoder.decoder.0.weight: 0.01696285605430603\n",
      "Gradient for decoder.decoder.0.bias: 1.2951631433999466e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0009441765141673386\n",
      "Gradient for decoder.decoder.1.bias: 0.0006247172714211047\n",
      "Gradient for decoder.decoder.3.weight: 0.013826494105160236\n",
      "Gradient for decoder.decoder.3.bias: 1.2696413365098635e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0009129018289968371\n",
      "Gradient for decoder.decoder.4.bias: 0.0011583645828068256\n",
      "Gradient for decoder.decoder.6.weight: 0.0011422797106206417\n",
      "Gradient for decoder.decoder.6.bias: 0.00010515099711483344\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training VAE Epoch:  52%|█████▏    | 41/79 [00:00<00:00, 68.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient for encoder.encoder.0.weight: 0.14753447473049164\n",
      "Gradient for encoder.encoder.0.bias: 2.072368526784274e-10\n",
      "Gradient for encoder.encoder.1.weight: 0.013062880374491215\n",
      "Gradient for encoder.encoder.1.bias: 0.009608194231987\n",
      "Gradient for encoder.encoder.3.weight: 0.30426108837127686\n",
      "Gradient for encoder.encoder.3.bias: 1.3135280640952374e-09\n",
      "Gradient for encoder.encoder.4.weight: 0.025460492819547653\n",
      "Gradient for encoder.encoder.4.bias: 0.02023363672196865\n",
      "Gradient for encoder.mean.weight: 0.35500484704971313\n",
      "Gradient for encoder.mean.bias: 0.01175850722938776\n",
      "Gradient for encoder.log_var.weight: 0.18914085626602173\n",
      "Gradient for encoder.log_var.bias: 0.006417463067919016\n",
      "Gradient for decoder.decoder.0.weight: 0.015295949764549732\n",
      "Gradient for decoder.decoder.0.bias: 1.266649563014255e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0008166806655935943\n",
      "Gradient for decoder.decoder.1.bias: 0.0005531165516003966\n",
      "Gradient for decoder.decoder.3.weight: 0.012344361282885075\n",
      "Gradient for decoder.decoder.3.bias: 1.37486508289264e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0009290919406339526\n",
      "Gradient for decoder.decoder.4.bias: 0.0011958539253100753\n",
      "Gradient for decoder.decoder.6.weight: 0.0010020950576290488\n",
      "Gradient for decoder.decoder.6.bias: 8.512328349752352e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.12351945787668228\n",
      "Gradient for encoder.encoder.0.bias: 1.8243319355182308e-10\n",
      "Gradient for encoder.encoder.1.weight: 0.011694619432091713\n",
      "Gradient for encoder.encoder.1.bias: 0.008676884695887566\n",
      "Gradient for encoder.encoder.3.weight: 0.2602543532848358\n",
      "Gradient for encoder.encoder.3.bias: 1.2378053027006786e-09\n",
      "Gradient for encoder.encoder.4.weight: 0.022022798657417297\n",
      "Gradient for encoder.encoder.4.bias: 0.01717371493577957\n",
      "Gradient for encoder.mean.weight: 0.2784079909324646\n",
      "Gradient for encoder.mean.bias: 0.009513948112726212\n",
      "Gradient for encoder.log_var.weight: 0.1523798257112503\n",
      "Gradient for encoder.log_var.bias: 0.005880577024072409\n",
      "Gradient for decoder.decoder.0.weight: 0.01273711584508419\n",
      "Gradient for decoder.decoder.0.bias: 1.0925949728290973e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0007028270047158003\n",
      "Gradient for decoder.decoder.1.bias: 0.00046673504402861\n",
      "Gradient for decoder.decoder.3.weight: 0.010960033163428307\n",
      "Gradient for decoder.decoder.3.bias: 1.0609205181033587e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0007292073569260538\n",
      "Gradient for decoder.decoder.4.bias: 0.0008706341031938791\n",
      "Gradient for decoder.decoder.6.weight: 0.0009438812849111855\n",
      "Gradient for decoder.decoder.6.bias: 7.029152766335756e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.0714595839381218\n",
      "Gradient for encoder.encoder.0.bias: 1.0261771987707391e-10\n",
      "Gradient for encoder.encoder.1.weight: 0.006501916330307722\n",
      "Gradient for encoder.encoder.1.bias: 0.0048183174803853035\n",
      "Gradient for encoder.encoder.3.weight: 0.13302214443683624\n",
      "Gradient for encoder.encoder.3.bias: 8.856888555897058e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.011167669668793678\n",
      "Gradient for encoder.encoder.4.bias: 0.010908441618084908\n",
      "Gradient for encoder.mean.weight: 0.1526026427745819\n",
      "Gradient for encoder.mean.bias: 0.008280721493065357\n",
      "Gradient for encoder.log_var.weight: 0.08422830700874329\n",
      "Gradient for encoder.log_var.bias: 0.005403542425483465\n",
      "Gradient for decoder.decoder.0.weight: 0.01388697512447834\n",
      "Gradient for decoder.decoder.0.bias: 1.1695867885297417e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0007013864233158529\n",
      "Gradient for decoder.decoder.1.bias: 0.0005029424210079014\n",
      "Gradient for decoder.decoder.3.weight: 0.011392433196306229\n",
      "Gradient for decoder.decoder.3.bias: 1.2133789806245687e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0007743575843051076\n",
      "Gradient for decoder.decoder.4.bias: 0.0009578305180184543\n",
      "Gradient for decoder.decoder.6.weight: 0.0009293130715377629\n",
      "Gradient for decoder.decoder.6.bias: 6.954851414775476e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.08675815165042877\n",
      "Gradient for encoder.encoder.0.bias: 1.166239743666253e-10\n",
      "Gradient for encoder.encoder.1.weight: 0.01080229226499796\n",
      "Gradient for encoder.encoder.1.bias: 0.009485309012234211\n",
      "Gradient for encoder.encoder.3.weight: 0.23771445453166962\n",
      "Gradient for encoder.encoder.3.bias: 9.335774375784922e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.018440060317516327\n",
      "Gradient for encoder.encoder.4.bias: 0.016339007765054703\n",
      "Gradient for encoder.mean.weight: 0.25089511275291443\n",
      "Gradient for encoder.mean.bias: 0.010359790176153183\n",
      "Gradient for encoder.log_var.weight: 0.12844830751419067\n",
      "Gradient for encoder.log_var.bias: 0.00548539636656642\n",
      "Gradient for decoder.decoder.0.weight: 0.01648723892867565\n",
      "Gradient for decoder.decoder.0.bias: 1.2073081423480403e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0008190596709027886\n",
      "Gradient for decoder.decoder.1.bias: 0.0005781184881925583\n",
      "Gradient for decoder.decoder.3.weight: 0.013418608345091343\n",
      "Gradient for decoder.decoder.3.bias: 1.0703384706323149e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0006474259425885975\n",
      "Gradient for decoder.decoder.4.bias: 0.0007244572625495493\n",
      "Gradient for decoder.decoder.6.weight: 0.0008991925860755146\n",
      "Gradient for decoder.decoder.6.bias: 6.018176281941123e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.0755101665854454\n",
      "Gradient for encoder.encoder.0.bias: 1.0383475329556191e-10\n",
      "Gradient for encoder.encoder.1.weight: 0.008478592149913311\n",
      "Gradient for encoder.encoder.1.bias: 0.007208500988781452\n",
      "Gradient for encoder.encoder.3.weight: 0.18336261808872223\n",
      "Gradient for encoder.encoder.3.bias: 1.0136416150885452e-09\n",
      "Gradient for encoder.encoder.4.weight: 0.017195584252476692\n",
      "Gradient for encoder.encoder.4.bias: 0.016669167205691338\n",
      "Gradient for encoder.mean.weight: 0.22021083533763885\n",
      "Gradient for encoder.mean.bias: 0.010039876215159893\n",
      "Gradient for encoder.log_var.weight: 0.12306297570466995\n",
      "Gradient for encoder.log_var.bias: 0.005605062935501337\n",
      "Gradient for decoder.decoder.0.weight: 0.018537985160946846\n",
      "Gradient for decoder.decoder.0.bias: 1.6258648594114078e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0009914328111335635\n",
      "Gradient for decoder.decoder.1.bias: 0.0006457986892201006\n",
      "Gradient for decoder.decoder.3.weight: 0.01520322635769844\n",
      "Gradient for decoder.decoder.3.bias: 1.238401881042961e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0005960449925623834\n",
      "Gradient for decoder.decoder.4.bias: 0.0005525900050997734\n",
      "Gradient for decoder.decoder.6.weight: 0.0010995218763127923\n",
      "Gradient for decoder.decoder.6.bias: 7.883528451202437e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.07833930104970932\n",
      "Gradient for encoder.encoder.0.bias: 1.1324578774729588e-10\n",
      "Gradient for encoder.encoder.1.weight: 0.008873839862644672\n",
      "Gradient for encoder.encoder.1.bias: 0.0066752047277987\n",
      "Gradient for encoder.encoder.3.weight: 0.19168980419635773\n",
      "Gradient for encoder.encoder.3.bias: 9.426807112689062e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.017438413575291634\n",
      "Gradient for encoder.encoder.4.bias: 0.015038792043924332\n",
      "Gradient for encoder.mean.weight: 0.22300060093402863\n",
      "Gradient for encoder.mean.bias: 0.00827588140964508\n",
      "Gradient for encoder.log_var.weight: 0.11203332990407944\n",
      "Gradient for encoder.log_var.bias: 0.004207039251923561\n",
      "Gradient for decoder.decoder.0.weight: 0.013907544314861298\n",
      "Gradient for decoder.decoder.0.bias: 1.1525525672739789e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0007162269321270287\n",
      "Gradient for decoder.decoder.1.bias: 0.0005203094915486872\n",
      "Gradient for decoder.decoder.3.weight: 0.011255878023803234\n",
      "Gradient for decoder.decoder.3.bias: 8.493053482716562e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00048115389654412866\n",
      "Gradient for decoder.decoder.4.bias: 0.0005187269416637719\n",
      "Gradient for decoder.decoder.6.weight: 0.0008287234231829643\n",
      "Gradient for decoder.decoder.6.bias: 4.717537740361877e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.0677555501461029\n",
      "Gradient for encoder.encoder.0.bias: 9.722458255145838e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.009291850961744785\n",
      "Gradient for encoder.encoder.1.bias: 0.007758340332657099\n",
      "Gradient for encoder.encoder.3.weight: 0.19781385362148285\n",
      "Gradient for encoder.encoder.3.bias: 1.1046384917889895e-09\n",
      "Gradient for encoder.encoder.4.weight: 0.01972033455967903\n",
      "Gradient for encoder.encoder.4.bias: 0.019023356959223747\n",
      "Gradient for encoder.mean.weight: 0.255799800157547\n",
      "Gradient for encoder.mean.bias: 0.013087404891848564\n",
      "Gradient for encoder.log_var.weight: 0.14509795606136322\n",
      "Gradient for encoder.log_var.bias: 0.007216524798423052\n",
      "Gradient for decoder.decoder.0.weight: 0.018183765932917595\n",
      "Gradient for decoder.decoder.0.bias: 1.5829437760572773e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0010055864695459604\n",
      "Gradient for decoder.decoder.1.bias: 0.0006940309540368617\n",
      "Gradient for decoder.decoder.3.weight: 0.014835515059530735\n",
      "Gradient for decoder.decoder.3.bias: 1.3306863944073655e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0008667036890983582\n",
      "Gradient for decoder.decoder.4.bias: 0.0009485098998993635\n",
      "Gradient for decoder.decoder.6.weight: 0.0012702001258730888\n",
      "Gradient for decoder.decoder.6.bias: 0.00010703904263209552\n",
      "Gradient for encoder.encoder.0.weight: 0.10689359158277512\n",
      "Gradient for encoder.encoder.0.bias: 1.3998621706257097e-10\n",
      "Gradient for encoder.encoder.1.weight: 0.00927850790321827\n",
      "Gradient for encoder.encoder.1.bias: 0.006897322367876768\n",
      "Gradient for encoder.encoder.3.weight: 0.20533737540245056\n",
      "Gradient for encoder.encoder.3.bias: 9.430745073757407e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.015646133571863174\n",
      "Gradient for encoder.encoder.4.bias: 0.01274804212152958\n",
      "Gradient for encoder.mean.weight: 0.21201074123382568\n",
      "Gradient for encoder.mean.bias: 0.010967683047056198\n",
      "Gradient for encoder.log_var.weight: 0.1104835569858551\n",
      "Gradient for encoder.log_var.bias: 0.006430287845432758\n",
      "Gradient for decoder.decoder.0.weight: 0.015243826434016228\n",
      "Gradient for decoder.decoder.0.bias: 1.264926913213671e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0008579722489230335\n",
      "Gradient for decoder.decoder.1.bias: 0.000592234602663666\n",
      "Gradient for decoder.decoder.3.weight: 0.012767582200467587\n",
      "Gradient for decoder.decoder.3.bias: 9.513924370541105e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00046215736074373126\n",
      "Gradient for decoder.decoder.4.bias: 0.000395600131014362\n",
      "Gradient for decoder.decoder.6.weight: 0.0008153475355356932\n",
      "Gradient for decoder.decoder.6.bias: 4.4093725591665134e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.10427888482809067\n",
      "Gradient for encoder.encoder.0.bias: 1.4894455113712013e-10\n",
      "Gradient for encoder.encoder.1.weight: 0.008446527644991875\n",
      "Gradient for encoder.encoder.1.bias: 0.0063482290133833885\n",
      "Gradient for encoder.encoder.3.weight: 0.18565642833709717\n",
      "Gradient for encoder.encoder.3.bias: 9.77017911019118e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.016642095521092415\n",
      "Gradient for encoder.encoder.4.bias: 0.015174368396401405\n",
      "Gradient for encoder.mean.weight: 0.21313458681106567\n",
      "Gradient for encoder.mean.bias: 0.008703954517841339\n",
      "Gradient for encoder.log_var.weight: 0.1174577921628952\n",
      "Gradient for encoder.log_var.bias: 0.0049082254990935326\n",
      "Gradient for decoder.decoder.0.weight: 0.010403547435998917\n",
      "Gradient for decoder.decoder.0.bias: 9.110808635304224e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005272108828648925\n",
      "Gradient for decoder.decoder.1.bias: 0.00036980974255129695\n",
      "Gradient for decoder.decoder.3.weight: 0.008499454706907272\n",
      "Gradient for decoder.decoder.3.bias: 1.059656459800884e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0008050004835240543\n",
      "Gradient for decoder.decoder.4.bias: 0.0009718621731735766\n",
      "Gradient for decoder.decoder.6.weight: 0.0009576114825904369\n",
      "Gradient for decoder.decoder.6.bias: 7.713357626926154e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.05702643468976021\n",
      "Gradient for encoder.encoder.0.bias: 8.547929031266222e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.005986325908452272\n",
      "Gradient for encoder.encoder.1.bias: 0.005270443391054869\n",
      "Gradient for encoder.encoder.3.weight: 0.13926851749420166\n",
      "Gradient for encoder.encoder.3.bias: 9.555692903617796e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.014876896515488625\n",
      "Gradient for encoder.encoder.4.bias: 0.012770986184477806\n",
      "Gradient for encoder.mean.weight: 0.17948660254478455\n",
      "Gradient for encoder.mean.bias: 0.009038030169904232\n",
      "Gradient for encoder.log_var.weight: 0.10028576850891113\n",
      "Gradient for encoder.log_var.bias: 0.0064943223260343075\n",
      "Gradient for decoder.decoder.0.weight: 0.01886758953332901\n",
      "Gradient for decoder.decoder.0.bias: 1.6021750592898343e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0010226501617580652\n",
      "Gradient for decoder.decoder.1.bias: 0.0007129248697310686\n",
      "Gradient for decoder.decoder.3.weight: 0.015791285783052444\n",
      "Gradient for decoder.decoder.3.bias: 1.273383898325875e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0006636042962782085\n",
      "Gradient for decoder.decoder.4.bias: 0.0006519462913274765\n",
      "Gradient for decoder.decoder.6.weight: 0.0009558193851262331\n",
      "Gradient for decoder.decoder.6.bias: 5.882039477000944e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.056054022163152695\n",
      "Gradient for encoder.encoder.0.bias: 8.957801167497337e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.007743319030851126\n",
      "Gradient for encoder.encoder.1.bias: 0.005049478262662888\n",
      "Gradient for encoder.encoder.3.weight: 0.15744192898273468\n",
      "Gradient for encoder.encoder.3.bias: 9.036917325566662e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.015634268522262573\n",
      "Gradient for encoder.encoder.4.bias: 0.015702631324529648\n",
      "Gradient for encoder.mean.weight: 0.19377201795578003\n",
      "Gradient for encoder.mean.bias: 0.012258459813892841\n",
      "Gradient for encoder.log_var.weight: 0.10421939939260483\n",
      "Gradient for encoder.log_var.bias: 0.006051027216017246\n",
      "Gradient for decoder.decoder.0.weight: 0.015272989869117737\n",
      "Gradient for decoder.decoder.0.bias: 1.26951088530447e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0008199728326871991\n",
      "Gradient for decoder.decoder.1.bias: 0.000608025467954576\n",
      "Gradient for decoder.decoder.3.weight: 0.012635556980967522\n",
      "Gradient for decoder.decoder.3.bias: 9.58212814650139e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.000498094828799367\n",
      "Gradient for decoder.decoder.4.bias: 0.000472052488476038\n",
      "Gradient for decoder.decoder.6.weight: 0.0008743926300667226\n",
      "Gradient for decoder.decoder.6.bias: 5.766039248555899e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.07858908921480179\n",
      "Gradient for encoder.encoder.0.bias: 1.013592890175552e-10\n",
      "Gradient for encoder.encoder.1.weight: 0.007765071000903845\n",
      "Gradient for encoder.encoder.1.bias: 0.005186844151467085\n",
      "Gradient for encoder.encoder.3.weight: 0.16284406185150146\n",
      "Gradient for encoder.encoder.3.bias: 1.0970677699617681e-09\n",
      "Gradient for encoder.encoder.4.weight: 0.01604866236448288\n",
      "Gradient for encoder.encoder.4.bias: 0.016972895711660385\n",
      "Gradient for encoder.mean.weight: 0.21530164778232574\n",
      "Gradient for encoder.mean.bias: 0.01252045389264822\n",
      "Gradient for encoder.log_var.weight: 0.10979905724525452\n",
      "Gradient for encoder.log_var.bias: 0.006534998770803213\n",
      "Gradient for decoder.decoder.0.weight: 0.015647483989596367\n",
      "Gradient for decoder.decoder.0.bias: 1.5052059598730239e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0009214974706992507\n",
      "Gradient for decoder.decoder.1.bias: 0.0005801193765364587\n",
      "Gradient for decoder.decoder.3.weight: 0.013437076471745968\n",
      "Gradient for decoder.decoder.3.bias: 1.2446917108110966e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0005060326075181365\n",
      "Gradient for decoder.decoder.4.bias: 0.00046782323624938726\n",
      "Gradient for decoder.decoder.6.weight: 0.0008324248483404517\n",
      "Gradient for decoder.decoder.6.bias: 4.3431824451545253e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.09158417582511902\n",
      "Gradient for encoder.encoder.0.bias: 1.29872071430448e-10\n",
      "Gradient for encoder.encoder.1.weight: 0.008450324647128582\n",
      "Gradient for encoder.encoder.1.bias: 0.0061240652576088905\n",
      "Gradient for encoder.encoder.3.weight: 0.17840485274791718\n",
      "Gradient for encoder.encoder.3.bias: 1.2140214389333437e-09\n",
      "Gradient for encoder.encoder.4.weight: 0.01736883632838726\n",
      "Gradient for encoder.encoder.4.bias: 0.018441520631313324\n",
      "Gradient for encoder.mean.weight: 0.213317409157753\n",
      "Gradient for encoder.mean.bias: 0.01170288398861885\n",
      "Gradient for encoder.log_var.weight: 0.1255829632282257\n",
      "Gradient for encoder.log_var.bias: 0.00851229578256607\n",
      "Gradient for decoder.decoder.0.weight: 0.015404216945171356\n",
      "Gradient for decoder.decoder.0.bias: 1.3592039993515215e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0007785950438119471\n",
      "Gradient for decoder.decoder.1.bias: 0.0005752091528847814\n",
      "Gradient for decoder.decoder.3.weight: 0.01214286033064127\n",
      "Gradient for decoder.decoder.3.bias: 9.164823067120409e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00047348730731755495\n",
      "Gradient for decoder.decoder.4.bias: 0.000495725660584867\n",
      "Gradient for decoder.decoder.6.weight: 0.000845394330099225\n",
      "Gradient for decoder.decoder.6.bias: 5.4288266255753115e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.0691743791103363\n",
      "Gradient for encoder.encoder.0.bias: 9.515881832511397e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.006937575060874224\n",
      "Gradient for encoder.encoder.1.bias: 0.005445986520498991\n",
      "Gradient for encoder.encoder.3.weight: 0.1529947966337204\n",
      "Gradient for encoder.encoder.3.bias: 6.993974288604932e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.01246108952909708\n",
      "Gradient for encoder.encoder.4.bias: 0.010483518242835999\n",
      "Gradient for encoder.mean.weight: 0.1750919371843338\n",
      "Gradient for encoder.mean.bias: 0.008672780357301235\n",
      "Gradient for encoder.log_var.weight: 0.09404054284095764\n",
      "Gradient for encoder.log_var.bias: 0.004216345492750406\n",
      "Gradient for decoder.decoder.0.weight: 0.016317764297127724\n",
      "Gradient for decoder.decoder.0.bias: 1.3701829948420396e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0009021650184877217\n",
      "Gradient for decoder.decoder.1.bias: 0.0006122476770542562\n",
      "Gradient for decoder.decoder.3.weight: 0.013811470940709114\n",
      "Gradient for decoder.decoder.3.bias: 1.0331856897805025e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0005244733765721321\n",
      "Gradient for decoder.decoder.4.bias: 0.00043592805741354823\n",
      "Gradient for decoder.decoder.6.weight: 0.0009655572357587516\n",
      "Gradient for decoder.decoder.6.bias: 5.901921394979581e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.07093389332294464\n",
      "Gradient for encoder.encoder.0.bias: 1.052648662680511e-10\n",
      "Gradient for encoder.encoder.1.weight: 0.00799923948943615\n",
      "Gradient for encoder.encoder.1.bias: 0.0061225746758282185\n",
      "Gradient for encoder.encoder.3.weight: 0.18284736573696136\n",
      "Gradient for encoder.encoder.3.bias: 8.308245202925946e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.015559211373329163\n",
      "Gradient for encoder.encoder.4.bias: 0.01323151309043169\n",
      "Gradient for encoder.mean.weight: 0.2005387842655182\n",
      "Gradient for encoder.mean.bias: 0.008194252848625183\n",
      "Gradient for encoder.log_var.weight: 0.11262235045433044\n",
      "Gradient for encoder.log_var.bias: 0.004085928667336702\n",
      "Gradient for decoder.decoder.0.weight: 0.015243029221892357\n",
      "Gradient for decoder.decoder.0.bias: 1.2877240940234458e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0008431796450167894\n",
      "Gradient for decoder.decoder.1.bias: 0.0005542879807762802\n",
      "Gradient for decoder.decoder.3.weight: 0.012344230897724628\n",
      "Gradient for decoder.decoder.3.bias: 9.663093936129741e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00048225975478999317\n",
      "Gradient for decoder.decoder.4.bias: 0.0005076659144833684\n",
      "Gradient for decoder.decoder.6.weight: 0.0008423477993346751\n",
      "Gradient for decoder.decoder.6.bias: 4.897402322967537e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.07269255071878433\n",
      "Gradient for encoder.encoder.0.bias: 1.0071408984568819e-10\n",
      "Gradient for encoder.encoder.1.weight: 0.007909134961664677\n",
      "Gradient for encoder.encoder.1.bias: 0.005804914515465498\n",
      "Gradient for encoder.encoder.3.weight: 0.16574859619140625\n",
      "Gradient for encoder.encoder.3.bias: 9.195540440209982e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.01460249163210392\n",
      "Gradient for encoder.encoder.4.bias: 0.01300914864987135\n",
      "Gradient for encoder.mean.weight: 0.18375343084335327\n",
      "Gradient for encoder.mean.bias: 0.00851862970739603\n",
      "Gradient for encoder.log_var.weight: 0.10362376272678375\n",
      "Gradient for encoder.log_var.bias: 0.004647715482860804\n",
      "Gradient for decoder.decoder.0.weight: 0.0176997072994709\n",
      "Gradient for decoder.decoder.0.bias: 1.265685334317368e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0009251192095689476\n",
      "Gradient for decoder.decoder.1.bias: 0.00063626270275563\n",
      "Gradient for decoder.decoder.3.weight: 0.014785745181143284\n",
      "Gradient for decoder.decoder.3.bias: 1.0810817518969174e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0005981827853247523\n",
      "Gradient for decoder.decoder.4.bias: 0.0005249531823210418\n",
      "Gradient for decoder.decoder.6.weight: 0.0011114738881587982\n",
      "Gradient for decoder.decoder.6.bias: 8.301193884108216e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training VAE Epoch:  72%|███████▏  | 57/79 [00:00<00:00, 73.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient for encoder.encoder.0.weight: 0.07907920330762863\n",
      "Gradient for encoder.encoder.0.bias: 1.2082557176995579e-10\n",
      "Gradient for encoder.encoder.1.weight: 0.008041368797421455\n",
      "Gradient for encoder.encoder.1.bias: 0.006314641796052456\n",
      "Gradient for encoder.encoder.3.weight: 0.17749331891536713\n",
      "Gradient for encoder.encoder.3.bias: 1.0421324914133834e-09\n",
      "Gradient for encoder.encoder.4.weight: 0.018803300336003304\n",
      "Gradient for encoder.encoder.4.bias: 0.01717705838382244\n",
      "Gradient for encoder.mean.weight: 0.25453928112983704\n",
      "Gradient for encoder.mean.bias: 0.01181249599903822\n",
      "Gradient for encoder.log_var.weight: 0.1497652679681778\n",
      "Gradient for encoder.log_var.bias: 0.00814986415207386\n",
      "Gradient for decoder.decoder.0.weight: 0.01666703261435032\n",
      "Gradient for decoder.decoder.0.bias: 1.351488365664011e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0008978010155260563\n",
      "Gradient for decoder.decoder.1.bias: 0.0005787831614725292\n",
      "Gradient for decoder.decoder.3.weight: 0.014476174488663673\n",
      "Gradient for decoder.decoder.3.bias: 1.0744929251904622e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0005497082020156085\n",
      "Gradient for decoder.decoder.4.bias: 0.00045372231397777796\n",
      "Gradient for decoder.decoder.6.weight: 0.00092754588695243\n",
      "Gradient for decoder.decoder.6.bias: 5.7555382227292284e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.06297865509986877\n",
      "Gradient for encoder.encoder.0.bias: 9.380213272791593e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.006931455340236425\n",
      "Gradient for encoder.encoder.1.bias: 0.005969932768493891\n",
      "Gradient for encoder.encoder.3.weight: 0.15968985855579376\n",
      "Gradient for encoder.encoder.3.bias: 8.701583342762831e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.01648334413766861\n",
      "Gradient for encoder.encoder.4.bias: 0.014832014217972755\n",
      "Gradient for encoder.mean.weight: 0.2110435664653778\n",
      "Gradient for encoder.mean.bias: 0.010697607882320881\n",
      "Gradient for encoder.log_var.weight: 0.10157206654548645\n",
      "Gradient for encoder.log_var.bias: 0.006194164976477623\n",
      "Gradient for decoder.decoder.0.weight: 0.016194680705666542\n",
      "Gradient for decoder.decoder.0.bias: 1.2923553893706696e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0009031372028402984\n",
      "Gradient for decoder.decoder.1.bias: 0.0005998320411890745\n",
      "Gradient for decoder.decoder.3.weight: 0.013894866220653057\n",
      "Gradient for decoder.decoder.3.bias: 1.0290542723501162e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0005188051145523787\n",
      "Gradient for decoder.decoder.4.bias: 0.0004832229751627892\n",
      "Gradient for decoder.decoder.6.weight: 0.0007943618693388999\n",
      "Gradient for decoder.decoder.6.bias: 3.8625021261395887e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.08636025339365005\n",
      "Gradient for encoder.encoder.0.bias: 1.1926290510722026e-10\n",
      "Gradient for encoder.encoder.1.weight: 0.009246917441487312\n",
      "Gradient for encoder.encoder.1.bias: 0.0076711419969797134\n",
      "Gradient for encoder.encoder.3.weight: 0.2050294727087021\n",
      "Gradient for encoder.encoder.3.bias: 9.988483373746249e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.017956731840968132\n",
      "Gradient for encoder.encoder.4.bias: 0.014499431475996971\n",
      "Gradient for encoder.mean.weight: 0.22750698029994965\n",
      "Gradient for encoder.mean.bias: 0.0059294854290783405\n",
      "Gradient for encoder.log_var.weight: 0.1297374814748764\n",
      "Gradient for encoder.log_var.bias: 0.0035186547320336103\n",
      "Gradient for decoder.decoder.0.weight: 0.01701415330171585\n",
      "Gradient for decoder.decoder.0.bias: 1.320845377517088e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0008708071545697749\n",
      "Gradient for decoder.decoder.1.bias: 0.0006038861465640366\n",
      "Gradient for decoder.decoder.3.weight: 0.013907656073570251\n",
      "Gradient for decoder.decoder.3.bias: 1.0790983384634245e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0005609286017715931\n",
      "Gradient for decoder.decoder.4.bias: 0.0005102302529849112\n",
      "Gradient for decoder.decoder.6.weight: 0.0008639108273200691\n",
      "Gradient for decoder.decoder.6.bias: 4.5338420022744685e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.0894964262843132\n",
      "Gradient for encoder.encoder.0.bias: 1.1563678486981033e-10\n",
      "Gradient for encoder.encoder.1.weight: 0.008103934116661549\n",
      "Gradient for encoder.encoder.1.bias: 0.006487201899290085\n",
      "Gradient for encoder.encoder.3.weight: 0.17704825103282928\n",
      "Gradient for encoder.encoder.3.bias: 1.0815445206091567e-09\n",
      "Gradient for encoder.encoder.4.weight: 0.017832208424806595\n",
      "Gradient for encoder.encoder.4.bias: 0.016148308292031288\n",
      "Gradient for encoder.mean.weight: 0.19685843586921692\n",
      "Gradient for encoder.mean.bias: 0.011873267590999603\n",
      "Gradient for encoder.log_var.weight: 0.10118792206048965\n",
      "Gradient for encoder.log_var.bias: 0.007243708707392216\n",
      "Gradient for decoder.decoder.0.weight: 0.015577963553369045\n",
      "Gradient for decoder.decoder.0.bias: 1.348226252861906e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0008298202883452177\n",
      "Gradient for decoder.decoder.1.bias: 0.0005577579140663147\n",
      "Gradient for decoder.decoder.3.weight: 0.013091007247567177\n",
      "Gradient for decoder.decoder.3.bias: 9.352675578444547e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0004954741452820599\n",
      "Gradient for decoder.decoder.4.bias: 0.0004385177744552493\n",
      "Gradient for decoder.decoder.6.weight: 0.0008146780892275274\n",
      "Gradient for decoder.decoder.6.bias: 4.1527011489961296e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.08318311721086502\n",
      "Gradient for encoder.encoder.0.bias: 1.305687918895515e-10\n",
      "Gradient for encoder.encoder.1.weight: 0.010338135994970798\n",
      "Gradient for encoder.encoder.1.bias: 0.007461603730916977\n",
      "Gradient for encoder.encoder.3.weight: 0.2218456119298935\n",
      "Gradient for encoder.encoder.3.bias: 1.1207511585453744e-09\n",
      "Gradient for encoder.encoder.4.weight: 0.019367486238479614\n",
      "Gradient for encoder.encoder.4.bias: 0.02028314769268036\n",
      "Gradient for encoder.mean.weight: 0.24665997922420502\n",
      "Gradient for encoder.mean.bias: 0.01525297574698925\n",
      "Gradient for encoder.log_var.weight: 0.14073774218559265\n",
      "Gradient for encoder.log_var.bias: 0.010761200450360775\n",
      "Gradient for decoder.decoder.0.weight: 0.015919066965579987\n",
      "Gradient for decoder.decoder.0.bias: 1.310854064184852e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0008838874637149274\n",
      "Gradient for decoder.decoder.1.bias: 0.0006158382166177034\n",
      "Gradient for decoder.decoder.3.weight: 0.013272292912006378\n",
      "Gradient for decoder.decoder.3.bias: 1.0035244857320436e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.00052373151993379\n",
      "Gradient for decoder.decoder.4.bias: 0.0005416519707068801\n",
      "Gradient for decoder.decoder.6.weight: 0.0007941940566524863\n",
      "Gradient for decoder.decoder.6.bias: 4.436194649315439e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.06753120571374893\n",
      "Gradient for encoder.encoder.0.bias: 1.1044903186485655e-10\n",
      "Gradient for encoder.encoder.1.weight: 0.0107535719871521\n",
      "Gradient for encoder.encoder.1.bias: 0.007462147623300552\n",
      "Gradient for encoder.encoder.3.weight: 0.23114629089832306\n",
      "Gradient for encoder.encoder.3.bias: 1.1266517718766522e-09\n",
      "Gradient for encoder.encoder.4.weight: 0.02106495015323162\n",
      "Gradient for encoder.encoder.4.bias: 0.021426895633339882\n",
      "Gradient for encoder.mean.weight: 0.29069992899894714\n",
      "Gradient for encoder.mean.bias: 0.015317942015826702\n",
      "Gradient for encoder.log_var.weight: 0.16103041172027588\n",
      "Gradient for encoder.log_var.bias: 0.010052643716335297\n",
      "Gradient for decoder.decoder.0.weight: 0.016380617395043373\n",
      "Gradient for decoder.decoder.0.bias: 1.332232379969156e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0008868433069437742\n",
      "Gradient for decoder.decoder.1.bias: 0.0006337700760923326\n",
      "Gradient for decoder.decoder.3.weight: 0.013806943781673908\n",
      "Gradient for decoder.decoder.3.bias: 9.630993225151485e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0004682669532485306\n",
      "Gradient for decoder.decoder.4.bias: 0.0004614125064108521\n",
      "Gradient for decoder.decoder.6.weight: 0.0008607026538811624\n",
      "Gradient for decoder.decoder.6.bias: 5.095562300994061e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.08227847516536713\n",
      "Gradient for encoder.encoder.0.bias: 1.1996423299187597e-10\n",
      "Gradient for encoder.encoder.1.weight: 0.008777436800301075\n",
      "Gradient for encoder.encoder.1.bias: 0.006066570989787579\n",
      "Gradient for encoder.encoder.3.weight: 0.19613754749298096\n",
      "Gradient for encoder.encoder.3.bias: 9.179131343906022e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.01737760379910469\n",
      "Gradient for encoder.encoder.4.bias: 0.01400630921125412\n",
      "Gradient for encoder.mean.weight: 0.23480921983718872\n",
      "Gradient for encoder.mean.bias: 0.009698737412691116\n",
      "Gradient for encoder.log_var.weight: 0.12381184101104736\n",
      "Gradient for encoder.log_var.bias: 0.0059639327228069305\n",
      "Gradient for decoder.decoder.0.weight: 0.013311950489878654\n",
      "Gradient for decoder.decoder.0.bias: 1.1638302127581213e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0007312336820177734\n",
      "Gradient for decoder.decoder.1.bias: 0.0004883100627921522\n",
      "Gradient for decoder.decoder.3.weight: 0.011086951941251755\n",
      "Gradient for decoder.decoder.3.bias: 9.169624087812522e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0005387815763242543\n",
      "Gradient for decoder.decoder.4.bias: 0.0006225776742212474\n",
      "Gradient for decoder.decoder.6.weight: 0.0008042035042308271\n",
      "Gradient for decoder.decoder.6.bias: 4.7054694732651114e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.06661748141050339\n",
      "Gradient for encoder.encoder.0.bias: 8.59202153868921e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.007051827851682901\n",
      "Gradient for encoder.encoder.1.bias: 0.00522488821297884\n",
      "Gradient for encoder.encoder.3.weight: 0.15341097116470337\n",
      "Gradient for encoder.encoder.3.bias: 7.876770347081674e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.014328441582620144\n",
      "Gradient for encoder.encoder.4.bias: 0.014529390260577202\n",
      "Gradient for encoder.mean.weight: 0.18032106757164001\n",
      "Gradient for encoder.mean.bias: 0.010346399620175362\n",
      "Gradient for encoder.log_var.weight: 0.0985245555639267\n",
      "Gradient for encoder.log_var.bias: 0.006092490162700415\n",
      "Gradient for decoder.decoder.0.weight: 0.01720074936747551\n",
      "Gradient for decoder.decoder.0.bias: 1.5604395553481254e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0008961011772044003\n",
      "Gradient for decoder.decoder.1.bias: 0.0006210228311829269\n",
      "Gradient for decoder.decoder.3.weight: 0.01424657553434372\n",
      "Gradient for decoder.decoder.3.bias: 1.392539000777404e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0006286849384196103\n",
      "Gradient for decoder.decoder.4.bias: 0.0006742851110175252\n",
      "Gradient for decoder.decoder.6.weight: 0.0010122159728780389\n",
      "Gradient for decoder.decoder.6.bias: 7.728795753791928e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.0795847624540329\n",
      "Gradient for encoder.encoder.0.bias: 9.413005791492068e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.007494896184653044\n",
      "Gradient for encoder.encoder.1.bias: 0.005120015703141689\n",
      "Gradient for encoder.encoder.3.weight: 0.16741320490837097\n",
      "Gradient for encoder.encoder.3.bias: 8.933378481401633e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.014675851911306381\n",
      "Gradient for encoder.encoder.4.bias: 0.012616632506251335\n",
      "Gradient for encoder.mean.weight: 0.17693991959095\n",
      "Gradient for encoder.mean.bias: 0.00855268444865942\n",
      "Gradient for encoder.log_var.weight: 0.09937712550163269\n",
      "Gradient for encoder.log_var.bias: 0.005416775122284889\n",
      "Gradient for decoder.decoder.0.weight: 0.01684124395251274\n",
      "Gradient for decoder.decoder.0.bias: 1.3626103023689495e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.000897849618922919\n",
      "Gradient for decoder.decoder.1.bias: 0.0006238095811568201\n",
      "Gradient for decoder.decoder.3.weight: 0.013745722360908985\n",
      "Gradient for decoder.decoder.3.bias: 1.1876113981124092e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0005104569718241692\n",
      "Gradient for decoder.decoder.4.bias: 0.0004849621036555618\n",
      "Gradient for decoder.decoder.6.weight: 0.0008245498756878078\n",
      "Gradient for decoder.decoder.6.bias: 4.4628184696193784e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.09166381508111954\n",
      "Gradient for encoder.encoder.0.bias: 1.2272061145068847e-10\n",
      "Gradient for encoder.encoder.1.weight: 0.006936195306479931\n",
      "Gradient for encoder.encoder.1.bias: 0.005597434937953949\n",
      "Gradient for encoder.encoder.3.weight: 0.16119740903377533\n",
      "Gradient for encoder.encoder.3.bias: 8.438763021700879e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.014971937984228134\n",
      "Gradient for encoder.encoder.4.bias: 0.012370819225907326\n",
      "Gradient for encoder.mean.weight: 0.19668231904506683\n",
      "Gradient for encoder.mean.bias: 0.007115446031093597\n",
      "Gradient for encoder.log_var.weight: 0.104426808655262\n",
      "Gradient for encoder.log_var.bias: 0.003425405826419592\n",
      "Gradient for decoder.decoder.0.weight: 0.011803334578871727\n",
      "Gradient for decoder.decoder.0.bias: 1.0352495943832807e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0006533245323225856\n",
      "Gradient for decoder.decoder.1.bias: 0.00042980752186849713\n",
      "Gradient for decoder.decoder.3.weight: 0.01023141760379076\n",
      "Gradient for decoder.decoder.3.bias: 9.286488938942128e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0006304935668595135\n",
      "Gradient for decoder.decoder.4.bias: 0.0008018621592782438\n",
      "Gradient for decoder.decoder.6.weight: 0.0008522460702806711\n",
      "Gradient for decoder.decoder.6.bias: 5.766052345279604e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.05733335763216019\n",
      "Gradient for encoder.encoder.0.bias: 8.230253978336322e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.005963596049696207\n",
      "Gradient for encoder.encoder.1.bias: 0.004723928868770599\n",
      "Gradient for encoder.encoder.3.weight: 0.13612118363380432\n",
      "Gradient for encoder.encoder.3.bias: 7.206851782015633e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.012796915136277676\n",
      "Gradient for encoder.encoder.4.bias: 0.012781547382473946\n",
      "Gradient for encoder.mean.weight: 0.17082835733890533\n",
      "Gradient for encoder.mean.bias: 0.008831980638206005\n",
      "Gradient for encoder.log_var.weight: 0.09854493290185928\n",
      "Gradient for encoder.log_var.bias: 0.006850968115031719\n",
      "Gradient for decoder.decoder.0.weight: 0.016932204365730286\n",
      "Gradient for decoder.decoder.0.bias: 1.4033994799600435e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0009463455644436181\n",
      "Gradient for decoder.decoder.1.bias: 0.0006254028994590044\n",
      "Gradient for decoder.decoder.3.weight: 0.014540350995957851\n",
      "Gradient for decoder.decoder.3.bias: 1.0582217047083731e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0005581711884588003\n",
      "Gradient for decoder.decoder.4.bias: 0.00044645759044215083\n",
      "Gradient for decoder.decoder.6.weight: 0.0009014538954943419\n",
      "Gradient for decoder.decoder.6.bias: 5.526527456822805e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.06487376987934113\n",
      "Gradient for encoder.encoder.0.bias: 1.0358954666278564e-10\n",
      "Gradient for encoder.encoder.1.weight: 0.007671365048736334\n",
      "Gradient for encoder.encoder.1.bias: 0.006054576952010393\n",
      "Gradient for encoder.encoder.3.weight: 0.16202114522457123\n",
      "Gradient for encoder.encoder.3.bias: 1.042237518511513e-09\n",
      "Gradient for encoder.encoder.4.weight: 0.015103115700185299\n",
      "Gradient for encoder.encoder.4.bias: 0.014779442921280861\n",
      "Gradient for encoder.mean.weight: 0.19754882156848907\n",
      "Gradient for encoder.mean.bias: 0.011723827570676804\n",
      "Gradient for encoder.log_var.weight: 0.09991484135389328\n",
      "Gradient for encoder.log_var.bias: 0.00606200285255909\n",
      "Gradient for decoder.decoder.0.weight: 0.014628984965384007\n",
      "Gradient for decoder.decoder.0.bias: 1.287788348180996e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0007768936338834465\n",
      "Gradient for decoder.decoder.1.bias: 0.0005471958429552615\n",
      "Gradient for decoder.decoder.3.weight: 0.012224514037370682\n",
      "Gradient for decoder.decoder.3.bias: 9.558217411997916e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.000439396157162264\n",
      "Gradient for decoder.decoder.4.bias: 0.00043346453458070755\n",
      "Gradient for decoder.decoder.6.weight: 0.0007928938721306622\n",
      "Gradient for decoder.decoder.6.bias: 4.2481638956815004e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.06014063209295273\n",
      "Gradient for encoder.encoder.0.bias: 9.585283955448887e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0076889037154614925\n",
      "Gradient for encoder.encoder.1.bias: 0.0052467104978859425\n",
      "Gradient for encoder.encoder.3.weight: 0.17650263011455536\n",
      "Gradient for encoder.encoder.3.bias: 8.624449487903973e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.017645930871367455\n",
      "Gradient for encoder.encoder.4.bias: 0.012967525981366634\n",
      "Gradient for encoder.mean.weight: 0.21811443567276\n",
      "Gradient for encoder.mean.bias: 0.007743471302092075\n",
      "Gradient for encoder.log_var.weight: 0.11247871071100235\n",
      "Gradient for encoder.log_var.bias: 0.004199467599391937\n",
      "Gradient for decoder.decoder.0.weight: 0.01466331910341978\n",
      "Gradient for decoder.decoder.0.bias: 1.1281103134974657e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.000809724791906774\n",
      "Gradient for decoder.decoder.1.bias: 0.0005973032093606889\n",
      "Gradient for decoder.decoder.3.weight: 0.012627549469470978\n",
      "Gradient for decoder.decoder.3.bias: 9.95503401934883e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.000636195472907275\n",
      "Gradient for decoder.decoder.4.bias: 0.0007185045978985727\n",
      "Gradient for decoder.decoder.6.weight: 0.0009593963040970266\n",
      "Gradient for decoder.decoder.6.bias: 7.231423660414293e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.05822356417775154\n",
      "Gradient for encoder.encoder.0.bias: 8.12914943693066e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.00539438845589757\n",
      "Gradient for encoder.encoder.1.bias: 0.004260520916432142\n",
      "Gradient for encoder.encoder.3.weight: 0.11362757533788681\n",
      "Gradient for encoder.encoder.3.bias: 7.594523343534831e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.011510851792991161\n",
      "Gradient for encoder.encoder.4.bias: 0.011879587545990944\n",
      "Gradient for encoder.mean.weight: 0.15861988067626953\n",
      "Gradient for encoder.mean.bias: 0.010164659470319748\n",
      "Gradient for encoder.log_var.weight: 0.08856169879436493\n",
      "Gradient for encoder.log_var.bias: 0.00636602658778429\n",
      "Gradient for decoder.decoder.0.weight: 0.015652133151888847\n",
      "Gradient for decoder.decoder.0.bias: 1.3828302392049352e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0008704002830199897\n",
      "Gradient for decoder.decoder.1.bias: 0.0006533734267577529\n",
      "Gradient for decoder.decoder.3.weight: 0.013105634599924088\n",
      "Gradient for decoder.decoder.3.bias: 1.0251502424729608e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0005307190585881472\n",
      "Gradient for decoder.decoder.4.bias: 0.0005350703722797334\n",
      "Gradient for decoder.decoder.6.weight: 0.0008430582820437849\n",
      "Gradient for decoder.decoder.6.bias: 4.509787686401978e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.05626519396901131\n",
      "Gradient for encoder.encoder.0.bias: 8.00789018429171e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.00589092867448926\n",
      "Gradient for encoder.encoder.1.bias: 0.004192698746919632\n",
      "Gradient for encoder.encoder.3.weight: 0.12612052261829376\n",
      "Gradient for encoder.encoder.3.bias: 6.467111846042428e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.012167045846581459\n",
      "Gradient for encoder.encoder.4.bias: 0.009711130522191525\n",
      "Gradient for encoder.mean.weight: 0.15785306692123413\n",
      "Gradient for encoder.mean.bias: 0.006225370801985264\n",
      "Gradient for encoder.log_var.weight: 0.08832503110170364\n",
      "Gradient for encoder.log_var.bias: 0.0035129529424011707\n",
      "Gradient for decoder.decoder.0.weight: 0.013711228035390377\n",
      "Gradient for decoder.decoder.0.bias: 1.0798360122743489e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0007145070703700185\n",
      "Gradient for decoder.decoder.1.bias: 0.0004704316961579025\n",
      "Gradient for decoder.decoder.3.weight: 0.011495387181639671\n",
      "Gradient for decoder.decoder.3.bias: 1.1700999891228747e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.00074725819285959\n",
      "Gradient for decoder.decoder.4.bias: 0.0008916961960494518\n",
      "Gradient for decoder.decoder.6.weight: 0.0009137800079770386\n",
      "Gradient for decoder.decoder.6.bias: 6.83226462570019e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.09541288763284683\n",
      "Gradient for encoder.encoder.0.bias: 1.5970751110483405e-10\n",
      "Gradient for encoder.encoder.1.weight: 0.010655328631401062\n",
      "Gradient for encoder.encoder.1.bias: 0.009015199728310108\n",
      "Gradient for encoder.encoder.3.weight: 0.24101364612579346\n",
      "Gradient for encoder.encoder.3.bias: 1.354409917553312e-09\n",
      "Gradient for encoder.encoder.4.weight: 0.02345220558345318\n",
      "Gradient for encoder.encoder.4.bias: 0.022950991988182068\n",
      "Gradient for encoder.mean.weight: 0.3175720274448395\n",
      "Gradient for encoder.mean.bias: 0.014473401941359043\n",
      "Gradient for encoder.log_var.weight: 0.1797797679901123\n",
      "Gradient for encoder.log_var.bias: 0.009622236713767052\n",
      "Gradient for decoder.decoder.0.weight: 0.01524542085826397\n",
      "Gradient for decoder.decoder.0.bias: 1.4866348430064846e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0008558776462450624\n",
      "Gradient for decoder.decoder.1.bias: 0.000597609207034111\n",
      "Gradient for decoder.decoder.3.weight: 0.013162961229681969\n",
      "Gradient for decoder.decoder.3.bias: 1.1826228885070122e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0004873857251368463\n",
      "Gradient for decoder.decoder.4.bias: 0.0004822061164304614\n",
      "Gradient for decoder.decoder.6.weight: 0.0007791400421410799\n",
      "Gradient for decoder.decoder.6.bias: 3.719933010870591e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training VAE Epoch:  94%|█████████▎| 74/79 [00:01<00:00, 76.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient for encoder.encoder.0.weight: 0.059525661170482635\n",
      "Gradient for encoder.encoder.0.bias: 9.762019664849575e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.006445131730288267\n",
      "Gradient for encoder.encoder.1.bias: 0.005559337325394154\n",
      "Gradient for encoder.encoder.3.weight: 0.14386793971061707\n",
      "Gradient for encoder.encoder.3.bias: 8.287547870189371e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.017607765272259712\n",
      "Gradient for encoder.encoder.4.bias: 0.01520206592977047\n",
      "Gradient for encoder.mean.weight: 0.2123628556728363\n",
      "Gradient for encoder.mean.bias: 0.010255622677505016\n",
      "Gradient for encoder.log_var.weight: 0.12132654339075089\n",
      "Gradient for encoder.log_var.bias: 0.005216316320002079\n",
      "Gradient for decoder.decoder.0.weight: 0.014261823147535324\n",
      "Gradient for decoder.decoder.0.bias: 1.3006738741605517e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0007815223652869463\n",
      "Gradient for decoder.decoder.1.bias: 0.0005226118955761194\n",
      "Gradient for decoder.decoder.3.weight: 0.011746210046112537\n",
      "Gradient for decoder.decoder.3.bias: 1.1195966376220667e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0005647978978231549\n",
      "Gradient for decoder.decoder.4.bias: 0.0006219249335117638\n",
      "Gradient for decoder.decoder.6.weight: 0.0008172304951585829\n",
      "Gradient for decoder.decoder.6.bias: 5.200325176701881e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.05335149168968201\n",
      "Gradient for encoder.encoder.0.bias: 7.978766952687621e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.006441035773605108\n",
      "Gradient for encoder.encoder.1.bias: 0.0051932684145867825\n",
      "Gradient for encoder.encoder.3.weight: 0.14514712989330292\n",
      "Gradient for encoder.encoder.3.bias: 9.056440597454696e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.013687635771930218\n",
      "Gradient for encoder.encoder.4.bias: 0.01563677377998829\n",
      "Gradient for encoder.mean.weight: 0.17758093774318695\n",
      "Gradient for encoder.mean.bias: 0.01105432491749525\n",
      "Gradient for encoder.log_var.weight: 0.08852015435695648\n",
      "Gradient for encoder.log_var.bias: 0.006140830926597118\n",
      "Gradient for decoder.decoder.0.weight: 0.0176157858222723\n",
      "Gradient for decoder.decoder.0.bias: 1.453924897143466e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0009407710167579353\n",
      "Gradient for decoder.decoder.1.bias: 0.0006694118492305279\n",
      "Gradient for decoder.decoder.3.weight: 0.014655489474534988\n",
      "Gradient for decoder.decoder.3.bias: 1.0741788014634324e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0005202559405006468\n",
      "Gradient for decoder.decoder.4.bias: 0.0004615186189766973\n",
      "Gradient for decoder.decoder.6.weight: 0.0009455987601540983\n",
      "Gradient for decoder.decoder.6.bias: 6.684881373075768e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.05216550454497337\n",
      "Gradient for encoder.encoder.0.bias: 8.022305042487687e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.007274341303855181\n",
      "Gradient for encoder.encoder.1.bias: 0.005542167462408543\n",
      "Gradient for encoder.encoder.3.weight: 0.1535271555185318\n",
      "Gradient for encoder.encoder.3.bias: 6.519313422437278e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.010969098657369614\n",
      "Gradient for encoder.encoder.4.bias: 0.010015423409640789\n",
      "Gradient for encoder.mean.weight: 0.15584558248519897\n",
      "Gradient for encoder.mean.bias: 0.00536308903247118\n",
      "Gradient for encoder.log_var.weight: 0.08251793682575226\n",
      "Gradient for encoder.log_var.bias: 0.00368522759526968\n",
      "Gradient for decoder.decoder.0.weight: 0.01825295202434063\n",
      "Gradient for decoder.decoder.0.bias: 1.625222456613784e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0010599041124805808\n",
      "Gradient for decoder.decoder.1.bias: 0.0006839927518740296\n",
      "Gradient for decoder.decoder.3.weight: 0.015314173884689808\n",
      "Gradient for decoder.decoder.3.bias: 1.2890283285216242e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0006958183366805315\n",
      "Gradient for decoder.decoder.4.bias: 0.0007064889068715274\n",
      "Gradient for decoder.decoder.6.weight: 0.0009176491294056177\n",
      "Gradient for decoder.decoder.6.bias: 5.688905730494298e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.06467084586620331\n",
      "Gradient for encoder.encoder.0.bias: 1.1281681838726243e-10\n",
      "Gradient for encoder.encoder.1.weight: 0.010402383282780647\n",
      "Gradient for encoder.encoder.1.bias: 0.006891090422868729\n",
      "Gradient for encoder.encoder.3.weight: 0.21549755334854126\n",
      "Gradient for encoder.encoder.3.bias: 8.996322020671244e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.020534895360469818\n",
      "Gradient for encoder.encoder.4.bias: 0.014524227939546108\n",
      "Gradient for encoder.mean.weight: 0.24725043773651123\n",
      "Gradient for encoder.mean.bias: 0.00774867320433259\n",
      "Gradient for encoder.log_var.weight: 0.12535515427589417\n",
      "Gradient for encoder.log_var.bias: 0.00409681536257267\n",
      "Gradient for decoder.decoder.0.weight: 0.012803501449525356\n",
      "Gradient for decoder.decoder.0.bias: 1.047947978394248e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.000676769413985312\n",
      "Gradient for decoder.decoder.1.bias: 0.0004659069236367941\n",
      "Gradient for decoder.decoder.3.weight: 0.011224291287362576\n",
      "Gradient for decoder.decoder.3.bias: 9.504268899673818e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0005415976629592478\n",
      "Gradient for decoder.decoder.4.bias: 0.0006138642784208059\n",
      "Gradient for decoder.decoder.6.weight: 0.0008139613782986999\n",
      "Gradient for decoder.decoder.6.bias: 4.6459867007797584e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.04853953793644905\n",
      "Gradient for encoder.encoder.0.bias: 7.209747382441734e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.00533845741301775\n",
      "Gradient for encoder.encoder.1.bias: 0.004445395432412624\n",
      "Gradient for encoder.encoder.3.weight: 0.11623809486627579\n",
      "Gradient for encoder.encoder.3.bias: 6.762919113612043e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.011907859705388546\n",
      "Gradient for encoder.encoder.4.bias: 0.009160987101495266\n",
      "Gradient for encoder.mean.weight: 0.15265174210071564\n",
      "Gradient for encoder.mean.bias: 0.0067939055152237415\n",
      "Gradient for encoder.log_var.weight: 0.0873463824391365\n",
      "Gradient for encoder.log_var.bias: 0.0037106843665242195\n",
      "Gradient for decoder.decoder.0.weight: 0.016162171959877014\n",
      "Gradient for decoder.decoder.0.bias: 1.2929647630333108e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0008421820821240544\n",
      "Gradient for decoder.decoder.1.bias: 0.0006067448994144797\n",
      "Gradient for decoder.decoder.3.weight: 0.013491914607584476\n",
      "Gradient for decoder.decoder.3.bias: 1.1665052257470165e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0005485971341840923\n",
      "Gradient for decoder.decoder.4.bias: 0.0005336460890248418\n",
      "Gradient for decoder.decoder.6.weight: 0.0009491784148849547\n",
      "Gradient for decoder.decoder.6.bias: 6.386697350535542e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.10345496237277985\n",
      "Gradient for encoder.encoder.0.bias: 1.5810647235880992e-10\n",
      "Gradient for encoder.encoder.1.weight: 0.01072736456990242\n",
      "Gradient for encoder.encoder.1.bias: 0.008137902244925499\n",
      "Gradient for encoder.encoder.3.weight: 0.22011418640613556\n",
      "Gradient for encoder.encoder.3.bias: 1.0047611631591735e-09\n",
      "Gradient for encoder.encoder.4.weight: 0.018558776006102562\n",
      "Gradient for encoder.encoder.4.bias: 0.015422681346535683\n",
      "Gradient for encoder.mean.weight: 0.2391453981399536\n",
      "Gradient for encoder.mean.bias: 0.009463392198085785\n",
      "Gradient for encoder.log_var.weight: 0.13600589334964752\n",
      "Gradient for encoder.log_var.bias: 0.006075682584196329\n",
      "Gradient for decoder.decoder.0.weight: 0.012693296186625957\n",
      "Gradient for decoder.decoder.0.bias: 1.1410738326445014e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.000665920611936599\n",
      "Gradient for decoder.decoder.1.bias: 0.00044767765211872756\n",
      "Gradient for decoder.decoder.3.weight: 0.010628691874444485\n",
      "Gradient for decoder.decoder.3.bias: 1.0263125765908043e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0005063931457698345\n",
      "Gradient for decoder.decoder.4.bias: 0.0006037591956555843\n",
      "Gradient for decoder.decoder.6.weight: 0.0008399674552492797\n",
      "Gradient for decoder.decoder.6.bias: 5.1537321269279346e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.10219758749008179\n",
      "Gradient for encoder.encoder.0.bias: 1.5222463567443612e-10\n",
      "Gradient for encoder.encoder.1.weight: 0.010388486087322235\n",
      "Gradient for encoder.encoder.1.bias: 0.0077189551666378975\n",
      "Gradient for encoder.encoder.3.weight: 0.23063424229621887\n",
      "Gradient for encoder.encoder.3.bias: 1.109174641023003e-09\n",
      "Gradient for encoder.encoder.4.weight: 0.017459597438573837\n",
      "Gradient for encoder.encoder.4.bias: 0.014994737692177296\n",
      "Gradient for encoder.mean.weight: 0.2198760062456131\n",
      "Gradient for encoder.mean.bias: 0.0077549912966787815\n",
      "Gradient for encoder.log_var.weight: 0.12403464317321777\n",
      "Gradient for encoder.log_var.bias: 0.005011593922972679\n",
      "Gradient for decoder.decoder.0.weight: 0.012631524354219437\n",
      "Gradient for decoder.decoder.0.bias: 1.0374116843347991e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0006552183185704052\n",
      "Gradient for decoder.decoder.1.bias: 0.0004888288676738739\n",
      "Gradient for decoder.decoder.3.weight: 0.010350236669182777\n",
      "Gradient for decoder.decoder.3.bias: 7.88449999733487e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0004180258547421545\n",
      "Gradient for decoder.decoder.4.bias: 0.00041090353624895215\n",
      "Gradient for decoder.decoder.6.weight: 0.0008036508224904537\n",
      "Gradient for decoder.decoder.6.bias: 4.686440297518857e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.05230872333049774\n",
      "Gradient for encoder.encoder.0.bias: 8.218420388672598e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.005457637831568718\n",
      "Gradient for encoder.encoder.1.bias: 0.004006074275821447\n",
      "Gradient for encoder.encoder.3.weight: 0.11737537384033203\n",
      "Gradient for encoder.encoder.3.bias: 8.341560220337385e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.012308924458920956\n",
      "Gradient for encoder.encoder.4.bias: 0.013436428271234035\n",
      "Gradient for encoder.mean.weight: 0.16105936467647552\n",
      "Gradient for encoder.mean.bias: 0.009888618253171444\n",
      "Gradient for encoder.log_var.weight: 0.09824571013450623\n",
      "Gradient for encoder.log_var.bias: 0.006786074489355087\n",
      "Gradient for decoder.decoder.0.weight: 0.014842173084616661\n",
      "Gradient for decoder.decoder.0.bias: 1.298847140951409e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0008295761654153466\n",
      "Gradient for decoder.decoder.1.bias: 0.0005683904164470732\n",
      "Gradient for decoder.decoder.3.weight: 0.012356840074062347\n",
      "Gradient for decoder.decoder.3.bias: 1.1041866032623915e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0005147212650626898\n",
      "Gradient for decoder.decoder.4.bias: 0.000490955077111721\n",
      "Gradient for decoder.decoder.6.weight: 0.0009521400788798928\n",
      "Gradient for decoder.decoder.6.bias: 6.502008909592405e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.06178578734397888\n",
      "Gradient for encoder.encoder.0.bias: 1.0949625928180495e-10\n",
      "Gradient for encoder.encoder.1.weight: 0.00610756129026413\n",
      "Gradient for encoder.encoder.1.bias: 0.004359856713563204\n",
      "Gradient for encoder.encoder.3.weight: 0.12612707912921906\n",
      "Gradient for encoder.encoder.3.bias: 7.252856648598538e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.011441413313150406\n",
      "Gradient for encoder.encoder.4.bias: 0.011107882484793663\n",
      "Gradient for encoder.mean.weight: 0.1487644612789154\n",
      "Gradient for encoder.mean.bias: 0.0076075950637459755\n",
      "Gradient for encoder.log_var.weight: 0.0897601842880249\n",
      "Gradient for encoder.log_var.bias: 0.00454183854162693\n",
      "Gradient for decoder.decoder.0.weight: 0.011900772340595722\n",
      "Gradient for decoder.decoder.0.bias: 9.697866815150391e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005975798703730106\n",
      "Gradient for decoder.decoder.1.bias: 0.00041453365702182055\n",
      "Gradient for decoder.decoder.3.weight: 0.009881832636892796\n",
      "Gradient for decoder.decoder.3.bias: 9.787320953691392e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00047139739035628736\n",
      "Gradient for decoder.decoder.4.bias: 0.0005325808306224644\n",
      "Gradient for decoder.decoder.6.weight: 0.0007756749982945621\n",
      "Gradient for decoder.decoder.6.bias: 4.5925342419650406e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.056145425885915756\n",
      "Gradient for encoder.encoder.0.bias: 8.97792812315501e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.005518061108887196\n",
      "Gradient for encoder.encoder.1.bias: 0.003887354861944914\n",
      "Gradient for encoder.encoder.3.weight: 0.12644466757774353\n",
      "Gradient for encoder.encoder.3.bias: 6.835192967180603e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.011038869619369507\n",
      "Gradient for encoder.encoder.4.bias: 0.008624154143035412\n",
      "Gradient for encoder.mean.weight: 0.14126773178577423\n",
      "Gradient for encoder.mean.bias: 0.006318055093288422\n",
      "Gradient for encoder.log_var.weight: 0.07129749655723572\n",
      "Gradient for encoder.log_var.bias: 0.00348709081299603\n",
      "Gradient for decoder.decoder.0.weight: 0.014098498970270157\n",
      "Gradient for decoder.decoder.0.bias: 1.1379592407267936e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0007463821675628424\n",
      "Gradient for decoder.decoder.1.bias: 0.0005464571295306087\n",
      "Gradient for decoder.decoder.3.weight: 0.012065937742590904\n",
      "Gradient for decoder.decoder.3.bias: 1.094995483175154e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0006873022648505867\n",
      "Gradient for decoder.decoder.4.bias: 0.0008487533777952194\n",
      "Gradient for decoder.decoder.6.weight: 0.0009330232278443873\n",
      "Gradient for decoder.decoder.6.bias: 7.511179137509316e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.051989227533340454\n",
      "Gradient for encoder.encoder.0.bias: 7.099661136766855e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.007374120876193047\n",
      "Gradient for encoder.encoder.1.bias: 0.005643804091960192\n",
      "Gradient for encoder.encoder.3.weight: 0.1617550104856491\n",
      "Gradient for encoder.encoder.3.bias: 6.900091054085067e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.013744398020207882\n",
      "Gradient for encoder.encoder.4.bias: 0.011844448745250702\n",
      "Gradient for encoder.mean.weight: 0.18039804697036743\n",
      "Gradient for encoder.mean.bias: 0.008437012322247028\n",
      "Gradient for encoder.log_var.weight: 0.0899454727768898\n",
      "Gradient for encoder.log_var.bias: 0.0048056356608867645\n",
      "Gradient for decoder.decoder.0.weight: 0.016933584585785866\n",
      "Gradient for decoder.decoder.0.bias: 1.4601767017730083e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.000878832011949271\n",
      "Gradient for decoder.decoder.1.bias: 0.0006080673192627728\n",
      "Gradient for decoder.decoder.3.weight: 0.01421548705548048\n",
      "Gradient for decoder.decoder.3.bias: 1.151789080777732e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0005771146388724446\n",
      "Gradient for decoder.decoder.4.bias: 0.0005803282256238163\n",
      "Gradient for decoder.decoder.6.weight: 0.000840948719996959\n",
      "Gradient for decoder.decoder.6.bias: 4.328893555793911e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.06566839665174484\n",
      "Gradient for encoder.encoder.0.bias: 8.367003617726354e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.007547208108007908\n",
      "Gradient for encoder.encoder.1.bias: 0.005783799570053816\n",
      "Gradient for encoder.encoder.3.weight: 0.16794037818908691\n",
      "Gradient for encoder.encoder.3.bias: 8.33324631521748e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.01755732111632824\n",
      "Gradient for encoder.encoder.4.bias: 0.012460433878004551\n",
      "Gradient for encoder.mean.weight: 0.21003317832946777\n",
      "Gradient for encoder.mean.bias: 0.006912934593856335\n",
      "Gradient for encoder.log_var.weight: 0.11867005378007889\n",
      "Gradient for encoder.log_var.bias: 0.00352850160561502\n",
      "Gradient for decoder.decoder.0.weight: 0.019352149218320847\n",
      "Gradient for decoder.decoder.0.bias: 1.8741053153803477e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0010195962386205792\n",
      "Gradient for decoder.decoder.1.bias: 0.0006752826157025993\n",
      "Gradient for decoder.decoder.3.weight: 0.016133200377225876\n",
      "Gradient for decoder.decoder.3.bias: 1.2425528661541563e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0006745840655639768\n",
      "Gradient for decoder.decoder.4.bias: 0.0006528468220494688\n",
      "Gradient for decoder.decoder.6.weight: 0.0008435119525529444\n",
      "Gradient for decoder.decoder.6.bias: 4.398696546559222e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.08818034827709198\n",
      "Gradient for encoder.encoder.0.bias: 1.3232376305793991e-10\n",
      "Gradient for encoder.encoder.1.weight: 0.009903833270072937\n",
      "Gradient for encoder.encoder.1.bias: 0.00746004655957222\n",
      "Gradient for encoder.encoder.3.weight: 0.20037949085235596\n",
      "Gradient for encoder.encoder.3.bias: 9.896357067162853e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.01638505980372429\n",
      "Gradient for encoder.encoder.4.bias: 0.018415577709674835\n",
      "Gradient for encoder.mean.weight: 0.20584747195243835\n",
      "Gradient for encoder.mean.bias: 0.012952265329658985\n",
      "Gradient for encoder.log_var.weight: 0.12695854902267456\n",
      "Gradient for encoder.log_var.bias: 0.008878881111741066\n",
      "Gradient for decoder.decoder.0.weight: 0.01205367874354124\n",
      "Gradient for decoder.decoder.0.bias: 9.068533424194669e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0006644538952969015\n",
      "Gradient for decoder.decoder.1.bias: 0.0004178773669991642\n",
      "Gradient for decoder.decoder.3.weight: 0.00987454317510128\n",
      "Gradient for decoder.decoder.3.bias: 7.699436227470713e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00036195627762936056\n",
      "Gradient for decoder.decoder.4.bias: 0.0003520907775964588\n",
      "Gradient for decoder.decoder.6.weight: 0.0009200313943438232\n",
      "Gradient for decoder.decoder.6.bias: 6.927585491212085e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.06413280218839645\n",
      "Gradient for encoder.encoder.0.bias: 9.797213734730192e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.005400817841291428\n",
      "Gradient for encoder.encoder.1.bias: 0.004232847131788731\n",
      "Gradient for encoder.encoder.3.weight: 0.12046373635530472\n",
      "Gradient for encoder.encoder.3.bias: 7.434575732823134e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.010336726903915405\n",
      "Gradient for encoder.encoder.4.bias: 0.01070394180715084\n",
      "Gradient for encoder.mean.weight: 0.13426929712295532\n",
      "Gradient for encoder.mean.bias: 0.007576205767691135\n",
      "Gradient for encoder.log_var.weight: 0.07480233907699585\n",
      "Gradient for encoder.log_var.bias: 0.004259394481778145\n",
      "Gradient for decoder.decoder.0.weight: 0.012042119167745113\n",
      "Gradient for decoder.decoder.0.bias: 9.190222194366271e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0006698161014355719\n",
      "Gradient for decoder.decoder.1.bias: 0.00045121758012101054\n",
      "Gradient for decoder.decoder.3.weight: 0.010155553929507732\n",
      "Gradient for decoder.decoder.3.bias: 8.761660147404982e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0005537301767617464\n",
      "Gradient for decoder.decoder.4.bias: 0.0006431038491427898\n",
      "Gradient for decoder.decoder.6.weight: 0.0008439803496003151\n",
      "Gradient for decoder.decoder.6.bias: 5.931181294727139e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.05510571599006653\n",
      "Gradient for encoder.encoder.0.bias: 7.698412046730496e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.006762668490409851\n",
      "Gradient for encoder.encoder.1.bias: 0.005322526209056377\n",
      "Gradient for encoder.encoder.3.weight: 0.15010125935077667\n",
      "Gradient for encoder.encoder.3.bias: 7.626140274830107e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.01823289506137371\n",
      "Gradient for encoder.encoder.4.bias: 0.012721194885671139\n",
      "Gradient for encoder.mean.weight: 0.22245962917804718\n",
      "Gradient for encoder.mean.bias: 0.006633556913584471\n",
      "Gradient for encoder.log_var.weight: 0.1344866156578064\n",
      "Gradient for encoder.log_var.bias: 0.003911374136805534\n",
      "Gradient for decoder.decoder.0.weight: 0.017749259248375893\n",
      "Gradient for decoder.decoder.0.bias: 1.3689090139212823e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0009670770377852023\n",
      "Gradient for decoder.decoder.1.bias: 0.0006486932979896665\n",
      "Gradient for decoder.decoder.3.weight: 0.014355388469994068\n",
      "Gradient for decoder.decoder.3.bias: 1.0490757568204501e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0005479261162690818\n",
      "Gradient for decoder.decoder.4.bias: 0.0004940532962791622\n",
      "Gradient for decoder.decoder.6.weight: 0.0008014066843315959\n",
      "Gradient for decoder.decoder.6.bias: 3.801262573688291e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.4843749403953552\n",
      "Gradient for encoder.encoder.0.bias: 5.971732552900733e-10\n",
      "Gradient for encoder.encoder.1.weight: 0.03889088332653046\n",
      "Gradient for encoder.encoder.1.bias: 0.03219602629542351\n",
      "Gradient for encoder.encoder.3.weight: 0.8421145081520081\n",
      "Gradient for encoder.encoder.3.bias: 4.078102744387024e-09\n",
      "Gradient for encoder.encoder.4.weight: 0.06618890911340714\n",
      "Gradient for encoder.encoder.4.bias: 0.059776291251182556\n",
      "Gradient for encoder.mean.weight: 0.7813786268234253\n",
      "Gradient for encoder.mean.bias: 0.027937406674027443\n",
      "Gradient for encoder.log_var.weight: 0.5029422044754028\n",
      "Gradient for encoder.log_var.bias: 0.017903443425893784\n",
      "Gradient for decoder.decoder.0.weight: 0.0460803359746933\n",
      "Gradient for decoder.decoder.0.bias: 2.7292171300707935e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0019918158650398254\n",
      "Gradient for decoder.decoder.1.bias: 0.0016098872292786837\n",
      "Gradient for decoder.decoder.3.weight: 0.03728177770972252\n",
      "Gradient for decoder.decoder.3.bias: 1.9152331109939524e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0012365601724013686\n",
      "Gradient for decoder.decoder.4.bias: 0.001082827104255557\n",
      "Gradient for decoder.decoder.6.weight: 0.002355041913688183\n",
      "Gradient for decoder.decoder.6.bias: 0.00010557636414887384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3, Train Loss: 0.1039, Val Loss: 0.4705\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training VAE Epoch:   1%|▏         | 1/79 [00:00<00:15,  5.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient for encoder.encoder.0.weight: 0.054222382605075836\n",
      "Gradient for encoder.encoder.0.bias: 7.284219755154808e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.005843219347298145\n",
      "Gradient for encoder.encoder.1.bias: 0.004428391344845295\n",
      "Gradient for encoder.encoder.3.weight: 0.13175304234027863\n",
      "Gradient for encoder.encoder.3.bias: 7.003088664525592e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.015808241441845894\n",
      "Gradient for encoder.encoder.4.bias: 0.01174034085124731\n",
      "Gradient for encoder.mean.weight: 0.19400396943092346\n",
      "Gradient for encoder.mean.bias: 0.005762014072388411\n",
      "Gradient for encoder.log_var.weight: 0.1251036673784256\n",
      "Gradient for encoder.log_var.bias: 0.0035776032600551844\n",
      "Gradient for decoder.decoder.0.weight: 0.016311582177877426\n",
      "Gradient for decoder.decoder.0.bias: 1.4451739804854924e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.000886029563844204\n",
      "Gradient for decoder.decoder.1.bias: 0.0005880656535737216\n",
      "Gradient for decoder.decoder.3.weight: 0.013676405884325504\n",
      "Gradient for decoder.decoder.3.bias: 1.2049496123101022e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.00046238445793278515\n",
      "Gradient for decoder.decoder.4.bias: 0.0004090708971489221\n",
      "Gradient for decoder.decoder.6.weight: 0.0008610276854597032\n",
      "Gradient for decoder.decoder.6.bias: 4.83205403725151e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training VAE Epoch:  11%|█▏        | 9/79 [00:00<00:01, 35.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient for encoder.encoder.0.weight: 0.06705774366855621\n",
      "Gradient for encoder.encoder.0.bias: 1.0117713611368373e-10\n",
      "Gradient for encoder.encoder.1.weight: 0.009430114179849625\n",
      "Gradient for encoder.encoder.1.bias: 0.008061908185482025\n",
      "Gradient for encoder.encoder.3.weight: 0.20254312455654144\n",
      "Gradient for encoder.encoder.3.bias: 9.60281854034406e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.01661490462720394\n",
      "Gradient for encoder.encoder.4.bias: 0.016190283000469208\n",
      "Gradient for encoder.mean.weight: 0.21680563688278198\n",
      "Gradient for encoder.mean.bias: 0.010424942709505558\n",
      "Gradient for encoder.log_var.weight: 0.1322574019432068\n",
      "Gradient for encoder.log_var.bias: 0.007096549496054649\n",
      "Gradient for decoder.decoder.0.weight: 0.016920989379286766\n",
      "Gradient for decoder.decoder.0.bias: 1.3964557288304036e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0009226197726093233\n",
      "Gradient for decoder.decoder.1.bias: 0.0006013819947838783\n",
      "Gradient for decoder.decoder.3.weight: 0.014035388827323914\n",
      "Gradient for decoder.decoder.3.bias: 1.0809914768872275e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0004952418385073543\n",
      "Gradient for decoder.decoder.4.bias: 0.00044248258927837014\n",
      "Gradient for decoder.decoder.6.weight: 0.0007804468041285872\n",
      "Gradient for decoder.decoder.6.bias: 3.632037987699732e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.1029265969991684\n",
      "Gradient for encoder.encoder.0.bias: 1.3906302498423173e-10\n",
      "Gradient for encoder.encoder.1.weight: 0.01022269856184721\n",
      "Gradient for encoder.encoder.1.bias: 0.007293911185115576\n",
      "Gradient for encoder.encoder.3.weight: 0.22496365010738373\n",
      "Gradient for encoder.encoder.3.bias: 8.937903750450005e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.014327873475849628\n",
      "Gradient for encoder.encoder.4.bias: 0.013839926570653915\n",
      "Gradient for encoder.mean.weight: 0.19552771747112274\n",
      "Gradient for encoder.mean.bias: 0.007999824360013008\n",
      "Gradient for encoder.log_var.weight: 0.10861687362194061\n",
      "Gradient for encoder.log_var.bias: 0.0045365458354353905\n",
      "Gradient for decoder.decoder.0.weight: 0.014297542162239552\n",
      "Gradient for decoder.decoder.0.bias: 1.21361212745974e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0007332358509302139\n",
      "Gradient for decoder.decoder.1.bias: 0.000498086039442569\n",
      "Gradient for decoder.decoder.3.weight: 0.01215020939707756\n",
      "Gradient for decoder.decoder.3.bias: 1.0868485278425766e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0005519574042409658\n",
      "Gradient for decoder.decoder.4.bias: 0.0006023900350555778\n",
      "Gradient for decoder.decoder.6.weight: 0.0008526858873665333\n",
      "Gradient for decoder.decoder.6.bias: 5.558220436796546e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.12149703502655029\n",
      "Gradient for encoder.encoder.0.bias: 1.214174871755347e-10\n",
      "Gradient for encoder.encoder.1.weight: 0.010019363835453987\n",
      "Gradient for encoder.encoder.1.bias: 0.00839002151042223\n",
      "Gradient for encoder.encoder.3.weight: 0.23563307523727417\n",
      "Gradient for encoder.encoder.3.bias: 9.461748051720065e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.015209873206913471\n",
      "Gradient for encoder.encoder.4.bias: 0.014592298306524754\n",
      "Gradient for encoder.mean.weight: 0.20316646993160248\n",
      "Gradient for encoder.mean.bias: 0.008525046519935131\n",
      "Gradient for encoder.log_var.weight: 0.10580918937921524\n",
      "Gradient for encoder.log_var.bias: 0.0050820764154195786\n",
      "Gradient for decoder.decoder.0.weight: 0.015935149043798447\n",
      "Gradient for decoder.decoder.0.bias: 1.458210358018519e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.000815121631603688\n",
      "Gradient for decoder.decoder.1.bias: 0.0005679377936758101\n",
      "Gradient for decoder.decoder.3.weight: 0.013357293792068958\n",
      "Gradient for decoder.decoder.3.bias: 1.0962034752148853e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.00048522508586756885\n",
      "Gradient for decoder.decoder.4.bias: 0.0004328785580582917\n",
      "Gradient for decoder.decoder.6.weight: 0.0008250735700130463\n",
      "Gradient for decoder.decoder.6.bias: 4.219963011564687e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.13568590581417084\n",
      "Gradient for encoder.encoder.0.bias: 1.5245774087624397e-10\n",
      "Gradient for encoder.encoder.1.weight: 0.01187636237591505\n",
      "Gradient for encoder.encoder.1.bias: 0.008904003538191319\n",
      "Gradient for encoder.encoder.3.weight: 0.2662152349948883\n",
      "Gradient for encoder.encoder.3.bias: 1.1886198691968275e-09\n",
      "Gradient for encoder.encoder.4.weight: 0.022515304386615753\n",
      "Gradient for encoder.encoder.4.bias: 0.019244952127337456\n",
      "Gradient for encoder.mean.weight: 0.277673602104187\n",
      "Gradient for encoder.mean.bias: 0.010475900024175644\n",
      "Gradient for encoder.log_var.weight: 0.14645051956176758\n",
      "Gradient for encoder.log_var.bias: 0.005566882435232401\n",
      "Gradient for decoder.decoder.0.weight: 0.012564829550683498\n",
      "Gradient for decoder.decoder.0.bias: 1.05372321979047e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0007148922304622829\n",
      "Gradient for decoder.decoder.1.bias: 0.0005071063060313463\n",
      "Gradient for decoder.decoder.3.weight: 0.010716916061937809\n",
      "Gradient for decoder.decoder.3.bias: 8.586474586902426e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0004218615358695388\n",
      "Gradient for decoder.decoder.4.bias: 0.0004473052977118641\n",
      "Gradient for decoder.decoder.6.weight: 0.0008169672801159322\n",
      "Gradient for decoder.decoder.6.bias: 5.237264122115448e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.09486876428127289\n",
      "Gradient for encoder.encoder.0.bias: 1.510756103551003e-10\n",
      "Gradient for encoder.encoder.1.weight: 0.011720692738890648\n",
      "Gradient for encoder.encoder.1.bias: 0.008722738362848759\n",
      "Gradient for encoder.encoder.3.weight: 0.2575400173664093\n",
      "Gradient for encoder.encoder.3.bias: 9.716418780669756e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.019682627171278\n",
      "Gradient for encoder.encoder.4.bias: 0.01690993644297123\n",
      "Gradient for encoder.mean.weight: 0.26890745759010315\n",
      "Gradient for encoder.mean.bias: 0.008759739808738232\n",
      "Gradient for encoder.log_var.weight: 0.14324982464313507\n",
      "Gradient for encoder.log_var.bias: 0.004574497230350971\n",
      "Gradient for decoder.decoder.0.weight: 0.015590773895382881\n",
      "Gradient for decoder.decoder.0.bias: 1.4239170953445068e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0008136509568430483\n",
      "Gradient for decoder.decoder.1.bias: 0.000569559691939503\n",
      "Gradient for decoder.decoder.3.weight: 0.012984476052224636\n",
      "Gradient for decoder.decoder.3.bias: 1.1976832026139306e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0004288959316909313\n",
      "Gradient for decoder.decoder.4.bias: 0.0003914184926543385\n",
      "Gradient for decoder.decoder.6.weight: 0.0008098763064481318\n",
      "Gradient for decoder.decoder.6.bias: 4.3102783820359036e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.09948547929525375\n",
      "Gradient for encoder.encoder.0.bias: 1.446393282922287e-10\n",
      "Gradient for encoder.encoder.1.weight: 0.009154614992439747\n",
      "Gradient for encoder.encoder.1.bias: 0.006534121930599213\n",
      "Gradient for encoder.encoder.3.weight: 0.20206418633460999\n",
      "Gradient for encoder.encoder.3.bias: 1.0193816901704622e-09\n",
      "Gradient for encoder.encoder.4.weight: 0.018732978031039238\n",
      "Gradient for encoder.encoder.4.bias: 0.015343450009822845\n",
      "Gradient for encoder.mean.weight: 0.23960699141025543\n",
      "Gradient for encoder.mean.bias: 0.008861684240400791\n",
      "Gradient for encoder.log_var.weight: 0.14223085343837738\n",
      "Gradient for encoder.log_var.bias: 0.006557104177772999\n",
      "Gradient for decoder.decoder.0.weight: 0.012096775695681572\n",
      "Gradient for decoder.decoder.0.bias: 1.0817551715502915e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0006465057376772165\n",
      "Gradient for decoder.decoder.1.bias: 0.000496167573146522\n",
      "Gradient for decoder.decoder.3.weight: 0.010657663457095623\n",
      "Gradient for decoder.decoder.3.bias: 8.789985406210121e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00047685031313449144\n",
      "Gradient for decoder.decoder.4.bias: 0.0005841093370690942\n",
      "Gradient for decoder.decoder.6.weight: 0.0008098750258795917\n",
      "Gradient for decoder.decoder.6.bias: 5.707728996640071e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.08618322759866714\n",
      "Gradient for encoder.encoder.0.bias: 1.1376627417902796e-10\n",
      "Gradient for encoder.encoder.1.weight: 0.007988566532731056\n",
      "Gradient for encoder.encoder.1.bias: 0.006142114754766226\n",
      "Gradient for encoder.encoder.3.weight: 0.17504197359085083\n",
      "Gradient for encoder.encoder.3.bias: 8.963139674911247e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.017654595896601677\n",
      "Gradient for encoder.encoder.4.bias: 0.015560661442577839\n",
      "Gradient for encoder.mean.weight: 0.21393133699893951\n",
      "Gradient for encoder.mean.bias: 0.008305689319968224\n",
      "Gradient for encoder.log_var.weight: 0.134150892496109\n",
      "Gradient for encoder.log_var.bias: 0.006068981718271971\n",
      "Gradient for decoder.decoder.0.weight: 0.013225283473730087\n",
      "Gradient for decoder.decoder.0.bias: 1.225231860413345e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0007032529101707041\n",
      "Gradient for decoder.decoder.1.bias: 0.0004649539478123188\n",
      "Gradient for decoder.decoder.3.weight: 0.011210765689611435\n",
      "Gradient for decoder.decoder.3.bias: 9.311694471048071e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00037401041481643915\n",
      "Gradient for decoder.decoder.4.bias: 0.00033874434302560985\n",
      "Gradient for decoder.decoder.6.weight: 0.0008428990258835256\n",
      "Gradient for decoder.decoder.6.bias: 4.445022204890847e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.09560563415288925\n",
      "Gradient for encoder.encoder.0.bias: 1.3778155005805814e-10\n",
      "Gradient for encoder.encoder.1.weight: 0.008531825616955757\n",
      "Gradient for encoder.encoder.1.bias: 0.006773123983293772\n",
      "Gradient for encoder.encoder.3.weight: 0.20286458730697632\n",
      "Gradient for encoder.encoder.3.bias: 9.347350671262689e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.019734444096684456\n",
      "Gradient for encoder.encoder.4.bias: 0.020176846534013748\n",
      "Gradient for encoder.mean.weight: 0.24049155414104462\n",
      "Gradient for encoder.mean.bias: 0.013399394229054451\n",
      "Gradient for encoder.log_var.weight: 0.14476293325424194\n",
      "Gradient for encoder.log_var.bias: 0.010107387788593769\n",
      "Gradient for decoder.decoder.0.weight: 0.01068008691072464\n",
      "Gradient for decoder.decoder.0.bias: 8.32321989108209e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005617376300506294\n",
      "Gradient for decoder.decoder.1.bias: 0.00038150654290802777\n",
      "Gradient for decoder.decoder.3.weight: 0.00909888744354248\n",
      "Gradient for decoder.decoder.3.bias: 9.017641494635242e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0006753618363291025\n",
      "Gradient for decoder.decoder.4.bias: 0.0008557255496270955\n",
      "Gradient for decoder.decoder.6.weight: 0.0009171230485662818\n",
      "Gradient for decoder.decoder.6.bias: 7.303039456019178e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.12963177263736725\n",
      "Gradient for encoder.encoder.0.bias: 1.5309274681296614e-10\n",
      "Gradient for encoder.encoder.1.weight: 0.010004333220422268\n",
      "Gradient for encoder.encoder.1.bias: 0.0077247656881809235\n",
      "Gradient for encoder.encoder.3.weight: 0.2264001965522766\n",
      "Gradient for encoder.encoder.3.bias: 1.0138334616272004e-09\n",
      "Gradient for encoder.encoder.4.weight: 0.015920346602797508\n",
      "Gradient for encoder.encoder.4.bias: 0.01326737366616726\n",
      "Gradient for encoder.mean.weight: 0.19807426631450653\n",
      "Gradient for encoder.mean.bias: 0.008869904093444347\n",
      "Gradient for encoder.log_var.weight: 0.11906470358371735\n",
      "Gradient for encoder.log_var.bias: 0.0053258598782122135\n",
      "Gradient for decoder.decoder.0.weight: 0.015448478981852531\n",
      "Gradient for decoder.decoder.0.bias: 1.4609033427426255e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0008609850192442536\n",
      "Gradient for decoder.decoder.1.bias: 0.0005868648295290768\n",
      "Gradient for decoder.decoder.3.weight: 0.013064097613096237\n",
      "Gradient for decoder.decoder.3.bias: 1.3067222304208315e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0007350877276621759\n",
      "Gradient for decoder.decoder.4.bias: 0.0007768410723656416\n",
      "Gradient for decoder.decoder.6.weight: 0.0011251696851104498\n",
      "Gradient for decoder.decoder.6.bias: 8.780848293099552e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.08344482630491257\n",
      "Gradient for encoder.encoder.0.bias: 1.0319089333021836e-10\n",
      "Gradient for encoder.encoder.1.weight: 0.009079569950699806\n",
      "Gradient for encoder.encoder.1.bias: 0.006425187457352877\n",
      "Gradient for encoder.encoder.3.weight: 0.21863959729671478\n",
      "Gradient for encoder.encoder.3.bias: 9.063776396089906e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.024441473186016083\n",
      "Gradient for encoder.encoder.4.bias: 0.015249787829816341\n",
      "Gradient for encoder.mean.weight: 0.29261642694473267\n",
      "Gradient for encoder.mean.bias: 0.009211997501552105\n",
      "Gradient for encoder.log_var.weight: 0.15885506570339203\n",
      "Gradient for encoder.log_var.bias: 0.004732848610728979\n",
      "Gradient for decoder.decoder.0.weight: 0.015434525907039642\n",
      "Gradient for decoder.decoder.0.bias: 1.1756867701606666e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.000890682393219322\n",
      "Gradient for decoder.decoder.1.bias: 0.0005770071875303984\n",
      "Gradient for decoder.decoder.3.weight: 0.013246347196400166\n",
      "Gradient for decoder.decoder.3.bias: 1.1226504448291763e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0004937049234285951\n",
      "Gradient for decoder.decoder.4.bias: 0.0004940129583701491\n",
      "Gradient for decoder.decoder.6.weight: 0.0007766224443912506\n",
      "Gradient for decoder.decoder.6.bias: 4.1819159378064796e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.06836152076721191\n",
      "Gradient for encoder.encoder.0.bias: 1.058878748572134e-10\n",
      "Gradient for encoder.encoder.1.weight: 0.00913923792541027\n",
      "Gradient for encoder.encoder.1.bias: 0.0060270908288657665\n",
      "Gradient for encoder.encoder.3.weight: 0.1992761492729187\n",
      "Gradient for encoder.encoder.3.bias: 8.906689830112668e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.01969679817557335\n",
      "Gradient for encoder.encoder.4.bias: 0.014934140257537365\n",
      "Gradient for encoder.mean.weight: 0.25933802127838135\n",
      "Gradient for encoder.mean.bias: 0.008627022616565228\n",
      "Gradient for encoder.log_var.weight: 0.14035959541797638\n",
      "Gradient for encoder.log_var.bias: 0.005444463342428207\n",
      "Gradient for decoder.decoder.0.weight: 0.014317396096885204\n",
      "Gradient for decoder.decoder.0.bias: 1.2301215601695503e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.000740493880584836\n",
      "Gradient for decoder.decoder.1.bias: 0.0005248920060694218\n",
      "Gradient for decoder.decoder.3.weight: 0.012120324186980724\n",
      "Gradient for decoder.decoder.3.bias: 9.384722859939743e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0004113223112653941\n",
      "Gradient for decoder.decoder.4.bias: 0.0003527070803102106\n",
      "Gradient for decoder.decoder.6.weight: 0.0008334865560755134\n",
      "Gradient for decoder.decoder.6.bias: 5.123694791109301e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.05651115998625755\n",
      "Gradient for encoder.encoder.0.bias: 8.909453036443082e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0072419182397425175\n",
      "Gradient for encoder.encoder.1.bias: 0.0059411427937448025\n",
      "Gradient for encoder.encoder.3.weight: 0.16224949061870575\n",
      "Gradient for encoder.encoder.3.bias: 7.845832317165957e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.018543604761362076\n",
      "Gradient for encoder.encoder.4.bias: 0.01444159634411335\n",
      "Gradient for encoder.mean.weight: 0.23377658426761627\n",
      "Gradient for encoder.mean.bias: 0.009705965407192707\n",
      "Gradient for encoder.log_var.weight: 0.12373282015323639\n",
      "Gradient for encoder.log_var.bias: 0.005833197385072708\n",
      "Gradient for decoder.decoder.0.weight: 0.017229333519935608\n",
      "Gradient for decoder.decoder.0.bias: 1.3197420933863668e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0009088328806683421\n",
      "Gradient for decoder.decoder.1.bias: 0.0006086006760597229\n",
      "Gradient for decoder.decoder.3.weight: 0.014372474513947964\n",
      "Gradient for decoder.decoder.3.bias: 1.1911191477587124e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0006823597359471023\n",
      "Gradient for decoder.decoder.4.bias: 0.0006890826625749469\n",
      "Gradient for decoder.decoder.6.weight: 0.0009646423277445138\n",
      "Gradient for decoder.decoder.6.bias: 6.289638258749619e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.07404309511184692\n",
      "Gradient for encoder.encoder.0.bias: 1.0332826261283401e-10\n",
      "Gradient for encoder.encoder.1.weight: 0.008833645842969418\n",
      "Gradient for encoder.encoder.1.bias: 0.007299892138689756\n",
      "Gradient for encoder.encoder.3.weight: 0.2070636749267578\n",
      "Gradient for encoder.encoder.3.bias: 1.1472733874029473e-09\n",
      "Gradient for encoder.encoder.4.weight: 0.023785365745425224\n",
      "Gradient for encoder.encoder.4.bias: 0.01808914914727211\n",
      "Gradient for encoder.mean.weight: 0.2974570691585541\n",
      "Gradient for encoder.mean.bias: 0.009388620965182781\n",
      "Gradient for encoder.log_var.weight: 0.16200445592403412\n",
      "Gradient for encoder.log_var.bias: 0.004978054203093052\n",
      "Gradient for decoder.decoder.0.weight: 0.01700730249285698\n",
      "Gradient for decoder.decoder.0.bias: 1.349897554847601e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0008703230414539576\n",
      "Gradient for decoder.decoder.1.bias: 0.0006327290902845562\n",
      "Gradient for decoder.decoder.3.weight: 0.014596156775951385\n",
      "Gradient for decoder.decoder.3.bias: 1.0964494590037788e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.000525378854945302\n",
      "Gradient for decoder.decoder.4.bias: 0.0004524608375504613\n",
      "Gradient for decoder.decoder.6.weight: 0.0008472093031741679\n",
      "Gradient for decoder.decoder.6.bias: 4.5999109715921804e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.1543515920639038\n",
      "Gradient for encoder.encoder.0.bias: 1.816742034588259e-10\n",
      "Gradient for encoder.encoder.1.weight: 0.011280674487352371\n",
      "Gradient for encoder.encoder.1.bias: 0.008378250524401665\n",
      "Gradient for encoder.encoder.3.weight: 0.25815272331237793\n",
      "Gradient for encoder.encoder.3.bias: 1.0582157372596157e-09\n",
      "Gradient for encoder.encoder.4.weight: 0.01659778691828251\n",
      "Gradient for encoder.encoder.4.bias: 0.014877074398100376\n",
      "Gradient for encoder.mean.weight: 0.22261378169059753\n",
      "Gradient for encoder.mean.bias: 0.008261937648057938\n",
      "Gradient for encoder.log_var.weight: 0.12559820711612701\n",
      "Gradient for encoder.log_var.bias: 0.004851197823882103\n",
      "Gradient for decoder.decoder.0.weight: 0.01207282766699791\n",
      "Gradient for decoder.decoder.0.bias: 1.02971471627189e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0006648232811130583\n",
      "Gradient for decoder.decoder.1.bias: 0.00045584485633298755\n",
      "Gradient for decoder.decoder.3.weight: 0.010202190838754177\n",
      "Gradient for decoder.decoder.3.bias: 9.113149124218012e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0005663175252266228\n",
      "Gradient for decoder.decoder.4.bias: 0.0006655717152170837\n",
      "Gradient for decoder.decoder.6.weight: 0.0008080144762061536\n",
      "Gradient for decoder.decoder.6.bias: 5.0300670409342274e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.05462098494172096\n",
      "Gradient for encoder.encoder.0.bias: 8.526080536030989e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.005489848088473082\n",
      "Gradient for encoder.encoder.1.bias: 0.004517690744251013\n",
      "Gradient for encoder.encoder.3.weight: 0.1252112239599228\n",
      "Gradient for encoder.encoder.3.bias: 7.549919578409003e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.015780653804540634\n",
      "Gradient for encoder.encoder.4.bias: 0.012073329649865627\n",
      "Gradient for encoder.mean.weight: 0.1902252435684204\n",
      "Gradient for encoder.mean.bias: 0.008087841793894768\n",
      "Gradient for encoder.log_var.weight: 0.12355407327413559\n",
      "Gradient for encoder.log_var.bias: 0.004651630762964487\n",
      "Gradient for decoder.decoder.0.weight: 0.014071935787796974\n",
      "Gradient for decoder.decoder.0.bias: 1.240108710165444e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.000760686700232327\n",
      "Gradient for decoder.decoder.1.bias: 0.0005370057187974453\n",
      "Gradient for decoder.decoder.3.weight: 0.011819634586572647\n",
      "Gradient for decoder.decoder.3.bias: 8.935973488943816e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00041522830724716187\n",
      "Gradient for decoder.decoder.4.bias: 0.0003729513264261186\n",
      "Gradient for decoder.decoder.6.weight: 0.0008020997629500926\n",
      "Gradient for decoder.decoder.6.bias: 4.2824834963539615e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.045139335095882416\n",
      "Gradient for encoder.encoder.0.bias: 6.934645219169866e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.005069368053227663\n",
      "Gradient for encoder.encoder.1.bias: 0.004243751987814903\n",
      "Gradient for encoder.encoder.3.weight: 0.11253576725721359\n",
      "Gradient for encoder.encoder.3.bias: 7.211871655421476e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.014332621358335018\n",
      "Gradient for encoder.encoder.4.bias: 0.01333980355411768\n",
      "Gradient for encoder.mean.weight: 0.1814870834350586\n",
      "Gradient for encoder.mean.bias: 0.009948340244591236\n",
      "Gradient for encoder.log_var.weight: 0.11958606541156769\n",
      "Gradient for encoder.log_var.bias: 0.006023866590112448\n",
      "Gradient for decoder.decoder.0.weight: 0.014768143184483051\n",
      "Gradient for decoder.decoder.0.bias: 1.184094627904031e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.000761417846661061\n",
      "Gradient for decoder.decoder.1.bias: 0.0005655666464008391\n",
      "Gradient for decoder.decoder.3.weight: 0.01251566968858242\n",
      "Gradient for decoder.decoder.3.bias: 8.729966749498885e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.000445485464297235\n",
      "Gradient for decoder.decoder.4.bias: 0.0003784911532420665\n",
      "Gradient for decoder.decoder.6.weight: 0.0008114163647405803\n",
      "Gradient for decoder.decoder.6.bias: 4.406042717164382e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training VAE Epoch:  32%|███▏      | 25/79 [00:00<00:00, 60.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient for encoder.encoder.0.weight: 0.05056072026491165\n",
      "Gradient for encoder.encoder.0.bias: 6.511360894911888e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.00560374278575182\n",
      "Gradient for encoder.encoder.1.bias: 0.003983383998274803\n",
      "Gradient for encoder.encoder.3.weight: 0.12065327912569046\n",
      "Gradient for encoder.encoder.3.bias: 6.383784612040699e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.010559037327766418\n",
      "Gradient for encoder.encoder.4.bias: 0.008449319750070572\n",
      "Gradient for encoder.mean.weight: 0.13876661658287048\n",
      "Gradient for encoder.mean.bias: 0.006273412611335516\n",
      "Gradient for encoder.log_var.weight: 0.07053281366825104\n",
      "Gradient for encoder.log_var.bias: 0.0037964857183396816\n",
      "Gradient for decoder.decoder.0.weight: 0.013602115213871002\n",
      "Gradient for decoder.decoder.0.bias: 1.1070856731354439e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.000766317592933774\n",
      "Gradient for decoder.decoder.1.bias: 0.0005462230765260756\n",
      "Gradient for decoder.decoder.3.weight: 0.011707983911037445\n",
      "Gradient for decoder.decoder.3.bias: 8.907289489323844e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0004687361069954932\n",
      "Gradient for decoder.decoder.4.bias: 0.00043276342330500484\n",
      "Gradient for decoder.decoder.6.weight: 0.0008303491049446166\n",
      "Gradient for decoder.decoder.6.bias: 5.088159014121629e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.07739968597888947\n",
      "Gradient for encoder.encoder.0.bias: 1.317536774125827e-10\n",
      "Gradient for encoder.encoder.1.weight: 0.008454021997749805\n",
      "Gradient for encoder.encoder.1.bias: 0.0062009491957724094\n",
      "Gradient for encoder.encoder.3.weight: 0.19409146904945374\n",
      "Gradient for encoder.encoder.3.bias: 1.2909151525519746e-09\n",
      "Gradient for encoder.encoder.4.weight: 0.019788123667240143\n",
      "Gradient for encoder.encoder.4.bias: 0.019294360652565956\n",
      "Gradient for encoder.mean.weight: 0.226043239235878\n",
      "Gradient for encoder.mean.bias: 0.011637680232524872\n",
      "Gradient for encoder.log_var.weight: 0.14552974700927734\n",
      "Gradient for encoder.log_var.bias: 0.007069237995892763\n",
      "Gradient for decoder.decoder.0.weight: 0.014826145023107529\n",
      "Gradient for decoder.decoder.0.bias: 1.3608358884198424e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0007075482280924916\n",
      "Gradient for decoder.decoder.1.bias: 0.0005632836255244911\n",
      "Gradient for decoder.decoder.3.weight: 0.012637306936085224\n",
      "Gradient for decoder.decoder.3.bias: 1.1880704753330917e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0006907747010700405\n",
      "Gradient for decoder.decoder.4.bias: 0.0008356651524081826\n",
      "Gradient for decoder.decoder.6.weight: 0.0008914860081858933\n",
      "Gradient for decoder.decoder.6.bias: 6.569938705069944e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.058156728744506836\n",
      "Gradient for encoder.encoder.0.bias: 7.509048244314087e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.005290895234793425\n",
      "Gradient for encoder.encoder.1.bias: 0.0041052005253732204\n",
      "Gradient for encoder.encoder.3.weight: 0.12093982845544815\n",
      "Gradient for encoder.encoder.3.bias: 9.266140077457408e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.014276012778282166\n",
      "Gradient for encoder.encoder.4.bias: 0.01680939458310604\n",
      "Gradient for encoder.mean.weight: 0.19094598293304443\n",
      "Gradient for encoder.mean.bias: 0.014381160959601402\n",
      "Gradient for encoder.log_var.weight: 0.11787506192922592\n",
      "Gradient for encoder.log_var.bias: 0.00920536182820797\n",
      "Gradient for decoder.decoder.0.weight: 0.016771549358963966\n",
      "Gradient for decoder.decoder.0.bias: 1.274630678782529e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0008602985762991011\n",
      "Gradient for decoder.decoder.1.bias: 0.000655969197396189\n",
      "Gradient for decoder.decoder.3.weight: 0.014410962350666523\n",
      "Gradient for decoder.decoder.3.bias: 1.0699501701294523e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.000584583671297878\n",
      "Gradient for decoder.decoder.4.bias: 0.0005480166291818023\n",
      "Gradient for decoder.decoder.6.weight: 0.0008676602155901492\n",
      "Gradient for decoder.decoder.6.bias: 4.204045035294257e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.06261002272367477\n",
      "Gradient for encoder.encoder.0.bias: 8.512329729981616e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.005217392463237047\n",
      "Gradient for encoder.encoder.1.bias: 0.003991326317191124\n",
      "Gradient for encoder.encoder.3.weight: 0.12296153604984283\n",
      "Gradient for encoder.encoder.3.bias: 6.580249123366855e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.011890733614563942\n",
      "Gradient for encoder.encoder.4.bias: 0.010618593543767929\n",
      "Gradient for encoder.mean.weight: 0.15070763230323792\n",
      "Gradient for encoder.mean.bias: 0.008271240629255772\n",
      "Gradient for encoder.log_var.weight: 0.07807617634534836\n",
      "Gradient for encoder.log_var.bias: 0.004432621877640486\n",
      "Gradient for decoder.decoder.0.weight: 0.014056126587092876\n",
      "Gradient for decoder.decoder.0.bias: 1.1363202739866907e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0007803548942320049\n",
      "Gradient for decoder.decoder.1.bias: 0.0005131133948452771\n",
      "Gradient for decoder.decoder.3.weight: 0.012147992849349976\n",
      "Gradient for decoder.decoder.3.bias: 9.423253843898749e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00047524567344225943\n",
      "Gradient for decoder.decoder.4.bias: 0.0004928285488858819\n",
      "Gradient for decoder.decoder.6.weight: 0.0007853529532440007\n",
      "Gradient for decoder.decoder.6.bias: 4.228346369927749e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.04615626111626625\n",
      "Gradient for encoder.encoder.0.bias: 7.627778964014453e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.005210968665778637\n",
      "Gradient for encoder.encoder.1.bias: 0.004063740372657776\n",
      "Gradient for encoder.encoder.3.weight: 0.1090993881225586\n",
      "Gradient for encoder.encoder.3.bias: 6.443657829535709e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.012290354818105698\n",
      "Gradient for encoder.encoder.4.bias: 0.01053899247199297\n",
      "Gradient for encoder.mean.weight: 0.16017721593379974\n",
      "Gradient for encoder.mean.bias: 0.008031221106648445\n",
      "Gradient for encoder.log_var.weight: 0.08601873368024826\n",
      "Gradient for encoder.log_var.bias: 0.003973841667175293\n",
      "Gradient for decoder.decoder.0.weight: 0.014602459035813808\n",
      "Gradient for decoder.decoder.0.bias: 1.2290220230415372e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0007562922546640038\n",
      "Gradient for decoder.decoder.1.bias: 0.0005402607494033873\n",
      "Gradient for decoder.decoder.3.weight: 0.012319566681981087\n",
      "Gradient for decoder.decoder.3.bias: 9.903795838983598e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0004543585528153926\n",
      "Gradient for decoder.decoder.4.bias: 0.0004540876252576709\n",
      "Gradient for decoder.decoder.6.weight: 0.0007445880328305066\n",
      "Gradient for decoder.decoder.6.bias: 3.7960307963658124e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.05011344701051712\n",
      "Gradient for encoder.encoder.0.bias: 7.548474345586698e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.009505189955234528\n",
      "Gradient for encoder.encoder.1.bias: 0.006252682767808437\n",
      "Gradient for encoder.encoder.3.weight: 0.19388532638549805\n",
      "Gradient for encoder.encoder.3.bias: 9.570542136572158e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0247220266610384\n",
      "Gradient for encoder.encoder.4.bias: 0.019973566755652428\n",
      "Gradient for encoder.mean.weight: 0.2960900664329529\n",
      "Gradient for encoder.mean.bias: 0.012734842486679554\n",
      "Gradient for encoder.log_var.weight: 0.16420598328113556\n",
      "Gradient for encoder.log_var.bias: 0.00762838264927268\n",
      "Gradient for decoder.decoder.0.weight: 0.017400547862052917\n",
      "Gradient for decoder.decoder.0.bias: 1.4584580765308885e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0009390795603394508\n",
      "Gradient for decoder.decoder.1.bias: 0.0006687100394628942\n",
      "Gradient for decoder.decoder.3.weight: 0.015055314637720585\n",
      "Gradient for decoder.decoder.3.bias: 1.3385784147779134e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0008870037854649127\n",
      "Gradient for decoder.decoder.4.bias: 0.0010297978296875954\n",
      "Gradient for decoder.decoder.6.weight: 0.0011572639923542738\n",
      "Gradient for decoder.decoder.6.bias: 9.311724716098979e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.07993452250957489\n",
      "Gradient for encoder.encoder.0.bias: 1.3027072476301527e-10\n",
      "Gradient for encoder.encoder.1.weight: 0.011062433011829853\n",
      "Gradient for encoder.encoder.1.bias: 0.008028505370020866\n",
      "Gradient for encoder.encoder.3.weight: 0.2417011857032776\n",
      "Gradient for encoder.encoder.3.bias: 9.868755812547647e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.02732021175324917\n",
      "Gradient for encoder.encoder.4.bias: 0.017800141125917435\n",
      "Gradient for encoder.mean.weight: 0.33661317825317383\n",
      "Gradient for encoder.mean.bias: 0.008066320791840553\n",
      "Gradient for encoder.log_var.weight: 0.20205065608024597\n",
      "Gradient for encoder.log_var.bias: 0.004501985851675272\n",
      "Gradient for decoder.decoder.0.weight: 0.015452545136213303\n",
      "Gradient for decoder.decoder.0.bias: 1.1759815343737046e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0008247181540355086\n",
      "Gradient for decoder.decoder.1.bias: 0.0005935000372119248\n",
      "Gradient for decoder.decoder.3.weight: 0.013657103292644024\n",
      "Gradient for decoder.decoder.3.bias: 1.0138036243834136e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0006424594903364778\n",
      "Gradient for decoder.decoder.4.bias: 0.0006711773457936943\n",
      "Gradient for decoder.decoder.6.weight: 0.000985045451670885\n",
      "Gradient for decoder.decoder.6.bias: 6.969492096686736e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.06850861012935638\n",
      "Gradient for encoder.encoder.0.bias: 9.493912600522236e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.006280447356402874\n",
      "Gradient for encoder.encoder.1.bias: 0.005249612499028444\n",
      "Gradient for encoder.encoder.3.weight: 0.1438104510307312\n",
      "Gradient for encoder.encoder.3.bias: 8.785422389578912e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.01837269216775894\n",
      "Gradient for encoder.encoder.4.bias: 0.014911239966750145\n",
      "Gradient for encoder.mean.weight: 0.23334112763404846\n",
      "Gradient for encoder.mean.bias: 0.00992107018828392\n",
      "Gradient for encoder.log_var.weight: 0.14520075917243958\n",
      "Gradient for encoder.log_var.bias: 0.006077248137444258\n",
      "Gradient for decoder.decoder.0.weight: 0.014577191323041916\n",
      "Gradient for decoder.decoder.0.bias: 1.1368314623005915e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0007469853735528886\n",
      "Gradient for decoder.decoder.1.bias: 0.0005463523557409644\n",
      "Gradient for decoder.decoder.3.weight: 0.0123300077393651\n",
      "Gradient for decoder.decoder.3.bias: 9.270248457760033e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0004645792068913579\n",
      "Gradient for decoder.decoder.4.bias: 0.00039155452395789325\n",
      "Gradient for decoder.decoder.6.weight: 0.0008462753030471504\n",
      "Gradient for decoder.decoder.6.bias: 3.983829446951859e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.05038054659962654\n",
      "Gradient for encoder.encoder.0.bias: 6.96168261926644e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.006573960650712252\n",
      "Gradient for encoder.encoder.1.bias: 0.004663472063839436\n",
      "Gradient for encoder.encoder.3.weight: 0.12756067514419556\n",
      "Gradient for encoder.encoder.3.bias: 6.251806849988384e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.011933703906834126\n",
      "Gradient for encoder.encoder.4.bias: 0.010695436038076878\n",
      "Gradient for encoder.mean.weight: 0.15497317910194397\n",
      "Gradient for encoder.mean.bias: 0.006719478406012058\n",
      "Gradient for encoder.log_var.weight: 0.08767788857221603\n",
      "Gradient for encoder.log_var.bias: 0.004601505119353533\n",
      "Gradient for decoder.decoder.0.weight: 0.015904344618320465\n",
      "Gradient for decoder.decoder.0.bias: 1.4684149729493612e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0008946547750383615\n",
      "Gradient for decoder.decoder.1.bias: 0.0006387460744008422\n",
      "Gradient for decoder.decoder.3.weight: 0.013358472846448421\n",
      "Gradient for decoder.decoder.3.bias: 1.2168040186555373e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0004803178017027676\n",
      "Gradient for decoder.decoder.4.bias: 0.0004220763221383095\n",
      "Gradient for decoder.decoder.6.weight: 0.0008128630579449236\n",
      "Gradient for decoder.decoder.6.bias: 4.0350940253119916e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.06889820843935013\n",
      "Gradient for encoder.encoder.0.bias: 9.842004294879914e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.008141180500388145\n",
      "Gradient for encoder.encoder.1.bias: 0.006017679814249277\n",
      "Gradient for encoder.encoder.3.weight: 0.17456454038619995\n",
      "Gradient for encoder.encoder.3.bias: 9.213600993263071e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.016381096094846725\n",
      "Gradient for encoder.encoder.4.bias: 0.013706527650356293\n",
      "Gradient for encoder.mean.weight: 0.1918455809354782\n",
      "Gradient for encoder.mean.bias: 0.009098987095057964\n",
      "Gradient for encoder.log_var.weight: 0.10781826078891754\n",
      "Gradient for encoder.log_var.bias: 0.005036538001149893\n",
      "Gradient for decoder.decoder.0.weight: 0.015169752761721611\n",
      "Gradient for decoder.decoder.0.bias: 1.1548036832342845e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.000864333298522979\n",
      "Gradient for decoder.decoder.1.bias: 0.0005760883796028793\n",
      "Gradient for decoder.decoder.3.weight: 0.013143119402229786\n",
      "Gradient for decoder.decoder.3.bias: 8.372308402115891e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0004771547392010689\n",
      "Gradient for decoder.decoder.4.bias: 0.0004217078385408968\n",
      "Gradient for decoder.decoder.6.weight: 0.000833283003885299\n",
      "Gradient for decoder.decoder.6.bias: 4.7195706429192796e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.08312690258026123\n",
      "Gradient for encoder.encoder.0.bias: 1.259570781009245e-10\n",
      "Gradient for encoder.encoder.1.weight: 0.010948793031275272\n",
      "Gradient for encoder.encoder.1.bias: 0.008787302300333977\n",
      "Gradient for encoder.encoder.3.weight: 0.23264455795288086\n",
      "Gradient for encoder.encoder.3.bias: 1.2674350458041772e-09\n",
      "Gradient for encoder.encoder.4.weight: 0.0228177048265934\n",
      "Gradient for encoder.encoder.4.bias: 0.022264357656240463\n",
      "Gradient for encoder.mean.weight: 0.2603457570075989\n",
      "Gradient for encoder.mean.bias: 0.01161903515458107\n",
      "Gradient for encoder.log_var.weight: 0.14441925287246704\n",
      "Gradient for encoder.log_var.bias: 0.007433021906763315\n",
      "Gradient for decoder.decoder.0.weight: 0.01880771666765213\n",
      "Gradient for decoder.decoder.0.bias: 1.5873857783788026e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0010416420409455895\n",
      "Gradient for decoder.decoder.1.bias: 0.0006712446338497102\n",
      "Gradient for decoder.decoder.3.weight: 0.015894856303930283\n",
      "Gradient for decoder.decoder.3.bias: 1.3569027845772297e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0007278010598383844\n",
      "Gradient for decoder.decoder.4.bias: 0.0007401618640869856\n",
      "Gradient for decoder.decoder.6.weight: 0.0009829121408984065\n",
      "Gradient for decoder.decoder.6.bias: 6.464125181082636e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.05119774118065834\n",
      "Gradient for encoder.encoder.0.bias: 7.124668910396537e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.007863301783800125\n",
      "Gradient for encoder.encoder.1.bias: 0.0058253114111721516\n",
      "Gradient for encoder.encoder.3.weight: 0.17893221974372864\n",
      "Gradient for encoder.encoder.3.bias: 7.93734356019371e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.02025170437991619\n",
      "Gradient for encoder.encoder.4.bias: 0.015210230834782124\n",
      "Gradient for encoder.mean.weight: 0.26176995038986206\n",
      "Gradient for encoder.mean.bias: 0.011106633581221104\n",
      "Gradient for encoder.log_var.weight: 0.13205571472644806\n",
      "Gradient for encoder.log_var.bias: 0.0066027152352035046\n",
      "Gradient for decoder.decoder.0.weight: 0.01478968933224678\n",
      "Gradient for decoder.decoder.0.bias: 1.1953742162784664e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0008044677670113742\n",
      "Gradient for decoder.decoder.1.bias: 0.0005842066020704806\n",
      "Gradient for decoder.decoder.3.weight: 0.013318240642547607\n",
      "Gradient for decoder.decoder.3.bias: 1.0272670908362258e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0006025403272360563\n",
      "Gradient for decoder.decoder.4.bias: 0.0006236133049242198\n",
      "Gradient for decoder.decoder.6.weight: 0.0009074584813788533\n",
      "Gradient for decoder.decoder.6.bias: 6.205854879226536e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.05191778764128685\n",
      "Gradient for encoder.encoder.0.bias: 7.498653087356644e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0057693845592439175\n",
      "Gradient for encoder.encoder.1.bias: 0.005064006429165602\n",
      "Gradient for encoder.encoder.3.weight: 0.13043279945850372\n",
      "Gradient for encoder.encoder.3.bias: 8.216217706191742e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.01470969244837761\n",
      "Gradient for encoder.encoder.4.bias: 0.01342561561614275\n",
      "Gradient for encoder.mean.weight: 0.18142443895339966\n",
      "Gradient for encoder.mean.bias: 0.010327848605811596\n",
      "Gradient for encoder.log_var.weight: 0.09420046955347061\n",
      "Gradient for encoder.log_var.bias: 0.005248486064374447\n",
      "Gradient for decoder.decoder.0.weight: 0.01417385321110487\n",
      "Gradient for decoder.decoder.0.bias: 1.1132310351325003e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0007859693141654134\n",
      "Gradient for decoder.decoder.1.bias: 0.0005668101366609335\n",
      "Gradient for decoder.decoder.3.weight: 0.012437209486961365\n",
      "Gradient for decoder.decoder.3.bias: 9.21080225979587e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0005913097411394119\n",
      "Gradient for decoder.decoder.4.bias: 0.0005864216946065426\n",
      "Gradient for decoder.decoder.6.weight: 0.00110417022369802\n",
      "Gradient for decoder.decoder.6.bias: 8.584947499912232e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.04907599836587906\n",
      "Gradient for encoder.encoder.0.bias: 6.98164234758103e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.005197893362492323\n",
      "Gradient for encoder.encoder.1.bias: 0.004511150531470776\n",
      "Gradient for encoder.encoder.3.weight: 0.11504487693309784\n",
      "Gradient for encoder.encoder.3.bias: 7.461004591924336e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.011818149127066135\n",
      "Gradient for encoder.encoder.4.bias: 0.012144254520535469\n",
      "Gradient for encoder.mean.weight: 0.1565590798854828\n",
      "Gradient for encoder.mean.bias: 0.009249662980437279\n",
      "Gradient for encoder.log_var.weight: 0.08647435903549194\n",
      "Gradient for encoder.log_var.bias: 0.005484284367412329\n",
      "Gradient for decoder.decoder.0.weight: 0.01728082448244095\n",
      "Gradient for decoder.decoder.0.bias: 1.489911943819422e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0008311526034958661\n",
      "Gradient for decoder.decoder.1.bias: 0.0006471280357800424\n",
      "Gradient for decoder.decoder.3.weight: 0.015120277181267738\n",
      "Gradient for decoder.decoder.3.bias: 1.3190377956551202e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.000757837959099561\n",
      "Gradient for decoder.decoder.4.bias: 0.0008612630772404373\n",
      "Gradient for decoder.decoder.6.weight: 0.001054001972079277\n",
      "Gradient for decoder.decoder.6.bias: 7.693802035646513e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.05893101915717125\n",
      "Gradient for encoder.encoder.0.bias: 8.194772638248082e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.005354494322091341\n",
      "Gradient for encoder.encoder.1.bias: 0.004456644877791405\n",
      "Gradient for encoder.encoder.3.weight: 0.10954371839761734\n",
      "Gradient for encoder.encoder.3.bias: 5.87945081509389e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.008881240151822567\n",
      "Gradient for encoder.encoder.4.bias: 0.008536060340702534\n",
      "Gradient for encoder.mean.weight: 0.1201755478978157\n",
      "Gradient for encoder.mean.bias: 0.006068079266697168\n",
      "Gradient for encoder.log_var.weight: 0.06917303800582886\n",
      "Gradient for encoder.log_var.bias: 0.0035958068910986185\n",
      "Gradient for decoder.decoder.0.weight: 0.015164093114435673\n",
      "Gradient for decoder.decoder.0.bias: 1.1642953268165002e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0008177249692380428\n",
      "Gradient for decoder.decoder.1.bias: 0.0005708233220502734\n",
      "Gradient for decoder.decoder.3.weight: 0.012989365495741367\n",
      "Gradient for decoder.decoder.3.bias: 1.0795796895335386e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0007394853746518493\n",
      "Gradient for decoder.decoder.4.bias: 0.0008104212465696037\n",
      "Gradient for decoder.decoder.6.weight: 0.0010275868698954582\n",
      "Gradient for decoder.decoder.6.bias: 7.087197445798665e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.079062320291996\n",
      "Gradient for encoder.encoder.0.bias: 1.0532826000275719e-10\n",
      "Gradient for encoder.encoder.1.weight: 0.007206564769148827\n",
      "Gradient for encoder.encoder.1.bias: 0.005730812903493643\n",
      "Gradient for encoder.encoder.3.weight: 0.16070324182510376\n",
      "Gradient for encoder.encoder.3.bias: 8.779634796951541e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0143657261505723\n",
      "Gradient for encoder.encoder.4.bias: 0.014381076209247112\n",
      "Gradient for encoder.mean.weight: 0.18831191956996918\n",
      "Gradient for encoder.mean.bias: 0.008371646516025066\n",
      "Gradient for encoder.log_var.weight: 0.09777644276618958\n",
      "Gradient for encoder.log_var.bias: 0.004910232033580542\n",
      "Gradient for decoder.decoder.0.weight: 0.013581734150648117\n",
      "Gradient for decoder.decoder.0.bias: 1.0979370884678374e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.000694391957949847\n",
      "Gradient for decoder.decoder.1.bias: 0.0005159833235666156\n",
      "Gradient for decoder.decoder.3.weight: 0.011642631143331528\n",
      "Gradient for decoder.decoder.3.bias: 9.046537130519283e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.000432726985309273\n",
      "Gradient for decoder.decoder.4.bias: 0.00036592024844139814\n",
      "Gradient for decoder.decoder.6.weight: 0.0008177352719940245\n",
      "Gradient for decoder.decoder.6.bias: 3.9051705243764445e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training VAE Epoch:  52%|█████▏    | 41/79 [00:00<00:00, 69.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient for encoder.encoder.0.weight: 0.04423598572611809\n",
      "Gradient for encoder.encoder.0.bias: 6.460816603937047e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.004736579954624176\n",
      "Gradient for encoder.encoder.1.bias: 0.0033247293904423714\n",
      "Gradient for encoder.encoder.3.weight: 0.10318716615438461\n",
      "Gradient for encoder.encoder.3.bias: 6.735008106772966e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.011705307289958\n",
      "Gradient for encoder.encoder.4.bias: 0.009453610517084599\n",
      "Gradient for encoder.mean.weight: 0.15845122933387756\n",
      "Gradient for encoder.mean.bias: 0.0067598833702504635\n",
      "Gradient for encoder.log_var.weight: 0.10288293659687042\n",
      "Gradient for encoder.log_var.bias: 0.004102475941181183\n",
      "Gradient for decoder.decoder.0.weight: 0.014890024438500404\n",
      "Gradient for decoder.decoder.0.bias: 1.2679686467453877e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0007831336697563529\n",
      "Gradient for decoder.decoder.1.bias: 0.0005994825623929501\n",
      "Gradient for decoder.decoder.3.weight: 0.01241757906973362\n",
      "Gradient for decoder.decoder.3.bias: 9.377069259963733e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0004439701442606747\n",
      "Gradient for decoder.decoder.4.bias: 0.00039956491673365235\n",
      "Gradient for decoder.decoder.6.weight: 0.0008028296870179474\n",
      "Gradient for decoder.decoder.6.bias: 4.056395482621156e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.041539568454027176\n",
      "Gradient for encoder.encoder.0.bias: 7.161200105132437e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.006201034411787987\n",
      "Gradient for encoder.encoder.1.bias: 0.004831797443330288\n",
      "Gradient for encoder.encoder.3.weight: 0.14534948766231537\n",
      "Gradient for encoder.encoder.3.bias: 7.920083477941375e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.01929396204650402\n",
      "Gradient for encoder.encoder.4.bias: 0.01663026213645935\n",
      "Gradient for encoder.mean.weight: 0.2492801547050476\n",
      "Gradient for encoder.mean.bias: 0.011152106337249279\n",
      "Gradient for encoder.log_var.weight: 0.1517781913280487\n",
      "Gradient for encoder.log_var.bias: 0.0072694504633545876\n",
      "Gradient for decoder.decoder.0.weight: 0.015248690731823444\n",
      "Gradient for decoder.decoder.0.bias: 1.3341117099940902e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0008606662740930915\n",
      "Gradient for decoder.decoder.1.bias: 0.0006039288709871471\n",
      "Gradient for decoder.decoder.3.weight: 0.013381983153522015\n",
      "Gradient for decoder.decoder.3.bias: 9.663120303926576e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00048645728384144604\n",
      "Gradient for decoder.decoder.4.bias: 0.0004975380143150687\n",
      "Gradient for decoder.decoder.6.weight: 0.0008488214807584882\n",
      "Gradient for decoder.decoder.6.bias: 5.099695408716798e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.03927159681916237\n",
      "Gradient for encoder.encoder.0.bias: 5.966720867389697e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0053917523473501205\n",
      "Gradient for encoder.encoder.1.bias: 0.004962697625160217\n",
      "Gradient for encoder.encoder.3.weight: 0.12123651802539825\n",
      "Gradient for encoder.encoder.3.bias: 7.177381466938471e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.013819868676364422\n",
      "Gradient for encoder.encoder.4.bias: 0.012532194145023823\n",
      "Gradient for encoder.mean.weight: 0.1772039532661438\n",
      "Gradient for encoder.mean.bias: 0.00829458050429821\n",
      "Gradient for encoder.log_var.weight: 0.10553503781557083\n",
      "Gradient for encoder.log_var.bias: 0.005011231638491154\n",
      "Gradient for decoder.decoder.0.weight: 0.01677052117884159\n",
      "Gradient for decoder.decoder.0.bias: 1.3314786773133136e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0009243773529306054\n",
      "Gradient for decoder.decoder.1.bias: 0.0006490367231890559\n",
      "Gradient for decoder.decoder.3.weight: 0.014455851167440414\n",
      "Gradient for decoder.decoder.3.bias: 1.0256594185076295e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.000545311311725527\n",
      "Gradient for decoder.decoder.4.bias: 0.0004737334093078971\n",
      "Gradient for decoder.decoder.6.weight: 0.0008938916143961251\n",
      "Gradient for decoder.decoder.6.bias: 4.734441245091148e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.055036481469869614\n",
      "Gradient for encoder.encoder.0.bias: 8.916940796854789e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.005706286523491144\n",
      "Gradient for encoder.encoder.1.bias: 0.004256184678524733\n",
      "Gradient for encoder.encoder.3.weight: 0.12231730669736862\n",
      "Gradient for encoder.encoder.3.bias: 6.861372026101265e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.011724197305738926\n",
      "Gradient for encoder.encoder.4.bias: 0.010818316601216793\n",
      "Gradient for encoder.mean.weight: 0.153318852186203\n",
      "Gradient for encoder.mean.bias: 0.006458537187427282\n",
      "Gradient for encoder.log_var.weight: 0.08361989259719849\n",
      "Gradient for encoder.log_var.bias: 0.0042052119970321655\n",
      "Gradient for decoder.decoder.0.weight: 0.012656455859541893\n",
      "Gradient for decoder.decoder.0.bias: 1.011062136790919e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0006493974360637367\n",
      "Gradient for decoder.decoder.1.bias: 0.0004432442947290838\n",
      "Gradient for decoder.decoder.3.weight: 0.010933949612081051\n",
      "Gradient for decoder.decoder.3.bias: 9.213539653440961e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0006205954123288393\n",
      "Gradient for decoder.decoder.4.bias: 0.0007164871203713119\n",
      "Gradient for decoder.decoder.6.weight: 0.0008548003388568759\n",
      "Gradient for decoder.decoder.6.bias: 5.578868149314076e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.04502752050757408\n",
      "Gradient for encoder.encoder.0.bias: 5.8266613756075e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.004806486889719963\n",
      "Gradient for encoder.encoder.1.bias: 0.0038219583220779896\n",
      "Gradient for encoder.encoder.3.weight: 0.10849160701036453\n",
      "Gradient for encoder.encoder.3.bias: 6.341123737207965e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.011783896014094353\n",
      "Gradient for encoder.encoder.4.bias: 0.010355341248214245\n",
      "Gradient for encoder.mean.weight: 0.1464565247297287\n",
      "Gradient for encoder.mean.bias: 0.007387061137706041\n",
      "Gradient for encoder.log_var.weight: 0.07722201198339462\n",
      "Gradient for encoder.log_var.bias: 0.0038063491228967905\n",
      "Gradient for decoder.decoder.0.weight: 0.01617264747619629\n",
      "Gradient for decoder.decoder.0.bias: 1.2635374690983525e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0008801135700196028\n",
      "Gradient for decoder.decoder.1.bias: 0.0005852138856425881\n",
      "Gradient for decoder.decoder.3.weight: 0.01372198574244976\n",
      "Gradient for decoder.decoder.3.bias: 9.527114513963042e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0005210740491747856\n",
      "Gradient for decoder.decoder.4.bias: 0.0005143281305208802\n",
      "Gradient for decoder.decoder.6.weight: 0.0008952881908044219\n",
      "Gradient for decoder.decoder.6.bias: 5.397301720222458e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.04998939484357834\n",
      "Gradient for encoder.encoder.0.bias: 7.509774746505826e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0035315516870468855\n",
      "Gradient for encoder.encoder.1.bias: 0.003097392851486802\n",
      "Gradient for encoder.encoder.3.weight: 0.07997238636016846\n",
      "Gradient for encoder.encoder.3.bias: 5.992906171314871e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.00853776279836893\n",
      "Gradient for encoder.encoder.4.bias: 0.008850735612213612\n",
      "Gradient for encoder.mean.weight: 0.11629507690668106\n",
      "Gradient for encoder.mean.bias: 0.007058979943394661\n",
      "Gradient for encoder.log_var.weight: 0.07058540731668472\n",
      "Gradient for encoder.log_var.bias: 0.004204012919217348\n",
      "Gradient for decoder.decoder.0.weight: 0.01251176930963993\n",
      "Gradient for decoder.decoder.0.bias: 9.858749927538213e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0007105566910468042\n",
      "Gradient for decoder.decoder.1.bias: 0.00044949710718356073\n",
      "Gradient for decoder.decoder.3.weight: 0.010521761141717434\n",
      "Gradient for decoder.decoder.3.bias: 8.419091812594814e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00042212120024487376\n",
      "Gradient for decoder.decoder.4.bias: 0.00044994091149419546\n",
      "Gradient for decoder.decoder.6.weight: 0.0007874022703617811\n",
      "Gradient for decoder.decoder.6.bias: 4.4871936552226543e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.030952753499150276\n",
      "Gradient for encoder.encoder.0.bias: 4.66967228773818e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0034931330010294914\n",
      "Gradient for encoder.encoder.1.bias: 0.002781669143587351\n",
      "Gradient for encoder.encoder.3.weight: 0.07710279524326324\n",
      "Gradient for encoder.encoder.3.bias: 4.968241373859428e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.009268423542380333\n",
      "Gradient for encoder.encoder.4.bias: 0.008227941580116749\n",
      "Gradient for encoder.mean.weight: 0.1222982183098793\n",
      "Gradient for encoder.mean.bias: 0.005906608887016773\n",
      "Gradient for encoder.log_var.weight: 0.06880152970552444\n",
      "Gradient for encoder.log_var.bias: 0.0035502896644175053\n",
      "Gradient for decoder.decoder.0.weight: 0.016391132026910782\n",
      "Gradient for decoder.decoder.0.bias: 1.4619314092634283e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0009226918336935341\n",
      "Gradient for decoder.decoder.1.bias: 0.0006235229666344821\n",
      "Gradient for decoder.decoder.3.weight: 0.014401926659047604\n",
      "Gradient for decoder.decoder.3.bias: 1.1669543109604774e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0005828905268572271\n",
      "Gradient for decoder.decoder.4.bias: 0.0005498773534782231\n",
      "Gradient for decoder.decoder.6.weight: 0.0009075178531929851\n",
      "Gradient for decoder.decoder.6.bias: 5.417678039520979e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.041544750332832336\n",
      "Gradient for encoder.encoder.0.bias: 6.179679684636952e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.003799558850005269\n",
      "Gradient for encoder.encoder.1.bias: 0.0029358360916376114\n",
      "Gradient for encoder.encoder.3.weight: 0.08748959004878998\n",
      "Gradient for encoder.encoder.3.bias: 5.459614427216763e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.010320078581571579\n",
      "Gradient for encoder.encoder.4.bias: 0.00846771989017725\n",
      "Gradient for encoder.mean.weight: 0.13865777850151062\n",
      "Gradient for encoder.mean.bias: 0.007307292427867651\n",
      "Gradient for encoder.log_var.weight: 0.07611437886953354\n",
      "Gradient for encoder.log_var.bias: 0.004600473679602146\n",
      "Gradient for decoder.decoder.0.weight: 0.013082646764814854\n",
      "Gradient for decoder.decoder.0.bias: 1.0652025789203989e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0007010083645582199\n",
      "Gradient for decoder.decoder.1.bias: 0.00046880709123797715\n",
      "Gradient for decoder.decoder.3.weight: 0.010805033147335052\n",
      "Gradient for decoder.decoder.3.bias: 8.87268800098262e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0004300224536564201\n",
      "Gradient for decoder.decoder.4.bias: 0.00048675129073671997\n",
      "Gradient for decoder.decoder.6.weight: 0.0008109848713502288\n",
      "Gradient for decoder.decoder.6.bias: 4.6735553041798994e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.039800066500902176\n",
      "Gradient for encoder.encoder.0.bias: 5.948038589442817e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.00492322351783514\n",
      "Gradient for encoder.encoder.1.bias: 0.003721440676599741\n",
      "Gradient for encoder.encoder.3.weight: 0.11287325620651245\n",
      "Gradient for encoder.encoder.3.bias: 6.572889454936615e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.01193895936012268\n",
      "Gradient for encoder.encoder.4.bias: 0.010013267397880554\n",
      "Gradient for encoder.mean.weight: 0.13745719194412231\n",
      "Gradient for encoder.mean.bias: 0.006655675824731588\n",
      "Gradient for encoder.log_var.weight: 0.09059751778841019\n",
      "Gradient for encoder.log_var.bias: 0.0035635931417346\n",
      "Gradient for decoder.decoder.0.weight: 0.014648927375674248\n",
      "Gradient for decoder.decoder.0.bias: 1.3366323325936236e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0007463361253030598\n",
      "Gradient for decoder.decoder.1.bias: 0.0005168533534742892\n",
      "Gradient for decoder.decoder.3.weight: 0.012548064813017845\n",
      "Gradient for decoder.decoder.3.bias: 1.085815812262858e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.00047756178537383676\n",
      "Gradient for decoder.decoder.4.bias: 0.0005071100895293057\n",
      "Gradient for decoder.decoder.6.weight: 0.0008269648533314466\n",
      "Gradient for decoder.decoder.6.bias: 5.34624996362254e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.03979700058698654\n",
      "Gradient for encoder.encoder.0.bias: 5.166217106888915e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.004931983072310686\n",
      "Gradient for encoder.encoder.1.bias: 0.0038584850262850523\n",
      "Gradient for encoder.encoder.3.weight: 0.10538001358509064\n",
      "Gradient for encoder.encoder.3.bias: 7.114484001924382e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.012331529520452023\n",
      "Gradient for encoder.encoder.4.bias: 0.012516777031123638\n",
      "Gradient for encoder.mean.weight: 0.1561712622642517\n",
      "Gradient for encoder.mean.bias: 0.009040247648954391\n",
      "Gradient for encoder.log_var.weight: 0.09511413425207138\n",
      "Gradient for encoder.log_var.bias: 0.005759246647357941\n",
      "Gradient for decoder.decoder.0.weight: 0.01898285746574402\n",
      "Gradient for decoder.decoder.0.bias: 1.555583301060537e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0009956075809895992\n",
      "Gradient for decoder.decoder.1.bias: 0.0006999931065365672\n",
      "Gradient for decoder.decoder.3.weight: 0.01621106266975403\n",
      "Gradient for decoder.decoder.3.bias: 1.2554074446669006e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.00073625473305583\n",
      "Gradient for decoder.decoder.4.bias: 0.0007432513521052897\n",
      "Gradient for decoder.decoder.6.weight: 0.0009459425345994532\n",
      "Gradient for decoder.decoder.6.bias: 5.38882304681465e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.05063041299581528\n",
      "Gradient for encoder.encoder.0.bias: 7.099515419994873e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.005490420386195183\n",
      "Gradient for encoder.encoder.1.bias: 0.004522185306996107\n",
      "Gradient for encoder.encoder.3.weight: 0.11860349029302597\n",
      "Gradient for encoder.encoder.3.bias: 8.519117078442662e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.014025721698999405\n",
      "Gradient for encoder.encoder.4.bias: 0.01575629413127899\n",
      "Gradient for encoder.mean.weight: 0.17074348032474518\n",
      "Gradient for encoder.mean.bias: 0.010522584430873394\n",
      "Gradient for encoder.log_var.weight: 0.10017671436071396\n",
      "Gradient for encoder.log_var.bias: 0.007347521372139454\n",
      "Gradient for decoder.decoder.0.weight: 0.013867117464542389\n",
      "Gradient for decoder.decoder.0.bias: 1.1504300290177127e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0007112029707059264\n",
      "Gradient for decoder.decoder.1.bias: 0.0005204334738664329\n",
      "Gradient for decoder.decoder.3.weight: 0.011574365198612213\n",
      "Gradient for decoder.decoder.3.bias: 8.613831870007971e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0003799789701588452\n",
      "Gradient for decoder.decoder.4.bias: 0.00035991924232803285\n",
      "Gradient for decoder.decoder.6.weight: 0.0008061031112447381\n",
      "Gradient for decoder.decoder.6.bias: 4.452180291991681e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.04071523994207382\n",
      "Gradient for encoder.encoder.0.bias: 5.66717540950723e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.004747813567519188\n",
      "Gradient for encoder.encoder.1.bias: 0.004024225287139416\n",
      "Gradient for encoder.encoder.3.weight: 0.11052698642015457\n",
      "Gradient for encoder.encoder.3.bias: 9.68444879845265e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.01533628348261118\n",
      "Gradient for encoder.encoder.4.bias: 0.019033154472708702\n",
      "Gradient for encoder.mean.weight: 0.18835662305355072\n",
      "Gradient for encoder.mean.bias: 0.014016927219927311\n",
      "Gradient for encoder.log_var.weight: 0.11948549002408981\n",
      "Gradient for encoder.log_var.bias: 0.009571749716997147\n",
      "Gradient for decoder.decoder.0.weight: 0.016229724511504173\n",
      "Gradient for decoder.decoder.0.bias: 1.3488783701109952e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0008870320743881166\n",
      "Gradient for decoder.decoder.1.bias: 0.0006257486529648304\n",
      "Gradient for decoder.decoder.3.weight: 0.013846620917320251\n",
      "Gradient for decoder.decoder.3.bias: 1.0721000476276998e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0004621481930371374\n",
      "Gradient for decoder.decoder.4.bias: 0.0004402108897920698\n",
      "Gradient for decoder.decoder.6.weight: 0.0008816159679554403\n",
      "Gradient for decoder.decoder.6.bias: 5.702579437638633e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.0633804053068161\n",
      "Gradient for encoder.encoder.0.bias: 9.027665420768827e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0073090591467916965\n",
      "Gradient for encoder.encoder.1.bias: 0.005836967844516039\n",
      "Gradient for encoder.encoder.3.weight: 0.1596960574388504\n",
      "Gradient for encoder.encoder.3.bias: 7.373460175763569e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.014922392554581165\n",
      "Gradient for encoder.encoder.4.bias: 0.011600860394537449\n",
      "Gradient for encoder.mean.weight: 0.20283031463623047\n",
      "Gradient for encoder.mean.bias: 0.00671684043481946\n",
      "Gradient for encoder.log_var.weight: 0.11292096227407455\n",
      "Gradient for encoder.log_var.bias: 0.004270492121577263\n",
      "Gradient for decoder.decoder.0.weight: 0.016012409701943398\n",
      "Gradient for decoder.decoder.0.bias: 1.373369473700592e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0008470739703625441\n",
      "Gradient for decoder.decoder.1.bias: 0.0005967921460978687\n",
      "Gradient for decoder.decoder.3.weight: 0.013956934213638306\n",
      "Gradient for decoder.decoder.3.bias: 1.0516604254107165e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0005085766315460205\n",
      "Gradient for decoder.decoder.4.bias: 0.0004383863415569067\n",
      "Gradient for decoder.decoder.6.weight: 0.0008632829994894564\n",
      "Gradient for decoder.decoder.6.bias: 4.411908230395056e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.04057443514466286\n",
      "Gradient for encoder.encoder.0.bias: 6.43032987968084e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.004286492709070444\n",
      "Gradient for encoder.encoder.1.bias: 0.003545304061844945\n",
      "Gradient for encoder.encoder.3.weight: 0.09791339188814163\n",
      "Gradient for encoder.encoder.3.bias: 7.460242423817931e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.012993480078876019\n",
      "Gradient for encoder.encoder.4.bias: 0.016049079596996307\n",
      "Gradient for encoder.mean.weight: 0.1606537252664566\n",
      "Gradient for encoder.mean.bias: 0.012942947447299957\n",
      "Gradient for encoder.log_var.weight: 0.08837702125310898\n",
      "Gradient for encoder.log_var.bias: 0.007851963862776756\n",
      "Gradient for decoder.decoder.0.weight: 0.014240914955735207\n",
      "Gradient for decoder.decoder.0.bias: 1.169920965660154e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0008134330273605883\n",
      "Gradient for decoder.decoder.1.bias: 0.00051151990192011\n",
      "Gradient for decoder.decoder.3.weight: 0.012419073842465878\n",
      "Gradient for decoder.decoder.3.bias: 1.1548573902731007e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0007793183322064579\n",
      "Gradient for decoder.decoder.4.bias: 0.0009285999112762511\n",
      "Gradient for decoder.decoder.6.weight: 0.0010891687124967575\n",
      "Gradient for decoder.decoder.6.bias: 9.464706818107516e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.04457399621605873\n",
      "Gradient for encoder.encoder.0.bias: 6.893400433805041e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.004811667371541262\n",
      "Gradient for encoder.encoder.1.bias: 0.003966061864048243\n",
      "Gradient for encoder.encoder.3.weight: 0.1053246408700943\n",
      "Gradient for encoder.encoder.3.bias: 6.49951537035065e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.012983537279069424\n",
      "Gradient for encoder.encoder.4.bias: 0.012145605869591236\n",
      "Gradient for encoder.mean.weight: 0.16507649421691895\n",
      "Gradient for encoder.mean.bias: 0.008807726204395294\n",
      "Gradient for encoder.log_var.weight: 0.10001678019762039\n",
      "Gradient for encoder.log_var.bias: 0.0053660254925489426\n",
      "Gradient for decoder.decoder.0.weight: 0.012775194831192493\n",
      "Gradient for decoder.decoder.0.bias: 1.0974967462606955e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0006643919041380286\n",
      "Gradient for decoder.decoder.1.bias: 0.0004542809328995645\n",
      "Gradient for decoder.decoder.3.weight: 0.010541017167270184\n",
      "Gradient for decoder.decoder.3.bias: 9.346883683702956e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0004159281961619854\n",
      "Gradient for decoder.decoder.4.bias: 0.00042528402991592884\n",
      "Gradient for decoder.decoder.6.weight: 0.0008748821564950049\n",
      "Gradient for decoder.decoder.6.bias: 5.6182580010499805e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.0480232834815979\n",
      "Gradient for encoder.encoder.0.bias: 9.14443659683073e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.007853199727833271\n",
      "Gradient for encoder.encoder.1.bias: 0.0058913277462124825\n",
      "Gradient for encoder.encoder.3.weight: 0.16634777188301086\n",
      "Gradient for encoder.encoder.3.bias: 7.680971969570294e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.015994003042578697\n",
      "Gradient for encoder.encoder.4.bias: 0.015462632291018963\n",
      "Gradient for encoder.mean.weight: 0.21516360342502594\n",
      "Gradient for encoder.mean.bias: 0.011107567697763443\n",
      "Gradient for encoder.log_var.weight: 0.12238746136426926\n",
      "Gradient for encoder.log_var.bias: 0.007175734732300043\n",
      "Gradient for decoder.decoder.0.weight: 0.012676114216446877\n",
      "Gradient for decoder.decoder.0.bias: 1.1421680268242085e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0006148825050331652\n",
      "Gradient for decoder.decoder.1.bias: 0.00045203391346149147\n",
      "Gradient for decoder.decoder.3.weight: 0.01039317436516285\n",
      "Gradient for decoder.decoder.3.bias: 8.684922919721672e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00036071674549020827\n",
      "Gradient for decoder.decoder.4.bias: 0.0003983344358857721\n",
      "Gradient for decoder.decoder.6.weight: 0.0008144876919686794\n",
      "Gradient for decoder.decoder.6.bias: 4.984377301298082e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training VAE Epoch:  72%|███████▏  | 57/79 [00:00<00:00, 73.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient for encoder.encoder.0.weight: 0.05139670893549919\n",
      "Gradient for encoder.encoder.0.bias: 9.823891700122545e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.008365546353161335\n",
      "Gradient for encoder.encoder.1.bias: 0.006917701102793217\n",
      "Gradient for encoder.encoder.3.weight: 0.17984916269779205\n",
      "Gradient for encoder.encoder.3.bias: 1.0260056138022833e-09\n",
      "Gradient for encoder.encoder.4.weight: 0.0186421200633049\n",
      "Gradient for encoder.encoder.4.bias: 0.01798664778470993\n",
      "Gradient for encoder.mean.weight: 0.23366789519786835\n",
      "Gradient for encoder.mean.bias: 0.013684696517884731\n",
      "Gradient for encoder.log_var.weight: 0.13572077453136444\n",
      "Gradient for encoder.log_var.bias: 0.007941397838294506\n",
      "Gradient for decoder.decoder.0.weight: 0.012602615170180798\n",
      "Gradient for decoder.decoder.0.bias: 1.056671278254484e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0007026555249467492\n",
      "Gradient for decoder.decoder.1.bias: 0.0004406512889545411\n",
      "Gradient for decoder.decoder.3.weight: 0.010902022942900658\n",
      "Gradient for decoder.decoder.3.bias: 9.157571922990826e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0004940401995554566\n",
      "Gradient for decoder.decoder.4.bias: 0.0005435210186988115\n",
      "Gradient for decoder.decoder.6.weight: 0.0008461230900138617\n",
      "Gradient for decoder.decoder.6.bias: 5.4968444601399824e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.04533008113503456\n",
      "Gradient for encoder.encoder.0.bias: 7.157308773431126e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0053229243494570255\n",
      "Gradient for encoder.encoder.1.bias: 0.00400052173063159\n",
      "Gradient for encoder.encoder.3.weight: 0.12196602672338486\n",
      "Gradient for encoder.encoder.3.bias: 7.373339716565397e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.012526425532996655\n",
      "Gradient for encoder.encoder.4.bias: 0.010197233408689499\n",
      "Gradient for encoder.mean.weight: 0.1556100696325302\n",
      "Gradient for encoder.mean.bias: 0.006020727567374706\n",
      "Gradient for encoder.log_var.weight: 0.08676229417324066\n",
      "Gradient for encoder.log_var.bias: 0.00339882611297071\n",
      "Gradient for decoder.decoder.0.weight: 0.016473092138767242\n",
      "Gradient for decoder.decoder.0.bias: 1.3761833339565044e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0009071614476852119\n",
      "Gradient for decoder.decoder.1.bias: 0.0006186557002365589\n",
      "Gradient for decoder.decoder.3.weight: 0.014353867620229721\n",
      "Gradient for decoder.decoder.3.bias: 1.2137074678619797e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.000527736556250602\n",
      "Gradient for decoder.decoder.4.bias: 0.00043060045572929084\n",
      "Gradient for decoder.decoder.6.weight: 0.0008724229992367327\n",
      "Gradient for decoder.decoder.6.bias: 4.377253935672343e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.06006789579987526\n",
      "Gradient for encoder.encoder.0.bias: 7.0335709478897e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.006138739176094532\n",
      "Gradient for encoder.encoder.1.bias: 0.004690093919634819\n",
      "Gradient for encoder.encoder.3.weight: 0.13475395739078522\n",
      "Gradient for encoder.encoder.3.bias: 8.637043302783809e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.014032896608114243\n",
      "Gradient for encoder.encoder.4.bias: 0.013870076276361942\n",
      "Gradient for encoder.mean.weight: 0.18552111089229584\n",
      "Gradient for encoder.mean.bias: 0.01059211790561676\n",
      "Gradient for encoder.log_var.weight: 0.10221336781978607\n",
      "Gradient for encoder.log_var.bias: 0.0052992780692875385\n",
      "Gradient for decoder.decoder.0.weight: 0.015053970739245415\n",
      "Gradient for decoder.decoder.0.bias: 1.2417891714910922e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0007907806430011988\n",
      "Gradient for decoder.decoder.1.bias: 0.0005686416989192367\n",
      "Gradient for decoder.decoder.3.weight: 0.012741555459797382\n",
      "Gradient for decoder.decoder.3.bias: 1.0474902195634073e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.00048462703125551343\n",
      "Gradient for decoder.decoder.4.bias: 0.00042488047620281577\n",
      "Gradient for decoder.decoder.6.weight: 0.0008038743399083614\n",
      "Gradient for decoder.decoder.6.bias: 3.941297472920269e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.038330961018800735\n",
      "Gradient for encoder.encoder.0.bias: 6.02650498948698e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.006829780526459217\n",
      "Gradient for encoder.encoder.1.bias: 0.0047788070514798164\n",
      "Gradient for encoder.encoder.3.weight: 0.1402130126953125\n",
      "Gradient for encoder.encoder.3.bias: 6.509012218103294e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.014956993982195854\n",
      "Gradient for encoder.encoder.4.bias: 0.014090890064835548\n",
      "Gradient for encoder.mean.weight: 0.19250059127807617\n",
      "Gradient for encoder.mean.bias: 0.010187515988945961\n",
      "Gradient for encoder.log_var.weight: 0.10803825408220291\n",
      "Gradient for encoder.log_var.bias: 0.00498445238918066\n",
      "Gradient for decoder.decoder.0.weight: 0.01566351018846035\n",
      "Gradient for decoder.decoder.0.bias: 1.347288391961854e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0008145112660713494\n",
      "Gradient for decoder.decoder.1.bias: 0.0005829059518873692\n",
      "Gradient for decoder.decoder.3.weight: 0.013392632827162743\n",
      "Gradient for decoder.decoder.3.bias: 1.0978176007148122e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0005762302316725254\n",
      "Gradient for decoder.decoder.4.bias: 0.0005577004048973322\n",
      "Gradient for decoder.decoder.6.weight: 0.0008875222411006689\n",
      "Gradient for decoder.decoder.6.bias: 4.883372093900107e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.05231297016143799\n",
      "Gradient for encoder.encoder.0.bias: 6.892981324613245e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.005171987693756819\n",
      "Gradient for encoder.encoder.1.bias: 0.004245383199304342\n",
      "Gradient for encoder.encoder.3.weight: 0.1231829971075058\n",
      "Gradient for encoder.encoder.3.bias: 7.192139661604813e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.012665368616580963\n",
      "Gradient for encoder.encoder.4.bias: 0.012273197993636131\n",
      "Gradient for encoder.mean.weight: 0.1648740917444229\n",
      "Gradient for encoder.mean.bias: 0.008826443925499916\n",
      "Gradient for encoder.log_var.weight: 0.09579721838235855\n",
      "Gradient for encoder.log_var.bias: 0.0053216018714010715\n",
      "Gradient for decoder.decoder.0.weight: 0.013725118711590767\n",
      "Gradient for decoder.decoder.0.bias: 1.2074280464346998e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.000723309931345284\n",
      "Gradient for decoder.decoder.1.bias: 0.0005091523635201156\n",
      "Gradient for decoder.decoder.3.weight: 0.011841063387691975\n",
      "Gradient for decoder.decoder.3.bias: 1.0192283128596102e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.00040615207399241626\n",
      "Gradient for decoder.decoder.4.bias: 0.0003670164733193815\n",
      "Gradient for decoder.decoder.6.weight: 0.0007963753887452185\n",
      "Gradient for decoder.decoder.6.bias: 3.670775186037645e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.043649137020111084\n",
      "Gradient for encoder.encoder.0.bias: 7.326911299898597e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.005055311135947704\n",
      "Gradient for encoder.encoder.1.bias: 0.0038884009700268507\n",
      "Gradient for encoder.encoder.3.weight: 0.10584362596273422\n",
      "Gradient for encoder.encoder.3.bias: 6.243984218556875e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.011483278125524521\n",
      "Gradient for encoder.encoder.4.bias: 0.009695861488580704\n",
      "Gradient for encoder.mean.weight: 0.15767936408519745\n",
      "Gradient for encoder.mean.bias: 0.008021663874387741\n",
      "Gradient for encoder.log_var.weight: 0.08568879961967468\n",
      "Gradient for encoder.log_var.bias: 0.004066741093993187\n",
      "Gradient for decoder.decoder.0.weight: 0.012685824185609818\n",
      "Gradient for decoder.decoder.0.bias: 1.075012925899621e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0006680921651422977\n",
      "Gradient for decoder.decoder.1.bias: 0.0004789259110111743\n",
      "Gradient for decoder.decoder.3.weight: 0.010855283588171005\n",
      "Gradient for decoder.decoder.3.bias: 9.002677076042076e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00043487490620464087\n",
      "Gradient for decoder.decoder.4.bias: 0.0004496929468587041\n",
      "Gradient for decoder.decoder.6.weight: 0.0007974145119078457\n",
      "Gradient for decoder.decoder.6.bias: 4.655426164390519e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.06966791301965714\n",
      "Gradient for encoder.encoder.0.bias: 1.2967357743143282e-10\n",
      "Gradient for encoder.encoder.1.weight: 0.007687147706747055\n",
      "Gradient for encoder.encoder.1.bias: 0.005990691017359495\n",
      "Gradient for encoder.encoder.3.weight: 0.16662752628326416\n",
      "Gradient for encoder.encoder.3.bias: 8.419697161698991e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.01627792976796627\n",
      "Gradient for encoder.encoder.4.bias: 0.015343552455306053\n",
      "Gradient for encoder.mean.weight: 0.20577141642570496\n",
      "Gradient for encoder.mean.bias: 0.0096360445022583\n",
      "Gradient for encoder.log_var.weight: 0.12006297707557678\n",
      "Gradient for encoder.log_var.bias: 0.005410812795162201\n",
      "Gradient for decoder.decoder.0.weight: 0.011420439928770065\n",
      "Gradient for decoder.decoder.0.bias: 9.833418801452609e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005604767356999218\n",
      "Gradient for decoder.decoder.1.bias: 0.0004086471744813025\n",
      "Gradient for decoder.decoder.3.weight: 0.01007448136806488\n",
      "Gradient for decoder.decoder.3.bias: 9.543953821689044e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0006246813572943211\n",
      "Gradient for decoder.decoder.4.bias: 0.0006971279508434236\n",
      "Gradient for decoder.decoder.6.weight: 0.0008246969082392752\n",
      "Gradient for decoder.decoder.6.bias: 5.4666288633598015e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.058505892753601074\n",
      "Gradient for encoder.encoder.0.bias: 9.320296617820745e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0045418827794492245\n",
      "Gradient for encoder.encoder.1.bias: 0.0037240893580019474\n",
      "Gradient for encoder.encoder.3.weight: 0.10069207847118378\n",
      "Gradient for encoder.encoder.3.bias: 6.346911329835336e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.01012492273002863\n",
      "Gradient for encoder.encoder.4.bias: 0.009078934788703918\n",
      "Gradient for encoder.mean.weight: 0.12081252038478851\n",
      "Gradient for encoder.mean.bias: 0.004930662456899881\n",
      "Gradient for encoder.log_var.weight: 0.07971441745758057\n",
      "Gradient for encoder.log_var.bias: 0.003218021709471941\n",
      "Gradient for decoder.decoder.0.weight: 0.011965518817305565\n",
      "Gradient for decoder.decoder.0.bias: 9.511086362934407e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.000608721689786762\n",
      "Gradient for decoder.decoder.1.bias: 0.00044077294296585023\n",
      "Gradient for decoder.decoder.3.weight: 0.010341507382690907\n",
      "Gradient for decoder.decoder.3.bias: 1.0176604003930834e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0006137581076472998\n",
      "Gradient for decoder.decoder.4.bias: 0.0007818813319317997\n",
      "Gradient for decoder.decoder.6.weight: 0.0008797041955403984\n",
      "Gradient for decoder.decoder.6.bias: 7.043730875011533e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.046068258583545685\n",
      "Gradient for encoder.encoder.0.bias: 6.98654398223475e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.00592756038531661\n",
      "Gradient for encoder.encoder.1.bias: 0.004742072429507971\n",
      "Gradient for encoder.encoder.3.weight: 0.1330372840166092\n",
      "Gradient for encoder.encoder.3.bias: 7.133758583854899e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.013831838965415955\n",
      "Gradient for encoder.encoder.4.bias: 0.01097392663359642\n",
      "Gradient for encoder.mean.weight: 0.17452885210514069\n",
      "Gradient for encoder.mean.bias: 0.006066862028092146\n",
      "Gradient for encoder.log_var.weight: 0.09782392531633377\n",
      "Gradient for encoder.log_var.bias: 0.003343474818393588\n",
      "Gradient for decoder.decoder.0.weight: 0.01654350943863392\n",
      "Gradient for decoder.decoder.0.bias: 1.4555538718763472e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0008589252829551697\n",
      "Gradient for decoder.decoder.1.bias: 0.0006057366845197976\n",
      "Gradient for decoder.decoder.3.weight: 0.014180712401866913\n",
      "Gradient for decoder.decoder.3.bias: 1.1660618304265569e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0005534952506422997\n",
      "Gradient for decoder.decoder.4.bias: 0.0005515063530765474\n",
      "Gradient for decoder.decoder.6.weight: 0.0008548495825380087\n",
      "Gradient for decoder.decoder.6.bias: 4.965356856700964e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.049600061029195786\n",
      "Gradient for encoder.encoder.0.bias: 7.807275659299506e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.007301819510757923\n",
      "Gradient for encoder.encoder.1.bias: 0.005320676136761904\n",
      "Gradient for encoder.encoder.3.weight: 0.16442856192588806\n",
      "Gradient for encoder.encoder.3.bias: 7.134349777615512e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.016754329204559326\n",
      "Gradient for encoder.encoder.4.bias: 0.012246476486325264\n",
      "Gradient for encoder.mean.weight: 0.22474093735218048\n",
      "Gradient for encoder.mean.bias: 0.007763761095702648\n",
      "Gradient for encoder.log_var.weight: 0.10834486037492752\n",
      "Gradient for encoder.log_var.bias: 0.0043334513902664185\n",
      "Gradient for decoder.decoder.0.weight: 0.013915173709392548\n",
      "Gradient for decoder.decoder.0.bias: 1.1773171326723286e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0007108214194886386\n",
      "Gradient for decoder.decoder.1.bias: 0.0004946955014020205\n",
      "Gradient for decoder.decoder.3.weight: 0.01184304989874363\n",
      "Gradient for decoder.decoder.3.bias: 8.069093310192343e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0004101633676327765\n",
      "Gradient for decoder.decoder.4.bias: 0.00038459652569144964\n",
      "Gradient for decoder.decoder.6.weight: 0.0008165923063643277\n",
      "Gradient for decoder.decoder.6.bias: 4.7839697799645364e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.05154838413000107\n",
      "Gradient for encoder.encoder.0.bias: 7.578054850299054e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.006720114499330521\n",
      "Gradient for encoder.encoder.1.bias: 0.0050024595111608505\n",
      "Gradient for encoder.encoder.3.weight: 0.15062910318374634\n",
      "Gradient for encoder.encoder.3.bias: 6.540655239639648e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.01700747199356556\n",
      "Gradient for encoder.encoder.4.bias: 0.0125090591609478\n",
      "Gradient for encoder.mean.weight: 0.21793200075626373\n",
      "Gradient for encoder.mean.bias: 0.007531055249273777\n",
      "Gradient for encoder.log_var.weight: 0.12281753122806549\n",
      "Gradient for encoder.log_var.bias: 0.0037774229422211647\n",
      "Gradient for decoder.decoder.0.weight: 0.014676080085337162\n",
      "Gradient for decoder.decoder.0.bias: 1.3486656236239014e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0007969778380356729\n",
      "Gradient for decoder.decoder.1.bias: 0.0005592245724983513\n",
      "Gradient for decoder.decoder.3.weight: 0.01284975465387106\n",
      "Gradient for decoder.decoder.3.bias: 9.61572904634167e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0004687849141191691\n",
      "Gradient for decoder.decoder.4.bias: 0.0004345092747826129\n",
      "Gradient for decoder.decoder.6.weight: 0.0008032019250094891\n",
      "Gradient for decoder.decoder.6.bias: 3.887058119289577e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.052921198308467865\n",
      "Gradient for encoder.encoder.0.bias: 8.871376550034782e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.006994966417551041\n",
      "Gradient for encoder.encoder.1.bias: 0.005427968222647905\n",
      "Gradient for encoder.encoder.3.weight: 0.1534470021724701\n",
      "Gradient for encoder.encoder.3.bias: 8.309790633376224e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.01884206384420395\n",
      "Gradient for encoder.encoder.4.bias: 0.016757113859057426\n",
      "Gradient for encoder.mean.weight: 0.24707193672657013\n",
      "Gradient for encoder.mean.bias: 0.013026800937950611\n",
      "Gradient for encoder.log_var.weight: 0.14994622766971588\n",
      "Gradient for encoder.log_var.bias: 0.008155508898198605\n",
      "Gradient for decoder.decoder.0.weight: 0.012795663438737392\n",
      "Gradient for decoder.decoder.0.bias: 1.005624333805244e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.000722499389667064\n",
      "Gradient for decoder.decoder.1.bias: 0.00046682730317115784\n",
      "Gradient for decoder.decoder.3.weight: 0.011195790953934193\n",
      "Gradient for decoder.decoder.3.bias: 8.881440027863619e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0004175780632067472\n",
      "Gradient for decoder.decoder.4.bias: 0.0003417549596633762\n",
      "Gradient for decoder.decoder.6.weight: 0.0008093492360785604\n",
      "Gradient for decoder.decoder.6.bias: 3.922920586774126e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.03469086438417435\n",
      "Gradient for encoder.encoder.0.bias: 5.0836643922247404e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.004021327942609787\n",
      "Gradient for encoder.encoder.1.bias: 0.0037455554120242596\n",
      "Gradient for encoder.encoder.3.weight: 0.09508803486824036\n",
      "Gradient for encoder.encoder.3.bias: 6.304268218570996e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.010717523284256458\n",
      "Gradient for encoder.encoder.4.bias: 0.010923497378826141\n",
      "Gradient for encoder.mean.weight: 0.14102831482887268\n",
      "Gradient for encoder.mean.bias: 0.008342764340341091\n",
      "Gradient for encoder.log_var.weight: 0.09246978908777237\n",
      "Gradient for encoder.log_var.bias: 0.0051081497222185135\n",
      "Gradient for decoder.decoder.0.weight: 0.016833407804369926\n",
      "Gradient for decoder.decoder.0.bias: 1.503211721765041e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0008629925432614982\n",
      "Gradient for decoder.decoder.1.bias: 0.0006353514036163688\n",
      "Gradient for decoder.decoder.3.weight: 0.014270325191318989\n",
      "Gradient for decoder.decoder.3.bias: 1.2287880435390974e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0006602712091989815\n",
      "Gradient for decoder.decoder.4.bias: 0.0006796211819164455\n",
      "Gradient for decoder.decoder.6.weight: 0.0009988030651584268\n",
      "Gradient for decoder.decoder.6.bias: 6.868940545246005e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.04756772145628929\n",
      "Gradient for encoder.encoder.0.bias: 8.504261878039543e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.00615454139187932\n",
      "Gradient for encoder.encoder.1.bias: 0.00445170933380723\n",
      "Gradient for encoder.encoder.3.weight: 0.12815317511558533\n",
      "Gradient for encoder.encoder.3.bias: 6.121502194034179e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.013774937018752098\n",
      "Gradient for encoder.encoder.4.bias: 0.011012480594217777\n",
      "Gradient for encoder.mean.weight: 0.1685602217912674\n",
      "Gradient for encoder.mean.bias: 0.006882942747324705\n",
      "Gradient for encoder.log_var.weight: 0.0896712988615036\n",
      "Gradient for encoder.log_var.bias: 0.004517285618931055\n",
      "Gradient for decoder.decoder.0.weight: 0.011844160966575146\n",
      "Gradient for decoder.decoder.0.bias: 9.972176556738432e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0006202663062140346\n",
      "Gradient for decoder.decoder.1.bias: 0.0004710555949714035\n",
      "Gradient for decoder.decoder.3.weight: 0.010377008467912674\n",
      "Gradient for decoder.decoder.3.bias: 8.848692611973519e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0004822689516004175\n",
      "Gradient for decoder.decoder.4.bias: 0.0005550520145334303\n",
      "Gradient for decoder.decoder.6.weight: 0.0007675195229239762\n",
      "Gradient for decoder.decoder.6.bias: 4.3290969188092276e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.056536994874477386\n",
      "Gradient for encoder.encoder.0.bias: 9.447891080593962e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.008189919404685497\n",
      "Gradient for encoder.encoder.1.bias: 0.006139584816992283\n",
      "Gradient for encoder.encoder.3.weight: 0.1870862990617752\n",
      "Gradient for encoder.encoder.3.bias: 1.1288328050085283e-09\n",
      "Gradient for encoder.encoder.4.weight: 0.028796860948204994\n",
      "Gradient for encoder.encoder.4.bias: 0.022285720333456993\n",
      "Gradient for encoder.mean.weight: 0.33190852403640747\n",
      "Gradient for encoder.mean.bias: 0.011418653652071953\n",
      "Gradient for encoder.log_var.weight: 0.2180020958185196\n",
      "Gradient for encoder.log_var.bias: 0.006716873496770859\n",
      "Gradient for decoder.decoder.0.weight: 0.01596345379948616\n",
      "Gradient for decoder.decoder.0.bias: 1.300168445128591e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.000823097478132695\n",
      "Gradient for decoder.decoder.1.bias: 0.0006105481297709048\n",
      "Gradient for decoder.decoder.3.weight: 0.013381622731685638\n",
      "Gradient for decoder.decoder.3.bias: 1.0601673705590287e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0005693858838640153\n",
      "Gradient for decoder.decoder.4.bias: 0.0006360833649523556\n",
      "Gradient for decoder.decoder.6.weight: 0.0008766649989411235\n",
      "Gradient for decoder.decoder.6.bias: 6.104832573328167e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.04292577505111694\n",
      "Gradient for encoder.encoder.0.bias: 7.130829954293816e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.006717424839735031\n",
      "Gradient for encoder.encoder.1.bias: 0.005082927644252777\n",
      "Gradient for encoder.encoder.3.weight: 0.13893985748291016\n",
      "Gradient for encoder.encoder.3.bias: 5.947975445508291e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.013620073907077312\n",
      "Gradient for encoder.encoder.4.bias: 0.010674575343728065\n",
      "Gradient for encoder.mean.weight: 0.17826054990291595\n",
      "Gradient for encoder.mean.bias: 0.007256638258695602\n",
      "Gradient for encoder.log_var.weight: 0.08983249962329865\n",
      "Gradient for encoder.log_var.bias: 0.0044196369126439095\n",
      "Gradient for decoder.decoder.0.weight: 0.01370891835540533\n",
      "Gradient for decoder.decoder.0.bias: 1.1435500463230497e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0007194359204731882\n",
      "Gradient for decoder.decoder.1.bias: 0.0005781696527265012\n",
      "Gradient for decoder.decoder.3.weight: 0.011718605645000935\n",
      "Gradient for decoder.decoder.3.bias: 9.216293700431422e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0004832141275983304\n",
      "Gradient for decoder.decoder.4.bias: 0.00045529697672463953\n",
      "Gradient for decoder.decoder.6.weight: 0.000796297681517899\n",
      "Gradient for decoder.decoder.6.bias: 4.146213905187324e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training VAE Epoch:  92%|█████████▏| 73/79 [00:01<00:00, 75.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient for encoder.encoder.0.weight: 0.06133655831217766\n",
      "Gradient for encoder.encoder.0.bias: 7.872294482957898e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.006608010269701481\n",
      "Gradient for encoder.encoder.1.bias: 0.004894749261438847\n",
      "Gradient for encoder.encoder.3.weight: 0.15200747549533844\n",
      "Gradient for encoder.encoder.3.bias: 6.813420383444679e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0133559824898839\n",
      "Gradient for encoder.encoder.4.bias: 0.010901063680648804\n",
      "Gradient for encoder.mean.weight: 0.18765096366405487\n",
      "Gradient for encoder.mean.bias: 0.007231172639876604\n",
      "Gradient for encoder.log_var.weight: 0.09746089577674866\n",
      "Gradient for encoder.log_var.bias: 0.004120273981243372\n",
      "Gradient for decoder.decoder.0.weight: 0.015523798763751984\n",
      "Gradient for decoder.decoder.0.bias: 1.3469933501930598e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0007841902552172542\n",
      "Gradient for decoder.decoder.1.bias: 0.0005756058963015676\n",
      "Gradient for decoder.decoder.3.weight: 0.013211202807724476\n",
      "Gradient for decoder.decoder.3.bias: 1.19355858529957e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0005407927092164755\n",
      "Gradient for decoder.decoder.4.bias: 0.0005970041383989155\n",
      "Gradient for decoder.decoder.6.weight: 0.0008056070073507726\n",
      "Gradient for decoder.decoder.6.bias: 4.9474212573841214e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.044879183173179626\n",
      "Gradient for encoder.encoder.0.bias: 6.143582170770046e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0052541824989020824\n",
      "Gradient for encoder.encoder.1.bias: 0.004228346515446901\n",
      "Gradient for encoder.encoder.3.weight: 0.11294613033533096\n",
      "Gradient for encoder.encoder.3.bias: 8.155359720873889e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0124354287981987\n",
      "Gradient for encoder.encoder.4.bias: 0.015339864417910576\n",
      "Gradient for encoder.mean.weight: 0.14640147984027863\n",
      "Gradient for encoder.mean.bias: 0.010516198351979256\n",
      "Gradient for encoder.log_var.weight: 0.10001104325056076\n",
      "Gradient for encoder.log_var.bias: 0.007151495199650526\n",
      "Gradient for decoder.decoder.0.weight: 0.014617339707911015\n",
      "Gradient for decoder.decoder.0.bias: 1.1699728685865551e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.00075255346018821\n",
      "Gradient for decoder.decoder.1.bias: 0.0005444046691991389\n",
      "Gradient for decoder.decoder.3.weight: 0.012314828112721443\n",
      "Gradient for decoder.decoder.3.bias: 1.1017380757705197e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0006384673179127276\n",
      "Gradient for decoder.decoder.4.bias: 0.0007474767626263201\n",
      "Gradient for decoder.decoder.6.weight: 0.0008378246566280723\n",
      "Gradient for decoder.decoder.6.bias: 5.895741924177855e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.038699306547641754\n",
      "Gradient for encoder.encoder.0.bias: 5.950848841473899e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.004152603447437286\n",
      "Gradient for encoder.encoder.1.bias: 0.00328738521784544\n",
      "Gradient for encoder.encoder.3.weight: 0.08947300910949707\n",
      "Gradient for encoder.encoder.3.bias: 6.110517092317025e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.009201256558299065\n",
      "Gradient for encoder.encoder.4.bias: 0.010348721407353878\n",
      "Gradient for encoder.mean.weight: 0.12617337703704834\n",
      "Gradient for encoder.mean.bias: 0.00848929863423109\n",
      "Gradient for encoder.log_var.weight: 0.0744389221072197\n",
      "Gradient for encoder.log_var.bias: 0.0054121920838952065\n",
      "Gradient for decoder.decoder.0.weight: 0.015053129754960537\n",
      "Gradient for decoder.decoder.0.bias: 1.1959946921713538e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0007972693420015275\n",
      "Gradient for decoder.decoder.1.bias: 0.0005823252140544355\n",
      "Gradient for decoder.decoder.3.weight: 0.013082949444651604\n",
      "Gradient for decoder.decoder.3.bias: 9.496859548763226e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0005012970650568604\n",
      "Gradient for decoder.decoder.4.bias: 0.00044578706729225814\n",
      "Gradient for decoder.decoder.6.weight: 0.0008074099896475673\n",
      "Gradient for decoder.decoder.6.bias: 4.152327528572641e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.03309386968612671\n",
      "Gradient for encoder.encoder.0.bias: 4.5931099201812486e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.00450003519654274\n",
      "Gradient for encoder.encoder.1.bias: 0.003341782372444868\n",
      "Gradient for encoder.encoder.3.weight: 0.09854747354984283\n",
      "Gradient for encoder.encoder.3.bias: 5.875335773453116e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.01339497696608305\n",
      "Gradient for encoder.encoder.4.bias: 0.011569906026124954\n",
      "Gradient for encoder.mean.weight: 0.16641373932361603\n",
      "Gradient for encoder.mean.bias: 0.008247451856732368\n",
      "Gradient for encoder.log_var.weight: 0.09612453728914261\n",
      "Gradient for encoder.log_var.bias: 0.0045577953569591045\n",
      "Gradient for decoder.decoder.0.weight: 0.014391851611435413\n",
      "Gradient for decoder.decoder.0.bias: 1.228861873370235e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0008309538825415075\n",
      "Gradient for decoder.decoder.1.bias: 0.0005417104111984372\n",
      "Gradient for decoder.decoder.3.weight: 0.01279723085463047\n",
      "Gradient for decoder.decoder.3.bias: 1.0419918400339512e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0004817999142687768\n",
      "Gradient for decoder.decoder.4.bias: 0.00041702226735651493\n",
      "Gradient for decoder.decoder.6.weight: 0.0008616242557764053\n",
      "Gradient for decoder.decoder.6.bias: 4.5821481762686744e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.042011603713035583\n",
      "Gradient for encoder.encoder.0.bias: 7.15598344469548e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.006360485218465328\n",
      "Gradient for encoder.encoder.1.bias: 0.0045645288191735744\n",
      "Gradient for encoder.encoder.3.weight: 0.13193626701831818\n",
      "Gradient for encoder.encoder.3.bias: 6.724849010986134e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.015896765515208244\n",
      "Gradient for encoder.encoder.4.bias: 0.012084401212632656\n",
      "Gradient for encoder.mean.weight: 0.1971016824245453\n",
      "Gradient for encoder.mean.bias: 0.006802573334425688\n",
      "Gradient for encoder.log_var.weight: 0.12059102207422256\n",
      "Gradient for encoder.log_var.bias: 0.004455565009266138\n",
      "Gradient for decoder.decoder.0.weight: 0.0131699088960886\n",
      "Gradient for decoder.decoder.0.bias: 1.0772030489825113e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0006684995023533702\n",
      "Gradient for decoder.decoder.1.bias: 0.0004979018121957779\n",
      "Gradient for decoder.decoder.3.weight: 0.01103425957262516\n",
      "Gradient for decoder.decoder.3.bias: 8.909545323732004e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0004046414396725595\n",
      "Gradient for decoder.decoder.4.bias: 0.0003422107838559896\n",
      "Gradient for decoder.decoder.6.weight: 0.0007923274533823133\n",
      "Gradient for decoder.decoder.6.bias: 3.8992275221971795e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.035734422504901886\n",
      "Gradient for encoder.encoder.0.bias: 4.449158749753046e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.004931303206831217\n",
      "Gradient for encoder.encoder.1.bias: 0.003531605703756213\n",
      "Gradient for encoder.encoder.3.weight: 0.10401555895805359\n",
      "Gradient for encoder.encoder.3.bias: 5.168795946808302e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.010074363090097904\n",
      "Gradient for encoder.encoder.4.bias: 0.01010867953300476\n",
      "Gradient for encoder.mean.weight: 0.12838275730609894\n",
      "Gradient for encoder.mean.bias: 0.006707245018333197\n",
      "Gradient for encoder.log_var.weight: 0.07773295789957047\n",
      "Gradient for encoder.log_var.bias: 0.0037205738481134176\n",
      "Gradient for decoder.decoder.0.weight: 0.016866279765963554\n",
      "Gradient for decoder.decoder.0.bias: 1.3442343071989882e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0008534248336218297\n",
      "Gradient for decoder.decoder.1.bias: 0.0006445996114052832\n",
      "Gradient for decoder.decoder.3.weight: 0.014159345999360085\n",
      "Gradient for decoder.decoder.3.bias: 1.1112759323861354e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0005664402269758284\n",
      "Gradient for decoder.decoder.4.bias: 0.000542474735993892\n",
      "Gradient for decoder.decoder.6.weight: 0.0008049445459619164\n",
      "Gradient for decoder.decoder.6.bias: 4.022532812086865e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.04334566369652748\n",
      "Gradient for encoder.encoder.0.bias: 7.774808574723124e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.006278554443269968\n",
      "Gradient for encoder.encoder.1.bias: 0.004709341563284397\n",
      "Gradient for encoder.encoder.3.weight: 0.13341033458709717\n",
      "Gradient for encoder.encoder.3.bias: 7.020660164336334e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.016046185046434402\n",
      "Gradient for encoder.encoder.4.bias: 0.014101455919444561\n",
      "Gradient for encoder.mean.weight: 0.19478873908519745\n",
      "Gradient for encoder.mean.bias: 0.009051205590367317\n",
      "Gradient for encoder.log_var.weight: 0.12525005638599396\n",
      "Gradient for encoder.log_var.bias: 0.006357652600854635\n",
      "Gradient for decoder.decoder.0.weight: 0.012237954884767532\n",
      "Gradient for decoder.decoder.0.bias: 1.1611612366069224e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0006782000418752432\n",
      "Gradient for decoder.decoder.1.bias: 0.0004974090843461454\n",
      "Gradient for decoder.decoder.3.weight: 0.010641212575137615\n",
      "Gradient for decoder.decoder.3.bias: 9.734415357121051e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0004836524894926697\n",
      "Gradient for decoder.decoder.4.bias: 0.000493131170514971\n",
      "Gradient for decoder.decoder.6.weight: 0.0008187316707335413\n",
      "Gradient for decoder.decoder.6.bias: 5.305717058945447e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.04251771792769432\n",
      "Gradient for encoder.encoder.0.bias: 7.040458493978718e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.005121268332004547\n",
      "Gradient for encoder.encoder.1.bias: 0.004061817191541195\n",
      "Gradient for encoder.encoder.3.weight: 0.1125880628824234\n",
      "Gradient for encoder.encoder.3.bias: 7.344196362168987e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.014667823910713196\n",
      "Gradient for encoder.encoder.4.bias: 0.012018615379929543\n",
      "Gradient for encoder.mean.weight: 0.1691606044769287\n",
      "Gradient for encoder.mean.bias: 0.007056116126477718\n",
      "Gradient for encoder.log_var.weight: 0.12170065939426422\n",
      "Gradient for encoder.log_var.bias: 0.0040217009373009205\n",
      "Gradient for decoder.decoder.0.weight: 0.011425587348639965\n",
      "Gradient for decoder.decoder.0.bias: 1.1042895764479255e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0005802037194371223\n",
      "Gradient for decoder.decoder.1.bias: 0.0004537868080660701\n",
      "Gradient for decoder.decoder.3.weight: 0.009873013943433762\n",
      "Gradient for decoder.decoder.3.bias: 8.653860961160831e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00039415861829183996\n",
      "Gradient for decoder.decoder.4.bias: 0.0003543616912793368\n",
      "Gradient for decoder.decoder.6.weight: 0.0008098541293293238\n",
      "Gradient for decoder.decoder.6.bias: 5.5019056162564084e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.04450393095612526\n",
      "Gradient for encoder.encoder.0.bias: 6.222589110649324e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.004486182704567909\n",
      "Gradient for encoder.encoder.1.bias: 0.0035008906852453947\n",
      "Gradient for encoder.encoder.3.weight: 0.10453524440526962\n",
      "Gradient for encoder.encoder.3.bias: 5.696247362685369e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.01251097023487091\n",
      "Gradient for encoder.encoder.4.bias: 0.011171653866767883\n",
      "Gradient for encoder.mean.weight: 0.14578518271446228\n",
      "Gradient for encoder.mean.bias: 0.007174711674451828\n",
      "Gradient for encoder.log_var.weight: 0.10694057494401932\n",
      "Gradient for encoder.log_var.bias: 0.003844078630208969\n",
      "Gradient for decoder.decoder.0.weight: 0.013482669368386269\n",
      "Gradient for decoder.decoder.0.bias: 1.2218479006342875e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0007340232259593904\n",
      "Gradient for decoder.decoder.1.bias: 0.000489068275783211\n",
      "Gradient for decoder.decoder.3.weight: 0.011789347976446152\n",
      "Gradient for decoder.decoder.3.bias: 9.77062319940103e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0005528131732717156\n",
      "Gradient for decoder.decoder.4.bias: 0.0006528602680191398\n",
      "Gradient for decoder.decoder.6.weight: 0.0008512596832588315\n",
      "Gradient for decoder.decoder.6.bias: 6.116920849308372e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.03923414275050163\n",
      "Gradient for encoder.encoder.0.bias: 7.129979939790587e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0035265833139419556\n",
      "Gradient for encoder.encoder.1.bias: 0.002605453832075\n",
      "Gradient for encoder.encoder.3.weight: 0.08102971315383911\n",
      "Gradient for encoder.encoder.3.bias: 5.275467285237312e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.009444422088563442\n",
      "Gradient for encoder.encoder.4.bias: 0.00782183837145567\n",
      "Gradient for encoder.mean.weight: 0.12352871149778366\n",
      "Gradient for encoder.mean.bias: 0.006674057338386774\n",
      "Gradient for encoder.log_var.weight: 0.06471420079469681\n",
      "Gradient for encoder.log_var.bias: 0.003674011444672942\n",
      "Gradient for decoder.decoder.0.weight: 0.011466489173471928\n",
      "Gradient for decoder.decoder.0.bias: 9.329916700329122e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005809044814668596\n",
      "Gradient for decoder.decoder.1.bias: 0.0004403357161208987\n",
      "Gradient for decoder.decoder.3.weight: 0.009747028350830078\n",
      "Gradient for decoder.decoder.3.bias: 7.842078375563943e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00037899502785876393\n",
      "Gradient for decoder.decoder.4.bias: 0.00033845496363937855\n",
      "Gradient for decoder.decoder.6.weight: 0.0007736472762189806\n",
      "Gradient for decoder.decoder.6.bias: 4.185445141047239e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.05514311417937279\n",
      "Gradient for encoder.encoder.0.bias: 8.165012416183615e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.006408873479813337\n",
      "Gradient for encoder.encoder.1.bias: 0.004949319642037153\n",
      "Gradient for encoder.encoder.3.weight: 0.14104336500167847\n",
      "Gradient for encoder.encoder.3.bias: 7.718741201756529e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.014452197588980198\n",
      "Gradient for encoder.encoder.4.bias: 0.017013922333717346\n",
      "Gradient for encoder.mean.weight: 0.18797147274017334\n",
      "Gradient for encoder.mean.bias: 0.011875755153596401\n",
      "Gradient for encoder.log_var.weight: 0.1245875209569931\n",
      "Gradient for encoder.log_var.bias: 0.00885454285889864\n",
      "Gradient for decoder.decoder.0.weight: 0.014265010133385658\n",
      "Gradient for decoder.decoder.0.bias: 1.1133697436216394e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0007477824692614377\n",
      "Gradient for decoder.decoder.1.bias: 0.0005335055757313967\n",
      "Gradient for decoder.decoder.3.weight: 0.011975592002272606\n",
      "Gradient for decoder.decoder.3.bias: 9.554518287657743e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0004777239519171417\n",
      "Gradient for decoder.decoder.4.bias: 0.0004622800915967673\n",
      "Gradient for decoder.decoder.6.weight: 0.0007911549182608724\n",
      "Gradient for decoder.decoder.6.bias: 3.9392474718624726e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.055505577474832535\n",
      "Gradient for encoder.encoder.0.bias: 8.224726455452469e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.007354611996561289\n",
      "Gradient for encoder.encoder.1.bias: 0.005064868368208408\n",
      "Gradient for encoder.encoder.3.weight: 0.1803366243839264\n",
      "Gradient for encoder.encoder.3.bias: 8.041343702025472e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.024569164961576462\n",
      "Gradient for encoder.encoder.4.bias: 0.0162593312561512\n",
      "Gradient for encoder.mean.weight: 0.300343781709671\n",
      "Gradient for encoder.mean.bias: 0.008285189978778362\n",
      "Gradient for encoder.log_var.weight: 0.1672324240207672\n",
      "Gradient for encoder.log_var.bias: 0.00536334328353405\n",
      "Gradient for decoder.decoder.0.weight: 0.01597585342824459\n",
      "Gradient for decoder.decoder.0.bias: 1.3945612720167588e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0008108275360427797\n",
      "Gradient for decoder.decoder.1.bias: 0.0006342793349176645\n",
      "Gradient for decoder.decoder.3.weight: 0.013857937417924404\n",
      "Gradient for decoder.decoder.3.bias: 1.2066624088813427e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.000526430259924382\n",
      "Gradient for decoder.decoder.4.bias: 0.00043478398583829403\n",
      "Gradient for decoder.decoder.6.weight: 0.0008377927588298917\n",
      "Gradient for decoder.decoder.6.bias: 4.317172715673223e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.044035885483026505\n",
      "Gradient for encoder.encoder.0.bias: 5.581346496086326e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.005982970353215933\n",
      "Gradient for encoder.encoder.1.bias: 0.00454378966242075\n",
      "Gradient for encoder.encoder.3.weight: 0.14189985394477844\n",
      "Gradient for encoder.encoder.3.bias: 6.200049917914896e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.01844768226146698\n",
      "Gradient for encoder.encoder.4.bias: 0.011809296905994415\n",
      "Gradient for encoder.mean.weight: 0.2374017983675003\n",
      "Gradient for encoder.mean.bias: 0.006931655574589968\n",
      "Gradient for encoder.log_var.weight: 0.13271449506282806\n",
      "Gradient for encoder.log_var.bias: 0.003714680438861251\n",
      "Gradient for decoder.decoder.0.weight: 0.017533201724290848\n",
      "Gradient for decoder.decoder.0.bias: 1.4504948631088865e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0008865747367963195\n",
      "Gradient for decoder.decoder.1.bias: 0.0006916059064678848\n",
      "Gradient for decoder.decoder.3.weight: 0.014688994735479355\n",
      "Gradient for decoder.decoder.3.bias: 1.0963284446940946e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0006184297380968928\n",
      "Gradient for decoder.decoder.4.bias: 0.0006291571771726012\n",
      "Gradient for decoder.decoder.6.weight: 0.0008469457388855517\n",
      "Gradient for decoder.decoder.6.bias: 4.179758980171755e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.17342889308929443\n",
      "Gradient for encoder.encoder.0.bias: 2.6878263503782307e-10\n",
      "Gradient for encoder.encoder.1.weight: 0.02068961225450039\n",
      "Gradient for encoder.encoder.1.bias: 0.015441803261637688\n",
      "Gradient for encoder.encoder.3.weight: 0.46799468994140625\n",
      "Gradient for encoder.encoder.3.bias: 2.649307218050012e-09\n",
      "Gradient for encoder.encoder.4.weight: 0.0339384600520134\n",
      "Gradient for encoder.encoder.4.bias: 0.031961195170879364\n",
      "Gradient for encoder.mean.weight: 0.4148080050945282\n",
      "Gradient for encoder.mean.bias: 0.01710621453821659\n",
      "Gradient for encoder.log_var.weight: 0.24790367484092712\n",
      "Gradient for encoder.log_var.bias: 0.01129884459078312\n",
      "Gradient for decoder.decoder.0.weight: 0.05038628727197647\n",
      "Gradient for decoder.decoder.0.bias: 2.869456339205101e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.002301058964803815\n",
      "Gradient for decoder.decoder.1.bias: 0.0018167522503063083\n",
      "Gradient for decoder.decoder.3.weight: 0.04235585778951645\n",
      "Gradient for decoder.decoder.3.bias: 2.905674867381691e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0014307255623862147\n",
      "Gradient for decoder.decoder.4.bias: 0.0013221753761172295\n",
      "Gradient for decoder.decoder.6.weight: 0.0019536965992301702\n",
      "Gradient for decoder.decoder.6.bias: 9.738847438711673e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/3, Train Loss: 0.0952, Val Loss: 0.4324\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training VAE Epoch:   0%|          | 0/79 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient for encoder.encoder.0.weight: 0.046857260167598724\n",
      "Gradient for encoder.encoder.0.bias: 7.377393140828303e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.005698286462575197\n",
      "Gradient for encoder.encoder.1.bias: 0.0043030548840761185\n",
      "Gradient for encoder.encoder.3.weight: 0.11992698162794113\n",
      "Gradient for encoder.encoder.3.bias: 6.676357244828068e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.010874809697270393\n",
      "Gradient for encoder.encoder.4.bias: 0.009728480130434036\n",
      "Gradient for encoder.mean.weight: 0.1371963918209076\n",
      "Gradient for encoder.mean.bias: 0.007269422523677349\n",
      "Gradient for encoder.log_var.weight: 0.07801894098520279\n",
      "Gradient for encoder.log_var.bias: 0.004342372063547373\n",
      "Gradient for decoder.decoder.0.weight: 0.01238826010376215\n",
      "Gradient for decoder.decoder.0.bias: 1.0479276474351096e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0006126495427452028\n",
      "Gradient for decoder.decoder.1.bias: 0.00045988871715962887\n",
      "Gradient for decoder.decoder.3.weight: 0.010401156730949879\n",
      "Gradient for decoder.decoder.3.bias: 7.373719690395575e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0003816274693235755\n",
      "Gradient for decoder.decoder.4.bias: 0.0003329213068354875\n",
      "Gradient for decoder.decoder.6.weight: 0.0007785272900946438\n",
      "Gradient for decoder.decoder.6.bias: 4.135940253036097e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training VAE Epoch:  11%|█▏        | 9/79 [00:00<00:01, 35.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient for encoder.encoder.0.weight: 0.0434219092130661\n",
      "Gradient for encoder.encoder.0.bias: 6.550762016166445e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.006300824694335461\n",
      "Gradient for encoder.encoder.1.bias: 0.00508825434371829\n",
      "Gradient for encoder.encoder.3.weight: 0.13612942397594452\n",
      "Gradient for encoder.encoder.3.bias: 6.743324232338921e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.013480287976562977\n",
      "Gradient for encoder.encoder.4.bias: 0.011724256910383701\n",
      "Gradient for encoder.mean.weight: 0.16829858720302582\n",
      "Gradient for encoder.mean.bias: 0.007989956066012383\n",
      "Gradient for encoder.log_var.weight: 0.10524793714284897\n",
      "Gradient for encoder.log_var.bias: 0.004481806419789791\n",
      "Gradient for decoder.decoder.0.weight: 0.014805072918534279\n",
      "Gradient for decoder.decoder.0.bias: 1.115043612998079e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0007394534768536687\n",
      "Gradient for decoder.decoder.1.bias: 0.000534477352630347\n",
      "Gradient for decoder.decoder.3.weight: 0.01260365266352892\n",
      "Gradient for decoder.decoder.3.bias: 8.591566347249113e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0004053067823406309\n",
      "Gradient for decoder.decoder.4.bias: 0.00037198173231445253\n",
      "Gradient for decoder.decoder.6.weight: 0.0007420143811032176\n",
      "Gradient for decoder.decoder.6.bias: 3.667127384687774e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.06253890693187714\n",
      "Gradient for encoder.encoder.0.bias: 8.938406959035916e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.008866610005497932\n",
      "Gradient for encoder.encoder.1.bias: 0.005201143212616444\n",
      "Gradient for encoder.encoder.3.weight: 0.1901831328868866\n",
      "Gradient for encoder.encoder.3.bias: 6.752068903992381e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.014062920585274696\n",
      "Gradient for encoder.encoder.4.bias: 0.015869518741965294\n",
      "Gradient for encoder.mean.weight: 0.18864646553993225\n",
      "Gradient for encoder.mean.bias: 0.011659223586320877\n",
      "Gradient for encoder.log_var.weight: 0.119386225938797\n",
      "Gradient for encoder.log_var.bias: 0.007980046793818474\n",
      "Gradient for decoder.decoder.0.weight: 0.014402385801076889\n",
      "Gradient for decoder.decoder.0.bias: 1.108371450175838e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0007319513824768364\n",
      "Gradient for decoder.decoder.1.bias: 0.0005655818968079984\n",
      "Gradient for decoder.decoder.3.weight: 0.012279110960662365\n",
      "Gradient for decoder.decoder.3.bias: 9.532234723774735e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0005702681373804808\n",
      "Gradient for decoder.decoder.4.bias: 0.0006265696720220149\n",
      "Gradient for decoder.decoder.6.weight: 0.0008019387605600059\n",
      "Gradient for decoder.decoder.6.bias: 5.587605483015068e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.05596581846475601\n",
      "Gradient for encoder.encoder.0.bias: 7.797792273001036e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.007435765583068132\n",
      "Gradient for encoder.encoder.1.bias: 0.005438657011836767\n",
      "Gradient for encoder.encoder.3.weight: 0.1631058305501938\n",
      "Gradient for encoder.encoder.3.bias: 6.636184379793519e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.013421110808849335\n",
      "Gradient for encoder.encoder.4.bias: 0.010665487498044968\n",
      "Gradient for encoder.mean.weight: 0.17726658284664154\n",
      "Gradient for encoder.mean.bias: 0.005703751463443041\n",
      "Gradient for encoder.log_var.weight: 0.09174211323261261\n",
      "Gradient for encoder.log_var.bias: 0.0035737401340156794\n",
      "Gradient for decoder.decoder.0.weight: 0.014748874120414257\n",
      "Gradient for decoder.decoder.0.bias: 1.1361980106761038e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0008081869455054402\n",
      "Gradient for decoder.decoder.1.bias: 0.0005623943288810551\n",
      "Gradient for decoder.decoder.3.weight: 0.012797442264854908\n",
      "Gradient for decoder.decoder.3.bias: 1.029909907357407e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0005260289181023836\n",
      "Gradient for decoder.decoder.4.bias: 0.0004866750387009233\n",
      "Gradient for decoder.decoder.6.weight: 0.0008480777614749968\n",
      "Gradient for decoder.decoder.6.bias: 4.878277832176536e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.06252958625555038\n",
      "Gradient for encoder.encoder.0.bias: 8.108191201783299e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.007632564753293991\n",
      "Gradient for encoder.encoder.1.bias: 0.005534178111702204\n",
      "Gradient for encoder.encoder.3.weight: 0.16554081439971924\n",
      "Gradient for encoder.encoder.3.bias: 7.727141149160843e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.017428716644644737\n",
      "Gradient for encoder.encoder.4.bias: 0.015628211200237274\n",
      "Gradient for encoder.mean.weight: 0.2239343374967575\n",
      "Gradient for encoder.mean.bias: 0.00985763594508171\n",
      "Gradient for encoder.log_var.weight: 0.12165037542581558\n",
      "Gradient for encoder.log_var.bias: 0.006904606707394123\n",
      "Gradient for decoder.decoder.0.weight: 0.012845243327319622\n",
      "Gradient for decoder.decoder.0.bias: 1.0618703832898646e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0007553063915111125\n",
      "Gradient for decoder.decoder.1.bias: 0.00048356832121498883\n",
      "Gradient for decoder.decoder.3.weight: 0.011592534370720387\n",
      "Gradient for decoder.decoder.3.bias: 8.583890542812611e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0004908903501927853\n",
      "Gradient for decoder.decoder.4.bias: 0.0004973367904312909\n",
      "Gradient for decoder.decoder.6.weight: 0.0007960714865475893\n",
      "Gradient for decoder.decoder.6.bias: 4.3216394260525703e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.048395056277513504\n",
      "Gradient for encoder.encoder.0.bias: 7.171783306114676e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.006240176502615213\n",
      "Gradient for encoder.encoder.1.bias: 0.004892858676612377\n",
      "Gradient for encoder.encoder.3.weight: 0.1379508227109909\n",
      "Gradient for encoder.encoder.3.bias: 7.409898250543279e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.017155636101961136\n",
      "Gradient for encoder.encoder.4.bias: 0.01525606494396925\n",
      "Gradient for encoder.mean.weight: 0.2153426855802536\n",
      "Gradient for encoder.mean.bias: 0.008580464869737625\n",
      "Gradient for encoder.log_var.weight: 0.12796391546726227\n",
      "Gradient for encoder.log_var.bias: 0.006281806156039238\n",
      "Gradient for decoder.decoder.0.weight: 0.015580853447318077\n",
      "Gradient for decoder.decoder.0.bias: 1.2113261782520368e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0008722146740183234\n",
      "Gradient for decoder.decoder.1.bias: 0.0005740930209867656\n",
      "Gradient for decoder.decoder.3.weight: 0.013860827311873436\n",
      "Gradient for decoder.decoder.3.bias: 9.733067130035522e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0005628935759887099\n",
      "Gradient for decoder.decoder.4.bias: 0.00045269570546224713\n",
      "Gradient for decoder.decoder.6.weight: 0.0008843063260428607\n",
      "Gradient for decoder.decoder.6.bias: 4.744133184431121e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.03663009777665138\n",
      "Gradient for encoder.encoder.0.bias: 5.281821160996181e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.005081498064100742\n",
      "Gradient for encoder.encoder.1.bias: 0.0036228708922863007\n",
      "Gradient for encoder.encoder.3.weight: 0.10457050800323486\n",
      "Gradient for encoder.encoder.3.bias: 5.969661986959807e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.01326785422861576\n",
      "Gradient for encoder.encoder.4.bias: 0.012219260446727276\n",
      "Gradient for encoder.mean.weight: 0.16710039973258972\n",
      "Gradient for encoder.mean.bias: 0.009195416234433651\n",
      "Gradient for encoder.log_var.weight: 0.0968465730547905\n",
      "Gradient for encoder.log_var.bias: 0.005066409707069397\n",
      "Gradient for decoder.decoder.0.weight: 0.013871341943740845\n",
      "Gradient for decoder.decoder.0.bias: 1.1271635708132166e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0007343835895881057\n",
      "Gradient for decoder.decoder.1.bias: 0.0005156802362762392\n",
      "Gradient for decoder.decoder.3.weight: 0.011861604638397694\n",
      "Gradient for decoder.decoder.3.bias: 9.317883270520966e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0004801373870577663\n",
      "Gradient for decoder.decoder.4.bias: 0.00045647574006579816\n",
      "Gradient for decoder.decoder.6.weight: 0.0007546338601969182\n",
      "Gradient for decoder.decoder.6.bias: 3.979239409090951e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.03857969492673874\n",
      "Gradient for encoder.encoder.0.bias: 4.818605583989388e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.004427223466336727\n",
      "Gradient for encoder.encoder.1.bias: 0.0030198816675692797\n",
      "Gradient for encoder.encoder.3.weight: 0.08964724093675613\n",
      "Gradient for encoder.encoder.3.bias: 4.974410328095757e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.008686279878020287\n",
      "Gradient for encoder.encoder.4.bias: 0.007739757187664509\n",
      "Gradient for encoder.mean.weight: 0.11533283442258835\n",
      "Gradient for encoder.mean.bias: 0.00526765501126647\n",
      "Gradient for encoder.log_var.weight: 0.06208038330078125\n",
      "Gradient for encoder.log_var.bias: 0.002965067746117711\n",
      "Gradient for decoder.decoder.0.weight: 0.016263315454125404\n",
      "Gradient for decoder.decoder.0.bias: 1.4073334164699247e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0008257393492385745\n",
      "Gradient for decoder.decoder.1.bias: 0.000635030388366431\n",
      "Gradient for decoder.decoder.3.weight: 0.013870423659682274\n",
      "Gradient for decoder.decoder.3.bias: 1.0053086141326162e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.000584684603381902\n",
      "Gradient for decoder.decoder.4.bias: 0.000536486622877419\n",
      "Gradient for decoder.decoder.6.weight: 0.000817116058897227\n",
      "Gradient for decoder.decoder.6.bias: 4.285731483832933e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.039674706757068634\n",
      "Gradient for encoder.encoder.0.bias: 6.524218665315829e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.005887334235012531\n",
      "Gradient for encoder.encoder.1.bias: 0.004067530855536461\n",
      "Gradient for encoder.encoder.3.weight: 0.12727168202400208\n",
      "Gradient for encoder.encoder.3.bias: 5.583249418350533e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.01014471985399723\n",
      "Gradient for encoder.encoder.4.bias: 0.00920495018362999\n",
      "Gradient for encoder.mean.weight: 0.1405813843011856\n",
      "Gradient for encoder.mean.bias: 0.00630867388099432\n",
      "Gradient for encoder.log_var.weight: 0.07360586524009705\n",
      "Gradient for encoder.log_var.bias: 0.003937162458896637\n",
      "Gradient for decoder.decoder.0.weight: 0.015212489292025566\n",
      "Gradient for decoder.decoder.0.bias: 1.2807477300924575e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0008102465653792024\n",
      "Gradient for decoder.decoder.1.bias: 0.0006057026912458241\n",
      "Gradient for decoder.decoder.3.weight: 0.01314566470682621\n",
      "Gradient for decoder.decoder.3.bias: 1.214311706743132e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0007524533430114388\n",
      "Gradient for decoder.decoder.4.bias: 0.0008325811359100044\n",
      "Gradient for decoder.decoder.6.weight: 0.0009849786292761564\n",
      "Gradient for decoder.decoder.6.bias: 7.242300489451736e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.058214880526065826\n",
      "Gradient for encoder.encoder.0.bias: 8.312640159546802e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.006150993052870035\n",
      "Gradient for encoder.encoder.1.bias: 0.00411499198526144\n",
      "Gradient for encoder.encoder.3.weight: 0.13334189355373383\n",
      "Gradient for encoder.encoder.3.bias: 6.770705662795251e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.011765729635953903\n",
      "Gradient for encoder.encoder.4.bias: 0.011597130447626114\n",
      "Gradient for encoder.mean.weight: 0.159058079123497\n",
      "Gradient for encoder.mean.bias: 0.008138703182339668\n",
      "Gradient for encoder.log_var.weight: 0.095330610871315\n",
      "Gradient for encoder.log_var.bias: 0.004268195480108261\n",
      "Gradient for decoder.decoder.0.weight: 0.010682888329029083\n",
      "Gradient for decoder.decoder.0.bias: 9.593094374427125e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005526837194338441\n",
      "Gradient for decoder.decoder.1.bias: 0.00042497317190282047\n",
      "Gradient for decoder.decoder.3.weight: 0.009280148893594742\n",
      "Gradient for decoder.decoder.3.bias: 8.637012632872754e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0005203221808187664\n",
      "Gradient for decoder.decoder.4.bias: 0.0006121108308434486\n",
      "Gradient for decoder.decoder.6.weight: 0.0008557773544453084\n",
      "Gradient for decoder.decoder.6.bias: 6.081868923502043e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.04107389226555824\n",
      "Gradient for encoder.encoder.0.bias: 5.504336569872592e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.004273439757525921\n",
      "Gradient for encoder.encoder.1.bias: 0.0029550164472311735\n",
      "Gradient for encoder.encoder.3.weight: 0.0923430472612381\n",
      "Gradient for encoder.encoder.3.bias: 4.912471540663432e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.008075900375843048\n",
      "Gradient for encoder.encoder.4.bias: 0.00768190436065197\n",
      "Gradient for encoder.mean.weight: 0.11576967686414719\n",
      "Gradient for encoder.mean.bias: 0.0056783463805913925\n",
      "Gradient for encoder.log_var.weight: 0.06442424654960632\n",
      "Gradient for encoder.log_var.bias: 0.0037563962396234274\n",
      "Gradient for decoder.decoder.0.weight: 0.014582175761461258\n",
      "Gradient for decoder.decoder.0.bias: 1.2288521589187695e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0008493636269122362\n",
      "Gradient for decoder.decoder.1.bias: 0.0005775121971964836\n",
      "Gradient for decoder.decoder.3.weight: 0.013551060110330582\n",
      "Gradient for decoder.decoder.3.bias: 9.385302951470109e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0005117384716868401\n",
      "Gradient for decoder.decoder.4.bias: 0.00048299625632353127\n",
      "Gradient for decoder.decoder.6.weight: 0.0008096072124317288\n",
      "Gradient for decoder.decoder.6.bias: 4.306581104174256e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.05823175609111786\n",
      "Gradient for encoder.encoder.0.bias: 1.1163066304664682e-10\n",
      "Gradient for encoder.encoder.1.weight: 0.008076147176325321\n",
      "Gradient for encoder.encoder.1.bias: 0.0056763337925076485\n",
      "Gradient for encoder.encoder.3.weight: 0.16958588361740112\n",
      "Gradient for encoder.encoder.3.bias: 8.88981055435778e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.020184297114610672\n",
      "Gradient for encoder.encoder.4.bias: 0.017560016363859177\n",
      "Gradient for encoder.mean.weight: 0.24364987015724182\n",
      "Gradient for encoder.mean.bias: 0.009116060100495815\n",
      "Gradient for encoder.log_var.weight: 0.15722189843654633\n",
      "Gradient for encoder.log_var.bias: 0.005873641464859247\n",
      "Gradient for decoder.decoder.0.weight: 0.009864328429102898\n",
      "Gradient for decoder.decoder.0.bias: 8.55948645295257e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005363439559005201\n",
      "Gradient for decoder.decoder.1.bias: 0.0003850003413390368\n",
      "Gradient for decoder.decoder.3.weight: 0.008656597696244717\n",
      "Gradient for decoder.decoder.3.bias: 8.047631311347558e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0004569014417938888\n",
      "Gradient for decoder.decoder.4.bias: 0.000542994705028832\n",
      "Gradient for decoder.decoder.6.weight: 0.0007961343508213758\n",
      "Gradient for decoder.decoder.6.bias: 5.282231359160505e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.04087534919381142\n",
      "Gradient for encoder.encoder.0.bias: 6.914767369803343e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0053859492763876915\n",
      "Gradient for encoder.encoder.1.bias: 0.004167534410953522\n",
      "Gradient for encoder.encoder.3.weight: 0.12419583648443222\n",
      "Gradient for encoder.encoder.3.bias: 7.089288045492026e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.016899244859814644\n",
      "Gradient for encoder.encoder.4.bias: 0.01299764309078455\n",
      "Gradient for encoder.mean.weight: 0.20512276887893677\n",
      "Gradient for encoder.mean.bias: 0.008650912903249264\n",
      "Gradient for encoder.log_var.weight: 0.11329823732376099\n",
      "Gradient for encoder.log_var.bias: 0.005272701382637024\n",
      "Gradient for decoder.decoder.0.weight: 0.013482541777193546\n",
      "Gradient for decoder.decoder.0.bias: 1.0968428942881303e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0006945497589185834\n",
      "Gradient for decoder.decoder.1.bias: 0.000545537390280515\n",
      "Gradient for decoder.decoder.3.weight: 0.011765661649405956\n",
      "Gradient for decoder.decoder.3.bias: 8.76130279436893e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00043410673970356584\n",
      "Gradient for decoder.decoder.4.bias: 0.0003876124683301896\n",
      "Gradient for decoder.decoder.6.weight: 0.0007518082857131958\n",
      "Gradient for decoder.decoder.6.bias: 3.9654616557527333e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.03228291496634483\n",
      "Gradient for encoder.encoder.0.bias: 4.6641940310010455e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0038489087019115686\n",
      "Gradient for encoder.encoder.1.bias: 0.0029693911783397198\n",
      "Gradient for encoder.encoder.3.weight: 0.08303850144147873\n",
      "Gradient for encoder.encoder.3.bias: 4.6576276169219e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0075091710314154625\n",
      "Gradient for encoder.encoder.4.bias: 0.00933936145156622\n",
      "Gradient for encoder.mean.weight: 0.1039186641573906\n",
      "Gradient for encoder.mean.bias: 0.006907861679792404\n",
      "Gradient for encoder.log_var.weight: 0.06450941413640976\n",
      "Gradient for encoder.log_var.bias: 0.0048562693409621716\n",
      "Gradient for decoder.decoder.0.weight: 0.014629745855927467\n",
      "Gradient for decoder.decoder.0.bias: 1.3317290326053666e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0007530850707553327\n",
      "Gradient for decoder.decoder.1.bias: 0.000557959487196058\n",
      "Gradient for decoder.decoder.3.weight: 0.012800285592675209\n",
      "Gradient for decoder.decoder.3.bias: 8.968969317235675e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0004972135648131371\n",
      "Gradient for decoder.decoder.4.bias: 0.0004438998003024608\n",
      "Gradient for decoder.decoder.6.weight: 0.0008515018271282315\n",
      "Gradient for decoder.decoder.6.bias: 5.200246232561767e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.041000086814165115\n",
      "Gradient for encoder.encoder.0.bias: 6.346190239980842e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.005292991641908884\n",
      "Gradient for encoder.encoder.1.bias: 0.004108691122382879\n",
      "Gradient for encoder.encoder.3.weight: 0.11376035958528519\n",
      "Gradient for encoder.encoder.3.bias: 9.96602800285018e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.018408222123980522\n",
      "Gradient for encoder.encoder.4.bias: 0.017940828576683998\n",
      "Gradient for encoder.mean.weight: 0.22528335452079773\n",
      "Gradient for encoder.mean.bias: 0.010542756877839565\n",
      "Gradient for encoder.log_var.weight: 0.13752707839012146\n",
      "Gradient for encoder.log_var.bias: 0.007573001552373171\n",
      "Gradient for decoder.decoder.0.weight: 0.013796827755868435\n",
      "Gradient for decoder.decoder.0.bias: 1.1088506501888418e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0007675536908209324\n",
      "Gradient for decoder.decoder.1.bias: 0.0004900763742625713\n",
      "Gradient for decoder.decoder.3.weight: 0.011944127269089222\n",
      "Gradient for decoder.decoder.3.bias: 8.689475528012025e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00045233493437990546\n",
      "Gradient for decoder.decoder.4.bias: 0.0004021002387162298\n",
      "Gradient for decoder.decoder.6.weight: 0.0008199929725378752\n",
      "Gradient for decoder.decoder.6.bias: 4.986550266039558e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.03266558051109314\n",
      "Gradient for encoder.encoder.0.bias: 5.169639369362322e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0048072789795696735\n",
      "Gradient for encoder.encoder.1.bias: 0.003183581866323948\n",
      "Gradient for encoder.encoder.3.weight: 0.10737494379281998\n",
      "Gradient for encoder.encoder.3.bias: 5.141738701475163e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.013244755566120148\n",
      "Gradient for encoder.encoder.4.bias: 0.009547104127705097\n",
      "Gradient for encoder.mean.weight: 0.17040801048278809\n",
      "Gradient for encoder.mean.bias: 0.006991109345108271\n",
      "Gradient for encoder.log_var.weight: 0.10623404383659363\n",
      "Gradient for encoder.log_var.bias: 0.004978339187800884\n",
      "Gradient for decoder.decoder.0.weight: 0.015357254073023796\n",
      "Gradient for decoder.decoder.0.bias: 1.224514378783681e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0008338309708051383\n",
      "Gradient for decoder.decoder.1.bias: 0.0005628069629892707\n",
      "Gradient for decoder.decoder.3.weight: 0.013280699029564857\n",
      "Gradient for decoder.decoder.3.bias: 1.0256796106888899e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0005563279846683145\n",
      "Gradient for decoder.decoder.4.bias: 0.0006041271262802184\n",
      "Gradient for decoder.decoder.6.weight: 0.0007767668575979769\n",
      "Gradient for decoder.decoder.6.bias: 4.727040868601762e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.0874113142490387\n",
      "Gradient for encoder.encoder.0.bias: 1.277355027307081e-10\n",
      "Gradient for encoder.encoder.1.weight: 0.008753188885748386\n",
      "Gradient for encoder.encoder.1.bias: 0.006783114746212959\n",
      "Gradient for encoder.encoder.3.weight: 0.19894251227378845\n",
      "Gradient for encoder.encoder.3.bias: 9.732478156720958e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.017106056213378906\n",
      "Gradient for encoder.encoder.4.bias: 0.015701517462730408\n",
      "Gradient for encoder.mean.weight: 0.2297176867723465\n",
      "Gradient for encoder.mean.bias: 0.009067119099199772\n",
      "Gradient for encoder.log_var.weight: 0.14376428723335266\n",
      "Gradient for encoder.log_var.bias: 0.0060538300313055515\n",
      "Gradient for decoder.decoder.0.weight: 0.013413566164672375\n",
      "Gradient for decoder.decoder.0.bias: 1.2353142120336003e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0006915292469784617\n",
      "Gradient for decoder.decoder.1.bias: 0.00047993677435442805\n",
      "Gradient for decoder.decoder.3.weight: 0.01136208325624466\n",
      "Gradient for decoder.decoder.3.bias: 9.830829206247671e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00039865003782324493\n",
      "Gradient for decoder.decoder.4.bias: 0.0003590181877370924\n",
      "Gradient for decoder.decoder.6.weight: 0.0008169516804628074\n",
      "Gradient for decoder.decoder.6.bias: 4.776503556058742e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training VAE Epoch:  32%|███▏      | 25/79 [00:00<00:00, 60.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient for encoder.encoder.0.weight: 0.035911545157432556\n",
      "Gradient for encoder.encoder.0.bias: 5.013467072045863e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0043006339110434055\n",
      "Gradient for encoder.encoder.1.bias: 0.0027920822612941265\n",
      "Gradient for encoder.encoder.3.weight: 0.09197206795215607\n",
      "Gradient for encoder.encoder.3.bias: 5.384982459943899e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.009514877572655678\n",
      "Gradient for encoder.encoder.4.bias: 0.007935442961752415\n",
      "Gradient for encoder.mean.weight: 0.1251245141029358\n",
      "Gradient for encoder.mean.bias: 0.006355623248964548\n",
      "Gradient for encoder.log_var.weight: 0.06383849680423737\n",
      "Gradient for encoder.log_var.bias: 0.0029681255109608173\n",
      "Gradient for decoder.decoder.0.weight: 0.013579575344920158\n",
      "Gradient for decoder.decoder.0.bias: 1.2798416493264853e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0007294855313375592\n",
      "Gradient for decoder.decoder.1.bias: 0.0004801735340151936\n",
      "Gradient for decoder.decoder.3.weight: 0.01198398508131504\n",
      "Gradient for decoder.decoder.3.bias: 9.789776628243985e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00041193017386831343\n",
      "Gradient for decoder.decoder.4.bias: 0.00036679490585811436\n",
      "Gradient for decoder.decoder.6.weight: 0.0008021859102882445\n",
      "Gradient for decoder.decoder.6.bias: 4.800578244612552e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.03501879423856735\n",
      "Gradient for encoder.encoder.0.bias: 5.295778399139195e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.00427402276545763\n",
      "Gradient for encoder.encoder.1.bias: 0.003212518058717251\n",
      "Gradient for encoder.encoder.3.weight: 0.09278953075408936\n",
      "Gradient for encoder.encoder.3.bias: 5.581945461408111e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.009235593490302563\n",
      "Gradient for encoder.encoder.4.bias: 0.010224772617220879\n",
      "Gradient for encoder.mean.weight: 0.11884862929582596\n",
      "Gradient for encoder.mean.bias: 0.006872687488794327\n",
      "Gradient for encoder.log_var.weight: 0.07200666517019272\n",
      "Gradient for encoder.log_var.bias: 0.003887829603627324\n",
      "Gradient for decoder.decoder.0.weight: 0.013934148475527763\n",
      "Gradient for decoder.decoder.0.bias: 1.1860556980991532e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0007476715836673975\n",
      "Gradient for decoder.decoder.1.bias: 0.0005342881777323782\n",
      "Gradient for decoder.decoder.3.weight: 0.01208812277764082\n",
      "Gradient for decoder.decoder.3.bias: 9.684637120033202e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0005594639806076884\n",
      "Gradient for decoder.decoder.4.bias: 0.0005951469647698104\n",
      "Gradient for decoder.decoder.6.weight: 0.0007847312954254448\n",
      "Gradient for decoder.decoder.6.bias: 4.7799829189898446e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.030538905411958694\n",
      "Gradient for encoder.encoder.0.bias: 5.033056957315374e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0046076662838459015\n",
      "Gradient for encoder.encoder.1.bias: 0.00394115736708045\n",
      "Gradient for encoder.encoder.3.weight: 0.1013832688331604\n",
      "Gradient for encoder.encoder.3.bias: 6.502653415729753e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.012074654921889305\n",
      "Gradient for encoder.encoder.4.bias: 0.011030162684619427\n",
      "Gradient for encoder.mean.weight: 0.15740247070789337\n",
      "Gradient for encoder.mean.bias: 0.007532318588346243\n",
      "Gradient for encoder.log_var.weight: 0.09232588857412338\n",
      "Gradient for encoder.log_var.bias: 0.0039911773055791855\n",
      "Gradient for decoder.decoder.0.weight: 0.017245985567569733\n",
      "Gradient for decoder.decoder.0.bias: 1.3160458833816335e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0009148265235126019\n",
      "Gradient for decoder.decoder.1.bias: 0.0006508578662760556\n",
      "Gradient for decoder.decoder.3.weight: 0.014550992287695408\n",
      "Gradient for decoder.decoder.3.bias: 1.1713904846111234e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0006427211337722838\n",
      "Gradient for decoder.decoder.4.bias: 0.0005822181701660156\n",
      "Gradient for decoder.decoder.6.weight: 0.0009122362243942916\n",
      "Gradient for decoder.decoder.6.bias: 5.350392166292295e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.03424447029829025\n",
      "Gradient for encoder.encoder.0.bias: 5.572592040592461e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0036577892024070024\n",
      "Gradient for encoder.encoder.1.bias: 0.002841703360900283\n",
      "Gradient for encoder.encoder.3.weight: 0.07455199956893921\n",
      "Gradient for encoder.encoder.3.bias: 4.488469873553669e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.007961846888065338\n",
      "Gradient for encoder.encoder.4.bias: 0.007267727982252836\n",
      "Gradient for encoder.mean.weight: 0.10878931730985641\n",
      "Gradient for encoder.mean.bias: 0.004959900863468647\n",
      "Gradient for encoder.log_var.weight: 0.05171072110533714\n",
      "Gradient for encoder.log_var.bias: 0.0025313126388937235\n",
      "Gradient for decoder.decoder.0.weight: 0.013771080411970615\n",
      "Gradient for decoder.decoder.0.bias: 1.1536508554010894e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0006831987993791699\n",
      "Gradient for decoder.decoder.1.bias: 0.0005379857029765844\n",
      "Gradient for decoder.decoder.3.weight: 0.01172743272036314\n",
      "Gradient for decoder.decoder.3.bias: 9.289900099185289e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0005074534565210342\n",
      "Gradient for decoder.decoder.4.bias: 0.000454502587672323\n",
      "Gradient for decoder.decoder.6.weight: 0.0008562665898352861\n",
      "Gradient for decoder.decoder.6.bias: 5.309768675942905e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.029363231733441353\n",
      "Gradient for encoder.encoder.0.bias: 3.9924036299154864e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0038515811320394278\n",
      "Gradient for encoder.encoder.1.bias: 0.0028344239108264446\n",
      "Gradient for encoder.encoder.3.weight: 0.081383116543293\n",
      "Gradient for encoder.encoder.3.bias: 4.519079555009853e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.009530175477266312\n",
      "Gradient for encoder.encoder.4.bias: 0.007532136514782906\n",
      "Gradient for encoder.mean.weight: 0.1332269012928009\n",
      "Gradient for encoder.mean.bias: 0.0052698333747684956\n",
      "Gradient for encoder.log_var.weight: 0.07044240087270737\n",
      "Gradient for encoder.log_var.bias: 0.0036856827791780233\n",
      "Gradient for decoder.decoder.0.weight: 0.017827659845352173\n",
      "Gradient for decoder.decoder.0.bias: 1.5936818531514518e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0009884776081889868\n",
      "Gradient for decoder.decoder.1.bias: 0.0006723623373545706\n",
      "Gradient for decoder.decoder.3.weight: 0.015716707333922386\n",
      "Gradient for decoder.decoder.3.bias: 1.5393786245709862e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0008655213750898838\n",
      "Gradient for decoder.decoder.4.bias: 0.0009335883078165352\n",
      "Gradient for decoder.decoder.6.weight: 0.0010257391259074211\n",
      "Gradient for decoder.decoder.6.bias: 6.986832158872858e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.03858739137649536\n",
      "Gradient for encoder.encoder.0.bias: 4.64976390723848e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0037795633543282747\n",
      "Gradient for encoder.encoder.1.bias: 0.0028195271734148264\n",
      "Gradient for encoder.encoder.3.weight: 0.08123358339071274\n",
      "Gradient for encoder.encoder.3.bias: 5.658118973350668e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.009836114943027496\n",
      "Gradient for encoder.encoder.4.bias: 0.009918414987623692\n",
      "Gradient for encoder.mean.weight: 0.1314738392829895\n",
      "Gradient for encoder.mean.bias: 0.007243562489748001\n",
      "Gradient for encoder.log_var.weight: 0.07530852407217026\n",
      "Gradient for encoder.log_var.bias: 0.004636920988559723\n",
      "Gradient for decoder.decoder.0.weight: 0.015433240681886673\n",
      "Gradient for decoder.decoder.0.bias: 1.2895169654303373e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0008238549926318228\n",
      "Gradient for decoder.decoder.1.bias: 0.0006455157999880612\n",
      "Gradient for decoder.decoder.3.weight: 0.013450673781335354\n",
      "Gradient for decoder.decoder.3.bias: 1.1049313547450978e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0005259751342236996\n",
      "Gradient for decoder.decoder.4.bias: 0.00048083244473673403\n",
      "Gradient for decoder.decoder.6.weight: 0.0008206040365621448\n",
      "Gradient for decoder.decoder.6.bias: 4.2180847231065854e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.033699896186590195\n",
      "Gradient for encoder.encoder.0.bias: 5.5011918631553414e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0034230027813464403\n",
      "Gradient for encoder.encoder.1.bias: 0.0029468925204128027\n",
      "Gradient for encoder.encoder.3.weight: 0.07741177082061768\n",
      "Gradient for encoder.encoder.3.bias: 5.150481152682573e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.008949048817157745\n",
      "Gradient for encoder.encoder.4.bias: 0.009310312569141388\n",
      "Gradient for encoder.mean.weight: 0.1253826916217804\n",
      "Gradient for encoder.mean.bias: 0.007144301664084196\n",
      "Gradient for encoder.log_var.weight: 0.0742485374212265\n",
      "Gradient for encoder.log_var.bias: 0.004987443797290325\n",
      "Gradient for decoder.decoder.0.weight: 0.014005864970386028\n",
      "Gradient for decoder.decoder.0.bias: 1.25285989915902e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.000799899862613529\n",
      "Gradient for decoder.decoder.1.bias: 0.0005338012124411762\n",
      "Gradient for decoder.decoder.3.weight: 0.013016419485211372\n",
      "Gradient for decoder.decoder.3.bias: 1.0609509798475969e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.00044754010741598904\n",
      "Gradient for decoder.decoder.4.bias: 0.00038733071414753795\n",
      "Gradient for decoder.decoder.6.weight: 0.0007902619545347989\n",
      "Gradient for decoder.decoder.6.bias: 4.099204306839965e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.028560655191540718\n",
      "Gradient for encoder.encoder.0.bias: 4.394650615635598e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0034755419474095106\n",
      "Gradient for encoder.encoder.1.bias: 0.002853723941370845\n",
      "Gradient for encoder.encoder.3.weight: 0.07425165176391602\n",
      "Gradient for encoder.encoder.3.bias: 4.445315227030733e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.009643781930208206\n",
      "Gradient for encoder.encoder.4.bias: 0.0078120422549545765\n",
      "Gradient for encoder.mean.weight: 0.11824309080839157\n",
      "Gradient for encoder.mean.bias: 0.005138918291777372\n",
      "Gradient for encoder.log_var.weight: 0.07259997725486755\n",
      "Gradient for encoder.log_var.bias: 0.0029023822862654924\n",
      "Gradient for decoder.decoder.0.weight: 0.01419092807918787\n",
      "Gradient for decoder.decoder.0.bias: 1.2538869942346764e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0007611304172314703\n",
      "Gradient for decoder.decoder.1.bias: 0.0005426087300293148\n",
      "Gradient for decoder.decoder.3.weight: 0.012427905574440956\n",
      "Gradient for decoder.decoder.3.bias: 1.0199591171655698e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0005325055099092424\n",
      "Gradient for decoder.decoder.4.bias: 0.0005290161934681237\n",
      "Gradient for decoder.decoder.6.weight: 0.000814994506072253\n",
      "Gradient for decoder.decoder.6.bias: 4.4774566049454734e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.030392302200198174\n",
      "Gradient for encoder.encoder.0.bias: 4.562318231537965e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.003154429607093334\n",
      "Gradient for encoder.encoder.1.bias: 0.002651819260790944\n",
      "Gradient for encoder.encoder.3.weight: 0.07260990887880325\n",
      "Gradient for encoder.encoder.3.bias: 6.009768238612878e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.00904553011059761\n",
      "Gradient for encoder.encoder.4.bias: 0.011385057121515274\n",
      "Gradient for encoder.mean.weight: 0.11055562645196915\n",
      "Gradient for encoder.mean.bias: 0.008641055785119534\n",
      "Gradient for encoder.log_var.weight: 0.07197611033916473\n",
      "Gradient for encoder.log_var.bias: 0.006105451844632626\n",
      "Gradient for decoder.decoder.0.weight: 0.01580987684428692\n",
      "Gradient for decoder.decoder.0.bias: 1.2216845590717895e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0008065326255746186\n",
      "Gradient for decoder.decoder.1.bias: 0.0005774189485237002\n",
      "Gradient for decoder.decoder.3.weight: 0.01368696242570877\n",
      "Gradient for decoder.decoder.3.bias: 9.824917268641542e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0005171840311959386\n",
      "Gradient for decoder.decoder.4.bias: 0.00046135272714309394\n",
      "Gradient for decoder.decoder.6.weight: 0.0008050136384554207\n",
      "Gradient for decoder.decoder.6.bias: 4.289955904823728e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.029737547039985657\n",
      "Gradient for encoder.encoder.0.bias: 5.2025651148257523e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0037207186687737703\n",
      "Gradient for encoder.encoder.1.bias: 0.002617916092276573\n",
      "Gradient for encoder.encoder.3.weight: 0.07679252326488495\n",
      "Gradient for encoder.encoder.3.bias: 4.1429354391553375e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.009366150945425034\n",
      "Gradient for encoder.encoder.4.bias: 0.007184280082583427\n",
      "Gradient for encoder.mean.weight: 0.12963710725307465\n",
      "Gradient for encoder.mean.bias: 0.005327153485268354\n",
      "Gradient for encoder.log_var.weight: 0.06301978975534439\n",
      "Gradient for encoder.log_var.bias: 0.002708856016397476\n",
      "Gradient for decoder.decoder.0.weight: 0.013987274840474129\n",
      "Gradient for decoder.decoder.0.bias: 1.1580388731280422e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.000729598687030375\n",
      "Gradient for decoder.decoder.1.bias: 0.0005278864409774542\n",
      "Gradient for decoder.decoder.3.weight: 0.011691638268530369\n",
      "Gradient for decoder.decoder.3.bias: 9.117190336027647e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0005208891234360635\n",
      "Gradient for decoder.decoder.4.bias: 0.0006060869200155139\n",
      "Gradient for decoder.decoder.6.weight: 0.0007505695102736354\n",
      "Gradient for decoder.decoder.6.bias: 4.254429222783074e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.04131193086504936\n",
      "Gradient for encoder.encoder.0.bias: 6.593033063939657e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.004123392980545759\n",
      "Gradient for encoder.encoder.1.bias: 0.003118632361292839\n",
      "Gradient for encoder.encoder.3.weight: 0.08846922218799591\n",
      "Gradient for encoder.encoder.3.bias: 5.469086294951353e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.009907093830406666\n",
      "Gradient for encoder.encoder.4.bias: 0.009259889833629131\n",
      "Gradient for encoder.mean.weight: 0.13749803602695465\n",
      "Gradient for encoder.mean.bias: 0.007905237376689911\n",
      "Gradient for encoder.log_var.weight: 0.07653053849935532\n",
      "Gradient for encoder.log_var.bias: 0.004181123338639736\n",
      "Gradient for decoder.decoder.0.weight: 0.01122230663895607\n",
      "Gradient for decoder.decoder.0.bias: 8.841160442640827e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005867137806490064\n",
      "Gradient for decoder.decoder.1.bias: 0.0004121342790313065\n",
      "Gradient for decoder.decoder.3.weight: 0.009283102117478848\n",
      "Gradient for decoder.decoder.3.bias: 7.613767949443684e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0003340612165629864\n",
      "Gradient for decoder.decoder.4.bias: 0.0003386962634976953\n",
      "Gradient for decoder.decoder.6.weight: 0.0007318423013202846\n",
      "Gradient for decoder.decoder.6.bias: 3.353794090799056e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.03254978358745575\n",
      "Gradient for encoder.encoder.0.bias: 4.935442679543378e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.003821642603725195\n",
      "Gradient for encoder.encoder.1.bias: 0.003012305125594139\n",
      "Gradient for encoder.encoder.3.weight: 0.08060920983552933\n",
      "Gradient for encoder.encoder.3.bias: 5.683942205791936e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.010582556948065758\n",
      "Gradient for encoder.encoder.4.bias: 0.010662230663001537\n",
      "Gradient for encoder.mean.weight: 0.13768573105335236\n",
      "Gradient for encoder.mean.bias: 0.0077314553782343864\n",
      "Gradient for encoder.log_var.weight: 0.08061552792787552\n",
      "Gradient for encoder.log_var.bias: 0.004674647934734821\n",
      "Gradient for decoder.decoder.0.weight: 0.014709003269672394\n",
      "Gradient for decoder.decoder.0.bias: 1.3923709407670515e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0007456593448296189\n",
      "Gradient for decoder.decoder.1.bias: 0.0005341654177755117\n",
      "Gradient for decoder.decoder.3.weight: 0.01252313144505024\n",
      "Gradient for decoder.decoder.3.bias: 1.2725615006203839e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0004694226081483066\n",
      "Gradient for decoder.decoder.4.bias: 0.00041188063914887607\n",
      "Gradient for decoder.decoder.6.weight: 0.0008341662469319999\n",
      "Gradient for decoder.decoder.6.bias: 5.0614093197509646e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.027213146910071373\n",
      "Gradient for encoder.encoder.0.bias: 4.260136340916709e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0024495618417859077\n",
      "Gradient for encoder.encoder.1.bias: 0.002198701025918126\n",
      "Gradient for encoder.encoder.3.weight: 0.05222049728035927\n",
      "Gradient for encoder.encoder.3.bias: 4.660770103193101e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.005919124931097031\n",
      "Gradient for encoder.encoder.4.bias: 0.005993088241666555\n",
      "Gradient for encoder.mean.weight: 0.08320033550262451\n",
      "Gradient for encoder.mean.bias: 0.004367472603917122\n",
      "Gradient for encoder.log_var.weight: 0.04601920023560524\n",
      "Gradient for encoder.log_var.bias: 0.002720925956964493\n",
      "Gradient for decoder.decoder.0.weight: 0.013529069721698761\n",
      "Gradient for decoder.decoder.0.bias: 1.1241357844582467e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0007422541384585202\n",
      "Gradient for decoder.decoder.1.bias: 0.0004948995192535222\n",
      "Gradient for decoder.decoder.3.weight: 0.011811244301497936\n",
      "Gradient for decoder.decoder.3.bias: 8.509663113054344e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0004733818641398102\n",
      "Gradient for decoder.decoder.4.bias: 0.00048070878256112337\n",
      "Gradient for decoder.decoder.6.weight: 0.0008043699199333787\n",
      "Gradient for decoder.decoder.6.bias: 4.254193481756374e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.02800981141626835\n",
      "Gradient for encoder.encoder.0.bias: 4.531607727953357e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0030131819657981396\n",
      "Gradient for encoder.encoder.1.bias: 0.002339606638997793\n",
      "Gradient for encoder.encoder.3.weight: 0.06335879862308502\n",
      "Gradient for encoder.encoder.3.bias: 5.350443976759323e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.008305145427584648\n",
      "Gradient for encoder.encoder.4.bias: 0.008725050836801529\n",
      "Gradient for encoder.mean.weight: 0.10873139649629593\n",
      "Gradient for encoder.mean.bias: 0.006710459478199482\n",
      "Gradient for encoder.log_var.weight: 0.06015683710575104\n",
      "Gradient for encoder.log_var.bias: 0.003986059222370386\n",
      "Gradient for decoder.decoder.0.weight: 0.01483916211873293\n",
      "Gradient for decoder.decoder.0.bias: 1.2822597150741188e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0008265131618827581\n",
      "Gradient for decoder.decoder.1.bias: 0.0005573189118877053\n",
      "Gradient for decoder.decoder.3.weight: 0.013711768202483654\n",
      "Gradient for decoder.decoder.3.bias: 1.1587723142136852e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0006380659178830683\n",
      "Gradient for decoder.decoder.4.bias: 0.0006875210092402995\n",
      "Gradient for decoder.decoder.6.weight: 0.000984456273727119\n",
      "Gradient for decoder.decoder.6.bias: 6.848256452940404e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.037959735840559006\n",
      "Gradient for encoder.encoder.0.bias: 6.29926666384506e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.004856000188738108\n",
      "Gradient for encoder.encoder.1.bias: 0.0039313617162406445\n",
      "Gradient for encoder.encoder.3.weight: 0.1020423099398613\n",
      "Gradient for encoder.encoder.3.bias: 5.340896613859059e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.009442860260605812\n",
      "Gradient for encoder.encoder.4.bias: 0.008485885336995125\n",
      "Gradient for encoder.mean.weight: 0.12331153452396393\n",
      "Gradient for encoder.mean.bias: 0.004990872461348772\n",
      "Gradient for encoder.log_var.weight: 0.07531183212995529\n",
      "Gradient for encoder.log_var.bias: 0.0031297195237129927\n",
      "Gradient for decoder.decoder.0.weight: 0.015394449234008789\n",
      "Gradient for decoder.decoder.0.bias: 1.3986937996701698e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0007805780624039471\n",
      "Gradient for decoder.decoder.1.bias: 0.0005560980062000453\n",
      "Gradient for decoder.decoder.3.weight: 0.012852264568209648\n",
      "Gradient for decoder.decoder.3.bias: 1.0676864947711806e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0005030054016970098\n",
      "Gradient for decoder.decoder.4.bias: 0.0004586947616189718\n",
      "Gradient for decoder.decoder.6.weight: 0.0009458163403905928\n",
      "Gradient for decoder.decoder.6.bias: 6.83288526488468e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.02708480879664421\n",
      "Gradient for encoder.encoder.0.bias: 4.251353782902534e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0029769858811050653\n",
      "Gradient for encoder.encoder.1.bias: 0.0025992251466959715\n",
      "Gradient for encoder.encoder.3.weight: 0.06628891080617905\n",
      "Gradient for encoder.encoder.3.bias: 5.947805026274011e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.010015618056058884\n",
      "Gradient for encoder.encoder.4.bias: 0.010933809913694859\n",
      "Gradient for encoder.mean.weight: 0.12899434566497803\n",
      "Gradient for encoder.mean.bias: 0.00902075506746769\n",
      "Gradient for encoder.log_var.weight: 0.07555422186851501\n",
      "Gradient for encoder.log_var.bias: 0.005633112043142319\n",
      "Gradient for decoder.decoder.0.weight: 0.016649752855300903\n",
      "Gradient for decoder.decoder.0.bias: 1.4527416769549717e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0009232879965566099\n",
      "Gradient for decoder.decoder.1.bias: 0.0006545782089233398\n",
      "Gradient for decoder.decoder.3.weight: 0.014772974886000156\n",
      "Gradient for decoder.decoder.3.bias: 9.659401056794081e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0006377413519658148\n",
      "Gradient for decoder.decoder.4.bias: 0.0006549922400154173\n",
      "Gradient for decoder.decoder.6.weight: 0.0009400137350894511\n",
      "Gradient for decoder.decoder.6.bias: 6.24381355009973e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training VAE Epoch:  52%|█████▏    | 41/79 [00:00<00:00, 69.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient for encoder.encoder.0.weight: 0.03277476131916046\n",
      "Gradient for encoder.encoder.0.bias: 5.850779583038701e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.005198770202696323\n",
      "Gradient for encoder.encoder.1.bias: 0.004462424200028181\n",
      "Gradient for encoder.encoder.3.weight: 0.11481299996376038\n",
      "Gradient for encoder.encoder.3.bias: 5.704230421343937e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.011756489053368568\n",
      "Gradient for encoder.encoder.4.bias: 0.011771257035434246\n",
      "Gradient for encoder.mean.weight: 0.14865225553512573\n",
      "Gradient for encoder.mean.bias: 0.008552651852369308\n",
      "Gradient for encoder.log_var.weight: 0.07861120253801346\n",
      "Gradient for encoder.log_var.bias: 0.0043205758556723595\n",
      "Gradient for decoder.decoder.0.weight: 0.015068543143570423\n",
      "Gradient for decoder.decoder.0.bias: 1.1826546686410921e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.000816881307400763\n",
      "Gradient for decoder.decoder.1.bias: 0.0005250762915238738\n",
      "Gradient for decoder.decoder.3.weight: 0.013148914091289043\n",
      "Gradient for decoder.decoder.3.bias: 9.27644211445866e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0005729981930926442\n",
      "Gradient for decoder.decoder.4.bias: 0.0006334856152534485\n",
      "Gradient for decoder.decoder.6.weight: 0.000873854267410934\n",
      "Gradient for decoder.decoder.6.bias: 6.090917668188922e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.038879480212926865\n",
      "Gradient for encoder.encoder.0.bias: 6.680417330429123e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0038636073004454374\n",
      "Gradient for encoder.encoder.1.bias: 0.0027884242590516806\n",
      "Gradient for encoder.encoder.3.weight: 0.0838402584195137\n",
      "Gradient for encoder.encoder.3.bias: 4.3506637181778274e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.00943079311400652\n",
      "Gradient for encoder.encoder.4.bias: 0.00806732103228569\n",
      "Gradient for encoder.mean.weight: 0.12718304991722107\n",
      "Gradient for encoder.mean.bias: 0.006716316100209951\n",
      "Gradient for encoder.log_var.weight: 0.07411162555217743\n",
      "Gradient for encoder.log_var.bias: 0.004121302627027035\n",
      "Gradient for decoder.decoder.0.weight: 0.010280581191182137\n",
      "Gradient for decoder.decoder.0.bias: 9.182696963927484e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005537776160053909\n",
      "Gradient for decoder.decoder.1.bias: 0.0004011819255538285\n",
      "Gradient for decoder.decoder.3.weight: 0.008631071075797081\n",
      "Gradient for decoder.decoder.3.bias: 7.38569899683128e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00042476668022572994\n",
      "Gradient for decoder.decoder.4.bias: 0.0004370691312942654\n",
      "Gradient for decoder.decoder.6.weight: 0.0007910774438641965\n",
      "Gradient for decoder.decoder.6.bias: 4.747672937810421e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.0287795327603817\n",
      "Gradient for encoder.encoder.0.bias: 4.2947263800829916e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.004099603276699781\n",
      "Gradient for encoder.encoder.1.bias: 0.002978222444653511\n",
      "Gradient for encoder.encoder.3.weight: 0.08610319346189499\n",
      "Gradient for encoder.encoder.3.bias: 5.306301509300226e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.010257730260491371\n",
      "Gradient for encoder.encoder.4.bias: 0.010032977908849716\n",
      "Gradient for encoder.mean.weight: 0.1279391199350357\n",
      "Gradient for encoder.mean.bias: 0.0073525793850421906\n",
      "Gradient for encoder.log_var.weight: 0.07520585507154465\n",
      "Gradient for encoder.log_var.bias: 0.005408128723502159\n",
      "Gradient for decoder.decoder.0.weight: 0.015272130258381367\n",
      "Gradient for decoder.decoder.0.bias: 1.2894699197296688e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0008537962567061186\n",
      "Gradient for decoder.decoder.1.bias: 0.000545859569683671\n",
      "Gradient for decoder.decoder.3.weight: 0.013264251872897148\n",
      "Gradient for decoder.decoder.3.bias: 1.0321043325545176e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0004593796329572797\n",
      "Gradient for decoder.decoder.4.bias: 0.00040799201815389097\n",
      "Gradient for decoder.decoder.6.weight: 0.0007757145212963223\n",
      "Gradient for decoder.decoder.6.bias: 3.936816574423574e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.047907330095767975\n",
      "Gradient for encoder.encoder.0.bias: 6.959264414740929e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.006863288581371307\n",
      "Gradient for encoder.encoder.1.bias: 0.005422496702522039\n",
      "Gradient for encoder.encoder.3.weight: 0.15060041844844818\n",
      "Gradient for encoder.encoder.3.bias: 7.418858305463516e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.013768834993243217\n",
      "Gradient for encoder.encoder.4.bias: 0.013687264174222946\n",
      "Gradient for encoder.mean.weight: 0.1781805157661438\n",
      "Gradient for encoder.mean.bias: 0.00989347230643034\n",
      "Gradient for encoder.log_var.weight: 0.09768882393836975\n",
      "Gradient for encoder.log_var.bias: 0.005247540306299925\n",
      "Gradient for decoder.decoder.0.weight: 0.016443347558379173\n",
      "Gradient for decoder.decoder.0.bias: 1.4807613468725833e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.000849983945954591\n",
      "Gradient for decoder.decoder.1.bias: 0.0006159323384054005\n",
      "Gradient for decoder.decoder.3.weight: 0.014672619290649891\n",
      "Gradient for decoder.decoder.3.bias: 1.134804195057626e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0005395192420110106\n",
      "Gradient for decoder.decoder.4.bias: 0.0004553024482447654\n",
      "Gradient for decoder.decoder.6.weight: 0.0008111055358313024\n",
      "Gradient for decoder.decoder.6.bias: 3.597210888983682e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.04606420546770096\n",
      "Gradient for encoder.encoder.0.bias: 7.194630308182681e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.004091697279363871\n",
      "Gradient for encoder.encoder.1.bias: 0.002961196471005678\n",
      "Gradient for encoder.encoder.3.weight: 0.08673721551895142\n",
      "Gradient for encoder.encoder.3.bias: 6.163717314322525e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.009141291491687298\n",
      "Gradient for encoder.encoder.4.bias: 0.009652627632021904\n",
      "Gradient for encoder.mean.weight: 0.11283353716135025\n",
      "Gradient for encoder.mean.bias: 0.006774790585041046\n",
      "Gradient for encoder.log_var.weight: 0.06889679282903671\n",
      "Gradient for encoder.log_var.bias: 0.004168326500803232\n",
      "Gradient for decoder.decoder.0.weight: 0.012943287380039692\n",
      "Gradient for decoder.decoder.0.bias: 1.0590787968833837e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0006678177160210907\n",
      "Gradient for decoder.decoder.1.bias: 0.0004787816433236003\n",
      "Gradient for decoder.decoder.3.weight: 0.01123587042093277\n",
      "Gradient for decoder.decoder.3.bias: 8.547345470288903e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0004824132192879915\n",
      "Gradient for decoder.decoder.4.bias: 0.0005195693229325116\n",
      "Gradient for decoder.decoder.6.weight: 0.0007944181561470032\n",
      "Gradient for decoder.decoder.6.bias: 4.932675074087456e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.03600802272558212\n",
      "Gradient for encoder.encoder.0.bias: 5.457812674025675e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.003520444966852665\n",
      "Gradient for encoder.encoder.1.bias: 0.002865877468138933\n",
      "Gradient for encoder.encoder.3.weight: 0.08012150228023529\n",
      "Gradient for encoder.encoder.3.bias: 4.886414051163968e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.007997232489287853\n",
      "Gradient for encoder.encoder.4.bias: 0.008244347758591175\n",
      "Gradient for encoder.mean.weight: 0.10818352550268173\n",
      "Gradient for encoder.mean.bias: 0.006025094538927078\n",
      "Gradient for encoder.log_var.weight: 0.054573602974414825\n",
      "Gradient for encoder.log_var.bias: 0.0032779527828097343\n",
      "Gradient for decoder.decoder.0.weight: 0.013041500002145767\n",
      "Gradient for decoder.decoder.0.bias: 1.1162154534005708e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0007093704771250486\n",
      "Gradient for decoder.decoder.1.bias: 0.0005263719358481467\n",
      "Gradient for decoder.decoder.3.weight: 0.011351967230439186\n",
      "Gradient for decoder.decoder.3.bias: 9.557953734029567e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00045477846288122237\n",
      "Gradient for decoder.decoder.4.bias: 0.00044954477925784886\n",
      "Gradient for decoder.decoder.6.weight: 0.0007919822819530964\n",
      "Gradient for decoder.decoder.6.bias: 4.3440053559606895e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.03251378983259201\n",
      "Gradient for encoder.encoder.0.bias: 4.6539556930458303e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.004946664907038212\n",
      "Gradient for encoder.encoder.1.bias: 0.0038047870621085167\n",
      "Gradient for encoder.encoder.3.weight: 0.10899507999420166\n",
      "Gradient for encoder.encoder.3.bias: 6.113348716141331e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0121751818805933\n",
      "Gradient for encoder.encoder.4.bias: 0.010646732524037361\n",
      "Gradient for encoder.mean.weight: 0.16194111108779907\n",
      "Gradient for encoder.mean.bias: 0.008163615129888058\n",
      "Gradient for encoder.log_var.weight: 0.0812499076128006\n",
      "Gradient for encoder.log_var.bias: 0.004652013070881367\n",
      "Gradient for decoder.decoder.0.weight: 0.015198636800050735\n",
      "Gradient for decoder.decoder.0.bias: 1.212610706291528e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0007965947734192014\n",
      "Gradient for decoder.decoder.1.bias: 0.0005611876840703189\n",
      "Gradient for decoder.decoder.3.weight: 0.013855310156941414\n",
      "Gradient for decoder.decoder.3.bias: 1.0284015999895146e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0005877285148017108\n",
      "Gradient for decoder.decoder.4.bias: 0.0005943913129158318\n",
      "Gradient for decoder.decoder.6.weight: 0.0008949831244535744\n",
      "Gradient for decoder.decoder.6.bias: 5.2653114835266024e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.03918581083416939\n",
      "Gradient for encoder.encoder.0.bias: 6.028643556588165e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.004707333166152239\n",
      "Gradient for encoder.encoder.1.bias: 0.0035330047830939293\n",
      "Gradient for encoder.encoder.3.weight: 0.10380925983190536\n",
      "Gradient for encoder.encoder.3.bias: 6.129619034567213e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.009318681433796883\n",
      "Gradient for encoder.encoder.4.bias: 0.010026607662439346\n",
      "Gradient for encoder.mean.weight: 0.12351270020008087\n",
      "Gradient for encoder.mean.bias: 0.007219458930194378\n",
      "Gradient for encoder.log_var.weight: 0.06715035438537598\n",
      "Gradient for encoder.log_var.bias: 0.003902597352862358\n",
      "Gradient for decoder.decoder.0.weight: 0.012655351310968399\n",
      "Gradient for decoder.decoder.0.bias: 1.0114027670926617e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0006705396808683872\n",
      "Gradient for decoder.decoder.1.bias: 0.00048216208233498037\n",
      "Gradient for decoder.decoder.3.weight: 0.011120738461613655\n",
      "Gradient for decoder.decoder.3.bias: 8.436321780047606e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0005065586301498115\n",
      "Gradient for decoder.decoder.4.bias: 0.0005955420783720911\n",
      "Gradient for decoder.decoder.6.weight: 0.0008491488406434655\n",
      "Gradient for decoder.decoder.6.bias: 6.068214133847505e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.030617540702223778\n",
      "Gradient for encoder.encoder.0.bias: 4.221468660747796e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0030113565735518932\n",
      "Gradient for encoder.encoder.1.bias: 0.0027218072209507227\n",
      "Gradient for encoder.encoder.3.weight: 0.0726708471775055\n",
      "Gradient for encoder.encoder.3.bias: 4.3007469807676557e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.008505352772772312\n",
      "Gradient for encoder.encoder.4.bias: 0.007304708939045668\n",
      "Gradient for encoder.mean.weight: 0.11698728799819946\n",
      "Gradient for encoder.mean.bias: 0.0053539271466434\n",
      "Gradient for encoder.log_var.weight: 0.06589580327272415\n",
      "Gradient for encoder.log_var.bias: 0.003267338965088129\n",
      "Gradient for decoder.decoder.0.weight: 0.015165510587394238\n",
      "Gradient for decoder.decoder.0.bias: 1.3010309496408468e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0007678720867261291\n",
      "Gradient for decoder.decoder.1.bias: 0.000551369390450418\n",
      "Gradient for decoder.decoder.3.weight: 0.012862320989370346\n",
      "Gradient for decoder.decoder.3.bias: 9.370554332477354e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00047631034976802766\n",
      "Gradient for decoder.decoder.4.bias: 0.0004032519937027246\n",
      "Gradient for decoder.decoder.6.weight: 0.0008356591570191085\n",
      "Gradient for decoder.decoder.6.bias: 4.325295958551578e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.03082222118973732\n",
      "Gradient for encoder.encoder.0.bias: 4.933387379169041e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.004485379438847303\n",
      "Gradient for encoder.encoder.1.bias: 0.0036261160857975483\n",
      "Gradient for encoder.encoder.3.weight: 0.0928998589515686\n",
      "Gradient for encoder.encoder.3.bias: 4.699260980345343e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.01027702633291483\n",
      "Gradient for encoder.encoder.4.bias: 0.008944508619606495\n",
      "Gradient for encoder.mean.weight: 0.1316387951374054\n",
      "Gradient for encoder.mean.bias: 0.006171973422169685\n",
      "Gradient for encoder.log_var.weight: 0.07227180898189545\n",
      "Gradient for encoder.log_var.bias: 0.003190749092027545\n",
      "Gradient for decoder.decoder.0.weight: 0.013142004609107971\n",
      "Gradient for decoder.decoder.0.bias: 1.0760206614612855e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0006696645868942142\n",
      "Gradient for decoder.decoder.1.bias: 0.0004633292555809021\n",
      "Gradient for decoder.decoder.3.weight: 0.011375238187611103\n",
      "Gradient for decoder.decoder.3.bias: 8.980914623091252e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0004045251989737153\n",
      "Gradient for decoder.decoder.4.bias: 0.00035768403904512525\n",
      "Gradient for decoder.decoder.6.weight: 0.000800415757112205\n",
      "Gradient for decoder.decoder.6.bias: 4.438055111677386e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.024422911927103996\n",
      "Gradient for encoder.encoder.0.bias: 4.260128708133415e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.003439549822360277\n",
      "Gradient for encoder.encoder.1.bias: 0.002670228248462081\n",
      "Gradient for encoder.encoder.3.weight: 0.07505356520414352\n",
      "Gradient for encoder.encoder.3.bias: 4.6494255667717255e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.008513378910720348\n",
      "Gradient for encoder.encoder.4.bias: 0.00874248892068863\n",
      "Gradient for encoder.mean.weight: 0.10710525512695312\n",
      "Gradient for encoder.mean.bias: 0.00667797215282917\n",
      "Gradient for encoder.log_var.weight: 0.06646394729614258\n",
      "Gradient for encoder.log_var.bias: 0.004238094203174114\n",
      "Gradient for decoder.decoder.0.weight: 0.014583628624677658\n",
      "Gradient for decoder.decoder.0.bias: 1.174446095930648e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0008839395013637841\n",
      "Gradient for decoder.decoder.1.bias: 0.0005597409908659756\n",
      "Gradient for decoder.decoder.3.weight: 0.012869789265096188\n",
      "Gradient for decoder.decoder.3.bias: 9.623341012954256e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0004942463710904121\n",
      "Gradient for decoder.decoder.4.bias: 0.0004887167015112936\n",
      "Gradient for decoder.decoder.6.weight: 0.0008163204183802009\n",
      "Gradient for decoder.decoder.6.bias: 4.4133426854386926e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.025771744549274445\n",
      "Gradient for encoder.encoder.0.bias: 3.8749257275094706e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.003442856715992093\n",
      "Gradient for encoder.encoder.1.bias: 0.002808197634294629\n",
      "Gradient for encoder.encoder.3.weight: 0.075347401201725\n",
      "Gradient for encoder.encoder.3.bias: 4.4133130483459126e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.009278845973312855\n",
      "Gradient for encoder.encoder.4.bias: 0.009774517267942429\n",
      "Gradient for encoder.mean.weight: 0.11362191289663315\n",
      "Gradient for encoder.mean.bias: 0.006658818107098341\n",
      "Gradient for encoder.log_var.weight: 0.06891108304262161\n",
      "Gradient for encoder.log_var.bias: 0.004438095726072788\n",
      "Gradient for decoder.decoder.0.weight: 0.013736158609390259\n",
      "Gradient for decoder.decoder.0.bias: 1.1977398239881865e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0006989678367972374\n",
      "Gradient for decoder.decoder.1.bias: 0.0004759901203215122\n",
      "Gradient for decoder.decoder.3.weight: 0.011976327747106552\n",
      "Gradient for decoder.decoder.3.bias: 9.76053612933292e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0005821167142130435\n",
      "Gradient for decoder.decoder.4.bias: 0.0005680605536326766\n",
      "Gradient for decoder.decoder.6.weight: 0.0009286194108426571\n",
      "Gradient for decoder.decoder.6.bias: 5.941167546552606e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.022349774837493896\n",
      "Gradient for encoder.encoder.0.bias: 3.1954258683519754e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.003193795448169112\n",
      "Gradient for encoder.encoder.1.bias: 0.0026655523106455803\n",
      "Gradient for encoder.encoder.3.weight: 0.06806730479001999\n",
      "Gradient for encoder.encoder.3.bias: 4.2140360645426256e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.007861806079745293\n",
      "Gradient for encoder.encoder.4.bias: 0.007862360216677189\n",
      "Gradient for encoder.mean.weight: 0.10447665303945541\n",
      "Gradient for encoder.mean.bias: 0.00589307677000761\n",
      "Gradient for encoder.log_var.weight: 0.04866262897849083\n",
      "Gradient for encoder.log_var.bias: 0.00356904324144125\n",
      "Gradient for decoder.decoder.0.weight: 0.01765480265021324\n",
      "Gradient for decoder.decoder.0.bias: 1.5742404602114846e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0009598114411346614\n",
      "Gradient for decoder.decoder.1.bias: 0.0007075036410242319\n",
      "Gradient for decoder.decoder.3.weight: 0.015240956097841263\n",
      "Gradient for decoder.decoder.3.bias: 1.7699372523161117e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0011228953953832388\n",
      "Gradient for decoder.decoder.4.bias: 0.001338902860879898\n",
      "Gradient for decoder.decoder.6.weight: 0.0012136553414165974\n",
      "Gradient for decoder.decoder.6.bias: 0.00010455781739437953\n",
      "Gradient for encoder.encoder.0.weight: 0.02742954157292843\n",
      "Gradient for encoder.encoder.0.bias: 4.167812969746443e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0034908405505120754\n",
      "Gradient for encoder.encoder.1.bias: 0.0025868199300020933\n",
      "Gradient for encoder.encoder.3.weight: 0.07416737079620361\n",
      "Gradient for encoder.encoder.3.bias: 4.2425638002718813e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.008298167958855629\n",
      "Gradient for encoder.encoder.4.bias: 0.007058464922010899\n",
      "Gradient for encoder.mean.weight: 0.11181674897670746\n",
      "Gradient for encoder.mean.bias: 0.005653299391269684\n",
      "Gradient for encoder.log_var.weight: 0.05437961220741272\n",
      "Gradient for encoder.log_var.bias: 0.003005243605002761\n",
      "Gradient for decoder.decoder.0.weight: 0.013813025318086147\n",
      "Gradient for decoder.decoder.0.bias: 1.2406596583414142e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0006876795669086277\n",
      "Gradient for decoder.decoder.1.bias: 0.000508868251927197\n",
      "Gradient for decoder.decoder.3.weight: 0.011748593300580978\n",
      "Gradient for decoder.decoder.3.bias: 9.288279173569336e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00039909352199174464\n",
      "Gradient for decoder.decoder.4.bias: 0.0003682934620883316\n",
      "Gradient for decoder.decoder.6.weight: 0.0007845642394386232\n",
      "Gradient for decoder.decoder.6.bias: 4.525431722868234e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.03510967269539833\n",
      "Gradient for encoder.encoder.0.bias: 4.689664628854118e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.004556230269372463\n",
      "Gradient for encoder.encoder.1.bias: 0.0036733197048306465\n",
      "Gradient for encoder.encoder.3.weight: 0.09914284944534302\n",
      "Gradient for encoder.encoder.3.bias: 5.870914865369059e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.012213397771120071\n",
      "Gradient for encoder.encoder.4.bias: 0.009994382038712502\n",
      "Gradient for encoder.mean.weight: 0.14805059134960175\n",
      "Gradient for encoder.mean.bias: 0.006040302105247974\n",
      "Gradient for encoder.log_var.weight: 0.08087637275457382\n",
      "Gradient for encoder.log_var.bias: 0.0031813238747417927\n",
      "Gradient for decoder.decoder.0.weight: 0.01827489770948887\n",
      "Gradient for decoder.decoder.0.bias: 1.550360395619066e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0009809150360524654\n",
      "Gradient for decoder.decoder.1.bias: 0.0006748757441528141\n",
      "Gradient for decoder.decoder.3.weight: 0.016698848456144333\n",
      "Gradient for decoder.decoder.3.bias: 1.3050635572220415e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0007748993812128901\n",
      "Gradient for decoder.decoder.4.bias: 0.0008017946383915842\n",
      "Gradient for decoder.decoder.6.weight: 0.0009430032223463058\n",
      "Gradient for decoder.decoder.6.bias: 6.139843026176095e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.0231704730540514\n",
      "Gradient for encoder.encoder.0.bias: 3.8593385431884286e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.00308355875313282\n",
      "Gradient for encoder.encoder.1.bias: 0.0024890322238206863\n",
      "Gradient for encoder.encoder.3.weight: 0.06850307434797287\n",
      "Gradient for encoder.encoder.3.bias: 4.328740976777823e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.008285670541226864\n",
      "Gradient for encoder.encoder.4.bias: 0.007972046732902527\n",
      "Gradient for encoder.mean.weight: 0.09807544946670532\n",
      "Gradient for encoder.mean.bias: 0.005445627495646477\n",
      "Gradient for encoder.log_var.weight: 0.06332452595233917\n",
      "Gradient for encoder.log_var.bias: 0.0035574231296777725\n",
      "Gradient for decoder.decoder.0.weight: 0.013871465809643269\n",
      "Gradient for decoder.decoder.0.bias: 1.0895197244398247e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0007642963901162148\n",
      "Gradient for decoder.decoder.1.bias: 0.0004913961747661233\n",
      "Gradient for decoder.decoder.3.weight: 0.01229544822126627\n",
      "Gradient for decoder.decoder.3.bias: 9.310251181116058e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0005155354738235474\n",
      "Gradient for decoder.decoder.4.bias: 0.0005161893204785883\n",
      "Gradient for decoder.decoder.6.weight: 0.0008435791824012995\n",
      "Gradient for decoder.decoder.6.bias: 4.6435663534794e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training VAE Epoch:  72%|███████▏  | 57/79 [00:00<00:00, 73.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient for encoder.encoder.0.weight: 0.03537886217236519\n",
      "Gradient for encoder.encoder.0.bias: 4.765615679858115e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0051402016542851925\n",
      "Gradient for encoder.encoder.1.bias: 0.003814194817095995\n",
      "Gradient for encoder.encoder.3.weight: 0.1132740005850792\n",
      "Gradient for encoder.encoder.3.bias: 7.7975753631776e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.014654376544058323\n",
      "Gradient for encoder.encoder.4.bias: 0.013477139174938202\n",
      "Gradient for encoder.mean.weight: 0.1728188544511795\n",
      "Gradient for encoder.mean.bias: 0.008815862238407135\n",
      "Gradient for encoder.log_var.weight: 0.0967860147356987\n",
      "Gradient for encoder.log_var.bias: 0.00486889248713851\n",
      "Gradient for decoder.decoder.0.weight: 0.017129048705101013\n",
      "Gradient for decoder.decoder.0.bias: 1.4735533626630826e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0009164900402538478\n",
      "Gradient for decoder.decoder.1.bias: 0.0006514814449474216\n",
      "Gradient for decoder.decoder.3.weight: 0.01539207249879837\n",
      "Gradient for decoder.decoder.3.bias: 1.170656488413968e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0005650501698255539\n",
      "Gradient for decoder.decoder.4.bias: 0.0005246744258329272\n",
      "Gradient for decoder.decoder.6.weight: 0.0008458543452434242\n",
      "Gradient for decoder.decoder.6.bias: 3.788783214986324e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.041098032146692276\n",
      "Gradient for encoder.encoder.0.bias: 6.760709353459404e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.005260182544589043\n",
      "Gradient for encoder.encoder.1.bias: 0.004105608910322189\n",
      "Gradient for encoder.encoder.3.weight: 0.12073945999145508\n",
      "Gradient for encoder.encoder.3.bias: 5.792202273369185e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.013438621535897255\n",
      "Gradient for encoder.encoder.4.bias: 0.0105723412707448\n",
      "Gradient for encoder.mean.weight: 0.17486435174942017\n",
      "Gradient for encoder.mean.bias: 0.00659664673730731\n",
      "Gradient for encoder.log_var.weight: 0.09833381325006485\n",
      "Gradient for encoder.log_var.bias: 0.0034998913761228323\n",
      "Gradient for decoder.decoder.0.weight: 0.011751178652048111\n",
      "Gradient for decoder.decoder.0.bias: 9.642389664499262e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0006585886003449559\n",
      "Gradient for decoder.decoder.1.bias: 0.0004313756653573364\n",
      "Gradient for decoder.decoder.3.weight: 0.010336781851947308\n",
      "Gradient for decoder.decoder.3.bias: 7.660114209606661e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00038964205305092037\n",
      "Gradient for decoder.decoder.4.bias: 0.00039572868263348937\n",
      "Gradient for decoder.decoder.6.weight: 0.000829592754598707\n",
      "Gradient for decoder.decoder.6.bias: 4.520833681453951e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.03632216155529022\n",
      "Gradient for encoder.encoder.0.bias: 5.171395603409401e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.004493203945457935\n",
      "Gradient for encoder.encoder.1.bias: 0.0037180616054683924\n",
      "Gradient for encoder.encoder.3.weight: 0.1051836758852005\n",
      "Gradient for encoder.encoder.3.bias: 6.847560296563415e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.012675789184868336\n",
      "Gradient for encoder.encoder.4.bias: 0.012714012525975704\n",
      "Gradient for encoder.mean.weight: 0.1674363613128662\n",
      "Gradient for encoder.mean.bias: 0.009091378189623356\n",
      "Gradient for encoder.log_var.weight: 0.09943965077400208\n",
      "Gradient for encoder.log_var.bias: 0.0065486072562634945\n",
      "Gradient for decoder.decoder.0.weight: 0.01636711321771145\n",
      "Gradient for decoder.decoder.0.bias: 1.4077383703181567e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0009616893366910517\n",
      "Gradient for decoder.decoder.1.bias: 0.0006102354382164776\n",
      "Gradient for decoder.decoder.3.weight: 0.01416335441172123\n",
      "Gradient for decoder.decoder.3.bias: 1.2362032231205689e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0008483898127451539\n",
      "Gradient for decoder.decoder.4.bias: 0.0009625700768083334\n",
      "Gradient for decoder.decoder.6.weight: 0.000996044254861772\n",
      "Gradient for decoder.decoder.6.bias: 7.098486821632832e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.026439163833856583\n",
      "Gradient for encoder.encoder.0.bias: 4.342636319987214e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0033191184047609568\n",
      "Gradient for encoder.encoder.1.bias: 0.0027444057632237673\n",
      "Gradient for encoder.encoder.3.weight: 0.07000140100717545\n",
      "Gradient for encoder.encoder.3.bias: 3.918956548165653e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.007210522424429655\n",
      "Gradient for encoder.encoder.4.bias: 0.00622434401884675\n",
      "Gradient for encoder.mean.weight: 0.0959770679473877\n",
      "Gradient for encoder.mean.bias: 0.004843504633754492\n",
      "Gradient for encoder.log_var.weight: 0.04812397062778473\n",
      "Gradient for encoder.log_var.bias: 0.0031335479579865932\n",
      "Gradient for decoder.decoder.0.weight: 0.014983542263507843\n",
      "Gradient for decoder.decoder.0.bias: 1.1385299647503899e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0007826469372957945\n",
      "Gradient for decoder.decoder.1.bias: 0.0005651789833791554\n",
      "Gradient for decoder.decoder.3.weight: 0.012757653370499611\n",
      "Gradient for decoder.decoder.3.bias: 1.0027365743292549e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0004786696517840028\n",
      "Gradient for decoder.decoder.4.bias: 0.00045326206600293517\n",
      "Gradient for decoder.decoder.6.weight: 0.0008372128941118717\n",
      "Gradient for decoder.decoder.6.bias: 5.012355177314021e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.0330301858484745\n",
      "Gradient for encoder.encoder.0.bias: 4.7886732773561036e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0033694489393383265\n",
      "Gradient for encoder.encoder.1.bias: 0.0026243783067911863\n",
      "Gradient for encoder.encoder.3.weight: 0.07601771503686905\n",
      "Gradient for encoder.encoder.3.bias: 5.03480257485478e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.00884703267365694\n",
      "Gradient for encoder.encoder.4.bias: 0.009316455572843552\n",
      "Gradient for encoder.mean.weight: 0.10698778182268143\n",
      "Gradient for encoder.mean.bias: 0.006659762002527714\n",
      "Gradient for encoder.log_var.weight: 0.06967244297266006\n",
      "Gradient for encoder.log_var.bias: 0.0046729170717298985\n",
      "Gradient for decoder.decoder.0.weight: 0.014981575310230255\n",
      "Gradient for decoder.decoder.0.bias: 1.1497690993733656e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0007907229010015726\n",
      "Gradient for decoder.decoder.1.bias: 0.0005837806384079158\n",
      "Gradient for decoder.decoder.3.weight: 0.013367243111133575\n",
      "Gradient for decoder.decoder.3.bias: 9.677369322558249e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0004983029211871326\n",
      "Gradient for decoder.decoder.4.bias: 0.00041587738087400794\n",
      "Gradient for decoder.decoder.6.weight: 0.000868355855345726\n",
      "Gradient for decoder.decoder.6.bias: 4.468934639589861e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.030631285160779953\n",
      "Gradient for encoder.encoder.0.bias: 4.408499260089016e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0047216699458658695\n",
      "Gradient for encoder.encoder.1.bias: 0.0035357691813260317\n",
      "Gradient for encoder.encoder.3.weight: 0.09890472888946533\n",
      "Gradient for encoder.encoder.3.bias: 5.327482899275537e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.01099957525730133\n",
      "Gradient for encoder.encoder.4.bias: 0.011119079776108265\n",
      "Gradient for encoder.mean.weight: 0.14622238278388977\n",
      "Gradient for encoder.mean.bias: 0.007456808350980282\n",
      "Gradient for encoder.log_var.weight: 0.07795964926481247\n",
      "Gradient for encoder.log_var.bias: 0.004818405490368605\n",
      "Gradient for decoder.decoder.0.weight: 0.013755172491073608\n",
      "Gradient for decoder.decoder.0.bias: 1.0703644220955155e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0007423031493090093\n",
      "Gradient for decoder.decoder.1.bias: 0.0005130804493092\n",
      "Gradient for decoder.decoder.3.weight: 0.011975129134953022\n",
      "Gradient for decoder.decoder.3.bias: 8.280445079611454e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00040496038855053484\n",
      "Gradient for decoder.decoder.4.bias: 0.00037629486178047955\n",
      "Gradient for decoder.decoder.6.weight: 0.0007737461128272116\n",
      "Gradient for decoder.decoder.6.bias: 3.942307012039237e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.039724867790937424\n",
      "Gradient for encoder.encoder.0.bias: 7.30885491018185e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0048152790404856205\n",
      "Gradient for encoder.encoder.1.bias: 0.0035493276081979275\n",
      "Gradient for encoder.encoder.3.weight: 0.09473957121372223\n",
      "Gradient for encoder.encoder.3.bias: 5.625958587884838e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.01342169102281332\n",
      "Gradient for encoder.encoder.4.bias: 0.011175522580742836\n",
      "Gradient for encoder.mean.weight: 0.16654205322265625\n",
      "Gradient for encoder.mean.bias: 0.006971166934818029\n",
      "Gradient for encoder.log_var.weight: 0.09265448153018951\n",
      "Gradient for encoder.log_var.bias: 0.0036881661508232355\n",
      "Gradient for decoder.decoder.0.weight: 0.011102424934506416\n",
      "Gradient for decoder.decoder.0.bias: 9.302091735774454e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005930599290877581\n",
      "Gradient for decoder.decoder.1.bias: 0.0004206841404084116\n",
      "Gradient for decoder.decoder.3.weight: 0.009666122496128082\n",
      "Gradient for decoder.decoder.3.bias: 8.309434390563197e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00039118921267800033\n",
      "Gradient for decoder.decoder.4.bias: 0.00042474549263715744\n",
      "Gradient for decoder.decoder.6.weight: 0.0007567168213427067\n",
      "Gradient for decoder.decoder.6.bias: 3.516047217999585e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.03321022912859917\n",
      "Gradient for encoder.encoder.0.bias: 5.3413034412086446e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.004010635428130627\n",
      "Gradient for encoder.encoder.1.bias: 0.003100212197750807\n",
      "Gradient for encoder.encoder.3.weight: 0.09124763309955597\n",
      "Gradient for encoder.encoder.3.bias: 4.38140274061638e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.009483600966632366\n",
      "Gradient for encoder.encoder.4.bias: 0.0067942459136247635\n",
      "Gradient for encoder.mean.weight: 0.1275739222764969\n",
      "Gradient for encoder.mean.bias: 0.0050885966047644615\n",
      "Gradient for encoder.log_var.weight: 0.075813889503479\n",
      "Gradient for encoder.log_var.bias: 0.0027244538068771362\n",
      "Gradient for decoder.decoder.0.weight: 0.01262748520821333\n",
      "Gradient for decoder.decoder.0.bias: 9.7747629435041e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0007026510429568589\n",
      "Gradient for decoder.decoder.1.bias: 0.0004746037593577057\n",
      "Gradient for decoder.decoder.3.weight: 0.011178395710885525\n",
      "Gradient for decoder.decoder.3.bias: 1.0065857175556303e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0006330579635687172\n",
      "Gradient for decoder.decoder.4.bias: 0.0007328488281928003\n",
      "Gradient for decoder.decoder.6.weight: 0.0009039098513312638\n",
      "Gradient for decoder.decoder.6.bias: 6.732281326549128e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.031096871942281723\n",
      "Gradient for encoder.encoder.0.bias: 4.86577687863754e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.004367388319224119\n",
      "Gradient for encoder.encoder.1.bias: 0.0032920893281698227\n",
      "Gradient for encoder.encoder.3.weight: 0.08885958045721054\n",
      "Gradient for encoder.encoder.3.bias: 4.869672998175645e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.008761986158788204\n",
      "Gradient for encoder.encoder.4.bias: 0.008966108784079552\n",
      "Gradient for encoder.mean.weight: 0.11550355702638626\n",
      "Gradient for encoder.mean.bias: 0.0068441457115113735\n",
      "Gradient for encoder.log_var.weight: 0.06393741071224213\n",
      "Gradient for encoder.log_var.bias: 0.004233489744365215\n",
      "Gradient for decoder.decoder.0.weight: 0.015451415441930294\n",
      "Gradient for decoder.decoder.0.bias: 1.2946110850009518e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.000819272652734071\n",
      "Gradient for decoder.decoder.1.bias: 0.0005654996493831277\n",
      "Gradient for decoder.decoder.3.weight: 0.013626658357679844\n",
      "Gradient for decoder.decoder.3.bias: 1.0172132580699156e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0006004448514431715\n",
      "Gradient for decoder.decoder.4.bias: 0.0005235622520558536\n",
      "Gradient for decoder.decoder.6.weight: 0.0008682368788868189\n",
      "Gradient for decoder.decoder.6.bias: 4.819664900423959e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.03415687009692192\n",
      "Gradient for encoder.encoder.0.bias: 6.084625164826107e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.003130728844553232\n",
      "Gradient for encoder.encoder.1.bias: 0.0022852288093417883\n",
      "Gradient for encoder.encoder.3.weight: 0.062034014612436295\n",
      "Gradient for encoder.encoder.3.bias: 5.792412105520839e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.009492458775639534\n",
      "Gradient for encoder.encoder.4.bias: 0.010281501337885857\n",
      "Gradient for encoder.mean.weight: 0.13146649301052094\n",
      "Gradient for encoder.mean.bias: 0.009200326167047024\n",
      "Gradient for encoder.log_var.weight: 0.08010593056678772\n",
      "Gradient for encoder.log_var.bias: 0.006255529820919037\n",
      "Gradient for decoder.decoder.0.weight: 0.011943753808736801\n",
      "Gradient for decoder.decoder.0.bias: 1.0015313578470852e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0006312400801107287\n",
      "Gradient for decoder.decoder.1.bias: 0.0004500094219110906\n",
      "Gradient for decoder.decoder.3.weight: 0.010459359735250473\n",
      "Gradient for decoder.decoder.3.bias: 8.103234055978348e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0003811417846009135\n",
      "Gradient for decoder.decoder.4.bias: 0.00033046945463865995\n",
      "Gradient for decoder.decoder.6.weight: 0.0008027545991353691\n",
      "Gradient for decoder.decoder.6.bias: 4.6100594772724435e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.028428878635168076\n",
      "Gradient for encoder.encoder.0.bias: 4.488623014942128e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.004133735783398151\n",
      "Gradient for encoder.encoder.1.bias: 0.0029448391869664192\n",
      "Gradient for encoder.encoder.3.weight: 0.08491241931915283\n",
      "Gradient for encoder.encoder.3.bias: 4.829581734533406e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.009628650732338428\n",
      "Gradient for encoder.encoder.4.bias: 0.009175041690468788\n",
      "Gradient for encoder.mean.weight: 0.12056324630975723\n",
      "Gradient for encoder.mean.bias: 0.0072314017452299595\n",
      "Gradient for encoder.log_var.weight: 0.07599157840013504\n",
      "Gradient for encoder.log_var.bias: 0.00442197872325778\n",
      "Gradient for decoder.decoder.0.weight: 0.015685372054576874\n",
      "Gradient for decoder.decoder.0.bias: 1.3040395152597029e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0007756128907203674\n",
      "Gradient for decoder.decoder.1.bias: 0.0005894338246434927\n",
      "Gradient for decoder.decoder.3.weight: 0.013679955154657364\n",
      "Gradient for decoder.decoder.3.bias: 9.637083492330945e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00048401436652056873\n",
      "Gradient for decoder.decoder.4.bias: 0.00048414539196528494\n",
      "Gradient for decoder.decoder.6.weight: 0.0007566162385046482\n",
      "Gradient for decoder.decoder.6.bias: 3.3842341508716345e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.03003455512225628\n",
      "Gradient for encoder.encoder.0.bias: 4.8898524118712317e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.002917942125350237\n",
      "Gradient for encoder.encoder.1.bias: 0.0024585286155343056\n",
      "Gradient for encoder.encoder.3.weight: 0.060396064072847366\n",
      "Gradient for encoder.encoder.3.bias: 3.9177802668710626e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.006533957552164793\n",
      "Gradient for encoder.encoder.4.bias: 0.006838425528258085\n",
      "Gradient for encoder.mean.weight: 0.08680734038352966\n",
      "Gradient for encoder.mean.bias: 0.005434669088572264\n",
      "Gradient for encoder.log_var.weight: 0.053136322647333145\n",
      "Gradient for encoder.log_var.bias: 0.003409937722608447\n",
      "Gradient for decoder.decoder.0.weight: 0.014435533434152603\n",
      "Gradient for decoder.decoder.0.bias: 1.2131318172237116e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0007606311701238155\n",
      "Gradient for decoder.decoder.1.bias: 0.0005249012028798461\n",
      "Gradient for decoder.decoder.3.weight: 0.012645629234611988\n",
      "Gradient for decoder.decoder.3.bias: 9.35028443560526e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00043001415906473994\n",
      "Gradient for decoder.decoder.4.bias: 0.00039467631722800434\n",
      "Gradient for decoder.decoder.6.weight: 0.000798384309746325\n",
      "Gradient for decoder.decoder.6.bias: 4.3052074033766985e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.031226981431245804\n",
      "Gradient for encoder.encoder.0.bias: 5.325137900080712e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.003473583608865738\n",
      "Gradient for encoder.encoder.1.bias: 0.0026300002355128527\n",
      "Gradient for encoder.encoder.3.weight: 0.07415939122438431\n",
      "Gradient for encoder.encoder.3.bias: 5.107009259930351e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.009242373518645763\n",
      "Gradient for encoder.encoder.4.bias: 0.010091708973050117\n",
      "Gradient for encoder.mean.weight: 0.11844473332166672\n",
      "Gradient for encoder.mean.bias: 0.007759167347103357\n",
      "Gradient for encoder.log_var.weight: 0.06232646480202675\n",
      "Gradient for encoder.log_var.bias: 0.005089252255856991\n",
      "Gradient for decoder.decoder.0.weight: 0.012311088852584362\n",
      "Gradient for decoder.decoder.0.bias: 1.0922370646815338e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0006650845753028989\n",
      "Gradient for decoder.decoder.1.bias: 0.0004575306084007025\n",
      "Gradient for decoder.decoder.3.weight: 0.01056208461523056\n",
      "Gradient for decoder.decoder.3.bias: 7.774884902556067e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00039977426058612764\n",
      "Gradient for decoder.decoder.4.bias: 0.0003845785104203969\n",
      "Gradient for decoder.decoder.6.weight: 0.0007702993461862206\n",
      "Gradient for decoder.decoder.6.bias: 4.2178606236120686e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.03476390615105629\n",
      "Gradient for encoder.encoder.0.bias: 4.8746447850467334e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.003320849034935236\n",
      "Gradient for encoder.encoder.1.bias: 0.00281768711283803\n",
      "Gradient for encoder.encoder.3.weight: 0.07592137902975082\n",
      "Gradient for encoder.encoder.3.bias: 4.584218837866416e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.010810303501784801\n",
      "Gradient for encoder.encoder.4.bias: 0.008267109282314777\n",
      "Gradient for encoder.mean.weight: 0.14351262152194977\n",
      "Gradient for encoder.mean.bias: 0.005912020802497864\n",
      "Gradient for encoder.log_var.weight: 0.07009837031364441\n",
      "Gradient for encoder.log_var.bias: 0.0032898755744099617\n",
      "Gradient for decoder.decoder.0.weight: 0.013683658093214035\n",
      "Gradient for decoder.decoder.0.bias: 1.2612626221208956e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0006899789441376925\n",
      "Gradient for decoder.decoder.1.bias: 0.0004963089595548809\n",
      "Gradient for decoder.decoder.3.weight: 0.011817503720521927\n",
      "Gradient for decoder.decoder.3.bias: 9.153738877998308e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00043796980753540993\n",
      "Gradient for decoder.decoder.4.bias: 0.0003943094634450972\n",
      "Gradient for decoder.decoder.6.weight: 0.0008458908996544778\n",
      "Gradient for decoder.decoder.6.bias: 5.257741577224806e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.03726167231798172\n",
      "Gradient for encoder.encoder.0.bias: 6.507933775212749e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.006412866059690714\n",
      "Gradient for encoder.encoder.1.bias: 0.004640853498131037\n",
      "Gradient for encoder.encoder.3.weight: 0.13445380330085754\n",
      "Gradient for encoder.encoder.3.bias: 6.30811458623981e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.01647392101585865\n",
      "Gradient for encoder.encoder.4.bias: 0.01230853796005249\n",
      "Gradient for encoder.mean.weight: 0.21385417878627777\n",
      "Gradient for encoder.mean.bias: 0.008757318370044231\n",
      "Gradient for encoder.log_var.weight: 0.12152636051177979\n",
      "Gradient for encoder.log_var.bias: 0.004522806964814663\n",
      "Gradient for decoder.decoder.0.weight: 0.012362324632704258\n",
      "Gradient for decoder.decoder.0.bias: 1.1234034535956283e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.000646420638076961\n",
      "Gradient for decoder.decoder.1.bias: 0.00048250233521685004\n",
      "Gradient for decoder.decoder.3.weight: 0.010796500369906425\n",
      "Gradient for decoder.decoder.3.bias: 8.483826141603146e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0005137313273735344\n",
      "Gradient for decoder.decoder.4.bias: 0.0005555759416893125\n",
      "Gradient for decoder.decoder.6.weight: 0.0008386821718886495\n",
      "Gradient for decoder.decoder.6.bias: 5.5183449148898944e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.024396872147917747\n",
      "Gradient for encoder.encoder.0.bias: 3.770210185716216e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0028290916234254837\n",
      "Gradient for encoder.encoder.1.bias: 0.0023743468336760998\n",
      "Gradient for encoder.encoder.3.weight: 0.06253398954868317\n",
      "Gradient for encoder.encoder.3.bias: 4.4195197501650796e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.009533235803246498\n",
      "Gradient for encoder.encoder.4.bias: 0.008546401746571064\n",
      "Gradient for encoder.mean.weight: 0.1237916499376297\n",
      "Gradient for encoder.mean.bias: 0.005992107558995485\n",
      "Gradient for encoder.log_var.weight: 0.06468751281499863\n",
      "Gradient for encoder.log_var.bias: 0.0030827701557427645\n",
      "Gradient for decoder.decoder.0.weight: 0.015456536784768105\n",
      "Gradient for decoder.decoder.0.bias: 1.2899784018749472e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0007777420687489212\n",
      "Gradient for decoder.decoder.1.bias: 0.0005631781532429159\n",
      "Gradient for decoder.decoder.3.weight: 0.013284092769026756\n",
      "Gradient for decoder.decoder.3.bias: 1.1045780956564499e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0005200438317842782\n",
      "Gradient for decoder.decoder.4.bias: 0.0005018325173296034\n",
      "Gradient for decoder.decoder.6.weight: 0.0008931552874855697\n",
      "Gradient for decoder.decoder.6.bias: 5.487849557539448e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training VAE Epoch:  92%|█████████▏| 73/79 [00:01<00:00, 75.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient for encoder.encoder.0.weight: 0.028294885531067848\n",
      "Gradient for encoder.encoder.0.bias: 4.3596716514660017e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0040623401291668415\n",
      "Gradient for encoder.encoder.1.bias: 0.0030453891959041357\n",
      "Gradient for encoder.encoder.3.weight: 0.0823027566075325\n",
      "Gradient for encoder.encoder.3.bias: 4.106499584821677e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.007908156141638756\n",
      "Gradient for encoder.encoder.4.bias: 0.007746576331555843\n",
      "Gradient for encoder.mean.weight: 0.10518963634967804\n",
      "Gradient for encoder.mean.bias: 0.005977807566523552\n",
      "Gradient for encoder.log_var.weight: 0.06257549673318863\n",
      "Gradient for encoder.log_var.bias: 0.003536282340064645\n",
      "Gradient for decoder.decoder.0.weight: 0.015583496540784836\n",
      "Gradient for decoder.decoder.0.bias: 1.2954234906992212e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0008122749859467149\n",
      "Gradient for decoder.decoder.1.bias: 0.0005687868106178939\n",
      "Gradient for decoder.decoder.3.weight: 0.01323581114411354\n",
      "Gradient for decoder.decoder.3.bias: 9.361557362641548e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0005016855429857969\n",
      "Gradient for decoder.decoder.4.bias: 0.00047715959954075515\n",
      "Gradient for decoder.decoder.6.weight: 0.0007991940947249532\n",
      "Gradient for decoder.decoder.6.bias: 3.6841400287812576e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.021454844623804092\n",
      "Gradient for encoder.encoder.0.bias: 3.410018795113601e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.002917933976277709\n",
      "Gradient for encoder.encoder.1.bias: 0.002470003440976143\n",
      "Gradient for encoder.encoder.3.weight: 0.05985136702656746\n",
      "Gradient for encoder.encoder.3.bias: 3.9170763854734503e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.00669969292357564\n",
      "Gradient for encoder.encoder.4.bias: 0.007673120591789484\n",
      "Gradient for encoder.mean.weight: 0.0910186618566513\n",
      "Gradient for encoder.mean.bias: 0.00630143890157342\n",
      "Gradient for encoder.log_var.weight: 0.04623568803071976\n",
      "Gradient for encoder.log_var.bias: 0.003311276203021407\n",
      "Gradient for decoder.decoder.0.weight: 0.017601126804947853\n",
      "Gradient for decoder.decoder.0.bias: 1.495379930993579e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0009336216608062387\n",
      "Gradient for decoder.decoder.1.bias: 0.0006357933161780238\n",
      "Gradient for decoder.decoder.3.weight: 0.01532556489109993\n",
      "Gradient for decoder.decoder.3.bias: 1.1613209005556513e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0005841778474859893\n",
      "Gradient for decoder.decoder.4.bias: 0.0005786948604509234\n",
      "Gradient for decoder.decoder.6.weight: 0.0008484334102831781\n",
      "Gradient for decoder.decoder.6.bias: 4.487023761612363e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.020250864326953888\n",
      "Gradient for encoder.encoder.0.bias: 3.566443321223467e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.002806339878588915\n",
      "Gradient for encoder.encoder.1.bias: 0.002619008533656597\n",
      "Gradient for encoder.encoder.3.weight: 0.06171196699142456\n",
      "Gradient for encoder.encoder.3.bias: 4.707779721613292e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.00914466567337513\n",
      "Gradient for encoder.encoder.4.bias: 0.011116533540189266\n",
      "Gradient for encoder.mean.weight: 0.11077293753623962\n",
      "Gradient for encoder.mean.bias: 0.008644921705126762\n",
      "Gradient for encoder.log_var.weight: 0.07508589327335358\n",
      "Gradient for encoder.log_var.bias: 0.006154397036880255\n",
      "Gradient for decoder.decoder.0.weight: 0.01414246205240488\n",
      "Gradient for decoder.decoder.0.bias: 1.2010756278435508e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0007777033606544137\n",
      "Gradient for decoder.decoder.1.bias: 0.0005170737858861685\n",
      "Gradient for decoder.decoder.3.weight: 0.012887414544820786\n",
      "Gradient for decoder.decoder.3.bias: 9.518233423655431e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00047359924064949155\n",
      "Gradient for decoder.decoder.4.bias: 0.0003887830243911594\n",
      "Gradient for decoder.decoder.6.weight: 0.0007968200952745974\n",
      "Gradient for decoder.decoder.6.bias: 4.002411515102722e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.028375448659062386\n",
      "Gradient for encoder.encoder.0.bias: 4.383822818643246e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0035508815199136734\n",
      "Gradient for encoder.encoder.1.bias: 0.002919297432526946\n",
      "Gradient for encoder.encoder.3.weight: 0.07626505196094513\n",
      "Gradient for encoder.encoder.3.bias: 5.013887083293866e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.007917099632322788\n",
      "Gradient for encoder.encoder.4.bias: 0.009121177718043327\n",
      "Gradient for encoder.mean.weight: 0.10020504891872406\n",
      "Gradient for encoder.mean.bias: 0.006746575701981783\n",
      "Gradient for encoder.log_var.weight: 0.065656878054142\n",
      "Gradient for encoder.log_var.bias: 0.004861293826252222\n",
      "Gradient for decoder.decoder.0.weight: 0.012989545240998268\n",
      "Gradient for decoder.decoder.0.bias: 1.1415133421843748e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0007105262484401464\n",
      "Gradient for decoder.decoder.1.bias: 0.0005143992602825165\n",
      "Gradient for decoder.decoder.3.weight: 0.011563531123101711\n",
      "Gradient for decoder.decoder.3.bias: 8.704804238535147e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00040025258203968406\n",
      "Gradient for decoder.decoder.4.bias: 0.0003418860724195838\n",
      "Gradient for decoder.decoder.6.weight: 0.0008171239169314504\n",
      "Gradient for decoder.decoder.6.bias: 4.152684050495736e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.031774114817380905\n",
      "Gradient for encoder.encoder.0.bias: 4.988779875314542e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.003766086883842945\n",
      "Gradient for encoder.encoder.1.bias: 0.0027230370324105024\n",
      "Gradient for encoder.encoder.3.weight: 0.08203651010990143\n",
      "Gradient for encoder.encoder.3.bias: 5.066024266753288e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.012370179407298565\n",
      "Gradient for encoder.encoder.4.bias: 0.009915709495544434\n",
      "Gradient for encoder.mean.weight: 0.14581210911273956\n",
      "Gradient for encoder.mean.bias: 0.00766720762476325\n",
      "Gradient for encoder.log_var.weight: 0.09948806464672089\n",
      "Gradient for encoder.log_var.bias: 0.005021530669182539\n",
      "Gradient for decoder.decoder.0.weight: 0.015019441954791546\n",
      "Gradient for decoder.decoder.0.bias: 1.3277026700286854e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0008379887440241873\n",
      "Gradient for decoder.decoder.1.bias: 0.0005415690247900784\n",
      "Gradient for decoder.decoder.3.weight: 0.01344042643904686\n",
      "Gradient for decoder.decoder.3.bias: 1.0499821151421784e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.00048492359928786755\n",
      "Gradient for decoder.decoder.4.bias: 0.00043161524808965623\n",
      "Gradient for decoder.decoder.6.weight: 0.0008527101017534733\n",
      "Gradient for decoder.decoder.6.bias: 5.158183921594173e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.040862005203962326\n",
      "Gradient for encoder.encoder.0.bias: 6.425494164519208e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.004689787048846483\n",
      "Gradient for encoder.encoder.1.bias: 0.0036031133495271206\n",
      "Gradient for encoder.encoder.3.weight: 0.10364583134651184\n",
      "Gradient for encoder.encoder.3.bias: 6.527142160095423e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.011453025974333286\n",
      "Gradient for encoder.encoder.4.bias: 0.011166868731379509\n",
      "Gradient for encoder.mean.weight: 0.1438838392496109\n",
      "Gradient for encoder.mean.bias: 0.007078893482685089\n",
      "Gradient for encoder.log_var.weight: 0.07720499485731125\n",
      "Gradient for encoder.log_var.bias: 0.003681434551253915\n",
      "Gradient for decoder.decoder.0.weight: 0.011503337882459164\n",
      "Gradient for decoder.decoder.0.bias: 9.788535954013966e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005793992895632982\n",
      "Gradient for decoder.decoder.1.bias: 0.0004352265386842191\n",
      "Gradient for decoder.decoder.3.weight: 0.009603087790310383\n",
      "Gradient for decoder.decoder.3.bias: 8.150236041615244e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00036847355659119785\n",
      "Gradient for decoder.decoder.4.bias: 0.0003402249130886048\n",
      "Gradient for decoder.decoder.6.weight: 0.0007653905777260661\n",
      "Gradient for decoder.decoder.6.bias: 4.045161767862737e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.023357588797807693\n",
      "Gradient for encoder.encoder.0.bias: 3.6811328291141976e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0034298314712941647\n",
      "Gradient for encoder.encoder.1.bias: 0.002897195750847459\n",
      "Gradient for encoder.encoder.3.weight: 0.0746523067355156\n",
      "Gradient for encoder.encoder.3.bias: 4.1671410766497274e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.009203520603477955\n",
      "Gradient for encoder.encoder.4.bias: 0.008806644007563591\n",
      "Gradient for encoder.mean.weight: 0.11458612978458405\n",
      "Gradient for encoder.mean.bias: 0.006439968943595886\n",
      "Gradient for encoder.log_var.weight: 0.06900553405284882\n",
      "Gradient for encoder.log_var.bias: 0.0038452125154435635\n",
      "Gradient for decoder.decoder.0.weight: 0.017043979838490486\n",
      "Gradient for decoder.decoder.0.bias: 1.3921044872411414e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0009263865067623556\n",
      "Gradient for decoder.decoder.1.bias: 0.0006684582331217825\n",
      "Gradient for decoder.decoder.3.weight: 0.01495775580406189\n",
      "Gradient for decoder.decoder.3.bias: 1.1466916999269827e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0006661585066467524\n",
      "Gradient for decoder.decoder.4.bias: 0.0007474272279068828\n",
      "Gradient for decoder.decoder.6.weight: 0.0008616787963546813\n",
      "Gradient for decoder.decoder.6.bias: 5.154860264156014e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.02431541122496128\n",
      "Gradient for encoder.encoder.0.bias: 4.010492632433582e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.004466622602194548\n",
      "Gradient for encoder.encoder.1.bias: 0.0036450435873121023\n",
      "Gradient for encoder.encoder.3.weight: 0.09215029329061508\n",
      "Gradient for encoder.encoder.3.bias: 5.808815095598163e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.009236411191523075\n",
      "Gradient for encoder.encoder.4.bias: 0.011885827407240868\n",
      "Gradient for encoder.mean.weight: 0.11593805253505707\n",
      "Gradient for encoder.mean.bias: 0.008544120006263256\n",
      "Gradient for encoder.log_var.weight: 0.07555826008319855\n",
      "Gradient for encoder.log_var.bias: 0.006738587748259306\n",
      "Gradient for decoder.decoder.0.weight: 0.016446808353066444\n",
      "Gradient for decoder.decoder.0.bias: 1.3820795896624105e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0008732525166124105\n",
      "Gradient for decoder.decoder.1.bias: 0.0006098372396081686\n",
      "Gradient for decoder.decoder.3.weight: 0.013900813646614552\n",
      "Gradient for decoder.decoder.3.bias: 1.171246016840044e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0005592129891738296\n",
      "Gradient for decoder.decoder.4.bias: 0.0005653699627146125\n",
      "Gradient for decoder.decoder.6.weight: 0.0008926457958295941\n",
      "Gradient for decoder.decoder.6.bias: 6.0489721363410354e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.031004648655653\n",
      "Gradient for encoder.encoder.0.bias: 4.777742784733974e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.004129971843212843\n",
      "Gradient for encoder.encoder.1.bias: 0.003334872191771865\n",
      "Gradient for encoder.encoder.3.weight: 0.08934303373098373\n",
      "Gradient for encoder.encoder.3.bias: 4.0197531414598586e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.008001809008419514\n",
      "Gradient for encoder.encoder.4.bias: 0.006388045847415924\n",
      "Gradient for encoder.mean.weight: 0.1045314222574234\n",
      "Gradient for encoder.mean.bias: 0.004271626006811857\n",
      "Gradient for encoder.log_var.weight: 0.05953773111104965\n",
      "Gradient for encoder.log_var.bias: 0.0026414080057293177\n",
      "Gradient for decoder.decoder.0.weight: 0.015251503325998783\n",
      "Gradient for decoder.decoder.0.bias: 1.312986941393035e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0008241781033575535\n",
      "Gradient for decoder.decoder.1.bias: 0.0005817190394736826\n",
      "Gradient for decoder.decoder.3.weight: 0.013080107048153877\n",
      "Gradient for decoder.decoder.3.bias: 9.001609180270265e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0005238192388787866\n",
      "Gradient for decoder.decoder.4.bias: 0.0004392169357743114\n",
      "Gradient for decoder.decoder.6.weight: 0.0009348210878670216\n",
      "Gradient for decoder.decoder.6.bias: 5.5291700846282765e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.03409853205084801\n",
      "Gradient for encoder.encoder.0.bias: 5.5759452610715243e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0038370091933757067\n",
      "Gradient for encoder.encoder.1.bias: 0.0030463775619864464\n",
      "Gradient for encoder.encoder.3.weight: 0.08299961686134338\n",
      "Gradient for encoder.encoder.3.bias: 5.43296907462576e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.00987036433070898\n",
      "Gradient for encoder.encoder.4.bias: 0.009543174877762794\n",
      "Gradient for encoder.mean.weight: 0.12490542978048325\n",
      "Gradient for encoder.mean.bias: 0.006245708558708429\n",
      "Gradient for encoder.log_var.weight: 0.07616535574197769\n",
      "Gradient for encoder.log_var.bias: 0.004379499237984419\n",
      "Gradient for decoder.decoder.0.weight: 0.011868471279740334\n",
      "Gradient for decoder.decoder.0.bias: 9.539125045421315e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0006913061952218413\n",
      "Gradient for decoder.decoder.1.bias: 0.00047276608529500663\n",
      "Gradient for decoder.decoder.3.weight: 0.010523630306124687\n",
      "Gradient for decoder.decoder.3.bias: 8.220344543952152e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0003969745012000203\n",
      "Gradient for decoder.decoder.4.bias: 0.00039997429121285677\n",
      "Gradient for decoder.decoder.6.weight: 0.0007496752077713609\n",
      "Gradient for decoder.decoder.6.bias: 3.96745017496869e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.0331742987036705\n",
      "Gradient for encoder.encoder.0.bias: 4.7903018357553506e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.003911281004548073\n",
      "Gradient for encoder.encoder.1.bias: 0.003003043355420232\n",
      "Gradient for encoder.encoder.3.weight: 0.08574178814888\n",
      "Gradient for encoder.encoder.3.bias: 7.313403216357983e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.011017276905477047\n",
      "Gradient for encoder.encoder.4.bias: 0.011578284204006195\n",
      "Gradient for encoder.mean.weight: 0.14110954105854034\n",
      "Gradient for encoder.mean.bias: 0.00751784723252058\n",
      "Gradient for encoder.log_var.weight: 0.08485431969165802\n",
      "Gradient for encoder.log_var.bias: 0.005015568807721138\n",
      "Gradient for decoder.decoder.0.weight: 0.015170903876423836\n",
      "Gradient for decoder.decoder.0.bias: 1.33775546196091e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0007806046633049846\n",
      "Gradient for decoder.decoder.1.bias: 0.0005514079239219427\n",
      "Gradient for decoder.decoder.3.weight: 0.013317764736711979\n",
      "Gradient for decoder.decoder.3.bias: 1.0149255047497974e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0004956728080287576\n",
      "Gradient for decoder.decoder.4.bias: 0.0004761388117913157\n",
      "Gradient for decoder.decoder.6.weight: 0.000754781358409673\n",
      "Gradient for decoder.decoder.6.bias: 3.66124659194611e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.02524513378739357\n",
      "Gradient for encoder.encoder.0.bias: 3.614144053476487e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0036077434197068214\n",
      "Gradient for encoder.encoder.1.bias: 0.0028144894167780876\n",
      "Gradient for encoder.encoder.3.weight: 0.07418637722730637\n",
      "Gradient for encoder.encoder.3.bias: 4.809855846943378e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.007610767614096403\n",
      "Gradient for encoder.encoder.4.bias: 0.009325938299298286\n",
      "Gradient for encoder.mean.weight: 0.10309821367263794\n",
      "Gradient for encoder.mean.bias: 0.0066468240693211555\n",
      "Gradient for encoder.log_var.weight: 0.05490938946604729\n",
      "Gradient for encoder.log_var.bias: 0.0034501031041145325\n",
      "Gradient for decoder.decoder.0.weight: 0.01627521775662899\n",
      "Gradient for decoder.decoder.0.bias: 1.3209031091143686e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0008151571964845061\n",
      "Gradient for decoder.decoder.1.bias: 0.0005921724368818104\n",
      "Gradient for decoder.decoder.3.weight: 0.013944942504167557\n",
      "Gradient for decoder.decoder.3.bias: 1.1372457836555938e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0005526428576558828\n",
      "Gradient for decoder.decoder.4.bias: 0.0005394389154389501\n",
      "Gradient for decoder.decoder.6.weight: 0.0008393962634727359\n",
      "Gradient for decoder.decoder.6.bias: 4.7102315875235945e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.06230895221233368\n",
      "Gradient for encoder.encoder.0.bias: 8.58539836445793e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.007239801809191704\n",
      "Gradient for encoder.encoder.1.bias: 0.005522596184164286\n",
      "Gradient for encoder.encoder.3.weight: 0.15914921462535858\n",
      "Gradient for encoder.encoder.3.bias: 8.790109751188879e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.018540455028414726\n",
      "Gradient for encoder.encoder.4.bias: 0.018439121544361115\n",
      "Gradient for encoder.mean.weight: 0.24091006815433502\n",
      "Gradient for encoder.mean.bias: 0.014034248888492584\n",
      "Gradient for encoder.log_var.weight: 0.16285169124603271\n",
      "Gradient for encoder.log_var.bias: 0.01012987270951271\n",
      "Gradient for decoder.decoder.0.weight: 0.014051275327801704\n",
      "Gradient for decoder.decoder.0.bias: 1.3170260715344995e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0007568954606540501\n",
      "Gradient for decoder.decoder.1.bias: 0.0005715329316444695\n",
      "Gradient for decoder.decoder.3.weight: 0.012354277074337006\n",
      "Gradient for decoder.decoder.3.bias: 1.1077625622357701e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.000457241345429793\n",
      "Gradient for decoder.decoder.4.bias: 0.00042580338777042925\n",
      "Gradient for decoder.decoder.6.weight: 0.0008022725232876837\n",
      "Gradient for decoder.decoder.6.bias: 3.9790887967683375e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.10801240801811218\n",
      "Gradient for encoder.encoder.0.bias: 1.9235428527775156e-10\n",
      "Gradient for encoder.encoder.1.weight: 0.011651264503598213\n",
      "Gradient for encoder.encoder.1.bias: 0.009638126008212566\n",
      "Gradient for encoder.encoder.3.weight: 0.24773259460926056\n",
      "Gradient for encoder.encoder.3.bias: 2.0442314507818082e-09\n",
      "Gradient for encoder.encoder.4.weight: 0.034271493554115295\n",
      "Gradient for encoder.encoder.4.bias: 0.034860655665397644\n",
      "Gradient for encoder.mean.weight: 0.4127326011657715\n",
      "Gradient for encoder.mean.bias: 0.028096292167901993\n",
      "Gradient for encoder.log_var.weight: 0.27103951573371887\n",
      "Gradient for encoder.log_var.bias: 0.01924515888094902\n",
      "Gradient for decoder.decoder.0.weight: 0.046955183148384094\n",
      "Gradient for decoder.decoder.0.bias: 3.357903677336793e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.002146318554878235\n",
      "Gradient for decoder.decoder.1.bias: 0.0017352739814668894\n",
      "Gradient for decoder.decoder.3.weight: 0.040329717099666595\n",
      "Gradient for decoder.decoder.3.bias: 3.2470925948047125e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.002196827670559287\n",
      "Gradient for decoder.decoder.4.bias: 0.002484104596078396\n",
      "Gradient for decoder.decoder.6.weight: 0.002921604784205556\n",
      "Gradient for decoder.decoder.6.bias: 0.00019943210645578802\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/3, Train Loss: 0.0899, Val Loss: 0.3998\n",
      "Training VAE for class 2...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training VAE Epoch:  11%|█▏        | 9/79 [00:00<00:01, 37.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient for encoder.encoder.0.weight: 0.035512663424015045\n",
      "Gradient for encoder.encoder.0.bias: 6.047223138905267e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0050111557357013226\n",
      "Gradient for encoder.encoder.1.bias: 0.004164988175034523\n",
      "Gradient for encoder.encoder.3.weight: 0.11080105602741241\n",
      "Gradient for encoder.encoder.3.bias: 6.737637114895279e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.01300602313131094\n",
      "Gradient for encoder.encoder.4.bias: 0.014054947532713413\n",
      "Gradient for encoder.mean.weight: 0.16061916947364807\n",
      "Gradient for encoder.mean.bias: 0.0102977454662323\n",
      "Gradient for encoder.log_var.weight: 0.10003745555877686\n",
      "Gradient for encoder.log_var.bias: 0.007576556410640478\n",
      "Gradient for decoder.decoder.0.weight: 0.015225695446133614\n",
      "Gradient for decoder.decoder.0.bias: 1.2422179951343537e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.000835742219351232\n",
      "Gradient for decoder.decoder.1.bias: 0.0005594522226601839\n",
      "Gradient for decoder.decoder.3.weight: 0.013707581907510757\n",
      "Gradient for decoder.decoder.3.bias: 1.0727742999483425e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0004982438986189663\n",
      "Gradient for decoder.decoder.4.bias: 0.00042849924648180604\n",
      "Gradient for decoder.decoder.6.weight: 0.000987290870398283\n",
      "Gradient for decoder.decoder.6.bias: 8.245595381595194e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.04876237362623215\n",
      "Gradient for encoder.encoder.0.bias: 5.732427033056098e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.005975431762635708\n",
      "Gradient for encoder.encoder.1.bias: 0.004528571851551533\n",
      "Gradient for encoder.encoder.3.weight: 0.1340288668870926\n",
      "Gradient for encoder.encoder.3.bias: 7.943682378552808e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.01854507438838482\n",
      "Gradient for encoder.encoder.4.bias: 0.01534769032150507\n",
      "Gradient for encoder.mean.weight: 0.23555919528007507\n",
      "Gradient for encoder.mean.bias: 0.009308570995926857\n",
      "Gradient for encoder.log_var.weight: 0.1367609053850174\n",
      "Gradient for encoder.log_var.bias: 0.0052861846052110195\n",
      "Gradient for decoder.decoder.0.weight: 0.017342478036880493\n",
      "Gradient for decoder.decoder.0.bias: 1.6009044090381508e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0009334004134871066\n",
      "Gradient for decoder.decoder.1.bias: 0.0006690940354019403\n",
      "Gradient for decoder.decoder.3.weight: 0.015315293334424496\n",
      "Gradient for decoder.decoder.3.bias: 1.204302629842502e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0005533660296350718\n",
      "Gradient for decoder.decoder.4.bias: 0.0005037849768996239\n",
      "Gradient for decoder.decoder.6.weight: 0.0009841839782893658\n",
      "Gradient for decoder.decoder.6.bias: 8.010763122001663e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.04489845409989357\n",
      "Gradient for encoder.encoder.0.bias: 7.227733689330051e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.006034960970282555\n",
      "Gradient for encoder.encoder.1.bias: 0.004200412426143885\n",
      "Gradient for encoder.encoder.3.weight: 0.13052065670490265\n",
      "Gradient for encoder.encoder.3.bias: 5.723947427149767e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.014659919776022434\n",
      "Gradient for encoder.encoder.4.bias: 0.012673660181462765\n",
      "Gradient for encoder.mean.weight: 0.19076727330684662\n",
      "Gradient for encoder.mean.bias: 0.008506815880537033\n",
      "Gradient for encoder.log_var.weight: 0.11354764550924301\n",
      "Gradient for encoder.log_var.bias: 0.004829375538975\n",
      "Gradient for decoder.decoder.0.weight: 0.012356286868453026\n",
      "Gradient for decoder.decoder.0.bias: 1.060432505695097e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0006669046706520021\n",
      "Gradient for decoder.decoder.1.bias: 0.00047729373909533024\n",
      "Gradient for decoder.decoder.3.weight: 0.010819032788276672\n",
      "Gradient for decoder.decoder.3.bias: 1.2901196777548307e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0010292991064488888\n",
      "Gradient for decoder.decoder.4.bias: 0.0013030128320679069\n",
      "Gradient for decoder.decoder.6.weight: 0.001374205807223916\n",
      "Gradient for decoder.decoder.6.bias: 0.00013841055624652654\n",
      "Gradient for encoder.encoder.0.weight: 0.029761716723442078\n",
      "Gradient for encoder.encoder.0.bias: 5.0530954420757723e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.004600465297698975\n",
      "Gradient for encoder.encoder.1.bias: 0.0036938146222382784\n",
      "Gradient for encoder.encoder.3.weight: 0.10445259511470795\n",
      "Gradient for encoder.encoder.3.bias: 7.51058326642351e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.012655229307711124\n",
      "Gradient for encoder.encoder.4.bias: 0.013041162863373756\n",
      "Gradient for encoder.mean.weight: 0.16669240593910217\n",
      "Gradient for encoder.mean.bias: 0.010108931921422482\n",
      "Gradient for encoder.log_var.weight: 0.09660393744707108\n",
      "Gradient for encoder.log_var.bias: 0.005657760426402092\n",
      "Gradient for decoder.decoder.0.weight: 0.016888758167624474\n",
      "Gradient for decoder.decoder.0.bias: 1.3826742528699754e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0009067314094863832\n",
      "Gradient for decoder.decoder.1.bias: 0.0006802708376199007\n",
      "Gradient for decoder.decoder.3.weight: 0.014677423052489758\n",
      "Gradient for decoder.decoder.3.bias: 1.2171777474812018e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0005725803202949464\n",
      "Gradient for decoder.decoder.4.bias: 0.0005078455433249474\n",
      "Gradient for decoder.decoder.6.weight: 0.0010292743099853396\n",
      "Gradient for decoder.decoder.6.bias: 8.818164496915415e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.033225785940885544\n",
      "Gradient for encoder.encoder.0.bias: 4.548198970222295e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.004419961012899876\n",
      "Gradient for encoder.encoder.1.bias: 0.00384231167845428\n",
      "Gradient for encoder.encoder.3.weight: 0.09759445488452911\n",
      "Gradient for encoder.encoder.3.bias: 7.117140210510797e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.013120734132826328\n",
      "Gradient for encoder.encoder.4.bias: 0.013142176903784275\n",
      "Gradient for encoder.mean.weight: 0.17455221712589264\n",
      "Gradient for encoder.mean.bias: 0.010786427184939384\n",
      "Gradient for encoder.log_var.weight: 0.10339631885290146\n",
      "Gradient for encoder.log_var.bias: 0.006284060422331095\n",
      "Gradient for decoder.decoder.0.weight: 0.020493995398283005\n",
      "Gradient for decoder.decoder.0.bias: 1.7690786335844422e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0010308267083019018\n",
      "Gradient for decoder.decoder.1.bias: 0.0007663440774194896\n",
      "Gradient for decoder.decoder.3.weight: 0.01755872182548046\n",
      "Gradient for decoder.decoder.3.bias: 1.2670325899577506e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0005910060717724264\n",
      "Gradient for decoder.decoder.4.bias: 0.000551679462660104\n",
      "Gradient for decoder.decoder.6.weight: 0.0009778918465599418\n",
      "Gradient for decoder.decoder.6.bias: 7.524358807131648e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.032734114676713943\n",
      "Gradient for encoder.encoder.0.bias: 4.630994546173106e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.004055970348417759\n",
      "Gradient for encoder.encoder.1.bias: 0.003354682819917798\n",
      "Gradient for encoder.encoder.3.weight: 0.08662648499011993\n",
      "Gradient for encoder.encoder.3.bias: 5.480377818223303e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.009475178085267544\n",
      "Gradient for encoder.encoder.4.bias: 0.010626140981912613\n",
      "Gradient for encoder.mean.weight: 0.12803496420383453\n",
      "Gradient for encoder.mean.bias: 0.008518749848008156\n",
      "Gradient for encoder.log_var.weight: 0.07224328815937042\n",
      "Gradient for encoder.log_var.bias: 0.004692641086876392\n",
      "Gradient for decoder.decoder.0.weight: 0.013194659724831581\n",
      "Gradient for decoder.decoder.0.bias: 1.0336503181163081e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0006599110784009099\n",
      "Gradient for decoder.decoder.1.bias: 0.0004895370802842081\n",
      "Gradient for decoder.decoder.3.weight: 0.011424285359680653\n",
      "Gradient for decoder.decoder.3.bias: 1.3817950950123503e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0009076666901819408\n",
      "Gradient for decoder.decoder.4.bias: 0.0011226467322558165\n",
      "Gradient for decoder.decoder.6.weight: 0.001194659387692809\n",
      "Gradient for decoder.decoder.6.bias: 0.00011581483704503626\n",
      "Gradient for encoder.encoder.0.weight: 0.039326053112745285\n",
      "Gradient for encoder.encoder.0.bias: 5.859163848542792e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.005353628192096949\n",
      "Gradient for encoder.encoder.1.bias: 0.00391807546839118\n",
      "Gradient for encoder.encoder.3.weight: 0.10301985591650009\n",
      "Gradient for encoder.encoder.3.bias: 7.3846967429958e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.013190214522182941\n",
      "Gradient for encoder.encoder.4.bias: 0.013312121853232384\n",
      "Gradient for encoder.mean.weight: 0.1711794137954712\n",
      "Gradient for encoder.mean.bias: 0.009745800867676735\n",
      "Gradient for encoder.log_var.weight: 0.09941299259662628\n",
      "Gradient for encoder.log_var.bias: 0.005477794446051121\n",
      "Gradient for decoder.decoder.0.weight: 0.01485994178801775\n",
      "Gradient for decoder.decoder.0.bias: 1.2169999730193837e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0007861970807425678\n",
      "Gradient for decoder.decoder.1.bias: 0.0005474393256008625\n",
      "Gradient for decoder.decoder.3.weight: 0.01320990826934576\n",
      "Gradient for decoder.decoder.3.bias: 9.882918095005522e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0005591006483882666\n",
      "Gradient for decoder.decoder.4.bias: 0.000577396887820214\n",
      "Gradient for decoder.decoder.6.weight: 0.0010543353855609894\n",
      "Gradient for decoder.decoder.6.bias: 9.384755685459822e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.04640138894319534\n",
      "Gradient for encoder.encoder.0.bias: 5.3834828955823255e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.006883583497256041\n",
      "Gradient for encoder.encoder.1.bias: 0.004529585596174002\n",
      "Gradient for encoder.encoder.3.weight: 0.13280022144317627\n",
      "Gradient for encoder.encoder.3.bias: 6.456210011052121e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.011804923415184021\n",
      "Gradient for encoder.encoder.4.bias: 0.014701642096042633\n",
      "Gradient for encoder.mean.weight: 0.1503545492887497\n",
      "Gradient for encoder.mean.bias: 0.011254933662712574\n",
      "Gradient for encoder.log_var.weight: 0.09360356628894806\n",
      "Gradient for encoder.log_var.bias: 0.0079759256914258\n",
      "Gradient for decoder.decoder.0.weight: 0.018298864364624023\n",
      "Gradient for decoder.decoder.0.bias: 1.3922549224609782e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.001047142781317234\n",
      "Gradient for decoder.decoder.1.bias: 0.0007127543794922531\n",
      "Gradient for decoder.decoder.3.weight: 0.01607666164636612\n",
      "Gradient for decoder.decoder.3.bias: 1.2876398558514524e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0007474053418263793\n",
      "Gradient for decoder.decoder.4.bias: 0.0008221918251365423\n",
      "Gradient for decoder.decoder.6.weight: 0.001121765119023621\n",
      "Gradient for decoder.decoder.6.bias: 0.00010463965736562386\n",
      "Gradient for encoder.encoder.0.weight: 0.06610880047082901\n",
      "Gradient for encoder.encoder.0.bias: 1.0087977675432569e-10\n",
      "Gradient for encoder.encoder.1.weight: 0.008521722629666328\n",
      "Gradient for encoder.encoder.1.bias: 0.005946046207100153\n",
      "Gradient for encoder.encoder.3.weight: 0.16490651667118073\n",
      "Gradient for encoder.encoder.3.bias: 8.653588956519798e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.015229638665914536\n",
      "Gradient for encoder.encoder.4.bias: 0.014378772117197514\n",
      "Gradient for encoder.mean.weight: 0.19276145100593567\n",
      "Gradient for encoder.mean.bias: 0.008833561092615128\n",
      "Gradient for encoder.log_var.weight: 0.10997669398784637\n",
      "Gradient for encoder.log_var.bias: 0.005650026258081198\n",
      "Gradient for decoder.decoder.0.weight: 0.015765462070703506\n",
      "Gradient for decoder.decoder.0.bias: 1.4249097735063998e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.000862942892126739\n",
      "Gradient for decoder.decoder.1.bias: 0.0006045977352187037\n",
      "Gradient for decoder.decoder.3.weight: 0.014030720107257366\n",
      "Gradient for decoder.decoder.3.bias: 1.2583495356821572e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0007479547639377415\n",
      "Gradient for decoder.decoder.4.bias: 0.0008803883101791143\n",
      "Gradient for decoder.decoder.6.weight: 0.0010420415783300996\n",
      "Gradient for decoder.decoder.6.bias: 9.334435890195891e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.03198045864701271\n",
      "Gradient for encoder.encoder.0.bias: 4.809947579120788e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.005582899320870638\n",
      "Gradient for encoder.encoder.1.bias: 0.004323769826442003\n",
      "Gradient for encoder.encoder.3.weight: 0.11756981164216995\n",
      "Gradient for encoder.encoder.3.bias: 5.729091090422855e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.012520473450422287\n",
      "Gradient for encoder.encoder.4.bias: 0.013619968667626381\n",
      "Gradient for encoder.mean.weight: 0.16429246962070465\n",
      "Gradient for encoder.mean.bias: 0.008675744757056236\n",
      "Gradient for encoder.log_var.weight: 0.0995238795876503\n",
      "Gradient for encoder.log_var.bias: 0.006770238745957613\n",
      "Gradient for decoder.decoder.0.weight: 0.0164905097335577\n",
      "Gradient for decoder.decoder.0.bias: 1.5240296524776653e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.00088690803386271\n",
      "Gradient for decoder.decoder.1.bias: 0.0006756625371053815\n",
      "Gradient for decoder.decoder.3.weight: 0.014454790391027927\n",
      "Gradient for decoder.decoder.3.bias: 1.360105222891761e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.000706688326317817\n",
      "Gradient for decoder.decoder.4.bias: 0.0007857916643843055\n",
      "Gradient for decoder.decoder.6.weight: 0.0009931519161909819\n",
      "Gradient for decoder.decoder.6.bias: 8.556527609471232e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.034559816122055054\n",
      "Gradient for encoder.encoder.0.bias: 6.217071996106327e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.004799311049282551\n",
      "Gradient for encoder.encoder.1.bias: 0.003641311777755618\n",
      "Gradient for encoder.encoder.3.weight: 0.09974311292171478\n",
      "Gradient for encoder.encoder.3.bias: 5.504853239912677e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.011061876080930233\n",
      "Gradient for encoder.encoder.4.bias: 0.00969824381172657\n",
      "Gradient for encoder.mean.weight: 0.1428595781326294\n",
      "Gradient for encoder.mean.bias: 0.0068326606415212154\n",
      "Gradient for encoder.log_var.weight: 0.07920455932617188\n",
      "Gradient for encoder.log_var.bias: 0.0035289020743221045\n",
      "Gradient for decoder.decoder.0.weight: 0.014517083764076233\n",
      "Gradient for decoder.decoder.0.bias: 1.198369320443149e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0007775885751470923\n",
      "Gradient for decoder.decoder.1.bias: 0.0005351886502467096\n",
      "Gradient for decoder.decoder.3.weight: 0.012500056065618992\n",
      "Gradient for decoder.decoder.3.bias: 1.1379410608247653e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0006130337133072317\n",
      "Gradient for decoder.decoder.4.bias: 0.0006767762824892998\n",
      "Gradient for decoder.decoder.6.weight: 0.0009698710055090487\n",
      "Gradient for decoder.decoder.6.bias: 8.432227332377806e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.043890416622161865\n",
      "Gradient for encoder.encoder.0.bias: 6.558383003341106e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.00504462793469429\n",
      "Gradient for encoder.encoder.1.bias: 0.0038369635585695505\n",
      "Gradient for encoder.encoder.3.weight: 0.11158768087625504\n",
      "Gradient for encoder.encoder.3.bias: 5.902606736718496e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.011140204966068268\n",
      "Gradient for encoder.encoder.4.bias: 0.010277199558913708\n",
      "Gradient for encoder.mean.weight: 0.14650094509124756\n",
      "Gradient for encoder.mean.bias: 0.007281478028744459\n",
      "Gradient for encoder.log_var.weight: 0.08412886410951614\n",
      "Gradient for encoder.log_var.bias: 0.004136388190090656\n",
      "Gradient for decoder.decoder.0.weight: 0.01480154599994421\n",
      "Gradient for decoder.decoder.0.bias: 1.2413842176428602e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0008216631831601262\n",
      "Gradient for decoder.decoder.1.bias: 0.0006195968016982079\n",
      "Gradient for decoder.decoder.3.weight: 0.013638326898217201\n",
      "Gradient for decoder.decoder.3.bias: 1.0719904824929571e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.000502012437209487\n",
      "Gradient for decoder.decoder.4.bias: 0.0004912117146886885\n",
      "Gradient for decoder.decoder.6.weight: 0.0009004368330352008\n",
      "Gradient for decoder.decoder.6.bias: 7.351023668888956e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.02983289398252964\n",
      "Gradient for encoder.encoder.0.bias: 5.1833749098451065e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0054501378908753395\n",
      "Gradient for encoder.encoder.1.bias: 0.004060780163854361\n",
      "Gradient for encoder.encoder.3.weight: 0.11177318543195724\n",
      "Gradient for encoder.encoder.3.bias: 5.158325433463062e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.011063387617468834\n",
      "Gradient for encoder.encoder.4.bias: 0.010347300209105015\n",
      "Gradient for encoder.mean.weight: 0.1477063000202179\n",
      "Gradient for encoder.mean.bias: 0.006574028171598911\n",
      "Gradient for encoder.log_var.weight: 0.0891999676823616\n",
      "Gradient for encoder.log_var.bias: 0.004857752006500959\n",
      "Gradient for decoder.decoder.0.weight: 0.015562331303954124\n",
      "Gradient for decoder.decoder.0.bias: 1.295220458663593e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0008100027916952968\n",
      "Gradient for decoder.decoder.1.bias: 0.0005947755416855216\n",
      "Gradient for decoder.decoder.3.weight: 0.014243260957300663\n",
      "Gradient for decoder.decoder.3.bias: 1.190079701451907e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.000679398188367486\n",
      "Gradient for decoder.decoder.4.bias: 0.0007310929941013455\n",
      "Gradient for decoder.decoder.6.weight: 0.0009704994736239314\n",
      "Gradient for decoder.decoder.6.bias: 8.138248813338578e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.02452368661761284\n",
      "Gradient for encoder.encoder.0.bias: 4.1365619263267206e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.005032381974160671\n",
      "Gradient for encoder.encoder.1.bias: 0.003307243576273322\n",
      "Gradient for encoder.encoder.3.weight: 0.09896208345890045\n",
      "Gradient for encoder.encoder.3.bias: 4.594249147782392e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.010626818053424358\n",
      "Gradient for encoder.encoder.4.bias: 0.010159228928387165\n",
      "Gradient for encoder.mean.weight: 0.14194299280643463\n",
      "Gradient for encoder.mean.bias: 0.006449612323194742\n",
      "Gradient for encoder.log_var.weight: 0.08009164035320282\n",
      "Gradient for encoder.log_var.bias: 0.004609599243849516\n",
      "Gradient for decoder.decoder.0.weight: 0.018726114183664322\n",
      "Gradient for decoder.decoder.0.bias: 1.5379744700005915e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.000959911267273128\n",
      "Gradient for decoder.decoder.1.bias: 0.0006826729513704777\n",
      "Gradient for decoder.decoder.3.weight: 0.016100944951176643\n",
      "Gradient for decoder.decoder.3.bias: 1.2264533832961888e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0005871217581443489\n",
      "Gradient for decoder.decoder.4.bias: 0.0005028362502343953\n",
      "Gradient for decoder.decoder.6.weight: 0.000772812229115516\n",
      "Gradient for decoder.decoder.6.bias: 4.945117689203471e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.03786330670118332\n",
      "Gradient for encoder.encoder.0.bias: 5.815859599467288e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.004128501750528812\n",
      "Gradient for encoder.encoder.1.bias: 0.0030959530267864466\n",
      "Gradient for encoder.encoder.3.weight: 0.09307976067066193\n",
      "Gradient for encoder.encoder.3.bias: 5.486449072833466e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.010746559128165245\n",
      "Gradient for encoder.encoder.4.bias: 0.00915688369423151\n",
      "Gradient for encoder.mean.weight: 0.133890762925148\n",
      "Gradient for encoder.mean.bias: 0.006999057251960039\n",
      "Gradient for encoder.log_var.weight: 0.07461413741111755\n",
      "Gradient for encoder.log_var.bias: 0.0050463080406188965\n",
      "Gradient for decoder.decoder.0.weight: 0.014837645925581455\n",
      "Gradient for decoder.decoder.0.bias: 1.2195126852798666e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0006903414614498615\n",
      "Gradient for decoder.decoder.1.bias: 0.0005606623599305749\n",
      "Gradient for decoder.decoder.3.weight: 0.012594655156135559\n",
      "Gradient for decoder.decoder.3.bias: 1.1591363979768232e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0006893248646520078\n",
      "Gradient for decoder.decoder.4.bias: 0.0007572227623313665\n",
      "Gradient for decoder.decoder.6.weight: 0.000996678019873798\n",
      "Gradient for decoder.decoder.6.bias: 8.964845619630069e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.055818479508161545\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training VAE Epoch:  32%|███▏      | 25/79 [00:00<00:00, 61.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient for encoder.encoder.0.bias: 8.397802592208237e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0071537792682647705\n",
      "Gradient for encoder.encoder.1.bias: 0.004764815792441368\n",
      "Gradient for encoder.encoder.3.weight: 0.1612204909324646\n",
      "Gradient for encoder.encoder.3.bias: 8.628618375361441e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.018079057335853577\n",
      "Gradient for encoder.encoder.4.bias: 0.012782074511051178\n",
      "Gradient for encoder.mean.weight: 0.22495734691619873\n",
      "Gradient for encoder.mean.bias: 0.007679328788071871\n",
      "Gradient for encoder.log_var.weight: 0.13285574316978455\n",
      "Gradient for encoder.log_var.bias: 0.005247192922979593\n",
      "Gradient for decoder.decoder.0.weight: 0.014824229292571545\n",
      "Gradient for decoder.decoder.0.bias: 1.2032547180851338e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0007452634745277464\n",
      "Gradient for decoder.decoder.1.bias: 0.0005095396772958338\n",
      "Gradient for decoder.decoder.3.weight: 0.013098569586873055\n",
      "Gradient for decoder.decoder.3.bias: 1.0851163023684052e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0006634191959165037\n",
      "Gradient for decoder.decoder.4.bias: 0.0007901823264546692\n",
      "Gradient for decoder.decoder.6.weight: 0.0009916750714182854\n",
      "Gradient for decoder.decoder.6.bias: 9.055875125341117e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.038631975650787354\n",
      "Gradient for encoder.encoder.0.bias: 7.733147455724065e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.00574235524982214\n",
      "Gradient for encoder.encoder.1.bias: 0.0037534674629569054\n",
      "Gradient for encoder.encoder.3.weight: 0.11340890824794769\n",
      "Gradient for encoder.encoder.3.bias: 5.768228117375429e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.011054749600589275\n",
      "Gradient for encoder.encoder.4.bias: 0.010803093202412128\n",
      "Gradient for encoder.mean.weight: 0.14381049573421478\n",
      "Gradient for encoder.mean.bias: 0.007117666304111481\n",
      "Gradient for encoder.log_var.weight: 0.0816010981798172\n",
      "Gradient for encoder.log_var.bias: 0.0041482229717075825\n",
      "Gradient for decoder.decoder.0.weight: 0.012607469223439693\n",
      "Gradient for decoder.decoder.0.bias: 1.093881860092516e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0007081241346895695\n",
      "Gradient for decoder.decoder.1.bias: 0.0004876343591604382\n",
      "Gradient for decoder.decoder.3.weight: 0.011022240854799747\n",
      "Gradient for decoder.decoder.3.bias: 1.0931685417991943e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0006834199884906411\n",
      "Gradient for decoder.decoder.4.bias: 0.0008352103177458048\n",
      "Gradient for decoder.decoder.6.weight: 0.001013486529700458\n",
      "Gradient for decoder.decoder.6.bias: 9.784449503058568e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.03596029803156853\n",
      "Gradient for encoder.encoder.0.bias: 7.099622278960993e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.004128988832235336\n",
      "Gradient for encoder.encoder.1.bias: 0.003127071773633361\n",
      "Gradient for encoder.encoder.3.weight: 0.08595399558544159\n",
      "Gradient for encoder.encoder.3.bias: 6.302486310616473e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.010645232163369656\n",
      "Gradient for encoder.encoder.4.bias: 0.012429323047399521\n",
      "Gradient for encoder.mean.weight: 0.13900704681873322\n",
      "Gradient for encoder.mean.bias: 0.010009814985096455\n",
      "Gradient for encoder.log_var.weight: 0.07641908526420593\n",
      "Gradient for encoder.log_var.bias: 0.005934380926191807\n",
      "Gradient for decoder.decoder.0.weight: 0.012119782157242298\n",
      "Gradient for decoder.decoder.0.bias: 1.0748890666434363e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0006749525782652199\n",
      "Gradient for decoder.decoder.1.bias: 0.0005054116481915116\n",
      "Gradient for decoder.decoder.3.weight: 0.010746236890554428\n",
      "Gradient for decoder.decoder.3.bias: 1.198469101737487e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0007791931857354939\n",
      "Gradient for decoder.decoder.4.bias: 0.0010008777026087046\n",
      "Gradient for decoder.decoder.6.weight: 0.0009899060241878033\n",
      "Gradient for decoder.decoder.6.bias: 9.488131036050618e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.043785735964775085\n",
      "Gradient for encoder.encoder.0.bias: 7.024429649060693e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.005522595252841711\n",
      "Gradient for encoder.encoder.1.bias: 0.004139114171266556\n",
      "Gradient for encoder.encoder.3.weight: 0.11057467013597488\n",
      "Gradient for encoder.encoder.3.bias: 7.152314296376971e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.01576998457312584\n",
      "Gradient for encoder.encoder.4.bias: 0.013257026672363281\n",
      "Gradient for encoder.mean.weight: 0.20372653007507324\n",
      "Gradient for encoder.mean.bias: 0.00697657885029912\n",
      "Gradient for encoder.log_var.weight: 0.11678098887205124\n",
      "Gradient for encoder.log_var.bias: 0.004480644129216671\n",
      "Gradient for decoder.decoder.0.weight: 0.01645652949810028\n",
      "Gradient for decoder.decoder.0.bias: 1.4761403210883373e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0009134869906120002\n",
      "Gradient for decoder.decoder.1.bias: 0.0006463874597102404\n",
      "Gradient for decoder.decoder.3.weight: 0.014879497699439526\n",
      "Gradient for decoder.decoder.3.bias: 1.0936703626063249e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0005412203609012067\n",
      "Gradient for decoder.decoder.4.bias: 0.0004697014519479126\n",
      "Gradient for decoder.decoder.6.weight: 0.0007937396876513958\n",
      "Gradient for decoder.decoder.6.bias: 5.7492146879667416e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.051956385374069214\n",
      "Gradient for encoder.encoder.0.bias: 7.364077403426705e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.006412381771951914\n",
      "Gradient for encoder.encoder.1.bias: 0.0050413282588124275\n",
      "Gradient for encoder.encoder.3.weight: 0.13714846968650818\n",
      "Gradient for encoder.encoder.3.bias: 1.010310279880855e-09\n",
      "Gradient for encoder.encoder.4.weight: 0.01691318303346634\n",
      "Gradient for encoder.encoder.4.bias: 0.01631627418100834\n",
      "Gradient for encoder.mean.weight: 0.21286641061306\n",
      "Gradient for encoder.mean.bias: 0.009532211348414421\n",
      "Gradient for encoder.log_var.weight: 0.13172845542430878\n",
      "Gradient for encoder.log_var.bias: 0.0069616916589438915\n",
      "Gradient for decoder.decoder.0.weight: 0.017310794442892075\n",
      "Gradient for decoder.decoder.0.bias: 1.4786746826978003e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0009358422830700874\n",
      "Gradient for decoder.decoder.1.bias: 0.0006512050749734044\n",
      "Gradient for decoder.decoder.3.weight: 0.01576017215847969\n",
      "Gradient for decoder.decoder.3.bias: 1.1835996072129262e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0006506561185233295\n",
      "Gradient for decoder.decoder.4.bias: 0.0007227903115563095\n",
      "Gradient for decoder.decoder.6.weight: 0.0009018857381306589\n",
      "Gradient for decoder.decoder.6.bias: 7.458539766957983e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.03278927132487297\n",
      "Gradient for encoder.encoder.0.bias: 5.377594897160165e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0040064663626253605\n",
      "Gradient for encoder.encoder.1.bias: 0.0034870828967541456\n",
      "Gradient for encoder.encoder.3.weight: 0.08566218614578247\n",
      "Gradient for encoder.encoder.3.bias: 4.5726988862071494e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.007836873643100262\n",
      "Gradient for encoder.encoder.4.bias: 0.007506740279495716\n",
      "Gradient for encoder.mean.weight: 0.10215587168931961\n",
      "Gradient for encoder.mean.bias: 0.0053174193017184734\n",
      "Gradient for encoder.log_var.weight: 0.05252029374241829\n",
      "Gradient for encoder.log_var.bias: 0.0028549276757985353\n",
      "Gradient for decoder.decoder.0.weight: 0.01607458107173443\n",
      "Gradient for decoder.decoder.0.bias: 1.268878613291946e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0007869293913245201\n",
      "Gradient for decoder.decoder.1.bias: 0.0005864492268301547\n",
      "Gradient for decoder.decoder.3.weight: 0.013840760104358196\n",
      "Gradient for decoder.decoder.3.bias: 1.0957765944619169e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0005483653512783349\n",
      "Gradient for decoder.decoder.4.bias: 0.0005242672632448375\n",
      "Gradient for decoder.decoder.6.weight: 0.0007828833186067641\n",
      "Gradient for decoder.decoder.6.bias: 6.027587005519308e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.04675309360027313\n",
      "Gradient for encoder.encoder.0.bias: 8.439461629539124e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.004586081486195326\n",
      "Gradient for encoder.encoder.1.bias: 0.003582873847335577\n",
      "Gradient for encoder.encoder.3.weight: 0.09857484698295593\n",
      "Gradient for encoder.encoder.3.bias: 5.73299518968895e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.011574110947549343\n",
      "Gradient for encoder.encoder.4.bias: 0.01062333770096302\n",
      "Gradient for encoder.mean.weight: 0.14508354663848877\n",
      "Gradient for encoder.mean.bias: 0.006926041096448898\n",
      "Gradient for encoder.log_var.weight: 0.08328112959861755\n",
      "Gradient for encoder.log_var.bias: 0.003910610917955637\n",
      "Gradient for decoder.decoder.0.weight: 0.014354259707033634\n",
      "Gradient for decoder.decoder.0.bias: 1.391878001744118e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0007561324164271355\n",
      "Gradient for decoder.decoder.1.bias: 0.0005450749304145575\n",
      "Gradient for decoder.decoder.3.weight: 0.01256811898201704\n",
      "Gradient for decoder.decoder.3.bias: 1.177554165288086e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0006177519098855555\n",
      "Gradient for decoder.decoder.4.bias: 0.0006505506462417543\n",
      "Gradient for decoder.decoder.6.weight: 0.000899063132237643\n",
      "Gradient for decoder.decoder.6.bias: 7.870129775255919e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.05503310635685921\n",
      "Gradient for encoder.encoder.0.bias: 1.0519982801548977e-10\n",
      "Gradient for encoder.encoder.1.weight: 0.008134488947689533\n",
      "Gradient for encoder.encoder.1.bias: 0.005932813510298729\n",
      "Gradient for encoder.encoder.3.weight: 0.1642427295446396\n",
      "Gradient for encoder.encoder.3.bias: 7.747149588510638e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.02000339888036251\n",
      "Gradient for encoder.encoder.4.bias: 0.015577162615954876\n",
      "Gradient for encoder.mean.weight: 0.2601158916950226\n",
      "Gradient for encoder.mean.bias: 0.008549305610358715\n",
      "Gradient for encoder.log_var.weight: 0.14728347957134247\n",
      "Gradient for encoder.log_var.bias: 0.006299570668488741\n",
      "Gradient for decoder.decoder.0.weight: 0.012170468457043171\n",
      "Gradient for decoder.decoder.0.bias: 9.630544972605293e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0006429185741581023\n",
      "Gradient for decoder.decoder.1.bias: 0.0004601618566084653\n",
      "Gradient for decoder.decoder.3.weight: 0.010813268832862377\n",
      "Gradient for decoder.decoder.3.bias: 1.0098816921599862e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0007361449534073472\n",
      "Gradient for decoder.decoder.4.bias: 0.0008956885430961847\n",
      "Gradient for decoder.decoder.6.weight: 0.0009451009100303054\n",
      "Gradient for decoder.decoder.6.bias: 8.636957500129938e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.04126718267798424\n",
      "Gradient for encoder.encoder.0.bias: 5.778127282196621e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.006838025525212288\n",
      "Gradient for encoder.encoder.1.bias: 0.004292522091418505\n",
      "Gradient for encoder.encoder.3.weight: 0.13059823215007782\n",
      "Gradient for encoder.encoder.3.bias: 5.459101504179387e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.016960859298706055\n",
      "Gradient for encoder.encoder.4.bias: 0.010860625654459\n",
      "Gradient for encoder.mean.weight: 0.21684901416301727\n",
      "Gradient for encoder.mean.bias: 0.0055289794690907\n",
      "Gradient for encoder.log_var.weight: 0.11208653450012207\n",
      "Gradient for encoder.log_var.bias: 0.0033823284320533276\n",
      "Gradient for decoder.decoder.0.weight: 0.01767568290233612\n",
      "Gradient for decoder.decoder.0.bias: 1.422260503813888e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0009402469731867313\n",
      "Gradient for decoder.decoder.1.bias: 0.0006806867313571274\n",
      "Gradient for decoder.decoder.3.weight: 0.015517895109951496\n",
      "Gradient for decoder.decoder.3.bias: 1.195909898887848e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0005168503266759217\n",
      "Gradient for decoder.decoder.4.bias: 0.0004520051006693393\n",
      "Gradient for decoder.decoder.6.weight: 0.0008064491557888687\n",
      "Gradient for decoder.decoder.6.bias: 6.041384767740965e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.03745022416114807\n",
      "Gradient for encoder.encoder.0.bias: 7.537411667035698e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.00563671812415123\n",
      "Gradient for encoder.encoder.1.bias: 0.003667455166578293\n",
      "Gradient for encoder.encoder.3.weight: 0.10483802109956741\n",
      "Gradient for encoder.encoder.3.bias: 5.16009401874129e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.012729942798614502\n",
      "Gradient for encoder.encoder.4.bias: 0.008951273746788502\n",
      "Gradient for encoder.mean.weight: 0.16289106011390686\n",
      "Gradient for encoder.mean.bias: 0.005520083475857973\n",
      "Gradient for encoder.log_var.weight: 0.09448645263910294\n",
      "Gradient for encoder.log_var.bias: 0.0037537270691245794\n",
      "Gradient for decoder.decoder.0.weight: 0.014127588830888271\n",
      "Gradient for decoder.decoder.0.bias: 1.2706836971521085e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0007756550912745297\n",
      "Gradient for decoder.decoder.1.bias: 0.0005825581029057503\n",
      "Gradient for decoder.decoder.3.weight: 0.012642630375921726\n",
      "Gradient for decoder.decoder.3.bias: 9.509861648160367e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0004688923654612154\n",
      "Gradient for decoder.decoder.4.bias: 0.0004160486569162458\n",
      "Gradient for decoder.decoder.6.weight: 0.0007012001005932689\n",
      "Gradient for decoder.decoder.6.bias: 5.059947943664156e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.047721948474645615\n",
      "Gradient for encoder.encoder.0.bias: 5.922260598589801e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0037828118074685335\n",
      "Gradient for encoder.encoder.1.bias: 0.0026724019553512335\n",
      "Gradient for encoder.encoder.3.weight: 0.08080431073904037\n",
      "Gradient for encoder.encoder.3.bias: 5.261638902354093e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0078002410009503365\n",
      "Gradient for encoder.encoder.4.bias: 0.007195349782705307\n",
      "Gradient for encoder.mean.weight: 0.10283568501472473\n",
      "Gradient for encoder.mean.bias: 0.004857635125517845\n",
      "Gradient for encoder.log_var.weight: 0.05970671772956848\n",
      "Gradient for encoder.log_var.bias: 0.002894554752856493\n",
      "Gradient for decoder.decoder.0.weight: 0.01567501202225685\n",
      "Gradient for decoder.decoder.0.bias: 1.3600576220795801e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0007872447022236884\n",
      "Gradient for decoder.decoder.1.bias: 0.0005785071407444775\n",
      "Gradient for decoder.decoder.3.weight: 0.013798222877085209\n",
      "Gradient for decoder.decoder.3.bias: 1.1186016696251855e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0006769303581677377\n",
      "Gradient for decoder.decoder.4.bias: 0.0007593788322992623\n",
      "Gradient for decoder.decoder.6.weight: 0.0008461312390863895\n",
      "Gradient for decoder.decoder.6.bias: 7.302290759980679e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.039735615253448486\n",
      "Gradient for encoder.encoder.0.bias: 5.290028484705722e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.004743997473269701\n",
      "Gradient for encoder.encoder.1.bias: 0.00349906156770885\n",
      "Gradient for encoder.encoder.3.weight: 0.09750398993492126\n",
      "Gradient for encoder.encoder.3.bias: 6.075399072713594e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.009215711615979671\n",
      "Gradient for encoder.encoder.4.bias: 0.009129814803600311\n",
      "Gradient for encoder.mean.weight: 0.12161577492952347\n",
      "Gradient for encoder.mean.bias: 0.005761211737990379\n",
      "Gradient for encoder.log_var.weight: 0.06346039474010468\n",
      "Gradient for encoder.log_var.bias: 0.003935402724891901\n",
      "Gradient for decoder.decoder.0.weight: 0.01759461686015129\n",
      "Gradient for decoder.decoder.0.bias: 1.5920152696136114e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0009557975572533906\n",
      "Gradient for decoder.decoder.1.bias: 0.0007199884857982397\n",
      "Gradient for decoder.decoder.3.weight: 0.01613316498696804\n",
      "Gradient for decoder.decoder.3.bias: 1.3196491122080545e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0006110124522820115\n",
      "Gradient for decoder.decoder.4.bias: 0.0005376231856644154\n",
      "Gradient for decoder.decoder.6.weight: 0.0008256391738541424\n",
      "Gradient for decoder.decoder.6.bias: 6.421245780074969e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.033780090510845184\n",
      "Gradient for encoder.encoder.0.bias: 5.35750055430384e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.004778491333127022\n",
      "Gradient for encoder.encoder.1.bias: 0.0033167744986712933\n",
      "Gradient for encoder.encoder.3.weight: 0.09795215725898743\n",
      "Gradient for encoder.encoder.3.bias: 5.596131891216771e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.012419263832271099\n",
      "Gradient for encoder.encoder.4.bias: 0.010053910315036774\n",
      "Gradient for encoder.mean.weight: 0.16574950516223907\n",
      "Gradient for encoder.mean.bias: 0.005576987750828266\n",
      "Gradient for encoder.log_var.weight: 0.09952059388160706\n",
      "Gradient for encoder.log_var.bias: 0.003474368480965495\n",
      "Gradient for decoder.decoder.0.weight: 0.015268373303115368\n",
      "Gradient for decoder.decoder.0.bias: 1.4579586149476853e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0007489766576327384\n",
      "Gradient for decoder.decoder.1.bias: 0.0005725522059947252\n",
      "Gradient for decoder.decoder.3.weight: 0.013324321247637272\n",
      "Gradient for decoder.decoder.3.bias: 1.0567453162524387e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.000461608316982165\n",
      "Gradient for decoder.decoder.4.bias: 0.0004455699527170509\n",
      "Gradient for decoder.decoder.6.weight: 0.0006474769324995577\n",
      "Gradient for decoder.decoder.6.bias: 4.2837193177547306e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.02579755336046219\n",
      "Gradient for encoder.encoder.0.bias: 4.1823201152313416e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0032287640497088432\n",
      "Gradient for encoder.encoder.1.bias: 0.002482017735019326\n",
      "Gradient for encoder.encoder.3.weight: 0.069097600877285\n",
      "Gradient for encoder.encoder.3.bias: 4.4560674594684713e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.008409910835325718\n",
      "Gradient for encoder.encoder.4.bias: 0.007763874251395464\n",
      "Gradient for encoder.mean.weight: 0.10662728548049927\n",
      "Gradient for encoder.mean.bias: 0.005551173817366362\n",
      "Gradient for encoder.log_var.weight: 0.05870826542377472\n",
      "Gradient for encoder.log_var.bias: 0.0033717311453074217\n",
      "Gradient for decoder.decoder.0.weight: 0.018273619934916496\n",
      "Gradient for decoder.decoder.0.bias: 1.4591916563944096e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0009728452423587441\n",
      "Gradient for decoder.decoder.1.bias: 0.0007058822084218264\n",
      "Gradient for decoder.decoder.3.weight: 0.016862845048308372\n",
      "Gradient for decoder.decoder.3.bias: 1.1647503794787184e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0005867112777195871\n",
      "Gradient for decoder.decoder.4.bias: 0.0005064827855676413\n",
      "Gradient for decoder.decoder.6.weight: 0.0007235386874526739\n",
      "Gradient for decoder.decoder.6.bias: 4.687166438088752e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.03612585738301277\n",
      "Gradient for encoder.encoder.0.bias: 5.4224697648708187e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.003342194715514779\n",
      "Gradient for encoder.encoder.1.bias: 0.0029389532282948494\n",
      "Gradient for encoder.encoder.3.weight: 0.07472223043441772\n",
      "Gradient for encoder.encoder.3.bias: 5.692022408965158e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0108495419844985\n",
      "Gradient for encoder.encoder.4.bias: 0.008921719156205654\n",
      "Gradient for encoder.mean.weight: 0.1348283588886261\n",
      "Gradient for encoder.mean.bias: 0.006875505670905113\n",
      "Gradient for encoder.log_var.weight: 0.06369487196207047\n",
      "Gradient for encoder.log_var.bias: 0.0036215053405612707\n",
      "Gradient for decoder.decoder.0.weight: 0.015567241236567497\n",
      "Gradient for decoder.decoder.0.bias: 1.3489891148577016e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0008896685903891921\n",
      "Gradient for decoder.decoder.1.bias: 0.0006307585281319916\n",
      "Gradient for decoder.decoder.3.weight: 0.014368166215717793\n",
      "Gradient for decoder.decoder.3.bias: 1.1636223928856992e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0005520456470549107\n",
      "Gradient for decoder.decoder.4.bias: 0.0005074424552731216\n",
      "Gradient for decoder.decoder.6.weight: 0.000780383765231818\n",
      "Gradient for decoder.decoder.6.bias: 5.644787961500697e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.04137517139315605\n",
      "Gradient for encoder.encoder.0.bias: 5.475499567642039e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.00419220793992281\n",
      "Gradient for encoder.encoder.1.bias: 0.003153563942760229\n",
      "Gradient for encoder.encoder.3.weight: 0.087794728577137\n",
      "Gradient for encoder.encoder.3.bias: 6.790421003266545e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.013067320920526981\n",
      "Gradient for encoder.encoder.4.bias: 0.012275074608623981\n",
      "Gradient for encoder.mean.weight: 0.16275374591350555\n",
      "Gradient for encoder.mean.bias: 0.009683772921562195\n",
      "Gradient for encoder.log_var.weight: 0.09490915387868881\n",
      "Gradient for encoder.log_var.bias: 0.007320523727685213\n",
      "Gradient for decoder.decoder.0.weight: 0.018926726654171944\n",
      "Gradient for decoder.decoder.0.bias: 1.574797098280456e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0009620595374144614\n",
      "Gradient for decoder.decoder.1.bias: 0.0006920231389813125\n",
      "Gradient for decoder.decoder.3.weight: 0.016325363889336586\n",
      "Gradient for decoder.decoder.3.bias: 1.3743897686602224e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0005883831763640046\n",
      "Gradient for decoder.decoder.4.bias: 0.0005552534712478518\n",
      "Gradient for decoder.decoder.6.weight: 0.0007391094113700092\n",
      "Gradient for decoder.decoder.6.bias: 5.406737182056531e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training VAE Epoch:  52%|█████▏    | 41/79 [00:00<00:00, 69.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient for encoder.encoder.0.weight: 0.03444471210241318\n",
      "Gradient for encoder.encoder.0.bias: 6.084620307600375e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.005369226913899183\n",
      "Gradient for encoder.encoder.1.bias: 0.004268118180334568\n",
      "Gradient for encoder.encoder.3.weight: 0.12326617538928986\n",
      "Gradient for encoder.encoder.3.bias: 6.646025396683797e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.015065191313624382\n",
      "Gradient for encoder.encoder.4.bias: 0.014542798511683941\n",
      "Gradient for encoder.mean.weight: 0.1863124966621399\n",
      "Gradient for encoder.mean.bias: 0.009101253934204578\n",
      "Gradient for encoder.log_var.weight: 0.1218399628996849\n",
      "Gradient for encoder.log_var.bias: 0.006647586356848478\n",
      "Gradient for decoder.decoder.0.weight: 0.013544649817049503\n",
      "Gradient for decoder.decoder.0.bias: 1.1286830498002942e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0007039596093818545\n",
      "Gradient for decoder.decoder.1.bias: 0.0005608201608993113\n",
      "Gradient for decoder.decoder.3.weight: 0.011952097527682781\n",
      "Gradient for decoder.decoder.3.bias: 1.0690825308357077e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0004118838405702263\n",
      "Gradient for decoder.decoder.4.bias: 0.0003694365150295198\n",
      "Gradient for decoder.decoder.6.weight: 0.0005880419630557299\n",
      "Gradient for decoder.decoder.6.bias: 3.16596997436136e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.04882938042283058\n",
      "Gradient for encoder.encoder.0.bias: 6.506761796032379e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.007786829024553299\n",
      "Gradient for encoder.encoder.1.bias: 0.005660479422658682\n",
      "Gradient for encoder.encoder.3.weight: 0.1606442630290985\n",
      "Gradient for encoder.encoder.3.bias: 6.767031934806766e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.014201287180185318\n",
      "Gradient for encoder.encoder.4.bias: 0.010822526179254055\n",
      "Gradient for encoder.mean.weight: 0.18648438155651093\n",
      "Gradient for encoder.mean.bias: 0.006555979140102863\n",
      "Gradient for encoder.log_var.weight: 0.1062922477722168\n",
      "Gradient for encoder.log_var.bias: 0.004631112329661846\n",
      "Gradient for decoder.decoder.0.weight: 0.016905933618545532\n",
      "Gradient for decoder.decoder.0.bias: 1.5338511016871337e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0008287885575555265\n",
      "Gradient for decoder.decoder.1.bias: 0.0007034302689135075\n",
      "Gradient for decoder.decoder.3.weight: 0.01505504921078682\n",
      "Gradient for decoder.decoder.3.bias: 1.35205527329596e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0005414391052909195\n",
      "Gradient for decoder.decoder.4.bias: 0.0005126542528159916\n",
      "Gradient for decoder.decoder.6.weight: 0.0006502027390524745\n",
      "Gradient for decoder.decoder.6.bias: 3.385183299542405e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.04397827386856079\n",
      "Gradient for encoder.encoder.0.bias: 5.6573568746332015e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.004357330966740847\n",
      "Gradient for encoder.encoder.1.bias: 0.002980234567075968\n",
      "Gradient for encoder.encoder.3.weight: 0.08584559708833694\n",
      "Gradient for encoder.encoder.3.bias: 5.069590858219897e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.009779890067875385\n",
      "Gradient for encoder.encoder.4.bias: 0.008342231623828411\n",
      "Gradient for encoder.mean.weight: 0.12123586982488632\n",
      "Gradient for encoder.mean.bias: 0.005489910952746868\n",
      "Gradient for encoder.log_var.weight: 0.06876083463430405\n",
      "Gradient for encoder.log_var.bias: 0.004006713163107634\n",
      "Gradient for decoder.decoder.0.weight: 0.018002307042479515\n",
      "Gradient for decoder.decoder.0.bias: 1.541493321877141e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0009396800887770951\n",
      "Gradient for decoder.decoder.1.bias: 0.0006862717564217746\n",
      "Gradient for decoder.decoder.3.weight: 0.01589113287627697\n",
      "Gradient for decoder.decoder.3.bias: 1.3429028722367065e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0006800135015510023\n",
      "Gradient for decoder.decoder.4.bias: 0.0007178249070420861\n",
      "Gradient for decoder.decoder.6.weight: 0.0006908685900270939\n",
      "Gradient for decoder.decoder.6.bias: 4.349423761595972e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.027210012078285217\n",
      "Gradient for encoder.encoder.0.bias: 4.513209944656538e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.003687978722155094\n",
      "Gradient for encoder.encoder.1.bias: 0.0026279138401150703\n",
      "Gradient for encoder.encoder.3.weight: 0.07023395597934723\n",
      "Gradient for encoder.encoder.3.bias: 4.837830136494858e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.007180924993008375\n",
      "Gradient for encoder.encoder.4.bias: 0.008970262482762337\n",
      "Gradient for encoder.mean.weight: 0.09308524429798126\n",
      "Gradient for encoder.mean.bias: 0.007612958550453186\n",
      "Gradient for encoder.log_var.weight: 0.05180707201361656\n",
      "Gradient for encoder.log_var.bias: 0.004171139094978571\n",
      "Gradient for decoder.decoder.0.weight: 0.01744782365858555\n",
      "Gradient for decoder.decoder.0.bias: 1.554599643460719e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0009151753038167953\n",
      "Gradient for decoder.decoder.1.bias: 0.0006468272185884416\n",
      "Gradient for decoder.decoder.3.weight: 0.015319337137043476\n",
      "Gradient for decoder.decoder.3.bias: 1.216064471343259e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0005645114579237998\n",
      "Gradient for decoder.decoder.4.bias: 0.0005046558217145503\n",
      "Gradient for decoder.decoder.6.weight: 0.0006555125582963228\n",
      "Gradient for decoder.decoder.6.bias: 3.540351099218242e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.04177942872047424\n",
      "Gradient for encoder.encoder.0.bias: 6.054945433930925e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.004624600522220135\n",
      "Gradient for encoder.encoder.1.bias: 0.0032693459652364254\n",
      "Gradient for encoder.encoder.3.weight: 0.1031322330236435\n",
      "Gradient for encoder.encoder.3.bias: 5.535999991757024e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.015147925354540348\n",
      "Gradient for encoder.encoder.4.bias: 0.012657676823437214\n",
      "Gradient for encoder.mean.weight: 0.20117966830730438\n",
      "Gradient for encoder.mean.bias: 0.007380801718682051\n",
      "Gradient for encoder.log_var.weight: 0.12243230640888214\n",
      "Gradient for encoder.log_var.bias: 0.003986125811934471\n",
      "Gradient for decoder.decoder.0.weight: 0.015889691188931465\n",
      "Gradient for decoder.decoder.0.bias: 1.202472010852773e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0008667463553138077\n",
      "Gradient for decoder.decoder.1.bias: 0.0006566042429767549\n",
      "Gradient for decoder.decoder.3.weight: 0.014162848703563213\n",
      "Gradient for decoder.decoder.3.bias: 1.1441483177554446e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0006427388871088624\n",
      "Gradient for decoder.decoder.4.bias: 0.0006599518237635493\n",
      "Gradient for decoder.decoder.6.weight: 0.000718331488315016\n",
      "Gradient for decoder.decoder.6.bias: 5.389400394051336e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.04744983837008476\n",
      "Gradient for encoder.encoder.0.bias: 8.341502488740105e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.008557118475437164\n",
      "Gradient for encoder.encoder.1.bias: 0.0055200341157615185\n",
      "Gradient for encoder.encoder.3.weight: 0.16828536987304688\n",
      "Gradient for encoder.encoder.3.bias: 5.592148411004416e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.013730068691074848\n",
      "Gradient for encoder.encoder.4.bias: 0.012775701470673084\n",
      "Gradient for encoder.mean.weight: 0.18506723642349243\n",
      "Gradient for encoder.mean.bias: 0.008072900585830212\n",
      "Gradient for encoder.log_var.weight: 0.10836785286664963\n",
      "Gradient for encoder.log_var.bias: 0.005500913597643375\n",
      "Gradient for decoder.decoder.0.weight: 0.011805512011051178\n",
      "Gradient for decoder.decoder.0.bias: 9.471657486104235e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0006073863478377461\n",
      "Gradient for decoder.decoder.1.bias: 0.000481245486298576\n",
      "Gradient for decoder.decoder.3.weight: 0.010201824828982353\n",
      "Gradient for decoder.decoder.3.bias: 1.1538205807459789e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0008017614600248635\n",
      "Gradient for decoder.decoder.4.bias: 0.0009745842544361949\n",
      "Gradient for decoder.decoder.6.weight: 0.0008798440103419125\n",
      "Gradient for decoder.decoder.6.bias: 8.224710472859442e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.03907693549990654\n",
      "Gradient for encoder.encoder.0.bias: 5.0658234551637094e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.004646895918995142\n",
      "Gradient for encoder.encoder.1.bias: 0.003395899897441268\n",
      "Gradient for encoder.encoder.3.weight: 0.10712700337171555\n",
      "Gradient for encoder.encoder.3.bias: 5.748866938048991e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.009929900988936424\n",
      "Gradient for encoder.encoder.4.bias: 0.012270834296941757\n",
      "Gradient for encoder.mean.weight: 0.13151580095291138\n",
      "Gradient for encoder.mean.bias: 0.009586798958480358\n",
      "Gradient for encoder.log_var.weight: 0.07669781148433685\n",
      "Gradient for encoder.log_var.bias: 0.005471144802868366\n",
      "Gradient for decoder.decoder.0.weight: 0.01700723171234131\n",
      "Gradient for decoder.decoder.0.bias: 1.4742837506354078e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0009236459736712277\n",
      "Gradient for decoder.decoder.1.bias: 0.0006594657897949219\n",
      "Gradient for decoder.decoder.3.weight: 0.015157323330640793\n",
      "Gradient for decoder.decoder.3.bias: 1.3146077282311097e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0007856602896936238\n",
      "Gradient for decoder.decoder.4.bias: 0.0009031345252878964\n",
      "Gradient for decoder.decoder.6.weight: 0.000772064842749387\n",
      "Gradient for decoder.decoder.6.bias: 6.324827700154856e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.02825758047401905\n",
      "Gradient for encoder.encoder.0.bias: 4.849090920466814e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.006142404396086931\n",
      "Gradient for encoder.encoder.1.bias: 0.003909572958946228\n",
      "Gradient for encoder.encoder.3.weight: 0.12439226359128952\n",
      "Gradient for encoder.encoder.3.bias: 5.221169607771969e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.01596810482442379\n",
      "Gradient for encoder.encoder.4.bias: 0.011232415214180946\n",
      "Gradient for encoder.mean.weight: 0.21390104293823242\n",
      "Gradient for encoder.mean.bias: 0.00731999846175313\n",
      "Gradient for encoder.log_var.weight: 0.11441212147474289\n",
      "Gradient for encoder.log_var.bias: 0.004192018415778875\n",
      "Gradient for decoder.decoder.0.weight: 0.016708312556147575\n",
      "Gradient for decoder.decoder.0.bias: 1.348833822412132e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0008734440198168159\n",
      "Gradient for decoder.decoder.1.bias: 0.0006519606686197221\n",
      "Gradient for decoder.decoder.3.weight: 0.015492330305278301\n",
      "Gradient for decoder.decoder.3.bias: 1.298969543039874e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0006450660875998437\n",
      "Gradient for decoder.decoder.4.bias: 0.0007425026269629598\n",
      "Gradient for decoder.decoder.6.weight: 0.0006608317489735782\n",
      "Gradient for decoder.decoder.6.bias: 4.510248254518956e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.055341120809316635\n",
      "Gradient for encoder.encoder.0.bias: 7.71395794463281e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.004962907172739506\n",
      "Gradient for encoder.encoder.1.bias: 0.003590009408071637\n",
      "Gradient for encoder.encoder.3.weight: 0.11093331128358841\n",
      "Gradient for encoder.encoder.3.bias: 6.626831305922565e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.014293746091425419\n",
      "Gradient for encoder.encoder.4.bias: 0.010193300433456898\n",
      "Gradient for encoder.mean.weight: 0.17939601838588715\n",
      "Gradient for encoder.mean.bias: 0.005707091651856899\n",
      "Gradient for encoder.log_var.weight: 0.10670199990272522\n",
      "Gradient for encoder.log_var.bias: 0.003565701888874173\n",
      "Gradient for decoder.decoder.0.weight: 0.0183285903185606\n",
      "Gradient for decoder.decoder.0.bias: 1.615966388479606e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.001002007513307035\n",
      "Gradient for decoder.decoder.1.bias: 0.0007237816462293267\n",
      "Gradient for decoder.decoder.3.weight: 0.016315288841724396\n",
      "Gradient for decoder.decoder.3.bias: 1.2293648044003902e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0006509037339128554\n",
      "Gradient for decoder.decoder.4.bias: 0.0005707645905204117\n",
      "Gradient for decoder.decoder.6.weight: 0.0006952250259928405\n",
      "Gradient for decoder.decoder.6.bias: 4.110471127205528e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.030209699645638466\n",
      "Gradient for encoder.encoder.0.bias: 4.0144214341619744e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0028897069860249758\n",
      "Gradient for encoder.encoder.1.bias: 0.002508830279111862\n",
      "Gradient for encoder.encoder.3.weight: 0.061100684106349945\n",
      "Gradient for encoder.encoder.3.bias: 4.059880209794642e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.00676280353218317\n",
      "Gradient for encoder.encoder.4.bias: 0.005454786587506533\n",
      "Gradient for encoder.mean.weight: 0.09240572154521942\n",
      "Gradient for encoder.mean.bias: 0.004175346810370684\n",
      "Gradient for encoder.log_var.weight: 0.06443282216787338\n",
      "Gradient for encoder.log_var.bias: 0.0025676421355456114\n",
      "Gradient for decoder.decoder.0.weight: 0.019078988581895828\n",
      "Gradient for decoder.decoder.0.bias: 1.594149395822697e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0009937830036506057\n",
      "Gradient for decoder.decoder.1.bias: 0.0007219499093480408\n",
      "Gradient for decoder.decoder.3.weight: 0.01704408787190914\n",
      "Gradient for decoder.decoder.3.bias: 1.1541789746161157e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0006520788301713765\n",
      "Gradient for decoder.decoder.4.bias: 0.0006344089633785188\n",
      "Gradient for decoder.decoder.6.weight: 0.0006718930671922863\n",
      "Gradient for decoder.decoder.6.bias: 3.819120684056543e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.04090575873851776\n",
      "Gradient for encoder.encoder.0.bias: 6.717254530386185e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0063960133120417595\n",
      "Gradient for encoder.encoder.1.bias: 0.0037878702860325575\n",
      "Gradient for encoder.encoder.3.weight: 0.12377240508794785\n",
      "Gradient for encoder.encoder.3.bias: 6.40467068269146e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.018799781799316406\n",
      "Gradient for encoder.encoder.4.bias: 0.014578640460968018\n",
      "Gradient for encoder.mean.weight: 0.24664846062660217\n",
      "Gradient for encoder.mean.bias: 0.01015956699848175\n",
      "Gradient for encoder.log_var.weight: 0.1497291922569275\n",
      "Gradient for encoder.log_var.bias: 0.006957896985113621\n",
      "Gradient for decoder.decoder.0.weight: 0.01160846371203661\n",
      "Gradient for decoder.decoder.0.bias: 1.1146037565135103e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0006326719885692\n",
      "Gradient for decoder.decoder.1.bias: 0.0004690723435487598\n",
      "Gradient for decoder.decoder.3.weight: 0.010657284408807755\n",
      "Gradient for decoder.decoder.3.bias: 1.1980294534197355e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0007488970877602696\n",
      "Gradient for decoder.decoder.4.bias: 0.0008876185165718198\n",
      "Gradient for decoder.decoder.6.weight: 0.0006990460096858442\n",
      "Gradient for decoder.decoder.6.bias: 5.38221574970521e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.05356883257627487\n",
      "Gradient for encoder.encoder.0.bias: 7.75473227299095e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.005510813090950251\n",
      "Gradient for encoder.encoder.1.bias: 0.0039932806976139545\n",
      "Gradient for encoder.encoder.3.weight: 0.12054315209388733\n",
      "Gradient for encoder.encoder.3.bias: 7.8543688220023e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.015828873962163925\n",
      "Gradient for encoder.encoder.4.bias: 0.013120568357408047\n",
      "Gradient for encoder.mean.weight: 0.18047325313091278\n",
      "Gradient for encoder.mean.bias: 0.007051479537039995\n",
      "Gradient for encoder.log_var.weight: 0.11773744225502014\n",
      "Gradient for encoder.log_var.bias: 0.0045982166193425655\n",
      "Gradient for decoder.decoder.0.weight: 0.018112296238541603\n",
      "Gradient for decoder.decoder.0.bias: 1.4225348676788485e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0009298965451307595\n",
      "Gradient for decoder.decoder.1.bias: 0.0006773771601729095\n",
      "Gradient for decoder.decoder.3.weight: 0.016209596768021584\n",
      "Gradient for decoder.decoder.3.bias: 1.1950687661688164e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0005680127069354057\n",
      "Gradient for decoder.decoder.4.bias: 0.0005186524940654635\n",
      "Gradient for decoder.decoder.6.weight: 0.0006471751257777214\n",
      "Gradient for decoder.decoder.6.bias: 3.5983557609142736e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.03751300275325775\n",
      "Gradient for encoder.encoder.0.bias: 6.494780407928502e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.005825286731123924\n",
      "Gradient for encoder.encoder.1.bias: 0.004810366779565811\n",
      "Gradient for encoder.encoder.3.weight: 0.11061958968639374\n",
      "Gradient for encoder.encoder.3.bias: 5.601633046303789e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.011249666102230549\n",
      "Gradient for encoder.encoder.4.bias: 0.01183655858039856\n",
      "Gradient for encoder.mean.weight: 0.14254243671894073\n",
      "Gradient for encoder.mean.bias: 0.008521138690412045\n",
      "Gradient for encoder.log_var.weight: 0.07607244700193405\n",
      "Gradient for encoder.log_var.bias: 0.004490903113037348\n",
      "Gradient for decoder.decoder.0.weight: 0.014199991710484028\n",
      "Gradient for decoder.decoder.0.bias: 1.1720732717712679e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0007482389337383211\n",
      "Gradient for decoder.decoder.1.bias: 0.000518963614013046\n",
      "Gradient for decoder.decoder.3.weight: 0.012232513166964054\n",
      "Gradient for decoder.decoder.3.bias: 9.819884488893038e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00048316578613594174\n",
      "Gradient for decoder.decoder.4.bias: 0.0004497207119129598\n",
      "Gradient for decoder.decoder.6.weight: 0.0005898039089515805\n",
      "Gradient for decoder.decoder.6.bias: 3.5953547921963036e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.024687739089131355\n",
      "Gradient for encoder.encoder.0.bias: 3.703218981465639e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0041291117668151855\n",
      "Gradient for encoder.encoder.1.bias: 0.002940705744549632\n",
      "Gradient for encoder.encoder.3.weight: 0.07925232499837875\n",
      "Gradient for encoder.encoder.3.bias: 4.047695789655137e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.008970683440566063\n",
      "Gradient for encoder.encoder.4.bias: 0.007466254290193319\n",
      "Gradient for encoder.mean.weight: 0.12306544184684753\n",
      "Gradient for encoder.mean.bias: 0.004748434294015169\n",
      "Gradient for encoder.log_var.weight: 0.05885114148259163\n",
      "Gradient for encoder.log_var.bias: 0.002580223837867379\n",
      "Gradient for decoder.decoder.0.weight: 0.019270876422524452\n",
      "Gradient for decoder.decoder.0.bias: 1.6307911965274258e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0010084091918542981\n",
      "Gradient for decoder.decoder.1.bias: 0.0007741556037217379\n",
      "Gradient for decoder.decoder.3.weight: 0.016962310299277306\n",
      "Gradient for decoder.decoder.3.bias: 1.335386384804238e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0008440157398581505\n",
      "Gradient for decoder.decoder.4.bias: 0.0008949874900281429\n",
      "Gradient for decoder.decoder.6.weight: 0.0007917726179584861\n",
      "Gradient for decoder.decoder.6.bias: 5.533240255317651e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.025401663035154343\n",
      "Gradient for encoder.encoder.0.bias: 5.14860827582897e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.004785720258951187\n",
      "Gradient for encoder.encoder.1.bias: 0.0029262674506753683\n",
      "Gradient for encoder.encoder.3.weight: 0.0920223668217659\n",
      "Gradient for encoder.encoder.3.bias: 5.419342752333023e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.01475711539387703\n",
      "Gradient for encoder.encoder.4.bias: 0.012174522504210472\n",
      "Gradient for encoder.mean.weight: 0.18225184082984924\n",
      "Gradient for encoder.mean.bias: 0.006976517848670483\n",
      "Gradient for encoder.log_var.weight: 0.11520254611968994\n",
      "Gradient for encoder.log_var.bias: 0.005104676354676485\n",
      "Gradient for decoder.decoder.0.weight: 0.01382413413375616\n",
      "Gradient for decoder.decoder.0.bias: 1.2529836890262658e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0006874761311337352\n",
      "Gradient for decoder.decoder.1.bias: 0.0005279374890960753\n",
      "Gradient for decoder.decoder.3.weight: 0.011745043098926544\n",
      "Gradient for decoder.decoder.3.bias: 9.938863620995164e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.000413247209507972\n",
      "Gradient for decoder.decoder.4.bias: 0.00039509363705292344\n",
      "Gradient for decoder.decoder.6.weight: 0.0005799991195090115\n",
      "Gradient for decoder.decoder.6.bias: 3.352158091729507e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.022313479334115982\n",
      "Gradient for encoder.encoder.0.bias: 3.589210526011577e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.003235515207052231\n",
      "Gradient for encoder.encoder.1.bias: 0.002718712668865919\n",
      "Gradient for encoder.encoder.3.weight: 0.07237409800291061\n",
      "Gradient for encoder.encoder.3.bias: 5.287514870389032e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.010029717348515987\n",
      "Gradient for encoder.encoder.4.bias: 0.010824745520949364\n",
      "Gradient for encoder.mean.weight: 0.13710270822048187\n",
      "Gradient for encoder.mean.bias: 0.009822080843150616\n",
      "Gradient for encoder.log_var.weight: 0.07413826137781143\n",
      "Gradient for encoder.log_var.bias: 0.005664551164954901\n",
      "Gradient for decoder.decoder.0.weight: 0.016716474667191505\n",
      "Gradient for decoder.decoder.0.bias: 1.319028497537289e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0009185197995975614\n",
      "Gradient for decoder.decoder.1.bias: 0.0006113802082836628\n",
      "Gradient for decoder.decoder.3.weight: 0.014510930515825748\n",
      "Gradient for decoder.decoder.3.bias: 1.0878802719771485e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.000513742386829108\n",
      "Gradient for decoder.decoder.4.bias: 0.00045566936023533344\n",
      "Gradient for decoder.decoder.6.weight: 0.0005805238033644855\n",
      "Gradient for decoder.decoder.6.bias: 2.898410639318172e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training VAE Epoch:  72%|███████▏  | 57/79 [00:00<00:00, 73.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient for encoder.encoder.0.weight: 0.0366254597902298\n",
      "Gradient for encoder.encoder.0.bias: 5.949418041550913e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.004266700707376003\n",
      "Gradient for encoder.encoder.1.bias: 0.00349061144515872\n",
      "Gradient for encoder.encoder.3.weight: 0.09034930914640427\n",
      "Gradient for encoder.encoder.3.bias: 5.86158233062406e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.01353099662810564\n",
      "Gradient for encoder.encoder.4.bias: 0.010470736771821976\n",
      "Gradient for encoder.mean.weight: 0.17297017574310303\n",
      "Gradient for encoder.mean.bias: 0.007563483901321888\n",
      "Gradient for encoder.log_var.weight: 0.09388791024684906\n",
      "Gradient for encoder.log_var.bias: 0.003913805820047855\n",
      "Gradient for decoder.decoder.0.weight: 0.014892551116645336\n",
      "Gradient for decoder.decoder.0.bias: 1.2650362701815965e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0007859354955144227\n",
      "Gradient for decoder.decoder.1.bias: 0.0005595763213932514\n",
      "Gradient for decoder.decoder.3.weight: 0.01323416642844677\n",
      "Gradient for decoder.decoder.3.bias: 1.0275787165614503e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0004748171486426145\n",
      "Gradient for decoder.decoder.4.bias: 0.00044794491259381175\n",
      "Gradient for decoder.decoder.6.weight: 0.0006571970880031586\n",
      "Gradient for decoder.decoder.6.bias: 4.721214281744324e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.0258321575820446\n",
      "Gradient for encoder.encoder.0.bias: 4.3169499225337304e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.002999007236212492\n",
      "Gradient for encoder.encoder.1.bias: 0.0025122440420091152\n",
      "Gradient for encoder.encoder.3.weight: 0.06480766087770462\n",
      "Gradient for encoder.encoder.3.bias: 4.1455902599629724e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.008445675484836102\n",
      "Gradient for encoder.encoder.4.bias: 0.0068329512141644955\n",
      "Gradient for encoder.mean.weight: 0.11594457179307938\n",
      "Gradient for encoder.mean.bias: 0.005407634656876326\n",
      "Gradient for encoder.log_var.weight: 0.062317658215761185\n",
      "Gradient for encoder.log_var.bias: 0.002634585602208972\n",
      "Gradient for decoder.decoder.0.weight: 0.01501424890011549\n",
      "Gradient for decoder.decoder.0.bias: 1.2973949692351994e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0008250148384831846\n",
      "Gradient for decoder.decoder.1.bias: 0.0005364142125472426\n",
      "Gradient for decoder.decoder.3.weight: 0.013051445595920086\n",
      "Gradient for decoder.decoder.3.bias: 9.641099724122526e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00046549845137633383\n",
      "Gradient for decoder.decoder.4.bias: 0.0003761236439459026\n",
      "Gradient for decoder.decoder.6.weight: 0.0006224983953870833\n",
      "Gradient for decoder.decoder.6.bias: 4.029539559269324e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.037345368415117264\n",
      "Gradient for encoder.encoder.0.bias: 5.450508100413032e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0042771934531629086\n",
      "Gradient for encoder.encoder.1.bias: 0.003299082163721323\n",
      "Gradient for encoder.encoder.3.weight: 0.09035713225603104\n",
      "Gradient for encoder.encoder.3.bias: 4.699329259061358e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.009332610294222832\n",
      "Gradient for encoder.encoder.4.bias: 0.007901288568973541\n",
      "Gradient for encoder.mean.weight: 0.12744806706905365\n",
      "Gradient for encoder.mean.bias: 0.004932827781885862\n",
      "Gradient for encoder.log_var.weight: 0.06449520587921143\n",
      "Gradient for encoder.log_var.bias: 0.0031651549506932497\n",
      "Gradient for decoder.decoder.0.weight: 0.013861390762031078\n",
      "Gradient for decoder.decoder.0.bias: 1.1832926305466174e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0007935595931485295\n",
      "Gradient for decoder.decoder.1.bias: 0.0005710156983695924\n",
      "Gradient for decoder.decoder.3.weight: 0.012396651320159435\n",
      "Gradient for decoder.decoder.3.bias: 1.1943661337721068e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0006648249691352248\n",
      "Gradient for decoder.decoder.4.bias: 0.0007625592406839132\n",
      "Gradient for decoder.decoder.6.weight: 0.0006325470167212188\n",
      "Gradient for decoder.decoder.6.bias: 4.872359204455279e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.033124737441539764\n",
      "Gradient for encoder.encoder.0.bias: 6.58181495416521e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.004621915053576231\n",
      "Gradient for encoder.encoder.1.bias: 0.0036791604943573475\n",
      "Gradient for encoder.encoder.3.weight: 0.1030779555439949\n",
      "Gradient for encoder.encoder.3.bias: 5.695546811956831e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.010526556521654129\n",
      "Gradient for encoder.encoder.4.bias: 0.009540432132780552\n",
      "Gradient for encoder.mean.weight: 0.13595561683177948\n",
      "Gradient for encoder.mean.bias: 0.006684200372546911\n",
      "Gradient for encoder.log_var.weight: 0.07712296396493912\n",
      "Gradient for encoder.log_var.bias: 0.0046955193392932415\n",
      "Gradient for decoder.decoder.0.weight: 0.015816153958439827\n",
      "Gradient for decoder.decoder.0.bias: 1.3641908436223815e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0008656697464175522\n",
      "Gradient for decoder.decoder.1.bias: 0.0006721421959809959\n",
      "Gradient for decoder.decoder.3.weight: 0.014421737752854824\n",
      "Gradient for decoder.decoder.3.bias: 1.3543562105144957e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0008778797346167266\n",
      "Gradient for decoder.decoder.4.bias: 0.001030570245347917\n",
      "Gradient for decoder.decoder.6.weight: 0.0007988991565071046\n",
      "Gradient for decoder.decoder.6.bias: 6.0337999457260594e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.02920852228999138\n",
      "Gradient for encoder.encoder.0.bias: 5.4546294564472575e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.002797870198264718\n",
      "Gradient for encoder.encoder.1.bias: 0.0024857704993337393\n",
      "Gradient for encoder.encoder.3.weight: 0.05951298773288727\n",
      "Gradient for encoder.encoder.3.bias: 4.397376907050443e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.006438512355089188\n",
      "Gradient for encoder.encoder.4.bias: 0.006775785703212023\n",
      "Gradient for encoder.mean.weight: 0.08717454969882965\n",
      "Gradient for encoder.mean.bias: 0.005512333009392023\n",
      "Gradient for encoder.log_var.weight: 0.049569271504879\n",
      "Gradient for encoder.log_var.bias: 0.003509331028908491\n",
      "Gradient for decoder.decoder.0.weight: 0.011807027272880077\n",
      "Gradient for decoder.decoder.0.bias: 1.0282551893281422e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0006473857793025672\n",
      "Gradient for decoder.decoder.1.bias: 0.0004777962458319962\n",
      "Gradient for decoder.decoder.3.weight: 0.010701175779104233\n",
      "Gradient for decoder.decoder.3.bias: 1.2557219153386256e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0008371956646442413\n",
      "Gradient for decoder.decoder.4.bias: 0.0010141069069504738\n",
      "Gradient for decoder.decoder.6.weight: 0.0007316211122088134\n",
      "Gradient for decoder.decoder.6.bias: 6.200755888130516e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.026160825043916702\n",
      "Gradient for encoder.encoder.0.bias: 4.046425000625575e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.003510689130052924\n",
      "Gradient for encoder.encoder.1.bias: 0.0026645222678780556\n",
      "Gradient for encoder.encoder.3.weight: 0.07896523922681808\n",
      "Gradient for encoder.encoder.3.bias: 4.8523673967793e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.011069291271269321\n",
      "Gradient for encoder.encoder.4.bias: 0.010466797277331352\n",
      "Gradient for encoder.mean.weight: 0.14911726117134094\n",
      "Gradient for encoder.mean.bias: 0.008836928755044937\n",
      "Gradient for encoder.log_var.weight: 0.0729774683713913\n",
      "Gradient for encoder.log_var.bias: 0.005070826970040798\n",
      "Gradient for decoder.decoder.0.weight: 0.01622050441801548\n",
      "Gradient for decoder.decoder.0.bias: 1.2107942426453633e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.000838732288684696\n",
      "Gradient for decoder.decoder.1.bias: 0.0006105945212766528\n",
      "Gradient for decoder.decoder.3.weight: 0.014700233936309814\n",
      "Gradient for decoder.decoder.3.bias: 9.99984123284392e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0005236075376160443\n",
      "Gradient for decoder.decoder.4.bias: 0.00046340900007635355\n",
      "Gradient for decoder.decoder.6.weight: 0.0006526372744701803\n",
      "Gradient for decoder.decoder.6.bias: 4.324569454183802e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.04023333266377449\n",
      "Gradient for encoder.encoder.0.bias: 6.835415566897041e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.007729393430054188\n",
      "Gradient for encoder.encoder.1.bias: 0.00431459303945303\n",
      "Gradient for encoder.encoder.3.weight: 0.14252090454101562\n",
      "Gradient for encoder.encoder.3.bias: 5.952527915020767e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.01656542904675007\n",
      "Gradient for encoder.encoder.4.bias: 0.01271907240152359\n",
      "Gradient for encoder.mean.weight: 0.2137620747089386\n",
      "Gradient for encoder.mean.bias: 0.009860333055257797\n",
      "Gradient for encoder.log_var.weight: 0.11450958997011185\n",
      "Gradient for encoder.log_var.bias: 0.0050685349851846695\n",
      "Gradient for decoder.decoder.0.weight: 0.013495679013431072\n",
      "Gradient for decoder.decoder.0.bias: 1.15639407771706e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0006896505947224796\n",
      "Gradient for decoder.decoder.1.bias: 0.00047777630970813334\n",
      "Gradient for decoder.decoder.3.weight: 0.011177635751664639\n",
      "Gradient for decoder.decoder.3.bias: 9.898606934122256e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0005750562995672226\n",
      "Gradient for decoder.decoder.4.bias: 0.0006670409347862005\n",
      "Gradient for decoder.decoder.6.weight: 0.0005793282762169838\n",
      "Gradient for decoder.decoder.6.bias: 4.288938725949265e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.026629788801074028\n",
      "Gradient for encoder.encoder.0.bias: 3.9157854042626283e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0029027455020695925\n",
      "Gradient for encoder.encoder.1.bias: 0.0021960868034511805\n",
      "Gradient for encoder.encoder.3.weight: 0.06095936894416809\n",
      "Gradient for encoder.encoder.3.bias: 4.2216402595940394e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.008769904263317585\n",
      "Gradient for encoder.encoder.4.bias: 0.007263274863362312\n",
      "Gradient for encoder.mean.weight: 0.11415735632181168\n",
      "Gradient for encoder.mean.bias: 0.0061342911794781685\n",
      "Gradient for encoder.log_var.weight: 0.05583866685628891\n",
      "Gradient for encoder.log_var.bias: 0.003012455999851227\n",
      "Gradient for decoder.decoder.0.weight: 0.015829838812351227\n",
      "Gradient for decoder.decoder.0.bias: 1.5644531503600234e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0007665188168175519\n",
      "Gradient for decoder.decoder.1.bias: 0.000611689523793757\n",
      "Gradient for decoder.decoder.3.weight: 0.013848152942955494\n",
      "Gradient for decoder.decoder.3.bias: 1.218387751800165e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0004747430793941021\n",
      "Gradient for decoder.decoder.4.bias: 0.0004166416765656322\n",
      "Gradient for decoder.decoder.6.weight: 0.0006425307365134358\n",
      "Gradient for decoder.decoder.6.bias: 3.9687613025307655e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.039972178637981415\n",
      "Gradient for encoder.encoder.0.bias: 4.834869310466061e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0046185520477592945\n",
      "Gradient for encoder.encoder.1.bias: 0.003458272200077772\n",
      "Gradient for encoder.encoder.3.weight: 0.10161840915679932\n",
      "Gradient for encoder.encoder.3.bias: 5.697216587385867e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.015589126385748386\n",
      "Gradient for encoder.encoder.4.bias: 0.010683126747608185\n",
      "Gradient for encoder.mean.weight: 0.20619237422943115\n",
      "Gradient for encoder.mean.bias: 0.005019730422645807\n",
      "Gradient for encoder.log_var.weight: 0.10610544681549072\n",
      "Gradient for encoder.log_var.bias: 0.002742557553574443\n",
      "Gradient for decoder.decoder.0.weight: 0.01920188218355179\n",
      "Gradient for decoder.decoder.0.bias: 1.608326111179892e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.000992501387372613\n",
      "Gradient for decoder.decoder.1.bias: 0.0007994738407433033\n",
      "Gradient for decoder.decoder.3.weight: 0.017358871176838875\n",
      "Gradient for decoder.decoder.3.bias: 1.33468652796509e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0006011812947690487\n",
      "Gradient for decoder.decoder.4.bias: 0.0005308724357746542\n",
      "Gradient for decoder.decoder.6.weight: 0.0006360042025335133\n",
      "Gradient for decoder.decoder.6.bias: 3.52360111719463e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.02452765218913555\n",
      "Gradient for encoder.encoder.0.bias: 4.0384567218110234e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0034692895133048296\n",
      "Gradient for encoder.encoder.1.bias: 0.002551679266616702\n",
      "Gradient for encoder.encoder.3.weight: 0.07401488721370697\n",
      "Gradient for encoder.encoder.3.bias: 3.8150918535428957e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.008655919693410397\n",
      "Gradient for encoder.encoder.4.bias: 0.008187373168766499\n",
      "Gradient for encoder.mean.weight: 0.11705093830823898\n",
      "Gradient for encoder.mean.bias: 0.005562490783631802\n",
      "Gradient for encoder.log_var.weight: 0.059040941298007965\n",
      "Gradient for encoder.log_var.bias: 0.003349015489220619\n",
      "Gradient for decoder.decoder.0.weight: 0.016487013548612595\n",
      "Gradient for decoder.decoder.0.bias: 1.3352340066941082e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0008921043481677771\n",
      "Gradient for decoder.decoder.1.bias: 0.000672113848850131\n",
      "Gradient for decoder.decoder.3.weight: 0.015210437588393688\n",
      "Gradient for decoder.decoder.3.bias: 1.236022256767555e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0005414861370809376\n",
      "Gradient for decoder.decoder.4.bias: 0.000508389959577471\n",
      "Gradient for decoder.decoder.6.weight: 0.0005893220659345388\n",
      "Gradient for decoder.decoder.6.bias: 2.929536458395887e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.029110077768564224\n",
      "Gradient for encoder.encoder.0.bias: 3.916610438747803e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0036561761517077684\n",
      "Gradient for encoder.encoder.1.bias: 0.002748367842286825\n",
      "Gradient for encoder.encoder.3.weight: 0.07938359677791595\n",
      "Gradient for encoder.encoder.3.bias: 4.2778874886906237e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.008489437401294708\n",
      "Gradient for encoder.encoder.4.bias: 0.0074948715046048164\n",
      "Gradient for encoder.mean.weight: 0.10889121890068054\n",
      "Gradient for encoder.mean.bias: 0.004660290200263262\n",
      "Gradient for encoder.log_var.weight: 0.05834529921412468\n",
      "Gradient for encoder.log_var.bias: 0.0029199072159826756\n",
      "Gradient for decoder.decoder.0.weight: 0.016566844657063484\n",
      "Gradient for decoder.decoder.0.bias: 1.458853315927655e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0008886802825145423\n",
      "Gradient for decoder.decoder.1.bias: 0.000628700596280396\n",
      "Gradient for decoder.decoder.3.weight: 0.014748821966350079\n",
      "Gradient for decoder.decoder.3.bias: 1.0975161751636264e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0005397252389229834\n",
      "Gradient for decoder.decoder.4.bias: 0.0005167975323274732\n",
      "Gradient for decoder.decoder.6.weight: 0.0006058195140212774\n",
      "Gradient for decoder.decoder.6.bias: 2.9924567570560612e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.0416247621178627\n",
      "Gradient for encoder.encoder.0.bias: 6.312458195045778e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.005218807142227888\n",
      "Gradient for encoder.encoder.1.bias: 0.0037542504724115133\n",
      "Gradient for encoder.encoder.3.weight: 0.11166766285896301\n",
      "Gradient for encoder.encoder.3.bias: 5.352523424484446e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.011072766035795212\n",
      "Gradient for encoder.encoder.4.bias: 0.00939094927161932\n",
      "Gradient for encoder.mean.weight: 0.13835863769054413\n",
      "Gradient for encoder.mean.bias: 0.006010684184730053\n",
      "Gradient for encoder.log_var.weight: 0.07043303549289703\n",
      "Gradient for encoder.log_var.bias: 0.0037771319039165974\n",
      "Gradient for decoder.decoder.0.weight: 0.012231165543198586\n",
      "Gradient for decoder.decoder.0.bias: 1.0737822436768241e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0006373641663230956\n",
      "Gradient for decoder.decoder.1.bias: 0.0004628049791790545\n",
      "Gradient for decoder.decoder.3.weight: 0.010440689511597157\n",
      "Gradient for decoder.decoder.3.bias: 8.621885844162236e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0004529397701844573\n",
      "Gradient for decoder.decoder.4.bias: 0.00048742667422629893\n",
      "Gradient for decoder.decoder.6.weight: 0.0005806378903798759\n",
      "Gradient for decoder.decoder.6.bias: 3.765647124964744e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.038741741329431534\n",
      "Gradient for encoder.encoder.0.bias: 6.346388692346494e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.004283290822058916\n",
      "Gradient for encoder.encoder.1.bias: 0.002915882272645831\n",
      "Gradient for encoder.encoder.3.weight: 0.0960569828748703\n",
      "Gradient for encoder.encoder.3.bias: 4.960987176616527e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.01193992793560028\n",
      "Gradient for encoder.encoder.4.bias: 0.00871486309915781\n",
      "Gradient for encoder.mean.weight: 0.15322379767894745\n",
      "Gradient for encoder.mean.bias: 0.006688400637358427\n",
      "Gradient for encoder.log_var.weight: 0.08701242506504059\n",
      "Gradient for encoder.log_var.bias: 0.003813495161011815\n",
      "Gradient for decoder.decoder.0.weight: 0.014345791190862656\n",
      "Gradient for decoder.decoder.0.bias: 1.1847914316298613e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0007626317092217505\n",
      "Gradient for decoder.decoder.1.bias: 0.0005519880796782672\n",
      "Gradient for decoder.decoder.3.weight: 0.01260389108210802\n",
      "Gradient for decoder.decoder.3.bias: 1.3153605982196837e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0008618310675956309\n",
      "Gradient for decoder.decoder.4.bias: 0.0010692427167668939\n",
      "Gradient for decoder.decoder.6.weight: 0.0007531424053013325\n",
      "Gradient for decoder.decoder.6.bias: 6.862721784273162e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.03438284248113632\n",
      "Gradient for encoder.encoder.0.bias: 5.405755357235087e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.004482177086174488\n",
      "Gradient for encoder.encoder.1.bias: 0.0032401131466031075\n",
      "Gradient for encoder.encoder.3.weight: 0.09756093472242355\n",
      "Gradient for encoder.encoder.3.bias: 7.491022246952639e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.019069524481892586\n",
      "Gradient for encoder.encoder.4.bias: 0.015335061587393284\n",
      "Gradient for encoder.mean.weight: 0.23294579982757568\n",
      "Gradient for encoder.mean.bias: 0.010465259663760662\n",
      "Gradient for encoder.log_var.weight: 0.13912788033485413\n",
      "Gradient for encoder.log_var.bias: 0.005910181440412998\n",
      "Gradient for decoder.decoder.0.weight: 0.018043603748083115\n",
      "Gradient for decoder.decoder.0.bias: 1.4695751560100945e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0009323135600425303\n",
      "Gradient for decoder.decoder.1.bias: 0.0006950527895241976\n",
      "Gradient for decoder.decoder.3.weight: 0.01691187359392643\n",
      "Gradient for decoder.decoder.3.bias: 1.0670812150559428e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0006192405126057565\n",
      "Gradient for decoder.decoder.4.bias: 0.0005419659428298473\n",
      "Gradient for decoder.decoder.6.weight: 0.000658736506011337\n",
      "Gradient for decoder.decoder.6.bias: 4.031135904369876e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.02678767405450344\n",
      "Gradient for encoder.encoder.0.bias: 4.36114269697363e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.003636272856965661\n",
      "Gradient for encoder.encoder.1.bias: 0.003004226600751281\n",
      "Gradient for encoder.encoder.3.weight: 0.08297494798898697\n",
      "Gradient for encoder.encoder.3.bias: 4.0762893060986016e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.008251527324318886\n",
      "Gradient for encoder.encoder.4.bias: 0.0063489824533462524\n",
      "Gradient for encoder.mean.weight: 0.1125689148902893\n",
      "Gradient for encoder.mean.bias: 0.0036157916765660048\n",
      "Gradient for encoder.log_var.weight: 0.053895991295576096\n",
      "Gradient for encoder.log_var.bias: 0.002421023091301322\n",
      "Gradient for decoder.decoder.0.weight: 0.013753055594861507\n",
      "Gradient for decoder.decoder.0.bias: 1.2259342152542985e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0007104201358743012\n",
      "Gradient for decoder.decoder.1.bias: 0.0005259891040623188\n",
      "Gradient for decoder.decoder.3.weight: 0.011959156952798367\n",
      "Gradient for decoder.decoder.3.bias: 1.1206362227067501e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0006539207533933222\n",
      "Gradient for decoder.decoder.4.bias: 0.0007395606953650713\n",
      "Gradient for decoder.decoder.6.weight: 0.0006022585439495742\n",
      "Gradient for decoder.decoder.6.bias: 4.2740161006804556e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.0273689366877079\n",
      "Gradient for encoder.encoder.0.bias: 3.718133093078002e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.003266069572418928\n",
      "Gradient for encoder.encoder.1.bias: 0.0026254872791469097\n",
      "Gradient for encoder.encoder.3.weight: 0.07424631714820862\n",
      "Gradient for encoder.encoder.3.bias: 4.2604034189430706e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.007661391049623489\n",
      "Gradient for encoder.encoder.4.bias: 0.005801002960652113\n",
      "Gradient for encoder.mean.weight: 0.10383450984954834\n",
      "Gradient for encoder.mean.bias: 0.004220964852720499\n",
      "Gradient for encoder.log_var.weight: 0.054220039397478104\n",
      "Gradient for encoder.log_var.bias: 0.0021655659656971693\n",
      "Gradient for decoder.decoder.0.weight: 0.0176752470433712\n",
      "Gradient for decoder.decoder.0.bias: 1.6420130533045807e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0008819182985462248\n",
      "Gradient for decoder.decoder.1.bias: 0.0006303415866568685\n",
      "Gradient for decoder.decoder.3.weight: 0.01564537174999714\n",
      "Gradient for decoder.decoder.3.bias: 1.3236682583350756e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0007159945089370012\n",
      "Gradient for decoder.decoder.4.bias: 0.0007218025275506079\n",
      "Gradient for decoder.decoder.6.weight: 0.000671125017106533\n",
      "Gradient for decoder.decoder.6.bias: 3.813327202806249e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training VAE Epoch:  92%|█████████▏| 73/79 [00:01<00:00, 75.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient for encoder.encoder.0.weight: 0.04860638827085495\n",
      "Gradient for encoder.encoder.0.bias: 6.874134594880843e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.004072905983775854\n",
      "Gradient for encoder.encoder.1.bias: 0.003356151282787323\n",
      "Gradient for encoder.encoder.3.weight: 0.09228014945983887\n",
      "Gradient for encoder.encoder.3.bias: 6.93803736684373e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.012801917269825935\n",
      "Gradient for encoder.encoder.4.bias: 0.010728726163506508\n",
      "Gradient for encoder.mean.weight: 0.14817754924297333\n",
      "Gradient for encoder.mean.bias: 0.005925879813730717\n",
      "Gradient for encoder.log_var.weight: 0.09217572957277298\n",
      "Gradient for encoder.log_var.bias: 0.0031285572331398726\n",
      "Gradient for decoder.decoder.0.weight: 0.017188142985105515\n",
      "Gradient for decoder.decoder.0.bias: 1.571570373837261e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0009236384066753089\n",
      "Gradient for decoder.decoder.1.bias: 0.0006438663112930954\n",
      "Gradient for decoder.decoder.3.weight: 0.014991133473813534\n",
      "Gradient for decoder.decoder.3.bias: 1.1687537049276386e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0005299150943756104\n",
      "Gradient for decoder.decoder.4.bias: 0.0004927218542434275\n",
      "Gradient for decoder.decoder.6.weight: 0.000562206725589931\n",
      "Gradient for decoder.decoder.6.bias: 3.088938319706358e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.027523083612322807\n",
      "Gradient for encoder.encoder.0.bias: 5.014843054707008e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0033791069872677326\n",
      "Gradient for encoder.encoder.1.bias: 0.002996570896357298\n",
      "Gradient for encoder.encoder.3.weight: 0.07049953937530518\n",
      "Gradient for encoder.encoder.3.bias: 4.799511343911433e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.00788875948637724\n",
      "Gradient for encoder.encoder.4.bias: 0.008068853989243507\n",
      "Gradient for encoder.mean.weight: 0.10123563557863235\n",
      "Gradient for encoder.mean.bias: 0.005603858269751072\n",
      "Gradient for encoder.log_var.weight: 0.05709937587380409\n",
      "Gradient for encoder.log_var.bias: 0.0030133274849504232\n",
      "Gradient for decoder.decoder.0.weight: 0.014211118221282959\n",
      "Gradient for decoder.decoder.0.bias: 1.2513493019561395e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0007160190725699067\n",
      "Gradient for decoder.decoder.1.bias: 0.0005256993463262916\n",
      "Gradient for decoder.decoder.3.weight: 0.012485579587519169\n",
      "Gradient for decoder.decoder.3.bias: 1.0900830932358829e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0004914829041808844\n",
      "Gradient for decoder.decoder.4.bias: 0.0005002817488275468\n",
      "Gradient for decoder.decoder.6.weight: 0.0005841657985001802\n",
      "Gradient for decoder.decoder.6.bias: 3.688753713504411e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.030934901908040047\n",
      "Gradient for encoder.encoder.0.bias: 5.099041675005189e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.005556589458137751\n",
      "Gradient for encoder.encoder.1.bias: 0.004081788472831249\n",
      "Gradient for encoder.encoder.3.weight: 0.11596199125051498\n",
      "Gradient for encoder.encoder.3.bias: 6.058427648447662e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.01444536168128252\n",
      "Gradient for encoder.encoder.4.bias: 0.012410535477101803\n",
      "Gradient for encoder.mean.weight: 0.18602439761161804\n",
      "Gradient for encoder.mean.bias: 0.007508071605116129\n",
      "Gradient for encoder.log_var.weight: 0.10487846285104752\n",
      "Gradient for encoder.log_var.bias: 0.004413210321217775\n",
      "Gradient for decoder.decoder.0.weight: 0.013964720070362091\n",
      "Gradient for decoder.decoder.0.bias: 1.1116131626298653e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0007487059338018298\n",
      "Gradient for decoder.decoder.1.bias: 0.0005269575049169362\n",
      "Gradient for decoder.decoder.3.weight: 0.012366196140646935\n",
      "Gradient for decoder.decoder.3.bias: 8.890754105150833e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00042675473378039896\n",
      "Gradient for decoder.decoder.4.bias: 0.00040038867155089974\n",
      "Gradient for decoder.decoder.6.weight: 0.0005485502770170569\n",
      "Gradient for decoder.decoder.6.bias: 2.623017098812852e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.02768137864768505\n",
      "Gradient for encoder.encoder.0.bias: 5.079104498095788e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.005945668555796146\n",
      "Gradient for encoder.encoder.1.bias: 0.00357867986895144\n",
      "Gradient for encoder.encoder.3.weight: 0.11918468773365021\n",
      "Gradient for encoder.encoder.3.bias: 5.577961426084244e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.01437073852866888\n",
      "Gradient for encoder.encoder.4.bias: 0.01160130463540554\n",
      "Gradient for encoder.mean.weight: 0.18365676701068878\n",
      "Gradient for encoder.mean.bias: 0.007239153608679771\n",
      "Gradient for encoder.log_var.weight: 0.10076653212308884\n",
      "Gradient for encoder.log_var.bias: 0.004406300839036703\n",
      "Gradient for decoder.decoder.0.weight: 0.01546411495655775\n",
      "Gradient for decoder.decoder.0.bias: 1.2929127213290315e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.000809545861557126\n",
      "Gradient for decoder.decoder.1.bias: 0.0005938930553384125\n",
      "Gradient for decoder.decoder.3.weight: 0.013721289113163948\n",
      "Gradient for decoder.decoder.3.bias: 1.0039127168459672e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0005295100854709744\n",
      "Gradient for decoder.decoder.4.bias: 0.0005407756543718278\n",
      "Gradient for decoder.decoder.6.weight: 0.0005969874328002334\n",
      "Gradient for decoder.decoder.6.bias: 3.403650043765083e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.028211034834384918\n",
      "Gradient for encoder.encoder.0.bias: 4.5563535583381665e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0033744201064109802\n",
      "Gradient for encoder.encoder.1.bias: 0.002787497127428651\n",
      "Gradient for encoder.encoder.3.weight: 0.06830422580242157\n",
      "Gradient for encoder.encoder.3.bias: 4.0293976488747774e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.009463516995310783\n",
      "Gradient for encoder.encoder.4.bias: 0.008157342672348022\n",
      "Gradient for encoder.mean.weight: 0.12408645451068878\n",
      "Gradient for encoder.mean.bias: 0.005171582102775574\n",
      "Gradient for encoder.log_var.weight: 0.07460878044366837\n",
      "Gradient for encoder.log_var.bias: 0.0029424347449094057\n",
      "Gradient for decoder.decoder.0.weight: 0.014714528806507587\n",
      "Gradient for decoder.decoder.0.bias: 1.2907216961899337e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0007899350603111088\n",
      "Gradient for decoder.decoder.1.bias: 0.0005522612482309341\n",
      "Gradient for decoder.decoder.3.weight: 0.013079626485705376\n",
      "Gradient for decoder.decoder.3.bias: 1.0240325948318585e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0004550946468953043\n",
      "Gradient for decoder.decoder.4.bias: 0.0004128881264477968\n",
      "Gradient for decoder.decoder.6.weight: 0.0005561467842198908\n",
      "Gradient for decoder.decoder.6.bias: 2.782787305477541e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.02697402983903885\n",
      "Gradient for encoder.encoder.0.bias: 3.808645759884044e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.004521658644080162\n",
      "Gradient for encoder.encoder.1.bias: 0.0029502061661332846\n",
      "Gradient for encoder.encoder.3.weight: 0.08689290285110474\n",
      "Gradient for encoder.encoder.3.bias: 5.296674765453702e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.011242474429309368\n",
      "Gradient for encoder.encoder.4.bias: 0.010737616568803787\n",
      "Gradient for encoder.mean.weight: 0.1441245675086975\n",
      "Gradient for encoder.mean.bias: 0.009450515732169151\n",
      "Gradient for encoder.log_var.weight: 0.07703385502099991\n",
      "Gradient for encoder.log_var.bias: 0.005214375909417868\n",
      "Gradient for decoder.decoder.0.weight: 0.017118491232395172\n",
      "Gradient for decoder.decoder.0.bias: 1.493272172581328e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.000847350456751883\n",
      "Gradient for decoder.decoder.1.bias: 0.0006525255157612264\n",
      "Gradient for decoder.decoder.3.weight: 0.01458781212568283\n",
      "Gradient for decoder.decoder.3.bias: 1.1466871896459452e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0005413808976300061\n",
      "Gradient for decoder.decoder.4.bias: 0.0004950654110871255\n",
      "Gradient for decoder.decoder.6.weight: 0.0006212321459315717\n",
      "Gradient for decoder.decoder.6.bias: 3.492722680675797e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.028701668605208397\n",
      "Gradient for encoder.encoder.0.bias: 3.8425027049093785e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.004053403623402119\n",
      "Gradient for encoder.encoder.1.bias: 0.002960554789751768\n",
      "Gradient for encoder.encoder.3.weight: 0.08432402461767197\n",
      "Gradient for encoder.encoder.3.bias: 3.860871899963314e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.009204419329762459\n",
      "Gradient for encoder.encoder.4.bias: 0.006374217104166746\n",
      "Gradient for encoder.mean.weight: 0.11757183820009232\n",
      "Gradient for encoder.mean.bias: 0.004226272460073233\n",
      "Gradient for encoder.log_var.weight: 0.0575224831700325\n",
      "Gradient for encoder.log_var.bias: 0.002506179502233863\n",
      "Gradient for decoder.decoder.0.weight: 0.019817128777503967\n",
      "Gradient for decoder.decoder.0.bias: 1.7145618258496143e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0010395091958343983\n",
      "Gradient for decoder.decoder.1.bias: 0.000762801559176296\n",
      "Gradient for decoder.decoder.3.weight: 0.017708666622638702\n",
      "Gradient for decoder.decoder.3.bias: 1.5362469629742748e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0008316983003169298\n",
      "Gradient for decoder.decoder.4.bias: 0.0008525526500307024\n",
      "Gradient for decoder.decoder.6.weight: 0.0007140432135201991\n",
      "Gradient for decoder.decoder.6.bias: 4.539381552604027e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.03175358846783638\n",
      "Gradient for encoder.encoder.0.bias: 4.001215331284058e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.004864507354795933\n",
      "Gradient for encoder.encoder.1.bias: 0.003029849845916033\n",
      "Gradient for encoder.encoder.3.weight: 0.09246527403593063\n",
      "Gradient for encoder.encoder.3.bias: 4.750343451931371e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.010901698842644691\n",
      "Gradient for encoder.encoder.4.bias: 0.010303670540452003\n",
      "Gradient for encoder.mean.weight: 0.14027974009513855\n",
      "Gradient for encoder.mean.bias: 0.008138950914144516\n",
      "Gradient for encoder.log_var.weight: 0.07121243327856064\n",
      "Gradient for encoder.log_var.bias: 0.0041967835277318954\n",
      "Gradient for decoder.decoder.0.weight: 0.021470289677381516\n",
      "Gradient for decoder.decoder.0.bias: 1.7464769908048794e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.001062598661519587\n",
      "Gradient for decoder.decoder.1.bias: 0.0007976656197570264\n",
      "Gradient for decoder.decoder.3.weight: 0.01948356255888939\n",
      "Gradient for decoder.decoder.3.bias: 1.38159580997943e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.000913557130843401\n",
      "Gradient for decoder.decoder.4.bias: 0.0009890320943668485\n",
      "Gradient for decoder.decoder.6.weight: 0.0008076268713921309\n",
      "Gradient for decoder.decoder.6.bias: 6.093938645790331e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.02999068982899189\n",
      "Gradient for encoder.encoder.0.bias: 4.825734950530958e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.004123208113014698\n",
      "Gradient for encoder.encoder.1.bias: 0.0025134822353720665\n",
      "Gradient for encoder.encoder.3.weight: 0.08221663534641266\n",
      "Gradient for encoder.encoder.3.bias: 4.810568055013675e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.01148185320198536\n",
      "Gradient for encoder.encoder.4.bias: 0.00966055877506733\n",
      "Gradient for encoder.mean.weight: 0.14317123591899872\n",
      "Gradient for encoder.mean.bias: 0.005529501941055059\n",
      "Gradient for encoder.log_var.weight: 0.09125354140996933\n",
      "Gradient for encoder.log_var.bias: 0.0034620703663676977\n",
      "Gradient for decoder.decoder.0.weight: 0.012940964661538601\n",
      "Gradient for decoder.decoder.0.bias: 1.1978482095109655e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0006738407537341118\n",
      "Gradient for decoder.decoder.1.bias: 0.000489389116410166\n",
      "Gradient for decoder.decoder.3.weight: 0.011074591428041458\n",
      "Gradient for decoder.decoder.3.bias: 9.58296428321681e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00047177879605442286\n",
      "Gradient for decoder.decoder.4.bias: 0.0005065056029707193\n",
      "Gradient for decoder.decoder.6.weight: 0.0005453265039250255\n",
      "Gradient for decoder.decoder.6.bias: 3.236859629396349e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.03198724240064621\n",
      "Gradient for encoder.encoder.0.bias: 4.3215514500261065e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.003980659414082766\n",
      "Gradient for encoder.encoder.1.bias: 0.0027401491533964872\n",
      "Gradient for encoder.encoder.3.weight: 0.07965393364429474\n",
      "Gradient for encoder.encoder.3.bias: 4.5963682859806454e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.008760496973991394\n",
      "Gradient for encoder.encoder.4.bias: 0.008451986126601696\n",
      "Gradient for encoder.mean.weight: 0.12172950059175491\n",
      "Gradient for encoder.mean.bias: 0.006108066998422146\n",
      "Gradient for encoder.log_var.weight: 0.06262444704771042\n",
      "Gradient for encoder.log_var.bias: 0.0034932272974401712\n",
      "Gradient for decoder.decoder.0.weight: 0.014405544847249985\n",
      "Gradient for decoder.decoder.0.bias: 1.376315728052191e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0007250314811244607\n",
      "Gradient for decoder.decoder.1.bias: 0.0005344949313439429\n",
      "Gradient for decoder.decoder.3.weight: 0.012533328495919704\n",
      "Gradient for decoder.decoder.3.bias: 1.1514181275096291e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0004556691274046898\n",
      "Gradient for decoder.decoder.4.bias: 0.0003811836941167712\n",
      "Gradient for decoder.decoder.6.weight: 0.0005953062791377306\n",
      "Gradient for decoder.decoder.6.bias: 3.054839180549607e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.021551018580794334\n",
      "Gradient for encoder.encoder.0.bias: 2.9583790278620015e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.00262702745385468\n",
      "Gradient for encoder.encoder.1.bias: 0.0019904011860489845\n",
      "Gradient for encoder.encoder.3.weight: 0.051553644239902496\n",
      "Gradient for encoder.encoder.3.bias: 3.448911711778635e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.006439269054681063\n",
      "Gradient for encoder.encoder.4.bias: 0.006315623410046101\n",
      "Gradient for encoder.mean.weight: 0.08516956120729446\n",
      "Gradient for encoder.mean.bias: 0.005126130301505327\n",
      "Gradient for encoder.log_var.weight: 0.0458911694586277\n",
      "Gradient for encoder.log_var.bias: 0.0031055277213454247\n",
      "Gradient for decoder.decoder.0.weight: 0.018218157812952995\n",
      "Gradient for decoder.decoder.0.bias: 1.4888275334801193e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0009594502625986934\n",
      "Gradient for decoder.decoder.1.bias: 0.0006733051268383861\n",
      "Gradient for decoder.decoder.3.weight: 0.01650538481771946\n",
      "Gradient for decoder.decoder.3.bias: 1.4293795314035407e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0008019917877390981\n",
      "Gradient for decoder.decoder.4.bias: 0.0008738545584492385\n",
      "Gradient for decoder.decoder.6.weight: 0.0006944549968466163\n",
      "Gradient for decoder.decoder.6.bias: 4.685266685555689e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.04989345371723175\n",
      "Gradient for encoder.encoder.0.bias: 6.55890550205207e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0058629391714930534\n",
      "Gradient for encoder.encoder.1.bias: 0.004372245632112026\n",
      "Gradient for encoder.encoder.3.weight: 0.11885172128677368\n",
      "Gradient for encoder.encoder.3.bias: 5.554747772862356e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.013435417786240578\n",
      "Gradient for encoder.encoder.4.bias: 0.010782409459352493\n",
      "Gradient for encoder.mean.weight: 0.16990895569324493\n",
      "Gradient for encoder.mean.bias: 0.00699583301320672\n",
      "Gradient for encoder.log_var.weight: 0.08937425166368484\n",
      "Gradient for encoder.log_var.bias: 0.0036922793369740248\n",
      "Gradient for decoder.decoder.0.weight: 0.01905694603919983\n",
      "Gradient for decoder.decoder.0.bias: 1.5956598542476996e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0010243860306218266\n",
      "Gradient for decoder.decoder.1.bias: 0.0007088115671649575\n",
      "Gradient for decoder.decoder.3.weight: 0.016732530668377876\n",
      "Gradient for decoder.decoder.3.bias: 1.2872382326722942e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0006595638697035611\n",
      "Gradient for decoder.decoder.4.bias: 0.0006338264793157578\n",
      "Gradient for decoder.decoder.6.weight: 0.0006206415127962828\n",
      "Gradient for decoder.decoder.6.bias: 3.5633343941299245e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.02810262329876423\n",
      "Gradient for encoder.encoder.0.bias: 4.426388075517984e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0036660307087004185\n",
      "Gradient for encoder.encoder.1.bias: 0.002516204258427024\n",
      "Gradient for encoder.encoder.3.weight: 0.06841515004634857\n",
      "Gradient for encoder.encoder.3.bias: 3.520748970142762e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.006673166994005442\n",
      "Gradient for encoder.encoder.4.bias: 0.005905627738684416\n",
      "Gradient for encoder.mean.weight: 0.08834275603294373\n",
      "Gradient for encoder.mean.bias: 0.0045180292800068855\n",
      "Gradient for encoder.log_var.weight: 0.04701611399650574\n",
      "Gradient for encoder.log_var.bias: 0.0025894949212670326\n",
      "Gradient for decoder.decoder.0.weight: 0.015459786169230938\n",
      "Gradient for decoder.decoder.0.bias: 1.2355579059875055e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0008062419365160167\n",
      "Gradient for decoder.decoder.1.bias: 0.0005789151764474809\n",
      "Gradient for decoder.decoder.3.weight: 0.013447574339807034\n",
      "Gradient for decoder.decoder.3.bias: 1.0420637269747957e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0004666375170927495\n",
      "Gradient for decoder.decoder.4.bias: 0.00040995722520165145\n",
      "Gradient for decoder.decoder.6.weight: 0.0005448562442325056\n",
      "Gradient for decoder.decoder.6.bias: 2.520604175515473e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.021424230188131332\n",
      "Gradient for encoder.encoder.0.bias: 2.8297190979298392e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.003065569791942835\n",
      "Gradient for encoder.encoder.1.bias: 0.002023765817284584\n",
      "Gradient for encoder.encoder.3.weight: 0.059762563556432724\n",
      "Gradient for encoder.encoder.3.bias: 3.409246773777852e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.006351566407829523\n",
      "Gradient for encoder.encoder.4.bias: 0.005869445390999317\n",
      "Gradient for encoder.mean.weight: 0.08448931574821472\n",
      "Gradient for encoder.mean.bias: 0.00515405461192131\n",
      "Gradient for encoder.log_var.weight: 0.04683513566851616\n",
      "Gradient for encoder.log_var.bias: 0.002795071806758642\n",
      "Gradient for decoder.decoder.0.weight: 0.018059320747852325\n",
      "Gradient for decoder.decoder.0.bias: 1.519669390326328e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0009340335964225233\n",
      "Gradient for decoder.decoder.1.bias: 0.0006556204752996564\n",
      "Gradient for decoder.decoder.3.weight: 0.016211634501814842\n",
      "Gradient for decoder.decoder.3.bias: 1.1316649700665593e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.00054813118185848\n",
      "Gradient for decoder.decoder.4.bias: 0.0005022443365305662\n",
      "Gradient for decoder.decoder.6.weight: 0.0005781071959063411\n",
      "Gradient for decoder.decoder.6.bias: 2.949654299300164e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.032849784940481186\n",
      "Gradient for encoder.encoder.0.bias: 5.081500498160807e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.004529373720288277\n",
      "Gradient for encoder.encoder.1.bias: 0.003222644329071045\n",
      "Gradient for encoder.encoder.3.weight: 0.0906226858496666\n",
      "Gradient for encoder.encoder.3.bias: 6.934952057058297e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.01793544553220272\n",
      "Gradient for encoder.encoder.4.bias: 0.014615976251661777\n",
      "Gradient for encoder.mean.weight: 0.2206549197435379\n",
      "Gradient for encoder.mean.bias: 0.008250358514487743\n",
      "Gradient for encoder.log_var.weight: 0.12541459500789642\n",
      "Gradient for encoder.log_var.bias: 0.004401677288115025\n",
      "Gradient for decoder.decoder.0.weight: 0.017086952924728394\n",
      "Gradient for decoder.decoder.0.bias: 1.3675879872998564e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0008920483523979783\n",
      "Gradient for decoder.decoder.1.bias: 0.0006683035171590745\n",
      "Gradient for decoder.decoder.3.weight: 0.015586376190185547\n",
      "Gradient for decoder.decoder.3.bias: 1.1748570172276374e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0005874894559383392\n",
      "Gradient for decoder.decoder.4.bias: 0.0005341017385944724\n",
      "Gradient for decoder.decoder.6.weight: 0.0005644474877044559\n",
      "Gradient for decoder.decoder.6.bias: 2.2965097741689533e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.07996874302625656\n",
      "Gradient for encoder.encoder.0.bias: 1.5296933164599125e-10\n",
      "Gradient for encoder.encoder.1.weight: 0.011393839493393898\n",
      "Gradient for encoder.encoder.1.bias: 0.008915584534406662\n",
      "Gradient for encoder.encoder.3.weight: 0.250494122505188\n",
      "Gradient for encoder.encoder.3.bias: 1.3110241781078003e-09\n",
      "Gradient for encoder.encoder.4.weight: 0.027217868715524673\n",
      "Gradient for encoder.encoder.4.bias: 0.02503039315342903\n",
      "Gradient for encoder.mean.weight: 0.352388858795166\n",
      "Gradient for encoder.mean.bias: 0.01128958910703659\n",
      "Gradient for encoder.log_var.weight: 0.21233177185058594\n",
      "Gradient for encoder.log_var.bias: 0.006947475019842386\n",
      "Gradient for decoder.decoder.0.weight: 0.040576573461294174\n",
      "Gradient for decoder.decoder.0.bias: 2.4543791998787867e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0018478304846212268\n",
      "Gradient for decoder.decoder.1.bias: 0.0014114471850916743\n",
      "Gradient for decoder.decoder.3.weight: 0.033818136900663376\n",
      "Gradient for decoder.decoder.3.bias: 2.932426801383059e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0015658126212656498\n",
      "Gradient for decoder.decoder.4.bias: 0.0017018069047480822\n",
      "Gradient for decoder.decoder.6.weight: 0.0019558994099497795\n",
      "Gradient for decoder.decoder.6.bias: 0.00012969587987754494\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3, Train Loss: 0.0723, Val Loss: 0.2834\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training VAE Epoch:   0%|          | 0/79 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient for encoder.encoder.0.weight: 0.046299148350954056\n",
      "Gradient for encoder.encoder.0.bias: 8.273363938382516e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.006440593395382166\n",
      "Gradient for encoder.encoder.1.bias: 0.004776510875672102\n",
      "Gradient for encoder.encoder.3.weight: 0.14166101813316345\n",
      "Gradient for encoder.encoder.3.bias: 9.7196173332037e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.02334938570857048\n",
      "Gradient for encoder.encoder.4.bias: 0.0187489353120327\n",
      "Gradient for encoder.mean.weight: 0.28793877363204956\n",
      "Gradient for encoder.mean.bias: 0.01095972303301096\n",
      "Gradient for encoder.log_var.weight: 0.173061341047287\n",
      "Gradient for encoder.log_var.bias: 0.006374026648700237\n",
      "Gradient for decoder.decoder.0.weight: 0.013388451188802719\n",
      "Gradient for decoder.decoder.0.bias: 1.195560178635091e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0007046748069114983\n",
      "Gradient for decoder.decoder.1.bias: 0.0005089505575597286\n",
      "Gradient for decoder.decoder.3.weight: 0.012024465948343277\n",
      "Gradient for decoder.decoder.3.bias: 1.0100011799130115e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0005587136838585138\n",
      "Gradient for decoder.decoder.4.bias: 0.0005890332395210862\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training VAE Epoch:  11%|█▏        | 9/79 [00:00<00:02, 34.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient for decoder.decoder.6.weight: 0.0006265168194659054\n",
      "Gradient for decoder.decoder.6.bias: 4.5290660636965185e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.030224312096834183\n",
      "Gradient for encoder.encoder.0.bias: 4.624460189783797e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0038773170672357082\n",
      "Gradient for encoder.encoder.1.bias: 0.0030425691511482\n",
      "Gradient for encoder.encoder.3.weight: 0.0865781307220459\n",
      "Gradient for encoder.encoder.3.bias: 5.572856065505505e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.013121835887432098\n",
      "Gradient for encoder.encoder.4.bias: 0.011486541479825974\n",
      "Gradient for encoder.mean.weight: 0.16389784216880798\n",
      "Gradient for encoder.mean.bias: 0.005976996384561062\n",
      "Gradient for encoder.log_var.weight: 0.1034456416964531\n",
      "Gradient for encoder.log_var.bias: 0.0034827960189431906\n",
      "Gradient for decoder.decoder.0.weight: 0.01640547625720501\n",
      "Gradient for decoder.decoder.0.bias: 1.329998056132098e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0008728831307962537\n",
      "Gradient for decoder.decoder.1.bias: 0.0006233557360246778\n",
      "Gradient for decoder.decoder.3.weight: 0.014880049973726273\n",
      "Gradient for decoder.decoder.3.bias: 1.0935190253302807e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0005301801138557494\n",
      "Gradient for decoder.decoder.4.bias: 0.00047423719661310315\n",
      "Gradient for decoder.decoder.6.weight: 0.0005963363219052553\n",
      "Gradient for decoder.decoder.6.bias: 3.385108720976859e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.04116743057966232\n",
      "Gradient for encoder.encoder.0.bias: 6.54560294854889e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.005103994160890579\n",
      "Gradient for encoder.encoder.1.bias: 0.0038888861890882254\n",
      "Gradient for encoder.encoder.3.weight: 0.11219078302383423\n",
      "Gradient for encoder.encoder.3.bias: 5.296795779763386e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.014608064666390419\n",
      "Gradient for encoder.encoder.4.bias: 0.010909792967140675\n",
      "Gradient for encoder.mean.weight: 0.18812832236289978\n",
      "Gradient for encoder.mean.bias: 0.008227499201893806\n",
      "Gradient for encoder.log_var.weight: 0.0940157100558281\n",
      "Gradient for encoder.log_var.bias: 0.0038402732461690903\n",
      "Gradient for decoder.decoder.0.weight: 0.013260460458695889\n",
      "Gradient for decoder.decoder.0.bias: 1.1008249867217046e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0007028687396086752\n",
      "Gradient for decoder.decoder.1.bias: 0.00048581016017124057\n",
      "Gradient for decoder.decoder.3.weight: 0.011664573103189468\n",
      "Gradient for decoder.decoder.3.bias: 1.0553959789438849e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0005478437524288893\n",
      "Gradient for decoder.decoder.4.bias: 0.0006128972163423896\n",
      "Gradient for decoder.decoder.6.weight: 0.0005887787556275725\n",
      "Gradient for decoder.decoder.6.bias: 4.121296660741791e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.02773079089820385\n",
      "Gradient for encoder.encoder.0.bias: 3.715996954589684e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.003508874448016286\n",
      "Gradient for encoder.encoder.1.bias: 0.002640205668285489\n",
      "Gradient for encoder.encoder.3.weight: 0.07457426190376282\n",
      "Gradient for encoder.encoder.3.bias: 4.815076670716678e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.008759652264416218\n",
      "Gradient for encoder.encoder.4.bias: 0.00917146261781454\n",
      "Gradient for encoder.mean.weight: 0.12011796981096268\n",
      "Gradient for encoder.mean.bias: 0.006732551846653223\n",
      "Gradient for encoder.log_var.weight: 0.06251943856477737\n",
      "Gradient for encoder.log_var.bias: 0.0034082788042724133\n",
      "Gradient for decoder.decoder.0.weight: 0.01742587983608246\n",
      "Gradient for decoder.decoder.0.bias: 1.510242625402114e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0009254571050405502\n",
      "Gradient for decoder.decoder.1.bias: 0.0006927818758413196\n",
      "Gradient for decoder.decoder.3.weight: 0.016299476847052574\n",
      "Gradient for decoder.decoder.3.bias: 1.1594474685905354e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0006360606639645994\n",
      "Gradient for decoder.decoder.4.bias: 0.0005994908278807998\n",
      "Gradient for decoder.decoder.6.weight: 0.0006539327441714704\n",
      "Gradient for decoder.decoder.6.bias: 3.5826495150104165e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.038441672921180725\n",
      "Gradient for encoder.encoder.0.bias: 5.366298724829299e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.004552221857011318\n",
      "Gradient for encoder.encoder.1.bias: 0.0033262704964727163\n",
      "Gradient for encoder.encoder.3.weight: 0.10184583067893982\n",
      "Gradient for encoder.encoder.3.bias: 5.404509062501006e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.012781934812664986\n",
      "Gradient for encoder.encoder.4.bias: 0.011169272474944592\n",
      "Gradient for encoder.mean.weight: 0.16721659898757935\n",
      "Gradient for encoder.mean.bias: 0.008841014467179775\n",
      "Gradient for encoder.log_var.weight: 0.08775294572114944\n",
      "Gradient for encoder.log_var.bias: 0.004878679756075144\n",
      "Gradient for decoder.decoder.0.weight: 0.013090383261442184\n",
      "Gradient for decoder.decoder.0.bias: 1.0928098009843623e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0007059538038447499\n",
      "Gradient for decoder.decoder.1.bias: 0.00048818395589478314\n",
      "Gradient for decoder.decoder.3.weight: 0.011488951742649078\n",
      "Gradient for decoder.decoder.3.bias: 8.634109399663359e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00046517804730683565\n",
      "Gradient for decoder.decoder.4.bias: 0.0005233025876805186\n",
      "Gradient for decoder.decoder.6.weight: 0.0005734904552809894\n",
      "Gradient for decoder.decoder.6.bias: 3.687071875901893e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.04732669144868851\n",
      "Gradient for encoder.encoder.0.bias: 5.867623054101045e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.006419085897505283\n",
      "Gradient for encoder.encoder.1.bias: 0.0046511366963386536\n",
      "Gradient for encoder.encoder.3.weight: 0.12640197575092316\n",
      "Gradient for encoder.encoder.3.bias: 6.223091486567967e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.01263495534658432\n",
      "Gradient for encoder.encoder.4.bias: 0.013521476648747921\n",
      "Gradient for encoder.mean.weight: 0.16086556017398834\n",
      "Gradient for encoder.mean.bias: 0.009142755530774593\n",
      "Gradient for encoder.log_var.weight: 0.09173073619604111\n",
      "Gradient for encoder.log_var.bias: 0.005088698584586382\n",
      "Gradient for decoder.decoder.0.weight: 0.020142659544944763\n",
      "Gradient for decoder.decoder.0.bias: 1.7264160934171713e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0010474345181137323\n",
      "Gradient for decoder.decoder.1.bias: 0.0007760684238746762\n",
      "Gradient for decoder.decoder.3.weight: 0.01811288855969906\n",
      "Gradient for decoder.decoder.3.bias: 1.4465559305953946e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0006329370080493391\n",
      "Gradient for decoder.decoder.4.bias: 0.0005391614395193756\n",
      "Gradient for decoder.decoder.6.weight: 0.0006589284166693687\n",
      "Gradient for decoder.decoder.6.bias: 3.841165016638115e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.021793736144900322\n",
      "Gradient for encoder.encoder.0.bias: 3.4743083410226916e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.004048668779432774\n",
      "Gradient for encoder.encoder.1.bias: 0.0034912314731627703\n",
      "Gradient for encoder.encoder.3.weight: 0.09222721308469772\n",
      "Gradient for encoder.encoder.3.bias: 5.070147635066746e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.011302374303340912\n",
      "Gradient for encoder.encoder.4.bias: 0.011020242236554623\n",
      "Gradient for encoder.mean.weight: 0.1465776264667511\n",
      "Gradient for encoder.mean.bias: 0.00660606799647212\n",
      "Gradient for encoder.log_var.weight: 0.08435769379138947\n",
      "Gradient for encoder.log_var.bias: 0.00415441207587719\n",
      "Gradient for decoder.decoder.0.weight: 0.020730236545205116\n",
      "Gradient for decoder.decoder.0.bias: 1.6999962548780445e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0011588888010010123\n",
      "Gradient for decoder.decoder.1.bias: 0.0007816312136128545\n",
      "Gradient for decoder.decoder.3.weight: 0.01835830695927143\n",
      "Gradient for decoder.decoder.3.bias: 1.5447376711108518e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0007034619338810444\n",
      "Gradient for decoder.decoder.4.bias: 0.0006651866133324802\n",
      "Gradient for decoder.decoder.6.weight: 0.0006443812744691968\n",
      "Gradient for decoder.decoder.6.bias: 3.5423094232100993e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.034619953483343124\n",
      "Gradient for encoder.encoder.0.bias: 6.058546719867053e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0034593595191836357\n",
      "Gradient for encoder.encoder.1.bias: 0.0026064924895763397\n",
      "Gradient for encoder.encoder.3.weight: 0.08062548190355301\n",
      "Gradient for encoder.encoder.3.bias: 5.38233513314168e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.008618141524493694\n",
      "Gradient for encoder.encoder.4.bias: 0.0090335663408041\n",
      "Gradient for encoder.mean.weight: 0.10954193025827408\n",
      "Gradient for encoder.mean.bias: 0.006654918193817139\n",
      "Gradient for encoder.log_var.weight: 0.06365528702735901\n",
      "Gradient for encoder.log_var.bias: 0.004261462949216366\n",
      "Gradient for decoder.decoder.0.weight: 0.012324482202529907\n",
      "Gradient for decoder.decoder.0.bias: 1.1957364265402504e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0006592425634153187\n",
      "Gradient for decoder.decoder.1.bias: 0.0005087798344902694\n",
      "Gradient for decoder.decoder.3.weight: 0.010988800786435604\n",
      "Gradient for decoder.decoder.3.bias: 1.014528738796372e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0005509583279490471\n",
      "Gradient for decoder.decoder.4.bias: 0.0006366276065818965\n",
      "Gradient for decoder.decoder.6.weight: 0.0006339139072224498\n",
      "Gradient for decoder.decoder.6.bias: 4.9234051402891055e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.026299767196178436\n",
      "Gradient for encoder.encoder.0.bias: 3.951619240161186e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.003153142286464572\n",
      "Gradient for encoder.encoder.1.bias: 0.002399669960141182\n",
      "Gradient for encoder.encoder.3.weight: 0.06698678433895111\n",
      "Gradient for encoder.encoder.3.bias: 4.0031336578927323e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.008381389081478119\n",
      "Gradient for encoder.encoder.4.bias: 0.0070068323984742165\n",
      "Gradient for encoder.mean.weight: 0.10645128041505814\n",
      "Gradient for encoder.mean.bias: 0.004895778372883797\n",
      "Gradient for encoder.log_var.weight: 0.06190936639904976\n",
      "Gradient for encoder.log_var.bias: 0.0029076975770294666\n",
      "Gradient for decoder.decoder.0.weight: 0.016023660078644753\n",
      "Gradient for decoder.decoder.0.bias: 1.348998690531289e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0008488402818329632\n",
      "Gradient for decoder.decoder.1.bias: 0.0006030469085089862\n",
      "Gradient for decoder.decoder.3.weight: 0.014637471176683903\n",
      "Gradient for decoder.decoder.3.bias: 1.1384748005438539e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0007197982049547136\n",
      "Gradient for decoder.decoder.4.bias: 0.0007355375564657152\n",
      "Gradient for decoder.decoder.6.weight: 0.0007430545520037413\n",
      "Gradient for decoder.decoder.6.bias: 5.2263443649280816e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.024747971445322037\n",
      "Gradient for encoder.encoder.0.bias: 4.595818517416639e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.003953207284212112\n",
      "Gradient for encoder.encoder.1.bias: 0.002460230141878128\n",
      "Gradient for encoder.encoder.3.weight: 0.07446802407503128\n",
      "Gradient for encoder.encoder.3.bias: 3.755739608202191e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.008623292669653893\n",
      "Gradient for encoder.encoder.4.bias: 0.007777379360049963\n",
      "Gradient for encoder.mean.weight: 0.11513537913560867\n",
      "Gradient for encoder.mean.bias: 0.005257814656943083\n",
      "Gradient for encoder.log_var.weight: 0.07442638278007507\n",
      "Gradient for encoder.log_var.bias: 0.0033713970333337784\n",
      "Gradient for decoder.decoder.0.weight: 0.01493101567029953\n",
      "Gradient for decoder.decoder.0.bias: 1.3106790652805955e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0008321759523823857\n",
      "Gradient for decoder.decoder.1.bias: 0.000584324006922543\n",
      "Gradient for decoder.decoder.3.weight: 0.013237492181360722\n",
      "Gradient for decoder.decoder.3.bias: 1.1140834782485953e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0004772600659634918\n",
      "Gradient for decoder.decoder.4.bias: 0.0004359210724942386\n",
      "Gradient for decoder.decoder.6.weight: 0.0005750956479460001\n",
      "Gradient for decoder.decoder.6.bias: 2.5651073883636855e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.02732638642191887\n",
      "Gradient for encoder.encoder.0.bias: 5.146481157902727e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0029814396984875202\n",
      "Gradient for encoder.encoder.1.bias: 0.002380691235885024\n",
      "Gradient for encoder.encoder.3.weight: 0.06467680633068085\n",
      "Gradient for encoder.encoder.3.bias: 4.1303885311982924e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.007879108190536499\n",
      "Gradient for encoder.encoder.4.bias: 0.006893562152981758\n",
      "Gradient for encoder.mean.weight: 0.10186893492937088\n",
      "Gradient for encoder.mean.bias: 0.0057020667009055614\n",
      "Gradient for encoder.log_var.weight: 0.0511922650039196\n",
      "Gradient for encoder.log_var.bias: 0.0032097825314849615\n",
      "Gradient for decoder.decoder.0.weight: 0.013439868576824665\n",
      "Gradient for decoder.decoder.0.bias: 1.162627355499879e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0006870541837997735\n",
      "Gradient for decoder.decoder.1.bias: 0.0004962363163940609\n",
      "Gradient for decoder.decoder.3.weight: 0.012136423029005527\n",
      "Gradient for decoder.decoder.3.bias: 9.144521251336357e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0005283142672851682\n",
      "Gradient for decoder.decoder.4.bias: 0.0005617691203951836\n",
      "Gradient for decoder.decoder.6.weight: 0.0005957894027233124\n",
      "Gradient for decoder.decoder.6.bias: 4.0309638279723004e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.042808253318071365\n",
      "Gradient for encoder.encoder.0.bias: 7.257675710414802e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0046079037711024284\n",
      "Gradient for encoder.encoder.1.bias: 0.003616571659222245\n",
      "Gradient for encoder.encoder.3.weight: 0.09702005982398987\n",
      "Gradient for encoder.encoder.3.bias: 6.939036567565893e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.018183670938014984\n",
      "Gradient for encoder.encoder.4.bias: 0.012561595998704433\n",
      "Gradient for encoder.mean.weight: 0.22256572544574738\n",
      "Gradient for encoder.mean.bias: 0.008059573359787464\n",
      "Gradient for encoder.log_var.weight: 0.12156036496162415\n",
      "Gradient for encoder.log_var.bias: 0.004210382234305143\n",
      "Gradient for decoder.decoder.0.weight: 0.013738471083343029\n",
      "Gradient for decoder.decoder.0.bias: 1.2333722931856528e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.000728517712559551\n",
      "Gradient for decoder.decoder.1.bias: 0.0005198594299145043\n",
      "Gradient for decoder.decoder.3.weight: 0.012607003562152386\n",
      "Gradient for decoder.decoder.3.bias: 9.841636533503006e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0005547871114686131\n",
      "Gradient for decoder.decoder.4.bias: 0.0005764762172475457\n",
      "Gradient for decoder.decoder.6.weight: 0.0005948187317699194\n",
      "Gradient for decoder.decoder.6.bias: 3.943993942812085e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.036634061485528946\n",
      "Gradient for encoder.encoder.0.bias: 5.800054186932968e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0045042685233056545\n",
      "Gradient for encoder.encoder.1.bias: 0.0032336555887013674\n",
      "Gradient for encoder.encoder.3.weight: 0.09452953189611435\n",
      "Gradient for encoder.encoder.3.bias: 4.904040507014429e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.009618496522307396\n",
      "Gradient for encoder.encoder.4.bias: 0.009344021789729595\n",
      "Gradient for encoder.mean.weight: 0.13349531590938568\n",
      "Gradient for encoder.mean.bias: 0.005991586018353701\n",
      "Gradient for encoder.log_var.weight: 0.07489090412855148\n",
      "Gradient for encoder.log_var.bias: 0.004126602318137884\n",
      "Gradient for decoder.decoder.0.weight: 0.015334186144173145\n",
      "Gradient for decoder.decoder.0.bias: 1.3679507526731527e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.000807145785074681\n",
      "Gradient for decoder.decoder.1.bias: 0.0005769478157162666\n",
      "Gradient for decoder.decoder.3.weight: 0.013715344481170177\n",
      "Gradient for decoder.decoder.3.bias: 1.1278450395835193e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.00046502871555276215\n",
      "Gradient for decoder.decoder.4.bias: 0.00043657992500811815\n",
      "Gradient for decoder.decoder.6.weight: 0.0005520336562767625\n",
      "Gradient for decoder.decoder.6.bias: 2.886884794861544e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.02643698640167713\n",
      "Gradient for encoder.encoder.0.bias: 5.108760289807002e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.005115846171975136\n",
      "Gradient for encoder.encoder.1.bias: 0.0033840904943645\n",
      "Gradient for encoder.encoder.3.weight: 0.10907941311597824\n",
      "Gradient for encoder.encoder.3.bias: 5.294303329073102e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.013835230842232704\n",
      "Gradient for encoder.encoder.4.bias: 0.01160800363868475\n",
      "Gradient for encoder.mean.weight: 0.1707172393798828\n",
      "Gradient for encoder.mean.bias: 0.005949205718934536\n",
      "Gradient for encoder.log_var.weight: 0.1088247075676918\n",
      "Gradient for encoder.log_var.bias: 0.004629736300557852\n",
      "Gradient for decoder.decoder.0.weight: 0.01356152631342411\n",
      "Gradient for decoder.decoder.0.bias: 1.1307926123249601e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0006936765275895596\n",
      "Gradient for decoder.decoder.1.bias: 0.0005468183662742376\n",
      "Gradient for decoder.decoder.3.weight: 0.012202438898384571\n",
      "Gradient for decoder.decoder.3.bias: 9.054819394282987e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00044663992593996227\n",
      "Gradient for decoder.decoder.4.bias: 0.0003787093155551702\n",
      "Gradient for decoder.decoder.6.weight: 0.0005769258132204413\n",
      "Gradient for decoder.decoder.6.bias: 3.166238820995204e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.025425124913454056\n",
      "Gradient for encoder.encoder.0.bias: 3.7153884135943116e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.004092928487807512\n",
      "Gradient for encoder.encoder.1.bias: 0.0028442959301173687\n",
      "Gradient for encoder.encoder.3.weight: 0.07815120369195938\n",
      "Gradient for encoder.encoder.3.bias: 3.4374755819577274e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.007698941510170698\n",
      "Gradient for encoder.encoder.4.bias: 0.007076000329107046\n",
      "Gradient for encoder.mean.weight: 0.09762658923864365\n",
      "Gradient for encoder.mean.bias: 0.004617571365088224\n",
      "Gradient for encoder.log_var.weight: 0.061915285885334015\n",
      "Gradient for encoder.log_var.bias: 0.0030024240259081125\n",
      "Gradient for decoder.decoder.0.weight: 0.016362112015485764\n",
      "Gradient for decoder.decoder.0.bias: 1.3004368415447942e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0008983304142020643\n",
      "Gradient for decoder.decoder.1.bias: 0.0006000060238875449\n",
      "Gradient for decoder.decoder.3.weight: 0.015122083015739918\n",
      "Gradient for decoder.decoder.3.bias: 1.2031516061217218e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0005368365673348308\n",
      "Gradient for decoder.decoder.4.bias: 0.0005028697778470814\n",
      "Gradient for decoder.decoder.6.weight: 0.0006199665367603302\n",
      "Gradient for decoder.decoder.6.bias: 3.360117261763662e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.022969292476773262\n",
      "Gradient for encoder.encoder.0.bias: 3.723423305790341e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.003314386587589979\n",
      "Gradient for encoder.encoder.1.bias: 0.002298457082360983\n",
      "Gradient for encoder.encoder.3.weight: 0.06719863414764404\n",
      "Gradient for encoder.encoder.3.bias: 4.596578673243812e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.008699878118932247\n",
      "Gradient for encoder.encoder.4.bias: 0.009030726738274097\n",
      "Gradient for encoder.mean.weight: 0.11062701046466827\n",
      "Gradient for encoder.mean.bias: 0.00702436501160264\n",
      "Gradient for encoder.log_var.weight: 0.06573688238859177\n",
      "Gradient for encoder.log_var.bias: 0.004067129921168089\n",
      "Gradient for decoder.decoder.0.weight: 0.016108868643641472\n",
      "Gradient for decoder.decoder.0.bias: 1.3237839990853928e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0007931282743811607\n",
      "Gradient for decoder.decoder.1.bias: 0.0006084914202801883\n",
      "Gradient for decoder.decoder.3.weight: 0.014164148829877377\n",
      "Gradient for decoder.decoder.3.bias: 1.2112189029522824e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0005429557641036808\n",
      "Gradient for decoder.decoder.4.bias: 0.0004991671303287148\n",
      "Gradient for decoder.decoder.6.weight: 0.0006017362466081977\n",
      "Gradient for decoder.decoder.6.bias: 3.1806222978048027e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training VAE Epoch:  32%|███▏      | 25/79 [00:00<00:00, 59.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient for encoder.encoder.0.weight: 0.018041037023067474\n",
      "Gradient for encoder.encoder.0.bias: 2.607813791299929e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.002767556579783559\n",
      "Gradient for encoder.encoder.1.bias: 0.0022131402511149645\n",
      "Gradient for encoder.encoder.3.weight: 0.054805438965559006\n",
      "Gradient for encoder.encoder.3.bias: 5.122710589056112e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.00851347204297781\n",
      "Gradient for encoder.encoder.4.bias: 0.010962866246700287\n",
      "Gradient for encoder.mean.weight: 0.10693284869194031\n",
      "Gradient for encoder.mean.bias: 0.008624025620520115\n",
      "Gradient for encoder.log_var.weight: 0.06850937753915787\n",
      "Gradient for encoder.log_var.bias: 0.005513807293027639\n",
      "Gradient for decoder.decoder.0.weight: 0.018697677180171013\n",
      "Gradient for decoder.decoder.0.bias: 1.521541087567968e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0009566678781993687\n",
      "Gradient for decoder.decoder.1.bias: 0.0007109190919436514\n",
      "Gradient for decoder.decoder.3.weight: 0.015900008380413055\n",
      "Gradient for decoder.decoder.3.bias: 1.268194854686655e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0005920827970840037\n",
      "Gradient for decoder.decoder.4.bias: 0.0005058360402472317\n",
      "Gradient for decoder.decoder.6.weight: 0.0006191750871948898\n",
      "Gradient for decoder.decoder.6.bias: 2.9264698241604492e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.03163589537143707\n",
      "Gradient for encoder.encoder.0.bias: 5.2392982313742564e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.003617434296756983\n",
      "Gradient for encoder.encoder.1.bias: 0.0028039829339832067\n",
      "Gradient for encoder.encoder.3.weight: 0.07939459383487701\n",
      "Gradient for encoder.encoder.3.bias: 6.101223415377888e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.015328492969274521\n",
      "Gradient for encoder.encoder.4.bias: 0.011694739572703838\n",
      "Gradient for encoder.mean.weight: 0.19502264261245728\n",
      "Gradient for encoder.mean.bias: 0.0063409991562366486\n",
      "Gradient for encoder.log_var.weight: 0.11636780947446823\n",
      "Gradient for encoder.log_var.bias: 0.003819194622337818\n",
      "Gradient for decoder.decoder.0.weight: 0.015901437029242516\n",
      "Gradient for decoder.decoder.0.bias: 1.3003249865750632e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0008413289324380457\n",
      "Gradient for decoder.decoder.1.bias: 0.0005843794206157327\n",
      "Gradient for decoder.decoder.3.weight: 0.014425663277506828\n",
      "Gradient for decoder.decoder.3.bias: 1.0071088407670459e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0005025565042160451\n",
      "Gradient for decoder.decoder.4.bias: 0.00046203265083022416\n",
      "Gradient for decoder.decoder.6.weight: 0.0005619808216579258\n",
      "Gradient for decoder.decoder.6.bias: 3.308735540485941e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.01841682754456997\n",
      "Gradient for encoder.encoder.0.bias: 3.335121415148912e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0024129359517246485\n",
      "Gradient for encoder.encoder.1.bias: 0.0018092355458065867\n",
      "Gradient for encoder.encoder.3.weight: 0.05493398755788803\n",
      "Gradient for encoder.encoder.3.bias: 3.2428268403883465e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.006521487608551979\n",
      "Gradient for encoder.encoder.4.bias: 0.005764408968389034\n",
      "Gradient for encoder.mean.weight: 0.08664064854383469\n",
      "Gradient for encoder.mean.bias: 0.004077752120792866\n",
      "Gradient for encoder.log_var.weight: 0.05078050121665001\n",
      "Gradient for encoder.log_var.bias: 0.0024136153515428305\n",
      "Gradient for decoder.decoder.0.weight: 0.013689589686691761\n",
      "Gradient for decoder.decoder.0.bias: 1.0728966326478684e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0007399543537758291\n",
      "Gradient for decoder.decoder.1.bias: 0.0005648242658935487\n",
      "Gradient for decoder.decoder.3.weight: 0.011978316120803356\n",
      "Gradient for decoder.decoder.3.bias: 1.0200142813721058e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.00042857686639763415\n",
      "Gradient for decoder.decoder.4.bias: 0.0004474296001717448\n",
      "Gradient for decoder.decoder.6.weight: 0.0005374912288971245\n",
      "Gradient for decoder.decoder.6.bias: 2.9808248655172065e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.036180417984724045\n",
      "Gradient for encoder.encoder.0.bias: 4.576761192254253e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0052308193407952785\n",
      "Gradient for encoder.encoder.1.bias: 0.0038782290648669004\n",
      "Gradient for encoder.encoder.3.weight: 0.10347454994916916\n",
      "Gradient for encoder.encoder.3.bias: 4.745726034371955e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.010185353457927704\n",
      "Gradient for encoder.encoder.4.bias: 0.009026393294334412\n",
      "Gradient for encoder.mean.weight: 0.13506509363651276\n",
      "Gradient for encoder.mean.bias: 0.00593869574368\n",
      "Gradient for encoder.log_var.weight: 0.06710507720708847\n",
      "Gradient for encoder.log_var.bias: 0.003251161426305771\n",
      "Gradient for decoder.decoder.0.weight: 0.017224155366420746\n",
      "Gradient for decoder.decoder.0.bias: 1.3627500516921742e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0009075583075173199\n",
      "Gradient for decoder.decoder.1.bias: 0.0005957458051852882\n",
      "Gradient for decoder.decoder.3.weight: 0.01573539339005947\n",
      "Gradient for decoder.decoder.3.bias: 1.1795348031640174e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.000638151541352272\n",
      "Gradient for decoder.decoder.4.bias: 0.0005229401285760105\n",
      "Gradient for decoder.decoder.6.weight: 0.0007201482658274472\n",
      "Gradient for decoder.decoder.6.bias: 4.249880657880567e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.027981895953416824\n",
      "Gradient for encoder.encoder.0.bias: 4.13921570630027e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.003423765767365694\n",
      "Gradient for encoder.encoder.1.bias: 0.002693450776860118\n",
      "Gradient for encoder.encoder.3.weight: 0.06973013281822205\n",
      "Gradient for encoder.encoder.3.bias: 3.8421724135595525e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.008256631903350353\n",
      "Gradient for encoder.encoder.4.bias: 0.007627767510712147\n",
      "Gradient for encoder.mean.weight: 0.1029357761144638\n",
      "Gradient for encoder.mean.bias: 0.005244752857834101\n",
      "Gradient for encoder.log_var.weight: 0.06127430871129036\n",
      "Gradient for encoder.log_var.bias: 0.0031257064547389746\n",
      "Gradient for decoder.decoder.0.weight: 0.01433336641639471\n",
      "Gradient for decoder.decoder.0.bias: 1.3216552852135521e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0007703708251938224\n",
      "Gradient for decoder.decoder.1.bias: 0.000579753250349313\n",
      "Gradient for decoder.decoder.3.weight: 0.012950844131410122\n",
      "Gradient for decoder.decoder.3.bias: 1.0437784664363292e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.000569779658690095\n",
      "Gradient for decoder.decoder.4.bias: 0.000575366779230535\n",
      "Gradient for decoder.decoder.6.weight: 0.0005827929708175361\n",
      "Gradient for decoder.decoder.6.bias: 3.530169851728715e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.024194655939936638\n",
      "Gradient for encoder.encoder.0.bias: 3.9350633862511586e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.002337586134672165\n",
      "Gradient for encoder.encoder.1.bias: 0.001830306719057262\n",
      "Gradient for encoder.encoder.3.weight: 0.04889373481273651\n",
      "Gradient for encoder.encoder.3.bias: 3.7215347470365145e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.007295210380107164\n",
      "Gradient for encoder.encoder.4.bias: 0.007451566401869059\n",
      "Gradient for encoder.mean.weight: 0.093531534075737\n",
      "Gradient for encoder.mean.bias: 0.006298594176769257\n",
      "Gradient for encoder.log_var.weight: 0.053823795169591904\n",
      "Gradient for encoder.log_var.bias: 0.003841720288619399\n",
      "Gradient for decoder.decoder.0.weight: 0.012839248403906822\n",
      "Gradient for decoder.decoder.0.bias: 1.1038658181972139e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0007026615785434842\n",
      "Gradient for decoder.decoder.1.bias: 0.00045883317943662405\n",
      "Gradient for decoder.decoder.3.weight: 0.011519083753228188\n",
      "Gradient for decoder.decoder.3.bias: 9.381719706658131e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0004605049907695502\n",
      "Gradient for decoder.decoder.4.bias: 0.0005110139609314501\n",
      "Gradient for decoder.decoder.6.weight: 0.00053802301408723\n",
      "Gradient for decoder.decoder.6.bias: 3.114434002782218e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.018020477145910263\n",
      "Gradient for encoder.encoder.0.bias: 2.8583992811581638e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0026275338605046272\n",
      "Gradient for encoder.encoder.1.bias: 0.002106480998918414\n",
      "Gradient for encoder.encoder.3.weight: 0.05094482749700546\n",
      "Gradient for encoder.encoder.3.bias: 3.309048035582407e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.007322825491428375\n",
      "Gradient for encoder.encoder.4.bias: 0.006192155182361603\n",
      "Gradient for encoder.mean.weight: 0.09510862082242966\n",
      "Gradient for encoder.mean.bias: 0.004923810251057148\n",
      "Gradient for encoder.log_var.weight: 0.04992828890681267\n",
      "Gradient for encoder.log_var.bias: 0.0022764415480196476\n",
      "Gradient for decoder.decoder.0.weight: 0.01651773974299431\n",
      "Gradient for decoder.decoder.0.bias: 1.3463061221408168e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0008494729408994317\n",
      "Gradient for decoder.decoder.1.bias: 0.0005685830838046968\n",
      "Gradient for decoder.decoder.3.weight: 0.014883830212056637\n",
      "Gradient for decoder.decoder.3.bias: 1.0914558146168929e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0005214184056967497\n",
      "Gradient for decoder.decoder.4.bias: 0.0004695694660767913\n",
      "Gradient for decoder.decoder.6.weight: 0.0005891736946068704\n",
      "Gradient for decoder.decoder.6.bias: 2.921024861279875e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.026410257443785667\n",
      "Gradient for encoder.encoder.0.bias: 4.422264637815587e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.003812312614172697\n",
      "Gradient for encoder.encoder.1.bias: 0.0026913222391158342\n",
      "Gradient for encoder.encoder.3.weight: 0.07460242509841919\n",
      "Gradient for encoder.encoder.3.bias: 4.5034156959111726e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.010456490330398083\n",
      "Gradient for encoder.encoder.4.bias: 0.008875584229826927\n",
      "Gradient for encoder.mean.weight: 0.13609462976455688\n",
      "Gradient for encoder.mean.bias: 0.005564293824136257\n",
      "Gradient for encoder.log_var.weight: 0.08096051216125488\n",
      "Gradient for encoder.log_var.bias: 0.0032710896339267492\n",
      "Gradient for decoder.decoder.0.weight: 0.013183469884097576\n",
      "Gradient for decoder.decoder.0.bias: 1.1214214279409163e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0006905156187713146\n",
      "Gradient for decoder.decoder.1.bias: 0.000492629362270236\n",
      "Gradient for decoder.decoder.3.weight: 0.011541919782757759\n",
      "Gradient for decoder.decoder.3.bias: 9.298040809513353e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0004908872651867568\n",
      "Gradient for decoder.decoder.4.bias: 0.0004771543317474425\n",
      "Gradient for decoder.decoder.6.weight: 0.0005566164618358016\n",
      "Gradient for decoder.decoder.6.bias: 3.1524145015282556e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.029297439381480217\n",
      "Gradient for encoder.encoder.0.bias: 3.682416177541725e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.002669747918844223\n",
      "Gradient for encoder.encoder.1.bias: 0.002279117703437805\n",
      "Gradient for encoder.encoder.3.weight: 0.060023557394742966\n",
      "Gradient for encoder.encoder.3.bias: 4.290784672011938e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.010721507482230663\n",
      "Gradient for encoder.encoder.4.bias: 0.008166789077222347\n",
      "Gradient for encoder.mean.weight: 0.1297290176153183\n",
      "Gradient for encoder.mean.bias: 0.004982093349099159\n",
      "Gradient for encoder.log_var.weight: 0.07900002598762512\n",
      "Gradient for encoder.log_var.bias: 0.0029178867116570473\n",
      "Gradient for decoder.decoder.0.weight: 0.019740207120776176\n",
      "Gradient for decoder.decoder.0.bias: 1.6606079011882713e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0009619620977900922\n",
      "Gradient for decoder.decoder.1.bias: 0.0007533415337093174\n",
      "Gradient for decoder.decoder.3.weight: 0.017541106790304184\n",
      "Gradient for decoder.decoder.3.bias: 1.4959666838620933e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0007155129569582641\n",
      "Gradient for decoder.decoder.4.bias: 0.0006832644576206803\n",
      "Gradient for decoder.decoder.6.weight: 0.0006879873108118773\n",
      "Gradient for decoder.decoder.6.bias: 4.005049413535744e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.020205343142151833\n",
      "Gradient for encoder.encoder.0.bias: 3.1539493239307603e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.002210030797868967\n",
      "Gradient for encoder.encoder.1.bias: 0.001909548183903098\n",
      "Gradient for encoder.encoder.3.weight: 0.04817621409893036\n",
      "Gradient for encoder.encoder.3.bias: 3.0292396369091534e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.006258673500269651\n",
      "Gradient for encoder.encoder.4.bias: 0.005074487533420324\n",
      "Gradient for encoder.mean.weight: 0.08450362086296082\n",
      "Gradient for encoder.mean.bias: 0.004196185618638992\n",
      "Gradient for encoder.log_var.weight: 0.0457121804356575\n",
      "Gradient for encoder.log_var.bias: 0.0024755827616900206\n",
      "Gradient for decoder.decoder.0.weight: 0.01655443012714386\n",
      "Gradient for decoder.decoder.0.bias: 1.272819072362097e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0009069624939002097\n",
      "Gradient for decoder.decoder.1.bias: 0.0006590446573682129\n",
      "Gradient for decoder.decoder.3.weight: 0.014742051251232624\n",
      "Gradient for decoder.decoder.3.bias: 1.1295186314042027e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0005090300110168755\n",
      "Gradient for decoder.decoder.4.bias: 0.00044572105980478227\n",
      "Gradient for decoder.decoder.6.weight: 0.0005743746878579259\n",
      "Gradient for decoder.decoder.6.bias: 2.80983167613158e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.056942712515592575\n",
      "Gradient for encoder.encoder.0.bias: 8.512499038992871e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.006683550775051117\n",
      "Gradient for encoder.encoder.1.bias: 0.004676160868257284\n",
      "Gradient for encoder.encoder.3.weight: 0.14567485451698303\n",
      "Gradient for encoder.encoder.3.bias: 6.619265691121257e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.013940544798970222\n",
      "Gradient for encoder.encoder.4.bias: 0.013158807530999184\n",
      "Gradient for encoder.mean.weight: 0.16508784890174866\n",
      "Gradient for encoder.mean.bias: 0.008691814728081226\n",
      "Gradient for encoder.log_var.weight: 0.1065339669585228\n",
      "Gradient for encoder.log_var.bias: 0.00610153004527092\n",
      "Gradient for decoder.decoder.0.weight: 0.015873871743679047\n",
      "Gradient for decoder.decoder.0.bias: 1.408777677847084e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0008042689296416938\n",
      "Gradient for decoder.decoder.1.bias: 0.0006057225982658565\n",
      "Gradient for decoder.decoder.3.weight: 0.01376798003911972\n",
      "Gradient for decoder.decoder.3.bias: 1.0579218751027852e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0004744571342598647\n",
      "Gradient for decoder.decoder.4.bias: 0.00043855971307493746\n",
      "Gradient for decoder.decoder.6.weight: 0.000545595888979733\n",
      "Gradient for decoder.decoder.6.bias: 3.0236966267693788e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.02741978131234646\n",
      "Gradient for encoder.encoder.0.bias: 4.1695653874018745e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.003155623096972704\n",
      "Gradient for encoder.encoder.1.bias: 0.0024956143461167812\n",
      "Gradient for encoder.encoder.3.weight: 0.06837057322263718\n",
      "Gradient for encoder.encoder.3.bias: 5.93845528307213e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.009536445140838623\n",
      "Gradient for encoder.encoder.4.bias: 0.01104936096817255\n",
      "Gradient for encoder.mean.weight: 0.12026675790548325\n",
      "Gradient for encoder.mean.bias: 0.007993530482053757\n",
      "Gradient for encoder.log_var.weight: 0.07414546608924866\n",
      "Gradient for encoder.log_var.bias: 0.005739267915487289\n",
      "Gradient for decoder.decoder.0.weight: 0.015946410596370697\n",
      "Gradient for decoder.decoder.0.bias: 1.4961619443365493e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.000810901285149157\n",
      "Gradient for decoder.decoder.1.bias: 0.0006043806206434965\n",
      "Gradient for decoder.decoder.3.weight: 0.014222394675016403\n",
      "Gradient for decoder.decoder.3.bias: 1.2131402826742743e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0005565190804190934\n",
      "Gradient for decoder.decoder.4.bias: 0.000504935160279274\n",
      "Gradient for decoder.decoder.6.weight: 0.000579336890950799\n",
      "Gradient for decoder.decoder.6.bias: 2.6995588996214792e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.028330067172646523\n",
      "Gradient for encoder.encoder.0.bias: 3.453648131368503e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0027254573069512844\n",
      "Gradient for encoder.encoder.1.bias: 0.0023453200701624155\n",
      "Gradient for encoder.encoder.3.weight: 0.055971261113882065\n",
      "Gradient for encoder.encoder.3.bias: 4.0108749654876874e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.008958748541772366\n",
      "Gradient for encoder.encoder.4.bias: 0.0075216894038021564\n",
      "Gradient for encoder.mean.weight: 0.11377262324094772\n",
      "Gradient for encoder.mean.bias: 0.005729013122618198\n",
      "Gradient for encoder.log_var.weight: 0.06958401948213577\n",
      "Gradient for encoder.log_var.bias: 0.0033586265053600073\n",
      "Gradient for decoder.decoder.0.weight: 0.018445050343871117\n",
      "Gradient for decoder.decoder.0.bias: 1.7165266430474446e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0010024857474491\n",
      "Gradient for decoder.decoder.1.bias: 0.0007476326427422464\n",
      "Gradient for decoder.decoder.3.weight: 0.01690453290939331\n",
      "Gradient for decoder.decoder.3.bias: 1.5446305345889755e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0007379462476819754\n",
      "Gradient for decoder.decoder.4.bias: 0.0007672388455830514\n",
      "Gradient for decoder.decoder.6.weight: 0.0006907639908604324\n",
      "Gradient for decoder.decoder.6.bias: 4.397522934596054e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.02271544188261032\n",
      "Gradient for encoder.encoder.0.bias: 3.775679421891276e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.003499402431771159\n",
      "Gradient for encoder.encoder.1.bias: 0.002599847037345171\n",
      "Gradient for encoder.encoder.3.weight: 0.0753362700343132\n",
      "Gradient for encoder.encoder.3.bias: 5.49641165914494e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.012561378069221973\n",
      "Gradient for encoder.encoder.4.bias: 0.011760029941797256\n",
      "Gradient for encoder.mean.weight: 0.1620272547006607\n",
      "Gradient for encoder.mean.bias: 0.00829558540135622\n",
      "Gradient for encoder.log_var.weight: 0.09408024698495865\n",
      "Gradient for encoder.log_var.bias: 0.0050703855231404305\n",
      "Gradient for decoder.decoder.0.weight: 0.014770577661693096\n",
      "Gradient for decoder.decoder.0.bias: 1.2500384061198133e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0008514950168319046\n",
      "Gradient for decoder.decoder.1.bias: 0.0006245151744224131\n",
      "Gradient for decoder.decoder.3.weight: 0.013195266015827656\n",
      "Gradient for decoder.decoder.3.bias: 1.0423018698135778e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0005544664454646409\n",
      "Gradient for decoder.decoder.4.bias: 0.0005283118807710707\n",
      "Gradient for decoder.decoder.6.weight: 0.0006161944475024939\n",
      "Gradient for decoder.decoder.6.bias: 3.4631208109203726e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.02798454277217388\n",
      "Gradient for encoder.encoder.0.bias: 4.7950254877804355e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0039052271749824286\n",
      "Gradient for encoder.encoder.1.bias: 0.002932355972006917\n",
      "Gradient for encoder.encoder.3.weight: 0.0807092934846878\n",
      "Gradient for encoder.encoder.3.bias: 5.288144921955507e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.012580876238644123\n",
      "Gradient for encoder.encoder.4.bias: 0.01090908795595169\n",
      "Gradient for encoder.mean.weight: 0.16150052845478058\n",
      "Gradient for encoder.mean.bias: 0.00678925821557641\n",
      "Gradient for encoder.log_var.weight: 0.09367164969444275\n",
      "Gradient for encoder.log_var.bias: 0.004233906976878643\n",
      "Gradient for decoder.decoder.0.weight: 0.014000989496707916\n",
      "Gradient for decoder.decoder.0.bias: 1.1790218801266406e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0007799750892445445\n",
      "Gradient for decoder.decoder.1.bias: 0.0005825851112604141\n",
      "Gradient for decoder.decoder.3.weight: 0.01237250305712223\n",
      "Gradient for decoder.decoder.3.bias: 1.0177531040156396e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.00046001109876669943\n",
      "Gradient for decoder.decoder.4.bias: 0.00042975714313797653\n",
      "Gradient for decoder.decoder.6.weight: 0.0005371880251914263\n",
      "Gradient for decoder.decoder.6.bias: 2.322202817595098e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.02563236467540264\n",
      "Gradient for encoder.encoder.0.bias: 3.771971970878418e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.002953049959614873\n",
      "Gradient for encoder.encoder.1.bias: 0.002478389535099268\n",
      "Gradient for encoder.encoder.3.weight: 0.06565722078084946\n",
      "Gradient for encoder.encoder.3.bias: 4.797692798597097e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.009078153409063816\n",
      "Gradient for encoder.encoder.4.bias: 0.00910990871489048\n",
      "Gradient for encoder.mean.weight: 0.11376570165157318\n",
      "Gradient for encoder.mean.bias: 0.0062892381101846695\n",
      "Gradient for encoder.log_var.weight: 0.06655193120241165\n",
      "Gradient for encoder.log_var.bias: 0.003530269954353571\n",
      "Gradient for decoder.decoder.0.weight: 0.014851419255137444\n",
      "Gradient for decoder.decoder.0.bias: 1.271872746011482e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.000814379716757685\n",
      "Gradient for decoder.decoder.1.bias: 0.0005830384325236082\n",
      "Gradient for decoder.decoder.3.weight: 0.01365318987518549\n",
      "Gradient for decoder.decoder.3.bias: 9.90475965134685e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0004869131662417203\n",
      "Gradient for decoder.decoder.4.bias: 0.00047560714301653206\n",
      "Gradient for decoder.decoder.6.weight: 0.0005843734834343195\n",
      "Gradient for decoder.decoder.6.bias: 2.9100485335220583e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training VAE Epoch:  52%|█████▏    | 41/79 [00:00<00:00, 69.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient for encoder.encoder.0.weight: 0.024144623428583145\n",
      "Gradient for encoder.encoder.0.bias: 3.846755206038388e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0033354246988892555\n",
      "Gradient for encoder.encoder.1.bias: 0.0028012983966618776\n",
      "Gradient for encoder.encoder.3.weight: 0.0707029476761818\n",
      "Gradient for encoder.encoder.3.bias: 4.205250037081498e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.00809100829064846\n",
      "Gradient for encoder.encoder.4.bias: 0.008987552486360073\n",
      "Gradient for encoder.mean.weight: 0.10382215678691864\n",
      "Gradient for encoder.mean.bias: 0.006609034258872271\n",
      "Gradient for encoder.log_var.weight: 0.06693486869335175\n",
      "Gradient for encoder.log_var.bias: 0.004149896092712879\n",
      "Gradient for decoder.decoder.0.weight: 0.01748533360660076\n",
      "Gradient for decoder.decoder.0.bias: 1.4266715586686018e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0008563461015000939\n",
      "Gradient for decoder.decoder.1.bias: 0.0006321860128082335\n",
      "Gradient for decoder.decoder.3.weight: 0.015590235590934753\n",
      "Gradient for decoder.decoder.3.bias: 1.0810566331009852e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0006842028815299273\n",
      "Gradient for decoder.decoder.4.bias: 0.000682630343362689\n",
      "Gradient for decoder.decoder.6.weight: 0.0006978240562602878\n",
      "Gradient for decoder.decoder.6.bias: 4.27348495577462e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.025643959641456604\n",
      "Gradient for encoder.encoder.0.bias: 3.9775609889103336e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0033232124987989664\n",
      "Gradient for encoder.encoder.1.bias: 0.0028948818799108267\n",
      "Gradient for encoder.encoder.3.weight: 0.07462415844202042\n",
      "Gradient for encoder.encoder.3.bias: 5.113285905800069e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.010700262151658535\n",
      "Gradient for encoder.encoder.4.bias: 0.010634854435920715\n",
      "Gradient for encoder.mean.weight: 0.14582598209381104\n",
      "Gradient for encoder.mean.bias: 0.007924520410597324\n",
      "Gradient for encoder.log_var.weight: 0.08017265796661377\n",
      "Gradient for encoder.log_var.bias: 0.005224491469562054\n",
      "Gradient for decoder.decoder.0.weight: 0.01914609968662262\n",
      "Gradient for decoder.decoder.0.bias: 1.7756915382527438e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.00106517702806741\n",
      "Gradient for decoder.decoder.1.bias: 0.0007306820480152965\n",
      "Gradient for decoder.decoder.3.weight: 0.017522480338811874\n",
      "Gradient for decoder.decoder.3.bias: 1.5947373976921142e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.000941073230933398\n",
      "Gradient for decoder.decoder.4.bias: 0.0010354523546993732\n",
      "Gradient for decoder.decoder.6.weight: 0.000820252054836601\n",
      "Gradient for decoder.decoder.6.bias: 5.897306255064905e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.021368900313973427\n",
      "Gradient for encoder.encoder.0.bias: 3.584530935962782e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0031407522037625313\n",
      "Gradient for encoder.encoder.1.bias: 0.0024270315188914537\n",
      "Gradient for encoder.encoder.3.weight: 0.06763794273138046\n",
      "Gradient for encoder.encoder.3.bias: 3.517481861337046e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.007748632226139307\n",
      "Gradient for encoder.encoder.4.bias: 0.007420843467116356\n",
      "Gradient for encoder.mean.weight: 0.09925253689289093\n",
      "Gradient for encoder.mean.bias: 0.005143686663359404\n",
      "Gradient for encoder.log_var.weight: 0.059694379568099976\n",
      "Gradient for encoder.log_var.bias: 0.003131536301225424\n",
      "Gradient for decoder.decoder.0.weight: 0.01573551632463932\n",
      "Gradient for decoder.decoder.0.bias: 1.3690747147077076e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0008431026944890618\n",
      "Gradient for decoder.decoder.1.bias: 0.0005819557700306177\n",
      "Gradient for decoder.decoder.3.weight: 0.013721697963774204\n",
      "Gradient for decoder.decoder.3.bias: 1.3528714259969377e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0005865944549441338\n",
      "Gradient for decoder.decoder.4.bias: 0.0005854518385604024\n",
      "Gradient for decoder.decoder.6.weight: 0.0006125669460743666\n",
      "Gradient for decoder.decoder.6.bias: 3.426254625082947e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.03147256374359131\n",
      "Gradient for encoder.encoder.0.bias: 4.703569131403462e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.004133074544370174\n",
      "Gradient for encoder.encoder.1.bias: 0.0031451808754354715\n",
      "Gradient for encoder.encoder.3.weight: 0.08147701621055603\n",
      "Gradient for encoder.encoder.3.bias: 4.507060835656773e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.008729924447834492\n",
      "Gradient for encoder.encoder.4.bias: 0.008128003217279911\n",
      "Gradient for encoder.mean.weight: 0.11473875492811203\n",
      "Gradient for encoder.mean.bias: 0.005466843955218792\n",
      "Gradient for encoder.log_var.weight: 0.06259087473154068\n",
      "Gradient for encoder.log_var.bias: 0.0034432641696184874\n",
      "Gradient for decoder.decoder.0.weight: 0.020536743104457855\n",
      "Gradient for decoder.decoder.0.bias: 1.787389958263219e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0010152308968827128\n",
      "Gradient for decoder.decoder.1.bias: 0.0007710838690400124\n",
      "Gradient for decoder.decoder.3.weight: 0.018236953765153885\n",
      "Gradient for decoder.decoder.3.bias: 1.680416084059999e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0010691997595131397\n",
      "Gradient for decoder.decoder.4.bias: 0.0011692071566358209\n",
      "Gradient for decoder.decoder.6.weight: 0.0008694580756127834\n",
      "Gradient for decoder.decoder.6.bias: 6.613948062295094e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.02342688851058483\n",
      "Gradient for encoder.encoder.0.bias: 3.650837965274434e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0021054609678685665\n",
      "Gradient for encoder.encoder.1.bias: 0.0018268435960635543\n",
      "Gradient for encoder.encoder.3.weight: 0.04682319983839989\n",
      "Gradient for encoder.encoder.3.bias: 3.56259355349664e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.00770100811496377\n",
      "Gradient for encoder.encoder.4.bias: 0.006449330598115921\n",
      "Gradient for encoder.mean.weight: 0.09563945978879929\n",
      "Gradient for encoder.mean.bias: 0.003731791628524661\n",
      "Gradient for encoder.log_var.weight: 0.05693388357758522\n",
      "Gradient for encoder.log_var.bias: 0.002260501030832529\n",
      "Gradient for decoder.decoder.0.weight: 0.01714373379945755\n",
      "Gradient for decoder.decoder.0.bias: 1.6217227560844094e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0009124689386226237\n",
      "Gradient for decoder.decoder.1.bias: 0.000666305364575237\n",
      "Gradient for decoder.decoder.3.weight: 0.01552827563136816\n",
      "Gradient for decoder.decoder.3.bias: 1.30678010079599e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0005827006534673274\n",
      "Gradient for decoder.decoder.4.bias: 0.0005240037571638823\n",
      "Gradient for decoder.decoder.6.weight: 0.0006378873367793858\n",
      "Gradient for decoder.decoder.6.bias: 3.4371434594504535e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.021093571558594704\n",
      "Gradient for encoder.encoder.0.bias: 4.150640248168358e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.002657695673406124\n",
      "Gradient for encoder.encoder.1.bias: 0.00209051463752985\n",
      "Gradient for encoder.encoder.3.weight: 0.054222531616687775\n",
      "Gradient for encoder.encoder.3.bias: 3.571648810041239e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.006696627475321293\n",
      "Gradient for encoder.encoder.4.bias: 0.006484516896307468\n",
      "Gradient for encoder.mean.weight: 0.09193570911884308\n",
      "Gradient for encoder.mean.bias: 0.0050445012748241425\n",
      "Gradient for encoder.log_var.weight: 0.052676860243082047\n",
      "Gradient for encoder.log_var.bias: 0.00304974103346467\n",
      "Gradient for decoder.decoder.0.weight: 0.014793898910284042\n",
      "Gradient for decoder.decoder.0.bias: 1.2156424478160233e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0007962578674778342\n",
      "Gradient for decoder.decoder.1.bias: 0.000542026711627841\n",
      "Gradient for decoder.decoder.3.weight: 0.013319922611117363\n",
      "Gradient for decoder.decoder.3.bias: 9.72997307724377e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0005253098206594586\n",
      "Gradient for decoder.decoder.4.bias: 0.000478228583233431\n",
      "Gradient for decoder.decoder.6.weight: 0.0005671815597452223\n",
      "Gradient for decoder.decoder.6.bias: 2.6137748136534356e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.03178895637392998\n",
      "Gradient for encoder.encoder.0.bias: 5.280166234800099e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.003577728057280183\n",
      "Gradient for encoder.encoder.1.bias: 0.002736439695581794\n",
      "Gradient for encoder.encoder.3.weight: 0.07567663490772247\n",
      "Gradient for encoder.encoder.3.bias: 6.280420072890536e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.013874060474336147\n",
      "Gradient for encoder.encoder.4.bias: 0.01074987556785345\n",
      "Gradient for encoder.mean.weight: 0.16837212443351746\n",
      "Gradient for encoder.mean.bias: 0.006022329442203045\n",
      "Gradient for encoder.log_var.weight: 0.09997177869081497\n",
      "Gradient for encoder.log_var.bias: 0.0034189799334853888\n",
      "Gradient for decoder.decoder.0.weight: 0.015103215351700783\n",
      "Gradient for decoder.decoder.0.bias: 1.3132557541428724e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0008120978600345552\n",
      "Gradient for decoder.decoder.1.bias: 0.0005817150231450796\n",
      "Gradient for decoder.decoder.3.weight: 0.013312879018485546\n",
      "Gradient for decoder.decoder.3.bias: 1.0737479655409388e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0004637990496121347\n",
      "Gradient for decoder.decoder.4.bias: 0.0004240544803906232\n",
      "Gradient for decoder.decoder.6.weight: 0.0006074502598494291\n",
      "Gradient for decoder.decoder.6.bias: 3.7826725019840524e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.035638049244880676\n",
      "Gradient for encoder.encoder.0.bias: 4.085842081336111e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.004478476941585541\n",
      "Gradient for encoder.encoder.1.bias: 0.003195627825334668\n",
      "Gradient for encoder.encoder.3.weight: 0.10039248317480087\n",
      "Gradient for encoder.encoder.3.bias: 3.729559439058505e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.009440584108233452\n",
      "Gradient for encoder.encoder.4.bias: 0.007477667648345232\n",
      "Gradient for encoder.mean.weight: 0.13068056106567383\n",
      "Gradient for encoder.mean.bias: 0.004344999324530363\n",
      "Gradient for encoder.log_var.weight: 0.06425309181213379\n",
      "Gradient for encoder.log_var.bias: 0.002527041593566537\n",
      "Gradient for decoder.decoder.0.weight: 0.018274374306201935\n",
      "Gradient for decoder.decoder.0.bias: 1.4906334500075502e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0009945558849722147\n",
      "Gradient for decoder.decoder.1.bias: 0.0007113507599569857\n",
      "Gradient for decoder.decoder.3.weight: 0.01745143160223961\n",
      "Gradient for decoder.decoder.3.bias: 1.3113908570172583e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0007454548613168299\n",
      "Gradient for decoder.decoder.4.bias: 0.0007003393257036805\n",
      "Gradient for decoder.decoder.6.weight: 0.0007278514094650745\n",
      "Gradient for decoder.decoder.6.bias: 4.6332537749549374e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.020523538812994957\n",
      "Gradient for encoder.encoder.0.bias: 3.0675122164591784e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.002543375827372074\n",
      "Gradient for encoder.encoder.1.bias: 0.00202969741076231\n",
      "Gradient for encoder.encoder.3.weight: 0.056345660239458084\n",
      "Gradient for encoder.encoder.3.bias: 3.688281347002942e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.00814066268503666\n",
      "Gradient for encoder.encoder.4.bias: 0.00732369115576148\n",
      "Gradient for encoder.mean.weight: 0.10543867200613022\n",
      "Gradient for encoder.mean.bias: 0.005169684998691082\n",
      "Gradient for encoder.log_var.weight: 0.05543678253889084\n",
      "Gradient for encoder.log_var.bias: 0.003144568996503949\n",
      "Gradient for decoder.decoder.0.weight: 0.015060733072459698\n",
      "Gradient for decoder.decoder.0.bias: 1.1668517541085777e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0007827235967852175\n",
      "Gradient for decoder.decoder.1.bias: 0.0005821141530759633\n",
      "Gradient for decoder.decoder.3.weight: 0.013494759798049927\n",
      "Gradient for decoder.decoder.3.bias: 1.379619196661963e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.000842474983073771\n",
      "Gradient for decoder.decoder.4.bias: 0.001027518417686224\n",
      "Gradient for decoder.decoder.6.weight: 0.0007244866574183106\n",
      "Gradient for decoder.decoder.6.bias: 6.120786565588787e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.02613873966038227\n",
      "Gradient for encoder.encoder.0.bias: 3.862193551085191e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0034917830489575863\n",
      "Gradient for encoder.encoder.1.bias: 0.002752810949459672\n",
      "Gradient for encoder.encoder.3.weight: 0.07445033639669418\n",
      "Gradient for encoder.encoder.3.bias: 4.4624132167214725e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0090039586648345\n",
      "Gradient for encoder.encoder.4.bias: 0.008531459607183933\n",
      "Gradient for encoder.mean.weight: 0.12595172226428986\n",
      "Gradient for encoder.mean.bias: 0.005791467614471912\n",
      "Gradient for encoder.log_var.weight: 0.069229856133461\n",
      "Gradient for encoder.log_var.bias: 0.0034288414753973484\n",
      "Gradient for decoder.decoder.0.weight: 0.01803390122950077\n",
      "Gradient for decoder.decoder.0.bias: 1.4851235519142136e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0009247407433576882\n",
      "Gradient for decoder.decoder.1.bias: 0.0006913850083947182\n",
      "Gradient for decoder.decoder.3.weight: 0.016156306490302086\n",
      "Gradient for decoder.decoder.3.bias: 1.311203645659731e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.000611744006164372\n",
      "Gradient for decoder.decoder.4.bias: 0.0005022842087782919\n",
      "Gradient for decoder.decoder.6.weight: 0.0006298284279182553\n",
      "Gradient for decoder.decoder.6.bias: 3.0190236429916695e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.024471465498209\n",
      "Gradient for encoder.encoder.0.bias: 3.737472137332887e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.002908852882683277\n",
      "Gradient for encoder.encoder.1.bias: 0.0022308228071779013\n",
      "Gradient for encoder.encoder.3.weight: 0.05911252275109291\n",
      "Gradient for encoder.encoder.3.bias: 3.722968877628574e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.007863731123507023\n",
      "Gradient for encoder.encoder.4.bias: 0.007446333300322294\n",
      "Gradient for encoder.mean.weight: 0.10197782516479492\n",
      "Gradient for encoder.mean.bias: 0.005606829654425383\n",
      "Gradient for encoder.log_var.weight: 0.06390547007322311\n",
      "Gradient for encoder.log_var.bias: 0.0032911913003772497\n",
      "Gradient for decoder.decoder.0.weight: 0.018444601446390152\n",
      "Gradient for decoder.decoder.0.bias: 1.3733859882680832e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0009985403157770634\n",
      "Gradient for decoder.decoder.1.bias: 0.0007065534009598196\n",
      "Gradient for decoder.decoder.3.weight: 0.016365408897399902\n",
      "Gradient for decoder.decoder.3.bias: 1.1147305994940737e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0006637282785959542\n",
      "Gradient for decoder.decoder.4.bias: 0.0005457733059301972\n",
      "Gradient for decoder.decoder.6.weight: 0.0006499026203528047\n",
      "Gradient for decoder.decoder.6.bias: 2.8843842301284894e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.021482793614268303\n",
      "Gradient for encoder.encoder.0.bias: 3.9941019241984677e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0033038142137229443\n",
      "Gradient for encoder.encoder.1.bias: 0.002133506815880537\n",
      "Gradient for encoder.encoder.3.weight: 0.06487391889095306\n",
      "Gradient for encoder.encoder.3.bias: 4.542685394515189e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.010813605971634388\n",
      "Gradient for encoder.encoder.4.bias: 0.009783254005014896\n",
      "Gradient for encoder.mean.weight: 0.13432130217552185\n",
      "Gradient for encoder.mean.bias: 0.007409246172755957\n",
      "Gradient for encoder.log_var.weight: 0.07926052063703537\n",
      "Gradient for encoder.log_var.bias: 0.004584233742207289\n",
      "Gradient for decoder.decoder.0.weight: 0.015520143322646618\n",
      "Gradient for decoder.decoder.0.bias: 1.433713148202287e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.000754042761400342\n",
      "Gradient for decoder.decoder.1.bias: 0.0005807813722640276\n",
      "Gradient for decoder.decoder.3.weight: 0.013371962122619152\n",
      "Gradient for decoder.decoder.3.bias: 1.0956155427344072e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0004476408357731998\n",
      "Gradient for decoder.decoder.4.bias: 0.00041718027205206454\n",
      "Gradient for decoder.decoder.6.weight: 0.0005828605499118567\n",
      "Gradient for decoder.decoder.6.bias: 3.3074211387429386e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.021061290055513382\n",
      "Gradient for encoder.encoder.0.bias: 3.6913139211947055e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0023539301473647356\n",
      "Gradient for encoder.encoder.1.bias: 0.0019444330828264356\n",
      "Gradient for encoder.encoder.3.weight: 0.04736931249499321\n",
      "Gradient for encoder.encoder.3.bias: 3.8689459969099005e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.007328391540795565\n",
      "Gradient for encoder.encoder.4.bias: 0.007779755163937807\n",
      "Gradient for encoder.mean.weight: 0.09678970277309418\n",
      "Gradient for encoder.mean.bias: 0.005737870465964079\n",
      "Gradient for encoder.log_var.weight: 0.05846640095114708\n",
      "Gradient for encoder.log_var.bias: 0.003887389088049531\n",
      "Gradient for decoder.decoder.0.weight: 0.015427550300955772\n",
      "Gradient for decoder.decoder.0.bias: 1.2441002394947276e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0008089826442301273\n",
      "Gradient for decoder.decoder.1.bias: 0.0005907457089051604\n",
      "Gradient for decoder.decoder.3.weight: 0.013632128946483135\n",
      "Gradient for decoder.decoder.3.bias: 1.1422580242781422e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0005922235432080925\n",
      "Gradient for decoder.decoder.4.bias: 0.0006066201021894813\n",
      "Gradient for decoder.decoder.6.weight: 0.0006672720774076879\n",
      "Gradient for decoder.decoder.6.bias: 4.167579754721373e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.030581394210457802\n",
      "Gradient for encoder.encoder.0.bias: 4.383299279098196e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0025774703826755285\n",
      "Gradient for encoder.encoder.1.bias: 0.002187908161431551\n",
      "Gradient for encoder.encoder.3.weight: 0.056056443601846695\n",
      "Gradient for encoder.encoder.3.bias: 4.887749094351079e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.01075390912592411\n",
      "Gradient for encoder.encoder.4.bias: 0.009213188663125038\n",
      "Gradient for encoder.mean.weight: 0.14205031096935272\n",
      "Gradient for encoder.mean.bias: 0.006158367730677128\n",
      "Gradient for encoder.log_var.weight: 0.07296660542488098\n",
      "Gradient for encoder.log_var.bias: 0.0035429419949650764\n",
      "Gradient for decoder.decoder.0.weight: 0.014875760301947594\n",
      "Gradient for decoder.decoder.0.bias: 1.215782197139248e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.000791440368629992\n",
      "Gradient for decoder.decoder.1.bias: 0.0006379577098414302\n",
      "Gradient for decoder.decoder.3.weight: 0.013761483132839203\n",
      "Gradient for decoder.decoder.3.bias: 1.0224258939484088e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0005771759315393865\n",
      "Gradient for decoder.decoder.4.bias: 0.0005450624157674611\n",
      "Gradient for decoder.decoder.6.weight: 0.0006103415507823229\n",
      "Gradient for decoder.decoder.6.bias: 3.5229939385317266e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.02657356858253479\n",
      "Gradient for encoder.encoder.0.bias: 3.9454328693011576e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0028729941695928574\n",
      "Gradient for encoder.encoder.1.bias: 0.0021035545505583286\n",
      "Gradient for encoder.encoder.3.weight: 0.06111166998744011\n",
      "Gradient for encoder.encoder.3.bias: 3.857212049762637e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.008115479722619057\n",
      "Gradient for encoder.encoder.4.bias: 0.007473608013242483\n",
      "Gradient for encoder.mean.weight: 0.11746721714735031\n",
      "Gradient for encoder.mean.bias: 0.005924125202000141\n",
      "Gradient for encoder.log_var.weight: 0.05958591774106026\n",
      "Gradient for encoder.log_var.bias: 0.0036940008867532015\n",
      "Gradient for decoder.decoder.0.weight: 0.0169537216424942\n",
      "Gradient for decoder.decoder.0.bias: 1.4204140641460583e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0008091983036138117\n",
      "Gradient for decoder.decoder.1.bias: 0.0006490485975518823\n",
      "Gradient for decoder.decoder.3.weight: 0.0149384168908\n",
      "Gradient for decoder.decoder.3.bias: 1.2515324887552026e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0007944508688524365\n",
      "Gradient for decoder.decoder.4.bias: 0.00088269985280931\n",
      "Gradient for decoder.decoder.6.weight: 0.0007100484799593687\n",
      "Gradient for decoder.decoder.6.bias: 5.1442868425510824e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.020420968532562256\n",
      "Gradient for encoder.encoder.0.bias: 3.761543160285541e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.003437557490542531\n",
      "Gradient for encoder.encoder.1.bias: 0.0023093009367585182\n",
      "Gradient for encoder.encoder.3.weight: 0.06255722790956497\n",
      "Gradient for encoder.encoder.3.bias: 3.8435593596730655e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.007762759458273649\n",
      "Gradient for encoder.encoder.4.bias: 0.009244629181921482\n",
      "Gradient for encoder.mean.weight: 0.09785313904285431\n",
      "Gradient for encoder.mean.bias: 0.006980972830206156\n",
      "Gradient for encoder.log_var.weight: 0.057317011058330536\n",
      "Gradient for encoder.log_var.bias: 0.0043613361194729805\n",
      "Gradient for decoder.decoder.0.weight: 0.017492521554231644\n",
      "Gradient for decoder.decoder.0.bias: 1.6255978507739854e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0008649759110994637\n",
      "Gradient for decoder.decoder.1.bias: 0.0006929413066245615\n",
      "Gradient for decoder.decoder.3.weight: 0.015622603707015514\n",
      "Gradient for decoder.decoder.3.bias: 1.257528525755447e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0006426100735552609\n",
      "Gradient for decoder.decoder.4.bias: 0.0006305513088591397\n",
      "Gradient for decoder.decoder.6.weight: 0.0006424970924854279\n",
      "Gradient for decoder.decoder.6.bias: 4.0542177885072306e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training VAE Epoch:  72%|███████▏  | 57/79 [00:00<00:00, 73.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient for encoder.encoder.0.weight: 0.04411860182881355\n",
      "Gradient for encoder.encoder.0.bias: 6.926991619193856e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.006356716156005859\n",
      "Gradient for encoder.encoder.1.bias: 0.0059573473408818245\n",
      "Gradient for encoder.encoder.3.weight: 0.14175686240196228\n",
      "Gradient for encoder.encoder.3.bias: 9.886114149537661e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.025910545140504837\n",
      "Gradient for encoder.encoder.4.bias: 0.018950365483760834\n",
      "Gradient for encoder.mean.weight: 0.33313292264938354\n",
      "Gradient for encoder.mean.bias: 0.009483224712312222\n",
      "Gradient for encoder.log_var.weight: 0.18429701030254364\n",
      "Gradient for encoder.log_var.bias: 0.0056867958046495914\n",
      "Gradient for decoder.decoder.0.weight: 0.018529070541262627\n",
      "Gradient for decoder.decoder.0.bias: 1.4884195265185696e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0009758741362020373\n",
      "Gradient for decoder.decoder.1.bias: 0.0006912398966960609\n",
      "Gradient for decoder.decoder.3.weight: 0.016447752714157104\n",
      "Gradient for decoder.decoder.3.bias: 1.3292164591227618e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.000594848592299968\n",
      "Gradient for decoder.decoder.4.bias: 0.0005356835899874568\n",
      "Gradient for decoder.decoder.6.weight: 0.0007122598472051322\n",
      "Gradient for decoder.decoder.6.bias: 4.892296783509664e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.03101780265569687\n",
      "Gradient for encoder.encoder.0.bias: 4.5851503149840767e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.004434605129063129\n",
      "Gradient for encoder.encoder.1.bias: 0.0031184034887701273\n",
      "Gradient for encoder.encoder.3.weight: 0.0940462127327919\n",
      "Gradient for encoder.encoder.3.bias: 5.284118143045191e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.013847282156348228\n",
      "Gradient for encoder.encoder.4.bias: 0.011167692020535469\n",
      "Gradient for encoder.mean.weight: 0.17287710309028625\n",
      "Gradient for encoder.mean.bias: 0.005725471302866936\n",
      "Gradient for encoder.log_var.weight: 0.10318055003881454\n",
      "Gradient for encoder.log_var.bias: 0.0035732605028897524\n",
      "Gradient for decoder.decoder.0.weight: 0.01499677263200283\n",
      "Gradient for decoder.decoder.0.bias: 1.2172032826107682e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0007516108453273773\n",
      "Gradient for decoder.decoder.1.bias: 0.0005905345315113664\n",
      "Gradient for decoder.decoder.3.weight: 0.013094467110931873\n",
      "Gradient for decoder.decoder.3.bias: 1.0941258316021774e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0005873931804671884\n",
      "Gradient for decoder.decoder.4.bias: 0.0006286430871114135\n",
      "Gradient for decoder.decoder.6.weight: 0.000606932386290282\n",
      "Gradient for decoder.decoder.6.bias: 3.5795048461295664e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.027839811518788338\n",
      "Gradient for encoder.encoder.0.bias: 4.9871509699705996e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.004298119340091944\n",
      "Gradient for encoder.encoder.1.bias: 0.003585257101804018\n",
      "Gradient for encoder.encoder.3.weight: 0.09129549562931061\n",
      "Gradient for encoder.encoder.3.bias: 5.360765720219263e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.010922825895249844\n",
      "Gradient for encoder.encoder.4.bias: 0.013147207908332348\n",
      "Gradient for encoder.mean.weight: 0.1431242823600769\n",
      "Gradient for encoder.mean.bias: 0.009921880438923836\n",
      "Gradient for encoder.log_var.weight: 0.088935486972332\n",
      "Gradient for encoder.log_var.bias: 0.0066821682266891\n",
      "Gradient for decoder.decoder.0.weight: 0.013505603186786175\n",
      "Gradient for decoder.decoder.0.bias: 1.0874508238334357e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0007190730539150536\n",
      "Gradient for decoder.decoder.1.bias: 0.0005179858999326825\n",
      "Gradient for decoder.decoder.3.weight: 0.012041114270687103\n",
      "Gradient for decoder.decoder.3.bias: 1.0827655438916395e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0006178512703627348\n",
      "Gradient for decoder.decoder.4.bias: 0.0006520447204820812\n",
      "Gradient for decoder.decoder.6.weight: 0.0006154018337838352\n",
      "Gradient for decoder.decoder.6.bias: 4.0462095057591796e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.0332648828625679\n",
      "Gradient for encoder.encoder.0.bias: 4.319856625190077e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.002735087415203452\n",
      "Gradient for encoder.encoder.1.bias: 0.002040114952251315\n",
      "Gradient for encoder.encoder.3.weight: 0.05698558688163757\n",
      "Gradient for encoder.encoder.3.bias: 5.280422210596214e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.009980706498026848\n",
      "Gradient for encoder.encoder.4.bias: 0.008875299245119095\n",
      "Gradient for encoder.mean.weight: 0.12599417567253113\n",
      "Gradient for encoder.mean.bias: 0.006210972089320421\n",
      "Gradient for encoder.log_var.weight: 0.07906150072813034\n",
      "Gradient for encoder.log_var.bias: 0.0036741006188094616\n",
      "Gradient for decoder.decoder.0.weight: 0.014607145451009274\n",
      "Gradient for decoder.decoder.0.bias: 1.2451796538304194e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0007168834563344717\n",
      "Gradient for decoder.decoder.1.bias: 0.0005444428534246981\n",
      "Gradient for decoder.decoder.3.weight: 0.01323009468615055\n",
      "Gradient for decoder.decoder.3.bias: 9.680632684361257e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0005287920939736068\n",
      "Gradient for decoder.decoder.4.bias: 0.00047730919322930276\n",
      "Gradient for decoder.decoder.6.weight: 0.0005935598164796829\n",
      "Gradient for decoder.decoder.6.bias: 3.293918052804656e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.0357557013630867\n",
      "Gradient for encoder.encoder.0.bias: 5.112774092985717e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.004248704761266708\n",
      "Gradient for encoder.encoder.1.bias: 0.0032889314461499453\n",
      "Gradient for encoder.encoder.3.weight: 0.09167453646659851\n",
      "Gradient for encoder.encoder.3.bias: 4.653406548982275e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.009385582990944386\n",
      "Gradient for encoder.encoder.4.bias: 0.007752557285130024\n",
      "Gradient for encoder.mean.weight: 0.13184219598770142\n",
      "Gradient for encoder.mean.bias: 0.005473259836435318\n",
      "Gradient for encoder.log_var.weight: 0.0681724026799202\n",
      "Gradient for encoder.log_var.bias: 0.0027889995835721493\n",
      "Gradient for decoder.decoder.0.weight: 0.01574275642633438\n",
      "Gradient for decoder.decoder.0.bias: 1.2910460200910023e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0008351476863026619\n",
      "Gradient for decoder.decoder.1.bias: 0.0005912721389904618\n",
      "Gradient for decoder.decoder.3.weight: 0.014047008939087391\n",
      "Gradient for decoder.decoder.3.bias: 1.0649526399619802e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0004961014492437243\n",
      "Gradient for decoder.decoder.4.bias: 0.00043343030847609043\n",
      "Gradient for decoder.decoder.6.weight: 0.0005805339897051454\n",
      "Gradient for decoder.decoder.6.bias: 2.743910408753436e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.021913405507802963\n",
      "Gradient for encoder.encoder.0.bias: 3.723977029523873e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0034017888829112053\n",
      "Gradient for encoder.encoder.1.bias: 0.0022530050482600927\n",
      "Gradient for encoder.encoder.3.weight: 0.06834995001554489\n",
      "Gradient for encoder.encoder.3.bias: 4.300780842569907e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.008933006785809994\n",
      "Gradient for encoder.encoder.4.bias: 0.008030496537685394\n",
      "Gradient for encoder.mean.weight: 0.12562774121761322\n",
      "Gradient for encoder.mean.bias: 0.00607267115265131\n",
      "Gradient for encoder.log_var.weight: 0.06333978474140167\n",
      "Gradient for encoder.log_var.bias: 0.003527883905917406\n",
      "Gradient for decoder.decoder.0.weight: 0.016928780823946\n",
      "Gradient for decoder.decoder.0.bias: 1.3388877506681496e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0009081272291950881\n",
      "Gradient for decoder.decoder.1.bias: 0.0006884150207042694\n",
      "Gradient for decoder.decoder.3.weight: 0.015710191801190376\n",
      "Gradient for decoder.decoder.3.bias: 1.1099742652787015e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0005779822240583599\n",
      "Gradient for decoder.decoder.4.bias: 0.0004989617737010121\n",
      "Gradient for decoder.decoder.6.weight: 0.0006095963763073087\n",
      "Gradient for decoder.decoder.6.bias: 2.5439583623665385e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.032910656183958054\n",
      "Gradient for encoder.encoder.0.bias: 4.7614821807595575e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.004703648388385773\n",
      "Gradient for encoder.encoder.1.bias: 0.0031810826621949673\n",
      "Gradient for encoder.encoder.3.weight: 0.0951179787516594\n",
      "Gradient for encoder.encoder.3.bias: 3.948354976301971e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.009722976014018059\n",
      "Gradient for encoder.encoder.4.bias: 0.007722066715359688\n",
      "Gradient for encoder.mean.weight: 0.13668306171894073\n",
      "Gradient for encoder.mean.bias: 0.004783594980835915\n",
      "Gradient for encoder.log_var.weight: 0.07199623435735703\n",
      "Gradient for encoder.log_var.bias: 0.002641830826178193\n",
      "Gradient for decoder.decoder.0.weight: 0.016945907846093178\n",
      "Gradient for decoder.decoder.0.bias: 1.437897162448465e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.000934131327085197\n",
      "Gradient for decoder.decoder.1.bias: 0.0006515671266242862\n",
      "Gradient for decoder.decoder.3.weight: 0.015622394159436226\n",
      "Gradient for decoder.decoder.3.bias: 1.113351147385977e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0005583196179941297\n",
      "Gradient for decoder.decoder.4.bias: 0.000493067956995219\n",
      "Gradient for decoder.decoder.6.weight: 0.0006269008736126125\n",
      "Gradient for decoder.decoder.6.bias: 3.308310260763392e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.025474000722169876\n",
      "Gradient for encoder.encoder.0.bias: 4.273623468997734e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0031536046881228685\n",
      "Gradient for encoder.encoder.1.bias: 0.0026568651665002108\n",
      "Gradient for encoder.encoder.3.weight: 0.062209948897361755\n",
      "Gradient for encoder.encoder.3.bias: 3.249799873650261e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.006463177036494017\n",
      "Gradient for encoder.encoder.4.bias: 0.00546578923240304\n",
      "Gradient for encoder.mean.weight: 0.09136054664850235\n",
      "Gradient for encoder.mean.bias: 0.004301504231989384\n",
      "Gradient for encoder.log_var.weight: 0.04808110371232033\n",
      "Gradient for encoder.log_var.bias: 0.0021449143532663584\n",
      "Gradient for decoder.decoder.0.weight: 0.013206408359110355\n",
      "Gradient for decoder.decoder.0.bias: 1.277646322073167e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0007133442559279501\n",
      "Gradient for decoder.decoder.1.bias: 0.0005656754365190864\n",
      "Gradient for decoder.decoder.3.weight: 0.01225739624351263\n",
      "Gradient for decoder.decoder.3.bias: 1.2633799562067338e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0006474995170719922\n",
      "Gradient for decoder.decoder.4.bias: 0.0007033813744783401\n",
      "Gradient for decoder.decoder.6.weight: 0.0006474480614997447\n",
      "Gradient for decoder.decoder.6.bias: 4.7611934860469773e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.025844689458608627\n",
      "Gradient for encoder.encoder.0.bias: 3.922588295846019e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0028053263667970896\n",
      "Gradient for encoder.encoder.1.bias: 0.0022471414413303137\n",
      "Gradient for encoder.encoder.3.weight: 0.05777131766080856\n",
      "Gradient for encoder.encoder.3.bias: 3.24778454130481e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.006586055271327496\n",
      "Gradient for encoder.encoder.4.bias: 0.005721596535295248\n",
      "Gradient for encoder.mean.weight: 0.08813314139842987\n",
      "Gradient for encoder.mean.bias: 0.003908510785549879\n",
      "Gradient for encoder.log_var.weight: 0.04616684094071388\n",
      "Gradient for encoder.log_var.bias: 0.0025228504091501236\n",
      "Gradient for decoder.decoder.0.weight: 0.014845103956758976\n",
      "Gradient for decoder.decoder.0.bias: 1.2332920795721236e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0008039178792387247\n",
      "Gradient for decoder.decoder.1.bias: 0.0005516742239706218\n",
      "Gradient for decoder.decoder.3.weight: 0.013758225366473198\n",
      "Gradient for decoder.decoder.3.bias: 1.1703274460650448e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0006412377115339041\n",
      "Gradient for decoder.decoder.4.bias: 0.0007565045962110162\n",
      "Gradient for decoder.decoder.6.weight: 0.0005980755668133497\n",
      "Gradient for decoder.decoder.6.bias: 4.2478633986320347e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.033383335918188095\n",
      "Gradient for encoder.encoder.0.bias: 5.658304727540475e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.005313048139214516\n",
      "Gradient for encoder.encoder.1.bias: 0.0034003937616944313\n",
      "Gradient for encoder.encoder.3.weight: 0.10225629806518555\n",
      "Gradient for encoder.encoder.3.bias: 4.988445767573069e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.012985759414732456\n",
      "Gradient for encoder.encoder.4.bias: 0.010301695205271244\n",
      "Gradient for encoder.mean.weight: 0.1682627946138382\n",
      "Gradient for encoder.mean.bias: 0.007224211934953928\n",
      "Gradient for encoder.log_var.weight: 0.10602256655693054\n",
      "Gradient for encoder.log_var.bias: 0.004459264222532511\n",
      "Gradient for decoder.decoder.0.weight: 0.01292678713798523\n",
      "Gradient for decoder.decoder.0.bias: 1.1992581927522394e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0006275094347074628\n",
      "Gradient for decoder.decoder.1.bias: 0.0004722732992377132\n",
      "Gradient for decoder.decoder.3.weight: 0.011426561512053013\n",
      "Gradient for decoder.decoder.3.bias: 1.08038328283655e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0007246271125040948\n",
      "Gradient for decoder.decoder.4.bias: 0.0008789998246356845\n",
      "Gradient for decoder.decoder.6.weight: 0.0006631479482166469\n",
      "Gradient for decoder.decoder.6.bias: 5.356880137696862e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.0322234071791172\n",
      "Gradient for encoder.encoder.0.bias: 4.196430355984937e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.004237729124724865\n",
      "Gradient for encoder.encoder.1.bias: 0.0031780628487467766\n",
      "Gradient for encoder.encoder.3.weight: 0.09032328426837921\n",
      "Gradient for encoder.encoder.3.bias: 4.3003456351442537e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.008989360183477402\n",
      "Gradient for encoder.encoder.4.bias: 0.007514771539717913\n",
      "Gradient for encoder.mean.weight: 0.12496616691350937\n",
      "Gradient for encoder.mean.bias: 0.004025245551019907\n",
      "Gradient for encoder.log_var.weight: 0.06713160872459412\n",
      "Gradient for encoder.log_var.bias: 0.002501883078366518\n",
      "Gradient for decoder.decoder.0.weight: 0.01838552951812744\n",
      "Gradient for decoder.decoder.0.bias: 1.5667564468024864e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0008963553700596094\n",
      "Gradient for decoder.decoder.1.bias: 0.0007004832150414586\n",
      "Gradient for decoder.decoder.3.weight: 0.016406772658228874\n",
      "Gradient for decoder.decoder.3.bias: 1.2289394502040807e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0006313479389064014\n",
      "Gradient for decoder.decoder.4.bias: 0.0005614475230686367\n",
      "Gradient for decoder.decoder.6.weight: 0.000662351434584707\n",
      "Gradient for decoder.decoder.6.bias: 3.939491216442548e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.028575679287314415\n",
      "Gradient for encoder.encoder.0.bias: 4.435751072007221e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.004122772254049778\n",
      "Gradient for encoder.encoder.1.bias: 0.002978451317176223\n",
      "Gradient for encoder.encoder.3.weight: 0.0844673365354538\n",
      "Gradient for encoder.encoder.3.bias: 4.831324784682067e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.012348138727247715\n",
      "Gradient for encoder.encoder.4.bias: 0.011253570206463337\n",
      "Gradient for encoder.mean.weight: 0.15770046412944794\n",
      "Gradient for encoder.mean.bias: 0.007149426266551018\n",
      "Gradient for encoder.log_var.weight: 0.09225521981716156\n",
      "Gradient for encoder.log_var.bias: 0.004157353192567825\n",
      "Gradient for decoder.decoder.0.weight: 0.013559764251112938\n",
      "Gradient for decoder.decoder.0.bias: 1.1341850375545803e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0006802392890676856\n",
      "Gradient for decoder.decoder.1.bias: 0.0005172740784473717\n",
      "Gradient for decoder.decoder.3.weight: 0.012359271757304668\n",
      "Gradient for decoder.decoder.3.bias: 1.0547589884835062e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.000641306338366121\n",
      "Gradient for decoder.decoder.4.bias: 0.0007122803945094347\n",
      "Gradient for decoder.decoder.6.weight: 0.000633746909443289\n",
      "Gradient for decoder.decoder.6.bias: 4.6591321734013036e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.018554555252194405\n",
      "Gradient for encoder.encoder.0.bias: 3.1302252456733015e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0029892853926867247\n",
      "Gradient for encoder.encoder.1.bias: 0.002013907767832279\n",
      "Gradient for encoder.encoder.3.weight: 0.06263710558414459\n",
      "Gradient for encoder.encoder.3.bias: 4.4760931072751475e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.00988151878118515\n",
      "Gradient for encoder.encoder.4.bias: 0.009083962999284267\n",
      "Gradient for encoder.mean.weight: 0.12275468558073044\n",
      "Gradient for encoder.mean.bias: 0.006964490283280611\n",
      "Gradient for encoder.log_var.weight: 0.0734478309750557\n",
      "Gradient for encoder.log_var.bias: 0.0042599574662745\n",
      "Gradient for decoder.decoder.0.weight: 0.0165015310049057\n",
      "Gradient for decoder.decoder.0.bias: 1.3277187682625424e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0009014700190164149\n",
      "Gradient for decoder.decoder.1.bias: 0.0006303554982878268\n",
      "Gradient for decoder.decoder.3.weight: 0.014623656868934631\n",
      "Gradient for decoder.decoder.3.bias: 1.1329827354078503e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0006062595639377832\n",
      "Gradient for decoder.decoder.4.bias: 0.0005003685364499688\n",
      "Gradient for decoder.decoder.6.weight: 0.0007062985096126795\n",
      "Gradient for decoder.decoder.6.bias: 4.066230030730367e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.02753501385450363\n",
      "Gradient for encoder.encoder.0.bias: 4.80392149670994e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0024109608493745327\n",
      "Gradient for encoder.encoder.1.bias: 0.0019083120860159397\n",
      "Gradient for encoder.encoder.3.weight: 0.048305172473192215\n",
      "Gradient for encoder.encoder.3.bias: 3.4353567213152303e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.006109178531914949\n",
      "Gradient for encoder.encoder.4.bias: 0.005600727628916502\n",
      "Gradient for encoder.mean.weight: 0.07987777143716812\n",
      "Gradient for encoder.mean.bias: 0.004392937291413546\n",
      "Gradient for encoder.log_var.weight: 0.04325515031814575\n",
      "Gradient for encoder.log_var.bias: 0.0024136544670909643\n",
      "Gradient for decoder.decoder.0.weight: 0.012984641827642918\n",
      "Gradient for decoder.decoder.0.bias: 1.0661116434107498e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0006212845328263938\n",
      "Gradient for decoder.decoder.1.bias: 0.00047253072261810303\n",
      "Gradient for decoder.decoder.3.weight: 0.011601448059082031\n",
      "Gradient for decoder.decoder.3.bias: 8.951118318778484e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0004212047206237912\n",
      "Gradient for decoder.decoder.4.bias: 0.00036170717794448137\n",
      "Gradient for decoder.decoder.6.weight: 0.0005822795210406184\n",
      "Gradient for decoder.decoder.6.bias: 3.0166804208420217e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.036919157952070236\n",
      "Gradient for encoder.encoder.0.bias: 5.759012711159528e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.00485334312543273\n",
      "Gradient for encoder.encoder.1.bias: 0.003450264921411872\n",
      "Gradient for encoder.encoder.3.weight: 0.1021493673324585\n",
      "Gradient for encoder.encoder.3.bias: 4.936489550466661e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.009114231914281845\n",
      "Gradient for encoder.encoder.4.bias: 0.00911447312682867\n",
      "Gradient for encoder.mean.weight: 0.12451964616775513\n",
      "Gradient for encoder.mean.bias: 0.006315009668469429\n",
      "Gradient for encoder.log_var.weight: 0.08244411647319794\n",
      "Gradient for encoder.log_var.bias: 0.0038021320942789316\n",
      "Gradient for decoder.decoder.0.weight: 0.01318148709833622\n",
      "Gradient for decoder.decoder.0.bias: 1.171908403652111e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0006820403505116701\n",
      "Gradient for decoder.decoder.1.bias: 0.0004681848222389817\n",
      "Gradient for decoder.decoder.3.weight: 0.012080494314432144\n",
      "Gradient for decoder.decoder.3.bias: 1.0308055103935843e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0004611348849721253\n",
      "Gradient for decoder.decoder.4.bias: 0.0004384480125736445\n",
      "Gradient for decoder.decoder.6.weight: 0.0005601784214377403\n",
      "Gradient for decoder.decoder.6.bias: 3.088358062086627e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.05227586627006531\n",
      "Gradient for encoder.encoder.0.bias: 6.819741993346895e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.004842995200306177\n",
      "Gradient for encoder.encoder.1.bias: 0.00385210569947958\n",
      "Gradient for encoder.encoder.3.weight: 0.10599157214164734\n",
      "Gradient for encoder.encoder.3.bias: 1.007603112057609e-09\n",
      "Gradient for encoder.encoder.4.weight: 0.02419140934944153\n",
      "Gradient for encoder.encoder.4.bias: 0.018330466002225876\n",
      "Gradient for encoder.mean.weight: 0.30269914865493774\n",
      "Gradient for encoder.mean.bias: 0.011086025275290012\n",
      "Gradient for encoder.log_var.weight: 0.1808636337518692\n",
      "Gradient for encoder.log_var.bias: 0.0065702591091394424\n",
      "Gradient for decoder.decoder.0.weight: 0.017826450988650322\n",
      "Gradient for decoder.decoder.0.bias: 1.4278143944945754e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0009870921494439244\n",
      "Gradient for decoder.decoder.1.bias: 0.000721265678294003\n",
      "Gradient for decoder.decoder.3.weight: 0.016055911779403687\n",
      "Gradient for decoder.decoder.3.bias: 1.1383952808197151e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0005944992881268263\n",
      "Gradient for decoder.decoder.4.bias: 0.0005476739606820047\n",
      "Gradient for decoder.decoder.6.weight: 0.0006194158922880888\n",
      "Gradient for decoder.decoder.6.bias: 3.0943829187890515e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training VAE Epoch:  92%|█████████▏| 73/79 [00:01<00:00, 74.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient for encoder.encoder.0.weight: 0.021157514303922653\n",
      "Gradient for encoder.encoder.0.bias: 3.2298982932665865e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.00282479589805007\n",
      "Gradient for encoder.encoder.1.bias: 0.00220107170753181\n",
      "Gradient for encoder.encoder.3.weight: 0.06123632937669754\n",
      "Gradient for encoder.encoder.3.bias: 4.31165547709611e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.012660989537835121\n",
      "Gradient for encoder.encoder.4.bias: 0.00931404996663332\n",
      "Gradient for encoder.mean.weight: 0.16167587041854858\n",
      "Gradient for encoder.mean.bias: 0.006302709225565195\n",
      "Gradient for encoder.log_var.weight: 0.09900707751512527\n",
      "Gradient for encoder.log_var.bias: 0.0039298743940889835\n",
      "Gradient for decoder.decoder.0.weight: 0.018252499401569366\n",
      "Gradient for decoder.decoder.0.bias: 1.5395300312359694e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0009308344451710582\n",
      "Gradient for decoder.decoder.1.bias: 0.0006753492634743452\n",
      "Gradient for decoder.decoder.3.weight: 0.016006534919142723\n",
      "Gradient for decoder.decoder.3.bias: 1.0940313238672061e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0005597661947831511\n",
      "Gradient for decoder.decoder.4.bias: 0.0004680620913859457\n",
      "Gradient for decoder.decoder.6.weight: 0.0005761106149293482\n",
      "Gradient for decoder.decoder.6.bias: 2.3089822207111865e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.04487394914031029\n",
      "Gradient for encoder.encoder.0.bias: 7.650527433789023e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.00601202342659235\n",
      "Gradient for encoder.encoder.1.bias: 0.004437083378434181\n",
      "Gradient for encoder.encoder.3.weight: 0.12188444286584854\n",
      "Gradient for encoder.encoder.3.bias: 5.210216147411018e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.009567368775606155\n",
      "Gradient for encoder.encoder.4.bias: 0.008679129183292389\n",
      "Gradient for encoder.mean.weight: 0.13119348883628845\n",
      "Gradient for encoder.mean.bias: 0.005175214726477861\n",
      "Gradient for encoder.log_var.weight: 0.06673555821180344\n",
      "Gradient for encoder.log_var.bias: 0.0033002712298184633\n",
      "Gradient for decoder.decoder.0.weight: 0.014511159621179104\n",
      "Gradient for decoder.decoder.0.bias: 1.231060531292627e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0007798747974447906\n",
      "Gradient for decoder.decoder.1.bias: 0.0005989109631627798\n",
      "Gradient for decoder.decoder.3.weight: 0.013906330801546574\n",
      "Gradient for decoder.decoder.3.bias: 1.0156072510758563e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0005214384873397648\n",
      "Gradient for decoder.decoder.4.bias: 0.00048332635196857154\n",
      "Gradient for decoder.decoder.6.weight: 0.0006230960716493428\n",
      "Gradient for decoder.decoder.6.bias: 3.8162328564794734e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.021990014240145683\n",
      "Gradient for encoder.encoder.0.bias: 3.968085929284548e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0035763857886195183\n",
      "Gradient for encoder.encoder.1.bias: 0.003139722626656294\n",
      "Gradient for encoder.encoder.3.weight: 0.07811515778303146\n",
      "Gradient for encoder.encoder.3.bias: 4.1007755524624656e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.009165899828076363\n",
      "Gradient for encoder.encoder.4.bias: 0.009564228355884552\n",
      "Gradient for encoder.mean.weight: 0.1155916079878807\n",
      "Gradient for encoder.mean.bias: 0.006696266587823629\n",
      "Gradient for encoder.log_var.weight: 0.07136747241020203\n",
      "Gradient for encoder.log_var.bias: 0.004414152819663286\n",
      "Gradient for decoder.decoder.0.weight: 0.015094916336238384\n",
      "Gradient for decoder.decoder.0.bias: 1.2186809894565442e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0008339420310221612\n",
      "Gradient for decoder.decoder.1.bias: 0.0005933785578235984\n",
      "Gradient for decoder.decoder.3.weight: 0.01372960489243269\n",
      "Gradient for decoder.decoder.3.bias: 1.0651662191163425e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0004988820874132216\n",
      "Gradient for decoder.decoder.4.bias: 0.00044661943684332073\n",
      "Gradient for decoder.decoder.6.weight: 0.0005843068938702345\n",
      "Gradient for decoder.decoder.6.bias: 3.009949614352081e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.020944295451045036\n",
      "Gradient for encoder.encoder.0.bias: 3.2588685222600944e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.003478747559711337\n",
      "Gradient for encoder.encoder.1.bias: 0.002929312875494361\n",
      "Gradient for encoder.encoder.3.weight: 0.07550700753927231\n",
      "Gradient for encoder.encoder.3.bias: 4.340027504046162e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0079886419698596\n",
      "Gradient for encoder.encoder.4.bias: 0.009249110706150532\n",
      "Gradient for encoder.mean.weight: 0.10691244900226593\n",
      "Gradient for encoder.mean.bias: 0.006664365064352751\n",
      "Gradient for encoder.log_var.weight: 0.06584420055150986\n",
      "Gradient for encoder.log_var.bias: 0.004435359500348568\n",
      "Gradient for decoder.decoder.0.weight: 0.016653256490826607\n",
      "Gradient for decoder.decoder.0.bias: 1.5287147936415835e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0008977263350971043\n",
      "Gradient for decoder.decoder.1.bias: 0.0006192312575876713\n",
      "Gradient for decoder.decoder.3.weight: 0.014894463121891022\n",
      "Gradient for decoder.decoder.3.bias: 1.2379322567035445e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0005800091894343495\n",
      "Gradient for decoder.decoder.4.bias: 0.0005673350533470511\n",
      "Gradient for decoder.decoder.6.weight: 0.0005760547355748713\n",
      "Gradient for decoder.decoder.6.bias: 2.691082590899896e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.03370092436671257\n",
      "Gradient for encoder.encoder.0.bias: 3.317187149964873e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.004512685816735029\n",
      "Gradient for encoder.encoder.1.bias: 0.003037551883608103\n",
      "Gradient for encoder.encoder.3.weight: 0.09011037647724152\n",
      "Gradient for encoder.encoder.3.bias: 4.3476303113187953e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.008769598789513111\n",
      "Gradient for encoder.encoder.4.bias: 0.00950705911964178\n",
      "Gradient for encoder.mean.weight: 0.11931571364402771\n",
      "Gradient for encoder.mean.bias: 0.0061504533514380455\n",
      "Gradient for encoder.log_var.weight: 0.07663258910179138\n",
      "Gradient for encoder.log_var.bias: 0.0040077934972941875\n",
      "Gradient for decoder.decoder.0.weight: 0.022288260981440544\n",
      "Gradient for decoder.decoder.0.bias: 1.860624709859593e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0011473603080958128\n",
      "Gradient for decoder.decoder.1.bias: 0.0008966401219367981\n",
      "Gradient for decoder.decoder.3.weight: 0.019696827977895737\n",
      "Gradient for decoder.decoder.3.bias: 1.785627895545261e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0007888179388828576\n",
      "Gradient for decoder.decoder.4.bias: 0.000711368746124208\n",
      "Gradient for decoder.decoder.6.weight: 0.0006728680455125868\n",
      "Gradient for decoder.decoder.6.bias: 3.2009571441449225e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.024069592356681824\n",
      "Gradient for encoder.encoder.0.bias: 4.372840631261532e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.00451195752248168\n",
      "Gradient for encoder.encoder.1.bias: 0.0031447475776076317\n",
      "Gradient for encoder.encoder.3.weight: 0.08473611623048782\n",
      "Gradient for encoder.encoder.3.bias: 5.259102042742825e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.012229014188051224\n",
      "Gradient for encoder.encoder.4.bias: 0.011147059500217438\n",
      "Gradient for encoder.mean.weight: 0.15948525071144104\n",
      "Gradient for encoder.mean.bias: 0.008138454519212246\n",
      "Gradient for encoder.log_var.weight: 0.08225264400243759\n",
      "Gradient for encoder.log_var.bias: 0.004147975705564022\n",
      "Gradient for decoder.decoder.0.weight: 0.015426361933350563\n",
      "Gradient for decoder.decoder.0.bias: 1.292794760132665e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0008283013594336808\n",
      "Gradient for decoder.decoder.1.bias: 0.0006334292120300233\n",
      "Gradient for decoder.decoder.3.weight: 0.013298445381224155\n",
      "Gradient for decoder.decoder.3.bias: 1.165083723941862e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0005657742731273174\n",
      "Gradient for decoder.decoder.4.bias: 0.0005734128644689918\n",
      "Gradient for decoder.decoder.6.weight: 0.0006249317084439099\n",
      "Gradient for decoder.decoder.6.bias: 3.668313001981005e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.0231462549418211\n",
      "Gradient for encoder.encoder.0.bias: 3.1727669103087663e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.002834183629602194\n",
      "Gradient for encoder.encoder.1.bias: 0.001986961578950286\n",
      "Gradient for encoder.encoder.3.weight: 0.05168085917830467\n",
      "Gradient for encoder.encoder.3.bias: 3.9416550579041143e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.007179524749517441\n",
      "Gradient for encoder.encoder.4.bias: 0.008384943008422852\n",
      "Gradient for encoder.mean.weight: 0.09717783331871033\n",
      "Gradient for encoder.mean.bias: 0.007159015629440546\n",
      "Gradient for encoder.log_var.weight: 0.05675408989191055\n",
      "Gradient for encoder.log_var.bias: 0.0037818264681845903\n",
      "Gradient for decoder.decoder.0.weight: 0.020487455651164055\n",
      "Gradient for decoder.decoder.0.bias: 1.722545855953328e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0010174476774409413\n",
      "Gradient for decoder.decoder.1.bias: 0.0007670689956285059\n",
      "Gradient for decoder.decoder.3.weight: 0.017851870507001877\n",
      "Gradient for decoder.decoder.3.bias: 1.3661563547096023e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0008368943817913532\n",
      "Gradient for decoder.decoder.4.bias: 0.0009000922436825931\n",
      "Gradient for decoder.decoder.6.weight: 0.0007029046537354589\n",
      "Gradient for decoder.decoder.6.bias: 4.597604493028484e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.022016292437911034\n",
      "Gradient for encoder.encoder.0.bias: 3.3883028327519327e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.004499285016208887\n",
      "Gradient for encoder.encoder.1.bias: 0.0028499504551291466\n",
      "Gradient for encoder.encoder.3.weight: 0.08574197441339493\n",
      "Gradient for encoder.encoder.3.bias: 4.897393046654486e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.014643744565546513\n",
      "Gradient for encoder.encoder.4.bias: 0.010835288092494011\n",
      "Gradient for encoder.mean.weight: 0.18876177072525024\n",
      "Gradient for encoder.mean.bias: 0.00656577292829752\n",
      "Gradient for encoder.log_var.weight: 0.1000407338142395\n",
      "Gradient for encoder.log_var.bias: 0.004051778465509415\n",
      "Gradient for decoder.decoder.0.weight: 0.01724967360496521\n",
      "Gradient for decoder.decoder.0.bias: 1.4636988843186316e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0010181172983720899\n",
      "Gradient for decoder.decoder.1.bias: 0.0007399083115160465\n",
      "Gradient for decoder.decoder.3.weight: 0.016504546627402306\n",
      "Gradient for decoder.decoder.3.bias: 1.162435564472375e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0006794525543227792\n",
      "Gradient for decoder.decoder.4.bias: 0.0005911181797273457\n",
      "Gradient for decoder.decoder.6.weight: 0.0007050730637274683\n",
      "Gradient for decoder.decoder.6.bias: 3.887817001668736e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.030071208253502846\n",
      "Gradient for encoder.encoder.0.bias: 3.371970758170306e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.003005784237757325\n",
      "Gradient for encoder.encoder.1.bias: 0.0019825920462608337\n",
      "Gradient for encoder.encoder.3.weight: 0.06371951848268509\n",
      "Gradient for encoder.encoder.3.bias: 3.373858414867925e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.006609026808291674\n",
      "Gradient for encoder.encoder.4.bias: 0.005300954915583134\n",
      "Gradient for encoder.mean.weight: 0.08324475586414337\n",
      "Gradient for encoder.mean.bias: 0.003762040752917528\n",
      "Gradient for encoder.log_var.weight: 0.0440586619079113\n",
      "Gradient for encoder.log_var.bias: 0.0021053049713373184\n",
      "Gradient for decoder.decoder.0.weight: 0.017861930653452873\n",
      "Gradient for decoder.decoder.0.bias: 1.546082428749429e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0010094260796904564\n",
      "Gradient for decoder.decoder.1.bias: 0.0006629700656048954\n",
      "Gradient for decoder.decoder.3.weight: 0.015928925946354866\n",
      "Gradient for decoder.decoder.3.bias: 1.3843116930534194e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0005735444719903171\n",
      "Gradient for decoder.decoder.4.bias: 0.0004772285174112767\n",
      "Gradient for decoder.decoder.6.weight: 0.0005651402752846479\n",
      "Gradient for decoder.decoder.6.bias: 2.505574047972914e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.018966568633913994\n",
      "Gradient for encoder.encoder.0.bias: 3.137136384001593e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0029882751405239105\n",
      "Gradient for encoder.encoder.1.bias: 0.0025055462028831244\n",
      "Gradient for encoder.encoder.3.weight: 0.06332915276288986\n",
      "Gradient for encoder.encoder.3.bias: 4.387509522363331e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.00867956131696701\n",
      "Gradient for encoder.encoder.4.bias: 0.009321129880845547\n",
      "Gradient for encoder.mean.weight: 0.11239667236804962\n",
      "Gradient for encoder.mean.bias: 0.007162194233387709\n",
      "Gradient for encoder.log_var.weight: 0.06442030519247055\n",
      "Gradient for encoder.log_var.bias: 0.0035669910721480846\n",
      "Gradient for decoder.decoder.0.weight: 0.01634431630373001\n",
      "Gradient for decoder.decoder.0.bias: 1.4433232387034423e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0008126289467327297\n",
      "Gradient for decoder.decoder.1.bias: 0.000681294419337064\n",
      "Gradient for decoder.decoder.3.weight: 0.014266034588217735\n",
      "Gradient for decoder.decoder.3.bias: 1.1401208449557387e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0005866233841516078\n",
      "Gradient for decoder.decoder.4.bias: 0.00055418920237571\n",
      "Gradient for decoder.decoder.6.weight: 0.0006243232055567205\n",
      "Gradient for decoder.decoder.6.bias: 3.531313268467784e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.030419547110795975\n",
      "Gradient for encoder.encoder.0.bias: 4.840678552442412e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.005715732928365469\n",
      "Gradient for encoder.encoder.1.bias: 0.003773108357563615\n",
      "Gradient for encoder.encoder.3.weight: 0.11734878271818161\n",
      "Gradient for encoder.encoder.3.bias: 5.941007685805744e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.015906941145658493\n",
      "Gradient for encoder.encoder.4.bias: 0.012686711736023426\n",
      "Gradient for encoder.mean.weight: 0.20245981216430664\n",
      "Gradient for encoder.mean.bias: 0.006566242780536413\n",
      "Gradient for encoder.log_var.weight: 0.12227010726928711\n",
      "Gradient for encoder.log_var.bias: 0.00421546958386898\n",
      "Gradient for decoder.decoder.0.weight: 0.014740931801497936\n",
      "Gradient for decoder.decoder.0.bias: 1.191418491641727e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.000763349758926779\n",
      "Gradient for decoder.decoder.1.bias: 0.0006025603506714106\n",
      "Gradient for decoder.decoder.3.weight: 0.013605332002043724\n",
      "Gradient for decoder.decoder.3.bias: 1.0092061908384409e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0004812316328752786\n",
      "Gradient for decoder.decoder.4.bias: 0.0004132782050874084\n",
      "Gradient for decoder.decoder.6.weight: 0.0005925845471210778\n",
      "Gradient for decoder.decoder.6.bias: 3.151356213493273e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.01962209679186344\n",
      "Gradient for encoder.encoder.0.bias: 3.054245745204298e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0030895730014890432\n",
      "Gradient for encoder.encoder.1.bias: 0.0024997389409691095\n",
      "Gradient for encoder.encoder.3.weight: 0.06771896034479141\n",
      "Gradient for encoder.encoder.3.bias: 3.9200198642674877e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.01028588879853487\n",
      "Gradient for encoder.encoder.4.bias: 0.008140967227518559\n",
      "Gradient for encoder.mean.weight: 0.13032259047031403\n",
      "Gradient for encoder.mean.bias: 0.004500919487327337\n",
      "Gradient for encoder.log_var.weight: 0.08558616042137146\n",
      "Gradient for encoder.log_var.bias: 0.0028508331160992384\n",
      "Gradient for decoder.decoder.0.weight: 0.017032550647854805\n",
      "Gradient for decoder.decoder.0.bias: 1.447256620101811e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0008946318412199616\n",
      "Gradient for decoder.decoder.1.bias: 0.0006523455958813429\n",
      "Gradient for decoder.decoder.3.weight: 0.014834427274763584\n",
      "Gradient for decoder.decoder.3.bias: 1.1777934183498928e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0004966550040990114\n",
      "Gradient for decoder.decoder.4.bias: 0.0004592259938362986\n",
      "Gradient for decoder.decoder.6.weight: 0.0006235396140255034\n",
      "Gradient for decoder.decoder.6.bias: 3.584137448342517e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.02069688029587269\n",
      "Gradient for encoder.encoder.0.bias: 3.378063453962632e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0025277298409491777\n",
      "Gradient for encoder.encoder.1.bias: 0.0019326258916407824\n",
      "Gradient for encoder.encoder.3.weight: 0.054707933217287064\n",
      "Gradient for encoder.encoder.3.bias: 3.5507594087214045e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.009001549333333969\n",
      "Gradient for encoder.encoder.4.bias: 0.007246688008308411\n",
      "Gradient for encoder.mean.weight: 0.11858829855918884\n",
      "Gradient for encoder.mean.bias: 0.005154361017048359\n",
      "Gradient for encoder.log_var.weight: 0.05474978685379028\n",
      "Gradient for encoder.log_var.bias: 0.0026721907779574394\n",
      "Gradient for decoder.decoder.0.weight: 0.014898085966706276\n",
      "Gradient for decoder.decoder.0.bias: 1.3818166055834524e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.00071877078153193\n",
      "Gradient for decoder.decoder.1.bias: 0.0006040181033313274\n",
      "Gradient for decoder.decoder.3.weight: 0.01251258049160242\n",
      "Gradient for decoder.decoder.3.bias: 1.034850607983806e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0005605334299616516\n",
      "Gradient for decoder.decoder.4.bias: 0.0006066546775400639\n",
      "Gradient for decoder.decoder.6.weight: 0.0005741050117649138\n",
      "Gradient for decoder.decoder.6.bias: 3.858080162899569e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.02943495102226734\n",
      "Gradient for encoder.encoder.0.bias: 3.6435843925319844e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.003902892116457224\n",
      "Gradient for encoder.encoder.1.bias: 0.002837900537997484\n",
      "Gradient for encoder.encoder.3.weight: 0.08269453048706055\n",
      "Gradient for encoder.encoder.3.bias: 5.472332587075357e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.016065342351794243\n",
      "Gradient for encoder.encoder.4.bias: 0.011486544273793697\n",
      "Gradient for encoder.mean.weight: 0.20885391533374786\n",
      "Gradient for encoder.mean.bias: 0.005658838897943497\n",
      "Gradient for encoder.log_var.weight: 0.11030615121126175\n",
      "Gradient for encoder.log_var.bias: 0.0029640726279467344\n",
      "Gradient for decoder.decoder.0.weight: 0.019877158105373383\n",
      "Gradient for decoder.decoder.0.bias: 1.5532601593815087e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0010362268658354878\n",
      "Gradient for decoder.decoder.1.bias: 0.0007361169555224478\n",
      "Gradient for decoder.decoder.3.weight: 0.01761510968208313\n",
      "Gradient for decoder.decoder.3.bias: 1.2884245059741062e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0006892079254612327\n",
      "Gradient for decoder.decoder.4.bias: 0.0006353401113301516\n",
      "Gradient for decoder.decoder.6.weight: 0.0007141266250982881\n",
      "Gradient for decoder.decoder.6.bias: 4.4360593165038154e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.12665675580501556\n",
      "Gradient for encoder.encoder.0.bias: 2.6325611135469273e-10\n",
      "Gradient for encoder.encoder.1.weight: 0.015370390377938747\n",
      "Gradient for encoder.encoder.1.bias: 0.01174346636980772\n",
      "Gradient for encoder.encoder.3.weight: 0.2872304618358612\n",
      "Gradient for encoder.encoder.3.bias: 2.1266375327400056e-09\n",
      "Gradient for encoder.encoder.4.weight: 0.03377153351902962\n",
      "Gradient for encoder.encoder.4.bias: 0.03138788789510727\n",
      "Gradient for encoder.mean.weight: 0.40779730677604675\n",
      "Gradient for encoder.mean.bias: 0.019375350326299667\n",
      "Gradient for encoder.log_var.weight: 0.2186547964811325\n",
      "Gradient for encoder.log_var.bias: 0.0103108249604702\n",
      "Gradient for decoder.decoder.0.weight: 0.03552863746881485\n",
      "Gradient for decoder.decoder.0.bias: 2.1591654852937125e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0015878007980063558\n",
      "Gradient for decoder.decoder.1.bias: 0.0012626057723537087\n",
      "Gradient for decoder.decoder.3.weight: 0.03134094923734665\n",
      "Gradient for decoder.decoder.3.bias: 2.100971480123448e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0010596244828775525\n",
      "Gradient for decoder.decoder.4.bias: 0.0009425109601579607\n",
      "Gradient for decoder.decoder.6.weight: 0.001523137791082263\n",
      "Gradient for decoder.decoder.6.bias: 9.780246909940615e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/3, Train Loss: 0.0696, Val Loss: 0.2783\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training VAE Epoch:   1%|▏         | 1/79 [00:00<00:13,  5.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient for encoder.encoder.0.weight: 0.01965748332440853\n",
      "Gradient for encoder.encoder.0.bias: 2.7725275200674027e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0029842164367437363\n",
      "Gradient for encoder.encoder.1.bias: 0.0022253328934311867\n",
      "Gradient for encoder.encoder.3.weight: 0.06513188779354095\n",
      "Gradient for encoder.encoder.3.bias: 4.676151688087771e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.008716498501598835\n",
      "Gradient for encoder.encoder.4.bias: 0.010200923308730125\n",
      "Gradient for encoder.mean.weight: 0.1102515161037445\n",
      "Gradient for encoder.mean.bias: 0.007344170473515987\n",
      "Gradient for encoder.log_var.weight: 0.0678173303604126\n",
      "Gradient for encoder.log_var.bias: 0.00481951329857111\n",
      "Gradient for decoder.decoder.0.weight: 0.01903047040104866\n",
      "Gradient for decoder.decoder.0.bias: 1.6697608573590372e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0009885047329589725\n",
      "Gradient for decoder.decoder.1.bias: 0.0007197657250799239\n",
      "Gradient for decoder.decoder.3.weight: 0.01632765121757984\n",
      "Gradient for decoder.decoder.3.bias: 1.1965932411595048e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0005718859029002488\n",
      "Gradient for decoder.decoder.4.bias: 0.0005648963851854205\n",
      "Gradient for decoder.decoder.6.weight: 0.0006211476284079254\n",
      "Gradient for decoder.decoder.6.bias: 3.413127706153318e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.03504418581724167\n",
      "Gradient for encoder.encoder.0.bias: 4.9848316446832186e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.005329666193574667\n",
      "Gradient for encoder.encoder.1.bias: 0.0040929121896624565\n",
      "Gradient for encoder.encoder.3.weight: 0.10922331362962723\n",
      "Gradient for encoder.encoder.3.bias: 5.463545171835449e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.011661910451948643\n",
      "Gradient for encoder.encoder.4.bias: 0.012178418226540089\n",
      "Gradient for encoder.mean.weight: 0.15138746798038483\n",
      "Gradient for encoder.mean.bias: 0.008116993121802807\n",
      "Gradient for encoder.log_var.weight: 0.07894901931285858\n",
      "Gradient for encoder.log_var.bias: 0.004445686470717192\n",
      "Gradient for decoder.decoder.0.weight: 0.01765131950378418\n",
      "Gradient for decoder.decoder.0.bias: 1.585447190199929e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0008826496778056026\n",
      "Gradient for decoder.decoder.1.bias: 0.0006571759004145861\n",
      "Gradient for decoder.decoder.3.weight: 0.015096950344741344\n",
      "Gradient for decoder.decoder.3.bias: 1.2489335954324332e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0006947671645320952\n",
      "Gradient for decoder.decoder.4.bias: 0.0007193561759777367\n",
      "Gradient for decoder.decoder.6.weight: 0.0006828015903010964\n",
      "Gradient for decoder.decoder.6.bias: 3.971017213189043e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training VAE Epoch:  10%|█         | 8/79 [00:00<00:02, 33.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient for encoder.encoder.0.weight: 0.027590397745370865\n",
      "Gradient for encoder.encoder.0.bias: 5.0191933942400624e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.005169756710529327\n",
      "Gradient for encoder.encoder.1.bias: 0.003245950909331441\n",
      "Gradient for encoder.encoder.3.weight: 0.1099579855799675\n",
      "Gradient for encoder.encoder.3.bias: 5.017926629768965e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.01417325809597969\n",
      "Gradient for encoder.encoder.4.bias: 0.011525837704539299\n",
      "Gradient for encoder.mean.weight: 0.1768220216035843\n",
      "Gradient for encoder.mean.bias: 0.007166564930230379\n",
      "Gradient for encoder.log_var.weight: 0.09452638775110245\n",
      "Gradient for encoder.log_var.bias: 0.0037969115655869246\n",
      "Gradient for decoder.decoder.0.weight: 0.01215844415128231\n",
      "Gradient for decoder.decoder.0.bias: 1.0747663869992152e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0006359871476888657\n",
      "Gradient for decoder.decoder.1.bias: 0.0004623265704140067\n",
      "Gradient for decoder.decoder.3.weight: 0.011267883703112602\n",
      "Gradient for decoder.decoder.3.bias: 9.757551711064849e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0005345137324184179\n",
      "Gradient for decoder.decoder.4.bias: 0.000603965250775218\n",
      "Gradient for decoder.decoder.6.weight: 0.00060510472394526\n",
      "Gradient for decoder.decoder.6.bias: 4.29905740020331e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.02583772875368595\n",
      "Gradient for encoder.encoder.0.bias: 4.4503140755880466e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0043896036222577095\n",
      "Gradient for encoder.encoder.1.bias: 0.0028714549262076616\n",
      "Gradient for encoder.encoder.3.weight: 0.09463398903608322\n",
      "Gradient for encoder.encoder.3.bias: 5.654512413855173e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.01347446907311678\n",
      "Gradient for encoder.encoder.4.bias: 0.013786958530545235\n",
      "Gradient for encoder.mean.weight: 0.1644190549850464\n",
      "Gradient for encoder.mean.bias: 0.009724391624331474\n",
      "Gradient for encoder.log_var.weight: 0.08786439150571823\n",
      "Gradient for encoder.log_var.bias: 0.004840472247451544\n",
      "Gradient for decoder.decoder.0.weight: 0.015154390595853329\n",
      "Gradient for decoder.decoder.0.bias: 1.2253890957492075e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0008069434552453458\n",
      "Gradient for decoder.decoder.1.bias: 0.0005425950512290001\n",
      "Gradient for decoder.decoder.3.weight: 0.01305508054792881\n",
      "Gradient for decoder.decoder.3.bias: 1.0197170885462015e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0005668862140737474\n",
      "Gradient for decoder.decoder.4.bias: 0.0006208842969499528\n",
      "Gradient for decoder.decoder.6.weight: 0.0006071822135709226\n",
      "Gradient for decoder.decoder.6.bias: 4.04115671699401e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.040572039783000946\n",
      "Gradient for encoder.encoder.0.bias: 6.26689117266821e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.00691722659394145\n",
      "Gradient for encoder.encoder.1.bias: 0.004552669357508421\n",
      "Gradient for encoder.encoder.3.weight: 0.13893628120422363\n",
      "Gradient for encoder.encoder.3.bias: 7.950989311389378e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.018028900027275085\n",
      "Gradient for encoder.encoder.4.bias: 0.016849515959620476\n",
      "Gradient for encoder.mean.weight: 0.2355118989944458\n",
      "Gradient for encoder.mean.bias: 0.010841812938451767\n",
      "Gradient for encoder.log_var.weight: 0.13776428997516632\n",
      "Gradient for encoder.log_var.bias: 0.006755133159458637\n",
      "Gradient for decoder.decoder.0.weight: 0.014848986640572548\n",
      "Gradient for decoder.decoder.0.bias: 1.3073259141904714e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.000735059380531311\n",
      "Gradient for decoder.decoder.1.bias: 0.00056707754265517\n",
      "Gradient for decoder.decoder.3.weight: 0.013182119466364384\n",
      "Gradient for decoder.decoder.3.bias: 1.0794839327976646e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.000600270286668092\n",
      "Gradient for decoder.decoder.4.bias: 0.0006554201245307922\n",
      "Gradient for decoder.decoder.6.weight: 0.000639138335827738\n",
      "Gradient for decoder.decoder.6.bias: 4.36175505456049e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.03247104957699776\n",
      "Gradient for encoder.encoder.0.bias: 5.525823548735431e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0038576482329517603\n",
      "Gradient for encoder.encoder.1.bias: 0.0032137054949998856\n",
      "Gradient for encoder.encoder.3.weight: 0.08302901685237885\n",
      "Gradient for encoder.encoder.3.bias: 5.172220984839271e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.009609589353203773\n",
      "Gradient for encoder.encoder.4.bias: 0.01081834826618433\n",
      "Gradient for encoder.mean.weight: 0.12112191319465637\n",
      "Gradient for encoder.mean.bias: 0.00718032056465745\n",
      "Gradient for encoder.log_var.weight: 0.0748244896531105\n",
      "Gradient for encoder.log_var.bias: 0.004991109948605299\n",
      "Gradient for decoder.decoder.0.weight: 0.013400230556726456\n",
      "Gradient for decoder.decoder.0.bias: 1.1747734729450343e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0006714728660881519\n",
      "Gradient for decoder.decoder.1.bias: 0.0004965728148818016\n",
      "Gradient for decoder.decoder.3.weight: 0.011668495833873749\n",
      "Gradient for decoder.decoder.3.bias: 1.184032455414652e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0006938420119695365\n",
      "Gradient for decoder.decoder.4.bias: 0.00083526800153777\n",
      "Gradient for decoder.decoder.6.weight: 0.0006605129456147552\n",
      "Gradient for decoder.decoder.6.bias: 5.119693378219381e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.024959878996014595\n",
      "Gradient for encoder.encoder.0.bias: 3.8956626119412974e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0028647021390497684\n",
      "Gradient for encoder.encoder.1.bias: 0.00218222732655704\n",
      "Gradient for encoder.encoder.3.weight: 0.06036858633160591\n",
      "Gradient for encoder.encoder.3.bias: 4.266402786612389e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.008651341311633587\n",
      "Gradient for encoder.encoder.4.bias: 0.008384387008845806\n",
      "Gradient for encoder.mean.weight: 0.10964140295982361\n",
      "Gradient for encoder.mean.bias: 0.005360725801438093\n",
      "Gradient for encoder.log_var.weight: 0.0561523512005806\n",
      "Gradient for encoder.log_var.bias: 0.0030993695836514235\n",
      "Gradient for decoder.decoder.0.weight: 0.014730079099535942\n",
      "Gradient for decoder.decoder.0.bias: 1.3282140665094033e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0008150242501869798\n",
      "Gradient for decoder.decoder.1.bias: 0.0005724464426748455\n",
      "Gradient for decoder.decoder.3.weight: 0.012651762925088406\n",
      "Gradient for decoder.decoder.3.bias: 1.1062097071690147e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0004311038355808705\n",
      "Gradient for decoder.decoder.4.bias: 0.00039406982250511646\n",
      "Gradient for decoder.decoder.6.weight: 0.0006218235939741135\n",
      "Gradient for decoder.decoder.6.bias: 3.8532692997250706e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.02506347931921482\n",
      "Gradient for encoder.encoder.0.bias: 3.522164157554464e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0037004747427999973\n",
      "Gradient for encoder.encoder.1.bias: 0.002831237157806754\n",
      "Gradient for encoder.encoder.3.weight: 0.07606863975524902\n",
      "Gradient for encoder.encoder.3.bias: 3.798523440234902e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.00810609944164753\n",
      "Gradient for encoder.encoder.4.bias: 0.007497279904782772\n",
      "Gradient for encoder.mean.weight: 0.10974662005901337\n",
      "Gradient for encoder.mean.bias: 0.005055320914834738\n",
      "Gradient for encoder.log_var.weight: 0.06287521868944168\n",
      "Gradient for encoder.log_var.bias: 0.0027887423057109118\n",
      "Gradient for decoder.decoder.0.weight: 0.016259420663118362\n",
      "Gradient for decoder.decoder.0.bias: 1.288614215333439e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0007928552222438157\n",
      "Gradient for decoder.decoder.1.bias: 0.0006041322485543787\n",
      "Gradient for decoder.decoder.3.weight: 0.014256411232054234\n",
      "Gradient for decoder.decoder.3.bias: 1.0476999129371833e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0005728431860916317\n",
      "Gradient for decoder.decoder.4.bias: 0.0005578800337389112\n",
      "Gradient for decoder.decoder.6.weight: 0.0006050140364095569\n",
      "Gradient for decoder.decoder.6.bias: 3.341191404615529e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.033117178827524185\n",
      "Gradient for encoder.encoder.0.bias: 6.874548152957516e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.005121704190969467\n",
      "Gradient for encoder.encoder.1.bias: 0.004127263091504574\n",
      "Gradient for encoder.encoder.3.weight: 0.10763712227344513\n",
      "Gradient for encoder.encoder.3.bias: 5.749040687952345e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.014218141324818134\n",
      "Gradient for encoder.encoder.4.bias: 0.0127145079895854\n",
      "Gradient for encoder.mean.weight: 0.18667298555374146\n",
      "Gradient for encoder.mean.bias: 0.008673228323459625\n",
      "Gradient for encoder.log_var.weight: 0.0989043265581131\n",
      "Gradient for encoder.log_var.bias: 0.005081538110971451\n",
      "Gradient for decoder.decoder.0.weight: 0.012993894517421722\n",
      "Gradient for decoder.decoder.0.bias: 1.081890826926113e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0006408803747035563\n",
      "Gradient for decoder.decoder.1.bias: 0.0005092592327855527\n",
      "Gradient for decoder.decoder.3.weight: 0.011491847224533558\n",
      "Gradient for decoder.decoder.3.bias: 8.639790272102488e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0004023398505523801\n",
      "Gradient for decoder.decoder.4.bias: 0.0003540845646057278\n",
      "Gradient for decoder.decoder.6.weight: 0.0006549066747538745\n",
      "Gradient for decoder.decoder.6.bias: 4.6722318074898794e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.03521938621997833\n",
      "Gradient for encoder.encoder.0.bias: 4.7942864955796693e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0038829827681183815\n",
      "Gradient for encoder.encoder.1.bias: 0.0032859542407095432\n",
      "Gradient for encoder.encoder.3.weight: 0.0885009765625\n",
      "Gradient for encoder.encoder.3.bias: 7.020119485723342e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.01734907552599907\n",
      "Gradient for encoder.encoder.4.bias: 0.013379689306020737\n",
      "Gradient for encoder.mean.weight: 0.2147921919822693\n",
      "Gradient for encoder.mean.bias: 0.00808709766715765\n",
      "Gradient for encoder.log_var.weight: 0.12803246080875397\n",
      "Gradient for encoder.log_var.bias: 0.004668413661420345\n",
      "Gradient for decoder.decoder.0.weight: 0.017557293176651\n",
      "Gradient for decoder.decoder.0.bias: 1.4880005561046517e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0009594490402378142\n",
      "Gradient for decoder.decoder.1.bias: 0.000676398747600615\n",
      "Gradient for decoder.decoder.3.weight: 0.0158877931535244\n",
      "Gradient for decoder.decoder.3.bias: 1.4910124523925816e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0008669483941048384\n",
      "Gradient for decoder.decoder.4.bias: 0.0009503463516011834\n",
      "Gradient for decoder.decoder.6.weight: 0.0007789373048581183\n",
      "Gradient for decoder.decoder.6.bias: 5.5726140999468043e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.025706298649311066\n",
      "Gradient for encoder.encoder.0.bias: 4.6559200939100265e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0029850562568753958\n",
      "Gradient for encoder.encoder.1.bias: 0.0025124400854110718\n",
      "Gradient for encoder.encoder.3.weight: 0.06998556107282639\n",
      "Gradient for encoder.encoder.3.bias: 4.381006390996589e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.00898580439388752\n",
      "Gradient for encoder.encoder.4.bias: 0.00944976881146431\n",
      "Gradient for encoder.mean.weight: 0.11531388014554977\n",
      "Gradient for encoder.mean.bias: 0.007662680000066757\n",
      "Gradient for encoder.log_var.weight: 0.053933847695589066\n",
      "Gradient for encoder.log_var.bias: 0.0037373732775449753\n",
      "Gradient for decoder.decoder.0.weight: 0.013629482127726078\n",
      "Gradient for decoder.decoder.0.bias: 1.0803850869489651e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0006854567909613252\n",
      "Gradient for decoder.decoder.1.bias: 0.000548193755093962\n",
      "Gradient for decoder.decoder.3.weight: 0.011973714455962181\n",
      "Gradient for decoder.decoder.3.bias: 9.995917982230651e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0004639778344426304\n",
      "Gradient for decoder.decoder.4.bias: 0.0005076475790701807\n",
      "Gradient for decoder.decoder.6.weight: 0.0005150358192622662\n",
      "Gradient for decoder.decoder.6.bias: 2.9657767299795523e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.020937012508511543\n",
      "Gradient for encoder.encoder.0.bias: 3.014644436860614e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.003134286729618907\n",
      "Gradient for encoder.encoder.1.bias: 0.002346675144508481\n",
      "Gradient for encoder.encoder.3.weight: 0.06867903470993042\n",
      "Gradient for encoder.encoder.3.bias: 3.5001848641691424e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.006841214839369059\n",
      "Gradient for encoder.encoder.4.bias: 0.006774229928851128\n",
      "Gradient for encoder.mean.weight: 0.09013323485851288\n",
      "Gradient for encoder.mean.bias: 0.00489454111084342\n",
      "Gradient for encoder.log_var.weight: 0.04691450670361519\n",
      "Gradient for encoder.log_var.bias: 0.0027334094047546387\n",
      "Gradient for decoder.decoder.0.weight: 0.017367077991366386\n",
      "Gradient for decoder.decoder.0.bias: 1.5448346768476284e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0008947924943640828\n",
      "Gradient for decoder.decoder.1.bias: 0.0006494809058494866\n",
      "Gradient for decoder.decoder.3.weight: 0.015171345323324203\n",
      "Gradient for decoder.decoder.3.bias: 1.1810546984847292e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0005186123307794333\n",
      "Gradient for decoder.decoder.4.bias: 0.00046845327597111464\n",
      "Gradient for decoder.decoder.6.weight: 0.0006016279803588986\n",
      "Gradient for decoder.decoder.6.bias: 2.9541452022385783e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.039912495762109756\n",
      "Gradient for encoder.encoder.0.bias: 7.343175373319966e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.003893917892128229\n",
      "Gradient for encoder.encoder.1.bias: 0.0028099126648157835\n",
      "Gradient for encoder.encoder.3.weight: 0.07378224283456802\n",
      "Gradient for encoder.encoder.3.bias: 5.589742002598541e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.013221027329564095\n",
      "Gradient for encoder.encoder.4.bias: 0.0125734843313694\n",
      "Gradient for encoder.mean.weight: 0.16498127579689026\n",
      "Gradient for encoder.mean.bias: 0.007452459540218115\n",
      "Gradient for encoder.log_var.weight: 0.10446774214506149\n",
      "Gradient for encoder.log_var.bias: 0.004800771363079548\n",
      "Gradient for decoder.decoder.0.weight: 0.01836474798619747\n",
      "Gradient for decoder.decoder.0.bias: 1.5168168110424318e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0009588149259798229\n",
      "Gradient for decoder.decoder.1.bias: 0.0006992520065978169\n",
      "Gradient for decoder.decoder.3.weight: 0.016530590131878853\n",
      "Gradient for decoder.decoder.3.bias: 1.3857767711122904e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0007956193876452744\n",
      "Gradient for decoder.decoder.4.bias: 0.000801467802375555\n",
      "Gradient for decoder.decoder.6.weight: 0.0006907145725563169\n",
      "Gradient for decoder.decoder.6.bias: 4.516233821050264e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.026571357622742653\n",
      "Gradient for encoder.encoder.0.bias: 4.101209302720399e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0032065119594335556\n",
      "Gradient for encoder.encoder.1.bias: 0.002291089855134487\n",
      "Gradient for encoder.encoder.3.weight: 0.07132087647914886\n",
      "Gradient for encoder.encoder.3.bias: 4.149050547574973e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.009898049756884575\n",
      "Gradient for encoder.encoder.4.bias: 0.0077583822421729565\n",
      "Gradient for encoder.mean.weight: 0.12221512943506241\n",
      "Gradient for encoder.mean.bias: 0.005129228811711073\n",
      "Gradient for encoder.log_var.weight: 0.06887894868850708\n",
      "Gradient for encoder.log_var.bias: 0.003137991763651371\n",
      "Gradient for decoder.decoder.0.weight: 0.014263711869716644\n",
      "Gradient for decoder.decoder.0.bias: 1.2059322984647736e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0007553754840046167\n",
      "Gradient for decoder.decoder.1.bias: 0.0005576645489782095\n",
      "Gradient for decoder.decoder.3.weight: 0.012952914461493492\n",
      "Gradient for decoder.decoder.3.bias: 9.556499341867308e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0004490858409553766\n",
      "Gradient for decoder.decoder.4.bias: 0.000404757127398625\n",
      "Gradient for decoder.decoder.6.weight: 0.0005733935395255685\n",
      "Gradient for decoder.decoder.6.bias: 2.543683694966603e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.019714877009391785\n",
      "Gradient for encoder.encoder.0.bias: 3.2632195556825394e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.003004019847139716\n",
      "Gradient for encoder.encoder.1.bias: 0.0021445811726152897\n",
      "Gradient for encoder.encoder.3.weight: 0.06362668424844742\n",
      "Gradient for encoder.encoder.3.bias: 3.659723357696265e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.007490491960197687\n",
      "Gradient for encoder.encoder.4.bias: 0.006766977719962597\n",
      "Gradient for encoder.mean.weight: 0.09448596835136414\n",
      "Gradient for encoder.mean.bias: 0.004549251403659582\n",
      "Gradient for encoder.log_var.weight: 0.0600772388279438\n",
      "Gradient for encoder.log_var.bias: 0.002983626676723361\n",
      "Gradient for decoder.decoder.0.weight: 0.017420019954442978\n",
      "Gradient for decoder.decoder.0.bias: 1.4578979690149652e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0009099112940020859\n",
      "Gradient for decoder.decoder.1.bias: 0.0006554590072482824\n",
      "Gradient for decoder.decoder.3.weight: 0.015796450898051262\n",
      "Gradient for decoder.decoder.3.bias: 1.365658558460936e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.000787899480201304\n",
      "Gradient for decoder.decoder.4.bias: 0.0008632821845822036\n",
      "Gradient for decoder.decoder.6.weight: 0.0006875971448607743\n",
      "Gradient for decoder.decoder.6.bias: 4.505027027335018e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training VAE Epoch:  20%|██        | 16/79 [00:00<00:01, 50.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient for encoder.encoder.0.weight: 0.021657021716237068\n",
      "Gradient for encoder.encoder.0.bias: 3.6091372945801226e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.00423052255064249\n",
      "Gradient for encoder.encoder.1.bias: 0.0028491299599409103\n",
      "Gradient for encoder.encoder.3.weight: 0.08066336810588837\n",
      "Gradient for encoder.encoder.3.bias: 3.9886746683315266e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.01065154280513525\n",
      "Gradient for encoder.encoder.4.bias: 0.009138834662735462\n",
      "Gradient for encoder.mean.weight: 0.14295606315135956\n",
      "Gradient for encoder.mean.bias: 0.005321774631738663\n",
      "Gradient for encoder.log_var.weight: 0.08181075751781464\n",
      "Gradient for encoder.log_var.bias: 0.003992695827037096\n",
      "Gradient for decoder.decoder.0.weight: 0.01622183248400688\n",
      "Gradient for decoder.decoder.0.bias: 1.2729352294460483e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0008303355425596237\n",
      "Gradient for decoder.decoder.1.bias: 0.0006367006571963429\n",
      "Gradient for decoder.decoder.3.weight: 0.015048942528665066\n",
      "Gradient for decoder.decoder.3.bias: 1.0517992726777337e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0005556577234528959\n",
      "Gradient for decoder.decoder.4.bias: 0.0005375317996367812\n",
      "Gradient for decoder.decoder.6.weight: 0.0006540700560435653\n",
      "Gradient for decoder.decoder.6.bias: 4.338424696470611e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.021375015377998352\n",
      "Gradient for encoder.encoder.0.bias: 3.472653761771305e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.002231708960607648\n",
      "Gradient for encoder.encoder.1.bias: 0.0018181460909545422\n",
      "Gradient for encoder.encoder.3.weight: 0.046042751520872116\n",
      "Gradient for encoder.encoder.3.bias: 3.146970739553723e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.005038158036768436\n",
      "Gradient for encoder.encoder.4.bias: 0.004956813529133797\n",
      "Gradient for encoder.mean.weight: 0.07109366357326508\n",
      "Gradient for encoder.mean.bias: 0.004092669580131769\n",
      "Gradient for encoder.log_var.weight: 0.03654123842716217\n",
      "Gradient for encoder.log_var.bias: 0.002223439747467637\n",
      "Gradient for decoder.decoder.0.weight: 0.01332254521548748\n",
      "Gradient for decoder.decoder.0.bias: 1.074435679315755e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0007081471267156303\n",
      "Gradient for decoder.decoder.1.bias: 0.0005250577814877033\n",
      "Gradient for decoder.decoder.3.weight: 0.012016954831779003\n",
      "Gradient for decoder.decoder.3.bias: 9.587144272904524e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0005675619468092918\n",
      "Gradient for decoder.decoder.4.bias: 0.0006402577855624259\n",
      "Gradient for decoder.decoder.6.weight: 0.0005590569344349205\n",
      "Gradient for decoder.decoder.6.bias: 3.579517579055391e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.025597166270017624\n",
      "Gradient for encoder.encoder.0.bias: 4.350840174249804e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.003786833258345723\n",
      "Gradient for encoder.encoder.1.bias: 0.002591807162389159\n",
      "Gradient for encoder.encoder.3.weight: 0.07905915379524231\n",
      "Gradient for encoder.encoder.3.bias: 4.520479268688149e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.012322913855314255\n",
      "Gradient for encoder.encoder.4.bias: 0.010471543297171593\n",
      "Gradient for encoder.mean.weight: 0.15804409980773926\n",
      "Gradient for encoder.mean.bias: 0.007456991821527481\n",
      "Gradient for encoder.log_var.weight: 0.09597788751125336\n",
      "Gradient for encoder.log_var.bias: 0.004400619305670261\n",
      "Gradient for decoder.decoder.0.weight: 0.014068281278014183\n",
      "Gradient for decoder.decoder.0.bias: 1.146926650874569e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0006978500168770552\n",
      "Gradient for decoder.decoder.1.bias: 0.000521116133313626\n",
      "Gradient for decoder.decoder.3.weight: 0.012549089267849922\n",
      "Gradient for decoder.decoder.3.bias: 8.821175734308184e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00044567955774255097\n",
      "Gradient for decoder.decoder.4.bias: 0.0003990225668530911\n",
      "Gradient for decoder.decoder.6.weight: 0.0005721145425923169\n",
      "Gradient for decoder.decoder.6.bias: 3.254934199503623e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training VAE Epoch:  30%|███       | 24/79 [00:00<00:00, 60.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient for encoder.encoder.0.weight: 0.026029132306575775\n",
      "Gradient for encoder.encoder.0.bias: 5.196296865017658e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.00431530037894845\n",
      "Gradient for encoder.encoder.1.bias: 0.0026975979562848806\n",
      "Gradient for encoder.encoder.3.weight: 0.08364441245794296\n",
      "Gradient for encoder.encoder.3.bias: 4.798384467541439e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.013243907131254673\n",
      "Gradient for encoder.encoder.4.bias: 0.010952530428767204\n",
      "Gradient for encoder.mean.weight: 0.16940654814243317\n",
      "Gradient for encoder.mean.bias: 0.007381584960967302\n",
      "Gradient for encoder.log_var.weight: 0.10429035872220993\n",
      "Gradient for encoder.log_var.bias: 0.00438670301809907\n",
      "Gradient for decoder.decoder.0.weight: 0.010995923541486263\n",
      "Gradient for decoder.decoder.0.bias: 9.181852500539378e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005904597928747535\n",
      "Gradient for decoder.decoder.1.bias: 0.0004308113129809499\n",
      "Gradient for decoder.decoder.3.weight: 0.010062097571790218\n",
      "Gradient for decoder.decoder.3.bias: 1.2329566534408087e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0008583868038840592\n",
      "Gradient for decoder.decoder.4.bias: 0.0010579136433079839\n",
      "Gradient for decoder.decoder.6.weight: 0.0007025717641226947\n",
      "Gradient for decoder.decoder.6.bias: 6.063773616915569e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.01763848029077053\n",
      "Gradient for encoder.encoder.0.bias: 3.153380681575335e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.00241199042648077\n",
      "Gradient for encoder.encoder.1.bias: 0.0017519028624519706\n",
      "Gradient for encoder.encoder.3.weight: 0.0504562072455883\n",
      "Gradient for encoder.encoder.3.bias: 3.313205820809628e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.00654004467651248\n",
      "Gradient for encoder.encoder.4.bias: 0.005768610164523125\n",
      "Gradient for encoder.mean.weight: 0.08282948285341263\n",
      "Gradient for encoder.mean.bias: 0.004433908499777317\n",
      "Gradient for encoder.log_var.weight: 0.04784419387578964\n",
      "Gradient for encoder.log_var.bias: 0.0028843560721725225\n",
      "Gradient for decoder.decoder.0.weight: 0.01697923056781292\n",
      "Gradient for decoder.decoder.0.bias: 1.520599618443086e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0008880470995791256\n",
      "Gradient for decoder.decoder.1.bias: 0.0006973285926505923\n",
      "Gradient for decoder.decoder.3.weight: 0.015517165884375572\n",
      "Gradient for decoder.decoder.3.bias: 1.238070063136476e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0006245723343454301\n",
      "Gradient for decoder.decoder.4.bias: 0.0006528939702548087\n",
      "Gradient for decoder.decoder.6.weight: 0.0006519962917082012\n",
      "Gradient for decoder.decoder.6.bias: 4.094228279427625e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.015751194208860397\n",
      "Gradient for encoder.encoder.0.bias: 2.6499673982938177e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0020573348738253117\n",
      "Gradient for encoder.encoder.1.bias: 0.0015280513325706124\n",
      "Gradient for encoder.encoder.3.weight: 0.043254319578409195\n",
      "Gradient for encoder.encoder.3.bias: 3.033410189701158e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.006059050559997559\n",
      "Gradient for encoder.encoder.4.bias: 0.005688412114977837\n",
      "Gradient for encoder.mean.weight: 0.08073113858699799\n",
      "Gradient for encoder.mean.bias: 0.004560026805847883\n",
      "Gradient for encoder.log_var.weight: 0.04069395735859871\n",
      "Gradient for encoder.log_var.bias: 0.0023874063044786453\n",
      "Gradient for decoder.decoder.0.weight: 0.018401682376861572\n",
      "Gradient for decoder.decoder.0.bias: 1.5078870096996155e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0009638586197979748\n",
      "Gradient for decoder.decoder.1.bias: 0.0007154472405090928\n",
      "Gradient for decoder.decoder.3.weight: 0.016953416168689728\n",
      "Gradient for decoder.decoder.3.bias: 1.5142591347494516e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0009421986760571599\n",
      "Gradient for decoder.decoder.4.bias: 0.001005249097943306\n",
      "Gradient for decoder.decoder.6.weight: 0.0007579335942864418\n",
      "Gradient for decoder.decoder.6.bias: 5.1638406148413196e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.027782898396253586\n",
      "Gradient for encoder.encoder.0.bias: 3.7284054316133464e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.003613274311646819\n",
      "Gradient for encoder.encoder.1.bias: 0.00267701200209558\n",
      "Gradient for encoder.encoder.3.weight: 0.07874187082052231\n",
      "Gradient for encoder.encoder.3.bias: 4.907128592357424e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.014488758519291878\n",
      "Gradient for encoder.encoder.4.bias: 0.009308465756475925\n",
      "Gradient for encoder.mean.weight: 0.18451173603534698\n",
      "Gradient for encoder.mean.bias: 0.0049685221165418625\n",
      "Gradient for encoder.log_var.weight: 0.10397414863109589\n",
      "Gradient for encoder.log_var.bias: 0.002720687072724104\n",
      "Gradient for decoder.decoder.0.weight: 0.02126086689531803\n",
      "Gradient for decoder.decoder.0.bias: 1.6173401506947016e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0011485428549349308\n",
      "Gradient for decoder.decoder.1.bias: 0.0007947156555019319\n",
      "Gradient for decoder.decoder.3.weight: 0.01892939954996109\n",
      "Gradient for decoder.decoder.3.bias: 1.2903630941529798e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0006582593778148293\n",
      "Gradient for decoder.decoder.4.bias: 0.0005879700183868408\n",
      "Gradient for decoder.decoder.6.weight: 0.0006384728476405144\n",
      "Gradient for decoder.decoder.6.bias: 3.2807507523102686e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.020783627405762672\n",
      "Gradient for encoder.encoder.0.bias: 3.550435639931848e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0027476476971060038\n",
      "Gradient for encoder.encoder.1.bias: 0.0018725284608080983\n",
      "Gradient for encoder.encoder.3.weight: 0.054878897964954376\n",
      "Gradient for encoder.encoder.3.bias: 3.456093466969179e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.005818289238959551\n",
      "Gradient for encoder.encoder.4.bias: 0.006373018957674503\n",
      "Gradient for encoder.mean.weight: 0.08056699484586716\n",
      "Gradient for encoder.mean.bias: 0.0048642950132489204\n",
      "Gradient for encoder.log_var.weight: 0.05137970298528671\n",
      "Gradient for encoder.log_var.bias: 0.0033864984288811684\n",
      "Gradient for decoder.decoder.0.weight: 0.014437026344239712\n",
      "Gradient for decoder.decoder.0.bias: 1.2951401062721857e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0007000599871389568\n",
      "Gradient for decoder.decoder.1.bias: 0.0005460167885757983\n",
      "Gradient for decoder.decoder.3.weight: 0.012932579964399338\n",
      "Gradient for decoder.decoder.3.bias: 1.1459864307505896e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.00046381595893763006\n",
      "Gradient for decoder.decoder.4.bias: 0.00040123009239323437\n",
      "Gradient for decoder.decoder.6.weight: 0.0006315158680081367\n",
      "Gradient for decoder.decoder.6.bias: 3.962509072152898e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.02770143933594227\n",
      "Gradient for encoder.encoder.0.bias: 4.0175612836534924e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.003948709927499294\n",
      "Gradient for encoder.encoder.1.bias: 0.0026645732577890158\n",
      "Gradient for encoder.encoder.3.weight: 0.08461906760931015\n",
      "Gradient for encoder.encoder.3.bias: 3.9502653925715947e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.008436424657702446\n",
      "Gradient for encoder.encoder.4.bias: 0.0080504659563303\n",
      "Gradient for encoder.mean.weight: 0.11006108671426773\n",
      "Gradient for encoder.mean.bias: 0.005421745125204325\n",
      "Gradient for encoder.log_var.weight: 0.06351422518491745\n",
      "Gradient for encoder.log_var.bias: 0.002892295829951763\n",
      "Gradient for decoder.decoder.0.weight: 0.014496303163468838\n",
      "Gradient for decoder.decoder.0.bias: 1.1855504078450707e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0007394959684461355\n",
      "Gradient for decoder.decoder.1.bias: 0.0005149889620952308\n",
      "Gradient for decoder.decoder.3.weight: 0.012982385233044624\n",
      "Gradient for decoder.decoder.3.bias: 1.0592319382718429e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0005687592783942819\n",
      "Gradient for decoder.decoder.4.bias: 0.0006181927165016532\n",
      "Gradient for decoder.decoder.6.weight: 0.000598232087213546\n",
      "Gradient for decoder.decoder.6.bias: 3.60502272087615e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.024725455790758133\n",
      "Gradient for encoder.encoder.0.bias: 5.360934959841579e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0031205895356833935\n",
      "Gradient for encoder.encoder.1.bias: 0.0025616763159632683\n",
      "Gradient for encoder.encoder.3.weight: 0.0621318556368351\n",
      "Gradient for encoder.encoder.3.bias: 4.36387370683633e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.008158720098435879\n",
      "Gradient for encoder.encoder.4.bias: 0.00900883786380291\n",
      "Gradient for encoder.mean.weight: 0.10368870198726654\n",
      "Gradient for encoder.mean.bias: 0.00672120600938797\n",
      "Gradient for encoder.log_var.weight: 0.06470717489719391\n",
      "Gradient for encoder.log_var.bias: 0.004392998293042183\n",
      "Gradient for decoder.decoder.0.weight: 0.011482386849820614\n",
      "Gradient for decoder.decoder.0.bias: 9.455006916292419e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0006355534424073994\n",
      "Gradient for decoder.decoder.1.bias: 0.00047835861914791167\n",
      "Gradient for decoder.decoder.3.weight: 0.010188454762101173\n",
      "Gradient for decoder.decoder.3.bias: 1.0629859492627958e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0007156682549975812\n",
      "Gradient for decoder.decoder.4.bias: 0.0008543701260350645\n",
      "Gradient for decoder.decoder.6.weight: 0.0006720133824273944\n",
      "Gradient for decoder.decoder.6.bias: 5.534388401429169e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.02114737220108509\n",
      "Gradient for encoder.encoder.0.bias: 3.223183872580471e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.002443477278575301\n",
      "Gradient for encoder.encoder.1.bias: 0.0020041363313794136\n",
      "Gradient for encoder.encoder.3.weight: 0.05591597780585289\n",
      "Gradient for encoder.encoder.3.bias: 4.5329826003914775e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.013311948627233505\n",
      "Gradient for encoder.encoder.4.bias: 0.01023662555962801\n",
      "Gradient for encoder.mean.weight: 0.1695464700460434\n",
      "Gradient for encoder.mean.bias: 0.006582909729331732\n",
      "Gradient for encoder.log_var.weight: 0.09637715667486191\n",
      "Gradient for encoder.log_var.bias: 0.0036237139720469713\n",
      "Gradient for decoder.decoder.0.weight: 0.016770504415035248\n",
      "Gradient for decoder.decoder.0.bias: 1.429861368196228e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0009032042580656707\n",
      "Gradient for decoder.decoder.1.bias: 0.000640787766315043\n",
      "Gradient for decoder.decoder.3.weight: 0.01456278096884489\n",
      "Gradient for decoder.decoder.3.bias: 1.0363127717072373e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0005211828975006938\n",
      "Gradient for decoder.decoder.4.bias: 0.0004390282847452909\n",
      "Gradient for decoder.decoder.6.weight: 0.0005784735549241304\n",
      "Gradient for decoder.decoder.6.bias: 3.0302888262667693e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.026448065415024757\n",
      "Gradient for encoder.encoder.0.bias: 3.373618745472484e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0027206502854824066\n",
      "Gradient for encoder.encoder.1.bias: 0.0021335931960493326\n",
      "Gradient for encoder.encoder.3.weight: 0.05680694058537483\n",
      "Gradient for encoder.encoder.3.bias: 5.29128074688856e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.014361036941409111\n",
      "Gradient for encoder.encoder.4.bias: 0.010661229491233826\n",
      "Gradient for encoder.mean.weight: 0.18127955496311188\n",
      "Gradient for encoder.mean.bias: 0.007075055502355099\n",
      "Gradient for encoder.log_var.weight: 0.10729168355464935\n",
      "Gradient for encoder.log_var.bias: 0.004322851076722145\n",
      "Gradient for decoder.decoder.0.weight: 0.019502917304635048\n",
      "Gradient for decoder.decoder.0.bias: 1.637415758537486e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0010353628313168883\n",
      "Gradient for decoder.decoder.1.bias: 0.0007117684581317008\n",
      "Gradient for decoder.decoder.3.weight: 0.017573468387126923\n",
      "Gradient for decoder.decoder.3.bias: 1.368494900733097e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0006967487279325724\n",
      "Gradient for decoder.decoder.4.bias: 0.0006575545412488282\n",
      "Gradient for decoder.decoder.6.weight: 0.0006337393424473703\n",
      "Gradient for decoder.decoder.6.bias: 3.346289668115787e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.018876532092690468\n",
      "Gradient for encoder.encoder.0.bias: 2.249850826474553e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.002116616116836667\n",
      "Gradient for encoder.encoder.1.bias: 0.0018137423321604729\n",
      "Gradient for encoder.encoder.3.weight: 0.04622437432408333\n",
      "Gradient for encoder.encoder.3.bias: 3.292578154567849e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.006813878193497658\n",
      "Gradient for encoder.encoder.4.bias: 0.006592638790607452\n",
      "Gradient for encoder.mean.weight: 0.09128856658935547\n",
      "Gradient for encoder.mean.bias: 0.004628324881196022\n",
      "Gradient for encoder.log_var.weight: 0.057170893996953964\n",
      "Gradient for encoder.log_var.bias: 0.0027194670401513577\n",
      "Gradient for decoder.decoder.0.weight: 0.020673202350735664\n",
      "Gradient for decoder.decoder.0.bias: 1.7036089206001748e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0011594361858442426\n",
      "Gradient for decoder.decoder.1.bias: 0.0007973956526257098\n",
      "Gradient for decoder.decoder.3.weight: 0.019184108823537827\n",
      "Gradient for decoder.decoder.3.bias: 1.3929199460527286e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0008790353895165026\n",
      "Gradient for decoder.decoder.4.bias: 0.0008752886787988245\n",
      "Gradient for decoder.decoder.6.weight: 0.0007448164978995919\n",
      "Gradient for decoder.decoder.6.bias: 4.220439222990535e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.016405966132879257\n",
      "Gradient for encoder.encoder.0.bias: 2.952059430239018e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.002693102927878499\n",
      "Gradient for encoder.encoder.1.bias: 0.002071796916425228\n",
      "Gradient for encoder.encoder.3.weight: 0.05532942712306976\n",
      "Gradient for encoder.encoder.3.bias: 3.0994701250008916e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.006924147251993418\n",
      "Gradient for encoder.encoder.4.bias: 0.006602222565561533\n",
      "Gradient for encoder.mean.weight: 0.09108716249465942\n",
      "Gradient for encoder.mean.bias: 0.004596344195306301\n",
      "Gradient for encoder.log_var.weight: 0.053839247673749924\n",
      "Gradient for encoder.log_var.bias: 0.002466150326654315\n",
      "Gradient for decoder.decoder.0.weight: 0.016173334792256355\n",
      "Gradient for decoder.decoder.0.bias: 1.2883820399434143e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0008500540279783309\n",
      "Gradient for decoder.decoder.1.bias: 0.0006146956002339721\n",
      "Gradient for decoder.decoder.3.weight: 0.013872827403247356\n",
      "Gradient for decoder.decoder.3.bias: 1.0479145329256312e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0005228574736975133\n",
      "Gradient for decoder.decoder.4.bias: 0.0005117707187309861\n",
      "Gradient for decoder.decoder.6.weight: 0.0005754518206231296\n",
      "Gradient for decoder.decoder.6.bias: 2.8053700589225627e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.022577809169888496\n",
      "Gradient for encoder.encoder.0.bias: 3.3835410168103763e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.001966626849025488\n",
      "Gradient for encoder.encoder.1.bias: 0.0016487124375998974\n",
      "Gradient for encoder.encoder.3.weight: 0.04265366494655609\n",
      "Gradient for encoder.encoder.3.bias: 4.0713787896606846e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.007016003131866455\n",
      "Gradient for encoder.encoder.4.bias: 0.008124842308461666\n",
      "Gradient for encoder.mean.weight: 0.09309177845716476\n",
      "Gradient for encoder.mean.bias: 0.006777490954846144\n",
      "Gradient for encoder.log_var.weight: 0.05738353729248047\n",
      "Gradient for encoder.log_var.bias: 0.004164916463196278\n",
      "Gradient for decoder.decoder.0.weight: 0.016436928883194923\n",
      "Gradient for decoder.decoder.0.bias: 1.4200887687998431e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0008176404517143965\n",
      "Gradient for decoder.decoder.1.bias: 0.000587114249356091\n",
      "Gradient for decoder.decoder.3.weight: 0.014581931754946709\n",
      "Gradient for decoder.decoder.3.bias: 1.4661917513425493e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0007067265105433762\n",
      "Gradient for decoder.decoder.4.bias: 0.0007113434839993715\n",
      "Gradient for decoder.decoder.6.weight: 0.000709187937900424\n",
      "Gradient for decoder.decoder.6.bias: 4.667745088227093e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.017005037516355515\n",
      "Gradient for encoder.encoder.0.bias: 2.608174613782932e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0022974545136094093\n",
      "Gradient for encoder.encoder.1.bias: 0.0016814878908917308\n",
      "Gradient for encoder.encoder.3.weight: 0.043807365000247955\n",
      "Gradient for encoder.encoder.3.bias: 3.124264180698333e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.005323213059455156\n",
      "Gradient for encoder.encoder.4.bias: 0.005453974474221468\n",
      "Gradient for encoder.mean.weight: 0.07438149303197861\n",
      "Gradient for encoder.mean.bias: 0.004079901613295078\n",
      "Gradient for encoder.log_var.weight: 0.04776284843683243\n",
      "Gradient for encoder.log_var.bias: 0.0022816723212599754\n",
      "Gradient for decoder.decoder.0.weight: 0.01658216305077076\n",
      "Gradient for decoder.decoder.0.bias: 1.4579107365797483e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0008207398350350559\n",
      "Gradient for decoder.decoder.1.bias: 0.000661246944218874\n",
      "Gradient for decoder.decoder.3.weight: 0.013997209258377552\n",
      "Gradient for decoder.decoder.3.bias: 1.134997859586484e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0005762881482951343\n",
      "Gradient for decoder.decoder.4.bias: 0.0005467681912705302\n",
      "Gradient for decoder.decoder.6.weight: 0.0005800341023132205\n",
      "Gradient for decoder.decoder.6.bias: 3.153051147819497e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training VAE Epoch:  41%|████      | 32/79 [00:00<00:00, 66.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient for encoder.encoder.0.weight: 0.014419140294194221\n",
      "Gradient for encoder.encoder.0.bias: 2.258886307171526e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0027676764875650406\n",
      "Gradient for encoder.encoder.1.bias: 0.001930930302478373\n",
      "Gradient for encoder.encoder.3.weight: 0.05758132413029671\n",
      "Gradient for encoder.encoder.3.bias: 3.466807396712568e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.011074879206717014\n",
      "Gradient for encoder.encoder.4.bias: 0.008362023159861565\n",
      "Gradient for encoder.mean.weight: 0.1454172432422638\n",
      "Gradient for encoder.mean.bias: 0.005195306614041328\n",
      "Gradient for encoder.log_var.weight: 0.07642153650522232\n",
      "Gradient for encoder.log_var.bias: 0.0029395348392426968\n",
      "Gradient for decoder.decoder.0.weight: 0.017601704224944115\n",
      "Gradient for decoder.decoder.0.bias: 1.576539315761849e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0008906535222195089\n",
      "Gradient for decoder.decoder.1.bias: 0.0006821047863923013\n",
      "Gradient for decoder.decoder.3.weight: 0.015615287236869335\n",
      "Gradient for decoder.decoder.3.bias: 1.4292980687891088e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.000886536028701812\n",
      "Gradient for decoder.decoder.4.bias: 0.0009300708770751953\n",
      "Gradient for decoder.decoder.6.weight: 0.000850188487675041\n",
      "Gradient for decoder.decoder.6.bias: 6.445345206884667e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.02735559456050396\n",
      "Gradient for encoder.encoder.0.bias: 3.440337945082028e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0035256065893918276\n",
      "Gradient for encoder.encoder.1.bias: 0.002412289148196578\n",
      "Gradient for encoder.encoder.3.weight: 0.069975845515728\n",
      "Gradient for encoder.encoder.3.bias: 3.822415994836348e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0076027484610676765\n",
      "Gradient for encoder.encoder.4.bias: 0.006656513083726168\n",
      "Gradient for encoder.mean.weight: 0.10166371613740921\n",
      "Gradient for encoder.mean.bias: 0.005087652243673801\n",
      "Gradient for encoder.log_var.weight: 0.05672471225261688\n",
      "Gradient for encoder.log_var.bias: 0.002911609597504139\n",
      "Gradient for decoder.decoder.0.weight: 0.01805245876312256\n",
      "Gradient for decoder.decoder.0.bias: 1.4442561035998835e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0009487024508416653\n",
      "Gradient for decoder.decoder.1.bias: 0.0006614992744289339\n",
      "Gradient for decoder.decoder.3.weight: 0.01637076772749424\n",
      "Gradient for decoder.decoder.3.bias: 1.3372825069524197e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0006284930277615786\n",
      "Gradient for decoder.decoder.4.bias: 0.0005768432165496051\n",
      "Gradient for decoder.decoder.6.weight: 0.0006141329649835825\n",
      "Gradient for decoder.decoder.6.bias: 2.950663292722311e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.019709112122654915\n",
      "Gradient for encoder.encoder.0.bias: 3.2777575792453106e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0024159522727131844\n",
      "Gradient for encoder.encoder.1.bias: 0.001933518098667264\n",
      "Gradient for encoder.encoder.3.weight: 0.04858361929655075\n",
      "Gradient for encoder.encoder.3.bias: 3.5729513792048806e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.006976257544010878\n",
      "Gradient for encoder.encoder.4.bias: 0.007625423837453127\n",
      "Gradient for encoder.mean.weight: 0.088251031935215\n",
      "Gradient for encoder.mean.bias: 0.005345674231648445\n",
      "Gradient for encoder.log_var.weight: 0.056351643055677414\n",
      "Gradient for encoder.log_var.bias: 0.003850583452731371\n",
      "Gradient for decoder.decoder.0.weight: 0.014149369671940804\n",
      "Gradient for decoder.decoder.0.bias: 1.173238312057734e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0007443146896548569\n",
      "Gradient for decoder.decoder.1.bias: 0.0005773534066975117\n",
      "Gradient for decoder.decoder.3.weight: 0.013335577212274075\n",
      "Gradient for decoder.decoder.3.bias: 1.019542159030884e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0005879828240722418\n",
      "Gradient for decoder.decoder.4.bias: 0.0006261178059503436\n",
      "Gradient for decoder.decoder.6.weight: 0.000601551029831171\n",
      "Gradient for decoder.decoder.6.bias: 3.919596565538086e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training VAE Epoch:  51%|█████     | 40/79 [00:00<00:00, 70.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient for encoder.encoder.0.weight: 0.028431223705410957\n",
      "Gradient for encoder.encoder.0.bias: 3.4121490355421e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.00271073286421597\n",
      "Gradient for encoder.encoder.1.bias: 0.0023849867284297943\n",
      "Gradient for encoder.encoder.3.weight: 0.06096896901726723\n",
      "Gradient for encoder.encoder.3.bias: 4.270857278942941e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.010010913945734501\n",
      "Gradient for encoder.encoder.4.bias: 0.007227069232612848\n",
      "Gradient for encoder.mean.weight: 0.13523349165916443\n",
      "Gradient for encoder.mean.bias: 0.005439374130219221\n",
      "Gradient for encoder.log_var.weight: 0.07513383775949478\n",
      "Gradient for encoder.log_var.bias: 0.003229080466553569\n",
      "Gradient for decoder.decoder.0.weight: 0.017878305166959763\n",
      "Gradient for decoder.decoder.0.bias: 1.5091365657138311e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0009603088838048279\n",
      "Gradient for decoder.decoder.1.bias: 0.000725373683962971\n",
      "Gradient for decoder.decoder.3.weight: 0.016337329521775246\n",
      "Gradient for decoder.decoder.3.bias: 1.186742509817762e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0006316720973700285\n",
      "Gradient for decoder.decoder.4.bias: 0.0006033401004970074\n",
      "Gradient for decoder.decoder.6.weight: 0.0006734085618518293\n",
      "Gradient for decoder.decoder.6.bias: 4.056029865751043e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.021920625120401382\n",
      "Gradient for encoder.encoder.0.bias: 3.836115106126137e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0026651532389223576\n",
      "Gradient for encoder.encoder.1.bias: 0.00183707638643682\n",
      "Gradient for encoder.encoder.3.weight: 0.054459549486637115\n",
      "Gradient for encoder.encoder.3.bias: 3.6205879960782283e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.008747398853302002\n",
      "Gradient for encoder.encoder.4.bias: 0.006830182857811451\n",
      "Gradient for encoder.mean.weight: 0.12022244185209274\n",
      "Gradient for encoder.mean.bias: 0.004741382319480181\n",
      "Gradient for encoder.log_var.weight: 0.06990084797143936\n",
      "Gradient for encoder.log_var.bias: 0.002955583855509758\n",
      "Gradient for decoder.decoder.0.weight: 0.013646137900650501\n",
      "Gradient for decoder.decoder.0.bias: 1.1687184553466068e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0006919924053363502\n",
      "Gradient for decoder.decoder.1.bias: 0.000530652585439384\n",
      "Gradient for decoder.decoder.3.weight: 0.012460831552743912\n",
      "Gradient for decoder.decoder.3.bias: 1.0365534125478248e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0006978238234296441\n",
      "Gradient for decoder.decoder.4.bias: 0.0008261591428890824\n",
      "Gradient for decoder.decoder.6.weight: 0.0006579859764315188\n",
      "Gradient for decoder.decoder.6.bias: 5.31945624970831e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.028046071529388428\n",
      "Gradient for encoder.encoder.0.bias: 4.046257426337796e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0037476499564945698\n",
      "Gradient for encoder.encoder.1.bias: 0.002756404457613826\n",
      "Gradient for encoder.encoder.3.weight: 0.08238257467746735\n",
      "Gradient for encoder.encoder.3.bias: 4.888545124259736e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.008282016031444073\n",
      "Gradient for encoder.encoder.4.bias: 0.008884306065738201\n",
      "Gradient for encoder.mean.weight: 0.10925676673650742\n",
      "Gradient for encoder.mean.bias: 0.006018780637532473\n",
      "Gradient for encoder.log_var.weight: 0.0707724392414093\n",
      "Gradient for encoder.log_var.bias: 0.00481129065155983\n",
      "Gradient for decoder.decoder.0.weight: 0.01958652399480343\n",
      "Gradient for decoder.decoder.0.bias: 1.5148787779750705e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0010644701542332768\n",
      "Gradient for decoder.decoder.1.bias: 0.0007434820872731507\n",
      "Gradient for decoder.decoder.3.weight: 0.018168434500694275\n",
      "Gradient for decoder.decoder.3.bias: 1.482414052622616e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0010239256080240011\n",
      "Gradient for decoder.decoder.4.bias: 0.001115333870984614\n",
      "Gradient for decoder.decoder.6.weight: 0.0008511145133525133\n",
      "Gradient for decoder.decoder.6.bias: 6.542945629917085e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.03727079555392265\n",
      "Gradient for encoder.encoder.0.bias: 6.735167978888512e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.006381119601428509\n",
      "Gradient for encoder.encoder.1.bias: 0.0046180253848433495\n",
      "Gradient for encoder.encoder.3.weight: 0.14264436066150665\n",
      "Gradient for encoder.encoder.3.bias: 4.3130357618714754e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.009370564483106136\n",
      "Gradient for encoder.encoder.4.bias: 0.007057972718030214\n",
      "Gradient for encoder.mean.weight: 0.12939631938934326\n",
      "Gradient for encoder.mean.bias: 0.0033871824853122234\n",
      "Gradient for encoder.log_var.weight: 0.06767284125089645\n",
      "Gradient for encoder.log_var.bias: 0.0025643056724220514\n",
      "Gradient for decoder.decoder.0.weight: 0.013816452585160732\n",
      "Gradient for decoder.decoder.0.bias: 1.1530205262788584e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0006899147410877049\n",
      "Gradient for decoder.decoder.1.bias: 0.0005165363545529544\n",
      "Gradient for decoder.decoder.3.weight: 0.01283967588096857\n",
      "Gradient for decoder.decoder.3.bias: 1.0895524066301121e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.000557881488930434\n",
      "Gradient for decoder.decoder.4.bias: 0.0005605397163890302\n",
      "Gradient for decoder.decoder.6.weight: 0.0005979238776490092\n",
      "Gradient for decoder.decoder.6.bias: 3.89491870009806e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.024798471480607986\n",
      "Gradient for encoder.encoder.0.bias: 4.196942446355045e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.004299887455999851\n",
      "Gradient for encoder.encoder.1.bias: 0.0034034699201583862\n",
      "Gradient for encoder.encoder.3.weight: 0.08993363380432129\n",
      "Gradient for encoder.encoder.3.bias: 5.234602196146909e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.01271684281527996\n",
      "Gradient for encoder.encoder.4.bias: 0.011026551946997643\n",
      "Gradient for encoder.mean.weight: 0.16014555096626282\n",
      "Gradient for encoder.mean.bias: 0.006509887520223856\n",
      "Gradient for encoder.log_var.weight: 0.10094843059778214\n",
      "Gradient for encoder.log_var.bias: 0.00411487091332674\n",
      "Gradient for decoder.decoder.0.weight: 0.012510841712355614\n",
      "Gradient for decoder.decoder.0.bias: 1.0787946230772505e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0006192618166096509\n",
      "Gradient for decoder.decoder.1.bias: 0.0004570135788526386\n",
      "Gradient for decoder.decoder.3.weight: 0.01071053184568882\n",
      "Gradient for decoder.decoder.3.bias: 1.0973854464024768e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0007134370389394462\n",
      "Gradient for decoder.decoder.4.bias: 0.0008642157772555947\n",
      "Gradient for decoder.decoder.6.weight: 0.0006138657918199897\n",
      "Gradient for decoder.decoder.6.bias: 4.652265488402918e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.023969542235136032\n",
      "Gradient for encoder.encoder.0.bias: 4.332457656519573e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0027513366658240557\n",
      "Gradient for encoder.encoder.1.bias: 0.0023647351190447807\n",
      "Gradient for encoder.encoder.3.weight: 0.05621090531349182\n",
      "Gradient for encoder.encoder.3.bias: 3.5630651207263497e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.007344686891883612\n",
      "Gradient for encoder.encoder.4.bias: 0.006457908544689417\n",
      "Gradient for encoder.mean.weight: 0.09595982730388641\n",
      "Gradient for encoder.mean.bias: 0.003987286239862442\n",
      "Gradient for encoder.log_var.weight: 0.06509695947170258\n",
      "Gradient for encoder.log_var.bias: 0.0023047199938446283\n",
      "Gradient for decoder.decoder.0.weight: 0.013699882663786411\n",
      "Gradient for decoder.decoder.0.bias: 1.1018243262217453e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0007067415863275528\n",
      "Gradient for decoder.decoder.1.bias: 0.0005405985866673291\n",
      "Gradient for decoder.decoder.3.weight: 0.012028057128190994\n",
      "Gradient for decoder.decoder.3.bias: 8.666598688700233e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0004051972064189613\n",
      "Gradient for decoder.decoder.4.bias: 0.0003801299608312547\n",
      "Gradient for decoder.decoder.6.weight: 0.0005597910494543612\n",
      "Gradient for decoder.decoder.6.bias: 3.3282427466474473e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.03597600758075714\n",
      "Gradient for encoder.encoder.0.bias: 4.935527680993701e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.002734506968408823\n",
      "Gradient for encoder.encoder.1.bias: 0.0022313063964247704\n",
      "Gradient for encoder.encoder.3.weight: 0.061361219733953476\n",
      "Gradient for encoder.encoder.3.bias: 3.552898253378345e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0076393443159759045\n",
      "Gradient for encoder.encoder.4.bias: 0.0068267579190433025\n",
      "Gradient for encoder.mean.weight: 0.10209384560585022\n",
      "Gradient for encoder.mean.bias: 0.004033141303807497\n",
      "Gradient for encoder.log_var.weight: 0.05356862396001816\n",
      "Gradient for encoder.log_var.bias: 0.002601288491860032\n",
      "Gradient for decoder.decoder.0.weight: 0.012760407291352749\n",
      "Gradient for decoder.decoder.0.bias: 1.0726339261246665e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0006261166417971253\n",
      "Gradient for decoder.decoder.1.bias: 0.0005107047036290169\n",
      "Gradient for decoder.decoder.3.weight: 0.011280092410743237\n",
      "Gradient for decoder.decoder.3.bias: 1.4246752388924477e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0008696612785570323\n",
      "Gradient for decoder.decoder.4.bias: 0.001077356399036944\n",
      "Gradient for decoder.decoder.6.weight: 0.0007502499502152205\n",
      "Gradient for decoder.decoder.6.bias: 6.770493200747296e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.024781644344329834\n",
      "Gradient for encoder.encoder.0.bias: 3.9243670812982856e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.004104971885681152\n",
      "Gradient for encoder.encoder.1.bias: 0.0029088908340781927\n",
      "Gradient for encoder.encoder.3.weight: 0.08609742671251297\n",
      "Gradient for encoder.encoder.3.bias: 4.109853291023313e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.009005577303469181\n",
      "Gradient for encoder.encoder.4.bias: 0.008893311955034733\n",
      "Gradient for encoder.mean.weight: 0.11758600175380707\n",
      "Gradient for encoder.mean.bias: 0.0060696895234286785\n",
      "Gradient for encoder.log_var.weight: 0.07351316511631012\n",
      "Gradient for encoder.log_var.bias: 0.0035099012311547995\n",
      "Gradient for decoder.decoder.0.weight: 0.015009360387921333\n",
      "Gradient for decoder.decoder.0.bias: 1.1496392726684235e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0007780761225149035\n",
      "Gradient for decoder.decoder.1.bias: 0.0005883373087272048\n",
      "Gradient for decoder.decoder.3.weight: 0.013835197314620018\n",
      "Gradient for decoder.decoder.3.bias: 9.853606125487246e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00049108563689515\n",
      "Gradient for decoder.decoder.4.bias: 0.0004346855275798589\n",
      "Gradient for decoder.decoder.6.weight: 0.0005753146833740175\n",
      "Gradient for decoder.decoder.6.bias: 2.5427891159779392e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.021661870181560516\n",
      "Gradient for encoder.encoder.0.bias: 2.71899672915632e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0028347433544695377\n",
      "Gradient for encoder.encoder.1.bias: 0.0020373952575027943\n",
      "Gradient for encoder.encoder.3.weight: 0.06093372777104378\n",
      "Gradient for encoder.encoder.3.bias: 3.584072760798307e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.007796463556587696\n",
      "Gradient for encoder.encoder.4.bias: 0.006576905958354473\n",
      "Gradient for encoder.mean.weight: 0.10281404852867126\n",
      "Gradient for encoder.mean.bias: 0.004782648291438818\n",
      "Gradient for encoder.log_var.weight: 0.06274916976690292\n",
      "Gradient for encoder.log_var.bias: 0.002763736294582486\n",
      "Gradient for decoder.decoder.0.weight: 0.01815051957964897\n",
      "Gradient for decoder.decoder.0.bias: 1.6080696496612035e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0009551735711283982\n",
      "Gradient for decoder.decoder.1.bias: 0.0007120172958821058\n",
      "Gradient for decoder.decoder.3.weight: 0.016098065301775932\n",
      "Gradient for decoder.decoder.3.bias: 1.3709106072568034e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0005851869354955852\n",
      "Gradient for decoder.decoder.4.bias: 0.00047844008076936007\n",
      "Gradient for decoder.decoder.6.weight: 0.0005878933006897569\n",
      "Gradient for decoder.decoder.6.bias: 2.3346672605839558e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.022421367466449738\n",
      "Gradient for encoder.encoder.0.bias: 3.5968034106659275e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0037837151903659105\n",
      "Gradient for encoder.encoder.1.bias: 0.0024827599991112947\n",
      "Gradient for encoder.encoder.3.weight: 0.07974285632371902\n",
      "Gradient for encoder.encoder.3.bias: 3.8556607906414797e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.007466884795576334\n",
      "Gradient for encoder.encoder.4.bias: 0.007356768008321524\n",
      "Gradient for encoder.mean.weight: 0.09250947833061218\n",
      "Gradient for encoder.mean.bias: 0.005120828747749329\n",
      "Gradient for encoder.log_var.weight: 0.05742283910512924\n",
      "Gradient for encoder.log_var.bias: 0.0031602252274751663\n",
      "Gradient for decoder.decoder.0.weight: 0.01501590944826603\n",
      "Gradient for decoder.decoder.0.bias: 1.210687383679243e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0007631683838553727\n",
      "Gradient for decoder.decoder.1.bias: 0.0006024863687343895\n",
      "Gradient for decoder.decoder.3.weight: 0.013356355018913746\n",
      "Gradient for decoder.decoder.3.bias: 1.1466624871836473e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0005191874806769192\n",
      "Gradient for decoder.decoder.4.bias: 0.0004418299358803779\n",
      "Gradient for decoder.decoder.6.weight: 0.0005940285627730191\n",
      "Gradient for decoder.decoder.6.bias: 3.376409949851222e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.025175845250487328\n",
      "Gradient for encoder.encoder.0.bias: 3.501366557800978e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.002384640509262681\n",
      "Gradient for encoder.encoder.1.bias: 0.0019444064237177372\n",
      "Gradient for encoder.encoder.3.weight: 0.04963982477784157\n",
      "Gradient for encoder.encoder.3.bias: 3.0276553486530133e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.004846297204494476\n",
      "Gradient for encoder.encoder.4.bias: 0.005619669333100319\n",
      "Gradient for encoder.mean.weight: 0.07049804925918579\n",
      "Gradient for encoder.mean.bias: 0.003976005595177412\n",
      "Gradient for encoder.log_var.weight: 0.04158792272210121\n",
      "Gradient for encoder.log_var.bias: 0.0025084882508963346\n",
      "Gradient for decoder.decoder.0.weight: 0.01350429654121399\n",
      "Gradient for decoder.decoder.0.bias: 1.1071091959857782e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0007474651210941374\n",
      "Gradient for decoder.decoder.1.bias: 0.0005446939030662179\n",
      "Gradient for decoder.decoder.3.weight: 0.011648588813841343\n",
      "Gradient for decoder.decoder.3.bias: 9.603530470858601e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00042000151006504893\n",
      "Gradient for decoder.decoder.4.bias: 0.0003678124339785427\n",
      "Gradient for decoder.decoder.6.weight: 0.000528621778357774\n",
      "Gradient for decoder.decoder.6.bias: 2.4076316549326293e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.02697942964732647\n",
      "Gradient for encoder.encoder.0.bias: 3.475037271827297e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0021418025717139244\n",
      "Gradient for encoder.encoder.1.bias: 0.0016546782571822405\n",
      "Gradient for encoder.encoder.3.weight: 0.04973555728793144\n",
      "Gradient for encoder.encoder.3.bias: 3.635318157613199e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.00902008917182684\n",
      "Gradient for encoder.encoder.4.bias: 0.0063100894913077354\n",
      "Gradient for encoder.mean.weight: 0.12156901508569717\n",
      "Gradient for encoder.mean.bias: 0.003864897880703211\n",
      "Gradient for encoder.log_var.weight: 0.07165776193141937\n",
      "Gradient for encoder.log_var.bias: 0.0026463018730282784\n",
      "Gradient for decoder.decoder.0.weight: 0.016232149675488472\n",
      "Gradient for decoder.decoder.0.bias: 1.440555730258808e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0008149704081006348\n",
      "Gradient for decoder.decoder.1.bias: 0.0007052788860164583\n",
      "Gradient for decoder.decoder.3.weight: 0.014921923168003559\n",
      "Gradient for decoder.decoder.3.bias: 1.1302124514056544e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.000619061291217804\n",
      "Gradient for decoder.decoder.4.bias: 0.0007048784173093736\n",
      "Gradient for decoder.decoder.6.weight: 0.000631556031294167\n",
      "Gradient for decoder.decoder.6.bias: 3.769320755964145e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.0170903243124485\n",
      "Gradient for encoder.encoder.0.bias: 2.8782660282944406e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.002718735486268997\n",
      "Gradient for encoder.encoder.1.bias: 0.001908905920572579\n",
      "Gradient for encoder.encoder.3.weight: 0.05552709475159645\n",
      "Gradient for encoder.encoder.3.bias: 4.005646092597459e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0075385719537734985\n",
      "Gradient for encoder.encoder.4.bias: 0.008008167147636414\n",
      "Gradient for encoder.mean.weight: 0.09230145812034607\n",
      "Gradient for encoder.mean.bias: 0.005164202302694321\n",
      "Gradient for encoder.log_var.weight: 0.05575970187783241\n",
      "Gradient for encoder.log_var.bias: 0.0038262817542999983\n",
      "Gradient for decoder.decoder.0.weight: 0.0161347147077322\n",
      "Gradient for decoder.decoder.0.bias: 1.4021937777553006e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0008228098158724606\n",
      "Gradient for decoder.decoder.1.bias: 0.0006269971490837634\n",
      "Gradient for decoder.decoder.3.weight: 0.014709513634443283\n",
      "Gradient for decoder.decoder.3.bias: 1.2485412703711063e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.000718644936569035\n",
      "Gradient for decoder.decoder.4.bias: 0.0007841091137379408\n",
      "Gradient for decoder.decoder.6.weight: 0.0007172413752414286\n",
      "Gradient for decoder.decoder.6.bias: 4.709322456619702e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training VAE Epoch:  61%|██████    | 48/79 [00:00<00:00, 71.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient for encoder.encoder.0.weight: 0.023308340460062027\n",
      "Gradient for encoder.encoder.0.bias: 3.5808522813596255e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0027290431316941977\n",
      "Gradient for encoder.encoder.1.bias: 0.00230938452295959\n",
      "Gradient for encoder.encoder.3.weight: 0.057155054062604904\n",
      "Gradient for encoder.encoder.3.bias: 4.123577035386461e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0073509919457137585\n",
      "Gradient for encoder.encoder.4.bias: 0.0094313258305192\n",
      "Gradient for encoder.mean.weight: 0.09876624494791031\n",
      "Gradient for encoder.mean.bias: 0.006881368812173605\n",
      "Gradient for encoder.log_var.weight: 0.056055761873722076\n",
      "Gradient for encoder.log_var.bias: 0.004278162494301796\n",
      "Gradient for decoder.decoder.0.weight: 0.015387045219540596\n",
      "Gradient for decoder.decoder.0.bias: 1.1897428875418115e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0007860354380682111\n",
      "Gradient for decoder.decoder.1.bias: 0.0005917189409956336\n",
      "Gradient for decoder.decoder.3.weight: 0.014147769659757614\n",
      "Gradient for decoder.decoder.3.bias: 1.0656866361591355e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0005397129571065307\n",
      "Gradient for decoder.decoder.4.bias: 0.0005080141709186137\n",
      "Gradient for decoder.decoder.6.weight: 0.0006544289644807577\n",
      "Gradient for decoder.decoder.6.bias: 4.392681876197457e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.02418706938624382\n",
      "Gradient for encoder.encoder.0.bias: 3.3426154205651315e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0029658570419996977\n",
      "Gradient for encoder.encoder.1.bias: 0.0021761145908385515\n",
      "Gradient for encoder.encoder.3.weight: 0.06401971727609634\n",
      "Gradient for encoder.encoder.3.bias: 3.6714731255216293e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.007038818672299385\n",
      "Gradient for encoder.encoder.4.bias: 0.006777720991522074\n",
      "Gradient for encoder.mean.weight: 0.09760917723178864\n",
      "Gradient for encoder.mean.bias: 0.005071866326034069\n",
      "Gradient for encoder.log_var.weight: 0.055271703749895096\n",
      "Gradient for encoder.log_var.bias: 0.003223678795620799\n",
      "Gradient for decoder.decoder.0.weight: 0.016295485198497772\n",
      "Gradient for decoder.decoder.0.bias: 1.2880703448292508e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0008561131544411182\n",
      "Gradient for decoder.decoder.1.bias: 0.0006105803768150508\n",
      "Gradient for decoder.decoder.3.weight: 0.014814099296927452\n",
      "Gradient for decoder.decoder.3.bias: 1.1818122869211578e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0006632040021941066\n",
      "Gradient for decoder.decoder.4.bias: 0.0007247481844387949\n",
      "Gradient for decoder.decoder.6.weight: 0.0006499219452962279\n",
      "Gradient for decoder.decoder.6.bias: 4.2347615817561746e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.02575286664068699\n",
      "Gradient for encoder.encoder.0.bias: 3.671737219823612e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.002539977664127946\n",
      "Gradient for encoder.encoder.1.bias: 0.0019834181293845177\n",
      "Gradient for encoder.encoder.3.weight: 0.05365263670682907\n",
      "Gradient for encoder.encoder.3.bias: 3.867504649868181e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.008318983018398285\n",
      "Gradient for encoder.encoder.4.bias: 0.007838472723960876\n",
      "Gradient for encoder.mean.weight: 0.10963496565818787\n",
      "Gradient for encoder.mean.bias: 0.005121358670294285\n",
      "Gradient for encoder.log_var.weight: 0.07104259729385376\n",
      "Gradient for encoder.log_var.bias: 0.0031994993332773447\n",
      "Gradient for decoder.decoder.0.weight: 0.01697523705661297\n",
      "Gradient for decoder.decoder.0.bias: 1.4099239831200094e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0008814398315735161\n",
      "Gradient for decoder.decoder.1.bias: 0.0006204660166986287\n",
      "Gradient for decoder.decoder.3.weight: 0.015407158061861992\n",
      "Gradient for decoder.decoder.3.bias: 1.381107450626473e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.000716320937499404\n",
      "Gradient for decoder.decoder.4.bias: 0.0007628913735970855\n",
      "Gradient for decoder.decoder.6.weight: 0.0007316044648177922\n",
      "Gradient for decoder.decoder.6.bias: 5.022857294534333e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training VAE Epoch:  71%|███████   | 56/79 [00:00<00:00, 72.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient for encoder.encoder.0.weight: 0.016555188223719597\n",
      "Gradient for encoder.encoder.0.bias: 2.866276833934922e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0030137100256979465\n",
      "Gradient for encoder.encoder.1.bias: 0.002236600499600172\n",
      "Gradient for encoder.encoder.3.weight: 0.060716718435287476\n",
      "Gradient for encoder.encoder.3.bias: 3.3523916975752854e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.00716012716293335\n",
      "Gradient for encoder.encoder.4.bias: 0.007805076893419027\n",
      "Gradient for encoder.mean.weight: 0.09154821187257767\n",
      "Gradient for encoder.mean.bias: 0.005595685448497534\n",
      "Gradient for encoder.log_var.weight: 0.054315220564603806\n",
      "Gradient for encoder.log_var.bias: 0.0032769409008324146\n",
      "Gradient for decoder.decoder.0.weight: 0.01662692241370678\n",
      "Gradient for decoder.decoder.0.bias: 1.353303719087151e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0008587168413214386\n",
      "Gradient for decoder.decoder.1.bias: 0.0006267692660912871\n",
      "Gradient for decoder.decoder.3.weight: 0.0143907330930233\n",
      "Gradient for decoder.decoder.3.bias: 1.0895233326646547e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0005263350903987885\n",
      "Gradient for decoder.decoder.4.bias: 0.000486956414533779\n",
      "Gradient for decoder.decoder.6.weight: 0.0005890110041946173\n",
      "Gradient for decoder.decoder.6.bias: 3.1487707019550726e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.017970072105526924\n",
      "Gradient for encoder.encoder.0.bias: 3.211527571655992e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0024778470396995544\n",
      "Gradient for encoder.encoder.1.bias: 0.0018119629239663482\n",
      "Gradient for encoder.encoder.3.weight: 0.052900370210409164\n",
      "Gradient for encoder.encoder.3.bias: 3.1301081171442036e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.00803224928677082\n",
      "Gradient for encoder.encoder.4.bias: 0.006472068373113871\n",
      "Gradient for encoder.mean.weight: 0.10532378405332565\n",
      "Gradient for encoder.mean.bias: 0.0036886001471430063\n",
      "Gradient for encoder.log_var.weight: 0.059796422719955444\n",
      "Gradient for encoder.log_var.bias: 0.0024745839182287455\n",
      "Gradient for decoder.decoder.0.weight: 0.01301860623061657\n",
      "Gradient for decoder.decoder.0.bias: 1.0572166753153311e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0007252182113006711\n",
      "Gradient for decoder.decoder.1.bias: 0.0005211933748796582\n",
      "Gradient for decoder.decoder.3.weight: 0.011847986839711666\n",
      "Gradient for decoder.decoder.3.bias: 1.0170735087466909e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0005777791375294328\n",
      "Gradient for decoder.decoder.4.bias: 0.000625446205958724\n",
      "Gradient for decoder.decoder.6.weight: 0.0005664239870384336\n",
      "Gradient for decoder.decoder.6.bias: 3.2607666071271524e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.020750168710947037\n",
      "Gradient for encoder.encoder.0.bias: 3.0830230729472774e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.002323427703231573\n",
      "Gradient for encoder.encoder.1.bias: 0.001806764048524201\n",
      "Gradient for encoder.encoder.3.weight: 0.04967113584280014\n",
      "Gradient for encoder.encoder.3.bias: 3.320382302440805e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.005947410129010677\n",
      "Gradient for encoder.encoder.4.bias: 0.005915714427828789\n",
      "Gradient for encoder.mean.weight: 0.08192244172096252\n",
      "Gradient for encoder.mean.bias: 0.00441680708900094\n",
      "Gradient for encoder.log_var.weight: 0.048498280346393585\n",
      "Gradient for encoder.log_var.bias: 0.002750164130702615\n",
      "Gradient for decoder.decoder.0.weight: 0.015855049714446068\n",
      "Gradient for decoder.decoder.0.bias: 1.32032315636188e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0008075771620497108\n",
      "Gradient for decoder.decoder.1.bias: 0.0006508759688585997\n",
      "Gradient for decoder.decoder.3.weight: 0.014691990800201893\n",
      "Gradient for decoder.decoder.3.bias: 1.1333386312761817e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0005626216880045831\n",
      "Gradient for decoder.decoder.4.bias: 0.0005696286098100245\n",
      "Gradient for decoder.decoder.6.weight: 0.0006088889786042273\n",
      "Gradient for decoder.decoder.6.bias: 3.5524401027942076e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.027761133387684822\n",
      "Gradient for encoder.encoder.0.bias: 3.885360089217471e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.002627372508868575\n",
      "Gradient for encoder.encoder.1.bias: 0.0022632020991295576\n",
      "Gradient for encoder.encoder.3.weight: 0.05737236514687538\n",
      "Gradient for encoder.encoder.3.bias: 3.912933033145549e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.008611260913312435\n",
      "Gradient for encoder.encoder.4.bias: 0.006901299115270376\n",
      "Gradient for encoder.mean.weight: 0.10610104352235794\n",
      "Gradient for encoder.mean.bias: 0.005405968055129051\n",
      "Gradient for encoder.log_var.weight: 0.06418263167142868\n",
      "Gradient for encoder.log_var.bias: 0.0030098850838840008\n",
      "Gradient for decoder.decoder.0.weight: 0.01400834135711193\n",
      "Gradient for decoder.decoder.0.bias: 1.2268654148162028e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0007523152162320912\n",
      "Gradient for decoder.decoder.1.bias: 0.0005912095075473189\n",
      "Gradient for decoder.decoder.3.weight: 0.013186685740947723\n",
      "Gradient for decoder.decoder.3.bias: 1.0131283312286854e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.000490209087729454\n",
      "Gradient for decoder.decoder.4.bias: 0.00047107000136747956\n",
      "Gradient for decoder.decoder.6.weight: 0.000572739343624562\n",
      "Gradient for decoder.decoder.6.bias: 2.695513830985874e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.022078564390540123\n",
      "Gradient for encoder.encoder.0.bias: 3.294750583471284e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.003668682649731636\n",
      "Gradient for encoder.encoder.1.bias: 0.0029608742333948612\n",
      "Gradient for encoder.encoder.3.weight: 0.07527761161327362\n",
      "Gradient for encoder.encoder.3.bias: 4.1310135867611564e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0113279540091753\n",
      "Gradient for encoder.encoder.4.bias: 0.010092520155012608\n",
      "Gradient for encoder.mean.weight: 0.14742206037044525\n",
      "Gradient for encoder.mean.bias: 0.00469603156670928\n",
      "Gradient for encoder.log_var.weight: 0.0821380466222763\n",
      "Gradient for encoder.log_var.bias: 0.0033245300874114037\n",
      "Gradient for decoder.decoder.0.weight: 0.01649838127195835\n",
      "Gradient for decoder.decoder.0.bias: 1.2476944477590735e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.000817331369034946\n",
      "Gradient for decoder.decoder.1.bias: 0.0006313790800049901\n",
      "Gradient for decoder.decoder.3.weight: 0.014986847527325153\n",
      "Gradient for decoder.decoder.3.bias: 1.0577495823671512e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0005688935634680092\n",
      "Gradient for decoder.decoder.4.bias: 0.0005811374285258353\n",
      "Gradient for decoder.decoder.6.weight: 0.0006029462092556059\n",
      "Gradient for decoder.decoder.6.bias: 3.734869460458867e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.0223517008125782\n",
      "Gradient for encoder.encoder.0.bias: 3.8886602271581694e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.003211439121514559\n",
      "Gradient for encoder.encoder.1.bias: 0.002471807412803173\n",
      "Gradient for encoder.encoder.3.weight: 0.06499440968036652\n",
      "Gradient for encoder.encoder.3.bias: 2.946005661641493e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.006862926762551069\n",
      "Gradient for encoder.encoder.4.bias: 0.005998384207487106\n",
      "Gradient for encoder.mean.weight: 0.09505701065063477\n",
      "Gradient for encoder.mean.bias: 0.004050303716212511\n",
      "Gradient for encoder.log_var.weight: 0.04881445690989494\n",
      "Gradient for encoder.log_var.bias: 0.002190849045291543\n",
      "Gradient for decoder.decoder.0.weight: 0.013403123244643211\n",
      "Gradient for decoder.decoder.0.bias: 1.0617285522984687e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.000670098583213985\n",
      "Gradient for decoder.decoder.1.bias: 0.0005191870732232928\n",
      "Gradient for decoder.decoder.3.weight: 0.01174040138721466\n",
      "Gradient for decoder.decoder.3.bias: 1.1533337479496808e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0008060804102569818\n",
      "Gradient for decoder.decoder.4.bias: 0.000967977219261229\n",
      "Gradient for decoder.decoder.6.weight: 0.000718382652848959\n",
      "Gradient for decoder.decoder.6.bias: 5.968242112430744e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.019720660522580147\n",
      "Gradient for encoder.encoder.0.bias: 3.015109342752176e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0020672501996159554\n",
      "Gradient for encoder.encoder.1.bias: 0.0015822291607037187\n",
      "Gradient for encoder.encoder.3.weight: 0.040638335049152374\n",
      "Gradient for encoder.encoder.3.bias: 3.13408354823963e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.005693175829946995\n",
      "Gradient for encoder.encoder.4.bias: 0.005804399028420448\n",
      "Gradient for encoder.mean.weight: 0.07843875139951706\n",
      "Gradient for encoder.mean.bias: 0.003236031625419855\n",
      "Gradient for encoder.log_var.weight: 0.047190528362989426\n",
      "Gradient for encoder.log_var.bias: 0.0024957500863820314\n",
      "Gradient for decoder.decoder.0.weight: 0.01591433957219124\n",
      "Gradient for decoder.decoder.0.bias: 1.4174907081443422e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0007935676840133965\n",
      "Gradient for decoder.decoder.1.bias: 0.0005886267754249275\n",
      "Gradient for decoder.decoder.3.weight: 0.014123788103461266\n",
      "Gradient for decoder.decoder.3.bias: 1.1359795742960088e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0005158765707165003\n",
      "Gradient for decoder.decoder.4.bias: 0.0004879515618085861\n",
      "Gradient for decoder.decoder.6.weight: 0.0005832294118590653\n",
      "Gradient for decoder.decoder.6.bias: 3.0003837309777737e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.021074363961815834\n",
      "Gradient for encoder.encoder.0.bias: 2.797686735056537e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.003149275900796056\n",
      "Gradient for encoder.encoder.1.bias: 0.0021892257500439882\n",
      "Gradient for encoder.encoder.3.weight: 0.05828651785850525\n",
      "Gradient for encoder.encoder.3.bias: 2.8109770067175077e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.005838703364133835\n",
      "Gradient for encoder.encoder.4.bias: 0.00536867743358016\n",
      "Gradient for encoder.mean.weight: 0.08099360764026642\n",
      "Gradient for encoder.mean.bias: 0.0034689814783632755\n",
      "Gradient for encoder.log_var.weight: 0.04706433042883873\n",
      "Gradient for encoder.log_var.bias: 0.002440050709992647\n",
      "Gradient for decoder.decoder.0.weight: 0.019363990053534508\n",
      "Gradient for decoder.decoder.0.bias: 1.6811273206851496e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0009621123899705708\n",
      "Gradient for decoder.decoder.1.bias: 0.0007171149482019246\n",
      "Gradient for decoder.decoder.3.weight: 0.017122900113463402\n",
      "Gradient for decoder.decoder.3.bias: 1.3882665850228904e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0007532311137765646\n",
      "Gradient for decoder.decoder.4.bias: 0.0007083720993250608\n",
      "Gradient for decoder.decoder.6.weight: 0.0007094002212397754\n",
      "Gradient for decoder.decoder.6.bias: 4.388943125377409e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.023681310936808586\n",
      "Gradient for encoder.encoder.0.bias: 4.1452213189741016e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.004555457271635532\n",
      "Gradient for encoder.encoder.1.bias: 0.0029111250769346952\n",
      "Gradient for encoder.encoder.3.weight: 0.08046349138021469\n",
      "Gradient for encoder.encoder.3.bias: 3.682626981138526e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.010133136063814163\n",
      "Gradient for encoder.encoder.4.bias: 0.008481714874505997\n",
      "Gradient for encoder.mean.weight: 0.13626377284526825\n",
      "Gradient for encoder.mean.bias: 0.005219528451561928\n",
      "Gradient for encoder.log_var.weight: 0.07422244548797607\n",
      "Gradient for encoder.log_var.bias: 0.0035418292973190546\n",
      "Gradient for decoder.decoder.0.weight: 0.016830632463097572\n",
      "Gradient for decoder.decoder.0.bias: 1.5003927267276396e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0008349506533704698\n",
      "Gradient for decoder.decoder.1.bias: 0.0006299131200648844\n",
      "Gradient for decoder.decoder.3.weight: 0.014677225612103939\n",
      "Gradient for decoder.decoder.3.bias: 1.2580669839223901e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0005478107486851513\n",
      "Gradient for decoder.decoder.4.bias: 0.0004662228166125715\n",
      "Gradient for decoder.decoder.6.weight: 0.0006043751491233706\n",
      "Gradient for decoder.decoder.6.bias: 3.465024201432243e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.017829906195402145\n",
      "Gradient for encoder.encoder.0.bias: 3.38193986704205e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.003029411658644676\n",
      "Gradient for encoder.encoder.1.bias: 0.002076521283015609\n",
      "Gradient for encoder.encoder.3.weight: 0.06159783527255058\n",
      "Gradient for encoder.encoder.3.bias: 4.253268848231073e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.009827359579503536\n",
      "Gradient for encoder.encoder.4.bias: 0.008419529534876347\n",
      "Gradient for encoder.mean.weight: 0.12617723643779755\n",
      "Gradient for encoder.mean.bias: 0.005489440634846687\n",
      "Gradient for encoder.log_var.weight: 0.07624874264001846\n",
      "Gradient for encoder.log_var.bias: 0.0038360615726560354\n",
      "Gradient for decoder.decoder.0.weight: 0.0164661668241024\n",
      "Gradient for decoder.decoder.0.bias: 1.342317645924851e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0008999553974717855\n",
      "Gradient for decoder.decoder.1.bias: 0.0006270887679420412\n",
      "Gradient for decoder.decoder.3.weight: 0.015774158760905266\n",
      "Gradient for decoder.decoder.3.bias: 1.262200899354582e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0008302658097818494\n",
      "Gradient for decoder.decoder.4.bias: 0.0008251341641880572\n",
      "Gradient for decoder.decoder.6.weight: 0.0007575826602987945\n",
      "Gradient for decoder.decoder.6.bias: 5.0132533942814916e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.023973284289240837\n",
      "Gradient for encoder.encoder.0.bias: 3.3402620946976214e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0027312543243169785\n",
      "Gradient for encoder.encoder.1.bias: 0.0019246952142566442\n",
      "Gradient for encoder.encoder.3.weight: 0.05346016585826874\n",
      "Gradient for encoder.encoder.3.bias: 3.137322623913974e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.006553053855895996\n",
      "Gradient for encoder.encoder.4.bias: 0.005441457033157349\n",
      "Gradient for encoder.mean.weight: 0.08635140210390091\n",
      "Gradient for encoder.mean.bias: 0.0036546404007822275\n",
      "Gradient for encoder.log_var.weight: 0.05374176427721977\n",
      "Gradient for encoder.log_var.bias: 0.0023573758080601692\n",
      "Gradient for decoder.decoder.0.weight: 0.01549026370048523\n",
      "Gradient for decoder.decoder.0.bias: 1.469089572214699e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0007384468335658312\n",
      "Gradient for decoder.decoder.1.bias: 0.0005630261730402708\n",
      "Gradient for decoder.decoder.3.weight: 0.013517643325030804\n",
      "Gradient for decoder.decoder.3.bias: 1.217082268301084e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0004987824358977377\n",
      "Gradient for decoder.decoder.4.bias: 0.0004539046494755894\n",
      "Gradient for decoder.decoder.6.weight: 0.0005800587823614478\n",
      "Gradient for decoder.decoder.6.bias: 3.147392999380827e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.01840982772409916\n",
      "Gradient for encoder.encoder.0.bias: 2.62394116851139e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0019788281060755253\n",
      "Gradient for encoder.encoder.1.bias: 0.0016777794808149338\n",
      "Gradient for encoder.encoder.3.weight: 0.03765922039747238\n",
      "Gradient for encoder.encoder.3.bias: 3.343081922402291e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.007178271654993296\n",
      "Gradient for encoder.encoder.4.bias: 0.007061142940074205\n",
      "Gradient for encoder.mean.weight: 0.09428039193153381\n",
      "Gradient for encoder.mean.bias: 0.00534460274502635\n",
      "Gradient for encoder.log_var.weight: 0.05318786948919296\n",
      "Gradient for encoder.log_var.bias: 0.0032927324064075947\n",
      "Gradient for decoder.decoder.0.weight: 0.018828775733709335\n",
      "Gradient for decoder.decoder.0.bias: 1.489222911654764e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0010022892383858562\n",
      "Gradient for decoder.decoder.1.bias: 0.0007153708138503134\n",
      "Gradient for decoder.decoder.3.weight: 0.01722949557006359\n",
      "Gradient for decoder.decoder.3.bias: 1.3811299326427218e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0007239878177642822\n",
      "Gradient for decoder.decoder.4.bias: 0.0007454376318491995\n",
      "Gradient for decoder.decoder.6.weight: 0.0006410541827790439\n",
      "Gradient for decoder.decoder.6.bias: 3.702291724039242e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.016244687139987946\n",
      "Gradient for encoder.encoder.0.bias: 2.921758668339436e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0029799649491906166\n",
      "Gradient for encoder.encoder.1.bias: 0.002028324641287327\n",
      "Gradient for encoder.encoder.3.weight: 0.05990856885910034\n",
      "Gradient for encoder.encoder.3.bias: 3.2866917520912864e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.010127844288945198\n",
      "Gradient for encoder.encoder.4.bias: 0.007526949513703585\n",
      "Gradient for encoder.mean.weight: 0.12766167521476746\n",
      "Gradient for encoder.mean.bias: 0.0038293772377073765\n",
      "Gradient for encoder.log_var.weight: 0.08060267567634583\n",
      "Gradient for encoder.log_var.bias: 0.0026971222832798958\n",
      "Gradient for decoder.decoder.0.weight: 0.015180261805653572\n",
      "Gradient for decoder.decoder.0.bias: 1.2819072192638004e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0007942121010273695\n",
      "Gradient for decoder.decoder.1.bias: 0.0005764066008850932\n",
      "Gradient for decoder.decoder.3.weight: 0.013588936068117619\n",
      "Gradient for decoder.decoder.3.bias: 9.873261930248844e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0004963214742019773\n",
      "Gradient for decoder.decoder.4.bias: 0.00041976055945269763\n",
      "Gradient for decoder.decoder.6.weight: 0.0006000773282721639\n",
      "Gradient for decoder.decoder.6.bias: 3.352952262503095e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training VAE Epoch:  81%|████████  | 64/79 [00:01<00:00, 74.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient for encoder.encoder.0.weight: 0.018397601321339607\n",
      "Gradient for encoder.encoder.0.bias: 2.8939208668310457e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.002165185520425439\n",
      "Gradient for encoder.encoder.1.bias: 0.001855843118391931\n",
      "Gradient for encoder.encoder.3.weight: 0.049459099769592285\n",
      "Gradient for encoder.encoder.3.bias: 2.8074498281682736e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.005970613099634647\n",
      "Gradient for encoder.encoder.4.bias: 0.005997689440846443\n",
      "Gradient for encoder.mean.weight: 0.07968634366989136\n",
      "Gradient for encoder.mean.bias: 0.004417710471898317\n",
      "Gradient for encoder.log_var.weight: 0.046725474298000336\n",
      "Gradient for encoder.log_var.bias: 0.002767435973510146\n",
      "Gradient for decoder.decoder.0.weight: 0.01578882709145546\n",
      "Gradient for decoder.decoder.0.bias: 1.3978322666030607e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0007954264874570072\n",
      "Gradient for decoder.decoder.1.bias: 0.000624973326921463\n",
      "Gradient for decoder.decoder.3.weight: 0.014112036675214767\n",
      "Gradient for decoder.decoder.3.bias: 1.1051319581678598e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0005165655165910721\n",
      "Gradient for decoder.decoder.4.bias: 0.0004925110260955989\n",
      "Gradient for decoder.decoder.6.weight: 0.0006000113789923489\n",
      "Gradient for decoder.decoder.6.bias: 3.0953022360336035e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.014344952069222927\n",
      "Gradient for encoder.encoder.0.bias: 2.1323158516661778e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0021299542859196663\n",
      "Gradient for encoder.encoder.1.bias: 0.001727237249724567\n",
      "Gradient for encoder.encoder.3.weight: 0.041267022490501404\n",
      "Gradient for encoder.encoder.3.bias: 2.354209327481982e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0050294832326471806\n",
      "Gradient for encoder.encoder.4.bias: 0.004809060599654913\n",
      "Gradient for encoder.mean.weight: 0.07205329090356827\n",
      "Gradient for encoder.mean.bias: 0.003064017742872238\n",
      "Gradient for encoder.log_var.weight: 0.03963084891438484\n",
      "Gradient for encoder.log_var.bias: 0.0020338925532996655\n",
      "Gradient for decoder.decoder.0.weight: 0.017384938895702362\n",
      "Gradient for decoder.decoder.0.bias: 1.6545111114485422e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0008842716342769563\n",
      "Gradient for decoder.decoder.1.bias: 0.0007320952718146145\n",
      "Gradient for decoder.decoder.3.weight: 0.016602152958512306\n",
      "Gradient for decoder.decoder.3.bias: 1.3629401773851413e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0006007318734191358\n",
      "Gradient for decoder.decoder.4.bias: 0.0005244249477982521\n",
      "Gradient for decoder.decoder.6.weight: 0.0006298779044300318\n",
      "Gradient for decoder.decoder.6.bias: 3.545927393133752e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.023072993382811546\n",
      "Gradient for encoder.encoder.0.bias: 2.946680399684709e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0020775592420250177\n",
      "Gradient for encoder.encoder.1.bias: 0.0018724908586591482\n",
      "Gradient for encoder.encoder.3.weight: 0.04294779524207115\n",
      "Gradient for encoder.encoder.3.bias: 2.9596558537292594e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.006501412950456142\n",
      "Gradient for encoder.encoder.4.bias: 0.005913929082453251\n",
      "Gradient for encoder.mean.weight: 0.08690427988767624\n",
      "Gradient for encoder.mean.bias: 0.0034776427783071995\n",
      "Gradient for encoder.log_var.weight: 0.049774572253227234\n",
      "Gradient for encoder.log_var.bias: 0.001875040354207158\n",
      "Gradient for decoder.decoder.0.weight: 0.017284000292420387\n",
      "Gradient for decoder.decoder.0.bias: 1.4141016135837958e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0009096196736209095\n",
      "Gradient for decoder.decoder.1.bias: 0.0006399602279998362\n",
      "Gradient for decoder.decoder.3.weight: 0.015687810257077217\n",
      "Gradient for decoder.decoder.3.bias: 1.1307772079804934e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0005825314437970519\n",
      "Gradient for decoder.decoder.4.bias: 0.0005483240820467472\n",
      "Gradient for decoder.decoder.6.weight: 0.0006071884417906404\n",
      "Gradient for decoder.decoder.6.bias: 3.0344128390424885e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training VAE Epoch:  91%|█████████ | 72/79 [00:01<00:00, 75.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient for encoder.encoder.0.weight: 0.017894059419631958\n",
      "Gradient for encoder.encoder.0.bias: 2.930210935003785e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0025660875253379345\n",
      "Gradient for encoder.encoder.1.bias: 0.0019074357114732265\n",
      "Gradient for encoder.encoder.3.weight: 0.04859960079193115\n",
      "Gradient for encoder.encoder.3.bias: 3.4303665463752964e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.006230194587260485\n",
      "Gradient for encoder.encoder.4.bias: 0.00836602970957756\n",
      "Gradient for encoder.mean.weight: 0.08113455027341843\n",
      "Gradient for encoder.mean.bias: 0.00661516236141324\n",
      "Gradient for encoder.log_var.weight: 0.0522150918841362\n",
      "Gradient for encoder.log_var.bias: 0.004622297361493111\n",
      "Gradient for decoder.decoder.0.weight: 0.0183342844247818\n",
      "Gradient for decoder.decoder.0.bias: 1.4926263003367524e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0009082469623535872\n",
      "Gradient for decoder.decoder.1.bias: 0.0007179302629083395\n",
      "Gradient for decoder.decoder.3.weight: 0.01750345528125763\n",
      "Gradient for decoder.decoder.3.bias: 1.2897745371720504e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0006211193394847214\n",
      "Gradient for decoder.decoder.4.bias: 0.0005746628157794476\n",
      "Gradient for decoder.decoder.6.weight: 0.0006215089233592153\n",
      "Gradient for decoder.decoder.6.bias: 2.8385999030433595e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.015852322801947594\n",
      "Gradient for encoder.encoder.0.bias: 2.338756098507755e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0021163253113627434\n",
      "Gradient for encoder.encoder.1.bias: 0.0015457337722182274\n",
      "Gradient for encoder.encoder.3.weight: 0.039985012263059616\n",
      "Gradient for encoder.encoder.3.bias: 2.6523838680958534e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0056930105201900005\n",
      "Gradient for encoder.encoder.4.bias: 0.0051086717285215855\n",
      "Gradient for encoder.mean.weight: 0.07923804223537445\n",
      "Gradient for encoder.mean.bias: 0.0034909804817289114\n",
      "Gradient for encoder.log_var.weight: 0.03952641785144806\n",
      "Gradient for encoder.log_var.bias: 0.0019426955841481686\n",
      "Gradient for decoder.decoder.0.weight: 0.01700161211192608\n",
      "Gradient for decoder.decoder.0.bias: 1.30462030067946e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0007847899687476456\n",
      "Gradient for decoder.decoder.1.bias: 0.0006385413580574095\n",
      "Gradient for decoder.decoder.3.weight: 0.015124361030757427\n",
      "Gradient for decoder.decoder.3.bias: 1.144058528468328e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0005220387247391045\n",
      "Gradient for decoder.decoder.4.bias: 0.000479211681522429\n",
      "Gradient for decoder.decoder.6.weight: 0.0006115218857303262\n",
      "Gradient for decoder.decoder.6.bias: 2.9134087526472285e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.023299440741539\n",
      "Gradient for encoder.encoder.0.bias: 3.903413356431962e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0021416128147393465\n",
      "Gradient for encoder.encoder.1.bias: 0.0016086384421214461\n",
      "Gradient for encoder.encoder.3.weight: 0.04391595348715782\n",
      "Gradient for encoder.encoder.3.bias: 4.4130166187983377e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.00774016696959734\n",
      "Gradient for encoder.encoder.4.bias: 0.009258311241865158\n",
      "Gradient for encoder.mean.weight: 0.10058487951755524\n",
      "Gradient for encoder.mean.bias: 0.007469036616384983\n",
      "Gradient for encoder.log_var.weight: 0.059978682547807693\n",
      "Gradient for encoder.log_var.bias: 0.005020349286496639\n",
      "Gradient for decoder.decoder.0.weight: 0.011693504638969898\n",
      "Gradient for decoder.decoder.0.bias: 9.121376570719875e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0006193700828589499\n",
      "Gradient for decoder.decoder.1.bias: 0.0004552868485916406\n",
      "Gradient for decoder.decoder.3.weight: 0.010363196954131126\n",
      "Gradient for decoder.decoder.3.bias: 8.100855403148088e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0005187823553569615\n",
      "Gradient for decoder.decoder.4.bias: 0.0005997512489557266\n",
      "Gradient for decoder.decoder.6.weight: 0.0005866005085408688\n",
      "Gradient for decoder.decoder.6.bias: 3.941955583286472e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.015829555690288544\n",
      "Gradient for encoder.encoder.0.bias: 2.4340253770849252e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0022201924584805965\n",
      "Gradient for encoder.encoder.1.bias: 0.0017610362265259027\n",
      "Gradient for encoder.encoder.3.weight: 0.04080755263566971\n",
      "Gradient for encoder.encoder.3.bias: 2.6150670517921526e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0047513218596577644\n",
      "Gradient for encoder.encoder.4.bias: 0.005325036123394966\n",
      "Gradient for encoder.mean.weight: 0.06484366208314896\n",
      "Gradient for encoder.mean.bias: 0.003843126120045781\n",
      "Gradient for encoder.log_var.weight: 0.03847593069076538\n",
      "Gradient for encoder.log_var.bias: 0.002259056083858013\n",
      "Gradient for decoder.decoder.0.weight: 0.01721161976456642\n",
      "Gradient for decoder.decoder.0.bias: 1.4187079289129656e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0008500642725266516\n",
      "Gradient for decoder.decoder.1.bias: 0.0006524730706587434\n",
      "Gradient for decoder.decoder.3.weight: 0.0152892442420125\n",
      "Gradient for decoder.decoder.3.bias: 1.2115176917237847e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0005904511781409383\n",
      "Gradient for decoder.decoder.4.bias: 0.0005956467939540744\n",
      "Gradient for decoder.decoder.6.weight: 0.00060203269822523\n",
      "Gradient for decoder.decoder.6.bias: 3.215302785974927e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.02309309132397175\n",
      "Gradient for encoder.encoder.0.bias: 3.066186540778837e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0024045587051659822\n",
      "Gradient for encoder.encoder.1.bias: 0.0018980269087478518\n",
      "Gradient for encoder.encoder.3.weight: 0.04939718917012215\n",
      "Gradient for encoder.encoder.3.bias: 2.554397249276974e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0060205357149243355\n",
      "Gradient for encoder.encoder.4.bias: 0.004298673011362553\n",
      "Gradient for encoder.mean.weight: 0.08318186551332474\n",
      "Gradient for encoder.mean.bias: 0.0031664669513702393\n",
      "Gradient for encoder.log_var.weight: 0.0469808392226696\n",
      "Gradient for encoder.log_var.bias: 0.0019104685634374619\n",
      "Gradient for decoder.decoder.0.weight: 0.017751337960362434\n",
      "Gradient for decoder.decoder.0.bias: 1.4894038780077778e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0009560749167576432\n",
      "Gradient for decoder.decoder.1.bias: 0.0007411311962641776\n",
      "Gradient for decoder.decoder.3.weight: 0.016290204599499702\n",
      "Gradient for decoder.decoder.3.bias: 1.2090700662881204e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0005671487306244671\n",
      "Gradient for decoder.decoder.4.bias: 0.0004835694271605462\n",
      "Gradient for decoder.decoder.6.weight: 0.0006260531954467297\n",
      "Gradient for decoder.decoder.6.bias: 3.7304922443581745e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.023420164361596107\n",
      "Gradient for encoder.encoder.0.bias: 3.276470761370831e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0026194967795163393\n",
      "Gradient for encoder.encoder.1.bias: 0.0017169903730973601\n",
      "Gradient for encoder.encoder.3.weight: 0.048702456057071686\n",
      "Gradient for encoder.encoder.3.bias: 3.12352421705242e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.005967322271317244\n",
      "Gradient for encoder.encoder.4.bias: 0.005536338314414024\n",
      "Gradient for encoder.mean.weight: 0.07888505607843399\n",
      "Gradient for encoder.mean.bias: 0.0043412307277321815\n",
      "Gradient for encoder.log_var.weight: 0.04702536389231682\n",
      "Gradient for encoder.log_var.bias: 0.0025077739264816046\n",
      "Gradient for decoder.decoder.0.weight: 0.01459515281021595\n",
      "Gradient for decoder.decoder.0.bias: 1.1659775922545634e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0008490640902891755\n",
      "Gradient for decoder.decoder.1.bias: 0.0005379574140533805\n",
      "Gradient for decoder.decoder.3.weight: 0.013897518627345562\n",
      "Gradient for decoder.decoder.3.bias: 1.176541780667506e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0006032977835275233\n",
      "Gradient for decoder.decoder.4.bias: 0.0006466459017246962\n",
      "Gradient for decoder.decoder.6.weight: 0.0006191745051182806\n",
      "Gradient for decoder.decoder.6.bias: 4.1739091102499515e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.028505394235253334\n",
      "Gradient for encoder.encoder.0.bias: 4.253005586596359e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0043941680341959\n",
      "Gradient for encoder.encoder.1.bias: 0.0029862644150853157\n",
      "Gradient for encoder.encoder.3.weight: 0.0899842381477356\n",
      "Gradient for encoder.encoder.3.bias: 4.2499198604772914e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.009318914264440536\n",
      "Gradient for encoder.encoder.4.bias: 0.008106771856546402\n",
      "Gradient for encoder.mean.weight: 0.12417717278003693\n",
      "Gradient for encoder.mean.bias: 0.005142585840076208\n",
      "Gradient for encoder.log_var.weight: 0.07623106986284256\n",
      "Gradient for encoder.log_var.bias: 0.0036846771836280823\n",
      "Gradient for decoder.decoder.0.weight: 0.01531301625072956\n",
      "Gradient for decoder.decoder.0.bias: 1.2357910528226768e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0007746730698272586\n",
      "Gradient for decoder.decoder.1.bias: 0.0005879384698346257\n",
      "Gradient for decoder.decoder.3.weight: 0.014005574397742748\n",
      "Gradient for decoder.decoder.3.bias: 1.0238907638404626e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0005372731829993427\n",
      "Gradient for decoder.decoder.4.bias: 0.0005230300012044609\n",
      "Gradient for decoder.decoder.6.weight: 0.0005852883332408965\n",
      "Gradient for decoder.decoder.6.bias: 3.1053255952429026e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.024300482124090195\n",
      "Gradient for encoder.encoder.0.bias: 3.209888257971194e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.002394719747826457\n",
      "Gradient for encoder.encoder.1.bias: 0.0019325645407661796\n",
      "Gradient for encoder.encoder.3.weight: 0.056994810700416565\n",
      "Gradient for encoder.encoder.3.bias: 3.746991883435413e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.009934766218066216\n",
      "Gradient for encoder.encoder.4.bias: 0.007854949682950974\n",
      "Gradient for encoder.mean.weight: 0.12460390478372574\n",
      "Gradient for encoder.mean.bias: 0.004081124905496836\n",
      "Gradient for encoder.log_var.weight: 0.08046320080757141\n",
      "Gradient for encoder.log_var.bias: 0.003106934018433094\n",
      "Gradient for decoder.decoder.0.weight: 0.01929817534983158\n",
      "Gradient for decoder.decoder.0.bias: 1.728085174956817e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0009386256569996476\n",
      "Gradient for decoder.decoder.1.bias: 0.0007365808123722672\n",
      "Gradient for decoder.decoder.3.weight: 0.016840634867548943\n",
      "Gradient for decoder.decoder.3.bias: 1.3020638733873824e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0005676024593412876\n",
      "Gradient for decoder.decoder.4.bias: 0.0005240899627096951\n",
      "Gradient for decoder.decoder.6.weight: 0.0006283718976192176\n",
      "Gradient for decoder.decoder.6.bias: 3.5807232052320614e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.014518748968839645\n",
      "Gradient for encoder.encoder.0.bias: 2.325679232528799e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.002062935149297118\n",
      "Gradient for encoder.encoder.1.bias: 0.0019087016116827726\n",
      "Gradient for encoder.encoder.3.weight: 0.04458688944578171\n",
      "Gradient for encoder.encoder.3.bias: 3.374474311090836e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.007119716610759497\n",
      "Gradient for encoder.encoder.4.bias: 0.0074530248530209064\n",
      "Gradient for encoder.mean.weight: 0.09688292443752289\n",
      "Gradient for encoder.mean.bias: 0.005456516984850168\n",
      "Gradient for encoder.log_var.weight: 0.05772840604186058\n",
      "Gradient for encoder.log_var.bias: 0.0035999349784106016\n",
      "Gradient for decoder.decoder.0.weight: 0.017364269122481346\n",
      "Gradient for decoder.decoder.0.bias: 1.3538474508134613e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0008435592753812671\n",
      "Gradient for decoder.decoder.1.bias: 0.0006747533334419131\n",
      "Gradient for decoder.decoder.3.weight: 0.015304525382816792\n",
      "Gradient for decoder.decoder.3.bias: 1.23581825328678e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0005744902882725\n",
      "Gradient for decoder.decoder.4.bias: 0.0005140555440448225\n",
      "Gradient for decoder.decoder.6.weight: 0.0006390326889231801\n",
      "Gradient for decoder.decoder.6.bias: 3.182694490533322e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.019497498869895935\n",
      "Gradient for encoder.encoder.0.bias: 3.5891352390127196e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0025519963819533587\n",
      "Gradient for encoder.encoder.1.bias: 0.0020121263805776834\n",
      "Gradient for encoder.encoder.3.weight: 0.05235759913921356\n",
      "Gradient for encoder.encoder.3.bias: 2.7698443538781703e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0054202601313591\n",
      "Gradient for encoder.encoder.4.bias: 0.004287426359951496\n",
      "Gradient for encoder.mean.weight: 0.07688304781913757\n",
      "Gradient for encoder.mean.bias: 0.003005468752235174\n",
      "Gradient for encoder.log_var.weight: 0.03828920051455498\n",
      "Gradient for encoder.log_var.bias: 0.0018417065730318427\n",
      "Gradient for decoder.decoder.0.weight: 0.01411818154156208\n",
      "Gradient for decoder.decoder.0.bias: 1.20975826578551e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0007291499641723931\n",
      "Gradient for decoder.decoder.1.bias: 0.0005655699642375112\n",
      "Gradient for decoder.decoder.3.weight: 0.012984737753868103\n",
      "Gradient for decoder.decoder.3.bias: 1.1435725977282374e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.000512928469106555\n",
      "Gradient for decoder.decoder.4.bias: 0.0005089057376608253\n",
      "Gradient for decoder.decoder.6.weight: 0.0005738536128774285\n",
      "Gradient for decoder.decoder.6.bias: 3.05264002236072e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.024464154615998268\n",
      "Gradient for encoder.encoder.0.bias: 4.670229133973969e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.003898654831573367\n",
      "Gradient for encoder.encoder.1.bias: 0.003427596064284444\n",
      "Gradient for encoder.encoder.3.weight: 0.08079423755407333\n",
      "Gradient for encoder.encoder.3.bias: 4.558666499843156e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.009995776228606701\n",
      "Gradient for encoder.encoder.4.bias: 0.010393572971224785\n",
      "Gradient for encoder.mean.weight: 0.13004779815673828\n",
      "Gradient for encoder.mean.bias: 0.00660126656293869\n",
      "Gradient for encoder.log_var.weight: 0.07946600019931793\n",
      "Gradient for encoder.log_var.bias: 0.004577564541250467\n",
      "Gradient for decoder.decoder.0.weight: 0.01262241043150425\n",
      "Gradient for decoder.decoder.0.bias: 1.0896703678264785e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0006537778535857797\n",
      "Gradient for decoder.decoder.1.bias: 0.0004799168964382261\n",
      "Gradient for decoder.decoder.3.weight: 0.011084003373980522\n",
      "Gradient for decoder.decoder.3.bias: 9.829254771220874e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0004981032107025385\n",
      "Gradient for decoder.decoder.4.bias: 0.000539841887075454\n",
      "Gradient for decoder.decoder.6.weight: 0.0005717173917219043\n",
      "Gradient for decoder.decoder.6.bias: 3.366004239069298e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.023930378258228302\n",
      "Gradient for encoder.encoder.0.bias: 2.653276556796591e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0031697433441877365\n",
      "Gradient for encoder.encoder.1.bias: 0.002343496074900031\n",
      "Gradient for encoder.encoder.3.weight: 0.06482936441898346\n",
      "Gradient for encoder.encoder.3.bias: 3.011009497289052e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0070253475569188595\n",
      "Gradient for encoder.encoder.4.bias: 0.00604150490835309\n",
      "Gradient for encoder.mean.weight: 0.09253166615962982\n",
      "Gradient for encoder.mean.bias: 0.003505802247673273\n",
      "Gradient for encoder.log_var.weight: 0.0544300451874733\n",
      "Gradient for encoder.log_var.bias: 0.002547916490584612\n",
      "Gradient for decoder.decoder.0.weight: 0.019297264516353607\n",
      "Gradient for decoder.decoder.0.bias: 1.619951256470742e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0010549949947744608\n",
      "Gradient for decoder.decoder.1.bias: 0.0007751043885946274\n",
      "Gradient for decoder.decoder.3.weight: 0.01815181039273739\n",
      "Gradient for decoder.decoder.3.bias: 1.343097300043894e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0006528449011966586\n",
      "Gradient for decoder.decoder.4.bias: 0.0005701705231331289\n",
      "Gradient for decoder.decoder.6.weight: 0.0006115188589319587\n",
      "Gradient for decoder.decoder.6.bias: 2.883148772525601e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.0585278682410717\n",
      "Gradient for encoder.encoder.0.bias: 1.0052889076739291e-10\n",
      "Gradient for encoder.encoder.1.weight: 0.005153873935341835\n",
      "Gradient for encoder.encoder.1.bias: 0.0038105237763375044\n",
      "Gradient for encoder.encoder.3.weight: 0.1105605885386467\n",
      "Gradient for encoder.encoder.3.bias: 1.0368084168987934e-09\n",
      "Gradient for encoder.encoder.4.weight: 0.01900288090109825\n",
      "Gradient for encoder.encoder.4.bias: 0.021099301055073738\n",
      "Gradient for encoder.mean.weight: 0.23785702884197235\n",
      "Gradient for encoder.mean.bias: 0.012548885308206081\n",
      "Gradient for encoder.log_var.weight: 0.15879395604133606\n",
      "Gradient for encoder.log_var.bias: 0.009394814260303974\n",
      "Gradient for decoder.decoder.0.weight: 0.06473368406295776\n",
      "Gradient for decoder.decoder.0.bias: 4.2321732229844145e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.002646263223141432\n",
      "Gradient for decoder.decoder.1.bias: 0.0022725083399564028\n",
      "Gradient for decoder.decoder.3.weight: 0.05270392447710037\n",
      "Gradient for decoder.decoder.3.bias: 3.538694615112803e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0018490649526938796\n",
      "Gradient for decoder.decoder.4.bias: 0.0015810936456546187\n",
      "Gradient for decoder.decoder.6.weight: 0.0015314968768507242\n",
      "Gradient for decoder.decoder.6.bias: 7.283325248863548e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/3, Train Loss: 0.0682, Val Loss: 0.2720\n",
      "Training VAE for class 3...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training VAE Epoch:  11%|█▏        | 9/79 [00:00<00:01, 35.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient for encoder.encoder.0.weight: 0.022807251662015915\n",
      "Gradient for encoder.encoder.0.bias: 3.415090779612662e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.002752430271357298\n",
      "Gradient for encoder.encoder.1.bias: 0.002069446025416255\n",
      "Gradient for encoder.encoder.3.weight: 0.05293828621506691\n",
      "Gradient for encoder.encoder.3.bias: 3.638200574140882e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.008876697160303593\n",
      "Gradient for encoder.encoder.4.bias: 0.0071664112620055676\n",
      "Gradient for encoder.mean.weight: 0.11460629105567932\n",
      "Gradient for encoder.mean.bias: 0.004641756881028414\n",
      "Gradient for encoder.log_var.weight: 0.06549664586782455\n",
      "Gradient for encoder.log_var.bias: 0.0027670562267303467\n",
      "Gradient for decoder.decoder.0.weight: 0.01646231859922409\n",
      "Gradient for decoder.decoder.0.bias: 1.4443696239041515e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0008644069894216955\n",
      "Gradient for decoder.decoder.1.bias: 0.0006766215083189309\n",
      "Gradient for decoder.decoder.3.weight: 0.014888482168316841\n",
      "Gradient for decoder.decoder.3.bias: 1.2938421167785208e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0007789403898641467\n",
      "Gradient for decoder.decoder.4.bias: 0.0008311732090078294\n",
      "Gradient for decoder.decoder.6.weight: 0.0007817334262654185\n",
      "Gradient for decoder.decoder.6.bias: 5.362698721000925e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.018500080332159996\n",
      "Gradient for encoder.encoder.0.bias: 2.6916311193780906e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.001967343734577298\n",
      "Gradient for encoder.encoder.1.bias: 0.0015139022143557668\n",
      "Gradient for encoder.encoder.3.weight: 0.04061530530452728\n",
      "Gradient for encoder.encoder.3.bias: 3.317639774014225e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.006366013549268246\n",
      "Gradient for encoder.encoder.4.bias: 0.007761454675346613\n",
      "Gradient for encoder.mean.weight: 0.08623223751783371\n",
      "Gradient for encoder.mean.bias: 0.005602320656180382\n",
      "Gradient for encoder.log_var.weight: 0.04599886015057564\n",
      "Gradient for encoder.log_var.bias: 0.0033491067588329315\n",
      "Gradient for decoder.decoder.0.weight: 0.014659243635833263\n",
      "Gradient for decoder.decoder.0.bias: 1.2767624457676874e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.000736547983251512\n",
      "Gradient for decoder.decoder.1.bias: 0.0005870736204087734\n",
      "Gradient for decoder.decoder.3.weight: 0.012809257954359055\n",
      "Gradient for decoder.decoder.3.bias: 1.0318482179805244e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0004909978597424924\n",
      "Gradient for decoder.decoder.4.bias: 0.00046871931408531964\n",
      "Gradient for decoder.decoder.6.weight: 0.0007209780160337687\n",
      "Gradient for decoder.decoder.6.bias: 5.033309571444988e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.021900620311498642\n",
      "Gradient for encoder.encoder.0.bias: 3.178735399900212e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0028144908137619495\n",
      "Gradient for encoder.encoder.1.bias: 0.0024155264254659414\n",
      "Gradient for encoder.encoder.3.weight: 0.060242995619773865\n",
      "Gradient for encoder.encoder.3.bias: 3.659705594127871e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.009214245714247227\n",
      "Gradient for encoder.encoder.4.bias: 0.008926904760301113\n",
      "Gradient for encoder.mean.weight: 0.12286040931940079\n",
      "Gradient for encoder.mean.bias: 0.0048738038167357445\n",
      "Gradient for encoder.log_var.weight: 0.07108460366725922\n",
      "Gradient for encoder.log_var.bias: 0.003254661802202463\n",
      "Gradient for decoder.decoder.0.weight: 0.01529599167406559\n",
      "Gradient for decoder.decoder.0.bias: 1.2367037949267967e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0008274897118099034\n",
      "Gradient for decoder.decoder.1.bias: 0.0005754560115747154\n",
      "Gradient for decoder.decoder.3.weight: 0.014119794592261314\n",
      "Gradient for decoder.decoder.3.bias: 1.387285564202756e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0010902689537033439\n",
      "Gradient for decoder.decoder.4.bias: 0.0012931860983371735\n",
      "Gradient for decoder.decoder.6.weight: 0.000993807683698833\n",
      "Gradient for decoder.decoder.6.bias: 8.259974129032344e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.027243806049227715\n",
      "Gradient for encoder.encoder.0.bias: 3.5166671658037885e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.002405178966000676\n",
      "Gradient for encoder.encoder.1.bias: 0.0023833061568439007\n",
      "Gradient for encoder.encoder.3.weight: 0.055959075689315796\n",
      "Gradient for encoder.encoder.3.bias: 3.5544905907514135e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.007370456587523222\n",
      "Gradient for encoder.encoder.4.bias: 0.007400164380669594\n",
      "Gradient for encoder.mean.weight: 0.09903325140476227\n",
      "Gradient for encoder.mean.bias: 0.005313186440616846\n",
      "Gradient for encoder.log_var.weight: 0.05336185544729233\n",
      "Gradient for encoder.log_var.bias: 0.003348290454596281\n",
      "Gradient for decoder.decoder.0.weight: 0.014672952704131603\n",
      "Gradient for decoder.decoder.0.bias: 1.2805276283778255e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.000789753976278007\n",
      "Gradient for decoder.decoder.1.bias: 0.000603752036113292\n",
      "Gradient for decoder.decoder.3.weight: 0.013316076248884201\n",
      "Gradient for decoder.decoder.3.bias: 1.136002888979526e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0007551517919637263\n",
      "Gradient for decoder.decoder.4.bias: 0.0008574858075007796\n",
      "Gradient for decoder.decoder.6.weight: 0.0007605876307934523\n",
      "Gradient for decoder.decoder.6.bias: 5.265263098408468e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.02306346409022808\n",
      "Gradient for encoder.encoder.0.bias: 4.142227880143956e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0030883941799402237\n",
      "Gradient for encoder.encoder.1.bias: 0.002603783505037427\n",
      "Gradient for encoder.encoder.3.weight: 0.060985106974840164\n",
      "Gradient for encoder.encoder.3.bias: 3.975881568418771e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.009033074602484703\n",
      "Gradient for encoder.encoder.4.bias: 0.009151587262749672\n",
      "Gradient for encoder.mean.weight: 0.12555277347564697\n",
      "Gradient for encoder.mean.bias: 0.006118221674114466\n",
      "Gradient for encoder.log_var.weight: 0.06779449433088303\n",
      "Gradient for encoder.log_var.bias: 0.00349056301638484\n",
      "Gradient for decoder.decoder.0.weight: 0.013740879483520985\n",
      "Gradient for decoder.decoder.0.bias: 1.1558591583860078e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0006461040466092527\n",
      "Gradient for decoder.decoder.1.bias: 0.0005511300405487418\n",
      "Gradient for decoder.decoder.3.weight: 0.012270230799913406\n",
      "Gradient for decoder.decoder.3.bias: 8.736432410838546e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0004915655008517206\n",
      "Gradient for decoder.decoder.4.bias: 0.00042967204353772104\n",
      "Gradient for decoder.decoder.6.weight: 0.0007995723863132298\n",
      "Gradient for decoder.decoder.6.bias: 6.126426887931302e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.026214543730020523\n",
      "Gradient for encoder.encoder.0.bias: 3.631173486895456e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.002873725723475218\n",
      "Gradient for encoder.encoder.1.bias: 0.002205053810030222\n",
      "Gradient for encoder.encoder.3.weight: 0.06273318827152252\n",
      "Gradient for encoder.encoder.3.bias: 3.8212660813385924e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.007184190209954977\n",
      "Gradient for encoder.encoder.4.bias: 0.007048516534268856\n",
      "Gradient for encoder.mean.weight: 0.09658533334732056\n",
      "Gradient for encoder.mean.bias: 0.0040655494667589664\n",
      "Gradient for encoder.log_var.weight: 0.05545685067772865\n",
      "Gradient for encoder.log_var.bias: 0.0025451849214732647\n",
      "Gradient for decoder.decoder.0.weight: 0.015424183569848537\n",
      "Gradient for decoder.decoder.0.bias: 1.3168828527643228e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0007833958370611072\n",
      "Gradient for decoder.decoder.1.bias: 0.000625328510068357\n",
      "Gradient for decoder.decoder.3.weight: 0.014152010902762413\n",
      "Gradient for decoder.decoder.3.bias: 1.0757034152319989e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0005501796258613467\n",
      "Gradient for decoder.decoder.4.bias: 0.0005128016928210855\n",
      "Gradient for decoder.decoder.6.weight: 0.0007470652344636619\n",
      "Gradient for decoder.decoder.6.bias: 5.2650848374469206e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.024760127067565918\n",
      "Gradient for encoder.encoder.0.bias: 3.663976066992092e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.002529089106246829\n",
      "Gradient for encoder.encoder.1.bias: 0.002080905716866255\n",
      "Gradient for encoder.encoder.3.weight: 0.0552702359855175\n",
      "Gradient for encoder.encoder.3.bias: 3.987242203074004e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.007142066489905119\n",
      "Gradient for encoder.encoder.4.bias: 0.006462535355240107\n",
      "Gradient for encoder.mean.weight: 0.09454253315925598\n",
      "Gradient for encoder.mean.bias: 0.004037246573716402\n",
      "Gradient for encoder.log_var.weight: 0.05477767437696457\n",
      "Gradient for encoder.log_var.bias: 0.002640813123434782\n",
      "Gradient for decoder.decoder.0.weight: 0.017565203830599785\n",
      "Gradient for decoder.decoder.0.bias: 1.5033992106783245e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0009301194222643971\n",
      "Gradient for decoder.decoder.1.bias: 0.0006833313382230699\n",
      "Gradient for decoder.decoder.3.weight: 0.014811060391366482\n",
      "Gradient for decoder.decoder.3.bias: 1.4153796190630175e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.000995235051959753\n",
      "Gradient for decoder.decoder.4.bias: 0.0011814057361334562\n",
      "Gradient for decoder.decoder.6.weight: 0.0008941683336161077\n",
      "Gradient for decoder.decoder.6.bias: 7.074580935295671e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.020848702639341354\n",
      "Gradient for encoder.encoder.0.bias: 2.989294922706165e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.002514199586585164\n",
      "Gradient for encoder.encoder.1.bias: 0.0018575694411993027\n",
      "Gradient for encoder.encoder.3.weight: 0.048971258103847504\n",
      "Gradient for encoder.encoder.3.bias: 3.5127636910381455e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.006637694779783487\n",
      "Gradient for encoder.encoder.4.bias: 0.006258700974285603\n",
      "Gradient for encoder.mean.weight: 0.08437252044677734\n",
      "Gradient for encoder.mean.bias: 0.0046768877655267715\n",
      "Gradient for encoder.log_var.weight: 0.05421590432524681\n",
      "Gradient for encoder.log_var.bias: 0.0028578583151102066\n",
      "Gradient for decoder.decoder.0.weight: 0.01662673056125641\n",
      "Gradient for decoder.decoder.0.bias: 1.4217642341218806e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0008447363507002592\n",
      "Gradient for decoder.decoder.1.bias: 0.000653489725664258\n",
      "Gradient for decoder.decoder.3.weight: 0.015382987447082996\n",
      "Gradient for decoder.decoder.3.bias: 1.4402394554746678e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0010416674194857478\n",
      "Gradient for decoder.decoder.4.bias: 0.001101348432712257\n",
      "Gradient for decoder.decoder.6.weight: 0.0008844545809552073\n",
      "Gradient for decoder.decoder.6.bias: 6.210753053892404e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.020646069198846817\n",
      "Gradient for encoder.encoder.0.bias: 3.427088821061908e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0034247669391334057\n",
      "Gradient for encoder.encoder.1.bias: 0.00247177598066628\n",
      "Gradient for encoder.encoder.3.weight: 0.06440075486898422\n",
      "Gradient for encoder.encoder.3.bias: 3.6560443561484135e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.008524102158844471\n",
      "Gradient for encoder.encoder.4.bias: 0.00803200714290142\n",
      "Gradient for encoder.mean.weight: 0.10845022648572922\n",
      "Gradient for encoder.mean.bias: 0.00506061315536499\n",
      "Gradient for encoder.log_var.weight: 0.0628092885017395\n",
      "Gradient for encoder.log_var.bias: 0.0029043168760836124\n",
      "Gradient for decoder.decoder.0.weight: 0.014191837050020695\n",
      "Gradient for decoder.decoder.0.bias: 1.2578511843219786e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.000741633411962539\n",
      "Gradient for decoder.decoder.1.bias: 0.0005691375699825585\n",
      "Gradient for decoder.decoder.3.weight: 0.013013786636292934\n",
      "Gradient for decoder.decoder.3.bias: 1.2333009613563206e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0004464859375730157\n",
      "Gradient for decoder.decoder.4.bias: 0.000396536459447816\n",
      "Gradient for decoder.decoder.6.weight: 0.0006915226695127785\n",
      "Gradient for decoder.decoder.6.bias: 4.4052605517208576e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.021356964483857155\n",
      "Gradient for encoder.encoder.0.bias: 3.173297735692415e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.002654760843142867\n",
      "Gradient for encoder.encoder.1.bias: 0.0023520509712398052\n",
      "Gradient for encoder.encoder.3.weight: 0.05793707072734833\n",
      "Gradient for encoder.encoder.3.bias: 3.3566732726697524e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.009898589923977852\n",
      "Gradient for encoder.encoder.4.bias: 0.007734301500022411\n",
      "Gradient for encoder.mean.weight: 0.13303621113300323\n",
      "Gradient for encoder.mean.bias: 0.004485961981117725\n",
      "Gradient for encoder.log_var.weight: 0.07453051954507828\n",
      "Gradient for encoder.log_var.bias: 0.002847492229193449\n",
      "Gradient for decoder.decoder.0.weight: 0.016010716557502747\n",
      "Gradient for decoder.decoder.0.bias: 1.1852342718388087e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0008321124478243291\n",
      "Gradient for decoder.decoder.1.bias: 0.0006367721944116056\n",
      "Gradient for decoder.decoder.3.weight: 0.014893129467964172\n",
      "Gradient for decoder.decoder.3.bias: 9.981451776219785e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0005401464877650142\n",
      "Gradient for decoder.decoder.4.bias: 0.00047529779840260744\n",
      "Gradient for decoder.decoder.6.weight: 0.0007314913091249764\n",
      "Gradient for decoder.decoder.6.bias: 4.732680463348515e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.023828765377402306\n",
      "Gradient for encoder.encoder.0.bias: 3.4912482627103e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0023233010433614254\n",
      "Gradient for encoder.encoder.1.bias: 0.0021298180799931288\n",
      "Gradient for encoder.encoder.3.weight: 0.04989277571439743\n",
      "Gradient for encoder.encoder.3.bias: 3.376936230647942e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.004933047108352184\n",
      "Gradient for encoder.encoder.4.bias: 0.005632147658616304\n",
      "Gradient for encoder.mean.weight: 0.06265013664960861\n",
      "Gradient for encoder.mean.bias: 0.004238313529640436\n",
      "Gradient for encoder.log_var.weight: 0.04042024165391922\n",
      "Gradient for encoder.log_var.bias: 0.002441565040498972\n",
      "Gradient for decoder.decoder.0.weight: 0.014521650969982147\n",
      "Gradient for decoder.decoder.0.bias: 1.1499275837101308e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0007444790098816156\n",
      "Gradient for decoder.decoder.1.bias: 0.0005587103078141809\n",
      "Gradient for decoder.decoder.3.weight: 0.01276729442179203\n",
      "Gradient for decoder.decoder.3.bias: 1.050464507046378e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.000552772602532059\n",
      "Gradient for decoder.decoder.4.bias: 0.0005922830896452069\n",
      "Gradient for decoder.decoder.6.weight: 0.0007250314811244607\n",
      "Gradient for decoder.decoder.6.bias: 4.686668762587942e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.021571405231952667\n",
      "Gradient for encoder.encoder.0.bias: 3.413370280869188e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.002284182235598564\n",
      "Gradient for encoder.encoder.1.bias: 0.0017504612915217876\n",
      "Gradient for encoder.encoder.3.weight: 0.04567398875951767\n",
      "Gradient for encoder.encoder.3.bias: 3.3461988735439263e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.005306761711835861\n",
      "Gradient for encoder.encoder.4.bias: 0.0053374022245407104\n",
      "Gradient for encoder.mean.weight: 0.07712618261575699\n",
      "Gradient for encoder.mean.bias: 0.0038773026317358017\n",
      "Gradient for encoder.log_var.weight: 0.04215693101286888\n",
      "Gradient for encoder.log_var.bias: 0.002397453412413597\n",
      "Gradient for decoder.decoder.0.weight: 0.015931932255625725\n",
      "Gradient for decoder.decoder.0.bias: 1.3685440281019368e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0007980880327522755\n",
      "Gradient for decoder.decoder.1.bias: 0.00062546506524086\n",
      "Gradient for decoder.decoder.3.weight: 0.013911809772253036\n",
      "Gradient for decoder.decoder.3.bias: 1.3005978238833649e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0006538350717164576\n",
      "Gradient for decoder.decoder.4.bias: 0.0007006128435023129\n",
      "Gradient for decoder.decoder.6.weight: 0.000714518188033253\n",
      "Gradient for decoder.decoder.6.bias: 4.62231801066082e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.023529641330242157\n",
      "Gradient for encoder.encoder.0.bias: 3.784466837131184e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.002018101280555129\n",
      "Gradient for encoder.encoder.1.bias: 0.0016155124176293612\n",
      "Gradient for encoder.encoder.3.weight: 0.04564249888062477\n",
      "Gradient for encoder.encoder.3.bias: 4.005578091437201e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.010166331194341183\n",
      "Gradient for encoder.encoder.4.bias: 0.00870503019541502\n",
      "Gradient for encoder.mean.weight: 0.12993624806404114\n",
      "Gradient for encoder.mean.bias: 0.005758007988333702\n",
      "Gradient for encoder.log_var.weight: 0.07660595327615738\n",
      "Gradient for encoder.log_var.bias: 0.0032123043201863766\n",
      "Gradient for decoder.decoder.0.weight: 0.013719589449465275\n",
      "Gradient for decoder.decoder.0.bias: 1.1275338995808681e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0006900759181007743\n",
      "Gradient for decoder.decoder.1.bias: 0.0004988159635104239\n",
      "Gradient for decoder.decoder.3.weight: 0.012185770086944103\n",
      "Gradient for decoder.decoder.3.bias: 8.760758785086864e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0004282477020751685\n",
      "Gradient for decoder.decoder.4.bias: 0.00039263584767468274\n",
      "Gradient for decoder.decoder.6.weight: 0.0006990653928369284\n",
      "Gradient for decoder.decoder.6.bias: 4.4068954593967646e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.015414183028042316\n",
      "Gradient for encoder.encoder.0.bias: 2.6166626157508865e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0015370342880487442\n",
      "Gradient for encoder.encoder.1.bias: 0.0013770466903224587\n",
      "Gradient for encoder.encoder.3.weight: 0.03643929585814476\n",
      "Gradient for encoder.encoder.3.bias: 3.077760268865859e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.005947949830442667\n",
      "Gradient for encoder.encoder.4.bias: 0.00543486513197422\n",
      "Gradient for encoder.mean.weight: 0.07982984930276871\n",
      "Gradient for encoder.mean.bias: 0.004029166419059038\n",
      "Gradient for encoder.log_var.weight: 0.04569483920931816\n",
      "Gradient for encoder.log_var.bias: 0.0021355499047785997\n",
      "Gradient for decoder.decoder.0.weight: 0.015672024339437485\n",
      "Gradient for decoder.decoder.0.bias: 1.3124971942612973e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0008339418563991785\n",
      "Gradient for decoder.decoder.1.bias: 0.000603534048423171\n",
      "Gradient for decoder.decoder.3.weight: 0.014505099505186081\n",
      "Gradient for decoder.decoder.3.bias: 1.2891229750344735e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.000739061099011451\n",
      "Gradient for decoder.decoder.4.bias: 0.0007796523859724402\n",
      "Gradient for decoder.decoder.6.weight: 0.0008349369745701551\n",
      "Gradient for decoder.decoder.6.bias: 5.959823465673253e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.02587948925793171\n",
      "Gradient for encoder.encoder.0.bias: 4.151286259190812e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.002976713003590703\n",
      "Gradient for encoder.encoder.1.bias: 0.0024838356766849756\n",
      "Gradient for encoder.encoder.3.weight: 0.06323075294494629\n",
      "Gradient for encoder.encoder.3.bias: 4.50058379453111e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.008486862294375896\n",
      "Gradient for encoder.encoder.4.bias: 0.008284230716526508\n",
      "Gradient for encoder.mean.weight: 0.10847130417823792\n",
      "Gradient for encoder.mean.bias: 0.005545877385884523\n",
      "Gradient for encoder.log_var.weight: 0.06502170115709305\n",
      "Gradient for encoder.log_var.bias: 0.0031042329501360655\n",
      "Gradient for decoder.decoder.0.weight: 0.01492972020059824\n",
      "Gradient for decoder.decoder.0.bias: 1.2732430387796256e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0007152262260206044\n",
      "Gradient for decoder.decoder.1.bias: 0.0005568848573602736\n",
      "Gradient for decoder.decoder.3.weight: 0.013271698728203773\n",
      "Gradient for decoder.decoder.3.bias: 8.944661678000898e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00047359184827655554\n",
      "Gradient for decoder.decoder.4.bias: 0.0004231888451613486\n",
      "Gradient for decoder.decoder.6.weight: 0.0006961566396057606\n",
      "Gradient for decoder.decoder.6.bias: 4.436545350472443e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.018012817949056625\n",
      "Gradient for encoder.encoder.0.bias: 2.6858515411731787e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0018385956063866615\n",
      "Gradient for encoder.encoder.1.bias: 0.0016682089772075415\n",
      "Gradient for encoder.encoder.3.weight: 0.040486425161361694\n",
      "Gradient for encoder.encoder.3.bias: 3.690458494354232e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.006800081580877304\n",
      "Gradient for encoder.encoder.4.bias: 0.006330305244773626\n",
      "Gradient for encoder.mean.weight: 0.08756901323795319\n",
      "Gradient for encoder.mean.bias: 0.004070628434419632\n",
      "Gradient for encoder.log_var.weight: 0.05520135909318924\n",
      "Gradient for encoder.log_var.bias: 0.0020068951416760683\n",
      "Gradient for decoder.decoder.0.weight: 0.01619061827659607\n",
      "Gradient for decoder.decoder.0.bias: 1.3387721486957105e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0008982425206340849\n",
      "Gradient for decoder.decoder.1.bias: 0.000630359398201108\n",
      "Gradient for decoder.decoder.3.weight: 0.014838618226349354\n",
      "Gradient for decoder.decoder.3.bias: 1.2393533421750647e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0006467315834015608\n",
      "Gradient for decoder.decoder.4.bias: 0.000570056086871773\n",
      "Gradient for decoder.decoder.6.weight: 0.0007952135056257248\n",
      "Gradient for decoder.decoder.6.bias: 5.526042150449939e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training VAE Epoch:  32%|███▏      | 25/79 [00:00<00:00, 59.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient for encoder.encoder.0.weight: 0.019179567694664\n",
      "Gradient for encoder.encoder.0.bias: 3.3364280088710174e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.002234848914667964\n",
      "Gradient for encoder.encoder.1.bias: 0.0020922718103975058\n",
      "Gradient for encoder.encoder.3.weight: 0.04822926968336105\n",
      "Gradient for encoder.encoder.3.bias: 3.5575864476555807e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.006843269802629948\n",
      "Gradient for encoder.encoder.4.bias: 0.0068259998224675655\n",
      "Gradient for encoder.mean.weight: 0.0851820632815361\n",
      "Gradient for encoder.mean.bias: 0.004662964027374983\n",
      "Gradient for encoder.log_var.weight: 0.055197663605213165\n",
      "Gradient for encoder.log_var.bias: 0.002285150345414877\n",
      "Gradient for decoder.decoder.0.weight: 0.01458796113729477\n",
      "Gradient for decoder.decoder.0.bias: 1.2530972093305337e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0007715873653069139\n",
      "Gradient for decoder.decoder.1.bias: 0.0005826753913424909\n",
      "Gradient for decoder.decoder.3.weight: 0.013255116529762745\n",
      "Gradient for decoder.decoder.3.bias: 9.462564759532555e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0005103516741655767\n",
      "Gradient for decoder.decoder.4.bias: 0.0004434535512700677\n",
      "Gradient for decoder.decoder.6.weight: 0.0007769163930788636\n",
      "Gradient for decoder.decoder.6.bias: 5.84004374104552e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.01930040493607521\n",
      "Gradient for encoder.encoder.0.bias: 3.049988386849556e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.003089804667979479\n",
      "Gradient for encoder.encoder.1.bias: 0.0023887932766228914\n",
      "Gradient for encoder.encoder.3.weight: 0.061410412192344666\n",
      "Gradient for encoder.encoder.3.bias: 3.7181033252231543e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.009259716607630253\n",
      "Gradient for encoder.encoder.4.bias: 0.009038574062287807\n",
      "Gradient for encoder.mean.weight: 0.12863333523273468\n",
      "Gradient for encoder.mean.bias: 0.005959867034107447\n",
      "Gradient for encoder.log_var.weight: 0.06385327875614166\n",
      "Gradient for encoder.log_var.bias: 0.0035026499535888433\n",
      "Gradient for decoder.decoder.0.weight: 0.01688857190310955\n",
      "Gradient for decoder.decoder.0.bias: 1.3873539816966485e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0008392938179895282\n",
      "Gradient for decoder.decoder.1.bias: 0.0006237613852135837\n",
      "Gradient for decoder.decoder.3.weight: 0.015491875819861889\n",
      "Gradient for decoder.decoder.3.bias: 1.2682581373990587e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0006548599922098219\n",
      "Gradient for decoder.decoder.4.bias: 0.0006777627277188003\n",
      "Gradient for decoder.decoder.6.weight: 0.0008360407082363963\n",
      "Gradient for decoder.decoder.6.bias: 6.0106143791927025e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.025613151490688324\n",
      "Gradient for encoder.encoder.0.bias: 4.017730939609443e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0031378453131765127\n",
      "Gradient for encoder.encoder.1.bias: 0.002530967816710472\n",
      "Gradient for encoder.encoder.3.weight: 0.06530152261257172\n",
      "Gradient for encoder.encoder.3.bias: 4.212914461731998e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.008635605685412884\n",
      "Gradient for encoder.encoder.4.bias: 0.007247771602123976\n",
      "Gradient for encoder.mean.weight: 0.12213696539402008\n",
      "Gradient for encoder.mean.bias: 0.00433694152161479\n",
      "Gradient for encoder.log_var.weight: 0.06474617123603821\n",
      "Gradient for encoder.log_var.bias: 0.0022623685654252768\n",
      "Gradient for decoder.decoder.0.weight: 0.014069796539843082\n",
      "Gradient for decoder.decoder.0.bias: 1.1604558286526512e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0007907793042249978\n",
      "Gradient for decoder.decoder.1.bias: 0.0005550215137191117\n",
      "Gradient for decoder.decoder.3.weight: 0.012466480024158955\n",
      "Gradient for decoder.decoder.3.bias: 1.0512805903584166e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0005792564479634166\n",
      "Gradient for decoder.decoder.4.bias: 0.0006489986553788185\n",
      "Gradient for decoder.decoder.6.weight: 0.0006924853078089654\n",
      "Gradient for decoder.decoder.6.bias: 4.7930687287589535e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.019263429567217827\n",
      "Gradient for encoder.encoder.0.bias: 2.766724523095565e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0022375439293682575\n",
      "Gradient for encoder.encoder.1.bias: 0.0017974195070564747\n",
      "Gradient for encoder.encoder.3.weight: 0.0486612394452095\n",
      "Gradient for encoder.encoder.3.bias: 3.943785298332614e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.008370650932192802\n",
      "Gradient for encoder.encoder.4.bias: 0.008725935593247414\n",
      "Gradient for encoder.mean.weight: 0.115759938955307\n",
      "Gradient for encoder.mean.bias: 0.005911518353968859\n",
      "Gradient for encoder.log_var.weight: 0.06651479005813599\n",
      "Gradient for encoder.log_var.bias: 0.003750633215531707\n",
      "Gradient for decoder.decoder.0.weight: 0.014592686668038368\n",
      "Gradient for decoder.decoder.0.bias: 1.1870768257260522e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0007827009540051222\n",
      "Gradient for decoder.decoder.1.bias: 0.0005630140658468008\n",
      "Gradient for decoder.decoder.3.weight: 0.012949429452419281\n",
      "Gradient for decoder.decoder.3.bias: 1.0776048803284866e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0005115689127705991\n",
      "Gradient for decoder.decoder.4.bias: 0.0004701454599853605\n",
      "Gradient for decoder.decoder.6.weight: 0.0007007368840277195\n",
      "Gradient for decoder.decoder.6.bias: 4.11440669267904e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.018058013170957565\n",
      "Gradient for encoder.encoder.0.bias: 3.073643423112671e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0021393008064478636\n",
      "Gradient for encoder.encoder.1.bias: 0.0021733364555984735\n",
      "Gradient for encoder.encoder.3.weight: 0.04519586265087128\n",
      "Gradient for encoder.encoder.3.bias: 3.969790607349921e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.007164918817579746\n",
      "Gradient for encoder.encoder.4.bias: 0.008495396003127098\n",
      "Gradient for encoder.mean.weight: 0.10025135427713394\n",
      "Gradient for encoder.mean.bias: 0.006519673857837915\n",
      "Gradient for encoder.log_var.weight: 0.05798271298408508\n",
      "Gradient for encoder.log_var.bias: 0.004226111341267824\n",
      "Gradient for decoder.decoder.0.weight: 0.015671147033572197\n",
      "Gradient for decoder.decoder.0.bias: 1.1439658942347108e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0007995247724466026\n",
      "Gradient for decoder.decoder.1.bias: 0.0006165355443954468\n",
      "Gradient for decoder.decoder.3.weight: 0.01390128955245018\n",
      "Gradient for decoder.decoder.3.bias: 9.952508261967807e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0004980526282452047\n",
      "Gradient for decoder.decoder.4.bias: 0.0004807790392078459\n",
      "Gradient for decoder.decoder.6.weight: 0.0006681954255327582\n",
      "Gradient for decoder.decoder.6.bias: 3.794658914557658e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.020464319735765457\n",
      "Gradient for encoder.encoder.0.bias: 3.313003343885512e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0015482850139960647\n",
      "Gradient for encoder.encoder.1.bias: 0.0015362950507551432\n",
      "Gradient for encoder.encoder.3.weight: 0.0333331860601902\n",
      "Gradient for encoder.encoder.3.bias: 3.242163759686889e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.004649501759558916\n",
      "Gradient for encoder.encoder.4.bias: 0.0045982711017131805\n",
      "Gradient for encoder.mean.weight: 0.06246988847851753\n",
      "Gradient for encoder.mean.bias: 0.003725989256054163\n",
      "Gradient for encoder.log_var.weight: 0.032560259103775024\n",
      "Gradient for encoder.log_var.bias: 0.0020497303921729326\n",
      "Gradient for decoder.decoder.0.weight: 0.012777754105627537\n",
      "Gradient for decoder.decoder.0.bias: 1.1500737168157471e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0006755614303983748\n",
      "Gradient for decoder.decoder.1.bias: 0.0005300620687194169\n",
      "Gradient for decoder.decoder.3.weight: 0.011912424117326736\n",
      "Gradient for decoder.decoder.3.bias: 1.0274327916226511e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.00045129473437555134\n",
      "Gradient for decoder.decoder.4.bias: 0.00040071437251754105\n",
      "Gradient for decoder.decoder.6.weight: 0.0007603050908073783\n",
      "Gradient for decoder.decoder.6.bias: 5.270569454296492e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.01606874167919159\n",
      "Gradient for encoder.encoder.0.bias: 2.4871030582240827e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.001986465882509947\n",
      "Gradient for encoder.encoder.1.bias: 0.001543527003377676\n",
      "Gradient for encoder.encoder.3.weight: 0.03830084204673767\n",
      "Gradient for encoder.encoder.3.bias: 2.7462071505723884e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.005182354245334864\n",
      "Gradient for encoder.encoder.4.bias: 0.0051514278165996075\n",
      "Gradient for encoder.mean.weight: 0.07492935657501221\n",
      "Gradient for encoder.mean.bias: 0.004063330125063658\n",
      "Gradient for encoder.log_var.weight: 0.044250015169382095\n",
      "Gradient for encoder.log_var.bias: 0.0027077440172433853\n",
      "Gradient for decoder.decoder.0.weight: 0.016817599534988403\n",
      "Gradient for decoder.decoder.0.bias: 1.3701843826208204e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0008408203721046448\n",
      "Gradient for decoder.decoder.1.bias: 0.0006597602041438222\n",
      "Gradient for decoder.decoder.3.weight: 0.015119923278689384\n",
      "Gradient for decoder.decoder.3.bias: 1.1346949074786394e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0005206549540162086\n",
      "Gradient for decoder.decoder.4.bias: 0.000461876712506637\n",
      "Gradient for decoder.decoder.6.weight: 0.0007051583961583674\n",
      "Gradient for decoder.decoder.6.bias: 3.529528112267144e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.01535060629248619\n",
      "Gradient for encoder.encoder.0.bias: 2.7708717265095828e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0023102134000509977\n",
      "Gradient for encoder.encoder.1.bias: 0.0018812681082636118\n",
      "Gradient for encoder.encoder.3.weight: 0.04815452918410301\n",
      "Gradient for encoder.encoder.3.bias: 3.854760954880021e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.008214390836656094\n",
      "Gradient for encoder.encoder.4.bias: 0.0074787563644349575\n",
      "Gradient for encoder.mean.weight: 0.10303641110658646\n",
      "Gradient for encoder.mean.bias: 0.005017820745706558\n",
      "Gradient for encoder.log_var.weight: 0.06919480860233307\n",
      "Gradient for encoder.log_var.bias: 0.0031726553570479155\n",
      "Gradient for decoder.decoder.0.weight: 0.014363867230713367\n",
      "Gradient for decoder.decoder.0.bias: 1.225072127075677e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0007075995672494173\n",
      "Gradient for decoder.decoder.1.bias: 0.000602757791057229\n",
      "Gradient for decoder.decoder.3.weight: 0.012377005070447922\n",
      "Gradient for decoder.decoder.3.bias: 1.056964238355107e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0004952591261826456\n",
      "Gradient for decoder.decoder.4.bias: 0.0004754900000989437\n",
      "Gradient for decoder.decoder.6.weight: 0.0007344013429246843\n",
      "Gradient for decoder.decoder.6.bias: 4.44500328740105e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.01717204600572586\n",
      "Gradient for encoder.encoder.0.bias: 2.467253137905523e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0016870411345735192\n",
      "Gradient for encoder.encoder.1.bias: 0.0013929930282756686\n",
      "Gradient for encoder.encoder.3.weight: 0.0361567959189415\n",
      "Gradient for encoder.encoder.3.bias: 2.417884781280577e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.005094679072499275\n",
      "Gradient for encoder.encoder.4.bias: 0.004294455982744694\n",
      "Gradient for encoder.mean.weight: 0.07256175577640533\n",
      "Gradient for encoder.mean.bias: 0.0037073444109410048\n",
      "Gradient for encoder.log_var.weight: 0.046946246176958084\n",
      "Gradient for encoder.log_var.bias: 0.002459567738696933\n",
      "Gradient for decoder.decoder.0.weight: 0.015337151475250721\n",
      "Gradient for decoder.decoder.0.bias: 1.256617587763742e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0007440518820658326\n",
      "Gradient for decoder.decoder.1.bias: 0.0006044028559699655\n",
      "Gradient for decoder.decoder.3.weight: 0.013838308863341808\n",
      "Gradient for decoder.decoder.3.bias: 1.0589744359190689e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0004790989332832396\n",
      "Gradient for decoder.decoder.4.bias: 0.0004054296587128192\n",
      "Gradient for decoder.decoder.6.weight: 0.000683279475197196\n",
      "Gradient for decoder.decoder.6.bias: 3.438604835537262e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.02313048392534256\n",
      "Gradient for encoder.encoder.0.bias: 3.818834137803151e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.002929731970652938\n",
      "Gradient for encoder.encoder.1.bias: 0.002157412702217698\n",
      "Gradient for encoder.encoder.3.weight: 0.05865832418203354\n",
      "Gradient for encoder.encoder.3.bias: 3.511529955702031e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.00950978696346283\n",
      "Gradient for encoder.encoder.4.bias: 0.007710755802690983\n",
      "Gradient for encoder.mean.weight: 0.1306062787771225\n",
      "Gradient for encoder.mean.bias: 0.003855123883113265\n",
      "Gradient for encoder.log_var.weight: 0.06714542210102081\n",
      "Gradient for encoder.log_var.bias: 0.002441799035295844\n",
      "Gradient for decoder.decoder.0.weight: 0.012805424630641937\n",
      "Gradient for decoder.decoder.0.bias: 1.0593295685090709e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.000663492945022881\n",
      "Gradient for decoder.decoder.1.bias: 0.0005487407906912267\n",
      "Gradient for decoder.decoder.3.weight: 0.011767992749810219\n",
      "Gradient for decoder.decoder.3.bias: 1.0412454232167079e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0005514337681233883\n",
      "Gradient for decoder.decoder.4.bias: 0.0005758245242759585\n",
      "Gradient for decoder.decoder.6.weight: 0.0008497342350892723\n",
      "Gradient for decoder.decoder.6.bias: 7.132365863071755e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.019767722114920616\n",
      "Gradient for encoder.encoder.0.bias: 3.2712253045241724e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.001975961495190859\n",
      "Gradient for encoder.encoder.1.bias: 0.0016833863919600844\n",
      "Gradient for encoder.encoder.3.weight: 0.044663138687610626\n",
      "Gradient for encoder.encoder.3.bias: 2.7360119725372556e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.004752687178552151\n",
      "Gradient for encoder.encoder.4.bias: 0.005270596127957106\n",
      "Gradient for encoder.mean.weight: 0.0668816938996315\n",
      "Gradient for encoder.mean.bias: 0.003923105541616678\n",
      "Gradient for encoder.log_var.weight: 0.042290862649679184\n",
      "Gradient for encoder.log_var.bias: 0.0026463200338184834\n",
      "Gradient for decoder.decoder.0.weight: 0.013728739693760872\n",
      "Gradient for decoder.decoder.0.bias: 1.1116643022779371e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0007327839848585427\n",
      "Gradient for decoder.decoder.1.bias: 0.0005223982152529061\n",
      "Gradient for decoder.decoder.3.weight: 0.012081759981811047\n",
      "Gradient for decoder.decoder.3.bias: 9.779143467225637e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0004759251023642719\n",
      "Gradient for decoder.decoder.4.bias: 0.0005147432675585151\n",
      "Gradient for decoder.decoder.6.weight: 0.0007057840120978653\n",
      "Gradient for decoder.decoder.6.bias: 4.7693865781184286e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.02623753249645233\n",
      "Gradient for encoder.encoder.0.bias: 5.095066729632336e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.003204906592145562\n",
      "Gradient for encoder.encoder.1.bias: 0.0027315043844282627\n",
      "Gradient for encoder.encoder.3.weight: 0.06600180268287659\n",
      "Gradient for encoder.encoder.3.bias: 3.9305325660876633e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0067169442772865295\n",
      "Gradient for encoder.encoder.4.bias: 0.005887626204639673\n",
      "Gradient for encoder.mean.weight: 0.08793401718139648\n",
      "Gradient for encoder.mean.bias: 0.003585446858778596\n",
      "Gradient for encoder.log_var.weight: 0.05275046080350876\n",
      "Gradient for encoder.log_var.bias: 0.002644628519192338\n",
      "Gradient for decoder.decoder.0.weight: 0.014420533552765846\n",
      "Gradient for decoder.decoder.0.bias: 1.3292422718080843e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0007313835667446256\n",
      "Gradient for decoder.decoder.1.bias: 0.0005889250314794481\n",
      "Gradient for decoder.decoder.3.weight: 0.012922041118144989\n",
      "Gradient for decoder.decoder.3.bias: 9.880615770008205e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.000543752743396908\n",
      "Gradient for decoder.decoder.4.bias: 0.0005704227369278669\n",
      "Gradient for decoder.decoder.6.weight: 0.0006818136316724122\n",
      "Gradient for decoder.decoder.6.bias: 4.584030102705583e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.017209691926836967\n",
      "Gradient for encoder.encoder.0.bias: 2.6602416450249855e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0019826136995106936\n",
      "Gradient for encoder.encoder.1.bias: 0.0015657924814149737\n",
      "Gradient for encoder.encoder.3.weight: 0.04322485625743866\n",
      "Gradient for encoder.encoder.3.bias: 3.4386907210581796e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.009385437704622746\n",
      "Gradient for encoder.encoder.4.bias: 0.00732265692204237\n",
      "Gradient for encoder.mean.weight: 0.12788136303424835\n",
      "Gradient for encoder.mean.bias: 0.0034335358068346977\n",
      "Gradient for encoder.log_var.weight: 0.07039831578731537\n",
      "Gradient for encoder.log_var.bias: 0.002009394345805049\n",
      "Gradient for decoder.decoder.0.weight: 0.016513215377926826\n",
      "Gradient for decoder.decoder.0.bias: 1.3735873549691746e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0008416231721639633\n",
      "Gradient for decoder.decoder.1.bias: 0.0006369939655996859\n",
      "Gradient for decoder.decoder.3.weight: 0.014617826789617538\n",
      "Gradient for decoder.decoder.3.bias: 1.3087740613482168e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0007852124981582165\n",
      "Gradient for decoder.decoder.4.bias: 0.0008623846806585789\n",
      "Gradient for decoder.decoder.6.weight: 0.0008795422036200762\n",
      "Gradient for decoder.decoder.6.bias: 6.307871808530763e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.020333990454673767\n",
      "Gradient for encoder.encoder.0.bias: 3.0095786973660665e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0018950346857309341\n",
      "Gradient for encoder.encoder.1.bias: 0.0016163394320756197\n",
      "Gradient for encoder.encoder.3.weight: 0.04275527596473694\n",
      "Gradient for encoder.encoder.3.bias: 3.0288402341760445e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.005516751203685999\n",
      "Gradient for encoder.encoder.4.bias: 0.004906936082988977\n",
      "Gradient for encoder.mean.weight: 0.0737498477101326\n",
      "Gradient for encoder.mean.bias: 0.0032804247457534075\n",
      "Gradient for encoder.log_var.weight: 0.04196954891085625\n",
      "Gradient for encoder.log_var.bias: 0.0018886892357841134\n",
      "Gradient for decoder.decoder.0.weight: 0.013599565252661705\n",
      "Gradient for decoder.decoder.0.bias: 1.1634380264746724e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0006993996794335544\n",
      "Gradient for decoder.decoder.1.bias: 0.0005383002571761608\n",
      "Gradient for decoder.decoder.3.weight: 0.012308943085372448\n",
      "Gradient for decoder.decoder.3.bias: 9.397851941095325e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0004253314982634038\n",
      "Gradient for decoder.decoder.4.bias: 0.0003710328892339021\n",
      "Gradient for decoder.decoder.6.weight: 0.0007010708213783801\n",
      "Gradient for decoder.decoder.6.bias: 3.982047928730026e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.018081113696098328\n",
      "Gradient for encoder.encoder.0.bias: 2.7529239304824316e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.001574214082211256\n",
      "Gradient for encoder.encoder.1.bias: 0.0013683532597497106\n",
      "Gradient for encoder.encoder.3.weight: 0.035885367542505264\n",
      "Gradient for encoder.encoder.3.bias: 3.1719499249405203e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.005741043481975794\n",
      "Gradient for encoder.encoder.4.bias: 0.005439624190330505\n",
      "Gradient for encoder.mean.weight: 0.07945452630519867\n",
      "Gradient for encoder.mean.bias: 0.004113106057047844\n",
      "Gradient for encoder.log_var.weight: 0.051339466124773026\n",
      "Gradient for encoder.log_var.bias: 0.0025728356558829546\n",
      "Gradient for decoder.decoder.0.weight: 0.015494666062295437\n",
      "Gradient for decoder.decoder.0.bias: 1.2496265133776774e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0007895621820352972\n",
      "Gradient for decoder.decoder.1.bias: 0.0005993316299282014\n",
      "Gradient for decoder.decoder.3.weight: 0.014227570034563541\n",
      "Gradient for decoder.decoder.3.bias: 1.0639533004619395e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0005162269808351994\n",
      "Gradient for decoder.decoder.4.bias: 0.0004892923752777278\n",
      "Gradient for decoder.decoder.6.weight: 0.0007018329342827201\n",
      "Gradient for decoder.decoder.6.bias: 3.929598824470304e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.02257578633725643\n",
      "Gradient for encoder.encoder.0.bias: 3.199913251039632e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0018784713465720415\n",
      "Gradient for encoder.encoder.1.bias: 0.0016231652116402984\n",
      "Gradient for encoder.encoder.3.weight: 0.04168231412768364\n",
      "Gradient for encoder.encoder.3.bias: 3.717706420491851e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.009447731077671051\n",
      "Gradient for encoder.encoder.4.bias: 0.007402557879686356\n",
      "Gradient for encoder.mean.weight: 0.1218590959906578\n",
      "Gradient for encoder.mean.bias: 0.003869115374982357\n",
      "Gradient for encoder.log_var.weight: 0.0821898877620697\n",
      "Gradient for encoder.log_var.bias: 0.00245643244124949\n",
      "Gradient for decoder.decoder.0.weight: 0.018918931484222412\n",
      "Gradient for decoder.decoder.0.bias: 1.6789256096494398e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0009766806615516543\n",
      "Gradient for decoder.decoder.1.bias: 0.0007337617571465671\n",
      "Gradient for decoder.decoder.3.weight: 0.016773616895079613\n",
      "Gradient for decoder.decoder.3.bias: 1.326368320730964e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0007286797044798732\n",
      "Gradient for decoder.decoder.4.bias: 0.0007115714251995087\n",
      "Gradient for decoder.decoder.6.weight: 0.0008406472043134272\n",
      "Gradient for decoder.decoder.6.bias: 5.3417650633491576e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training VAE Epoch:  52%|█████▏    | 41/79 [00:00<00:00, 69.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient for encoder.encoder.0.weight: 0.029298432171344757\n",
      "Gradient for encoder.encoder.0.bias: 5.873017350221943e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0036649294197559357\n",
      "Gradient for encoder.encoder.1.bias: 0.0029020258225500584\n",
      "Gradient for encoder.encoder.3.weight: 0.07564383745193481\n",
      "Gradient for encoder.encoder.3.bias: 4.4084752515161085e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.010238687507808208\n",
      "Gradient for encoder.encoder.4.bias: 0.009069258347153664\n",
      "Gradient for encoder.mean.weight: 0.13696204125881195\n",
      "Gradient for encoder.mean.bias: 0.004944990389049053\n",
      "Gradient for encoder.log_var.weight: 0.07351507991552353\n",
      "Gradient for encoder.log_var.bias: 0.0029244606848806143\n",
      "Gradient for decoder.decoder.0.weight: 0.010530543513596058\n",
      "Gradient for decoder.decoder.0.bias: 8.840590065561926e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005574996466748416\n",
      "Gradient for decoder.decoder.1.bias: 0.0004116976633667946\n",
      "Gradient for decoder.decoder.3.weight: 0.009347413666546345\n",
      "Gradient for decoder.decoder.3.bias: 7.201547691515486e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00035242107696831226\n",
      "Gradient for decoder.decoder.4.bias: 0.0003476398705970496\n",
      "Gradient for decoder.decoder.6.weight: 0.0007308663334697485\n",
      "Gradient for decoder.decoder.6.bias: 5.207536378293298e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.013846216723322868\n",
      "Gradient for encoder.encoder.0.bias: 2.178037784850151e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0014453365001827478\n",
      "Gradient for encoder.encoder.1.bias: 0.0014166826149448752\n",
      "Gradient for encoder.encoder.3.weight: 0.030164146795868874\n",
      "Gradient for encoder.encoder.3.bias: 3.3129982091040233e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.005314603913575411\n",
      "Gradient for encoder.encoder.4.bias: 0.006788125727325678\n",
      "Gradient for encoder.mean.weight: 0.0762350931763649\n",
      "Gradient for encoder.mean.bias: 0.005706318654119968\n",
      "Gradient for encoder.log_var.weight: 0.044696833938360214\n",
      "Gradient for encoder.log_var.bias: 0.00363244884647429\n",
      "Gradient for decoder.decoder.0.weight: 0.015871787443757057\n",
      "Gradient for decoder.decoder.0.bias: 1.2708031849051338e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0008083358989097178\n",
      "Gradient for decoder.decoder.1.bias: 0.0006152280839160085\n",
      "Gradient for decoder.decoder.3.weight: 0.014964062720537186\n",
      "Gradient for decoder.decoder.3.bias: 1.2199991017425305e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0005355760804377496\n",
      "Gradient for decoder.decoder.4.bias: 0.0004942970699630678\n",
      "Gradient for decoder.decoder.6.weight: 0.0006680756341665983\n",
      "Gradient for decoder.decoder.6.bias: 3.32342206093017e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.018149783834815025\n",
      "Gradient for encoder.encoder.0.bias: 2.6553681128915763e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0016691327327862382\n",
      "Gradient for encoder.encoder.1.bias: 0.001390838180668652\n",
      "Gradient for encoder.encoder.3.weight: 0.03565420210361481\n",
      "Gradient for encoder.encoder.3.bias: 2.5920460222650377e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.004104806575924158\n",
      "Gradient for encoder.encoder.4.bias: 0.004115124698728323\n",
      "Gradient for encoder.mean.weight: 0.05907647684216499\n",
      "Gradient for encoder.mean.bias: 0.0031097251921892166\n",
      "Gradient for encoder.log_var.weight: 0.037928368896245956\n",
      "Gradient for encoder.log_var.bias: 0.0018166354857385159\n",
      "Gradient for decoder.decoder.0.weight: 0.01568990759551525\n",
      "Gradient for decoder.decoder.0.bias: 1.2559370210496468e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0008336292230524123\n",
      "Gradient for decoder.decoder.1.bias: 0.0006802111165598035\n",
      "Gradient for decoder.decoder.3.weight: 0.01463318895548582\n",
      "Gradient for decoder.decoder.3.bias: 1.1025923923879688e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0006058037397451699\n",
      "Gradient for decoder.decoder.4.bias: 0.0006255560438148677\n",
      "Gradient for decoder.decoder.6.weight: 0.0007514083990827203\n",
      "Gradient for decoder.decoder.6.bias: 4.6929715608712286e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.018263516947627068\n",
      "Gradient for encoder.encoder.0.bias: 2.8942334640014167e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0019136103801429272\n",
      "Gradient for encoder.encoder.1.bias: 0.0015884054591879249\n",
      "Gradient for encoder.encoder.3.weight: 0.041652485728263855\n",
      "Gradient for encoder.encoder.3.bias: 2.765942475058125e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0053082662634551525\n",
      "Gradient for encoder.encoder.4.bias: 0.00435378635302186\n",
      "Gradient for encoder.mean.weight: 0.07054603099822998\n",
      "Gradient for encoder.mean.bias: 0.0029326239600777626\n",
      "Gradient for encoder.log_var.weight: 0.04367809370160103\n",
      "Gradient for encoder.log_var.bias: 0.0017132082721218467\n",
      "Gradient for decoder.decoder.0.weight: 0.014057143591344357\n",
      "Gradient for decoder.decoder.0.bias: 1.3496193052020544e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0007499234634451568\n",
      "Gradient for decoder.decoder.1.bias: 0.0005558982375077903\n",
      "Gradient for decoder.decoder.3.weight: 0.01272629015147686\n",
      "Gradient for decoder.decoder.3.bias: 1.366672747193931e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0005611506057903171\n",
      "Gradient for decoder.decoder.4.bias: 0.000615496828686446\n",
      "Gradient for decoder.decoder.6.weight: 0.0006974275456741452\n",
      "Gradient for decoder.decoder.6.bias: 4.3886499042855576e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.027159735560417175\n",
      "Gradient for encoder.encoder.0.bias: 4.472609088645996e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.003382657887414098\n",
      "Gradient for encoder.encoder.1.bias: 0.0025029710959643126\n",
      "Gradient for encoder.encoder.3.weight: 0.07190379500389099\n",
      "Gradient for encoder.encoder.3.bias: 3.5664030062498853e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.008287993259727955\n",
      "Gradient for encoder.encoder.4.bias: 0.006699221208691597\n",
      "Gradient for encoder.mean.weight: 0.11645753681659698\n",
      "Gradient for encoder.mean.bias: 0.0034104259684681892\n",
      "Gradient for encoder.log_var.weight: 0.0648629292845726\n",
      "Gradient for encoder.log_var.bias: 0.001999368891119957\n",
      "Gradient for decoder.decoder.0.weight: 0.012734539806842804\n",
      "Gradient for decoder.decoder.0.bias: 1.0527610033728152e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0006577059393748641\n",
      "Gradient for decoder.decoder.1.bias: 0.00048797010094858706\n",
      "Gradient for decoder.decoder.3.weight: 0.011563924141228199\n",
      "Gradient for decoder.decoder.3.bias: 8.760139141861245e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0005082804127596319\n",
      "Gradient for decoder.decoder.4.bias: 0.0005303723155520856\n",
      "Gradient for decoder.decoder.6.weight: 0.0007121488451957703\n",
      "Gradient for decoder.decoder.6.bias: 4.381610415293835e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.01849803514778614\n",
      "Gradient for encoder.encoder.0.bias: 2.810442850664785e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0017602193402126431\n",
      "Gradient for encoder.encoder.1.bias: 0.001547719002701342\n",
      "Gradient for encoder.encoder.3.weight: 0.03634519875049591\n",
      "Gradient for encoder.encoder.3.bias: 2.5948199144920636e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.005403971765190363\n",
      "Gradient for encoder.encoder.4.bias: 0.004941078368574381\n",
      "Gradient for encoder.mean.weight: 0.07134086638689041\n",
      "Gradient for encoder.mean.bias: 0.0033941848669201136\n",
      "Gradient for encoder.log_var.weight: 0.04173499345779419\n",
      "Gradient for encoder.log_var.bias: 0.0018800752004608512\n",
      "Gradient for decoder.decoder.0.weight: 0.014571509324014187\n",
      "Gradient for decoder.decoder.0.bias: 1.2864252718625124e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0007450053817592561\n",
      "Gradient for decoder.decoder.1.bias: 0.0006061972235329449\n",
      "Gradient for decoder.decoder.3.weight: 0.012912685051560402\n",
      "Gradient for decoder.decoder.3.bias: 1.1304136793288677e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.000614114454947412\n",
      "Gradient for decoder.decoder.4.bias: 0.0006296273786574602\n",
      "Gradient for decoder.decoder.6.weight: 0.000739469425752759\n",
      "Gradient for decoder.decoder.6.bias: 4.436116068973206e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.02179189957678318\n",
      "Gradient for encoder.encoder.0.bias: 3.86148960029864e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0022941925562918186\n",
      "Gradient for encoder.encoder.1.bias: 0.0019221770344302058\n",
      "Gradient for encoder.encoder.3.weight: 0.0502120703458786\n",
      "Gradient for encoder.encoder.3.bias: 3.7963984733657696e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.008861926384270191\n",
      "Gradient for encoder.encoder.4.bias: 0.007660156115889549\n",
      "Gradient for encoder.mean.weight: 0.11472219973802567\n",
      "Gradient for encoder.mean.bias: 0.00470591289922595\n",
      "Gradient for encoder.log_var.weight: 0.07012134045362473\n",
      "Gradient for encoder.log_var.bias: 0.002628131303936243\n",
      "Gradient for decoder.decoder.0.weight: 0.010978463105857372\n",
      "Gradient for decoder.decoder.0.bias: 8.872017703831503e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005516153178177774\n",
      "Gradient for decoder.decoder.1.bias: 0.00042895611841231585\n",
      "Gradient for decoder.decoder.3.weight: 0.009674105793237686\n",
      "Gradient for decoder.decoder.3.bias: 9.488234503640669e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0003945730859413743\n",
      "Gradient for decoder.decoder.4.bias: 0.0004337613645475358\n",
      "Gradient for decoder.decoder.6.weight: 0.0006747347651980817\n",
      "Gradient for decoder.decoder.6.bias: 4.0298229578183964e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.021709855645895004\n",
      "Gradient for encoder.encoder.0.bias: 3.599068265636163e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0018530043307691813\n",
      "Gradient for encoder.encoder.1.bias: 0.001739749452099204\n",
      "Gradient for encoder.encoder.3.weight: 0.03884163498878479\n",
      "Gradient for encoder.encoder.3.bias: 3.6562691763109e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.007785028778016567\n",
      "Gradient for encoder.encoder.4.bias: 0.006845169235020876\n",
      "Gradient for encoder.mean.weight: 0.10110063850879669\n",
      "Gradient for encoder.mean.bias: 0.004185290075838566\n",
      "Gradient for encoder.log_var.weight: 0.0526277981698513\n",
      "Gradient for encoder.log_var.bias: 0.002425950253382325\n",
      "Gradient for decoder.decoder.0.weight: 0.014645435847342014\n",
      "Gradient for decoder.decoder.0.bias: 1.3138971854953496e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0007577800424769521\n",
      "Gradient for decoder.decoder.1.bias: 0.0006121378391981125\n",
      "Gradient for decoder.decoder.3.weight: 0.013441713526844978\n",
      "Gradient for decoder.decoder.3.bias: 1.0712057629813643e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0004888851544819772\n",
      "Gradient for decoder.decoder.4.bias: 0.00043554522562772036\n",
      "Gradient for decoder.decoder.6.weight: 0.0006710159359499812\n",
      "Gradient for decoder.decoder.6.bias: 3.209157512173988e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.01497770007699728\n",
      "Gradient for encoder.encoder.0.bias: 2.5186113611352923e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.002030503237619996\n",
      "Gradient for encoder.encoder.1.bias: 0.0017220876179635525\n",
      "Gradient for encoder.encoder.3.weight: 0.04366688057780266\n",
      "Gradient for encoder.encoder.3.bias: 3.9527178752329917e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0076621719636023045\n",
      "Gradient for encoder.encoder.4.bias: 0.007083887699991465\n",
      "Gradient for encoder.mean.weight: 0.10353389382362366\n",
      "Gradient for encoder.mean.bias: 0.003746964503079653\n",
      "Gradient for encoder.log_var.weight: 0.054569046944379807\n",
      "Gradient for encoder.log_var.bias: 0.002371705137193203\n",
      "Gradient for decoder.decoder.0.weight: 0.017980564385652542\n",
      "Gradient for decoder.decoder.0.bias: 1.5509302175864548e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0008787933620624244\n",
      "Gradient for decoder.decoder.1.bias: 0.0007419509347528219\n",
      "Gradient for decoder.decoder.3.weight: 0.01605658046901226\n",
      "Gradient for decoder.decoder.3.bias: 1.346022460158025e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0007239672704599798\n",
      "Gradient for decoder.decoder.4.bias: 0.0007543661631643772\n",
      "Gradient for decoder.decoder.6.weight: 0.0008132037473842502\n",
      "Gradient for decoder.decoder.6.bias: 5.410387529991567e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.01951100490987301\n",
      "Gradient for encoder.encoder.0.bias: 3.265746353897647e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.00227093743160367\n",
      "Gradient for encoder.encoder.1.bias: 0.0018478623824194074\n",
      "Gradient for encoder.encoder.3.weight: 0.047809917479753494\n",
      "Gradient for encoder.encoder.3.bias: 4.0465711337311916e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.00801762007176876\n",
      "Gradient for encoder.encoder.4.bias: 0.008831499144434929\n",
      "Gradient for encoder.mean.weight: 0.10053940117359161\n",
      "Gradient for encoder.mean.bias: 0.006601153407245874\n",
      "Gradient for encoder.log_var.weight: 0.0639801099896431\n",
      "Gradient for encoder.log_var.bias: 0.00433326093479991\n",
      "Gradient for decoder.decoder.0.weight: 0.013885998167097569\n",
      "Gradient for decoder.decoder.0.bias: 1.2334618049170132e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0006993156857788563\n",
      "Gradient for decoder.decoder.1.bias: 0.0005359172937460244\n",
      "Gradient for decoder.decoder.3.weight: 0.012283666990697384\n",
      "Gradient for decoder.decoder.3.bias: 1.0454201393450546e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.00045705639058724046\n",
      "Gradient for decoder.decoder.4.bias: 0.0004053075972478837\n",
      "Gradient for decoder.decoder.6.weight: 0.0007213686476461589\n",
      "Gradient for decoder.decoder.6.bias: 4.228885882184841e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.022714952006936073\n",
      "Gradient for encoder.encoder.0.bias: 3.9768095067005405e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0020915623754262924\n",
      "Gradient for encoder.encoder.1.bias: 0.001623291289433837\n",
      "Gradient for encoder.encoder.3.weight: 0.04049130529165268\n",
      "Gradient for encoder.encoder.3.bias: 3.216676092154813e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.006603142246603966\n",
      "Gradient for encoder.encoder.4.bias: 0.0053818002343177795\n",
      "Gradient for encoder.mean.weight: 0.08335234224796295\n",
      "Gradient for encoder.mean.bias: 0.003613801905885339\n",
      "Gradient for encoder.log_var.weight: 0.0434391051530838\n",
      "Gradient for encoder.log_var.bias: 0.0020828903652727604\n",
      "Gradient for decoder.decoder.0.weight: 0.011450618505477905\n",
      "Gradient for decoder.decoder.0.bias: 1.03257569161741e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.000579486193601042\n",
      "Gradient for decoder.decoder.1.bias: 0.0004525800177361816\n",
      "Gradient for decoder.decoder.3.weight: 0.010464722290635109\n",
      "Gradient for decoder.decoder.3.bias: 1.2106159130720329e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0007770218071527779\n",
      "Gradient for decoder.decoder.4.bias: 0.000983270350843668\n",
      "Gradient for decoder.decoder.6.weight: 0.0008591669611632824\n",
      "Gradient for decoder.decoder.6.bias: 7.50642575439997e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.013356025330722332\n",
      "Gradient for encoder.encoder.0.bias: 2.0626467547857352e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0014432634925469756\n",
      "Gradient for encoder.encoder.1.bias: 0.0011838239151984453\n",
      "Gradient for encoder.encoder.3.weight: 0.03234710916876793\n",
      "Gradient for encoder.encoder.3.bias: 2.6699642496907927e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.004654356744140387\n",
      "Gradient for encoder.encoder.4.bias: 0.004357240162789822\n",
      "Gradient for encoder.mean.weight: 0.057959187775850296\n",
      "Gradient for encoder.mean.bias: 0.0029642987065017223\n",
      "Gradient for encoder.log_var.weight: 0.036517564207315445\n",
      "Gradient for encoder.log_var.bias: 0.002092737006023526\n",
      "Gradient for decoder.decoder.0.weight: 0.014940024353563786\n",
      "Gradient for decoder.decoder.0.bias: 1.2238808577702542e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0007547790883108974\n",
      "Gradient for decoder.decoder.1.bias: 0.0005809576250612736\n",
      "Gradient for decoder.decoder.3.weight: 0.013674081303179264\n",
      "Gradient for decoder.decoder.3.bias: 1.1326833915248358e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0005831200978718698\n",
      "Gradient for decoder.decoder.4.bias: 0.0005789765855297446\n",
      "Gradient for decoder.decoder.6.weight: 0.0007739377906545997\n",
      "Gradient for decoder.decoder.6.bias: 4.94997002533637e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.018558649346232414\n",
      "Gradient for encoder.encoder.0.bias: 2.704144200227354e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0020681454334408045\n",
      "Gradient for encoder.encoder.1.bias: 0.0017113571520894766\n",
      "Gradient for encoder.encoder.3.weight: 0.043783508241176605\n",
      "Gradient for encoder.encoder.3.bias: 2.907626639458982e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.006555154453963041\n",
      "Gradient for encoder.encoder.4.bias: 0.005915866699069738\n",
      "Gradient for encoder.mean.weight: 0.08304920047521591\n",
      "Gradient for encoder.mean.bias: 0.00400824099779129\n",
      "Gradient for encoder.log_var.weight: 0.04854535683989525\n",
      "Gradient for encoder.log_var.bias: 0.002828144235536456\n",
      "Gradient for decoder.decoder.0.weight: 0.014475771225988865\n",
      "Gradient for decoder.decoder.0.bias: 1.195886584204331e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0007334704278036952\n",
      "Gradient for decoder.decoder.1.bias: 0.0005426869029179215\n",
      "Gradient for decoder.decoder.3.weight: 0.013432233594357967\n",
      "Gradient for decoder.decoder.3.bias: 1.0638464414958193e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0004930979921482503\n",
      "Gradient for decoder.decoder.4.bias: 0.00044235281529836357\n",
      "Gradient for decoder.decoder.6.weight: 0.0007797023863531649\n",
      "Gradient for decoder.decoder.6.bias: 4.9351812776876613e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.01861589401960373\n",
      "Gradient for encoder.encoder.0.bias: 3.1329903948940085e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.001599157229065895\n",
      "Gradient for encoder.encoder.1.bias: 0.0014675220008939505\n",
      "Gradient for encoder.encoder.3.weight: 0.03536578640341759\n",
      "Gradient for encoder.encoder.3.bias: 3.486763378024449e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.009164207614958286\n",
      "Gradient for encoder.encoder.4.bias: 0.007058254908770323\n",
      "Gradient for encoder.mean.weight: 0.11502320319414139\n",
      "Gradient for encoder.mean.bias: 0.004548072814941406\n",
      "Gradient for encoder.log_var.weight: 0.07030685245990753\n",
      "Gradient for encoder.log_var.bias: 0.002668183296918869\n",
      "Gradient for decoder.decoder.0.weight: 0.01300556119531393\n",
      "Gradient for decoder.decoder.0.bias: 1.1047671805153314e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0006832447252236307\n",
      "Gradient for decoder.decoder.1.bias: 0.0005973135121166706\n",
      "Gradient for decoder.decoder.3.weight: 0.01207382045686245\n",
      "Gradient for decoder.decoder.3.bias: 1.0255762905586607e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0005159126594662666\n",
      "Gradient for decoder.decoder.4.bias: 0.000489993835799396\n",
      "Gradient for decoder.decoder.6.weight: 0.0006689212750643492\n",
      "Gradient for decoder.decoder.6.bias: 3.5420001950114965e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.0209841039031744\n",
      "Gradient for encoder.encoder.0.bias: 3.234470330459871e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.002646856941282749\n",
      "Gradient for encoder.encoder.1.bias: 0.0021351261530071497\n",
      "Gradient for encoder.encoder.3.weight: 0.056526876986026764\n",
      "Gradient for encoder.encoder.3.bias: 3.1726710147950143e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0060106199234724045\n",
      "Gradient for encoder.encoder.4.bias: 0.005912782624363899\n",
      "Gradient for encoder.mean.weight: 0.08408467471599579\n",
      "Gradient for encoder.mean.bias: 0.00402116822078824\n",
      "Gradient for encoder.log_var.weight: 0.04540374130010605\n",
      "Gradient for encoder.log_var.bias: 0.002669892506673932\n",
      "Gradient for decoder.decoder.0.weight: 0.014935551211237907\n",
      "Gradient for decoder.decoder.0.bias: 1.1957282386454438e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0007622100529260933\n",
      "Gradient for decoder.decoder.1.bias: 0.000592496944591403\n",
      "Gradient for decoder.decoder.3.weight: 0.013714863918721676\n",
      "Gradient for decoder.decoder.3.bias: 1.0918654869129796e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0005601936718448997\n",
      "Gradient for decoder.decoder.4.bias: 0.0005760770291090012\n",
      "Gradient for decoder.decoder.6.weight: 0.0007100150687620044\n",
      "Gradient for decoder.decoder.6.bias: 4.531099693849683e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.021746458485722542\n",
      "Gradient for encoder.encoder.0.bias: 3.5323324126812494e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0027776367496699095\n",
      "Gradient for encoder.encoder.1.bias: 0.0020138933323323727\n",
      "Gradient for encoder.encoder.3.weight: 0.05375753343105316\n",
      "Gradient for encoder.encoder.3.bias: 3.2463109977953764e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.007177931256592274\n",
      "Gradient for encoder.encoder.4.bias: 0.005794459953904152\n",
      "Gradient for encoder.mean.weight: 0.09816587716341019\n",
      "Gradient for encoder.mean.bias: 0.004087388981133699\n",
      "Gradient for encoder.log_var.weight: 0.05861448496580124\n",
      "Gradient for encoder.log_var.bias: 0.0027170395478606224\n",
      "Gradient for decoder.decoder.0.weight: 0.01458052359521389\n",
      "Gradient for decoder.decoder.0.bias: 1.1848486081156295e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0007425033836625516\n",
      "Gradient for decoder.decoder.1.bias: 0.000535427185241133\n",
      "Gradient for decoder.decoder.3.weight: 0.013232379220426083\n",
      "Gradient for decoder.decoder.3.bias: 1.1153605816716095e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0005741841741837561\n",
      "Gradient for decoder.decoder.4.bias: 0.0005568563938140869\n",
      "Gradient for decoder.decoder.6.weight: 0.0007993032340891659\n",
      "Gradient for decoder.decoder.6.bias: 5.416718340711668e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training VAE Epoch:  72%|███████▏  | 57/79 [00:00<00:00, 73.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient for encoder.encoder.0.weight: 0.018921583890914917\n",
      "Gradient for encoder.encoder.0.bias: 3.254111910488966e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.002280362881720066\n",
      "Gradient for encoder.encoder.1.bias: 0.001583747216500342\n",
      "Gradient for encoder.encoder.3.weight: 0.04709107428789139\n",
      "Gradient for encoder.encoder.3.bias: 3.2495828250489467e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0065495604649186134\n",
      "Gradient for encoder.encoder.4.bias: 0.006269237492233515\n",
      "Gradient for encoder.mean.weight: 0.08577378839254379\n",
      "Gradient for encoder.mean.bias: 0.004168596118688583\n",
      "Gradient for encoder.log_var.weight: 0.051460810005664825\n",
      "Gradient for encoder.log_var.bias: 0.0026003809180110693\n",
      "Gradient for decoder.decoder.0.weight: 0.011854670941829681\n",
      "Gradient for decoder.decoder.0.bias: 9.786185056759322e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0006113553536124527\n",
      "Gradient for decoder.decoder.1.bias: 0.00047181156696751714\n",
      "Gradient for decoder.decoder.3.weight: 0.010874764993786812\n",
      "Gradient for decoder.decoder.3.bias: 8.763065273420523e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0005285947700031102\n",
      "Gradient for decoder.decoder.4.bias: 0.0005431113531813025\n",
      "Gradient for decoder.decoder.6.weight: 0.0007115525077097118\n",
      "Gradient for decoder.decoder.6.bias: 4.6017084969207644e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.022572940215468407\n",
      "Gradient for encoder.encoder.0.bias: 4.4970256685150645e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.003039849456399679\n",
      "Gradient for encoder.encoder.1.bias: 0.002228546654805541\n",
      "Gradient for encoder.encoder.3.weight: 0.06130420044064522\n",
      "Gradient for encoder.encoder.3.bias: 3.741299492432404e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.008766824379563332\n",
      "Gradient for encoder.encoder.4.bias: 0.00833695475012064\n",
      "Gradient for encoder.mean.weight: 0.11559971421957016\n",
      "Gradient for encoder.mean.bias: 0.0043789963237941265\n",
      "Gradient for encoder.log_var.weight: 0.06553484499454498\n",
      "Gradient for encoder.log_var.bias: 0.002810204168781638\n",
      "Gradient for decoder.decoder.0.weight: 0.01149384118616581\n",
      "Gradient for decoder.decoder.0.bias: 9.980170162515734e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005855349008925259\n",
      "Gradient for decoder.decoder.1.bias: 0.00045257931924425066\n",
      "Gradient for decoder.decoder.3.weight: 0.010374494828283787\n",
      "Gradient for decoder.decoder.3.bias: 1.2251084868797335e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0008221286698244512\n",
      "Gradient for decoder.decoder.4.bias: 0.0010110529838129878\n",
      "Gradient for decoder.decoder.6.weight: 0.0008102611755020916\n",
      "Gradient for decoder.decoder.6.bias: 6.96157367201522e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.018391260877251625\n",
      "Gradient for encoder.encoder.0.bias: 3.1864930832847804e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.002204828429967165\n",
      "Gradient for encoder.encoder.1.bias: 0.001955021172761917\n",
      "Gradient for encoder.encoder.3.weight: 0.04724552482366562\n",
      "Gradient for encoder.encoder.3.bias: 3.891049982218675e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0081779258325696\n",
      "Gradient for encoder.encoder.4.bias: 0.009029277600347996\n",
      "Gradient for encoder.mean.weight: 0.10310396552085876\n",
      "Gradient for encoder.mean.bias: 0.005947194993495941\n",
      "Gradient for encoder.log_var.weight: 0.061640575528144836\n",
      "Gradient for encoder.log_var.bias: 0.004017665982246399\n",
      "Gradient for decoder.decoder.0.weight: 0.012436947785317898\n",
      "Gradient for decoder.decoder.0.bias: 1.006343688936262e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.000660850084386766\n",
      "Gradient for decoder.decoder.1.bias: 0.0005102370050735772\n",
      "Gradient for decoder.decoder.3.weight: 0.011302033439278603\n",
      "Gradient for decoder.decoder.3.bias: 1.0314779586018119e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0005162344896234572\n",
      "Gradient for decoder.decoder.4.bias: 0.0005634332774206996\n",
      "Gradient for decoder.decoder.6.weight: 0.0007319674477912486\n",
      "Gradient for decoder.decoder.6.bias: 4.724561586044729e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.015017333440482616\n",
      "Gradient for encoder.encoder.0.bias: 2.5701323014271082e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0018170301336795092\n",
      "Gradient for encoder.encoder.1.bias: 0.001578201656229794\n",
      "Gradient for encoder.encoder.3.weight: 0.038987208157777786\n",
      "Gradient for encoder.encoder.3.bias: 3.189393749103431e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.006577616557478905\n",
      "Gradient for encoder.encoder.4.bias: 0.006387480068951845\n",
      "Gradient for encoder.mean.weight: 0.08130823820829391\n",
      "Gradient for encoder.mean.bias: 0.004052408505231142\n",
      "Gradient for encoder.log_var.weight: 0.0476636104285717\n",
      "Gradient for encoder.log_var.bias: 0.0024697110056877136\n",
      "Gradient for decoder.decoder.0.weight: 0.013644321821630001\n",
      "Gradient for decoder.decoder.0.bias: 1.255120729570791e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0007046732935123146\n",
      "Gradient for decoder.decoder.1.bias: 0.0005280231707729399\n",
      "Gradient for decoder.decoder.3.weight: 0.01238046120852232\n",
      "Gradient for decoder.decoder.3.bias: 1.006853420082443e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0004976275959052145\n",
      "Gradient for decoder.decoder.4.bias: 0.0004391318652778864\n",
      "Gradient for decoder.decoder.6.weight: 0.0007327569182962179\n",
      "Gradient for decoder.decoder.6.bias: 4.243423245497979e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.018356015905737877\n",
      "Gradient for encoder.encoder.0.bias: 2.5898914957078745e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.002308794530108571\n",
      "Gradient for encoder.encoder.1.bias: 0.0018856556853279471\n",
      "Gradient for encoder.encoder.3.weight: 0.05464843660593033\n",
      "Gradient for encoder.encoder.3.bias: 3.6797631608465053e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.007610170636326075\n",
      "Gradient for encoder.encoder.4.bias: 0.00785871222615242\n",
      "Gradient for encoder.mean.weight: 0.09580087661743164\n",
      "Gradient for encoder.mean.bias: 0.005089629907160997\n",
      "Gradient for encoder.log_var.weight: 0.05972101166844368\n",
      "Gradient for encoder.log_var.bias: 0.0032005764078348875\n",
      "Gradient for decoder.decoder.0.weight: 0.016898952424526215\n",
      "Gradient for decoder.decoder.0.bias: 1.3096704276627236e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0008682331535965204\n",
      "Gradient for decoder.decoder.1.bias: 0.0006255436455830932\n",
      "Gradient for decoder.decoder.3.weight: 0.015577509999275208\n",
      "Gradient for decoder.decoder.3.bias: 1.3340505089498578e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0006510175298899412\n",
      "Gradient for decoder.decoder.4.bias: 0.0006187093094922602\n",
      "Gradient for decoder.decoder.6.weight: 0.000735269277356565\n",
      "Gradient for decoder.decoder.6.bias: 3.921263123629615e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.027223216369748116\n",
      "Gradient for encoder.encoder.0.bias: 5.3064205807196174e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.003838173346593976\n",
      "Gradient for encoder.encoder.1.bias: 0.002651441842317581\n",
      "Gradient for encoder.encoder.3.weight: 0.0693875104188919\n",
      "Gradient for encoder.encoder.3.bias: 3.6647479495499624e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.007222026586532593\n",
      "Gradient for encoder.encoder.4.bias: 0.006582207512110472\n",
      "Gradient for encoder.mean.weight: 0.09907586872577667\n",
      "Gradient for encoder.mean.bias: 0.003724500769749284\n",
      "Gradient for encoder.log_var.weight: 0.0544007271528244\n",
      "Gradient for encoder.log_var.bias: 0.002053748583421111\n",
      "Gradient for decoder.decoder.0.weight: 0.010523774661123753\n",
      "Gradient for decoder.decoder.0.bias: 9.804591860618217e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005724730435758829\n",
      "Gradient for decoder.decoder.1.bias: 0.0004133881884627044\n",
      "Gradient for decoder.decoder.3.weight: 0.009797918610274792\n",
      "Gradient for decoder.decoder.3.bias: 1.0613018103233784e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0007078810012899339\n",
      "Gradient for decoder.decoder.4.bias: 0.0008860037778504193\n",
      "Gradient for decoder.decoder.6.weight: 0.000776256900280714\n",
      "Gradient for decoder.decoder.6.bias: 6.0100039263488725e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.01663826033473015\n",
      "Gradient for encoder.encoder.0.bias: 2.2218274095542334e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0020019824150949717\n",
      "Gradient for encoder.encoder.1.bias: 0.0017339133191853762\n",
      "Gradient for encoder.encoder.3.weight: 0.04609187692403793\n",
      "Gradient for encoder.encoder.3.bias: 4.4371262220010976e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.012267276644706726\n",
      "Gradient for encoder.encoder.4.bias: 0.010888800956308842\n",
      "Gradient for encoder.mean.weight: 0.15310074388980865\n",
      "Gradient for encoder.mean.bias: 0.005719922948628664\n",
      "Gradient for encoder.log_var.weight: 0.09400475770235062\n",
      "Gradient for encoder.log_var.bias: 0.0036803551483899355\n",
      "Gradient for decoder.decoder.0.weight: 0.01667698100209236\n",
      "Gradient for decoder.decoder.0.bias: 1.4015720528615105e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0008638354483991861\n",
      "Gradient for decoder.decoder.1.bias: 0.0006377210956998169\n",
      "Gradient for decoder.decoder.3.weight: 0.01490600872784853\n",
      "Gradient for decoder.decoder.3.bias: 1.1217774625871257e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0005307259852997959\n",
      "Gradient for decoder.decoder.4.bias: 0.0004307696653995663\n",
      "Gradient for decoder.decoder.6.weight: 0.0007288022898137569\n",
      "Gradient for decoder.decoder.6.bias: 4.437648021848872e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.01763346791267395\n",
      "Gradient for encoder.encoder.0.bias: 2.8945457142270925e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0015326180728152394\n",
      "Gradient for encoder.encoder.1.bias: 0.00123806472402066\n",
      "Gradient for encoder.encoder.3.weight: 0.03248897194862366\n",
      "Gradient for encoder.encoder.3.bias: 2.4250976227158105e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.004321023356169462\n",
      "Gradient for encoder.encoder.4.bias: 0.0038123619742691517\n",
      "Gradient for encoder.mean.weight: 0.05565866082906723\n",
      "Gradient for encoder.mean.bias: 0.002953853690996766\n",
      "Gradient for encoder.log_var.weight: 0.031931743025779724\n",
      "Gradient for encoder.log_var.bias: 0.0015962353209033608\n",
      "Gradient for decoder.decoder.0.weight: 0.012883260846138\n",
      "Gradient for decoder.decoder.0.bias: 9.9007989307065e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0006187442340888083\n",
      "Gradient for decoder.decoder.1.bias: 0.00048528495244681835\n",
      "Gradient for decoder.decoder.3.weight: 0.011381750926375389\n",
      "Gradient for decoder.decoder.3.bias: 9.567684838840407e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.000502360169775784\n",
      "Gradient for decoder.decoder.4.bias: 0.0005378150381147861\n",
      "Gradient for decoder.decoder.6.weight: 0.0006854921230114996\n",
      "Gradient for decoder.decoder.6.bias: 4.2527310142759234e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.023943830281496048\n",
      "Gradient for encoder.encoder.0.bias: 3.3492979223392894e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0024571341928094625\n",
      "Gradient for encoder.encoder.1.bias: 0.0017257332801818848\n",
      "Gradient for encoder.encoder.3.weight: 0.050530437380075455\n",
      "Gradient for encoder.encoder.3.bias: 3.20145437937569e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.005520690698176622\n",
      "Gradient for encoder.encoder.4.bias: 0.00519983284175396\n",
      "Gradient for encoder.mean.weight: 0.07147791236639023\n",
      "Gradient for encoder.mean.bias: 0.0036929617635905743\n",
      "Gradient for encoder.log_var.weight: 0.044847577810287476\n",
      "Gradient for encoder.log_var.bias: 0.0025457125157117844\n",
      "Gradient for decoder.decoder.0.weight: 0.013846950605511665\n",
      "Gradient for decoder.decoder.0.bias: 1.1970398283711603e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0007120933732949197\n",
      "Gradient for decoder.decoder.1.bias: 0.0005414345068857074\n",
      "Gradient for decoder.decoder.3.weight: 0.012505785562098026\n",
      "Gradient for decoder.decoder.3.bias: 9.907160508637602e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00046982846106402576\n",
      "Gradient for decoder.decoder.4.bias: 0.00042552442755550146\n",
      "Gradient for decoder.decoder.6.weight: 0.0007163830450735986\n",
      "Gradient for decoder.decoder.6.bias: 4.1484330722596496e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.014915114268660545\n",
      "Gradient for encoder.encoder.0.bias: 2.7341344466247364e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0015665979590266943\n",
      "Gradient for encoder.encoder.1.bias: 0.0013463950017467141\n",
      "Gradient for encoder.encoder.3.weight: 0.03588263317942619\n",
      "Gradient for encoder.encoder.3.bias: 2.4783927687899165e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.004349241498857737\n",
      "Gradient for encoder.encoder.4.bias: 0.004291438963264227\n",
      "Gradient for encoder.mean.weight: 0.05831514671444893\n",
      "Gradient for encoder.mean.bias: 0.0030415065120905638\n",
      "Gradient for encoder.log_var.weight: 0.033724281936883926\n",
      "Gradient for encoder.log_var.bias: 0.001676276559010148\n",
      "Gradient for decoder.decoder.0.weight: 0.013454141095280647\n",
      "Gradient for decoder.decoder.0.bias: 1.1722856019247274e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0007180183893069625\n",
      "Gradient for decoder.decoder.1.bias: 0.0005598455318249762\n",
      "Gradient for decoder.decoder.3.weight: 0.012442723847925663\n",
      "Gradient for decoder.decoder.3.bias: 8.945211238398088e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00047641361015848815\n",
      "Gradient for decoder.decoder.4.bias: 0.000400932680349797\n",
      "Gradient for decoder.decoder.6.weight: 0.0007031967979855835\n",
      "Gradient for decoder.decoder.6.bias: 4.1779596358537674e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.019464567303657532\n",
      "Gradient for encoder.encoder.0.bias: 3.4804388537867936e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0021507455967366695\n",
      "Gradient for encoder.encoder.1.bias: 0.002195123117417097\n",
      "Gradient for encoder.encoder.3.weight: 0.04511445760726929\n",
      "Gradient for encoder.encoder.3.bias: 3.663749026383556e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.00922938622534275\n",
      "Gradient for encoder.encoder.4.bias: 0.008810248225927353\n",
      "Gradient for encoder.mean.weight: 0.11087381839752197\n",
      "Gradient for encoder.mean.bias: 0.005346629768610001\n",
      "Gradient for encoder.log_var.weight: 0.0790654644370079\n",
      "Gradient for encoder.log_var.bias: 0.003519534133374691\n",
      "Gradient for decoder.decoder.0.weight: 0.01379646360874176\n",
      "Gradient for decoder.decoder.0.bias: 1.170672447869947e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.000671075948048383\n",
      "Gradient for decoder.decoder.1.bias: 0.0005541950231418014\n",
      "Gradient for decoder.decoder.3.weight: 0.012412517331540585\n",
      "Gradient for decoder.decoder.3.bias: 1.2183563879997195e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0006866439362056553\n",
      "Gradient for decoder.decoder.4.bias: 0.0007902343641035259\n",
      "Gradient for decoder.decoder.6.weight: 0.0007304520113393664\n",
      "Gradient for decoder.decoder.6.bias: 5.3023315558675677e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.02470925636589527\n",
      "Gradient for encoder.encoder.0.bias: 3.333358936097319e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.002828178694471717\n",
      "Gradient for encoder.encoder.1.bias: 0.002316477708518505\n",
      "Gradient for encoder.encoder.3.weight: 0.05440681800246239\n",
      "Gradient for encoder.encoder.3.bias: 3.1796290600460964e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.006097727455198765\n",
      "Gradient for encoder.encoder.4.bias: 0.005461100023239851\n",
      "Gradient for encoder.mean.weight: 0.08198009431362152\n",
      "Gradient for encoder.mean.bias: 0.003389590885490179\n",
      "Gradient for encoder.log_var.weight: 0.04731466993689537\n",
      "Gradient for encoder.log_var.bias: 0.0020741685293614864\n",
      "Gradient for decoder.decoder.0.weight: 0.01765068620443344\n",
      "Gradient for decoder.decoder.0.bias: 1.4969120387675616e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.000900265877135098\n",
      "Gradient for decoder.decoder.1.bias: 0.000693730020429939\n",
      "Gradient for decoder.decoder.3.weight: 0.016243990510702133\n",
      "Gradient for decoder.decoder.3.bias: 1.2224121714865532e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0007442255155183375\n",
      "Gradient for decoder.decoder.4.bias: 0.0007012072019279003\n",
      "Gradient for decoder.decoder.6.weight: 0.0008224367047660053\n",
      "Gradient for decoder.decoder.6.bias: 5.210932795307599e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.01724337786436081\n",
      "Gradient for encoder.encoder.0.bias: 2.77242083457363e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0027319174259901047\n",
      "Gradient for encoder.encoder.1.bias: 0.0018587347585707903\n",
      "Gradient for encoder.encoder.3.weight: 0.054554492235183716\n",
      "Gradient for encoder.encoder.3.bias: 3.343254006971108e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.008916876278817654\n",
      "Gradient for encoder.encoder.4.bias: 0.006470071151852608\n",
      "Gradient for encoder.mean.weight: 0.11840937286615372\n",
      "Gradient for encoder.mean.bias: 0.0037813992239534855\n",
      "Gradient for encoder.log_var.weight: 0.06813369691371918\n",
      "Gradient for encoder.log_var.bias: 0.0023323409259319305\n",
      "Gradient for decoder.decoder.0.weight: 0.013428878039121628\n",
      "Gradient for decoder.decoder.0.bias: 1.0596430677356494e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0006525155622512102\n",
      "Gradient for decoder.decoder.1.bias: 0.0005366909899748862\n",
      "Gradient for decoder.decoder.3.weight: 0.012066450901329517\n",
      "Gradient for decoder.decoder.3.bias: 9.910918613575959e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.000611700292211026\n",
      "Gradient for decoder.decoder.4.bias: 0.0006306182476691902\n",
      "Gradient for decoder.decoder.6.weight: 0.0007250139024108648\n",
      "Gradient for decoder.decoder.6.bias: 4.95795720780734e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.01907629333436489\n",
      "Gradient for encoder.encoder.0.bias: 2.830337006431982e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0016669599572196603\n",
      "Gradient for encoder.encoder.1.bias: 0.001488487352617085\n",
      "Gradient for encoder.encoder.3.weight: 0.037351999431848526\n",
      "Gradient for encoder.encoder.3.bias: 3.4616370880868885e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.007131930906325579\n",
      "Gradient for encoder.encoder.4.bias: 0.007104037795215845\n",
      "Gradient for encoder.mean.weight: 0.09394987672567368\n",
      "Gradient for encoder.mean.bias: 0.005667072720825672\n",
      "Gradient for encoder.log_var.weight: 0.05923455208539963\n",
      "Gradient for encoder.log_var.bias: 0.0036799400113523006\n",
      "Gradient for decoder.decoder.0.weight: 0.015958212316036224\n",
      "Gradient for decoder.decoder.0.bias: 1.2931351822675907e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.000765208329539746\n",
      "Gradient for decoder.decoder.1.bias: 0.0006395685486495495\n",
      "Gradient for decoder.decoder.3.weight: 0.0139736607670784\n",
      "Gradient for decoder.decoder.3.bias: 1.0445865700203782e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0004950317088514566\n",
      "Gradient for decoder.decoder.4.bias: 0.0004181468684691936\n",
      "Gradient for decoder.decoder.6.weight: 0.0006941808387637138\n",
      "Gradient for decoder.decoder.6.bias: 3.7005618651164696e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.022531213238835335\n",
      "Gradient for encoder.encoder.0.bias: 4.138130463293699e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.00244551501236856\n",
      "Gradient for encoder.encoder.1.bias: 0.002219293499365449\n",
      "Gradient for encoder.encoder.3.weight: 0.049159303307533264\n",
      "Gradient for encoder.encoder.3.bias: 3.846458429546118e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.007665183860808611\n",
      "Gradient for encoder.encoder.4.bias: 0.007318291813135147\n",
      "Gradient for encoder.mean.weight: 0.09597183018922806\n",
      "Gradient for encoder.mean.bias: 0.005379655864089727\n",
      "Gradient for encoder.log_var.weight: 0.051725372672080994\n",
      "Gradient for encoder.log_var.bias: 0.003144521964713931\n",
      "Gradient for decoder.decoder.0.weight: 0.011794785037636757\n",
      "Gradient for decoder.decoder.0.bias: 1.0148955981170715e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0006114342249929905\n",
      "Gradient for decoder.decoder.1.bias: 0.0004875334561802447\n",
      "Gradient for decoder.decoder.3.weight: 0.01086884643882513\n",
      "Gradient for decoder.decoder.3.bias: 9.288966124065823e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0004668367619160563\n",
      "Gradient for decoder.decoder.4.bias: 0.00043518407619558275\n",
      "Gradient for decoder.decoder.6.weight: 0.00065950071439147\n",
      "Gradient for decoder.decoder.6.bias: 3.7958416214678437e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.023152513429522514\n",
      "Gradient for encoder.encoder.0.bias: 4.919449916873653e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.003870217129588127\n",
      "Gradient for encoder.encoder.1.bias: 0.0028302620630711317\n",
      "Gradient for encoder.encoder.3.weight: 0.0768524631857872\n",
      "Gradient for encoder.encoder.3.bias: 4.15477846571477e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.013805520720779896\n",
      "Gradient for encoder.encoder.4.bias: 0.011021633632481098\n",
      "Gradient for encoder.mean.weight: 0.17315925657749176\n",
      "Gradient for encoder.mean.bias: 0.005131109617650509\n",
      "Gradient for encoder.log_var.weight: 0.10414528101682663\n",
      "Gradient for encoder.log_var.bias: 0.00304128578864038\n",
      "Gradient for decoder.decoder.0.weight: 0.013463723473250866\n",
      "Gradient for decoder.decoder.0.bias: 1.1901730989638537e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0006594040896743536\n",
      "Gradient for decoder.decoder.1.bias: 0.000541846442501992\n",
      "Gradient for decoder.decoder.3.weight: 0.012159212492406368\n",
      "Gradient for decoder.decoder.3.bias: 9.138272083486498e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0004207107413094491\n",
      "Gradient for decoder.decoder.4.bias: 0.00038835956365801394\n",
      "Gradient for decoder.decoder.6.weight: 0.0007205053698271513\n",
      "Gradient for decoder.decoder.6.bias: 4.685278327087872e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training VAE Epoch:  94%|█████████▎| 74/79 [00:01<00:00, 76.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient for encoder.encoder.0.weight: 0.02099030464887619\n",
      "Gradient for encoder.encoder.0.bias: 3.3460692550058013e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.002149473875761032\n",
      "Gradient for encoder.encoder.1.bias: 0.001996186561882496\n",
      "Gradient for encoder.encoder.3.weight: 0.04590602591633797\n",
      "Gradient for encoder.encoder.3.bias: 3.160458839079894e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.007913819514214993\n",
      "Gradient for encoder.encoder.4.bias: 0.006619120016694069\n",
      "Gradient for encoder.mean.weight: 0.10450512915849686\n",
      "Gradient for encoder.mean.bias: 0.004215574823319912\n",
      "Gradient for encoder.log_var.weight: 0.06599833816289902\n",
      "Gradient for encoder.log_var.bias: 0.0027308606076985598\n",
      "Gradient for decoder.decoder.0.weight: 0.01387472078204155\n",
      "Gradient for decoder.decoder.0.bias: 1.2967099616290056e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0006978210294619203\n",
      "Gradient for decoder.decoder.1.bias: 0.0005491620977409184\n",
      "Gradient for decoder.decoder.3.weight: 0.012641161680221558\n",
      "Gradient for decoder.decoder.3.bias: 1.1518401510368648e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.00046479341108351946\n",
      "Gradient for decoder.decoder.4.bias: 0.0004120671364944428\n",
      "Gradient for decoder.decoder.6.weight: 0.0007040105410851538\n",
      "Gradient for decoder.decoder.6.bias: 4.053078009746969e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.02005903422832489\n",
      "Gradient for encoder.encoder.0.bias: 2.963647036113848e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0029801682103425264\n",
      "Gradient for encoder.encoder.1.bias: 0.002137540141120553\n",
      "Gradient for encoder.encoder.3.weight: 0.05887772887945175\n",
      "Gradient for encoder.encoder.3.bias: 3.6613917453465206e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.010056189261376858\n",
      "Gradient for encoder.encoder.4.bias: 0.007963061332702637\n",
      "Gradient for encoder.mean.weight: 0.1280008852481842\n",
      "Gradient for encoder.mean.bias: 0.004780331160873175\n",
      "Gradient for encoder.log_var.weight: 0.07767195999622345\n",
      "Gradient for encoder.log_var.bias: 0.002915183315053582\n",
      "Gradient for decoder.decoder.0.weight: 0.01221462432295084\n",
      "Gradient for decoder.decoder.0.bias: 1.0146988110859567e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0006398253608494997\n",
      "Gradient for decoder.decoder.1.bias: 0.0004720600263681263\n",
      "Gradient for decoder.decoder.3.weight: 0.011076197028160095\n",
      "Gradient for decoder.decoder.3.bias: 8.542239832154408e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0004548497963696718\n",
      "Gradient for decoder.decoder.4.bias: 0.0004939467762596905\n",
      "Gradient for decoder.decoder.6.weight: 0.000651789887342602\n",
      "Gradient for decoder.decoder.6.bias: 3.8137910451041535e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.024047652259469032\n",
      "Gradient for encoder.encoder.0.bias: 3.317099719901684e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0025547605473548174\n",
      "Gradient for encoder.encoder.1.bias: 0.002043989719823003\n",
      "Gradient for encoder.encoder.3.weight: 0.05059533193707466\n",
      "Gradient for encoder.encoder.3.bias: 3.4386191116730913e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.006051931995898485\n",
      "Gradient for encoder.encoder.4.bias: 0.005233699921518564\n",
      "Gradient for encoder.mean.weight: 0.08086836338043213\n",
      "Gradient for encoder.mean.bias: 0.003745240857824683\n",
      "Gradient for encoder.log_var.weight: 0.05495772510766983\n",
      "Gradient for encoder.log_var.bias: 0.0025274590589106083\n",
      "Gradient for decoder.decoder.0.weight: 0.013995314948260784\n",
      "Gradient for decoder.decoder.0.bias: 1.1812543998512837e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0006785930600017309\n",
      "Gradient for decoder.decoder.1.bias: 0.0005186121561564505\n",
      "Gradient for decoder.decoder.3.weight: 0.012905278243124485\n",
      "Gradient for decoder.decoder.3.bias: 9.680065082839917e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00046801482676528394\n",
      "Gradient for decoder.decoder.4.bias: 0.0004303038876969367\n",
      "Gradient for decoder.decoder.6.weight: 0.0007818671292625368\n",
      "Gradient for decoder.decoder.6.bias: 5.5369408073602244e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.018281567841768265\n",
      "Gradient for encoder.encoder.0.bias: 2.8101658153256714e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0025421662721782923\n",
      "Gradient for encoder.encoder.1.bias: 0.0017254669219255447\n",
      "Gradient for encoder.encoder.3.weight: 0.04755934700369835\n",
      "Gradient for encoder.encoder.3.bias: 2.7034807725812016e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.006628639530390501\n",
      "Gradient for encoder.encoder.4.bias: 0.005460298154503107\n",
      "Gradient for encoder.mean.weight: 0.08472301810979843\n",
      "Gradient for encoder.mean.bias: 0.003466532099992037\n",
      "Gradient for encoder.log_var.weight: 0.044623371213674545\n",
      "Gradient for encoder.log_var.bias: 0.002186510944738984\n",
      "Gradient for decoder.decoder.0.weight: 0.0160148236900568\n",
      "Gradient for decoder.decoder.0.bias: 1.1908261876580895e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0008340008789673448\n",
      "Gradient for decoder.decoder.1.bias: 0.0005949112819507718\n",
      "Gradient for decoder.decoder.3.weight: 0.014476590789854527\n",
      "Gradient for decoder.decoder.3.bias: 1.057433030027255e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0005281093763187528\n",
      "Gradient for decoder.decoder.4.bias: 0.00046980701154097915\n",
      "Gradient for decoder.decoder.6.weight: 0.0007059845956973732\n",
      "Gradient for decoder.decoder.6.bias: 3.8417561881942675e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.01853397861123085\n",
      "Gradient for encoder.encoder.0.bias: 3.0560717151351113e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0019008296076208353\n",
      "Gradient for encoder.encoder.1.bias: 0.0016021159244701266\n",
      "Gradient for encoder.encoder.3.weight: 0.042935214936733246\n",
      "Gradient for encoder.encoder.3.bias: 2.995270975691966e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0084299985319376\n",
      "Gradient for encoder.encoder.4.bias: 0.005969244055449963\n",
      "Gradient for encoder.mean.weight: 0.11368832737207413\n",
      "Gradient for encoder.mean.bias: 0.0029419483616948128\n",
      "Gradient for encoder.log_var.weight: 0.058047693222761154\n",
      "Gradient for encoder.log_var.bias: 0.0018092849059030414\n",
      "Gradient for decoder.decoder.0.weight: 0.013144269585609436\n",
      "Gradient for decoder.decoder.0.bias: 1.1025618612547916e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0006826349999755621\n",
      "Gradient for decoder.decoder.1.bias: 0.000564630317967385\n",
      "Gradient for decoder.decoder.3.weight: 0.012580327689647675\n",
      "Gradient for decoder.decoder.3.bias: 9.763118091754563e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0005306960083544254\n",
      "Gradient for decoder.decoder.4.bias: 0.0005737809697166085\n",
      "Gradient for decoder.decoder.6.weight: 0.0006989710382185876\n",
      "Gradient for decoder.decoder.6.bias: 4.868527321377769e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.0165590550750494\n",
      "Gradient for encoder.encoder.0.bias: 2.5456548327640327e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0016913390718400478\n",
      "Gradient for encoder.encoder.1.bias: 0.0012054613325744867\n",
      "Gradient for encoder.encoder.3.weight: 0.03519362211227417\n",
      "Gradient for encoder.encoder.3.bias: 2.6263194397024847e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.005905534140765667\n",
      "Gradient for encoder.encoder.4.bias: 0.005207044072449207\n",
      "Gradient for encoder.mean.weight: 0.08197014033794403\n",
      "Gradient for encoder.mean.bias: 0.004728131461888552\n",
      "Gradient for encoder.log_var.weight: 0.050141554325819016\n",
      "Gradient for encoder.log_var.bias: 0.002731755841523409\n",
      "Gradient for decoder.decoder.0.weight: 0.013110386207699776\n",
      "Gradient for decoder.decoder.0.bias: 1.0301980796212362e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0007091318257153034\n",
      "Gradient for decoder.decoder.1.bias: 0.0005251116235740483\n",
      "Gradient for decoder.decoder.3.weight: 0.011685444973409176\n",
      "Gradient for decoder.decoder.3.bias: 8.741601192907567e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0004109154106117785\n",
      "Gradient for decoder.decoder.4.bias: 0.00034600772778503597\n",
      "Gradient for decoder.decoder.6.weight: 0.0006561056943610311\n",
      "Gradient for decoder.decoder.6.bias: 2.843880429281853e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.021959805861115456\n",
      "Gradient for encoder.encoder.0.bias: 3.3996524345658585e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.002192744053900242\n",
      "Gradient for encoder.encoder.1.bias: 0.0016709695337340236\n",
      "Gradient for encoder.encoder.3.weight: 0.047079481184482574\n",
      "Gradient for encoder.encoder.3.bias: 3.15816789386858e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.006598371081054211\n",
      "Gradient for encoder.encoder.4.bias: 0.0064443135634064674\n",
      "Gradient for encoder.mean.weight: 0.08593150973320007\n",
      "Gradient for encoder.mean.bias: 0.005141204688698053\n",
      "Gradient for encoder.log_var.weight: 0.05168336257338524\n",
      "Gradient for encoder.log_var.bias: 0.003094423096626997\n",
      "Gradient for decoder.decoder.0.weight: 0.012526671402156353\n",
      "Gradient for decoder.decoder.0.bias: 1.0918098369838702e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0006599607295356691\n",
      "Gradient for decoder.decoder.1.bias: 0.0005061503034085035\n",
      "Gradient for decoder.decoder.3.weight: 0.011683489196002483\n",
      "Gradient for decoder.decoder.3.bias: 8.34808264182918e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0004323782632127404\n",
      "Gradient for decoder.decoder.4.bias: 0.0004007177776657045\n",
      "Gradient for decoder.decoder.6.weight: 0.0006748177693225443\n",
      "Gradient for decoder.decoder.6.bias: 3.561108678695746e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.017071658745408058\n",
      "Gradient for encoder.encoder.0.bias: 3.0179629628701576e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0016672255005687475\n",
      "Gradient for encoder.encoder.1.bias: 0.0014897570945322514\n",
      "Gradient for encoder.encoder.3.weight: 0.038486331701278687\n",
      "Gradient for encoder.encoder.3.bias: 2.7572019667410075e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.005101555958390236\n",
      "Gradient for encoder.encoder.4.bias: 0.0047640628181397915\n",
      "Gradient for encoder.mean.weight: 0.06725519150495529\n",
      "Gradient for encoder.mean.bias: 0.003710930934175849\n",
      "Gradient for encoder.log_var.weight: 0.038475364446640015\n",
      "Gradient for encoder.log_var.bias: 0.0021743415854871273\n",
      "Gradient for decoder.decoder.0.weight: 0.011426538228988647\n",
      "Gradient for decoder.decoder.0.bias: 9.296608621811586e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.000616043689660728\n",
      "Gradient for decoder.decoder.1.bias: 0.00042171854875050485\n",
      "Gradient for decoder.decoder.3.weight: 0.010388888418674469\n",
      "Gradient for decoder.decoder.3.bias: 7.401607104995378e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00038595861406065524\n",
      "Gradient for decoder.decoder.4.bias: 0.0003317578521091491\n",
      "Gradient for decoder.decoder.6.weight: 0.0006595322047360241\n",
      "Gradient for decoder.decoder.6.bias: 3.5889803257305175e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.020738843828439713\n",
      "Gradient for encoder.encoder.0.bias: 3.507160187266045e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0020926841534674168\n",
      "Gradient for encoder.encoder.1.bias: 0.0015951563837006688\n",
      "Gradient for encoder.encoder.3.weight: 0.03813726827502251\n",
      "Gradient for encoder.encoder.3.bias: 3.2244032444062043e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.009013146162033081\n",
      "Gradient for encoder.encoder.4.bias: 0.006496799644082785\n",
      "Gradient for encoder.mean.weight: 0.12048517167568207\n",
      "Gradient for encoder.mean.bias: 0.004159190226346254\n",
      "Gradient for encoder.log_var.weight: 0.07501260191202164\n",
      "Gradient for encoder.log_var.bias: 0.0025873861741274595\n",
      "Gradient for decoder.decoder.0.weight: 0.012239194475114346\n",
      "Gradient for decoder.decoder.0.bias: 1.0536500838487228e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0006117752636782825\n",
      "Gradient for decoder.decoder.1.bias: 0.00048715187585912645\n",
      "Gradient for decoder.decoder.3.weight: 0.011170427314937115\n",
      "Gradient for decoder.decoder.3.bias: 1.0912924036654559e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0007320759468711913\n",
      "Gradient for decoder.decoder.4.bias: 0.0008415654301643372\n",
      "Gradient for decoder.decoder.6.weight: 0.0007772940443828702\n",
      "Gradient for decoder.decoder.6.bias: 6.0900252719875425e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.018386634066700935\n",
      "Gradient for encoder.encoder.0.bias: 3.102391954445949e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0021104782354086637\n",
      "Gradient for encoder.encoder.1.bias: 0.0020130814518779516\n",
      "Gradient for encoder.encoder.3.weight: 0.04722517356276512\n",
      "Gradient for encoder.encoder.3.bias: 4.4492606821044944e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.011980476789176464\n",
      "Gradient for encoder.encoder.4.bias: 0.010343842208385468\n",
      "Gradient for encoder.mean.weight: 0.15143649280071259\n",
      "Gradient for encoder.mean.bias: 0.006649886257946491\n",
      "Gradient for encoder.log_var.weight: 0.09407960623502731\n",
      "Gradient for encoder.log_var.bias: 0.0041520558297634125\n",
      "Gradient for decoder.decoder.0.weight: 0.014283102005720139\n",
      "Gradient for decoder.decoder.0.bias: 1.0757352647550178e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0007652832427993417\n",
      "Gradient for decoder.decoder.1.bias: 0.0005638896836899221\n",
      "Gradient for decoder.decoder.3.weight: 0.013312102295458317\n",
      "Gradient for decoder.decoder.3.bias: 9.649836485436936e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0005008128355257213\n",
      "Gradient for decoder.decoder.4.bias: 0.000449395680334419\n",
      "Gradient for decoder.decoder.6.weight: 0.0007001180201768875\n",
      "Gradient for decoder.decoder.6.bias: 3.705801645992324e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.022575417533516884\n",
      "Gradient for encoder.encoder.0.bias: 3.165490786161129e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0026895510964095592\n",
      "Gradient for encoder.encoder.1.bias: 0.0021975573617964983\n",
      "Gradient for encoder.encoder.3.weight: 0.05615660175681114\n",
      "Gradient for encoder.encoder.3.bias: 3.4813196769789556e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.007783171255141497\n",
      "Gradient for encoder.encoder.4.bias: 0.006810062099248171\n",
      "Gradient for encoder.mean.weight: 0.10373584181070328\n",
      "Gradient for encoder.mean.bias: 0.005132060497999191\n",
      "Gradient for encoder.log_var.weight: 0.06089959293603897\n",
      "Gradient for encoder.log_var.bias: 0.003006019163876772\n",
      "Gradient for decoder.decoder.0.weight: 0.015276114456355572\n",
      "Gradient for decoder.decoder.0.bias: 1.3940212872931568e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0008412920869886875\n",
      "Gradient for decoder.decoder.1.bias: 0.0006434062961488962\n",
      "Gradient for decoder.decoder.3.weight: 0.014491257257759571\n",
      "Gradient for decoder.decoder.3.bias: 1.2546927385947981e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0006762876291759312\n",
      "Gradient for decoder.decoder.4.bias: 0.0006952577969059348\n",
      "Gradient for decoder.decoder.6.weight: 0.0008032596088014543\n",
      "Gradient for decoder.decoder.6.bias: 5.433880869532004e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.018664594739675522\n",
      "Gradient for encoder.encoder.0.bias: 3.147303598294293e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0020558289252221584\n",
      "Gradient for encoder.encoder.1.bias: 0.001956650987267494\n",
      "Gradient for encoder.encoder.3.weight: 0.04397716000676155\n",
      "Gradient for encoder.encoder.3.bias: 4.225933769586021e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.012706060893833637\n",
      "Gradient for encoder.encoder.4.bias: 0.010383631102740765\n",
      "Gradient for encoder.mean.weight: 0.1632727086544037\n",
      "Gradient for encoder.mean.bias: 0.006626473274081945\n",
      "Gradient for encoder.log_var.weight: 0.11167346686124802\n",
      "Gradient for encoder.log_var.bias: 0.004296724684536457\n",
      "Gradient for decoder.decoder.0.weight: 0.013038741424679756\n",
      "Gradient for decoder.decoder.0.bias: 1.1261255122851921e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0006669891881756485\n",
      "Gradient for decoder.decoder.1.bias: 0.0005594880203716457\n",
      "Gradient for decoder.decoder.3.weight: 0.01193233858793974\n",
      "Gradient for decoder.decoder.3.bias: 1.0680755585523727e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0006618324550800025\n",
      "Gradient for decoder.decoder.4.bias: 0.0007410496473312378\n",
      "Gradient for decoder.decoder.6.weight: 0.0007466909592039883\n",
      "Gradient for decoder.decoder.6.bias: 5.8139750763075426e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.017030559480190277\n",
      "Gradient for encoder.encoder.0.bias: 2.6046305737215114e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0018447900656610727\n",
      "Gradient for encoder.encoder.1.bias: 0.0014741956256330013\n",
      "Gradient for encoder.encoder.3.weight: 0.036301176995038986\n",
      "Gradient for encoder.encoder.3.bias: 2.660353604078125e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0052628968842327595\n",
      "Gradient for encoder.encoder.4.bias: 0.004697468131780624\n",
      "Gradient for encoder.mean.weight: 0.07379847019910812\n",
      "Gradient for encoder.mean.bias: 0.003257372649386525\n",
      "Gradient for encoder.log_var.weight: 0.037959132343530655\n",
      "Gradient for encoder.log_var.bias: 0.0019358893623575568\n",
      "Gradient for decoder.decoder.0.weight: 0.01471463218331337\n",
      "Gradient for decoder.decoder.0.bias: 1.3093150175169654e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0007582014077343047\n",
      "Gradient for decoder.decoder.1.bias: 0.0006047333008609712\n",
      "Gradient for decoder.decoder.3.weight: 0.013462238013744354\n",
      "Gradient for decoder.decoder.3.bias: 1.2457883336036701e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0006344551802612841\n",
      "Gradient for decoder.decoder.4.bias: 0.0007137059583328664\n",
      "Gradient for decoder.decoder.6.weight: 0.0008098375983536243\n",
      "Gradient for decoder.decoder.6.bias: 6.100091559346765e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.014970938675105572\n",
      "Gradient for encoder.encoder.0.bias: 2.1056113450046432e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0014532719505950809\n",
      "Gradient for encoder.encoder.1.bias: 0.0011442299000918865\n",
      "Gradient for encoder.encoder.3.weight: 0.031576283276081085\n",
      "Gradient for encoder.encoder.3.bias: 2.4868371251152155e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.005845789797604084\n",
      "Gradient for encoder.encoder.4.bias: 0.004713207017630339\n",
      "Gradient for encoder.mean.weight: 0.08359656482934952\n",
      "Gradient for encoder.mean.bias: 0.0035441869404166937\n",
      "Gradient for encoder.log_var.weight: 0.04089556634426117\n",
      "Gradient for encoder.log_var.bias: 0.0021037557162344456\n",
      "Gradient for decoder.decoder.0.weight: 0.016878673806786537\n",
      "Gradient for decoder.decoder.0.bias: 1.4082050803221335e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0008643303299322724\n",
      "Gradient for decoder.decoder.1.bias: 0.0006691814051009715\n",
      "Gradient for decoder.decoder.3.weight: 0.015411688014864922\n",
      "Gradient for decoder.decoder.3.bias: 1.1451154607877712e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0005859241937287152\n",
      "Gradient for decoder.decoder.4.bias: 0.000531575467903167\n",
      "Gradient for decoder.decoder.6.weight: 0.0007405343349091709\n",
      "Gradient for decoder.decoder.6.bias: 4.2794050386874005e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.05320116877555847\n",
      "Gradient for encoder.encoder.0.bias: 8.194729617105878e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.004955010488629341\n",
      "Gradient for encoder.encoder.1.bias: 0.004871208220720291\n",
      "Gradient for encoder.encoder.3.weight: 0.10053583979606628\n",
      "Gradient for encoder.encoder.3.bias: 9.278006696256114e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.017511051148176193\n",
      "Gradient for encoder.encoder.4.bias: 0.019312554970383644\n",
      "Gradient for encoder.mean.weight: 0.23112492263317108\n",
      "Gradient for encoder.mean.bias: 0.013089342974126339\n",
      "Gradient for encoder.log_var.weight: 0.140062153339386\n",
      "Gradient for encoder.log_var.bias: 0.008071341551840305\n",
      "Gradient for decoder.decoder.0.weight: 0.03842954710125923\n",
      "Gradient for decoder.decoder.0.bias: 2.742887028617247e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0015242811059579253\n",
      "Gradient for decoder.decoder.1.bias: 0.0013894460862502456\n",
      "Gradient for decoder.decoder.3.weight: 0.03357289731502533\n",
      "Gradient for decoder.decoder.3.bias: 2.3898832912649937e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0014010894810780883\n",
      "Gradient for decoder.decoder.4.bias: 0.0013135415501892567\n",
      "Gradient for decoder.decoder.6.weight: 0.0022121830843389034\n",
      "Gradient for decoder.decoder.6.bias: 0.00012885777687188238\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3, Train Loss: 0.0780, Val Loss: 0.3331\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training VAE Epoch:   1%|▏         | 1/79 [00:00<00:14,  5.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient for encoder.encoder.0.weight: 0.019338827580213547\n",
      "Gradient for encoder.encoder.0.bias: 3.529623815445859e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0030588393565267324\n",
      "Gradient for encoder.encoder.1.bias: 0.002169012324884534\n",
      "Gradient for encoder.encoder.3.weight: 0.058255452662706375\n",
      "Gradient for encoder.encoder.3.bias: 3.526320069280331e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0111303785815835\n",
      "Gradient for encoder.encoder.4.bias: 0.00812303926795721\n",
      "Gradient for encoder.mean.weight: 0.15085168182849884\n",
      "Gradient for encoder.mean.bias: 0.005099598318338394\n",
      "Gradient for encoder.log_var.weight: 0.08458558470010757\n",
      "Gradient for encoder.log_var.bias: 0.003076404333114624\n",
      "Gradient for decoder.decoder.0.weight: 0.01511955913156271\n",
      "Gradient for decoder.decoder.0.bias: 1.430385115908095e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0008187544881366193\n",
      "Gradient for decoder.decoder.1.bias: 0.000588464317843318\n",
      "Gradient for decoder.decoder.3.weight: 0.013575202785432339\n",
      "Gradient for decoder.decoder.3.bias: 1.3171276569412527e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0007208841852843761\n",
      "Gradient for decoder.decoder.4.bias: 0.0008111506467685103\n",
      "Gradient for decoder.decoder.6.weight: 0.0007731241639703512\n",
      "Gradient for decoder.decoder.6.bias: 5.347046680981293e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.015895988792181015\n",
      "Gradient for encoder.encoder.0.bias: 2.5443019219251184e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.002002130728214979\n",
      "Gradient for encoder.encoder.1.bias: 0.0015502505702897906\n",
      "Gradient for encoder.encoder.3.weight: 0.04104842618107796\n",
      "Gradient for encoder.encoder.3.bias: 2.3888188649401343e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0068305726163089275\n",
      "Gradient for encoder.encoder.4.bias: 0.004981210455298424\n",
      "Gradient for encoder.mean.weight: 0.09222294390201569\n",
      "Gradient for encoder.mean.bias: 0.0037515931762754917\n",
      "Gradient for encoder.log_var.weight: 0.05651768296957016\n",
      "Gradient for encoder.log_var.bias: 0.0025402840692549944\n",
      "Gradient for decoder.decoder.0.weight: 0.014200716279447079\n",
      "Gradient for decoder.decoder.0.bias: 1.1557016454943891e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0007439674227498472\n",
      "Gradient for decoder.decoder.1.bias: 0.0004967062850482762\n",
      "Gradient for decoder.decoder.3.weight: 0.012476573698222637\n",
      "Gradient for decoder.decoder.3.bias: 1.1973282088018067e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0007342637400142848\n",
      "Gradient for decoder.decoder.4.bias: 0.0008317793835885823\n",
      "Gradient for decoder.decoder.6.weight: 0.0007394447457045317\n",
      "Gradient for decoder.decoder.6.bias: 5.3700430726166815e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training VAE Epoch:  11%|█▏        | 9/79 [00:00<00:01, 37.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient for encoder.encoder.0.weight: 0.018384942784905434\n",
      "Gradient for encoder.encoder.0.bias: 2.4746022939114987e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.002068751724436879\n",
      "Gradient for encoder.encoder.1.bias: 0.0016838227165862918\n",
      "Gradient for encoder.encoder.3.weight: 0.04050937667489052\n",
      "Gradient for encoder.encoder.3.bias: 3.043144070069559e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0067138671875\n",
      "Gradient for encoder.encoder.4.bias: 0.006479328032582998\n",
      "Gradient for encoder.mean.weight: 0.08817296475172043\n",
      "Gradient for encoder.mean.bias: 0.0049828821793198586\n",
      "Gradient for encoder.log_var.weight: 0.04876412823796272\n",
      "Gradient for encoder.log_var.bias: 0.0030468290206044912\n",
      "Gradient for decoder.decoder.0.weight: 0.015832029283046722\n",
      "Gradient for decoder.decoder.0.bias: 1.4406509318831695e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0008415986085310578\n",
      "Gradient for decoder.decoder.1.bias: 0.0006520349998027086\n",
      "Gradient for decoder.decoder.3.weight: 0.01457610446959734\n",
      "Gradient for decoder.decoder.3.bias: 1.2485450173738144e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0005361681105569005\n",
      "Gradient for decoder.decoder.4.bias: 0.00045924208825454116\n",
      "Gradient for decoder.decoder.6.weight: 0.0006514973356388509\n",
      "Gradient for decoder.decoder.6.bias: 3.097178341704421e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.018807856366038322\n",
      "Gradient for encoder.encoder.0.bias: 2.6333454514193555e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.001774500240571797\n",
      "Gradient for encoder.encoder.1.bias: 0.0015603218926116824\n",
      "Gradient for encoder.encoder.3.weight: 0.0386882908642292\n",
      "Gradient for encoder.encoder.3.bias: 4.6320430824309256e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.011132542975246906\n",
      "Gradient for encoder.encoder.4.bias: 0.011476611718535423\n",
      "Gradient for encoder.mean.weight: 0.14200638234615326\n",
      "Gradient for encoder.mean.bias: 0.006078733596950769\n",
      "Gradient for encoder.log_var.weight: 0.08020104467868805\n",
      "Gradient for encoder.log_var.bias: 0.0036837421357631683\n",
      "Gradient for decoder.decoder.0.weight: 0.019470402970910072\n",
      "Gradient for decoder.decoder.0.bias: 1.6553677872899186e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0009629316045902669\n",
      "Gradient for decoder.decoder.1.bias: 0.0008313576690852642\n",
      "Gradient for decoder.decoder.3.weight: 0.017282355576753616\n",
      "Gradient for decoder.decoder.3.bias: 1.561655388337968e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0009403539588674903\n",
      "Gradient for decoder.decoder.4.bias: 0.0010922582587227225\n",
      "Gradient for decoder.decoder.6.weight: 0.0008301319903694093\n",
      "Gradient for decoder.decoder.6.bias: 5.5254025937756523e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.019003042951226234\n",
      "Gradient for encoder.encoder.0.bias: 3.738804404962437e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0030662259086966515\n",
      "Gradient for encoder.encoder.1.bias: 0.0021434989757835865\n",
      "Gradient for encoder.encoder.3.weight: 0.0556529276072979\n",
      "Gradient for encoder.encoder.3.bias: 4.2431125280018023e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.008295228704810143\n",
      "Gradient for encoder.encoder.4.bias: 0.00771348224952817\n",
      "Gradient for encoder.mean.weight: 0.1142372190952301\n",
      "Gradient for encoder.mean.bias: 0.006518315989524126\n",
      "Gradient for encoder.log_var.weight: 0.06407588720321655\n",
      "Gradient for encoder.log_var.bias: 0.003813661402091384\n",
      "Gradient for decoder.decoder.0.weight: 0.011846262961626053\n",
      "Gradient for decoder.decoder.0.bias: 1.0031377117858398e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.000635071424767375\n",
      "Gradient for decoder.decoder.1.bias: 0.000447145604994148\n",
      "Gradient for decoder.decoder.3.weight: 0.011149485595524311\n",
      "Gradient for decoder.decoder.3.bias: 9.774952375307677e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00044617141247726977\n",
      "Gradient for decoder.decoder.4.bias: 0.000479320646263659\n",
      "Gradient for decoder.decoder.6.weight: 0.0006860211724415421\n",
      "Gradient for decoder.decoder.6.bias: 4.232104038237594e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.016787393018603325\n",
      "Gradient for encoder.encoder.0.bias: 2.7160256682590145e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0021487316116690636\n",
      "Gradient for encoder.encoder.1.bias: 0.0016294034430757165\n",
      "Gradient for encoder.encoder.3.weight: 0.042564909905195236\n",
      "Gradient for encoder.encoder.3.bias: 3.3186456360745353e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.006532819010317326\n",
      "Gradient for encoder.encoder.4.bias: 0.007052524480968714\n",
      "Gradient for encoder.mean.weight: 0.08685406297445297\n",
      "Gradient for encoder.mean.bias: 0.005016656126827002\n",
      "Gradient for encoder.log_var.weight: 0.05408009514212608\n",
      "Gradient for encoder.log_var.bias: 0.0030587399378418922\n",
      "Gradient for decoder.decoder.0.weight: 0.0179437343031168\n",
      "Gradient for decoder.decoder.0.bias: 1.628836371336817e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0009421958238817751\n",
      "Gradient for decoder.decoder.1.bias: 0.0007403171039186418\n",
      "Gradient for decoder.decoder.3.weight: 0.016260484233498573\n",
      "Gradient for decoder.decoder.3.bias: 1.7465554003059935e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0006687995046377182\n",
      "Gradient for decoder.decoder.4.bias: 0.0006430083885788918\n",
      "Gradient for decoder.decoder.6.weight: 0.0007420802139677107\n",
      "Gradient for decoder.decoder.6.bias: 4.176169750280678e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.01650475338101387\n",
      "Gradient for encoder.encoder.0.bias: 2.6176193157478878e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.001625392702408135\n",
      "Gradient for encoder.encoder.1.bias: 0.0013142152456566691\n",
      "Gradient for encoder.encoder.3.weight: 0.03100578300654888\n",
      "Gradient for encoder.encoder.3.bias: 2.685333067020679e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.006122481543570757\n",
      "Gradient for encoder.encoder.4.bias: 0.005235804244875908\n",
      "Gradient for encoder.mean.weight: 0.08318617939949036\n",
      "Gradient for encoder.mean.bias: 0.004154955502599478\n",
      "Gradient for encoder.log_var.weight: 0.05557352676987648\n",
      "Gradient for encoder.log_var.bias: 0.0025758552365005016\n",
      "Gradient for decoder.decoder.0.weight: 0.012045598588883877\n",
      "Gradient for decoder.decoder.0.bias: 1.1048752190934152e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0005799304926767945\n",
      "Gradient for decoder.decoder.1.bias: 0.00046639645006507635\n",
      "Gradient for decoder.decoder.3.weight: 0.010939241386950016\n",
      "Gradient for decoder.decoder.3.bias: 9.405962814179603e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.000389736145734787\n",
      "Gradient for decoder.decoder.4.bias: 0.0003630460996646434\n",
      "Gradient for decoder.decoder.6.weight: 0.0006836189422756433\n",
      "Gradient for decoder.decoder.6.bias: 3.872531306114979e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.01704111509025097\n",
      "Gradient for encoder.encoder.0.bias: 2.6883452061698954e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0022794269025325775\n",
      "Gradient for encoder.encoder.1.bias: 0.0017697543371468782\n",
      "Gradient for encoder.encoder.3.weight: 0.04578103870153427\n",
      "Gradient for encoder.encoder.3.bias: 2.846694824309992e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.005847516469657421\n",
      "Gradient for encoder.encoder.4.bias: 0.0058046020567417145\n",
      "Gradient for encoder.mean.weight: 0.07960666716098785\n",
      "Gradient for encoder.mean.bias: 0.004130554385483265\n",
      "Gradient for encoder.log_var.weight: 0.04965644329786301\n",
      "Gradient for encoder.log_var.bias: 0.0024854964576661587\n",
      "Gradient for decoder.decoder.0.weight: 0.01605241745710373\n",
      "Gradient for decoder.decoder.0.bias: 1.2718971709180238e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0007748505449853837\n",
      "Gradient for decoder.decoder.1.bias: 0.0006058165454305708\n",
      "Gradient for decoder.decoder.3.weight: 0.014654009602963924\n",
      "Gradient for decoder.decoder.3.bias: 1.0487695434324706e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0005410609883256257\n",
      "Gradient for decoder.decoder.4.bias: 0.00046549970284104347\n",
      "Gradient for decoder.decoder.6.weight: 0.0006923791370354593\n",
      "Gradient for decoder.decoder.6.bias: 3.483261389192194e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.03353437781333923\n",
      "Gradient for encoder.encoder.0.bias: 6.68057206776318e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0037946088705211878\n",
      "Gradient for encoder.encoder.1.bias: 0.0031646203715354204\n",
      "Gradient for encoder.encoder.3.weight: 0.08167821913957596\n",
      "Gradient for encoder.encoder.3.bias: 4.1564734987176166e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.008143817074596882\n",
      "Gradient for encoder.encoder.4.bias: 0.008213894441723824\n",
      "Gradient for encoder.mean.weight: 0.11067304760217667\n",
      "Gradient for encoder.mean.bias: 0.004236070439219475\n",
      "Gradient for encoder.log_var.weight: 0.07813186943531036\n",
      "Gradient for encoder.log_var.bias: 0.0028813935350626707\n",
      "Gradient for decoder.decoder.0.weight: 0.010624842718243599\n",
      "Gradient for decoder.decoder.0.bias: 9.289501806675204e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.000532410922460258\n",
      "Gradient for decoder.decoder.1.bias: 0.0004188123275525868\n",
      "Gradient for decoder.decoder.3.weight: 0.009810350835323334\n",
      "Gradient for decoder.decoder.3.bias: 8.326045408679761e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00035485386615619063\n",
      "Gradient for decoder.decoder.4.bias: 0.0002997427072841674\n",
      "Gradient for decoder.decoder.6.weight: 0.0006536219152621925\n",
      "Gradient for decoder.decoder.6.bias: 3.604749508667737e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.014542118646204472\n",
      "Gradient for encoder.encoder.0.bias: 2.4622831551468494e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0016822625184431672\n",
      "Gradient for encoder.encoder.1.bias: 0.0014182456070557237\n",
      "Gradient for encoder.encoder.3.weight: 0.035149239003658295\n",
      "Gradient for encoder.encoder.3.bias: 3.011935700847346e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.006600996013730764\n",
      "Gradient for encoder.encoder.4.bias: 0.006210402585566044\n",
      "Gradient for encoder.mean.weight: 0.08578932285308838\n",
      "Gradient for encoder.mean.bias: 0.004762498661875725\n",
      "Gradient for encoder.log_var.weight: 0.04779403656721115\n",
      "Gradient for encoder.log_var.bias: 0.003105723764747381\n",
      "Gradient for decoder.decoder.0.weight: 0.016163481399416924\n",
      "Gradient for decoder.decoder.0.bias: 1.2582236641467404e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0007933953893370926\n",
      "Gradient for decoder.decoder.1.bias: 0.000605899142101407\n",
      "Gradient for decoder.decoder.3.weight: 0.014343843795359135\n",
      "Gradient for decoder.decoder.3.bias: 1.1497736096544031e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0005422962130978703\n",
      "Gradient for decoder.decoder.4.bias: 0.00047957146307453513\n",
      "Gradient for decoder.decoder.6.weight: 0.0006699343211948872\n",
      "Gradient for decoder.decoder.6.bias: 3.407762051210739e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.014320765621960163\n",
      "Gradient for encoder.encoder.0.bias: 2.4061712691758608e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0018401973647996783\n",
      "Gradient for encoder.encoder.1.bias: 0.0015563787892460823\n",
      "Gradient for encoder.encoder.3.weight: 0.039940085262060165\n",
      "Gradient for encoder.encoder.3.bias: 3.201127418694938e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.007234437391161919\n",
      "Gradient for encoder.encoder.4.bias: 0.006836211774498224\n",
      "Gradient for encoder.mean.weight: 0.0902026891708374\n",
      "Gradient for encoder.mean.bias: 0.005218392703682184\n",
      "Gradient for encoder.log_var.weight: 0.05247271806001663\n",
      "Gradient for encoder.log_var.bias: 0.002867391100153327\n",
      "Gradient for decoder.decoder.0.weight: 0.014419274404644966\n",
      "Gradient for decoder.decoder.0.bias: 1.149441375414284e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0007430478581227362\n",
      "Gradient for decoder.decoder.1.bias: 0.0005884047131985426\n",
      "Gradient for decoder.decoder.3.weight: 0.01350908912718296\n",
      "Gradient for decoder.decoder.3.bias: 1.0136672057292628e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.00048017650260590017\n",
      "Gradient for decoder.decoder.4.bias: 0.00043021028977818787\n",
      "Gradient for decoder.decoder.6.weight: 0.0006777388043701649\n",
      "Gradient for decoder.decoder.6.bias: 3.1687915907241404e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.016591735184192657\n",
      "Gradient for encoder.encoder.0.bias: 2.6115668655402047e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.00179027090780437\n",
      "Gradient for encoder.encoder.1.bias: 0.0014210803201422095\n",
      "Gradient for encoder.encoder.3.weight: 0.03875279426574707\n",
      "Gradient for encoder.encoder.3.bias: 2.986233482715761e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.006431402172893286\n",
      "Gradient for encoder.encoder.4.bias: 0.007325050421059132\n",
      "Gradient for encoder.mean.weight: 0.07920259237289429\n",
      "Gradient for encoder.mean.bias: 0.005437649320811033\n",
      "Gradient for encoder.log_var.weight: 0.048535846173763275\n",
      "Gradient for encoder.log_var.bias: 0.003129565855488181\n",
      "Gradient for decoder.decoder.0.weight: 0.013607451692223549\n",
      "Gradient for decoder.decoder.0.bias: 1.2615551658878843e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0006341920816339552\n",
      "Gradient for decoder.decoder.1.bias: 0.0005138418637216091\n",
      "Gradient for decoder.decoder.3.weight: 0.012141687795519829\n",
      "Gradient for decoder.decoder.3.bias: 1.288669310151036e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0005237823352217674\n",
      "Gradient for decoder.decoder.4.bias: 0.0005875413189642131\n",
      "Gradient for decoder.decoder.6.weight: 0.0006822545547038317\n",
      "Gradient for decoder.decoder.6.bias: 4.167243969277479e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.019500019028782845\n",
      "Gradient for encoder.encoder.0.bias: 3.4275131344241316e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.002074057934805751\n",
      "Gradient for encoder.encoder.1.bias: 0.001635952154174447\n",
      "Gradient for encoder.encoder.3.weight: 0.04337899014353752\n",
      "Gradient for encoder.encoder.3.bias: 3.153826089175027e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.006294329185038805\n",
      "Gradient for encoder.encoder.4.bias: 0.005836705211549997\n",
      "Gradient for encoder.mean.weight: 0.08439119905233383\n",
      "Gradient for encoder.mean.bias: 0.0045760986395180225\n",
      "Gradient for encoder.log_var.weight: 0.051562145352363586\n",
      "Gradient for encoder.log_var.bias: 0.0029439351055771112\n",
      "Gradient for decoder.decoder.0.weight: 0.012537839822471142\n",
      "Gradient for decoder.decoder.0.bias: 9.619693236428972e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.000632195733487606\n",
      "Gradient for decoder.decoder.1.bias: 0.0004562188987620175\n",
      "Gradient for decoder.decoder.3.weight: 0.011242091655731201\n",
      "Gradient for decoder.decoder.3.bias: 9.717731480618497e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00041851584683172405\n",
      "Gradient for decoder.decoder.4.bias: 0.00042116030817851424\n",
      "Gradient for decoder.decoder.6.weight: 0.0006686603301204741\n",
      "Gradient for decoder.decoder.6.bias: 4.0367889596382156e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.02464519999921322\n",
      "Gradient for encoder.encoder.0.bias: 3.543326743127295e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0022203854750841856\n",
      "Gradient for encoder.encoder.1.bias: 0.0021344712004065514\n",
      "Gradient for encoder.encoder.3.weight: 0.04948261007666588\n",
      "Gradient for encoder.encoder.3.bias: 5.149435322593376e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.013698415830731392\n",
      "Gradient for encoder.encoder.4.bias: 0.009681018069386482\n",
      "Gradient for encoder.mean.weight: 0.17847053706645966\n",
      "Gradient for encoder.mean.bias: 0.005712159443646669\n",
      "Gradient for encoder.log_var.weight: 0.10927831381559372\n",
      "Gradient for encoder.log_var.bias: 0.0035871402360498905\n",
      "Gradient for decoder.decoder.0.weight: 0.015435438603162766\n",
      "Gradient for decoder.decoder.0.bias: 1.2923788428320648e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0007965005352161825\n",
      "Gradient for decoder.decoder.1.bias: 0.0006193051231093705\n",
      "Gradient for decoder.decoder.3.weight: 0.01359492726624012\n",
      "Gradient for decoder.decoder.3.bias: 1.1009652911564416e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0005070433835498989\n",
      "Gradient for decoder.decoder.4.bias: 0.00041627505561336875\n",
      "Gradient for decoder.decoder.6.weight: 0.0006876433035358787\n",
      "Gradient for decoder.decoder.6.bias: 3.8080670492490754e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.014906509779393673\n",
      "Gradient for encoder.encoder.0.bias: 2.0305555847865975e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0016305741155520082\n",
      "Gradient for encoder.encoder.1.bias: 0.001262940582819283\n",
      "Gradient for encoder.encoder.3.weight: 0.0342913493514061\n",
      "Gradient for encoder.encoder.3.bias: 2.788714814627724e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.006259051617234945\n",
      "Gradient for encoder.encoder.4.bias: 0.005604326259344816\n",
      "Gradient for encoder.mean.weight: 0.08946359157562256\n",
      "Gradient for encoder.mean.bias: 0.00508042611181736\n",
      "Gradient for encoder.log_var.weight: 0.052947528660297394\n",
      "Gradient for encoder.log_var.bias: 0.003260101657360792\n",
      "Gradient for decoder.decoder.0.weight: 0.017225326970219612\n",
      "Gradient for decoder.decoder.0.bias: 1.5222340055132122e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0008936949889175594\n",
      "Gradient for decoder.decoder.1.bias: 0.0006814489606767893\n",
      "Gradient for decoder.decoder.3.weight: 0.01567244715988636\n",
      "Gradient for decoder.decoder.3.bias: 1.4473830467487403e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0007945746183395386\n",
      "Gradient for decoder.decoder.4.bias: 0.0008700637263245881\n",
      "Gradient for decoder.decoder.6.weight: 0.000812992628198117\n",
      "Gradient for decoder.decoder.6.bias: 5.1808005082421005e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.01764029450714588\n",
      "Gradient for encoder.encoder.0.bias: 2.838371204738621e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0017272826517000794\n",
      "Gradient for encoder.encoder.1.bias: 0.0015325071290135384\n",
      "Gradient for encoder.encoder.3.weight: 0.03655090555548668\n",
      "Gradient for encoder.encoder.3.bias: 3.091988609593699e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.006418534088879824\n",
      "Gradient for encoder.encoder.4.bias: 0.005461435299366713\n",
      "Gradient for encoder.mean.weight: 0.0848260149359703\n",
      "Gradient for encoder.mean.bias: 0.003559294156730175\n",
      "Gradient for encoder.log_var.weight: 0.053312815725803375\n",
      "Gradient for encoder.log_var.bias: 0.0023860475048422813\n",
      "Gradient for decoder.decoder.0.weight: 0.013309351168572903\n",
      "Gradient for decoder.decoder.0.bias: 1.1072683742119338e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0006524514174088836\n",
      "Gradient for decoder.decoder.1.bias: 0.0005279714823700488\n",
      "Gradient for decoder.decoder.3.weight: 0.012415239587426186\n",
      "Gradient for decoder.decoder.3.bias: 9.540432333032811e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0005628658109344542\n",
      "Gradient for decoder.decoder.4.bias: 0.0005257396260276437\n",
      "Gradient for decoder.decoder.6.weight: 0.0007787212380208075\n",
      "Gradient for decoder.decoder.6.bias: 4.715623435913585e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training VAE Epoch:  22%|██▏       | 17/79 [00:00<00:01, 52.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient for encoder.encoder.0.weight: 0.014935527928173542\n",
      "Gradient for encoder.encoder.0.bias: 2.381939263884636e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0016288667684420943\n",
      "Gradient for encoder.encoder.1.bias: 0.0013683685101568699\n",
      "Gradient for encoder.encoder.3.weight: 0.03384777158498764\n",
      "Gradient for encoder.encoder.3.bias: 2.4507845752808066e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.005182778928428888\n",
      "Gradient for encoder.encoder.4.bias: 0.005016313400119543\n",
      "Gradient for encoder.mean.weight: 0.06750425696372986\n",
      "Gradient for encoder.mean.bias: 0.003754159202799201\n",
      "Gradient for encoder.log_var.weight: 0.040358737111091614\n",
      "Gradient for encoder.log_var.bias: 0.002623239764943719\n",
      "Gradient for decoder.decoder.0.weight: 0.013017840683460236\n",
      "Gradient for decoder.decoder.0.bias: 1.0992223797856582e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0006809576880186796\n",
      "Gradient for decoder.decoder.1.bias: 0.0005117191467434168\n",
      "Gradient for decoder.decoder.3.weight: 0.011720121838152409\n",
      "Gradient for decoder.decoder.3.bias: 9.448826443492209e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0005328852566890419\n",
      "Gradient for decoder.decoder.4.bias: 0.00057471968466416\n",
      "Gradient for decoder.decoder.6.weight: 0.0006708088330924511\n",
      "Gradient for decoder.decoder.6.bias: 3.7513422284973785e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.01555544976145029\n",
      "Gradient for encoder.encoder.0.bias: 2.554308500823943e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.00168780202511698\n",
      "Gradient for encoder.encoder.1.bias: 0.0013235467486083508\n",
      "Gradient for encoder.encoder.3.weight: 0.0353567898273468\n",
      "Gradient for encoder.encoder.3.bias: 2.610686389292738e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.006426149047911167\n",
      "Gradient for encoder.encoder.4.bias: 0.005630032625049353\n",
      "Gradient for encoder.mean.weight: 0.08491244167089462\n",
      "Gradient for encoder.mean.bias: 0.0040375166572630405\n",
      "Gradient for encoder.log_var.weight: 0.042801618576049805\n",
      "Gradient for encoder.log_var.bias: 0.0023469391744583845\n",
      "Gradient for decoder.decoder.0.weight: 0.01237468421459198\n",
      "Gradient for decoder.decoder.0.bias: 1.0927458243825683e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0006469722138717771\n",
      "Gradient for decoder.decoder.1.bias: 0.0005278802709653974\n",
      "Gradient for decoder.decoder.3.weight: 0.011499635875225067\n",
      "Gradient for decoder.decoder.3.bias: 9.241103715584842e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0004516220069490373\n",
      "Gradient for decoder.decoder.4.bias: 0.00043045260827057064\n",
      "Gradient for decoder.decoder.6.weight: 0.0006784099969081581\n",
      "Gradient for decoder.decoder.6.bias: 4.0117283788276836e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training VAE Epoch:  32%|███▏      | 25/79 [00:00<00:00, 61.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient for encoder.encoder.0.weight: 0.014809622429311275\n",
      "Gradient for encoder.encoder.0.bias: 2.1011376666324466e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0014705624198541045\n",
      "Gradient for encoder.encoder.1.bias: 0.0012708124704658985\n",
      "Gradient for encoder.encoder.3.weight: 0.03274212405085564\n",
      "Gradient for encoder.encoder.3.bias: 2.7263735713489723e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0052437749691307545\n",
      "Gradient for encoder.encoder.4.bias: 0.005624260287731886\n",
      "Gradient for encoder.mean.weight: 0.0707794800400734\n",
      "Gradient for encoder.mean.bias: 0.004631287883967161\n",
      "Gradient for encoder.log_var.weight: 0.03906722366809845\n",
      "Gradient for encoder.log_var.bias: 0.0025810219813138247\n",
      "Gradient for decoder.decoder.0.weight: 0.015118679031729698\n",
      "Gradient for decoder.decoder.0.bias: 1.25773988446376e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0007122783572413027\n",
      "Gradient for decoder.decoder.1.bias: 0.0006207256228663027\n",
      "Gradient for decoder.decoder.3.weight: 0.01377546414732933\n",
      "Gradient for decoder.decoder.3.bias: 1.0052828708362327e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0004905693349428475\n",
      "Gradient for decoder.decoder.4.bias: 0.000433531153248623\n",
      "Gradient for decoder.decoder.6.weight: 0.0007067082333378494\n",
      "Gradient for decoder.decoder.6.bias: 3.568834290490486e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.018257129937410355\n",
      "Gradient for encoder.encoder.0.bias: 3.2573128222468384e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0024723908863961697\n",
      "Gradient for encoder.encoder.1.bias: 0.0017799134366214275\n",
      "Gradient for encoder.encoder.3.weight: 0.04726339504122734\n",
      "Gradient for encoder.encoder.3.bias: 3.989618357902458e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.008657622151076794\n",
      "Gradient for encoder.encoder.4.bias: 0.008811013773083687\n",
      "Gradient for encoder.mean.weight: 0.11879017949104309\n",
      "Gradient for encoder.mean.bias: 0.0067190565168857574\n",
      "Gradient for encoder.log_var.weight: 0.06258190423250198\n",
      "Gradient for encoder.log_var.bias: 0.0038950687739998102\n",
      "Gradient for decoder.decoder.0.weight: 0.01224848348647356\n",
      "Gradient for decoder.decoder.0.bias: 9.702957187718297e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0006323081906884909\n",
      "Gradient for decoder.decoder.1.bias: 0.0004911358118988574\n",
      "Gradient for decoder.decoder.3.weight: 0.011159476824104786\n",
      "Gradient for decoder.decoder.3.bias: 9.264215089510586e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00041398778557777405\n",
      "Gradient for decoder.decoder.4.bias: 0.00039002607809379697\n",
      "Gradient for decoder.decoder.6.weight: 0.0006816077511757612\n",
      "Gradient for decoder.decoder.6.bias: 4.3856176489498466e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.015900662168860435\n",
      "Gradient for encoder.encoder.0.bias: 2.6037637324005658e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0016707901377230883\n",
      "Gradient for encoder.encoder.1.bias: 0.001281483331695199\n",
      "Gradient for encoder.encoder.3.weight: 0.03194943070411682\n",
      "Gradient for encoder.encoder.3.bias: 2.579375601996503e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.004119387362152338\n",
      "Gradient for encoder.encoder.4.bias: 0.004423897713422775\n",
      "Gradient for encoder.mean.weight: 0.05903603509068489\n",
      "Gradient for encoder.mean.bias: 0.003912213258445263\n",
      "Gradient for encoder.log_var.weight: 0.03362581133842468\n",
      "Gradient for encoder.log_var.bias: 0.002422844525426626\n",
      "Gradient for decoder.decoder.0.weight: 0.013554466888308525\n",
      "Gradient for decoder.decoder.0.bias: 1.0883328266375614e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0006847159820608795\n",
      "Gradient for decoder.decoder.1.bias: 0.0005330021376721561\n",
      "Gradient for decoder.decoder.3.weight: 0.012577023357152939\n",
      "Gradient for decoder.decoder.3.bias: 9.232547365511934e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0004704572493210435\n",
      "Gradient for decoder.decoder.4.bias: 0.00044743859325535595\n",
      "Gradient for decoder.decoder.6.weight: 0.0007074037566781044\n",
      "Gradient for decoder.decoder.6.bias: 3.9309528801823035e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.016368327662348747\n",
      "Gradient for encoder.encoder.0.bias: 3.419339464350024e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0019718059338629246\n",
      "Gradient for encoder.encoder.1.bias: 0.002147186314687133\n",
      "Gradient for encoder.encoder.3.weight: 0.04130407050251961\n",
      "Gradient for encoder.encoder.3.bias: 3.9756162251158855e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.011402442120015621\n",
      "Gradient for encoder.encoder.4.bias: 0.009727219119668007\n",
      "Gradient for encoder.mean.weight: 0.13687926530838013\n",
      "Gradient for encoder.mean.bias: 0.006506334058940411\n",
      "Gradient for encoder.log_var.weight: 0.09443049132823944\n",
      "Gradient for encoder.log_var.bias: 0.004259126726537943\n",
      "Gradient for decoder.decoder.0.weight: 0.012835228815674782\n",
      "Gradient for decoder.decoder.0.bias: 9.750692614440837e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0006135928560979664\n",
      "Gradient for decoder.decoder.1.bias: 0.0004993993206880987\n",
      "Gradient for decoder.decoder.3.weight: 0.01140506099909544\n",
      "Gradient for decoder.decoder.3.bias: 1.4912407420020202e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0010821566684171557\n",
      "Gradient for decoder.decoder.4.bias: 0.0013883354840800166\n",
      "Gradient for decoder.decoder.6.weight: 0.0009567025117576122\n",
      "Gradient for decoder.decoder.6.bias: 8.884457929525524e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.023803548887372017\n",
      "Gradient for encoder.encoder.0.bias: 4.801957789735134e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.004303055349737406\n",
      "Gradient for encoder.encoder.1.bias: 0.003261024132370949\n",
      "Gradient for encoder.encoder.3.weight: 0.08987297862768173\n",
      "Gradient for encoder.encoder.3.bias: 4.129764585858453e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.01108656544238329\n",
      "Gradient for encoder.encoder.4.bias: 0.008609233424067497\n",
      "Gradient for encoder.mean.weight: 0.1474977284669876\n",
      "Gradient for encoder.mean.bias: 0.004655522294342518\n",
      "Gradient for encoder.log_var.weight: 0.08972097188234329\n",
      "Gradient for encoder.log_var.bias: 0.002812908496707678\n",
      "Gradient for decoder.decoder.0.weight: 0.012663311325013638\n",
      "Gradient for decoder.decoder.0.bias: 1.0254432719625228e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0006609404226765037\n",
      "Gradient for decoder.decoder.1.bias: 0.0004737170529551804\n",
      "Gradient for decoder.decoder.3.weight: 0.011857251636683941\n",
      "Gradient for decoder.decoder.3.bias: 8.500887493934073e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00041564853745512664\n",
      "Gradient for decoder.decoder.4.bias: 0.0003758933744393289\n",
      "Gradient for decoder.decoder.6.weight: 0.0007368879741989076\n",
      "Gradient for decoder.decoder.6.bias: 5.0473106966819614e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.01758214458823204\n",
      "Gradient for encoder.encoder.0.bias: 3.03510480637037e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0019543154630810022\n",
      "Gradient for encoder.encoder.1.bias: 0.0014939081156626344\n",
      "Gradient for encoder.encoder.3.weight: 0.03666834533214569\n",
      "Gradient for encoder.encoder.3.bias: 3.101511825143177e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.006361282430589199\n",
      "Gradient for encoder.encoder.4.bias: 0.0062354994006454945\n",
      "Gradient for encoder.mean.weight: 0.08045081049203873\n",
      "Gradient for encoder.mean.bias: 0.0037973637226969004\n",
      "Gradient for encoder.log_var.weight: 0.05286291241645813\n",
      "Gradient for encoder.log_var.bias: 0.002775536384433508\n",
      "Gradient for decoder.decoder.0.weight: 0.01502095814794302\n",
      "Gradient for decoder.decoder.0.bias: 1.297024848634365e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0007191018084995449\n",
      "Gradient for decoder.decoder.1.bias: 0.0005863814731128514\n",
      "Gradient for decoder.decoder.3.weight: 0.014079008251428604\n",
      "Gradient for decoder.decoder.3.bias: 1.166969715304944e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0006004585302434862\n",
      "Gradient for decoder.decoder.4.bias: 0.0006432228838093579\n",
      "Gradient for decoder.decoder.6.weight: 0.000670387817081064\n",
      "Gradient for decoder.decoder.6.bias: 3.7456644349731505e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.01871936023235321\n",
      "Gradient for encoder.encoder.0.bias: 3.3955130374074827e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0018744847038760781\n",
      "Gradient for encoder.encoder.1.bias: 0.0016081365756690502\n",
      "Gradient for encoder.encoder.3.weight: 0.03607555478811264\n",
      "Gradient for encoder.encoder.3.bias: 3.1760383212287024e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.006626386195421219\n",
      "Gradient for encoder.encoder.4.bias: 0.007419533096253872\n",
      "Gradient for encoder.mean.weight: 0.083746999502182\n",
      "Gradient for encoder.mean.bias: 0.005482403561472893\n",
      "Gradient for encoder.log_var.weight: 0.04798068106174469\n",
      "Gradient for encoder.log_var.bias: 0.0029249810613691807\n",
      "Gradient for decoder.decoder.0.weight: 0.010603165253996849\n",
      "Gradient for decoder.decoder.0.bias: 9.03335461988064e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005194144323468208\n",
      "Gradient for decoder.decoder.1.bias: 0.00043022684985771775\n",
      "Gradient for decoder.decoder.3.weight: 0.009579787030816078\n",
      "Gradient for decoder.decoder.3.bias: 1.0197018923685519e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0005626223282888532\n",
      "Gradient for decoder.decoder.4.bias: 0.0006722115213051438\n",
      "Gradient for decoder.decoder.6.weight: 0.0007084630196914077\n",
      "Gradient for decoder.decoder.6.bias: 5.101633723825216e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.013715545646846294\n",
      "Gradient for encoder.encoder.0.bias: 2.250066105657922e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0014753103023394942\n",
      "Gradient for encoder.encoder.1.bias: 0.001443324377760291\n",
      "Gradient for encoder.encoder.3.weight: 0.030600685626268387\n",
      "Gradient for encoder.encoder.3.bias: 2.7027116655808925e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.005294814705848694\n",
      "Gradient for encoder.encoder.4.bias: 0.0053371586836874485\n",
      "Gradient for encoder.mean.weight: 0.07544639706611633\n",
      "Gradient for encoder.mean.bias: 0.0038640322163701057\n",
      "Gradient for encoder.log_var.weight: 0.03888409212231636\n",
      "Gradient for encoder.log_var.bias: 0.0025783036835491657\n",
      "Gradient for decoder.decoder.0.weight: 0.016411177814006805\n",
      "Gradient for decoder.decoder.0.bias: 1.2456596865106917e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.000805111660156399\n",
      "Gradient for decoder.decoder.1.bias: 0.0006457517738454044\n",
      "Gradient for decoder.decoder.3.weight: 0.014778470620512962\n",
      "Gradient for decoder.decoder.3.bias: 1.1366591695649575e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0005472490447573364\n",
      "Gradient for decoder.decoder.4.bias: 0.00047600484685972333\n",
      "Gradient for decoder.decoder.6.weight: 0.000721669290214777\n",
      "Gradient for decoder.decoder.6.bias: 3.950984319089912e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.0164945088326931\n",
      "Gradient for encoder.encoder.0.bias: 2.71058783057887e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0018204995431005955\n",
      "Gradient for encoder.encoder.1.bias: 0.0013150899903848767\n",
      "Gradient for encoder.encoder.3.weight: 0.036873798817396164\n",
      "Gradient for encoder.encoder.3.bias: 2.952409428047531e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.006360173691064119\n",
      "Gradient for encoder.encoder.4.bias: 0.0053398944437503815\n",
      "Gradient for encoder.mean.weight: 0.08146712929010391\n",
      "Gradient for encoder.mean.bias: 0.0038854554295539856\n",
      "Gradient for encoder.log_var.weight: 0.053792983293533325\n",
      "Gradient for encoder.log_var.bias: 0.002379014855250716\n",
      "Gradient for decoder.decoder.0.weight: 0.012835923582315445\n",
      "Gradient for decoder.decoder.0.bias: 1.0743417960812351e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0006763004348613322\n",
      "Gradient for decoder.decoder.1.bias: 0.0005251527181826532\n",
      "Gradient for decoder.decoder.3.weight: 0.012050670571625233\n",
      "Gradient for decoder.decoder.3.bias: 8.519931288253346e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.000433696957770735\n",
      "Gradient for decoder.decoder.4.bias: 0.0004281207802705467\n",
      "Gradient for decoder.decoder.6.weight: 0.0006531398394145072\n",
      "Gradient for decoder.decoder.6.bias: 3.597334216465242e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.014326507225632668\n",
      "Gradient for encoder.encoder.0.bias: 2.4349560562297867e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0015518167056143284\n",
      "Gradient for encoder.encoder.1.bias: 0.00137892528437078\n",
      "Gradient for encoder.encoder.3.weight: 0.03210202604532242\n",
      "Gradient for encoder.encoder.3.bias: 2.3126149606422786e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.004627894144505262\n",
      "Gradient for encoder.encoder.4.bias: 0.004200217314064503\n",
      "Gradient for encoder.mean.weight: 0.05789921432733536\n",
      "Gradient for encoder.mean.bias: 0.0032791472040116787\n",
      "Gradient for encoder.log_var.weight: 0.04004410281777382\n",
      "Gradient for encoder.log_var.bias: 0.0022827978245913982\n",
      "Gradient for decoder.decoder.0.weight: 0.014648648910224438\n",
      "Gradient for decoder.decoder.0.bias: 1.178410008462194e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0007399031892418861\n",
      "Gradient for decoder.decoder.1.bias: 0.0005661437171511352\n",
      "Gradient for decoder.decoder.3.weight: 0.013509882614016533\n",
      "Gradient for decoder.decoder.3.bias: 1.0520923021672957e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0006191390566527843\n",
      "Gradient for decoder.decoder.4.bias: 0.0005791237344965339\n",
      "Gradient for decoder.decoder.6.weight: 0.0007175463251769543\n",
      "Gradient for decoder.decoder.6.bias: 3.634643871919252e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.021914606913924217\n",
      "Gradient for encoder.encoder.0.bias: 3.000094617178206e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.002606151159852743\n",
      "Gradient for encoder.encoder.1.bias: 0.0020278997253626585\n",
      "Gradient for encoder.encoder.3.weight: 0.055247996002435684\n",
      "Gradient for encoder.encoder.3.bias: 2.968000012426586e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.005878913216292858\n",
      "Gradient for encoder.encoder.4.bias: 0.00538727268576622\n",
      "Gradient for encoder.mean.weight: 0.07821985334157944\n",
      "Gradient for encoder.mean.bias: 0.003978123422712088\n",
      "Gradient for encoder.log_var.weight: 0.04986254870891571\n",
      "Gradient for encoder.log_var.bias: 0.0026331604458391666\n",
      "Gradient for decoder.decoder.0.weight: 0.015451843850314617\n",
      "Gradient for decoder.decoder.0.bias: 1.3278135535532698e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0008278142777271569\n",
      "Gradient for decoder.decoder.1.bias: 0.0006137873278930783\n",
      "Gradient for decoder.decoder.3.weight: 0.014454478397965431\n",
      "Gradient for decoder.decoder.3.bias: 1.2015445582935769e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0005622270982712507\n",
      "Gradient for decoder.decoder.4.bias: 0.0005202769534662366\n",
      "Gradient for decoder.decoder.6.weight: 0.000749733648262918\n",
      "Gradient for decoder.decoder.6.bias: 4.5946209866087884e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.013822231441736221\n",
      "Gradient for encoder.encoder.0.bias: 2.0297380096123696e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.001427876646630466\n",
      "Gradient for encoder.encoder.1.bias: 0.0011168717173859477\n",
      "Gradient for encoder.encoder.3.weight: 0.029549596831202507\n",
      "Gradient for encoder.encoder.3.bias: 2.49992998524462e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.005603473167866468\n",
      "Gradient for encoder.encoder.4.bias: 0.004954220727086067\n",
      "Gradient for encoder.mean.weight: 0.07355254888534546\n",
      "Gradient for encoder.mean.bias: 0.002794073661789298\n",
      "Gradient for encoder.log_var.weight: 0.041117388755083084\n",
      "Gradient for encoder.log_var.bias: 0.0017351813148707151\n",
      "Gradient for decoder.decoder.0.weight: 0.01780969463288784\n",
      "Gradient for decoder.decoder.0.bias: 1.443919567245544e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0009242302039638162\n",
      "Gradient for decoder.decoder.1.bias: 0.0007167079020291567\n",
      "Gradient for decoder.decoder.3.weight: 0.016507403925061226\n",
      "Gradient for decoder.decoder.3.bias: 1.223743606448835e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0006640622741542757\n",
      "Gradient for decoder.decoder.4.bias: 0.0006163519574329257\n",
      "Gradient for decoder.decoder.6.weight: 0.0007643713615834713\n",
      "Gradient for decoder.decoder.6.bias: 4.669213012675755e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.020428650081157684\n",
      "Gradient for encoder.encoder.0.bias: 3.5098174366865464e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0025899228639900684\n",
      "Gradient for encoder.encoder.1.bias: 0.0020469301380217075\n",
      "Gradient for encoder.encoder.3.weight: 0.05622747913002968\n",
      "Gradient for encoder.encoder.3.bias: 3.5337849313421543e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.010910761542618275\n",
      "Gradient for encoder.encoder.4.bias: 0.008728547021746635\n",
      "Gradient for encoder.mean.weight: 0.1342780590057373\n",
      "Gradient for encoder.mean.bias: 0.004926679655909538\n",
      "Gradient for encoder.log_var.weight: 0.08852248638868332\n",
      "Gradient for encoder.log_var.bias: 0.00344062433578074\n",
      "Gradient for decoder.decoder.0.weight: 0.012685507535934448\n",
      "Gradient for decoder.decoder.0.bias: 9.385194704725208e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0006896806880831718\n",
      "Gradient for decoder.decoder.1.bias: 0.0004992198664695024\n",
      "Gradient for decoder.decoder.3.weight: 0.01143903099000454\n",
      "Gradient for decoder.decoder.3.bias: 9.604808615115701e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00046886398922652006\n",
      "Gradient for decoder.decoder.4.bias: 0.0003896253474522382\n",
      "Gradient for decoder.decoder.6.weight: 0.0008384461398236454\n",
      "Gradient for decoder.decoder.6.bias: 6.263225805014372e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.012440125457942486\n",
      "Gradient for encoder.encoder.0.bias: 1.771351468282667e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.001327150035649538\n",
      "Gradient for encoder.encoder.1.bias: 0.0012648567790165544\n",
      "Gradient for encoder.encoder.3.weight: 0.02955794334411621\n",
      "Gradient for encoder.encoder.3.bias: 2.661042497464905e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0044266218319535255\n",
      "Gradient for encoder.encoder.4.bias: 0.0052537391893565655\n",
      "Gradient for encoder.mean.weight: 0.060671884566545486\n",
      "Gradient for encoder.mean.bias: 0.0042439717799425125\n",
      "Gradient for encoder.log_var.weight: 0.039862629026174545\n",
      "Gradient for encoder.log_var.bias: 0.003158056177198887\n",
      "Gradient for decoder.decoder.0.weight: 0.017544377595186234\n",
      "Gradient for decoder.decoder.0.bias: 1.5908765971239802e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0008290844270959496\n",
      "Gradient for decoder.decoder.1.bias: 0.0007268294575624168\n",
      "Gradient for decoder.decoder.3.weight: 0.015708032995462418\n",
      "Gradient for decoder.decoder.3.bias: 1.3809914323203998e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.000680407218169421\n",
      "Gradient for decoder.decoder.4.bias: 0.0007732369122095406\n",
      "Gradient for decoder.decoder.6.weight: 0.0007168746669776738\n",
      "Gradient for decoder.decoder.6.bias: 4.3538100726436824e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training VAE Epoch:  42%|████▏     | 33/79 [00:00<00:00, 66.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient for encoder.encoder.0.weight: 0.013391660526394844\n",
      "Gradient for encoder.encoder.0.bias: 2.089297658491862e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0014474783092737198\n",
      "Gradient for encoder.encoder.1.bias: 0.0012076676357537508\n",
      "Gradient for encoder.encoder.3.weight: 0.032192081212997437\n",
      "Gradient for encoder.encoder.3.bias: 2.2732503379696567e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.004521770868450403\n",
      "Gradient for encoder.encoder.4.bias: 0.0038066990673542023\n",
      "Gradient for encoder.mean.weight: 0.05901478976011276\n",
      "Gradient for encoder.mean.bias: 0.002695046365261078\n",
      "Gradient for encoder.log_var.weight: 0.036558598279953\n",
      "Gradient for encoder.log_var.bias: 0.0019289188785478473\n",
      "Gradient for decoder.decoder.0.weight: 0.01453123427927494\n",
      "Gradient for decoder.decoder.0.bias: 1.2444924257781764e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0007498327759094536\n",
      "Gradient for decoder.decoder.1.bias: 0.0005649002268910408\n",
      "Gradient for decoder.decoder.3.weight: 0.01344304159283638\n",
      "Gradient for decoder.decoder.3.bias: 1.021090711983419e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0005503790453076363\n",
      "Gradient for decoder.decoder.4.bias: 0.000565073627512902\n",
      "Gradient for decoder.decoder.6.weight: 0.0006835553795099258\n",
      "Gradient for decoder.decoder.6.bias: 4.051889482070692e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.018774505704641342\n",
      "Gradient for encoder.encoder.0.bias: 2.986487446232644e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0013677194947376847\n",
      "Gradient for encoder.encoder.1.bias: 0.0012187198735773563\n",
      "Gradient for encoder.encoder.3.weight: 0.031977757811546326\n",
      "Gradient for encoder.encoder.3.bias: 2.713185509595206e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.006154509726911783\n",
      "Gradient for encoder.encoder.4.bias: 0.004747978411614895\n",
      "Gradient for encoder.mean.weight: 0.07619894295930862\n",
      "Gradient for encoder.mean.bias: 0.0035170430783182383\n",
      "Gradient for encoder.log_var.weight: 0.045701202005147934\n",
      "Gradient for encoder.log_var.bias: 0.0025801043957471848\n",
      "Gradient for decoder.decoder.0.weight: 0.013187594711780548\n",
      "Gradient for decoder.decoder.0.bias: 1.1072949501755858e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0006529203965328634\n",
      "Gradient for decoder.decoder.1.bias: 0.0005152488010935485\n",
      "Gradient for decoder.decoder.3.weight: 0.012583237141370773\n",
      "Gradient for decoder.decoder.3.bias: 8.938631085309012e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0004348176880739629\n",
      "Gradient for decoder.decoder.4.bias: 0.0003882148303091526\n",
      "Gradient for decoder.decoder.6.weight: 0.0006606426904909313\n",
      "Gradient for decoder.decoder.6.bias: 2.8978671252843924e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training VAE Epoch:  52%|█████▏    | 41/79 [00:00<00:00, 69.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient for encoder.encoder.0.weight: 0.014679281041026115\n",
      "Gradient for encoder.encoder.0.bias: 2.036059862375872e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0012691771844401956\n",
      "Gradient for encoder.encoder.1.bias: 0.0012019539717584848\n",
      "Gradient for encoder.encoder.3.weight: 0.02969995327293873\n",
      "Gradient for encoder.encoder.3.bias: 2.347581573580726e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.00530573446303606\n",
      "Gradient for encoder.encoder.4.bias: 0.00455824937671423\n",
      "Gradient for encoder.mean.weight: 0.07350736856460571\n",
      "Gradient for encoder.mean.bias: 0.0032653696835041046\n",
      "Gradient for encoder.log_var.weight: 0.04166759178042412\n",
      "Gradient for encoder.log_var.bias: 0.0020389482378959656\n",
      "Gradient for decoder.decoder.0.weight: 0.015947595238685608\n",
      "Gradient for decoder.decoder.0.bias: 1.3293911804712621e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0008416608325205743\n",
      "Gradient for decoder.decoder.1.bias: 0.0006276529747992754\n",
      "Gradient for decoder.decoder.3.weight: 0.014636427164077759\n",
      "Gradient for decoder.decoder.3.bias: 1.0775743491953094e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0005320768686942756\n",
      "Gradient for decoder.decoder.4.bias: 0.00043347396422177553\n",
      "Gradient for decoder.decoder.6.weight: 0.0006826636963523924\n",
      "Gradient for decoder.decoder.6.bias: 3.1385923648485914e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.019437100738286972\n",
      "Gradient for encoder.encoder.0.bias: 3.5549275329005425e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0022486208472400904\n",
      "Gradient for encoder.encoder.1.bias: 0.0016543365782126784\n",
      "Gradient for encoder.encoder.3.weight: 0.04802690073847771\n",
      "Gradient for encoder.encoder.3.bias: 3.1343680428896903e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0059747230261564255\n",
      "Gradient for encoder.encoder.4.bias: 0.00566475884988904\n",
      "Gradient for encoder.mean.weight: 0.08077410608530045\n",
      "Gradient for encoder.mean.bias: 0.0038601208943873644\n",
      "Gradient for encoder.log_var.weight: 0.04680406302213669\n",
      "Gradient for encoder.log_var.bias: 0.0024452093057334423\n",
      "Gradient for decoder.decoder.0.weight: 0.010693024843931198\n",
      "Gradient for decoder.decoder.0.bias: 8.876277490799112e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.000544122711289674\n",
      "Gradient for decoder.decoder.1.bias: 0.0004088008136022836\n",
      "Gradient for decoder.decoder.3.weight: 0.00985963549464941\n",
      "Gradient for decoder.decoder.3.bias: 8.668313983273279e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0003928799123968929\n",
      "Gradient for decoder.decoder.4.bias: 0.00043233728501945734\n",
      "Gradient for decoder.decoder.6.weight: 0.0006762469420209527\n",
      "Gradient for decoder.decoder.6.bias: 4.0332739445148036e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.01593448780477047\n",
      "Gradient for encoder.encoder.0.bias: 2.1961118687463532e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0013330751098692417\n",
      "Gradient for encoder.encoder.1.bias: 0.001043273601680994\n",
      "Gradient for encoder.encoder.3.weight: 0.028117932379245758\n",
      "Gradient for encoder.encoder.3.bias: 2.4862831238259275e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.006709630601108074\n",
      "Gradient for encoder.encoder.4.bias: 0.004916171543300152\n",
      "Gradient for encoder.mean.weight: 0.08181097358465195\n",
      "Gradient for encoder.mean.bias: 0.0033339366782456636\n",
      "Gradient for encoder.log_var.weight: 0.05269129201769829\n",
      "Gradient for encoder.log_var.bias: 0.0023604684974998236\n",
      "Gradient for decoder.decoder.0.weight: 0.014059017412364483\n",
      "Gradient for decoder.decoder.0.bias: 1.1357929874389328e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0007011705893091857\n",
      "Gradient for decoder.decoder.1.bias: 0.0005421006353572011\n",
      "Gradient for decoder.decoder.3.weight: 0.012917442247271538\n",
      "Gradient for decoder.decoder.3.bias: 9.307654647017216e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00047804988571442664\n",
      "Gradient for decoder.decoder.4.bias: 0.00041401307680644095\n",
      "Gradient for decoder.decoder.6.weight: 0.0007013442809693515\n",
      "Gradient for decoder.decoder.6.bias: 3.780598126468249e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.014358862303197384\n",
      "Gradient for encoder.encoder.0.bias: 2.0361278635361302e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0020409696735441685\n",
      "Gradient for encoder.encoder.1.bias: 0.001547528081573546\n",
      "Gradient for encoder.encoder.3.weight: 0.040882956236600876\n",
      "Gradient for encoder.encoder.3.bias: 2.6797578045467674e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.006442164070904255\n",
      "Gradient for encoder.encoder.4.bias: 0.0054312958382070065\n",
      "Gradient for encoder.mean.weight: 0.08294754475355148\n",
      "Gradient for encoder.mean.bias: 0.003227438312023878\n",
      "Gradient for encoder.log_var.weight: 0.050339385867118835\n",
      "Gradient for encoder.log_var.bias: 0.0020275572314858437\n",
      "Gradient for decoder.decoder.0.weight: 0.018159154802560806\n",
      "Gradient for decoder.decoder.0.bias: 1.4840238760083224e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0009374556830152869\n",
      "Gradient for decoder.decoder.1.bias: 0.0007168969023041427\n",
      "Gradient for decoder.decoder.3.weight: 0.01664859987795353\n",
      "Gradient for decoder.decoder.3.bias: 1.2482918865241999e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.00063943030545488\n",
      "Gradient for decoder.decoder.4.bias: 0.0005258604069240391\n",
      "Gradient for decoder.decoder.6.weight: 0.0007727574557065964\n",
      "Gradient for decoder.decoder.6.bias: 4.347680805949494e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.016577817499637604\n",
      "Gradient for encoder.encoder.0.bias: 2.527885366310212e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.001712136552669108\n",
      "Gradient for encoder.encoder.1.bias: 0.0013287351466715336\n",
      "Gradient for encoder.encoder.3.weight: 0.03578049689531326\n",
      "Gradient for encoder.encoder.3.bias: 2.5101426492923906e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.005005508195608854\n",
      "Gradient for encoder.encoder.4.bias: 0.00483744777739048\n",
      "Gradient for encoder.mean.weight: 0.06761788576841354\n",
      "Gradient for encoder.mean.bias: 0.003296117763966322\n",
      "Gradient for encoder.log_var.weight: 0.039235811680555344\n",
      "Gradient for encoder.log_var.bias: 0.002117452910169959\n",
      "Gradient for decoder.decoder.0.weight: 0.012022600509226322\n",
      "Gradient for decoder.decoder.0.bias: 9.782314541739723e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0006318159867078066\n",
      "Gradient for decoder.decoder.1.bias: 0.00047943758545443416\n",
      "Gradient for decoder.decoder.3.weight: 0.01108619011938572\n",
      "Gradient for decoder.decoder.3.bias: 9.170215975462526e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0005197083810344338\n",
      "Gradient for decoder.decoder.4.bias: 0.0006133241695351899\n",
      "Gradient for decoder.decoder.6.weight: 0.0006944822962395847\n",
      "Gradient for decoder.decoder.6.bias: 4.80200833408162e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.018820209428668022\n",
      "Gradient for encoder.encoder.0.bias: 2.498292545061176e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0032674474641680717\n",
      "Gradient for encoder.encoder.1.bias: 0.0018891880754381418\n",
      "Gradient for encoder.encoder.3.weight: 0.058246858417987823\n",
      "Gradient for encoder.encoder.3.bias: 3.2743704969639964e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.008344556204974651\n",
      "Gradient for encoder.encoder.4.bias: 0.007786279544234276\n",
      "Gradient for encoder.mean.weight: 0.10957340896129608\n",
      "Gradient for encoder.mean.bias: 0.005146525334566832\n",
      "Gradient for encoder.log_var.weight: 0.06082192808389664\n",
      "Gradient for encoder.log_var.bias: 0.0030709397979080677\n",
      "Gradient for decoder.decoder.0.weight: 0.016358178108930588\n",
      "Gradient for decoder.decoder.0.bias: 1.692095907834812e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0008513124193996191\n",
      "Gradient for decoder.decoder.1.bias: 0.0006918981671333313\n",
      "Gradient for decoder.decoder.3.weight: 0.014715729281306267\n",
      "Gradient for decoder.decoder.3.bias: 1.4444993812201545e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0005462054978124797\n",
      "Gradient for decoder.decoder.4.bias: 0.00048012816114351153\n",
      "Gradient for decoder.decoder.6.weight: 0.0008357836049981415\n",
      "Gradient for decoder.decoder.6.bias: 6.240308721316978e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.015241499990224838\n",
      "Gradient for encoder.encoder.0.bias: 2.3212621061419192e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0017842132365331054\n",
      "Gradient for encoder.encoder.1.bias: 0.0013799472944810987\n",
      "Gradient for encoder.encoder.3.weight: 0.036838941276073456\n",
      "Gradient for encoder.encoder.3.bias: 2.836570145436923e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.007666049059480429\n",
      "Gradient for encoder.encoder.4.bias: 0.007641752250492573\n",
      "Gradient for encoder.mean.weight: 0.09745943546295166\n",
      "Gradient for encoder.mean.bias: 0.004531857091933489\n",
      "Gradient for encoder.log_var.weight: 0.057366155087947845\n",
      "Gradient for encoder.log_var.bias: 0.0030367285944521427\n",
      "Gradient for decoder.decoder.0.weight: 0.013063181191682816\n",
      "Gradient for decoder.decoder.0.bias: 1.1410636324704626e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0006855145911686122\n",
      "Gradient for decoder.decoder.1.bias: 0.0004872172139585018\n",
      "Gradient for decoder.decoder.3.weight: 0.011847716756165028\n",
      "Gradient for decoder.decoder.3.bias: 9.32875859893656e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00043368112528696656\n",
      "Gradient for decoder.decoder.4.bias: 0.00037256127689033747\n",
      "Gradient for decoder.decoder.6.weight: 0.0007074898458085954\n",
      "Gradient for decoder.decoder.6.bias: 4.0471379179507494e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.015741685405373573\n",
      "Gradient for encoder.encoder.0.bias: 2.351841117687048e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.001308669219724834\n",
      "Gradient for encoder.encoder.1.bias: 0.0010694359662011266\n",
      "Gradient for encoder.encoder.3.weight: 0.02875298261642456\n",
      "Gradient for encoder.encoder.3.bias: 2.9816060731491234e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.007013970520347357\n",
      "Gradient for encoder.encoder.4.bias: 0.005977575667202473\n",
      "Gradient for encoder.mean.weight: 0.08928240835666656\n",
      "Gradient for encoder.mean.bias: 0.0035958762746304274\n",
      "Gradient for encoder.log_var.weight: 0.05561893805861473\n",
      "Gradient for encoder.log_var.bias: 0.002194763859733939\n",
      "Gradient for decoder.decoder.0.weight: 0.01403832621872425\n",
      "Gradient for decoder.decoder.0.bias: 1.192110993253337e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0006828494369983673\n",
      "Gradient for decoder.decoder.1.bias: 0.000558617350179702\n",
      "Gradient for decoder.decoder.3.weight: 0.012719139456748962\n",
      "Gradient for decoder.decoder.3.bias: 1.0805011746439774e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0004349278751760721\n",
      "Gradient for decoder.decoder.4.bias: 0.000413352157920599\n",
      "Gradient for decoder.decoder.6.weight: 0.0006948100635781884\n",
      "Gradient for decoder.decoder.6.bias: 4.135323251830414e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.018272392451763153\n",
      "Gradient for encoder.encoder.0.bias: 2.454627300030321e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0023106259759515524\n",
      "Gradient for encoder.encoder.1.bias: 0.0017479656962677836\n",
      "Gradient for encoder.encoder.3.weight: 0.04886328801512718\n",
      "Gradient for encoder.encoder.3.bias: 2.645592078742709e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0055146352387964725\n",
      "Gradient for encoder.encoder.4.bias: 0.005356821697205305\n",
      "Gradient for encoder.mean.weight: 0.07858408987522125\n",
      "Gradient for encoder.mean.bias: 0.0037057907320559025\n",
      "Gradient for encoder.log_var.weight: 0.046915020793676376\n",
      "Gradient for encoder.log_var.bias: 0.0025694395881146193\n",
      "Gradient for decoder.decoder.0.weight: 0.015218404121696949\n",
      "Gradient for decoder.decoder.0.bias: 1.304299168669587e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0007425221847370267\n",
      "Gradient for decoder.decoder.1.bias: 0.000598721846472472\n",
      "Gradient for decoder.decoder.3.weight: 0.013629280030727386\n",
      "Gradient for decoder.decoder.3.bias: 1.0565960606445657e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0004884866648353636\n",
      "Gradient for decoder.decoder.4.bias: 0.00044662869186140597\n",
      "Gradient for decoder.decoder.6.weight: 0.0006762459524907172\n",
      "Gradient for decoder.decoder.6.bias: 3.802084029302932e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.012940521351993084\n",
      "Gradient for encoder.encoder.0.bias: 2.0643481715709733e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0015272476011887193\n",
      "Gradient for encoder.encoder.1.bias: 0.0013153692707419395\n",
      "Gradient for encoder.encoder.3.weight: 0.029534751549363136\n",
      "Gradient for encoder.encoder.3.bias: 2.528512954569351e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.005115239415317774\n",
      "Gradient for encoder.encoder.4.bias: 0.005165595095604658\n",
      "Gradient for encoder.mean.weight: 0.07306768000125885\n",
      "Gradient for encoder.mean.bias: 0.0034678441006690264\n",
      "Gradient for encoder.log_var.weight: 0.04116649180650711\n",
      "Gradient for encoder.log_var.bias: 0.002116054529324174\n",
      "Gradient for decoder.decoder.0.weight: 0.016462279483675957\n",
      "Gradient for decoder.decoder.0.bias: 1.4879049381466558e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.000796957581769675\n",
      "Gradient for decoder.decoder.1.bias: 0.00069143291329965\n",
      "Gradient for decoder.decoder.3.weight: 0.014229468069970608\n",
      "Gradient for decoder.decoder.3.bias: 1.2752704448004692e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0005587507621385157\n",
      "Gradient for decoder.decoder.4.bias: 0.0005659795715473592\n",
      "Gradient for decoder.decoder.6.weight: 0.0006983464700169861\n",
      "Gradient for decoder.decoder.6.bias: 4.0311162592843175e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.017902756109833717\n",
      "Gradient for encoder.encoder.0.bias: 3.099342657519877e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0020224733743816614\n",
      "Gradient for encoder.encoder.1.bias: 0.0017443932592868805\n",
      "Gradient for encoder.encoder.3.weight: 0.03816232085227966\n",
      "Gradient for encoder.encoder.3.bias: 3.184710828385562e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.005435836035758257\n",
      "Gradient for encoder.encoder.4.bias: 0.005066216457635164\n",
      "Gradient for encoder.mean.weight: 0.07090464234352112\n",
      "Gradient for encoder.mean.bias: 0.0033924183808267117\n",
      "Gradient for encoder.log_var.weight: 0.0383291132748127\n",
      "Gradient for encoder.log_var.bias: 0.0020941728726029396\n",
      "Gradient for decoder.decoder.0.weight: 0.011524279601871967\n",
      "Gradient for decoder.decoder.0.bias: 9.490502134168466e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005888199084438384\n",
      "Gradient for decoder.decoder.1.bias: 0.00043627177365124226\n",
      "Gradient for decoder.decoder.3.weight: 0.010357175953686237\n",
      "Gradient for decoder.decoder.3.bias: 7.582341005063498e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00035894877510145307\n",
      "Gradient for decoder.decoder.4.bias: 0.00030849725590087473\n",
      "Gradient for decoder.decoder.6.weight: 0.000642438477370888\n",
      "Gradient for decoder.decoder.6.bias: 3.559434844646603e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.015066614374518394\n",
      "Gradient for encoder.encoder.0.bias: 2.2026548987530425e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.001881068223156035\n",
      "Gradient for encoder.encoder.1.bias: 0.001516820047982037\n",
      "Gradient for encoder.encoder.3.weight: 0.03727520629763603\n",
      "Gradient for encoder.encoder.3.bias: 2.775448482150722e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.00791260413825512\n",
      "Gradient for encoder.encoder.4.bias: 0.006468805018812418\n",
      "Gradient for encoder.mean.weight: 0.10264579951763153\n",
      "Gradient for encoder.mean.bias: 0.0032456645276397467\n",
      "Gradient for encoder.log_var.weight: 0.057661306113004684\n",
      "Gradient for encoder.log_var.bias: 0.002073997166007757\n",
      "Gradient for decoder.decoder.0.weight: 0.014066563919186592\n",
      "Gradient for decoder.decoder.0.bias: 1.2095018042668215e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0007297546253539622\n",
      "Gradient for decoder.decoder.1.bias: 0.0005955765373073518\n",
      "Gradient for decoder.decoder.3.weight: 0.013701059855520725\n",
      "Gradient for decoder.decoder.3.bias: 1.0111458198514e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.000503075891174376\n",
      "Gradient for decoder.decoder.4.bias: 0.0004442304198164493\n",
      "Gradient for decoder.decoder.6.weight: 0.000773480802308768\n",
      "Gradient for decoder.decoder.6.bias: 4.838720633415505e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.01816728711128235\n",
      "Gradient for encoder.encoder.0.bias: 2.8515488581515314e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0016318924026563764\n",
      "Gradient for encoder.encoder.1.bias: 0.0014747065724804997\n",
      "Gradient for encoder.encoder.3.weight: 0.033241111785173416\n",
      "Gradient for encoder.encoder.3.bias: 3.9216441205525143e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.00841030664741993\n",
      "Gradient for encoder.encoder.4.bias: 0.008287198841571808\n",
      "Gradient for encoder.mean.weight: 0.10699523240327835\n",
      "Gradient for encoder.mean.bias: 0.004431991372257471\n",
      "Gradient for encoder.log_var.weight: 0.06551606953144073\n",
      "Gradient for encoder.log_var.bias: 0.003196566831320524\n",
      "Gradient for decoder.decoder.0.weight: 0.015970343723893166\n",
      "Gradient for decoder.decoder.0.bias: 1.3793423347951972e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0008340196800418198\n",
      "Gradient for decoder.decoder.1.bias: 0.0006524650380015373\n",
      "Gradient for decoder.decoder.3.weight: 0.015425843186676502\n",
      "Gradient for decoder.decoder.3.bias: 1.3800477427494684e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0006026694318279624\n",
      "Gradient for decoder.decoder.4.bias: 0.0006025400361977518\n",
      "Gradient for decoder.decoder.6.weight: 0.0006990098627284169\n",
      "Gradient for decoder.decoder.6.bias: 3.860726428683847e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.014325174503028393\n",
      "Gradient for encoder.encoder.0.bias: 2.1445701117728255e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.00171637290623039\n",
      "Gradient for encoder.encoder.1.bias: 0.0013543384848162532\n",
      "Gradient for encoder.encoder.3.weight: 0.034639522433280945\n",
      "Gradient for encoder.encoder.3.bias: 2.513208530174893e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.006627202499657869\n",
      "Gradient for encoder.encoder.4.bias: 0.005054784938693047\n",
      "Gradient for encoder.mean.weight: 0.09278986603021622\n",
      "Gradient for encoder.mean.bias: 0.0040742941200733185\n",
      "Gradient for encoder.log_var.weight: 0.052168238908052444\n",
      "Gradient for encoder.log_var.bias: 0.002191924722865224\n",
      "Gradient for decoder.decoder.0.weight: 0.016322290524840355\n",
      "Gradient for decoder.decoder.0.bias: 1.2297306228870042e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0008819023496471345\n",
      "Gradient for decoder.decoder.1.bias: 0.0006383733125403523\n",
      "Gradient for decoder.decoder.3.weight: 0.015491108410060406\n",
      "Gradient for decoder.decoder.3.bias: 1.0812281625582898e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0006468856008723378\n",
      "Gradient for decoder.decoder.4.bias: 0.0006190252606756985\n",
      "Gradient for decoder.decoder.6.weight: 0.0008048349991440773\n",
      "Gradient for decoder.decoder.6.bias: 5.449844684335403e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training VAE Epoch:  62%|██████▏   | 49/79 [00:00<00:00, 72.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient for encoder.encoder.0.weight: 0.0105819720774889\n",
      "Gradient for encoder.encoder.0.bias: 1.5439483025403433e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0011199319269508123\n",
      "Gradient for encoder.encoder.1.bias: 0.0010075729805976152\n",
      "Gradient for encoder.encoder.3.weight: 0.023654399439692497\n",
      "Gradient for encoder.encoder.3.bias: 1.9746457247116211e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.003977017477154732\n",
      "Gradient for encoder.encoder.4.bias: 0.003469214541837573\n",
      "Gradient for encoder.mean.weight: 0.05447373911738396\n",
      "Gradient for encoder.mean.bias: 0.002649459755048156\n",
      "Gradient for encoder.log_var.weight: 0.029893627390265465\n",
      "Gradient for encoder.log_var.bias: 0.001539421733468771\n",
      "Gradient for decoder.decoder.0.weight: 0.014988900162279606\n",
      "Gradient for decoder.decoder.0.bias: 1.2159354079166462e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0007437493186444044\n",
      "Gradient for decoder.decoder.1.bias: 0.0006186236278153956\n",
      "Gradient for decoder.decoder.3.weight: 0.013802766799926758\n",
      "Gradient for decoder.decoder.3.bias: 1.0606537176327535e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0004974936018697917\n",
      "Gradient for decoder.decoder.4.bias: 0.00044567885925062\n",
      "Gradient for decoder.decoder.6.weight: 0.0006889865035191178\n",
      "Gradient for decoder.decoder.6.bias: 3.588932304410264e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.01666409708559513\n",
      "Gradient for encoder.encoder.0.bias: 2.3567767529208972e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.001640976290218532\n",
      "Gradient for encoder.encoder.1.bias: 0.0012942550238221884\n",
      "Gradient for encoder.encoder.3.weight: 0.033067844808101654\n",
      "Gradient for encoder.encoder.3.bias: 2.572063673156322e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.006203189957886934\n",
      "Gradient for encoder.encoder.4.bias: 0.004800622351467609\n",
      "Gradient for encoder.mean.weight: 0.08125463128089905\n",
      "Gradient for encoder.mean.bias: 0.002974549774080515\n",
      "Gradient for encoder.log_var.weight: 0.04617698863148689\n",
      "Gradient for encoder.log_var.bias: 0.0018386050360277295\n",
      "Gradient for decoder.decoder.0.weight: 0.014080637134611607\n",
      "Gradient for decoder.decoder.0.bias: 1.2173582975005814e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0007438923348672688\n",
      "Gradient for decoder.decoder.1.bias: 0.0005863377591595054\n",
      "Gradient for decoder.decoder.3.weight: 0.0132828364148736\n",
      "Gradient for decoder.decoder.3.bias: 1.0748957973705231e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0005563274607993662\n",
      "Gradient for decoder.decoder.4.bias: 0.0005734738078899682\n",
      "Gradient for decoder.decoder.6.weight: 0.0007352663669735193\n",
      "Gradient for decoder.decoder.6.bias: 4.2460545955691487e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training VAE Epoch:  72%|███████▏  | 57/79 [00:00<00:00, 73.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient for encoder.encoder.0.weight: 0.0228146780282259\n",
      "Gradient for encoder.encoder.0.bias: 4.4493232015385686e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0027875646483153105\n",
      "Gradient for encoder.encoder.1.bias: 0.0022461996413767338\n",
      "Gradient for encoder.encoder.3.weight: 0.05167240649461746\n",
      "Gradient for encoder.encoder.3.bias: 3.344360621770903e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.00661276513710618\n",
      "Gradient for encoder.encoder.4.bias: 0.006229758728295565\n",
      "Gradient for encoder.mean.weight: 0.08398391306400299\n",
      "Gradient for encoder.mean.bias: 0.004232118371874094\n",
      "Gradient for encoder.log_var.weight: 0.05186198651790619\n",
      "Gradient for encoder.log_var.bias: 0.0027064948808401823\n",
      "Gradient for decoder.decoder.0.weight: 0.011598745360970497\n",
      "Gradient for decoder.decoder.0.bias: 1.0623547180843573e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0005411969614215195\n",
      "Gradient for decoder.decoder.1.bias: 0.00043716171057894826\n",
      "Gradient for decoder.decoder.3.weight: 0.010269304737448692\n",
      "Gradient for decoder.decoder.3.bias: 1.3219544903186886e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.00088908476755023\n",
      "Gradient for decoder.decoder.4.bias: 0.0011150686768814921\n",
      "Gradient for decoder.decoder.6.weight: 0.0008380677318200469\n",
      "Gradient for decoder.decoder.6.bias: 7.5317824666854e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.015003489330410957\n",
      "Gradient for encoder.encoder.0.bias: 2.4161632763974872e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0013053708244115114\n",
      "Gradient for encoder.encoder.1.bias: 0.0011701942421495914\n",
      "Gradient for encoder.encoder.3.weight: 0.02778596244752407\n",
      "Gradient for encoder.encoder.3.bias: 2.379256791584794e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0041800434701144695\n",
      "Gradient for encoder.encoder.4.bias: 0.003992190584540367\n",
      "Gradient for encoder.mean.weight: 0.058259859681129456\n",
      "Gradient for encoder.mean.bias: 0.0030456415843218565\n",
      "Gradient for encoder.log_var.weight: 0.03466073051095009\n",
      "Gradient for encoder.log_var.bias: 0.0021283035166561604\n",
      "Gradient for decoder.decoder.0.weight: 0.01482148002833128\n",
      "Gradient for decoder.decoder.0.bias: 1.164245366780392e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0007625974831171334\n",
      "Gradient for decoder.decoder.1.bias: 0.0005906489095650613\n",
      "Gradient for decoder.decoder.3.weight: 0.013014587573707104\n",
      "Gradient for decoder.decoder.3.bias: 9.260872624317074e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0004348437360022217\n",
      "Gradient for decoder.decoder.4.bias: 0.00040096748853102326\n",
      "Gradient for decoder.decoder.6.weight: 0.0006622060318477452\n",
      "Gradient for decoder.decoder.6.bias: 3.7878860894124955e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.0154656320810318\n",
      "Gradient for encoder.encoder.0.bias: 2.6989641424557398e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.002143462188541889\n",
      "Gradient for encoder.encoder.1.bias: 0.0017750164261087775\n",
      "Gradient for encoder.encoder.3.weight: 0.03539184108376503\n",
      "Gradient for encoder.encoder.3.bias: 2.2815326017333604e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.003831719048321247\n",
      "Gradient for encoder.encoder.4.bias: 0.003830746514722705\n",
      "Gradient for encoder.mean.weight: 0.05146962031722069\n",
      "Gradient for encoder.mean.bias: 0.0030238921754062176\n",
      "Gradient for encoder.log_var.weight: 0.02949431724846363\n",
      "Gradient for encoder.log_var.bias: 0.0017351623391732574\n",
      "Gradient for decoder.decoder.0.weight: 0.0132168959826231\n",
      "Gradient for decoder.decoder.0.bias: 1.1986008019437833e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0006326170987449586\n",
      "Gradient for decoder.decoder.1.bias: 0.0004979664226993918\n",
      "Gradient for decoder.decoder.3.weight: 0.01222312357276678\n",
      "Gradient for decoder.decoder.3.bias: 9.844151188653782e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0004834606370422989\n",
      "Gradient for decoder.decoder.4.bias: 0.0004913345328532159\n",
      "Gradient for decoder.decoder.6.weight: 0.0007076460751704872\n",
      "Gradient for decoder.decoder.6.bias: 4.4293941755313426e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.01735459454357624\n",
      "Gradient for encoder.encoder.0.bias: 2.608077122323582e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0027759894728660583\n",
      "Gradient for encoder.encoder.1.bias: 0.0021047117188572884\n",
      "Gradient for encoder.encoder.3.weight: 0.05444307625293732\n",
      "Gradient for encoder.encoder.3.bias: 3.337725651419987e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.009174934588372707\n",
      "Gradient for encoder.encoder.4.bias: 0.00836515985429287\n",
      "Gradient for encoder.mean.weight: 0.11783675104379654\n",
      "Gradient for encoder.mean.bias: 0.00531785748898983\n",
      "Gradient for encoder.log_var.weight: 0.07001239061355591\n",
      "Gradient for encoder.log_var.bias: 0.003678287845104933\n",
      "Gradient for decoder.decoder.0.weight: 0.014644090086221695\n",
      "Gradient for decoder.decoder.0.bias: 1.2331495546913374e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0007368270307779312\n",
      "Gradient for decoder.decoder.1.bias: 0.0005713914288207889\n",
      "Gradient for decoder.decoder.3.weight: 0.013775495812296867\n",
      "Gradient for decoder.decoder.3.bias: 8.550316010769166e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0004993611946702003\n",
      "Gradient for decoder.decoder.4.bias: 0.00044132856419309974\n",
      "Gradient for decoder.decoder.6.weight: 0.0007511877338401973\n",
      "Gradient for decoder.decoder.6.bias: 4.758355498779565e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.011053729802370071\n",
      "Gradient for encoder.encoder.0.bias: 1.6230513461001905e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0010037297615781426\n",
      "Gradient for encoder.encoder.1.bias: 0.0010293870000168681\n",
      "Gradient for encoder.encoder.3.weight: 0.020868143066763878\n",
      "Gradient for encoder.encoder.3.bias: 2.5358964927946204e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.005115207750350237\n",
      "Gradient for encoder.encoder.4.bias: 0.005822296719998121\n",
      "Gradient for encoder.mean.weight: 0.06679218262434006\n",
      "Gradient for encoder.mean.bias: 0.0046741776168346405\n",
      "Gradient for encoder.log_var.weight: 0.038573551923036575\n",
      "Gradient for encoder.log_var.bias: 0.0030308321584016085\n",
      "Gradient for decoder.decoder.0.weight: 0.013389786705374718\n",
      "Gradient for decoder.decoder.0.bias: 1.0934297911546764e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0006455727270804346\n",
      "Gradient for decoder.decoder.1.bias: 0.0005604864563792944\n",
      "Gradient for decoder.decoder.3.weight: 0.01205479260534048\n",
      "Gradient for decoder.decoder.3.bias: 9.292916436365317e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0004481668001972139\n",
      "Gradient for decoder.decoder.4.bias: 0.00042042939458042383\n",
      "Gradient for decoder.decoder.6.weight: 0.0006744267884641886\n",
      "Gradient for decoder.decoder.6.bias: 3.916166315320879e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.011515527032315731\n",
      "Gradient for encoder.encoder.0.bias: 1.5491767590969374e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0011617839336395264\n",
      "Gradient for encoder.encoder.1.bias: 0.0010328458156436682\n",
      "Gradient for encoder.encoder.3.weight: 0.0238385871052742\n",
      "Gradient for encoder.encoder.3.bias: 1.9663511097167685e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.004434399772435427\n",
      "Gradient for encoder.encoder.4.bias: 0.003108961507678032\n",
      "Gradient for encoder.mean.weight: 0.06287828087806702\n",
      "Gradient for encoder.mean.bias: 0.0023785154335200787\n",
      "Gradient for encoder.log_var.weight: 0.035101983696222305\n",
      "Gradient for encoder.log_var.bias: 0.0015218682819977403\n",
      "Gradient for decoder.decoder.0.weight: 0.016126291826367378\n",
      "Gradient for decoder.decoder.0.bias: 1.2328733867139618e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0008121387800201774\n",
      "Gradient for decoder.decoder.1.bias: 0.0006279526278376579\n",
      "Gradient for decoder.decoder.3.weight: 0.01473519392311573\n",
      "Gradient for decoder.decoder.3.bias: 1.0168033776070118e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0005358537309803069\n",
      "Gradient for decoder.decoder.4.bias: 0.0005145008908584714\n",
      "Gradient for decoder.decoder.6.weight: 0.0006904607289470732\n",
      "Gradient for decoder.decoder.6.bias: 3.843461672659032e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.01589144580066204\n",
      "Gradient for encoder.encoder.0.bias: 2.347490431209298e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0012733243638649583\n",
      "Gradient for encoder.encoder.1.bias: 0.0012422078289091587\n",
      "Gradient for encoder.encoder.3.weight: 0.02765893191099167\n",
      "Gradient for encoder.encoder.3.bias: 2.5818999715987445e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.005087134428322315\n",
      "Gradient for encoder.encoder.4.bias: 0.004263009410351515\n",
      "Gradient for encoder.mean.weight: 0.0671376958489418\n",
      "Gradient for encoder.mean.bias: 0.003518876386806369\n",
      "Gradient for encoder.log_var.weight: 0.034975286573171616\n",
      "Gradient for encoder.log_var.bias: 0.0020998413674533367\n",
      "Gradient for decoder.decoder.0.weight: 0.013827127404510975\n",
      "Gradient for decoder.decoder.0.bias: 1.306447727777993e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0006609268020838499\n",
      "Gradient for decoder.decoder.1.bias: 0.0005699656321667135\n",
      "Gradient for decoder.decoder.3.weight: 0.012094362638890743\n",
      "Gradient for decoder.decoder.3.bias: 8.986856397941168e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00044823516509495676\n",
      "Gradient for decoder.decoder.4.bias: 0.00043633332825265825\n",
      "Gradient for decoder.decoder.6.weight: 0.0006914338446222246\n",
      "Gradient for decoder.decoder.6.bias: 3.710541932377964e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.0169963575899601\n",
      "Gradient for encoder.encoder.0.bias: 2.60191555800926e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0012865873286500573\n",
      "Gradient for encoder.encoder.1.bias: 0.0012072339886799455\n",
      "Gradient for encoder.encoder.3.weight: 0.029552850872278214\n",
      "Gradient for encoder.encoder.3.bias: 3.0733923739312274e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.007160014472901821\n",
      "Gradient for encoder.encoder.4.bias: 0.005844260100275278\n",
      "Gradient for encoder.mean.weight: 0.09455825388431549\n",
      "Gradient for encoder.mean.bias: 0.003972195088863373\n",
      "Gradient for encoder.log_var.weight: 0.04947014898061752\n",
      "Gradient for encoder.log_var.bias: 0.002497929846867919\n",
      "Gradient for decoder.decoder.0.weight: 0.012782520614564419\n",
      "Gradient for decoder.decoder.0.bias: 1.031149679531218e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0006628119153901935\n",
      "Gradient for decoder.decoder.1.bias: 0.0005208440124988556\n",
      "Gradient for decoder.decoder.3.weight: 0.012050990015268326\n",
      "Gradient for decoder.decoder.3.bias: 9.703662873228325e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00047694655950181186\n",
      "Gradient for decoder.decoder.4.bias: 0.0004297517298255116\n",
      "Gradient for decoder.decoder.6.weight: 0.0007251662900671363\n",
      "Gradient for decoder.decoder.6.bias: 4.3790041672764346e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.013996952213346958\n",
      "Gradient for encoder.encoder.0.bias: 1.9315337523861942e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0017080532852560282\n",
      "Gradient for encoder.encoder.1.bias: 0.0011985352030023932\n",
      "Gradient for encoder.encoder.3.weight: 0.03310125321149826\n",
      "Gradient for encoder.encoder.3.bias: 2.582126179540012e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.005570594687014818\n",
      "Gradient for encoder.encoder.4.bias: 0.004865857772529125\n",
      "Gradient for encoder.mean.weight: 0.0691208764910698\n",
      "Gradient for encoder.mean.bias: 0.004118428099900484\n",
      "Gradient for encoder.log_var.weight: 0.03905075043439865\n",
      "Gradient for encoder.log_var.bias: 0.0024400108959525824\n",
      "Gradient for decoder.decoder.0.weight: 0.014818422496318817\n",
      "Gradient for decoder.decoder.0.bias: 1.1455374843150068e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0007008942193351686\n",
      "Gradient for decoder.decoder.1.bias: 0.0005584802129305899\n",
      "Gradient for decoder.decoder.3.weight: 0.01351210754364729\n",
      "Gradient for decoder.decoder.3.bias: 1.015161080197835e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0005266150692477822\n",
      "Gradient for decoder.decoder.4.bias: 0.00046329526230692863\n",
      "Gradient for decoder.decoder.6.weight: 0.0007079491042532027\n",
      "Gradient for decoder.decoder.6.bias: 3.824231316684745e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.015519999898970127\n",
      "Gradient for encoder.encoder.0.bias: 2.3718865413413504e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0020907982252538204\n",
      "Gradient for encoder.encoder.1.bias: 0.0017230060184374452\n",
      "Gradient for encoder.encoder.3.weight: 0.04094041511416435\n",
      "Gradient for encoder.encoder.3.bias: 2.7122343260188586e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.007190482225269079\n",
      "Gradient for encoder.encoder.4.bias: 0.0057761515490710735\n",
      "Gradient for encoder.mean.weight: 0.09648299962282181\n",
      "Gradient for encoder.mean.bias: 0.0035768754314631224\n",
      "Gradient for encoder.log_var.weight: 0.05515863001346588\n",
      "Gradient for encoder.log_var.bias: 0.0019720701966434717\n",
      "Gradient for decoder.decoder.0.weight: 0.01666462980210781\n",
      "Gradient for decoder.decoder.0.bias: 1.359094919939352e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0008790171123109758\n",
      "Gradient for decoder.decoder.1.bias: 0.0007057343609631062\n",
      "Gradient for decoder.decoder.3.weight: 0.016152765601873398\n",
      "Gradient for decoder.decoder.3.bias: 1.330742183114353e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0009043560130521655\n",
      "Gradient for decoder.decoder.4.bias: 0.001002348493784666\n",
      "Gradient for decoder.decoder.6.weight: 0.0009382063872180879\n",
      "Gradient for decoder.decoder.6.bias: 7.071100844768807e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.01313100941479206\n",
      "Gradient for encoder.encoder.0.bias: 2.0050407514848878e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0015671137953177094\n",
      "Gradient for encoder.encoder.1.bias: 0.0012742149410769343\n",
      "Gradient for encoder.encoder.3.weight: 0.032603856176137924\n",
      "Gradient for encoder.encoder.3.bias: 2.614262972766568e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.005909445695579052\n",
      "Gradient for encoder.encoder.4.bias: 0.005387703888118267\n",
      "Gradient for encoder.mean.weight: 0.07472048699855804\n",
      "Gradient for encoder.mean.bias: 0.003312948625534773\n",
      "Gradient for encoder.log_var.weight: 0.045917339622974396\n",
      "Gradient for encoder.log_var.bias: 0.002130637178197503\n",
      "Gradient for decoder.decoder.0.weight: 0.014420555904507637\n",
      "Gradient for decoder.decoder.0.bias: 1.210873762369502e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0007218265673145652\n",
      "Gradient for decoder.decoder.1.bias: 0.00058315898058936\n",
      "Gradient for decoder.decoder.3.weight: 0.013588901609182358\n",
      "Gradient for decoder.decoder.3.bias: 1.1963136037351774e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0007422019261866808\n",
      "Gradient for decoder.decoder.4.bias: 0.0008318114560097456\n",
      "Gradient for decoder.decoder.6.weight: 0.0007950320723466575\n",
      "Gradient for decoder.decoder.6.bias: 5.043683995609172e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.01691662147641182\n",
      "Gradient for encoder.encoder.0.bias: 2.836848290999061e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0017810440622270107\n",
      "Gradient for encoder.encoder.1.bias: 0.001520346850156784\n",
      "Gradient for encoder.encoder.3.weight: 0.03566442057490349\n",
      "Gradient for encoder.encoder.3.bias: 2.416815358952107e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0043126740492880344\n",
      "Gradient for encoder.encoder.4.bias: 0.004651754163205624\n",
      "Gradient for encoder.mean.weight: 0.05942559987306595\n",
      "Gradient for encoder.mean.bias: 0.0037768464535474777\n",
      "Gradient for encoder.log_var.weight: 0.03377364203333855\n",
      "Gradient for encoder.log_var.bias: 0.002168216509744525\n",
      "Gradient for decoder.decoder.0.weight: 0.013989520259201527\n",
      "Gradient for decoder.decoder.0.bias: 1.2216475053783427e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0006542529445141554\n",
      "Gradient for decoder.decoder.1.bias: 0.0005151947261765599\n",
      "Gradient for decoder.decoder.3.weight: 0.013106118887662888\n",
      "Gradient for decoder.decoder.3.bias: 1.045310782377129e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.000506507174577564\n",
      "Gradient for decoder.decoder.4.bias: 0.00040719867683947086\n",
      "Gradient for decoder.decoder.6.weight: 0.0006490977830253541\n",
      "Gradient for decoder.decoder.6.bias: 3.066381032112986e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.011985518969595432\n",
      "Gradient for encoder.encoder.0.bias: 2.087527720129323e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0014809754211455584\n",
      "Gradient for encoder.encoder.1.bias: 0.001307278755120933\n",
      "Gradient for encoder.encoder.3.weight: 0.031867846846580505\n",
      "Gradient for encoder.encoder.3.bias: 2.3726123843381686e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.004873576574027538\n",
      "Gradient for encoder.encoder.4.bias: 0.004492922220379114\n",
      "Gradient for encoder.mean.weight: 0.06613821536302567\n",
      "Gradient for encoder.mean.bias: 0.0032267102506011724\n",
      "Gradient for encoder.log_var.weight: 0.036741916090250015\n",
      "Gradient for encoder.log_var.bias: 0.001930275117047131\n",
      "Gradient for decoder.decoder.0.weight: 0.014981616288423538\n",
      "Gradient for decoder.decoder.0.bias: 1.181699044172646e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0007836750592105091\n",
      "Gradient for decoder.decoder.1.bias: 0.0006303950794972479\n",
      "Gradient for decoder.decoder.3.weight: 0.013902497477829456\n",
      "Gradient for decoder.decoder.3.bias: 9.386829508128969e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00048699721810407937\n",
      "Gradient for decoder.decoder.4.bias: 0.0004008126852568239\n",
      "Gradient for decoder.decoder.6.weight: 0.0006813796353526413\n",
      "Gradient for decoder.decoder.6.bias: 3.6463890864979476e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.013228354044258595\n",
      "Gradient for encoder.encoder.0.bias: 1.722424113059784e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0013474804582074285\n",
      "Gradient for encoder.encoder.1.bias: 0.001121879555284977\n",
      "Gradient for encoder.encoder.3.weight: 0.026443421840667725\n",
      "Gradient for encoder.encoder.3.bias: 1.9719437194254397e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.004579521715641022\n",
      "Gradient for encoder.encoder.4.bias: 0.0038071617018431425\n",
      "Gradient for encoder.mean.weight: 0.0606859028339386\n",
      "Gradient for encoder.mean.bias: 0.0031953079160302877\n",
      "Gradient for encoder.log_var.weight: 0.035234928131103516\n",
      "Gradient for encoder.log_var.bias: 0.0016789613291621208\n",
      "Gradient for decoder.decoder.0.weight: 0.015619991347193718\n",
      "Gradient for decoder.decoder.0.bias: 1.415769584900417e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0008367766859009862\n",
      "Gradient for decoder.decoder.1.bias: 0.0006779773393645883\n",
      "Gradient for decoder.decoder.3.weight: 0.014596614055335522\n",
      "Gradient for decoder.decoder.3.bias: 1.0942870221075651e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.000553482270333916\n",
      "Gradient for decoder.decoder.4.bias: 0.0004802652692887932\n",
      "Gradient for decoder.decoder.6.weight: 0.0006828757468611002\n",
      "Gradient for decoder.decoder.6.bias: 3.3876742236316204e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training VAE Epoch:  82%|████████▏ | 65/79 [00:01<00:00, 75.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient for encoder.encoder.0.weight: 0.015964478254318237\n",
      "Gradient for encoder.encoder.0.bias: 2.618523453623567e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0011716356966644526\n",
      "Gradient for encoder.encoder.1.bias: 0.0012232750887051225\n",
      "Gradient for encoder.encoder.3.weight: 0.02527627907693386\n",
      "Gradient for encoder.encoder.3.bias: 2.3758991996025713e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.00435961177572608\n",
      "Gradient for encoder.encoder.4.bias: 0.004923458211123943\n",
      "Gradient for encoder.mean.weight: 0.05839353799819946\n",
      "Gradient for encoder.mean.bias: 0.0036933105438947678\n",
      "Gradient for encoder.log_var.weight: 0.03749232739210129\n",
      "Gradient for encoder.log_var.bias: 0.0022986007388681173\n",
      "Gradient for decoder.decoder.0.weight: 0.012568102218210697\n",
      "Gradient for decoder.decoder.0.bias: 1.0126402494314846e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0006251063314266503\n",
      "Gradient for decoder.decoder.1.bias: 0.00046708545414730906\n",
      "Gradient for decoder.decoder.3.weight: 0.011448844335973263\n",
      "Gradient for decoder.decoder.3.bias: 8.418086366868138e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.000426487997174263\n",
      "Gradient for decoder.decoder.4.bias: 0.00037618112401105464\n",
      "Gradient for decoder.decoder.6.weight: 0.0006757593364454806\n",
      "Gradient for decoder.decoder.6.bias: 3.5607674362836406e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.015981482341885567\n",
      "Gradient for encoder.encoder.0.bias: 2.4039895074601247e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0020940678659826517\n",
      "Gradient for encoder.encoder.1.bias: 0.0013262627180665731\n",
      "Gradient for encoder.encoder.3.weight: 0.04052971675992012\n",
      "Gradient for encoder.encoder.3.bias: 2.459984715930119e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.006033935584127903\n",
      "Gradient for encoder.encoder.4.bias: 0.005984548944979906\n",
      "Gradient for encoder.mean.weight: 0.08113642781972885\n",
      "Gradient for encoder.mean.bias: 0.004681793972849846\n",
      "Gradient for encoder.log_var.weight: 0.043945442885160446\n",
      "Gradient for encoder.log_var.bias: 0.002724424237385392\n",
      "Gradient for decoder.decoder.0.weight: 0.014541909098625183\n",
      "Gradient for decoder.decoder.0.bias: 1.1457128995528976e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0007326599443331361\n",
      "Gradient for decoder.decoder.1.bias: 0.0005891942419111729\n",
      "Gradient for decoder.decoder.3.weight: 0.013177121989428997\n",
      "Gradient for decoder.decoder.3.bias: 1.0248330656326132e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0005060648545622826\n",
      "Gradient for decoder.decoder.4.bias: 0.0004973989562131464\n",
      "Gradient for decoder.decoder.6.weight: 0.0006356226513162255\n",
      "Gradient for decoder.decoder.6.bias: 3.0035540476092137e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training VAE Epoch:  92%|█████████▏| 73/79 [00:01<00:00, 75.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient for encoder.encoder.0.weight: 0.01293609756976366\n",
      "Gradient for encoder.encoder.0.bias: 2.2725018047897727e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0015094892587512732\n",
      "Gradient for encoder.encoder.1.bias: 0.0012229068670421839\n",
      "Gradient for encoder.encoder.3.weight: 0.03407689556479454\n",
      "Gradient for encoder.encoder.3.bias: 3.089914435427943e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.005916754249483347\n",
      "Gradient for encoder.encoder.4.bias: 0.006006690673530102\n",
      "Gradient for encoder.mean.weight: 0.07407207041978836\n",
      "Gradient for encoder.mean.bias: 0.004517595749348402\n",
      "Gradient for encoder.log_var.weight: 0.04296484962105751\n",
      "Gradient for encoder.log_var.bias: 0.0027241804637014866\n",
      "Gradient for decoder.decoder.0.weight: 0.013337786309421062\n",
      "Gradient for decoder.decoder.0.bias: 1.2034394314408559e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0007360957097262144\n",
      "Gradient for decoder.decoder.1.bias: 0.0005646086065098643\n",
      "Gradient for decoder.decoder.3.weight: 0.01234967540949583\n",
      "Gradient for decoder.decoder.3.bias: 1.0250997967142794e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0004932201700285077\n",
      "Gradient for decoder.decoder.4.bias: 0.00045478306128643453\n",
      "Gradient for decoder.decoder.6.weight: 0.0007553283357992768\n",
      "Gradient for decoder.decoder.6.bias: 4.4966327550355345e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.012725119479000568\n",
      "Gradient for encoder.encoder.0.bias: 1.9310162843733103e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0014090918703004718\n",
      "Gradient for encoder.encoder.1.bias: 0.0013390728272497654\n",
      "Gradient for encoder.encoder.3.weight: 0.028273895382881165\n",
      "Gradient for encoder.encoder.3.bias: 3.035257045702622e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.005837160162627697\n",
      "Gradient for encoder.encoder.4.bias: 0.006759073585271835\n",
      "Gradient for encoder.mean.weight: 0.07701729983091354\n",
      "Gradient for encoder.mean.bias: 0.005255958065390587\n",
      "Gradient for encoder.log_var.weight: 0.044450756162405014\n",
      "Gradient for encoder.log_var.bias: 0.0033598991576582193\n",
      "Gradient for decoder.decoder.0.weight: 0.015493002720177174\n",
      "Gradient for decoder.decoder.0.bias: 1.24875762508303e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0007605678983964026\n",
      "Gradient for decoder.decoder.1.bias: 0.00061804085271433\n",
      "Gradient for decoder.decoder.3.weight: 0.014186938293278217\n",
      "Gradient for decoder.decoder.3.bias: 1.1875971039909672e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0006723214173689485\n",
      "Gradient for decoder.decoder.4.bias: 0.0007077489281073213\n",
      "Gradient for decoder.decoder.6.weight: 0.0007948843413032591\n",
      "Gradient for decoder.decoder.6.bias: 4.9311795009998605e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.013861701823771\n",
      "Gradient for encoder.encoder.0.bias: 2.0985982049359642e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0017455582274124026\n",
      "Gradient for encoder.encoder.1.bias: 0.001360815018415451\n",
      "Gradient for encoder.encoder.3.weight: 0.03037712164223194\n",
      "Gradient for encoder.encoder.3.bias: 2.047820246708909e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0035708772484213114\n",
      "Gradient for encoder.encoder.4.bias: 0.003671371378004551\n",
      "Gradient for encoder.mean.weight: 0.04816563427448273\n",
      "Gradient for encoder.mean.bias: 0.002911113668233156\n",
      "Gradient for encoder.log_var.weight: 0.030138637870550156\n",
      "Gradient for encoder.log_var.bias: 0.001736197853460908\n",
      "Gradient for decoder.decoder.0.weight: 0.013381287455558777\n",
      "Gradient for decoder.decoder.0.bias: 1.1657698417710805e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0006703262333758175\n",
      "Gradient for decoder.decoder.1.bias: 0.0005748179974034429\n",
      "Gradient for decoder.decoder.3.weight: 0.0125266769900918\n",
      "Gradient for decoder.decoder.3.bias: 9.602359185567622e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0004529674188233912\n",
      "Gradient for decoder.decoder.4.bias: 0.0003933688858523965\n",
      "Gradient for decoder.decoder.6.weight: 0.0006786530138924718\n",
      "Gradient for decoder.decoder.6.bias: 3.709167503984645e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.014373444952070713\n",
      "Gradient for encoder.encoder.0.bias: 2.19943594587102e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0013942940859124064\n",
      "Gradient for encoder.encoder.1.bias: 0.001116171944886446\n",
      "Gradient for encoder.encoder.3.weight: 0.02922397293150425\n",
      "Gradient for encoder.encoder.3.bias: 2.322825543021878e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.005157929379492998\n",
      "Gradient for encoder.encoder.4.bias: 0.004969378467649221\n",
      "Gradient for encoder.mean.weight: 0.06865298002958298\n",
      "Gradient for encoder.mean.bias: 0.0032239877618849277\n",
      "Gradient for encoder.log_var.weight: 0.04117801412940025\n",
      "Gradient for encoder.log_var.bias: 0.001803424209356308\n",
      "Gradient for decoder.decoder.0.weight: 0.01238344144076109\n",
      "Gradient for decoder.decoder.0.bias: 1.0285210183536009e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0006334853824228048\n",
      "Gradient for decoder.decoder.1.bias: 0.0004802864568773657\n",
      "Gradient for decoder.decoder.3.weight: 0.011262436397373676\n",
      "Gradient for decoder.decoder.3.bias: 8.608286305999968e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0004452086868695915\n",
      "Gradient for decoder.decoder.4.bias: 0.00041567202424630523\n",
      "Gradient for decoder.decoder.6.weight: 0.0006887121126055717\n",
      "Gradient for decoder.decoder.6.bias: 3.822514554485679e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.015507378615438938\n",
      "Gradient for encoder.encoder.0.bias: 2.3192746334554926e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0014166946057230234\n",
      "Gradient for encoder.encoder.1.bias: 0.00132750126067549\n",
      "Gradient for encoder.encoder.3.weight: 0.03207983821630478\n",
      "Gradient for encoder.encoder.3.bias: 2.0680769596825854e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0037158187478780746\n",
      "Gradient for encoder.encoder.4.bias: 0.0029851368162781\n",
      "Gradient for encoder.mean.weight: 0.05165336653590202\n",
      "Gradient for encoder.mean.bias: 0.0019441272597759962\n",
      "Gradient for encoder.log_var.weight: 0.030124235898256302\n",
      "Gradient for encoder.log_var.bias: 0.0012522845063358545\n",
      "Gradient for decoder.decoder.0.weight: 0.014872522093355656\n",
      "Gradient for decoder.decoder.0.bias: 1.238771307754405e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0007389091188088059\n",
      "Gradient for decoder.decoder.1.bias: 0.0005806919652968645\n",
      "Gradient for decoder.decoder.3.weight: 0.012708102352917194\n",
      "Gradient for decoder.decoder.3.bias: 1.1266342719862266e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.00043034489499405026\n",
      "Gradient for decoder.decoder.4.bias: 0.0004139017255511135\n",
      "Gradient for decoder.decoder.6.weight: 0.0007161676185205579\n",
      "Gradient for decoder.decoder.6.bias: 4.2001654946943745e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.00924007873982191\n",
      "Gradient for encoder.encoder.0.bias: 1.4360847580552338e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0008165946928784251\n",
      "Gradient for encoder.encoder.1.bias: 0.0008564243325963616\n",
      "Gradient for encoder.encoder.3.weight: 0.017275379970669746\n",
      "Gradient for encoder.encoder.3.bias: 1.844272373707767e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.004005339927971363\n",
      "Gradient for encoder.encoder.4.bias: 0.003021368058398366\n",
      "Gradient for encoder.mean.weight: 0.05839790031313896\n",
      "Gradient for encoder.mean.bias: 0.0022496639285236597\n",
      "Gradient for encoder.log_var.weight: 0.039042502641677856\n",
      "Gradient for encoder.log_var.bias: 0.0017252766992896795\n",
      "Gradient for decoder.decoder.0.weight: 0.017650198191404343\n",
      "Gradient for decoder.decoder.0.bias: 1.4965320649373837e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.000983682693913579\n",
      "Gradient for decoder.decoder.1.bias: 0.0006697418284602463\n",
      "Gradient for decoder.decoder.3.weight: 0.01641876809298992\n",
      "Gradient for decoder.decoder.3.bias: 1.2509726587950354e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0005926901358179748\n",
      "Gradient for decoder.decoder.4.bias: 0.0005030184402130544\n",
      "Gradient for decoder.decoder.6.weight: 0.0007573671755380929\n",
      "Gradient for decoder.decoder.6.bias: 4.495589746511541e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.016035499051213264\n",
      "Gradient for encoder.encoder.0.bias: 2.7831979776404836e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0016379771986976266\n",
      "Gradient for encoder.encoder.1.bias: 0.0015110677340999246\n",
      "Gradient for encoder.encoder.3.weight: 0.03541020676493645\n",
      "Gradient for encoder.encoder.3.bias: 2.9150609703876285e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0058171674609184265\n",
      "Gradient for encoder.encoder.4.bias: 0.007084813434630632\n",
      "Gradient for encoder.mean.weight: 0.07444797456264496\n",
      "Gradient for encoder.mean.bias: 0.0052505130879580975\n",
      "Gradient for encoder.log_var.weight: 0.04275159165263176\n",
      "Gradient for encoder.log_var.bias: 0.0034876158460974693\n",
      "Gradient for decoder.decoder.0.weight: 0.011132941581308842\n",
      "Gradient for decoder.decoder.0.bias: 9.542661105754746e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005805598339065909\n",
      "Gradient for decoder.decoder.1.bias: 0.0004451870045159012\n",
      "Gradient for decoder.decoder.3.weight: 0.01042129471898079\n",
      "Gradient for decoder.decoder.3.bias: 9.992891930599157e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0006382755236700177\n",
      "Gradient for decoder.decoder.4.bias: 0.0007806458743289113\n",
      "Gradient for decoder.decoder.6.weight: 0.0006780600524507463\n",
      "Gradient for decoder.decoder.6.bias: 4.5352167944656685e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.014028102159500122\n",
      "Gradient for encoder.encoder.0.bias: 2.1267192867879814e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.001117503852583468\n",
      "Gradient for encoder.encoder.1.bias: 0.0011193669633939862\n",
      "Gradient for encoder.encoder.3.weight: 0.023934414610266685\n",
      "Gradient for encoder.encoder.3.bias: 2.540929133765246e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0053086671978235245\n",
      "Gradient for encoder.encoder.4.bias: 0.0051671420224010944\n",
      "Gradient for encoder.mean.weight: 0.0698501318693161\n",
      "Gradient for encoder.mean.bias: 0.0032977827358990908\n",
      "Gradient for encoder.log_var.weight: 0.040935490280389786\n",
      "Gradient for encoder.log_var.bias: 0.002183384494856\n",
      "Gradient for decoder.decoder.0.weight: 0.013633646070957184\n",
      "Gradient for decoder.decoder.0.bias: 1.1553805134845163e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0007154152262955904\n",
      "Gradient for decoder.decoder.1.bias: 0.0005727657699026167\n",
      "Gradient for decoder.decoder.3.weight: 0.01273039635270834\n",
      "Gradient for decoder.decoder.3.bias: 1.0218018098306914e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.00047442951472476125\n",
      "Gradient for decoder.decoder.4.bias: 0.0004717937554232776\n",
      "Gradient for decoder.decoder.6.weight: 0.0007293800008483231\n",
      "Gradient for decoder.decoder.6.bias: 4.1629435145296156e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.018882445991039276\n",
      "Gradient for encoder.encoder.0.bias: 3.4612694654878595e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.002736842492595315\n",
      "Gradient for encoder.encoder.1.bias: 0.002286940347403288\n",
      "Gradient for encoder.encoder.3.weight: 0.057688310742378235\n",
      "Gradient for encoder.encoder.3.bias: 3.0747504542461e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.007094716187566519\n",
      "Gradient for encoder.encoder.4.bias: 0.006357494741678238\n",
      "Gradient for encoder.mean.weight: 0.08973764628171921\n",
      "Gradient for encoder.mean.bias: 0.0040331338532269\n",
      "Gradient for encoder.log_var.weight: 0.05072353780269623\n",
      "Gradient for encoder.log_var.bias: 0.0020825937390327454\n",
      "Gradient for decoder.decoder.0.weight: 0.01230787392705679\n",
      "Gradient for decoder.decoder.0.bias: 9.826219699027305e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0006302265101112425\n",
      "Gradient for decoder.decoder.1.bias: 0.0004770073282998055\n",
      "Gradient for decoder.decoder.3.weight: 0.011094767600297928\n",
      "Gradient for decoder.decoder.3.bias: 1.0588859650217941e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0006661976804025471\n",
      "Gradient for decoder.decoder.4.bias: 0.0007976799388416111\n",
      "Gradient for decoder.decoder.6.weight: 0.0007417136221192777\n",
      "Gradient for decoder.decoder.6.bias: 5.664110722136684e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.014625017531216145\n",
      "Gradient for encoder.encoder.0.bias: 2.3469982901591635e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.001948283868841827\n",
      "Gradient for encoder.encoder.1.bias: 0.0016759835416451097\n",
      "Gradient for encoder.encoder.3.weight: 0.03766851872205734\n",
      "Gradient for encoder.encoder.3.bias: 2.477201499484494e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.004532103892415762\n",
      "Gradient for encoder.encoder.4.bias: 0.004327397793531418\n",
      "Gradient for encoder.mean.weight: 0.05988338217139244\n",
      "Gradient for encoder.mean.bias: 0.0026327359955757856\n",
      "Gradient for encoder.log_var.weight: 0.035709116607904434\n",
      "Gradient for encoder.log_var.bias: 0.001771852606907487\n",
      "Gradient for decoder.decoder.0.weight: 0.013036533258855343\n",
      "Gradient for decoder.decoder.0.bias: 1.0996892979564521e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0006679042708128691\n",
      "Gradient for decoder.decoder.1.bias: 0.0005306267412379384\n",
      "Gradient for decoder.decoder.3.weight: 0.011990456841886044\n",
      "Gradient for decoder.decoder.3.bias: 1.0014693935245234e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0004148068546783179\n",
      "Gradient for decoder.decoder.4.bias: 0.00042191226384602487\n",
      "Gradient for decoder.decoder.6.weight: 0.0006945563945919275\n",
      "Gradient for decoder.decoder.6.bias: 4.264253948349506e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.01587417535483837\n",
      "Gradient for encoder.encoder.0.bias: 2.3673918728150944e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.001627356861717999\n",
      "Gradient for encoder.encoder.1.bias: 0.001398624968715012\n",
      "Gradient for encoder.encoder.3.weight: 0.0321957990527153\n",
      "Gradient for encoder.encoder.3.bias: 2.4007604237930025e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.005143593065440655\n",
      "Gradient for encoder.encoder.4.bias: 0.004717099480330944\n",
      "Gradient for encoder.mean.weight: 0.06777822226285934\n",
      "Gradient for encoder.mean.bias: 0.003100139554589987\n",
      "Gradient for encoder.log_var.weight: 0.041858915239572525\n",
      "Gradient for encoder.log_var.bias: 0.0019662382546812296\n",
      "Gradient for decoder.decoder.0.weight: 0.012605322524905205\n",
      "Gradient for decoder.decoder.0.bias: 1.0427209096164347e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0006409784546121955\n",
      "Gradient for decoder.decoder.1.bias: 0.0004931622534058988\n",
      "Gradient for decoder.decoder.3.weight: 0.011821961961686611\n",
      "Gradient for decoder.decoder.3.bias: 8.647294685859563e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00043541728518903255\n",
      "Gradient for decoder.decoder.4.bias: 0.0003659413487184793\n",
      "Gradient for decoder.decoder.6.weight: 0.0006886607734486461\n",
      "Gradient for decoder.decoder.6.bias: 3.675858170026913e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.02337496541440487\n",
      "Gradient for encoder.encoder.0.bias: 2.968432097349982e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.002693754620850086\n",
      "Gradient for encoder.encoder.1.bias: 0.002287880750373006\n",
      "Gradient for encoder.encoder.3.weight: 0.05505700409412384\n",
      "Gradient for encoder.encoder.3.bias: 3.2298269614372543e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.006794344168156385\n",
      "Gradient for encoder.encoder.4.bias: 0.007371868938207626\n",
      "Gradient for encoder.mean.weight: 0.09002214670181274\n",
      "Gradient for encoder.mean.bias: 0.005526792723685503\n",
      "Gradient for encoder.log_var.weight: 0.053377989679574966\n",
      "Gradient for encoder.log_var.bias: 0.0035359710454940796\n",
      "Gradient for decoder.decoder.0.weight: 0.013881467282772064\n",
      "Gradient for decoder.decoder.0.bias: 1.187108467082254e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0006971039692871273\n",
      "Gradient for decoder.decoder.1.bias: 0.0005484427092596889\n",
      "Gradient for decoder.decoder.3.weight: 0.012442384846508503\n",
      "Gradient for decoder.decoder.3.bias: 9.715696303036481e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0004961113445460796\n",
      "Gradient for decoder.decoder.4.bias: 0.0004409428802318871\n",
      "Gradient for decoder.decoder.6.weight: 0.000728946237359196\n",
      "Gradient for decoder.decoder.6.bias: 4.097404962521978e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.14171412587165833\n",
      "Gradient for encoder.encoder.0.bias: 1.9195581235642578e-10\n",
      "Gradient for encoder.encoder.1.weight: 0.01458061020821333\n",
      "Gradient for encoder.encoder.1.bias: 0.011426382698118687\n",
      "Gradient for encoder.encoder.3.weight: 0.3179451823234558\n",
      "Gradient for encoder.encoder.3.bias: 1.4614688348402183e-09\n",
      "Gradient for encoder.encoder.4.weight: 0.028029827401041985\n",
      "Gradient for encoder.encoder.4.bias: 0.025889486074447632\n",
      "Gradient for encoder.mean.weight: 0.380357950925827\n",
      "Gradient for encoder.mean.bias: 0.011379026807844639\n",
      "Gradient for encoder.log_var.weight: 0.22746646404266357\n",
      "Gradient for encoder.log_var.bias: 0.007678565103560686\n",
      "Gradient for decoder.decoder.0.weight: 0.029742438346147537\n",
      "Gradient for decoder.decoder.0.bias: 1.9413474994234292e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0013578471262007952\n",
      "Gradient for decoder.decoder.1.bias: 0.0011398058850318193\n",
      "Gradient for decoder.decoder.3.weight: 0.02704702876508236\n",
      "Gradient for decoder.decoder.3.bias: 2.082265609937295e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0010863475035876036\n",
      "Gradient for decoder.decoder.4.bias: 0.0011031478643417358\n",
      "Gradient for decoder.decoder.6.weight: 0.0018600600305944681\n",
      "Gradient for decoder.decoder.6.bias: 0.00011909415479749441\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/3, Train Loss: 0.0764, Val Loss: 0.3316\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training VAE Epoch:   1%|▏         | 1/79 [00:00<00:15,  5.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient for encoder.encoder.0.weight: 0.01828322373330593\n",
      "Gradient for encoder.encoder.0.bias: 2.2591080048317558e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0017643974861130118\n",
      "Gradient for encoder.encoder.1.bias: 0.0013847918016836047\n",
      "Gradient for encoder.encoder.3.weight: 0.037533409893512726\n",
      "Gradient for encoder.encoder.3.bias: 2.467354376367581e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.004455657675862312\n",
      "Gradient for encoder.encoder.4.bias: 0.004915660247206688\n",
      "Gradient for encoder.mean.weight: 0.06160888820886612\n",
      "Gradient for encoder.mean.bias: 0.0032691999804228544\n",
      "Gradient for encoder.log_var.weight: 0.03396183252334595\n",
      "Gradient for encoder.log_var.bias: 0.0018086935160681605\n",
      "Gradient for decoder.decoder.0.weight: 0.013532377779483795\n",
      "Gradient for decoder.decoder.0.bias: 1.1489679346832204e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0006827136385254562\n",
      "Gradient for decoder.decoder.1.bias: 0.000546448805835098\n",
      "Gradient for decoder.decoder.3.weight: 0.012592190876603127\n",
      "Gradient for decoder.decoder.3.bias: 9.884199708709573e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0004857785243075341\n",
      "Gradient for decoder.decoder.4.bias: 0.00048781014629639685\n",
      "Gradient for decoder.decoder.6.weight: 0.0006918995641171932\n",
      "Gradient for decoder.decoder.6.bias: 4.2104929889319465e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training VAE Epoch:  11%|█▏        | 9/79 [00:00<00:01, 35.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient for encoder.encoder.0.weight: 0.023691920563578606\n",
      "Gradient for encoder.encoder.0.bias: 4.008563619928296e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.003892571898177266\n",
      "Gradient for encoder.encoder.1.bias: 0.0030837964732199907\n",
      "Gradient for encoder.encoder.3.weight: 0.08414322882890701\n",
      "Gradient for encoder.encoder.3.bias: 4.2869971461634293e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.009879031218588352\n",
      "Gradient for encoder.encoder.4.bias: 0.010258759371936321\n",
      "Gradient for encoder.mean.weight: 0.13363847136497498\n",
      "Gradient for encoder.mean.bias: 0.006893957499414682\n",
      "Gradient for encoder.log_var.weight: 0.07455506920814514\n",
      "Gradient for encoder.log_var.bias: 0.0035173874348402023\n",
      "Gradient for decoder.decoder.0.weight: 0.013265479356050491\n",
      "Gradient for decoder.decoder.0.bias: 1.1141199768305299e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0006923809996806085\n",
      "Gradient for decoder.decoder.1.bias: 0.000547808303963393\n",
      "Gradient for decoder.decoder.3.weight: 0.012491334229707718\n",
      "Gradient for decoder.decoder.3.bias: 9.992581762041652e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0004630959883797914\n",
      "Gradient for decoder.decoder.4.bias: 0.0004720721044577658\n",
      "Gradient for decoder.decoder.6.weight: 0.0007345137419179082\n",
      "Gradient for decoder.decoder.6.bias: 4.758101931656711e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.03278297185897827\n",
      "Gradient for encoder.encoder.0.bias: 4.908125642022476e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.004311738535761833\n",
      "Gradient for encoder.encoder.1.bias: 0.003349544946104288\n",
      "Gradient for encoder.encoder.3.weight: 0.10038076341152191\n",
      "Gradient for encoder.encoder.3.bias: 3.9615619118471557e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.008119145408272743\n",
      "Gradient for encoder.encoder.4.bias: 0.008339136838912964\n",
      "Gradient for encoder.mean.weight: 0.11607909947633743\n",
      "Gradient for encoder.mean.bias: 0.005183073226362467\n",
      "Gradient for encoder.log_var.weight: 0.06386715918779373\n",
      "Gradient for encoder.log_var.bias: 0.0031476242002099752\n",
      "Gradient for decoder.decoder.0.weight: 0.01187056116759777\n",
      "Gradient for decoder.decoder.0.bias: 9.871611861278495e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005682550836354494\n",
      "Gradient for decoder.decoder.1.bias: 0.0004651904746424407\n",
      "Gradient for decoder.decoder.3.weight: 0.010741319507360458\n",
      "Gradient for decoder.decoder.3.bias: 9.258589034333298e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0005199675797484815\n",
      "Gradient for decoder.decoder.4.bias: 0.0005407618009485304\n",
      "Gradient for decoder.decoder.6.weight: 0.0007293322705663741\n",
      "Gradient for decoder.decoder.6.bias: 5.059891918790527e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.020810987800359726\n",
      "Gradient for encoder.encoder.0.bias: 2.949084726422413e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.002808552235364914\n",
      "Gradient for encoder.encoder.1.bias: 0.002741477219387889\n",
      "Gradient for encoder.encoder.3.weight: 0.06661008298397064\n",
      "Gradient for encoder.encoder.3.bias: 4.444943024761727e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.01367495208978653\n",
      "Gradient for encoder.encoder.4.bias: 0.011516742408275604\n",
      "Gradient for encoder.mean.weight: 0.18570595979690552\n",
      "Gradient for encoder.mean.bias: 0.005567959509789944\n",
      "Gradient for encoder.log_var.weight: 0.10478059202432632\n",
      "Gradient for encoder.log_var.bias: 0.003101476700976491\n",
      "Gradient for decoder.decoder.0.weight: 0.016626769676804543\n",
      "Gradient for decoder.decoder.0.bias: 1.3459969250284587e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0008564505842514336\n",
      "Gradient for decoder.decoder.1.bias: 0.0006903769681230187\n",
      "Gradient for decoder.decoder.3.weight: 0.015466309152543545\n",
      "Gradient for decoder.decoder.3.bias: 1.1036205282977107e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0005532327340915799\n",
      "Gradient for decoder.decoder.4.bias: 0.0004768970247823745\n",
      "Gradient for decoder.decoder.6.weight: 0.0007032507564872503\n",
      "Gradient for decoder.decoder.6.bias: 3.269908484071493e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.02816607430577278\n",
      "Gradient for encoder.encoder.0.bias: 3.435789847072712e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0034338473342359066\n",
      "Gradient for encoder.encoder.1.bias: 0.0030658156611025333\n",
      "Gradient for encoder.encoder.3.weight: 0.07709642499685287\n",
      "Gradient for encoder.encoder.3.bias: 3.951149962766465e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.008640107698738575\n",
      "Gradient for encoder.encoder.4.bias: 0.009260554797947407\n",
      "Gradient for encoder.mean.weight: 0.12083274871110916\n",
      "Gradient for encoder.mean.bias: 0.005906021688133478\n",
      "Gradient for encoder.log_var.weight: 0.07198159396648407\n",
      "Gradient for encoder.log_var.bias: 0.0037154462188482285\n",
      "Gradient for decoder.decoder.0.weight: 0.013043937273323536\n",
      "Gradient for decoder.decoder.0.bias: 1.100014038191155e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0007062199874781072\n",
      "Gradient for decoder.decoder.1.bias: 0.0005216420977376401\n",
      "Gradient for decoder.decoder.3.weight: 0.012157455086708069\n",
      "Gradient for decoder.decoder.3.bias: 9.523402205724452e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0005382559611462057\n",
      "Gradient for decoder.decoder.4.bias: 0.0005355236935429275\n",
      "Gradient for decoder.decoder.6.weight: 0.0006979356985539198\n",
      "Gradient for decoder.decoder.6.bias: 4.191104380879551e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.02085508406162262\n",
      "Gradient for encoder.encoder.0.bias: 2.6406750050500527e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.001976702595129609\n",
      "Gradient for encoder.encoder.1.bias: 0.0018664845265448093\n",
      "Gradient for encoder.encoder.3.weight: 0.0453195758163929\n",
      "Gradient for encoder.encoder.3.bias: 3.922631386377162e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.009699194692075253\n",
      "Gradient for encoder.encoder.4.bias: 0.009018413722515106\n",
      "Gradient for encoder.mean.weight: 0.12815803289413452\n",
      "Gradient for encoder.mean.bias: 0.005081346724182367\n",
      "Gradient for encoder.log_var.weight: 0.07834513485431671\n",
      "Gradient for encoder.log_var.bias: 0.0033782750833779573\n",
      "Gradient for decoder.decoder.0.weight: 0.015818726271390915\n",
      "Gradient for decoder.decoder.0.bias: 1.3557698019805997e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0007850098772905767\n",
      "Gradient for decoder.decoder.1.bias: 0.0006152532296255231\n",
      "Gradient for decoder.decoder.3.weight: 0.014189045876264572\n",
      "Gradient for decoder.decoder.3.bias: 1.1502501728877235e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0006016412517055869\n",
      "Gradient for decoder.decoder.4.bias: 0.0005516316741704941\n",
      "Gradient for decoder.decoder.6.weight: 0.0007280069985426962\n",
      "Gradient for decoder.decoder.6.bias: 3.3941687433980405e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.022380957379937172\n",
      "Gradient for encoder.encoder.0.bias: 2.7363257493195903e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0023598438128829002\n",
      "Gradient for encoder.encoder.1.bias: 0.0019066017121076584\n",
      "Gradient for encoder.encoder.3.weight: 0.053844988346099854\n",
      "Gradient for encoder.encoder.3.bias: 2.779591834478623e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.004575017839670181\n",
      "Gradient for encoder.encoder.4.bias: 0.0047983815893530846\n",
      "Gradient for encoder.mean.weight: 0.0630144476890564\n",
      "Gradient for encoder.mean.bias: 0.003196924924850464\n",
      "Gradient for encoder.log_var.weight: 0.040724508464336395\n",
      "Gradient for encoder.log_var.bias: 0.0021533409599214792\n",
      "Gradient for decoder.decoder.0.weight: 0.016173046082258224\n",
      "Gradient for decoder.decoder.0.bias: 1.4283867144637696e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0008674960117787123\n",
      "Gradient for decoder.decoder.1.bias: 0.0006984486826695502\n",
      "Gradient for decoder.decoder.3.weight: 0.014745716005563736\n",
      "Gradient for decoder.decoder.3.bias: 1.3475823235076234e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0008153446833603084\n",
      "Gradient for decoder.decoder.4.bias: 0.0008990120841190219\n",
      "Gradient for decoder.decoder.6.weight: 0.0008418772486038506\n",
      "Gradient for decoder.decoder.6.bias: 5.744075679103844e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.020227253437042236\n",
      "Gradient for encoder.encoder.0.bias: 2.9750497204661386e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.002136439783498645\n",
      "Gradient for encoder.encoder.1.bias: 0.0016414382262155414\n",
      "Gradient for encoder.encoder.3.weight: 0.044559504836797714\n",
      "Gradient for encoder.encoder.3.bias: 2.7184240969369e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.005391641985625029\n",
      "Gradient for encoder.encoder.4.bias: 0.005148465279489756\n",
      "Gradient for encoder.mean.weight: 0.07141706347465515\n",
      "Gradient for encoder.mean.bias: 0.0035461431834846735\n",
      "Gradient for encoder.log_var.weight: 0.03789925202727318\n",
      "Gradient for encoder.log_var.bias: 0.0021124996710568666\n",
      "Gradient for decoder.decoder.0.weight: 0.011983770877122879\n",
      "Gradient for decoder.decoder.0.bias: 1.0739026334860569e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0006495887064374983\n",
      "Gradient for decoder.decoder.1.bias: 0.0005078531103208661\n",
      "Gradient for decoder.decoder.3.weight: 0.011180098168551922\n",
      "Gradient for decoder.decoder.3.bias: 1.06429337565217e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.00039868708699941635\n",
      "Gradient for decoder.decoder.4.bias: 0.000358243880327791\n",
      "Gradient for decoder.decoder.6.weight: 0.0006440834258683026\n",
      "Gradient for decoder.decoder.6.bias: 2.8745995223289356e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.024168647825717926\n",
      "Gradient for encoder.encoder.0.bias: 3.1909114239780934e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0022224625572562218\n",
      "Gradient for encoder.encoder.1.bias: 0.0017967155436053872\n",
      "Gradient for encoder.encoder.3.weight: 0.0463370680809021\n",
      "Gradient for encoder.encoder.3.bias: 3.3414809808007817e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.005592202302068472\n",
      "Gradient for encoder.encoder.4.bias: 0.0049158139154314995\n",
      "Gradient for encoder.mean.weight: 0.07853031158447266\n",
      "Gradient for encoder.mean.bias: 0.003432557452470064\n",
      "Gradient for encoder.log_var.weight: 0.03732757270336151\n",
      "Gradient for encoder.log_var.bias: 0.0018889721250161529\n",
      "Gradient for decoder.decoder.0.weight: 0.013969484716653824\n",
      "Gradient for decoder.decoder.0.bias: 1.1889490780792045e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0007166978321038187\n",
      "Gradient for decoder.decoder.1.bias: 0.000543622940313071\n",
      "Gradient for decoder.decoder.3.weight: 0.012657956220209599\n",
      "Gradient for decoder.decoder.3.bias: 1.0681003997925487e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0006096079596318305\n",
      "Gradient for decoder.decoder.4.bias: 0.0006288841250352561\n",
      "Gradient for decoder.decoder.6.weight: 0.0007345223566517234\n",
      "Gradient for decoder.decoder.6.bias: 4.206073208479211e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.029032032936811447\n",
      "Gradient for encoder.encoder.0.bias: 3.910818890950907e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.002621506340801716\n",
      "Gradient for encoder.encoder.1.bias: 0.001865479862317443\n",
      "Gradient for encoder.encoder.3.weight: 0.05744592100381851\n",
      "Gradient for encoder.encoder.3.bias: 3.4497885104123327e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.006422150414437056\n",
      "Gradient for encoder.encoder.4.bias: 0.006339715793728828\n",
      "Gradient for encoder.mean.weight: 0.08561362326145172\n",
      "Gradient for encoder.mean.bias: 0.0045145051553845406\n",
      "Gradient for encoder.log_var.weight: 0.045333556830883026\n",
      "Gradient for encoder.log_var.bias: 0.002564893336966634\n",
      "Gradient for decoder.decoder.0.weight: 0.012690839357674122\n",
      "Gradient for decoder.decoder.0.bias: 1.1036491859295339e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0005996266845613718\n",
      "Gradient for decoder.decoder.1.bias: 0.00048527572653256357\n",
      "Gradient for decoder.decoder.3.weight: 0.011574670672416687\n",
      "Gradient for decoder.decoder.3.bias: 1.1224455392921939e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.00041741805034689605\n",
      "Gradient for decoder.decoder.4.bias: 0.0003705487179104239\n",
      "Gradient for decoder.decoder.6.weight: 0.0006464707548730075\n",
      "Gradient for decoder.decoder.6.bias: 3.437445411691442e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.02986929938197136\n",
      "Gradient for encoder.encoder.0.bias: 4.0806420742445226e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0024257174227386713\n",
      "Gradient for encoder.encoder.1.bias: 0.0017124938312917948\n",
      "Gradient for encoder.encoder.3.weight: 0.04902755841612816\n",
      "Gradient for encoder.encoder.3.bias: 3.928205816183805e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.006598298437893391\n",
      "Gradient for encoder.encoder.4.bias: 0.006731575354933739\n",
      "Gradient for encoder.mean.weight: 0.08116871118545532\n",
      "Gradient for encoder.mean.bias: 0.004475310444831848\n",
      "Gradient for encoder.log_var.weight: 0.05482867360115051\n",
      "Gradient for encoder.log_var.bias: 0.002799635287374258\n",
      "Gradient for decoder.decoder.0.weight: 0.01350221037864685\n",
      "Gradient for decoder.decoder.0.bias: 1.2015688444222405e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0006503457552753389\n",
      "Gradient for decoder.decoder.1.bias: 0.0005062812124378979\n",
      "Gradient for decoder.decoder.3.weight: 0.01193249225616455\n",
      "Gradient for decoder.decoder.3.bias: 1.1119700299433433e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0006014350219629705\n",
      "Gradient for decoder.decoder.4.bias: 0.0006880277651362121\n",
      "Gradient for decoder.decoder.6.weight: 0.0007057340117171407\n",
      "Gradient for decoder.decoder.6.bias: 4.716304101748392e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.019814634695649147\n",
      "Gradient for encoder.encoder.0.bias: 2.5056231395259587e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.00236747064627707\n",
      "Gradient for encoder.encoder.1.bias: 0.0016684498405084014\n",
      "Gradient for encoder.encoder.3.weight: 0.04635472223162651\n",
      "Gradient for encoder.encoder.3.bias: 3.2112071335355097e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.006609884090721607\n",
      "Gradient for encoder.encoder.4.bias: 0.0065320758149027824\n",
      "Gradient for encoder.mean.weight: 0.09390424937009811\n",
      "Gradient for encoder.mean.bias: 0.004665598273277283\n",
      "Gradient for encoder.log_var.weight: 0.04708067700266838\n",
      "Gradient for encoder.log_var.bias: 0.002846837742254138\n",
      "Gradient for decoder.decoder.0.weight: 0.01701667346060276\n",
      "Gradient for decoder.decoder.0.bias: 1.5345971715596818e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0008713766001164913\n",
      "Gradient for decoder.decoder.1.bias: 0.0006767527083866298\n",
      "Gradient for decoder.decoder.3.weight: 0.015556800179183483\n",
      "Gradient for decoder.decoder.3.bias: 1.4004335191497574e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.000556421116925776\n",
      "Gradient for decoder.decoder.4.bias: 0.0005017310613766313\n",
      "Gradient for decoder.decoder.6.weight: 0.0006741525721736252\n",
      "Gradient for decoder.decoder.6.bias: 3.305487189209089e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.016987038776278496\n",
      "Gradient for encoder.encoder.0.bias: 2.5894595495623562e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0018516419222578406\n",
      "Gradient for encoder.encoder.1.bias: 0.0013172597391530871\n",
      "Gradient for encoder.encoder.3.weight: 0.037284545600414276\n",
      "Gradient for encoder.encoder.3.bias: 2.67565969380712e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.005458256229758263\n",
      "Gradient for encoder.encoder.4.bias: 0.005014656111598015\n",
      "Gradient for encoder.mean.weight: 0.08104400336742401\n",
      "Gradient for encoder.mean.bias: 0.004161312244832516\n",
      "Gradient for encoder.log_var.weight: 0.04735662415623665\n",
      "Gradient for encoder.log_var.bias: 0.002484259894117713\n",
      "Gradient for decoder.decoder.0.weight: 0.013605449348688126\n",
      "Gradient for decoder.decoder.0.bias: 1.0650242493470685e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0006912822718732059\n",
      "Gradient for decoder.decoder.1.bias: 0.0005153101519681513\n",
      "Gradient for decoder.decoder.3.weight: 0.012410066090524197\n",
      "Gradient for decoder.decoder.3.bias: 9.458252930860667e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0004385431529954076\n",
      "Gradient for decoder.decoder.4.bias: 0.0003892801178153604\n",
      "Gradient for decoder.decoder.6.weight: 0.0006590435514226556\n",
      "Gradient for decoder.decoder.6.bias: 3.1070117984199896e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.022899052128195763\n",
      "Gradient for encoder.encoder.0.bias: 3.033641740590731e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0018222227226942778\n",
      "Gradient for encoder.encoder.1.bias: 0.0015266123227775097\n",
      "Gradient for encoder.encoder.3.weight: 0.04210422933101654\n",
      "Gradient for encoder.encoder.3.bias: 2.705035917482945e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.004915516823530197\n",
      "Gradient for encoder.encoder.4.bias: 0.004634169861674309\n",
      "Gradient for encoder.mean.weight: 0.06907924264669418\n",
      "Gradient for encoder.mean.bias: 0.0034682760015130043\n",
      "Gradient for encoder.log_var.weight: 0.04399091377854347\n",
      "Gradient for encoder.log_var.bias: 0.0020985922310501337\n",
      "Gradient for decoder.decoder.0.weight: 0.01311102882027626\n",
      "Gradient for decoder.decoder.0.bias: 1.1439816455238727e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0006902424502186477\n",
      "Gradient for decoder.decoder.1.bias: 0.0004767368664033711\n",
      "Gradient for decoder.decoder.3.weight: 0.012177940458059311\n",
      "Gradient for decoder.decoder.3.bias: 1.2322813602860805e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0005715900333598256\n",
      "Gradient for decoder.decoder.4.bias: 0.0006777701782993972\n",
      "Gradient for decoder.decoder.6.weight: 0.0006904089241288602\n",
      "Gradient for decoder.decoder.6.bias: 4.691095818998292e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.022526847198605537\n",
      "Gradient for encoder.encoder.0.bias: 3.24197162171469e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0019119189819321036\n",
      "Gradient for encoder.encoder.1.bias: 0.0014322942588478327\n",
      "Gradient for encoder.encoder.3.weight: 0.040019724518060684\n",
      "Gradient for encoder.encoder.3.bias: 3.082832322753859e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.005913739092648029\n",
      "Gradient for encoder.encoder.4.bias: 0.006189726758748293\n",
      "Gradient for encoder.mean.weight: 0.08129139989614487\n",
      "Gradient for encoder.mean.bias: 0.0046634553000330925\n",
      "Gradient for encoder.log_var.weight: 0.05213744193315506\n",
      "Gradient for encoder.log_var.bias: 0.0027026806492358446\n",
      "Gradient for decoder.decoder.0.weight: 0.012880822643637657\n",
      "Gradient for decoder.decoder.0.bias: 1.2243132896383457e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0006689037545584142\n",
      "Gradient for decoder.decoder.1.bias: 0.0005248480010777712\n",
      "Gradient for decoder.decoder.3.weight: 0.01193438284099102\n",
      "Gradient for decoder.decoder.3.bias: 1.1612941858141212e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0005091914790682495\n",
      "Gradient for decoder.decoder.4.bias: 0.0005559162236750126\n",
      "Gradient for decoder.decoder.6.weight: 0.0006730182794854045\n",
      "Gradient for decoder.decoder.6.bias: 4.289040225557983e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.018874771893024445\n",
      "Gradient for encoder.encoder.0.bias: 2.6550105863831774e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0017669893568381667\n",
      "Gradient for encoder.encoder.1.bias: 0.00174043164588511\n",
      "Gradient for encoder.encoder.3.weight: 0.03715210035443306\n",
      "Gradient for encoder.encoder.3.bias: 3.6105829437360626e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.009871234185993671\n",
      "Gradient for encoder.encoder.4.bias: 0.0081314193084836\n",
      "Gradient for encoder.mean.weight: 0.12389907985925674\n",
      "Gradient for encoder.mean.bias: 0.004152773413807154\n",
      "Gradient for encoder.log_var.weight: 0.06860866397619247\n",
      "Gradient for encoder.log_var.bias: 0.0025023366324603558\n",
      "Gradient for decoder.decoder.0.weight: 0.01527363806962967\n",
      "Gradient for decoder.decoder.0.bias: 1.2547875238855255e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0007723851012997329\n",
      "Gradient for decoder.decoder.1.bias: 0.0006411853828467429\n",
      "Gradient for decoder.decoder.3.weight: 0.01402198150753975\n",
      "Gradient for decoder.decoder.3.bias: 1.0165535774264711e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0004945278633385897\n",
      "Gradient for decoder.decoder.4.bias: 0.0004677149700000882\n",
      "Gradient for decoder.decoder.6.weight: 0.000704858626704663\n",
      "Gradient for decoder.decoder.6.bias: 4.710477514890954e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.019853122532367706\n",
      "Gradient for encoder.encoder.0.bias: 2.717990763012601e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0023620787542313337\n",
      "Gradient for encoder.encoder.1.bias: 0.0017255733255296946\n",
      "Gradient for encoder.encoder.3.weight: 0.045797765254974365\n",
      "Gradient for encoder.encoder.3.bias: 3.4190009157164525e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.007879957556724548\n",
      "Gradient for encoder.encoder.4.bias: 0.00785496924072504\n",
      "Gradient for encoder.mean.weight: 0.0978136733174324\n",
      "Gradient for encoder.mean.bias: 0.005599007476121187\n",
      "Gradient for encoder.log_var.weight: 0.06838637590408325\n",
      "Gradient for encoder.log_var.bias: 0.003564723301678896\n",
      "Gradient for decoder.decoder.0.weight: 0.013258499093353748\n",
      "Gradient for decoder.decoder.0.bias: 1.0867795552371717e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0006657622870989144\n",
      "Gradient for decoder.decoder.1.bias: 0.0005232857656665146\n",
      "Gradient for decoder.decoder.3.weight: 0.0118624372407794\n",
      "Gradient for decoder.decoder.3.bias: 9.841708697999607e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0005522688734345138\n",
      "Gradient for decoder.decoder.4.bias: 0.0006266107666306198\n",
      "Gradient for decoder.decoder.6.weight: 0.0006681452505290508\n",
      "Gradient for decoder.decoder.6.bias: 4.1068757127504796e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training VAE Epoch:  32%|███▏      | 25/79 [00:00<00:00, 60.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient for encoder.encoder.0.weight: 0.018220683559775352\n",
      "Gradient for encoder.encoder.0.bias: 2.565913800878228e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0015922868624329567\n",
      "Gradient for encoder.encoder.1.bias: 0.0013423438649624586\n",
      "Gradient for encoder.encoder.3.weight: 0.03281758353114128\n",
      "Gradient for encoder.encoder.3.bias: 2.7997135165769294e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.005033433437347412\n",
      "Gradient for encoder.encoder.4.bias: 0.0052526467479765415\n",
      "Gradient for encoder.mean.weight: 0.06537003815174103\n",
      "Gradient for encoder.mean.bias: 0.003807895351201296\n",
      "Gradient for encoder.log_var.weight: 0.04209843650460243\n",
      "Gradient for encoder.log_var.bias: 0.002233432373031974\n",
      "Gradient for decoder.decoder.0.weight: 0.015287875197827816\n",
      "Gradient for decoder.decoder.0.bias: 1.336203370172484e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0008028117008507252\n",
      "Gradient for decoder.decoder.1.bias: 0.0005934183718636632\n",
      "Gradient for decoder.decoder.3.weight: 0.01467138808220625\n",
      "Gradient for decoder.decoder.3.bias: 1.105302724346835e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0006369043258018792\n",
      "Gradient for decoder.decoder.4.bias: 0.0006147140520624816\n",
      "Gradient for decoder.decoder.6.weight: 0.0007325375336222351\n",
      "Gradient for decoder.decoder.6.bias: 3.725386341102421e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.014618764631450176\n",
      "Gradient for encoder.encoder.0.bias: 2.1858658980078438e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0013191328616812825\n",
      "Gradient for encoder.encoder.1.bias: 0.0012053330428898335\n",
      "Gradient for encoder.encoder.3.weight: 0.028517894446849823\n",
      "Gradient for encoder.encoder.3.bias: 2.1646370806926996e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0041378517635166645\n",
      "Gradient for encoder.encoder.4.bias: 0.0038234139792621136\n",
      "Gradient for encoder.mean.weight: 0.058964941650629044\n",
      "Gradient for encoder.mean.bias: 0.0029229773208498955\n",
      "Gradient for encoder.log_var.weight: 0.03604630008339882\n",
      "Gradient for encoder.log_var.bias: 0.0016344451578333974\n",
      "Gradient for decoder.decoder.0.weight: 0.013596615754067898\n",
      "Gradient for decoder.decoder.0.bias: 1.0479307699373663e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0007011131965555251\n",
      "Gradient for decoder.decoder.1.bias: 0.0005389282596297562\n",
      "Gradient for decoder.decoder.3.weight: 0.012248508632183075\n",
      "Gradient for decoder.decoder.3.bias: 9.247870524919932e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.000498693436384201\n",
      "Gradient for decoder.decoder.4.bias: 0.0005371696897782385\n",
      "Gradient for decoder.decoder.6.weight: 0.0006718928343616426\n",
      "Gradient for decoder.decoder.6.bias: 4.102026650798507e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.014326666481792927\n",
      "Gradient for encoder.encoder.0.bias: 2.1602294605904682e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0013666539452970028\n",
      "Gradient for encoder.encoder.1.bias: 0.0010624307906255126\n",
      "Gradient for encoder.encoder.3.weight: 0.02994946576654911\n",
      "Gradient for encoder.encoder.3.bias: 2.3624863176863187e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.004753338638693094\n",
      "Gradient for encoder.encoder.4.bias: 0.0038439363706856966\n",
      "Gradient for encoder.mean.weight: 0.06116711348295212\n",
      "Gradient for encoder.mean.bias: 0.0032264890614897013\n",
      "Gradient for encoder.log_var.weight: 0.040555596351623535\n",
      "Gradient for encoder.log_var.bias: 0.001737452344968915\n",
      "Gradient for decoder.decoder.0.weight: 0.014527698047459126\n",
      "Gradient for decoder.decoder.0.bias: 1.224132739618966e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0007509136921726167\n",
      "Gradient for decoder.decoder.1.bias: 0.0005581072764471173\n",
      "Gradient for decoder.decoder.3.weight: 0.013306335546076298\n",
      "Gradient for decoder.decoder.3.bias: 1.2517617498097877e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0005783011438325047\n",
      "Gradient for decoder.decoder.4.bias: 0.0006257179193198681\n",
      "Gradient for decoder.decoder.6.weight: 0.0006891100783832371\n",
      "Gradient for decoder.decoder.6.bias: 4.1344144847244024e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.014885930344462395\n",
      "Gradient for encoder.encoder.0.bias: 2.2609750877089496e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0015193179715424776\n",
      "Gradient for encoder.encoder.1.bias: 0.001305149169638753\n",
      "Gradient for encoder.encoder.3.weight: 0.030915088951587677\n",
      "Gradient for encoder.encoder.3.bias: 2.56215437755003e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.005106019787490368\n",
      "Gradient for encoder.encoder.4.bias: 0.005149709060788155\n",
      "Gradient for encoder.mean.weight: 0.0709802657365799\n",
      "Gradient for encoder.mean.bias: 0.003965387120842934\n",
      "Gradient for encoder.log_var.weight: 0.037198107689619064\n",
      "Gradient for encoder.log_var.bias: 0.001958678476512432\n",
      "Gradient for decoder.decoder.0.weight: 0.013330303132534027\n",
      "Gradient for decoder.decoder.0.bias: 1.1758022333552276e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0006723145488649607\n",
      "Gradient for decoder.decoder.1.bias: 0.0005351888830773532\n",
      "Gradient for decoder.decoder.3.weight: 0.012490712106227875\n",
      "Gradient for decoder.decoder.3.bias: 9.98708962751671e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0005398369976319373\n",
      "Gradient for decoder.decoder.4.bias: 0.0006005203467793763\n",
      "Gradient for decoder.decoder.6.weight: 0.0007290391367860138\n",
      "Gradient for decoder.decoder.6.bias: 5.1610852096928284e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.013186939992010593\n",
      "Gradient for encoder.encoder.0.bias: 1.9088241404174866e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0013246290618553758\n",
      "Gradient for encoder.encoder.1.bias: 0.0010969664435833693\n",
      "Gradient for encoder.encoder.3.weight: 0.02645900845527649\n",
      "Gradient for encoder.encoder.3.bias: 2.3457980002916656e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.00481369299814105\n",
      "Gradient for encoder.encoder.4.bias: 0.004959405399858952\n",
      "Gradient for encoder.mean.weight: 0.06421888619661331\n",
      "Gradient for encoder.mean.bias: 0.0040290625765919685\n",
      "Gradient for encoder.log_var.weight: 0.039142727851867676\n",
      "Gradient for encoder.log_var.bias: 0.0022410477977246046\n",
      "Gradient for decoder.decoder.0.weight: 0.01444302685558796\n",
      "Gradient for decoder.decoder.0.bias: 1.1736865646039263e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0006844212184660137\n",
      "Gradient for decoder.decoder.1.bias: 0.0005686806980520487\n",
      "Gradient for decoder.decoder.3.weight: 0.013043791987001896\n",
      "Gradient for decoder.decoder.3.bias: 9.868095923737386e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00047044799430295825\n",
      "Gradient for decoder.decoder.4.bias: 0.0004088222049176693\n",
      "Gradient for decoder.decoder.6.weight: 0.0006419549463316798\n",
      "Gradient for decoder.decoder.6.bias: 3.162492794217542e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.02237355150282383\n",
      "Gradient for encoder.encoder.0.bias: 2.937929066693101e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.001850773231126368\n",
      "Gradient for encoder.encoder.1.bias: 0.001841820077970624\n",
      "Gradient for encoder.encoder.3.weight: 0.03789927065372467\n",
      "Gradient for encoder.encoder.3.bias: 2.638299856361215e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.00522865355014801\n",
      "Gradient for encoder.encoder.4.bias: 0.005390222184360027\n",
      "Gradient for encoder.mean.weight: 0.07090779393911362\n",
      "Gradient for encoder.mean.bias: 0.0037559824995696545\n",
      "Gradient for encoder.log_var.weight: 0.041838858276605606\n",
      "Gradient for encoder.log_var.bias: 0.002077082172036171\n",
      "Gradient for decoder.decoder.0.weight: 0.014104383066296577\n",
      "Gradient for decoder.decoder.0.bias: 1.328721438431657e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0006568602984771132\n",
      "Gradient for decoder.decoder.1.bias: 0.0005448305164463818\n",
      "Gradient for decoder.decoder.3.weight: 0.01240159198641777\n",
      "Gradient for decoder.decoder.3.bias: 1.1461179921790077e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.000468842830741778\n",
      "Gradient for decoder.decoder.4.bias: 0.0004463892837520689\n",
      "Gradient for decoder.decoder.6.weight: 0.000651865266263485\n",
      "Gradient for decoder.decoder.6.bias: 3.2587213354418054e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.013894788920879364\n",
      "Gradient for encoder.encoder.0.bias: 1.6374752248582425e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0012041560839861631\n",
      "Gradient for encoder.encoder.1.bias: 0.0011074371868744493\n",
      "Gradient for encoder.encoder.3.weight: 0.02610640600323677\n",
      "Gradient for encoder.encoder.3.bias: 2.1008085548945843e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.005180812440812588\n",
      "Gradient for encoder.encoder.4.bias: 0.004323183558881283\n",
      "Gradient for encoder.mean.weight: 0.0692853108048439\n",
      "Gradient for encoder.mean.bias: 0.0034042480401694775\n",
      "Gradient for encoder.log_var.weight: 0.04431195557117462\n",
      "Gradient for encoder.log_var.bias: 0.00167989288456738\n",
      "Gradient for decoder.decoder.0.weight: 0.018670612946152687\n",
      "Gradient for decoder.decoder.0.bias: 1.6636952926418758e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0009272888419218361\n",
      "Gradient for decoder.decoder.1.bias: 0.0007483330555260181\n",
      "Gradient for decoder.decoder.3.weight: 0.01757947914302349\n",
      "Gradient for decoder.decoder.3.bias: 1.6287923787494663e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0010349362855777144\n",
      "Gradient for decoder.decoder.4.bias: 0.001216656994074583\n",
      "Gradient for decoder.decoder.6.weight: 0.0009141305927187204\n",
      "Gradient for decoder.decoder.6.bias: 6.793371721869335e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.017000047490000725\n",
      "Gradient for encoder.encoder.0.bias: 2.250152321414678e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0015836956445127726\n",
      "Gradient for encoder.encoder.1.bias: 0.0012920093722641468\n",
      "Gradient for encoder.encoder.3.weight: 0.029856963083148003\n",
      "Gradient for encoder.encoder.3.bias: 2.0550317003653618e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.00465853326022625\n",
      "Gradient for encoder.encoder.4.bias: 0.004272383637726307\n",
      "Gradient for encoder.mean.weight: 0.06685412675142288\n",
      "Gradient for encoder.mean.bias: 0.003319030161947012\n",
      "Gradient for encoder.log_var.weight: 0.037573520094156265\n",
      "Gradient for encoder.log_var.bias: 0.0018861768767237663\n",
      "Gradient for decoder.decoder.0.weight: 0.014249465428292751\n",
      "Gradient for decoder.decoder.0.bias: 1.0964669450164166e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0006902912282384932\n",
      "Gradient for decoder.decoder.1.bias: 0.000559166306629777\n",
      "Gradient for decoder.decoder.3.weight: 0.013325750827789307\n",
      "Gradient for decoder.decoder.3.bias: 1.134166788263613e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0007118824869394302\n",
      "Gradient for decoder.decoder.4.bias: 0.0007974624168127775\n",
      "Gradient for decoder.decoder.6.weight: 0.0007396341534331441\n",
      "Gradient for decoder.decoder.6.bias: 5.4550742788705975e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.01312764547765255\n",
      "Gradient for encoder.encoder.0.bias: 2.0507045714324157e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0015554811106994748\n",
      "Gradient for encoder.encoder.1.bias: 0.0011871092719957232\n",
      "Gradient for encoder.encoder.3.weight: 0.031658608466386795\n",
      "Gradient for encoder.encoder.3.bias: 2.5453850138745793e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.004576688166707754\n",
      "Gradient for encoder.encoder.4.bias: 0.005101990420371294\n",
      "Gradient for encoder.mean.weight: 0.0624672956764698\n",
      "Gradient for encoder.mean.bias: 0.00397425377741456\n",
      "Gradient for encoder.log_var.weight: 0.0368938148021698\n",
      "Gradient for encoder.log_var.bias: 0.002575685502961278\n",
      "Gradient for decoder.decoder.0.weight: 0.01395106315612793\n",
      "Gradient for decoder.decoder.0.bias: 1.1767092855663464e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0007532553863711655\n",
      "Gradient for decoder.decoder.1.bias: 0.0005766022368334234\n",
      "Gradient for decoder.decoder.3.weight: 0.013067002408206463\n",
      "Gradient for decoder.decoder.3.bias: 9.589948279931093e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00048410039744339883\n",
      "Gradient for decoder.decoder.4.bias: 0.0005007726140320301\n",
      "Gradient for decoder.decoder.6.weight: 0.0006933158147148788\n",
      "Gradient for decoder.decoder.6.bias: 4.1484043322270736e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.0115778474137187\n",
      "Gradient for encoder.encoder.0.bias: 1.7519747805283536e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.001271065673790872\n",
      "Gradient for encoder.encoder.1.bias: 0.001144773792475462\n",
      "Gradient for encoder.encoder.3.weight: 0.02786446176469326\n",
      "Gradient for encoder.encoder.3.bias: 2.483312999679299e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.004718390293419361\n",
      "Gradient for encoder.encoder.4.bias: 0.0049068438820540905\n",
      "Gradient for encoder.mean.weight: 0.06299670040607452\n",
      "Gradient for encoder.mean.bias: 0.003917237743735313\n",
      "Gradient for encoder.log_var.weight: 0.03871675953269005\n",
      "Gradient for encoder.log_var.bias: 0.0022638654336333275\n",
      "Gradient for decoder.decoder.0.weight: 0.015311856754124165\n",
      "Gradient for decoder.decoder.0.bias: 1.3601811343910697e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.000801810179837048\n",
      "Gradient for decoder.decoder.1.bias: 0.0006200431380420923\n",
      "Gradient for decoder.decoder.3.weight: 0.013983993791043758\n",
      "Gradient for decoder.decoder.3.bias: 1.0725507981756977e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0005058951792307198\n",
      "Gradient for decoder.decoder.4.bias: 0.0004467106773518026\n",
      "Gradient for decoder.decoder.6.weight: 0.0006497236900031567\n",
      "Gradient for decoder.decoder.6.bias: 2.7100553779746406e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.016066187992691994\n",
      "Gradient for encoder.encoder.0.bias: 2.7217849501992575e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0018926585325971246\n",
      "Gradient for encoder.encoder.1.bias: 0.0013630555476993322\n",
      "Gradient for encoder.encoder.3.weight: 0.03389344736933708\n",
      "Gradient for encoder.encoder.3.bias: 2.305995117080073e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.004696621559560299\n",
      "Gradient for encoder.encoder.4.bias: 0.003992168232798576\n",
      "Gradient for encoder.mean.weight: 0.06000469997525215\n",
      "Gradient for encoder.mean.bias: 0.0030451228376477957\n",
      "Gradient for encoder.log_var.weight: 0.03796440735459328\n",
      "Gradient for encoder.log_var.bias: 0.001977912150323391\n",
      "Gradient for decoder.decoder.0.weight: 0.013914131559431553\n",
      "Gradient for decoder.decoder.0.bias: 1.1830922352906725e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0007328349747695029\n",
      "Gradient for decoder.decoder.1.bias: 0.000554226222448051\n",
      "Gradient for decoder.decoder.3.weight: 0.013096818700432777\n",
      "Gradient for decoder.decoder.3.bias: 1.0602966421524584e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0005205960478633642\n",
      "Gradient for decoder.decoder.4.bias: 0.0004990231827832758\n",
      "Gradient for decoder.decoder.6.weight: 0.0007773772813379765\n",
      "Gradient for decoder.decoder.6.bias: 5.1637645810842514e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.018408583477139473\n",
      "Gradient for encoder.encoder.0.bias: 2.5064355105297587e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0021176165901124477\n",
      "Gradient for encoder.encoder.1.bias: 0.0016176658682525158\n",
      "Gradient for encoder.encoder.3.weight: 0.046326134353876114\n",
      "Gradient for encoder.encoder.3.bias: 3.093997558156758e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.007296392694115639\n",
      "Gradient for encoder.encoder.4.bias: 0.006621628068387508\n",
      "Gradient for encoder.mean.weight: 0.10311900824308395\n",
      "Gradient for encoder.mean.bias: 0.0038841646164655685\n",
      "Gradient for encoder.log_var.weight: 0.05743527412414551\n",
      "Gradient for encoder.log_var.bias: 0.0022947913967072964\n",
      "Gradient for decoder.decoder.0.weight: 0.013995634391903877\n",
      "Gradient for decoder.decoder.0.bias: 1.0796209759522668e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0007187659502960742\n",
      "Gradient for decoder.decoder.1.bias: 0.0005907960585318506\n",
      "Gradient for decoder.decoder.3.weight: 0.012452813796699047\n",
      "Gradient for decoder.decoder.3.bias: 8.897990677603218e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0004612964403349906\n",
      "Gradient for decoder.decoder.4.bias: 0.00043322794954292476\n",
      "Gradient for decoder.decoder.6.weight: 0.0006670157890766859\n",
      "Gradient for decoder.decoder.6.bias: 3.130156983388588e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.013898990117013454\n",
      "Gradient for encoder.encoder.0.bias: 1.7416061648400927e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0011559197446331382\n",
      "Gradient for encoder.encoder.1.bias: 0.0009544010390527546\n",
      "Gradient for encoder.encoder.3.weight: 0.023821882903575897\n",
      "Gradient for encoder.encoder.3.bias: 2.0320735372170162e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0047171288169920444\n",
      "Gradient for encoder.encoder.4.bias: 0.003724269801750779\n",
      "Gradient for encoder.mean.weight: 0.060757678002119064\n",
      "Gradient for encoder.mean.bias: 0.002675152150914073\n",
      "Gradient for encoder.log_var.weight: 0.04128275066614151\n",
      "Gradient for encoder.log_var.bias: 0.001571113127283752\n",
      "Gradient for decoder.decoder.0.weight: 0.01735270768404007\n",
      "Gradient for decoder.decoder.0.bias: 1.4678454285377285e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0008992519578896463\n",
      "Gradient for decoder.decoder.1.bias: 0.00069914769846946\n",
      "Gradient for decoder.decoder.3.weight: 0.016374453902244568\n",
      "Gradient for decoder.decoder.3.bias: 1.3482016891774862e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0006406098254956305\n",
      "Gradient for decoder.decoder.4.bias: 0.0006067826179787517\n",
      "Gradient for decoder.decoder.6.weight: 0.0007217024685814977\n",
      "Gradient for decoder.decoder.6.bias: 3.618759001255967e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.018161259591579437\n",
      "Gradient for encoder.encoder.0.bias: 2.9007832594296623e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0021792284678667784\n",
      "Gradient for encoder.encoder.1.bias: 0.001696988707408309\n",
      "Gradient for encoder.encoder.3.weight: 0.04604698717594147\n",
      "Gradient for encoder.encoder.3.bias: 2.867709403275853e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.007406607735902071\n",
      "Gradient for encoder.encoder.4.bias: 0.0056709530763328075\n",
      "Gradient for encoder.mean.weight: 0.10082567483186722\n",
      "Gradient for encoder.mean.bias: 0.0037791270297020674\n",
      "Gradient for encoder.log_var.weight: 0.05902641639113426\n",
      "Gradient for encoder.log_var.bias: 0.0022712689824402332\n",
      "Gradient for decoder.decoder.0.weight: 0.013017451390624046\n",
      "Gradient for decoder.decoder.0.bias: 1.0590982951752537e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0007314506219699979\n",
      "Gradient for decoder.decoder.1.bias: 0.0005907280137762427\n",
      "Gradient for decoder.decoder.3.weight: 0.012837284244596958\n",
      "Gradient for decoder.decoder.3.bias: 9.300488157393261e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00046442245366051793\n",
      "Gradient for decoder.decoder.4.bias: 0.00042077485704794526\n",
      "Gradient for decoder.decoder.6.weight: 0.0006560651236213744\n",
      "Gradient for decoder.decoder.6.bias: 3.536845906637609e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.016962487250566483\n",
      "Gradient for encoder.encoder.0.bias: 2.5361530583967173e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0018482992891222239\n",
      "Gradient for encoder.encoder.1.bias: 0.0015792681369930506\n",
      "Gradient for encoder.encoder.3.weight: 0.03943302482366562\n",
      "Gradient for encoder.encoder.3.bias: 3.0406144269079505e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0071072448045015335\n",
      "Gradient for encoder.encoder.4.bias: 0.006593049503862858\n",
      "Gradient for encoder.mean.weight: 0.09207142889499664\n",
      "Gradient for encoder.mean.bias: 0.004374622832983732\n",
      "Gradient for encoder.log_var.weight: 0.058676134794950485\n",
      "Gradient for encoder.log_var.bias: 0.0027124586049467325\n",
      "Gradient for decoder.decoder.0.weight: 0.012527474202215672\n",
      "Gradient for decoder.decoder.0.bias: 9.984708199128889e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.000652892398647964\n",
      "Gradient for decoder.decoder.1.bias: 0.0004798478039447218\n",
      "Gradient for decoder.decoder.3.weight: 0.011440125294029713\n",
      "Gradient for decoder.decoder.3.bias: 8.372601223438636e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00041390841943211854\n",
      "Gradient for decoder.decoder.4.bias: 0.0003901499731000513\n",
      "Gradient for decoder.decoder.6.weight: 0.0006903056637383997\n",
      "Gradient for decoder.decoder.6.bias: 3.889339495799504e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.017122022807598114\n",
      "Gradient for encoder.encoder.0.bias: 2.5684751200905076e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0015250971773639321\n",
      "Gradient for encoder.encoder.1.bias: 0.0012236707843840122\n",
      "Gradient for encoder.encoder.3.weight: 0.03138982504606247\n",
      "Gradient for encoder.encoder.3.bias: 2.2400922783383237e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.004581103101372719\n",
      "Gradient for encoder.encoder.4.bias: 0.003653855063021183\n",
      "Gradient for encoder.mean.weight: 0.0612485371530056\n",
      "Gradient for encoder.mean.bias: 0.002691525500267744\n",
      "Gradient for encoder.log_var.weight: 0.033220335841178894\n",
      "Gradient for encoder.log_var.bias: 0.0014841711381450295\n",
      "Gradient for decoder.decoder.0.weight: 0.011519676074385643\n",
      "Gradient for decoder.decoder.0.bias: 9.207728329796439e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0006131513509899378\n",
      "Gradient for decoder.decoder.1.bias: 0.0004425644292496145\n",
      "Gradient for decoder.decoder.3.weight: 0.010471663437783718\n",
      "Gradient for decoder.decoder.3.bias: 8.917201699265576e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0005737487226724625\n",
      "Gradient for decoder.decoder.4.bias: 0.0006721031968481839\n",
      "Gradient for decoder.decoder.6.weight: 0.0007167829317040741\n",
      "Gradient for decoder.decoder.6.bias: 4.982567043043673e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training VAE Epoch:  53%|█████▎    | 42/79 [00:00<00:00, 71.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient for encoder.encoder.0.weight: 0.015619597397744656\n",
      "Gradient for encoder.encoder.0.bias: 2.1623187615449346e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0015494199469685555\n",
      "Gradient for encoder.encoder.1.bias: 0.001270973589271307\n",
      "Gradient for encoder.encoder.3.weight: 0.032263144850730896\n",
      "Gradient for encoder.encoder.3.bias: 2.470101900797772e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.005034630186855793\n",
      "Gradient for encoder.encoder.4.bias: 0.004966264590620995\n",
      "Gradient for encoder.mean.weight: 0.061755865812301636\n",
      "Gradient for encoder.mean.bias: 0.003472019685432315\n",
      "Gradient for encoder.log_var.weight: 0.04254523664712906\n",
      "Gradient for encoder.log_var.bias: 0.002208369318395853\n",
      "Gradient for decoder.decoder.0.weight: 0.012400408275425434\n",
      "Gradient for decoder.decoder.0.bias: 1.1535853522426365e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0006358639802783728\n",
      "Gradient for decoder.decoder.1.bias: 0.0005026971339248121\n",
      "Gradient for decoder.decoder.3.weight: 0.01169711071997881\n",
      "Gradient for decoder.decoder.3.bias: 8.930801237427843e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0004464141675271094\n",
      "Gradient for decoder.decoder.4.bias: 0.00037966755917295814\n",
      "Gradient for decoder.decoder.6.weight: 0.0007130942540243268\n",
      "Gradient for decoder.decoder.6.bias: 3.927153011318296e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.01658604107797146\n",
      "Gradient for encoder.encoder.0.bias: 2.3249688632653864e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0019478710601106286\n",
      "Gradient for encoder.encoder.1.bias: 0.00140264886431396\n",
      "Gradient for encoder.encoder.3.weight: 0.03790050745010376\n",
      "Gradient for encoder.encoder.3.bias: 2.401407406260603e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.006078335456550121\n",
      "Gradient for encoder.encoder.4.bias: 0.004665052983909845\n",
      "Gradient for encoder.mean.weight: 0.08271513134241104\n",
      "Gradient for encoder.mean.bias: 0.0032496468629688025\n",
      "Gradient for encoder.log_var.weight: 0.04447579383850098\n",
      "Gradient for encoder.log_var.bias: 0.0018391595222055912\n",
      "Gradient for decoder.decoder.0.weight: 0.014397951774299145\n",
      "Gradient for decoder.decoder.0.bias: 1.1494865476135985e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0007493012817576528\n",
      "Gradient for decoder.decoder.1.bias: 0.0005623617907986045\n",
      "Gradient for decoder.decoder.3.weight: 0.013209116645157337\n",
      "Gradient for decoder.decoder.3.bias: 1.0578626169488459e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0004901307402178645\n",
      "Gradient for decoder.decoder.4.bias: 0.0004203319549560547\n",
      "Gradient for decoder.decoder.6.weight: 0.0007124155526980758\n",
      "Gradient for decoder.decoder.6.bias: 4.1371062252437696e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.01917356438934803\n",
      "Gradient for encoder.encoder.0.bias: 2.737733650892693e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0016682085115462542\n",
      "Gradient for encoder.encoder.1.bias: 0.0013081409269943833\n",
      "Gradient for encoder.encoder.3.weight: 0.03763546049594879\n",
      "Gradient for encoder.encoder.3.bias: 3.3731947790549555e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.006064325105398893\n",
      "Gradient for encoder.encoder.4.bias: 0.0064261662773787975\n",
      "Gradient for encoder.mean.weight: 0.08194217830896378\n",
      "Gradient for encoder.mean.bias: 0.004744164180010557\n",
      "Gradient for encoder.log_var.weight: 0.04528643935918808\n",
      "Gradient for encoder.log_var.bias: 0.0027230826672166586\n",
      "Gradient for decoder.decoder.0.weight: 0.01181271392852068\n",
      "Gradient for decoder.decoder.0.bias: 1.0039506725956215e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0005905693396925926\n",
      "Gradient for decoder.decoder.1.bias: 0.0004861072520725429\n",
      "Gradient for decoder.decoder.3.weight: 0.010644659399986267\n",
      "Gradient for decoder.decoder.3.bias: 8.965279213457578e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0003809384361375123\n",
      "Gradient for decoder.decoder.4.bias: 0.0003564188373275101\n",
      "Gradient for decoder.decoder.6.weight: 0.0006730699678882957\n",
      "Gradient for decoder.decoder.6.bias: 3.3470074413344264e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.013957700692117214\n",
      "Gradient for encoder.encoder.0.bias: 2.1425958229848163e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0014684762572869658\n",
      "Gradient for encoder.encoder.1.bias: 0.001442823326215148\n",
      "Gradient for encoder.encoder.3.weight: 0.03266528248786926\n",
      "Gradient for encoder.encoder.3.bias: 3.671511983327491e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.010644528083503246\n",
      "Gradient for encoder.encoder.4.bias: 0.007613456808030605\n",
      "Gradient for encoder.mean.weight: 0.14157532155513763\n",
      "Gradient for encoder.mean.bias: 0.003746535163372755\n",
      "Gradient for encoder.log_var.weight: 0.08234348148107529\n",
      "Gradient for encoder.log_var.bias: 0.0021760198287665844\n",
      "Gradient for decoder.decoder.0.weight: 0.01624687947332859\n",
      "Gradient for decoder.decoder.0.bias: 1.235800489718386e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0009036287083290517\n",
      "Gradient for decoder.decoder.1.bias: 0.000656076823361218\n",
      "Gradient for decoder.decoder.3.weight: 0.015314103104174137\n",
      "Gradient for decoder.decoder.3.bias: 1.046326636444661e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0006041339365765452\n",
      "Gradient for decoder.decoder.4.bias: 0.0005070382612757385\n",
      "Gradient for decoder.decoder.6.weight: 0.0007325185579247773\n",
      "Gradient for decoder.decoder.6.bias: 4.067561530973762e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.017390182241797447\n",
      "Gradient for encoder.encoder.0.bias: 2.3808063159824755e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0027185925282537937\n",
      "Gradient for encoder.encoder.1.bias: 0.0020610413048416376\n",
      "Gradient for encoder.encoder.3.weight: 0.05097750574350357\n",
      "Gradient for encoder.encoder.3.bias: 2.898087880787159e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.00875135138630867\n",
      "Gradient for encoder.encoder.4.bias: 0.006150876637548208\n",
      "Gradient for encoder.mean.weight: 0.11392433941364288\n",
      "Gradient for encoder.mean.bias: 0.00321932602673769\n",
      "Gradient for encoder.log_var.weight: 0.06491239368915558\n",
      "Gradient for encoder.log_var.bias: 0.0019015941070392728\n",
      "Gradient for decoder.decoder.0.weight: 0.014954565092921257\n",
      "Gradient for decoder.decoder.0.bias: 1.1634802149496082e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0006975451251491904\n",
      "Gradient for decoder.decoder.1.bias: 0.0005624641198664904\n",
      "Gradient for decoder.decoder.3.weight: 0.01342987734824419\n",
      "Gradient for decoder.decoder.3.bias: 1.0152075707869912e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0004720849683508277\n",
      "Gradient for decoder.decoder.4.bias: 0.00043186568655073643\n",
      "Gradient for decoder.decoder.6.weight: 0.0007462213397957385\n",
      "Gradient for decoder.decoder.6.bias: 4.874559454037808e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.014270072802901268\n",
      "Gradient for encoder.encoder.0.bias: 2.344904652396007e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.001352578168734908\n",
      "Gradient for encoder.encoder.1.bias: 0.0011927415616810322\n",
      "Gradient for encoder.encoder.3.weight: 0.029439793899655342\n",
      "Gradient for encoder.encoder.3.bias: 2.65412580802149e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.006111447233706713\n",
      "Gradient for encoder.encoder.4.bias: 0.005896431393921375\n",
      "Gradient for encoder.mean.weight: 0.08372285217046738\n",
      "Gradient for encoder.mean.bias: 0.004022101406008005\n",
      "Gradient for encoder.log_var.weight: 0.05427299812436104\n",
      "Gradient for encoder.log_var.bias: 0.002426324412226677\n",
      "Gradient for decoder.decoder.0.weight: 0.01457416545599699\n",
      "Gradient for decoder.decoder.0.bias: 1.0727086580120115e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0007410437101498246\n",
      "Gradient for decoder.decoder.1.bias: 0.0005683627096004784\n",
      "Gradient for decoder.decoder.3.weight: 0.013674810528755188\n",
      "Gradient for decoder.decoder.3.bias: 9.749373530709704e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0005256653530523181\n",
      "Gradient for decoder.decoder.4.bias: 0.0004787484067492187\n",
      "Gradient for decoder.decoder.6.weight: 0.000643530220258981\n",
      "Gradient for decoder.decoder.6.bias: 2.924735235865228e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.014667659066617489\n",
      "Gradient for encoder.encoder.0.bias: 2.3121109193890987e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0013367843348532915\n",
      "Gradient for encoder.encoder.1.bias: 0.0011810208670794964\n",
      "Gradient for encoder.encoder.3.weight: 0.028061263263225555\n",
      "Gradient for encoder.encoder.3.bias: 2.0655005483760647e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.004123994614928961\n",
      "Gradient for encoder.encoder.4.bias: 0.0034862190950661898\n",
      "Gradient for encoder.mean.weight: 0.055573321878910065\n",
      "Gradient for encoder.mean.bias: 0.0026965318247675896\n",
      "Gradient for encoder.log_var.weight: 0.031023647636175156\n",
      "Gradient for encoder.log_var.bias: 0.001662106136791408\n",
      "Gradient for decoder.decoder.0.weight: 0.012890223413705826\n",
      "Gradient for decoder.decoder.0.bias: 1.0263371402752242e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0006567282835021615\n",
      "Gradient for decoder.decoder.1.bias: 0.000482077244669199\n",
      "Gradient for decoder.decoder.3.weight: 0.011854003183543682\n",
      "Gradient for decoder.decoder.3.bias: 9.354982760667596e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0004219669499434531\n",
      "Gradient for decoder.decoder.4.bias: 0.00040087351226247847\n",
      "Gradient for decoder.decoder.6.weight: 0.0006602364592254162\n",
      "Gradient for decoder.decoder.6.bias: 3.9241753256646916e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.016061216592788696\n",
      "Gradient for encoder.encoder.0.bias: 2.3769458623590367e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0013649601023644209\n",
      "Gradient for encoder.encoder.1.bias: 0.0011859503574669361\n",
      "Gradient for encoder.encoder.3.weight: 0.026049787178635597\n",
      "Gradient for encoder.encoder.3.bias: 2.1141181860695468e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.003771180985495448\n",
      "Gradient for encoder.encoder.4.bias: 0.0034771705977618694\n",
      "Gradient for encoder.mean.weight: 0.05300087109208107\n",
      "Gradient for encoder.mean.bias: 0.0027663076762109995\n",
      "Gradient for encoder.log_var.weight: 0.02979457937180996\n",
      "Gradient for encoder.log_var.bias: 0.001560549484565854\n",
      "Gradient for decoder.decoder.0.weight: 0.013061354868113995\n",
      "Gradient for decoder.decoder.0.bias: 1.1034102798124223e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0007046341779641807\n",
      "Gradient for decoder.decoder.1.bias: 0.0004974679904989898\n",
      "Gradient for decoder.decoder.3.weight: 0.012458101846277714\n",
      "Gradient for decoder.decoder.3.bias: 9.213018542508777e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0004427503445185721\n",
      "Gradient for decoder.decoder.4.bias: 0.0003948599041905254\n",
      "Gradient for decoder.decoder.6.weight: 0.000713186920620501\n",
      "Gradient for decoder.decoder.6.bias: 4.430463377502747e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.012782788835465908\n",
      "Gradient for encoder.encoder.0.bias: 2.3294954507036003e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0016473535215482116\n",
      "Gradient for encoder.encoder.1.bias: 0.0012197104515507817\n",
      "Gradient for encoder.encoder.3.weight: 0.03501433506608009\n",
      "Gradient for encoder.encoder.3.bias: 3.035630080638896e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.008626425638794899\n",
      "Gradient for encoder.encoder.4.bias: 0.007016767747700214\n",
      "Gradient for encoder.mean.weight: 0.11529673635959625\n",
      "Gradient for encoder.mean.bias: 0.003713829442858696\n",
      "Gradient for encoder.log_var.weight: 0.05859262868762016\n",
      "Gradient for encoder.log_var.bias: 0.002027749316766858\n",
      "Gradient for decoder.decoder.0.weight: 0.014343468472361565\n",
      "Gradient for decoder.decoder.0.bias: 1.265639398839724e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0007190429023467004\n",
      "Gradient for decoder.decoder.1.bias: 0.0005892263143323362\n",
      "Gradient for decoder.decoder.3.weight: 0.012892506085336208\n",
      "Gradient for decoder.decoder.3.bias: 1.1683332079570619e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0007291738293133676\n",
      "Gradient for decoder.decoder.4.bias: 0.0008488752064295113\n",
      "Gradient for decoder.decoder.6.weight: 0.0008045118302106857\n",
      "Gradient for decoder.decoder.6.bias: 5.80543746764306e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.013709202408790588\n",
      "Gradient for encoder.encoder.0.bias: 1.7663537299483778e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0011685186764225364\n",
      "Gradient for encoder.encoder.1.bias: 0.0009771902114152908\n",
      "Gradient for encoder.encoder.3.weight: 0.025739885866642\n",
      "Gradient for encoder.encoder.3.bias: 1.9831508657475183e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0038979100063443184\n",
      "Gradient for encoder.encoder.4.bias: 0.0035372506827116013\n",
      "Gradient for encoder.mean.weight: 0.05828379467129707\n",
      "Gradient for encoder.mean.bias: 0.002622864441946149\n",
      "Gradient for encoder.log_var.weight: 0.03229454904794693\n",
      "Gradient for encoder.log_var.bias: 0.0016907784156501293\n",
      "Gradient for decoder.decoder.0.weight: 0.014684255234897137\n",
      "Gradient for decoder.decoder.0.bias: 1.2785318637131837e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0007143709226511419\n",
      "Gradient for decoder.decoder.1.bias: 0.000588149530813098\n",
      "Gradient for decoder.decoder.3.weight: 0.013350065797567368\n",
      "Gradient for decoder.decoder.3.bias: 1.2645696989554978e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0007038715993985534\n",
      "Gradient for decoder.decoder.4.bias: 0.0008326398092322052\n",
      "Gradient for decoder.decoder.6.weight: 0.0006962229963392019\n",
      "Gradient for decoder.decoder.6.bias: 5.1745861128438264e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.015434077940881252\n",
      "Gradient for encoder.encoder.0.bias: 2.918863761802726e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.001945809694007039\n",
      "Gradient for encoder.encoder.1.bias: 0.001912733307108283\n",
      "Gradient for encoder.encoder.3.weight: 0.0392947681248188\n",
      "Gradient for encoder.encoder.3.bias: 3.1512203957362317e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.006722817663103342\n",
      "Gradient for encoder.encoder.4.bias: 0.007061862852424383\n",
      "Gradient for encoder.mean.weight: 0.08604267239570618\n",
      "Gradient for encoder.mean.bias: 0.005270328372716904\n",
      "Gradient for encoder.log_var.weight: 0.049039240926504135\n",
      "Gradient for encoder.log_var.bias: 0.0027749554719775915\n",
      "Gradient for decoder.decoder.0.weight: 0.011847706511616707\n",
      "Gradient for decoder.decoder.0.bias: 9.82926448567234e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0006463901372626424\n",
      "Gradient for decoder.decoder.1.bias: 0.00045294605661183596\n",
      "Gradient for decoder.decoder.3.weight: 0.011047692969441414\n",
      "Gradient for decoder.decoder.3.bias: 8.525633671263577e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0003801682614721358\n",
      "Gradient for decoder.decoder.4.bias: 0.0003662550589069724\n",
      "Gradient for decoder.decoder.6.weight: 0.0006976255681365728\n",
      "Gradient for decoder.decoder.6.bias: 4.062202060595155e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.010860894806683064\n",
      "Gradient for encoder.encoder.0.bias: 1.671007950065917e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0010014594299718738\n",
      "Gradient for encoder.encoder.1.bias: 0.0008829717990010977\n",
      "Gradient for encoder.encoder.3.weight: 0.02001437172293663\n",
      "Gradient for encoder.encoder.3.bias: 2.0253775045997457e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.004669231362640858\n",
      "Gradient for encoder.encoder.4.bias: 0.004327853675931692\n",
      "Gradient for encoder.mean.weight: 0.058028362691402435\n",
      "Gradient for encoder.mean.bias: 0.003135601757094264\n",
      "Gradient for encoder.log_var.weight: 0.03647032380104065\n",
      "Gradient for encoder.log_var.bias: 0.0019240647088736296\n",
      "Gradient for decoder.decoder.0.weight: 0.014763989485800266\n",
      "Gradient for decoder.decoder.0.bias: 1.2132468640846383e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0007216306403279305\n",
      "Gradient for decoder.decoder.1.bias: 0.0006030063377693295\n",
      "Gradient for decoder.decoder.3.weight: 0.01318010687828064\n",
      "Gradient for decoder.decoder.3.bias: 9.708855941426009e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0005057061789557338\n",
      "Gradient for decoder.decoder.4.bias: 0.0004408795211929828\n",
      "Gradient for decoder.decoder.6.weight: 0.0006788597092963755\n",
      "Gradient for decoder.decoder.6.bias: 3.42619969160296e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.011129644699394703\n",
      "Gradient for encoder.encoder.0.bias: 2.001679551277835e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0013289987109601498\n",
      "Gradient for encoder.encoder.1.bias: 0.001301100943237543\n",
      "Gradient for encoder.encoder.3.weight: 0.02770751155912876\n",
      "Gradient for encoder.encoder.3.bias: 2.46819786831054e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0061133974231779575\n",
      "Gradient for encoder.encoder.4.bias: 0.005427910014986992\n",
      "Gradient for encoder.mean.weight: 0.0789693295955658\n",
      "Gradient for encoder.mean.bias: 0.0040498292073607445\n",
      "Gradient for encoder.log_var.weight: 0.0460326224565506\n",
      "Gradient for encoder.log_var.bias: 0.002284557092934847\n",
      "Gradient for decoder.decoder.0.weight: 0.01449614204466343\n",
      "Gradient for decoder.decoder.0.bias: 1.2185717712664967e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0007978235371410847\n",
      "Gradient for decoder.decoder.1.bias: 0.0006047872011549771\n",
      "Gradient for decoder.decoder.3.weight: 0.013435025699436665\n",
      "Gradient for decoder.decoder.3.bias: 1.0336690531298487e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0005857505602762103\n",
      "Gradient for decoder.decoder.4.bias: 0.000616881821770221\n",
      "Gradient for decoder.decoder.6.weight: 0.0007178065716288984\n",
      "Gradient for decoder.decoder.6.bias: 4.5680579205509275e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.015332315117120743\n",
      "Gradient for encoder.encoder.0.bias: 2.291831481537887e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0014838252682238817\n",
      "Gradient for encoder.encoder.1.bias: 0.001312137464992702\n",
      "Gradient for encoder.encoder.3.weight: 0.03211033716797829\n",
      "Gradient for encoder.encoder.3.bias: 3.003323145733816e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.005526807624846697\n",
      "Gradient for encoder.encoder.4.bias: 0.005578971467912197\n",
      "Gradient for encoder.mean.weight: 0.07401059567928314\n",
      "Gradient for encoder.mean.bias: 0.004139360506087542\n",
      "Gradient for encoder.log_var.weight: 0.04493808373808861\n",
      "Gradient for encoder.log_var.bias: 0.0029831258580088615\n",
      "Gradient for decoder.decoder.0.weight: 0.015429318882524967\n",
      "Gradient for decoder.decoder.0.bias: 1.259457260704977e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0007575805066153407\n",
      "Gradient for decoder.decoder.1.bias: 0.0005935928784310818\n",
      "Gradient for decoder.decoder.3.weight: 0.01412294153124094\n",
      "Gradient for decoder.decoder.3.bias: 1.1181400944026976e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0005467062001116574\n",
      "Gradient for decoder.decoder.4.bias: 0.000520937261171639\n",
      "Gradient for decoder.decoder.6.weight: 0.000735736801289022\n",
      "Gradient for decoder.decoder.6.bias: 3.92805268347729e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.013095070607960224\n",
      "Gradient for encoder.encoder.0.bias: 1.9017055291614682e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.001472675590775907\n",
      "Gradient for encoder.encoder.1.bias: 0.001095178653486073\n",
      "Gradient for encoder.encoder.3.weight: 0.028861278668045998\n",
      "Gradient for encoder.encoder.3.bias: 1.7778978289584302e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0036605449859052896\n",
      "Gradient for encoder.encoder.4.bias: 0.0030509924981743097\n",
      "Gradient for encoder.mean.weight: 0.053124699741601944\n",
      "Gradient for encoder.mean.bias: 0.0023729889653623104\n",
      "Gradient for encoder.log_var.weight: 0.029643716290593147\n",
      "Gradient for encoder.log_var.bias: 0.0016278624534606934\n",
      "Gradient for decoder.decoder.0.weight: 0.016185572370886803\n",
      "Gradient for decoder.decoder.0.bias: 1.3630326034519413e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0008234264678321779\n",
      "Gradient for decoder.decoder.1.bias: 0.0006345674628391862\n",
      "Gradient for decoder.decoder.3.weight: 0.015459645539522171\n",
      "Gradient for decoder.decoder.3.bias: 1.3520022601465342e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0007225634180940688\n",
      "Gradient for decoder.decoder.4.bias: 0.0007810746901668608\n",
      "Gradient for decoder.decoder.6.weight: 0.0007509362185373902\n",
      "Gradient for decoder.decoder.6.bias: 4.888968396699056e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.020140767097473145\n",
      "Gradient for encoder.encoder.0.bias: 4.110506379717549e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.002430874854326248\n",
      "Gradient for encoder.encoder.1.bias: 0.002059614984318614\n",
      "Gradient for encoder.encoder.3.weight: 0.04650995880365372\n",
      "Gradient for encoder.encoder.3.bias: 2.784033559244392e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.006244721356779337\n",
      "Gradient for encoder.encoder.4.bias: 0.005674963351339102\n",
      "Gradient for encoder.mean.weight: 0.07880417257547379\n",
      "Gradient for encoder.mean.bias: 0.0035665540490299463\n",
      "Gradient for encoder.log_var.weight: 0.05347834900021553\n",
      "Gradient for encoder.log_var.bias: 0.002443893114104867\n",
      "Gradient for decoder.decoder.0.weight: 0.011356182396411896\n",
      "Gradient for decoder.decoder.0.bias: 9.932744904350699e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005734767182730138\n",
      "Gradient for decoder.decoder.1.bias: 0.00044767826329916716\n",
      "Gradient for decoder.decoder.3.weight: 0.0108021330088377\n",
      "Gradient for decoder.decoder.3.bias: 1.0456074894804601e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0006545564392581582\n",
      "Gradient for decoder.decoder.4.bias: 0.0007633913191966712\n",
      "Gradient for decoder.decoder.6.weight: 0.0007407713565044105\n",
      "Gradient for decoder.decoder.6.bias: 5.482191045302898e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.011765637435019016\n",
      "Gradient for encoder.encoder.0.bias: 1.9041468055092103e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0014335840241983533\n",
      "Gradient for encoder.encoder.1.bias: 0.0012223259545862675\n",
      "Gradient for encoder.encoder.3.weight: 0.030430501326918602\n",
      "Gradient for encoder.encoder.3.bias: 2.9715208071934285e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.006017090752720833\n",
      "Gradient for encoder.encoder.4.bias: 0.006145074963569641\n",
      "Gradient for encoder.mean.weight: 0.08113720268011093\n",
      "Gradient for encoder.mean.bias: 0.004983142018318176\n",
      "Gradient for encoder.log_var.weight: 0.043283816426992416\n",
      "Gradient for encoder.log_var.bias: 0.002870517550036311\n",
      "Gradient for decoder.decoder.0.weight: 0.015680953860282898\n",
      "Gradient for decoder.decoder.0.bias: 1.500016777455926e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0008300003246404231\n",
      "Gradient for decoder.decoder.1.bias: 0.0006633707671426237\n",
      "Gradient for decoder.decoder.3.weight: 0.014124400913715363\n",
      "Gradient for decoder.decoder.3.bias: 1.3822300248822472e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0005891493055969477\n",
      "Gradient for decoder.decoder.4.bias: 0.0005675771390087903\n",
      "Gradient for decoder.decoder.6.weight: 0.000675816903822124\n",
      "Gradient for decoder.decoder.6.bias: 3.349627149873413e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training VAE Epoch:  75%|███████▍  | 59/79 [00:00<00:00, 75.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient for encoder.encoder.0.weight: 0.020264774560928345\n",
      "Gradient for encoder.encoder.0.bias: 2.774187476961565e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.002078625839203596\n",
      "Gradient for encoder.encoder.1.bias: 0.0015878850826993585\n",
      "Gradient for encoder.encoder.3.weight: 0.042312879115343094\n",
      "Gradient for encoder.encoder.3.bias: 2.8466495827217386e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.007161429151892662\n",
      "Gradient for encoder.encoder.4.bias: 0.007246675901114941\n",
      "Gradient for encoder.mean.weight: 0.09331902861595154\n",
      "Gradient for encoder.mean.bias: 0.00536732142791152\n",
      "Gradient for encoder.log_var.weight: 0.05540227144956589\n",
      "Gradient for encoder.log_var.bias: 0.0032082023099064827\n",
      "Gradient for decoder.decoder.0.weight: 0.013038967736065388\n",
      "Gradient for decoder.decoder.0.bias: 1.0057848304212413e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0006550896214321256\n",
      "Gradient for decoder.decoder.1.bias: 0.0005375625332817435\n",
      "Gradient for decoder.decoder.3.weight: 0.012112978845834732\n",
      "Gradient for decoder.decoder.3.bias: 9.456168487131933e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0005805690889246762\n",
      "Gradient for decoder.decoder.4.bias: 0.0005897104856558144\n",
      "Gradient for decoder.decoder.6.weight: 0.0007046814425848424\n",
      "Gradient for decoder.decoder.6.bias: 4.375711068860255e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.010693290270864964\n",
      "Gradient for encoder.encoder.0.bias: 1.5489883681274463e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.001512244576588273\n",
      "Gradient for encoder.encoder.1.bias: 0.0011075218208134174\n",
      "Gradient for encoder.encoder.3.weight: 0.032027699053287506\n",
      "Gradient for encoder.encoder.3.bias: 2.84679391171494e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.006429789122194052\n",
      "Gradient for encoder.encoder.4.bias: 0.005964252166450024\n",
      "Gradient for encoder.mean.weight: 0.08040880411863327\n",
      "Gradient for encoder.mean.bias: 0.0038073742762207985\n",
      "Gradient for encoder.log_var.weight: 0.05440433323383331\n",
      "Gradient for encoder.log_var.bias: 0.002672957954928279\n",
      "Gradient for decoder.decoder.0.weight: 0.016942782327532768\n",
      "Gradient for decoder.decoder.0.bias: 1.242440594850791e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0008979740086942911\n",
      "Gradient for decoder.decoder.1.bias: 0.0006928826333023608\n",
      "Gradient for decoder.decoder.3.weight: 0.01589372754096985\n",
      "Gradient for decoder.decoder.3.bias: 1.2525688819486902e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0007724176393821836\n",
      "Gradient for decoder.decoder.4.bias: 0.0007976560737006366\n",
      "Gradient for decoder.decoder.6.weight: 0.0008104579173959792\n",
      "Gradient for decoder.decoder.6.bias: 4.6619654312962666e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.009794584475457668\n",
      "Gradient for encoder.encoder.0.bias: 1.5655305177220136e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0009041004232130945\n",
      "Gradient for encoder.encoder.1.bias: 0.0008780847419984639\n",
      "Gradient for encoder.encoder.3.weight: 0.02042793482542038\n",
      "Gradient for encoder.encoder.3.bias: 1.9552391650190515e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.004176293034106493\n",
      "Gradient for encoder.encoder.4.bias: 0.0035204992163926363\n",
      "Gradient for encoder.mean.weight: 0.05979371443390846\n",
      "Gradient for encoder.mean.bias: 0.002705082530155778\n",
      "Gradient for encoder.log_var.weight: 0.03169403225183487\n",
      "Gradient for encoder.log_var.bias: 0.0015337932854890823\n",
      "Gradient for decoder.decoder.0.weight: 0.01286440808326006\n",
      "Gradient for decoder.decoder.0.bias: 1.1063037985703517e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0006109935347922146\n",
      "Gradient for decoder.decoder.1.bias: 0.0005150779034011066\n",
      "Gradient for decoder.decoder.3.weight: 0.012148154899477959\n",
      "Gradient for decoder.decoder.3.bias: 1.044355157908683e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0006164401420392096\n",
      "Gradient for decoder.decoder.4.bias: 0.0006844016606919467\n",
      "Gradient for decoder.decoder.6.weight: 0.0007198461680673063\n",
      "Gradient for decoder.decoder.6.bias: 4.8118396080099046e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.016059041023254395\n",
      "Gradient for encoder.encoder.0.bias: 2.539004596846528e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0018984276102855802\n",
      "Gradient for encoder.encoder.1.bias: 0.0016247858293354511\n",
      "Gradient for encoder.encoder.3.weight: 0.038841813802719116\n",
      "Gradient for encoder.encoder.3.bias: 3.1868357952546944e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.005116145126521587\n",
      "Gradient for encoder.encoder.4.bias: 0.0055628567934036255\n",
      "Gradient for encoder.mean.weight: 0.07074922323226929\n",
      "Gradient for encoder.mean.bias: 0.0041223797015845776\n",
      "Gradient for encoder.log_var.weight: 0.04331013187766075\n",
      "Gradient for encoder.log_var.bias: 0.0025053995195776224\n",
      "Gradient for decoder.decoder.0.weight: 0.015252706594765186\n",
      "Gradient for decoder.decoder.0.bias: 1.2192302722979775e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0007378865266218781\n",
      "Gradient for decoder.decoder.1.bias: 0.0006014686659909785\n",
      "Gradient for decoder.decoder.3.weight: 0.013967638835310936\n",
      "Gradient for decoder.decoder.3.bias: 1.0143898915293548e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0005080447299405932\n",
      "Gradient for decoder.decoder.4.bias: 0.00045973752276040614\n",
      "Gradient for decoder.decoder.6.weight: 0.0006768442108295858\n",
      "Gradient for decoder.decoder.6.bias: 3.373425715835765e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.012462720274925232\n",
      "Gradient for encoder.encoder.0.bias: 1.696864176947699e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0011427614372223616\n",
      "Gradient for encoder.encoder.1.bias: 0.0009185057133436203\n",
      "Gradient for encoder.encoder.3.weight: 0.024071594700217247\n",
      "Gradient for encoder.encoder.3.bias: 1.9263560191440376e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.004340362269431353\n",
      "Gradient for encoder.encoder.4.bias: 0.004067826084792614\n",
      "Gradient for encoder.mean.weight: 0.05971016734838486\n",
      "Gradient for encoder.mean.bias: 0.0031630450394004583\n",
      "Gradient for encoder.log_var.weight: 0.029452910646796227\n",
      "Gradient for encoder.log_var.bias: 0.0016208105953410268\n",
      "Gradient for decoder.decoder.0.weight: 0.015306033194065094\n",
      "Gradient for decoder.decoder.0.bias: 1.1513283382225126e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0007550447480753064\n",
      "Gradient for decoder.decoder.1.bias: 0.0005983738810755312\n",
      "Gradient for decoder.decoder.3.weight: 0.01374912727624178\n",
      "Gradient for decoder.decoder.3.bias: 1.0303000813616237e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0005240084137767553\n",
      "Gradient for decoder.decoder.4.bias: 0.0004919433267787099\n",
      "Gradient for decoder.decoder.6.weight: 0.0006718143704347312\n",
      "Gradient for decoder.decoder.6.bias: 3.288451989647001e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.013459388166666031\n",
      "Gradient for encoder.encoder.0.bias: 2.1641560071783417e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0016727445181459188\n",
      "Gradient for encoder.encoder.1.bias: 0.001445626956410706\n",
      "Gradient for encoder.encoder.3.weight: 0.03543742746114731\n",
      "Gradient for encoder.encoder.3.bias: 2.7937305246972244e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0072274222038686275\n",
      "Gradient for encoder.encoder.4.bias: 0.0062460037879645824\n",
      "Gradient for encoder.mean.weight: 0.09546758979558945\n",
      "Gradient for encoder.mean.bias: 0.004282144829630852\n",
      "Gradient for encoder.log_var.weight: 0.05497368797659874\n",
      "Gradient for encoder.log_var.bias: 0.0025153651367872953\n",
      "Gradient for decoder.decoder.0.weight: 0.013365461491048336\n",
      "Gradient for decoder.decoder.0.bias: 1.1357923629384814e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0006703098188154399\n",
      "Gradient for decoder.decoder.1.bias: 0.0004975688643753529\n",
      "Gradient for decoder.decoder.3.weight: 0.012529886327683926\n",
      "Gradient for decoder.decoder.3.bias: 9.751686957937267e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0004737404524348676\n",
      "Gradient for decoder.decoder.4.bias: 0.00040714163333177567\n",
      "Gradient for decoder.decoder.6.weight: 0.0006684032850898802\n",
      "Gradient for decoder.decoder.6.bias: 2.8458782253437676e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.013243516907095909\n",
      "Gradient for encoder.encoder.0.bias: 1.8751609640044187e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0011887896107509732\n",
      "Gradient for encoder.encoder.1.bias: 0.0010753857204690576\n",
      "Gradient for encoder.encoder.3.weight: 0.025696342810988426\n",
      "Gradient for encoder.encoder.3.bias: 2.56599741454977e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.004584728740155697\n",
      "Gradient for encoder.encoder.4.bias: 0.005369555205106735\n",
      "Gradient for encoder.mean.weight: 0.06137583404779434\n",
      "Gradient for encoder.mean.bias: 0.004383482504636049\n",
      "Gradient for encoder.log_var.weight: 0.039133470505476\n",
      "Gradient for encoder.log_var.bias: 0.0027519469149410725\n",
      "Gradient for decoder.decoder.0.weight: 0.01556361187249422\n",
      "Gradient for decoder.decoder.0.bias: 1.298216534273422e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0007661415729671717\n",
      "Gradient for decoder.decoder.1.bias: 0.0006282291724346578\n",
      "Gradient for decoder.decoder.3.weight: 0.013919342309236526\n",
      "Gradient for decoder.decoder.3.bias: 1.2837736429460733e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0007865277002565563\n",
      "Gradient for decoder.decoder.4.bias: 0.0009308779845014215\n",
      "Gradient for decoder.decoder.6.weight: 0.0007914556772448123\n",
      "Gradient for decoder.decoder.6.bias: 5.38681706530042e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.01514695305377245\n",
      "Gradient for encoder.encoder.0.bias: 2.1013352516363604e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.001513930968940258\n",
      "Gradient for encoder.encoder.1.bias: 0.0012069299118593335\n",
      "Gradient for encoder.encoder.3.weight: 0.03257807716727257\n",
      "Gradient for encoder.encoder.3.bias: 2.2963987655888474e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.004769062157720327\n",
      "Gradient for encoder.encoder.4.bias: 0.0040053497068583965\n",
      "Gradient for encoder.mean.weight: 0.06421392410993576\n",
      "Gradient for encoder.mean.bias: 0.0027714595198631287\n",
      "Gradient for encoder.log_var.weight: 0.03524365276098251\n",
      "Gradient for encoder.log_var.bias: 0.001684602932073176\n",
      "Gradient for decoder.decoder.0.weight: 0.013029385358095169\n",
      "Gradient for decoder.decoder.0.bias: 1.2204207089361319e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0007218680111691356\n",
      "Gradient for decoder.decoder.1.bias: 0.0005336281610652804\n",
      "Gradient for decoder.decoder.3.weight: 0.011959662660956383\n",
      "Gradient for decoder.decoder.3.bias: 1.0450906112735581e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.00044573802733793855\n",
      "Gradient for decoder.decoder.4.bias: 0.0004153737099841237\n",
      "Gradient for decoder.decoder.6.weight: 0.0006630526622757316\n",
      "Gradient for decoder.decoder.6.bias: 3.1286061130231246e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.013279523700475693\n",
      "Gradient for encoder.encoder.0.bias: 2.4033358636543767e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.001711714663542807\n",
      "Gradient for encoder.encoder.1.bias: 0.001489235321059823\n",
      "Gradient for encoder.encoder.3.weight: 0.03514697402715683\n",
      "Gradient for encoder.encoder.3.bias: 2.980339308678026e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.005960274953395128\n",
      "Gradient for encoder.encoder.4.bias: 0.006040068808943033\n",
      "Gradient for encoder.mean.weight: 0.07931043952703476\n",
      "Gradient for encoder.mean.bias: 0.004367555025964975\n",
      "Gradient for encoder.log_var.weight: 0.04892987757921219\n",
      "Gradient for encoder.log_var.bias: 0.0029079336673021317\n",
      "Gradient for decoder.decoder.0.weight: 0.012996244244277477\n",
      "Gradient for decoder.decoder.0.bias: 1.1343652406292648e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.000658713688608259\n",
      "Gradient for decoder.decoder.1.bias: 0.0005221505416557193\n",
      "Gradient for decoder.decoder.3.weight: 0.012270522303879261\n",
      "Gradient for decoder.decoder.3.bias: 9.377875559435367e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0004453323781490326\n",
      "Gradient for decoder.decoder.4.bias: 0.00039239958277903497\n",
      "Gradient for decoder.decoder.6.weight: 0.0006742862751707435\n",
      "Gradient for decoder.decoder.6.bias: 3.872971865348518e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.010733142495155334\n",
      "Gradient for encoder.encoder.0.bias: 1.61572925178044e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.000928786292206496\n",
      "Gradient for encoder.encoder.1.bias: 0.0009358607931062579\n",
      "Gradient for encoder.encoder.3.weight: 0.020531922578811646\n",
      "Gradient for encoder.encoder.3.bias: 2.2992867332316536e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.005266394466161728\n",
      "Gradient for encoder.encoder.4.bias: 0.0046621705405414104\n",
      "Gradient for encoder.mean.weight: 0.06477475166320801\n",
      "Gradient for encoder.mean.bias: 0.003132700454443693\n",
      "Gradient for encoder.log_var.weight: 0.046485695987939835\n",
      "Gradient for encoder.log_var.bias: 0.0020914117339998484\n",
      "Gradient for decoder.decoder.0.weight: 0.015145243145525455\n",
      "Gradient for decoder.decoder.0.bias: 1.174934594061483e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0007538471836596727\n",
      "Gradient for decoder.decoder.1.bias: 0.0005876287468709052\n",
      "Gradient for decoder.decoder.3.weight: 0.013678460381925106\n",
      "Gradient for decoder.decoder.3.bias: 1.1648391973206884e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0004688236804213375\n",
      "Gradient for decoder.decoder.4.bias: 0.00043404995813034475\n",
      "Gradient for decoder.decoder.6.weight: 0.0007199450628831983\n",
      "Gradient for decoder.decoder.6.bias: 4.6486245992127806e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.0129954619333148\n",
      "Gradient for encoder.encoder.0.bias: 2.1816550302422577e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0014910113532096148\n",
      "Gradient for encoder.encoder.1.bias: 0.0011836751364171505\n",
      "Gradient for encoder.encoder.3.weight: 0.032741859555244446\n",
      "Gradient for encoder.encoder.3.bias: 2.821224365234798e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.006038395222276449\n",
      "Gradient for encoder.encoder.4.bias: 0.006549789570271969\n",
      "Gradient for encoder.mean.weight: 0.07790283858776093\n",
      "Gradient for encoder.mean.bias: 0.004474449437111616\n",
      "Gradient for encoder.log_var.weight: 0.04580716788768768\n",
      "Gradient for encoder.log_var.bias: 0.002821328118443489\n",
      "Gradient for decoder.decoder.0.weight: 0.014294484630227089\n",
      "Gradient for decoder.decoder.0.bias: 1.14410821094868e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0007117328932508826\n",
      "Gradient for decoder.decoder.1.bias: 0.0005454813363030553\n",
      "Gradient for decoder.decoder.3.weight: 0.012542142532765865\n",
      "Gradient for decoder.decoder.3.bias: 1.0001625222466615e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.00046099990140646696\n",
      "Gradient for decoder.decoder.4.bias: 0.0003975067229475826\n",
      "Gradient for decoder.decoder.6.weight: 0.0006454382673837245\n",
      "Gradient for decoder.decoder.6.bias: 2.9341628760448657e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.013972537592053413\n",
      "Gradient for encoder.encoder.0.bias: 1.9016524466231033e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0017772805877029896\n",
      "Gradient for encoder.encoder.1.bias: 0.001342818490229547\n",
      "Gradient for encoder.encoder.3.weight: 0.03808329626917839\n",
      "Gradient for encoder.encoder.3.bias: 2.957424583005519e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.008894089609384537\n",
      "Gradient for encoder.encoder.4.bias: 0.007438588421791792\n",
      "Gradient for encoder.mean.weight: 0.11631064116954803\n",
      "Gradient for encoder.mean.bias: 0.004960694350302219\n",
      "Gradient for encoder.log_var.weight: 0.06567905098199844\n",
      "Gradient for encoder.log_var.bias: 0.002724361838772893\n",
      "Gradient for decoder.decoder.0.weight: 0.017709676176309586\n",
      "Gradient for decoder.decoder.0.bias: 1.5037808498430394e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0008851605234667659\n",
      "Gradient for decoder.decoder.1.bias: 0.0007760786102153361\n",
      "Gradient for decoder.decoder.3.weight: 0.015837881714105606\n",
      "Gradient for decoder.decoder.3.bias: 1.5157813892940908e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0008710433612577617\n",
      "Gradient for decoder.decoder.4.bias: 0.0009207905968651175\n",
      "Gradient for decoder.decoder.6.weight: 0.0008427880820818245\n",
      "Gradient for decoder.decoder.6.bias: 5.305998638505116e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.009087048470973969\n",
      "Gradient for encoder.encoder.0.bias: 1.46794208732981e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0009462166344746947\n",
      "Gradient for encoder.encoder.1.bias: 0.0006796153611503541\n",
      "Gradient for encoder.encoder.3.weight: 0.0194148700684309\n",
      "Gradient for encoder.encoder.3.bias: 1.9427241759739644e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.004933871328830719\n",
      "Gradient for encoder.encoder.4.bias: 0.00414508581161499\n",
      "Gradient for encoder.mean.weight: 0.06513593345880508\n",
      "Gradient for encoder.mean.bias: 0.002847877563908696\n",
      "Gradient for encoder.log_var.weight: 0.035902999341487885\n",
      "Gradient for encoder.log_var.bias: 0.0013551199808716774\n",
      "Gradient for decoder.decoder.0.weight: 0.015185677446424961\n",
      "Gradient for decoder.decoder.0.bias: 1.3054239633714104e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.000757213681936264\n",
      "Gradient for decoder.decoder.1.bias: 0.0006153571885079145\n",
      "Gradient for decoder.decoder.3.weight: 0.013903426006436348\n",
      "Gradient for decoder.decoder.3.bias: 1.1510364189559752e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0005117486580274999\n",
      "Gradient for decoder.decoder.4.bias: 0.00046530741383321583\n",
      "Gradient for decoder.decoder.6.weight: 0.0006986383814364672\n",
      "Gradient for decoder.decoder.6.bias: 4.061410072608851e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.01346115954220295\n",
      "Gradient for encoder.encoder.0.bias: 2.5188609878434853e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0018052303930744529\n",
      "Gradient for encoder.encoder.1.bias: 0.001695670303888619\n",
      "Gradient for encoder.encoder.3.weight: 0.038795337080955505\n",
      "Gradient for encoder.encoder.3.bias: 3.297506157018404e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0078096287325024605\n",
      "Gradient for encoder.encoder.4.bias: 0.00785287469625473\n",
      "Gradient for encoder.mean.weight: 0.09985602647066116\n",
      "Gradient for encoder.mean.bias: 0.005338262300938368\n",
      "Gradient for encoder.log_var.weight: 0.06268317252397537\n",
      "Gradient for encoder.log_var.bias: 0.003629617393016815\n",
      "Gradient for decoder.decoder.0.weight: 0.012229889631271362\n",
      "Gradient for decoder.decoder.0.bias: 9.998583211379142e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0006696793134324253\n",
      "Gradient for decoder.decoder.1.bias: 0.000496522116009146\n",
      "Gradient for decoder.decoder.3.weight: 0.011492370627820492\n",
      "Gradient for decoder.decoder.3.bias: 9.114536902998793e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00045735840103589\n",
      "Gradient for decoder.decoder.4.bias: 0.0004472556756809354\n",
      "Gradient for decoder.decoder.6.weight: 0.0006793409120291471\n",
      "Gradient for decoder.decoder.6.bias: 4.063003871124238e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.020035631954669952\n",
      "Gradient for encoder.encoder.0.bias: 2.6067014866071325e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0020818060729652643\n",
      "Gradient for encoder.encoder.1.bias: 0.0015720631927251816\n",
      "Gradient for encoder.encoder.3.weight: 0.044039759784936905\n",
      "Gradient for encoder.encoder.3.bias: 4.147382992591986e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.00854666531085968\n",
      "Gradient for encoder.encoder.4.bias: 0.00873717200011015\n",
      "Gradient for encoder.mean.weight: 0.109248086810112\n",
      "Gradient for encoder.mean.bias: 0.00647994177415967\n",
      "Gradient for encoder.log_var.weight: 0.06667976081371307\n",
      "Gradient for encoder.log_var.bias: 0.0038993910420686007\n",
      "Gradient for decoder.decoder.0.weight: 0.012809992767870426\n",
      "Gradient for decoder.decoder.0.bias: 1.1095847157749361e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0006534381536766887\n",
      "Gradient for decoder.decoder.1.bias: 0.0005322530050761998\n",
      "Gradient for decoder.decoder.3.weight: 0.01216136571019888\n",
      "Gradient for decoder.decoder.3.bias: 1.0162465313712232e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.000497648783493787\n",
      "Gradient for decoder.decoder.4.bias: 0.0004952531890012324\n",
      "Gradient for decoder.decoder.6.weight: 0.0006919845473021269\n",
      "Gradient for decoder.decoder.6.bias: 4.001045454060659e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.013616799376904964\n",
      "Gradient for encoder.encoder.0.bias: 2.0771743700076506e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0012624473311007023\n",
      "Gradient for encoder.encoder.1.bias: 0.0011290519032627344\n",
      "Gradient for encoder.encoder.3.weight: 0.02686474844813347\n",
      "Gradient for encoder.encoder.3.bias: 2.3133089888105474e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.00503384368494153\n",
      "Gradient for encoder.encoder.4.bias: 0.004506316501647234\n",
      "Gradient for encoder.mean.weight: 0.0668918564915657\n",
      "Gradient for encoder.mean.bias: 0.003317509777843952\n",
      "Gradient for encoder.log_var.weight: 0.0433494970202446\n",
      "Gradient for encoder.log_var.bias: 0.002139253541827202\n",
      "Gradient for decoder.decoder.0.weight: 0.012586873024702072\n",
      "Gradient for decoder.decoder.0.bias: 1.0306512587821004e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0005630609812214971\n",
      "Gradient for decoder.decoder.1.bias: 0.0004797194851562381\n",
      "Gradient for decoder.decoder.3.weight: 0.011599062010645866\n",
      "Gradient for decoder.decoder.3.bias: 8.699502229703171e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0004328823124524206\n",
      "Gradient for decoder.decoder.4.bias: 0.00042147291242145\n",
      "Gradient for decoder.decoder.6.weight: 0.0006726384744979441\n",
      "Gradient for decoder.decoder.6.bias: 3.965486757806502e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.014561353251338005\n",
      "Gradient for encoder.encoder.0.bias: 2.3982807059730327e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0019646091386675835\n",
      "Gradient for encoder.encoder.1.bias: 0.0016030087135732174\n",
      "Gradient for encoder.encoder.3.weight: 0.040431659668684006\n",
      "Gradient for encoder.encoder.3.bias: 2.5594792951721956e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.006377422250807285\n",
      "Gradient for encoder.encoder.4.bias: 0.0053223674185574055\n",
      "Gradient for encoder.mean.weight: 0.08754673600196838\n",
      "Gradient for encoder.mean.bias: 0.003503873012959957\n",
      "Gradient for encoder.log_var.weight: 0.04760080948472023\n",
      "Gradient for encoder.log_var.bias: 0.001970438053831458\n",
      "Gradient for decoder.decoder.0.weight: 0.01809893362224102\n",
      "Gradient for decoder.decoder.0.bias: 1.6938717095626998e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0009016012772917747\n",
      "Gradient for decoder.decoder.1.bias: 0.0006969435489736497\n",
      "Gradient for decoder.decoder.3.weight: 0.016638820990920067\n",
      "Gradient for decoder.decoder.3.bias: 1.6227345855934772e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0008454336202703416\n",
      "Gradient for decoder.decoder.4.bias: 0.0009359383257105947\n",
      "Gradient for decoder.decoder.6.weight: 0.0008247049991041422\n",
      "Gradient for decoder.decoder.6.bias: 5.209560185903683e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient for encoder.encoder.0.weight: 0.011100506410002708\n",
      "Gradient for encoder.encoder.0.bias: 1.5707365963457676e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0010396696161478758\n",
      "Gradient for encoder.encoder.1.bias: 0.000767212244682014\n",
      "Gradient for encoder.encoder.3.weight: 0.02291780896484852\n",
      "Gradient for encoder.encoder.3.bias: 3.2219435452951473e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.008387768641114235\n",
      "Gradient for encoder.encoder.4.bias: 0.007334880065172911\n",
      "Gradient for encoder.mean.weight: 0.11161468178033829\n",
      "Gradient for encoder.mean.bias: 0.004311869386583567\n",
      "Gradient for encoder.log_var.weight: 0.06313475221395493\n",
      "Gradient for encoder.log_var.bias: 0.002465656027197838\n",
      "Gradient for decoder.decoder.0.weight: 0.015099303796887398\n",
      "Gradient for decoder.decoder.0.bias: 1.3242364149679275e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0007810924435034394\n",
      "Gradient for decoder.decoder.1.bias: 0.000648259767331183\n",
      "Gradient for decoder.decoder.3.weight: 0.014294427819550037\n",
      "Gradient for decoder.decoder.3.bias: 1.1404920757795978e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0005926800658926368\n",
      "Gradient for decoder.decoder.4.bias: 0.0005547740147449076\n",
      "Gradient for decoder.decoder.6.weight: 0.000738040660507977\n",
      "Gradient for decoder.decoder.6.bias: 4.0474293200531974e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.010649689473211765\n",
      "Gradient for encoder.encoder.0.bias: 1.4631599751235846e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0012226622784510255\n",
      "Gradient for encoder.encoder.1.bias: 0.0010387853253632784\n",
      "Gradient for encoder.encoder.3.weight: 0.026617703959345818\n",
      "Gradient for encoder.encoder.3.bias: 2.246697272667575e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.006503287237137556\n",
      "Gradient for encoder.encoder.4.bias: 0.004678793717175722\n",
      "Gradient for encoder.mean.weight: 0.08978506922721863\n",
      "Gradient for encoder.mean.bias: 0.0027137091383337975\n",
      "Gradient for encoder.log_var.weight: 0.04889877140522003\n",
      "Gradient for encoder.log_var.bias: 0.0016665696166455746\n",
      "Gradient for decoder.decoder.0.weight: 0.014930890873074532\n",
      "Gradient for decoder.decoder.0.bias: 1.1956180490102497e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0007671141065657139\n",
      "Gradient for decoder.decoder.1.bias: 0.0006324322894215584\n",
      "Gradient for decoder.decoder.3.weight: 0.014049498364329338\n",
      "Gradient for decoder.decoder.3.bias: 1.1189615206630421e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.000545903982128948\n",
      "Gradient for decoder.decoder.4.bias: 0.0004574641352519393\n",
      "Gradient for decoder.decoder.6.weight: 0.0006853528320789337\n",
      "Gradient for decoder.decoder.6.bias: 3.2668456697138026e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.0117157232016325\n",
      "Gradient for encoder.encoder.0.bias: 1.7673619512326155e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0012804715661332011\n",
      "Gradient for encoder.encoder.1.bias: 0.0010642289416864514\n",
      "Gradient for encoder.encoder.3.weight: 0.02712247706949711\n",
      "Gradient for encoder.encoder.3.bias: 2.4706439671895453e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.007055946625769138\n",
      "Gradient for encoder.encoder.4.bias: 0.005996318534016609\n",
      "Gradient for encoder.mean.weight: 0.09596746414899826\n",
      "Gradient for encoder.mean.bias: 0.0038916771300137043\n",
      "Gradient for encoder.log_var.weight: 0.053084518760442734\n",
      "Gradient for encoder.log_var.bias: 0.0020292974077165127\n",
      "Gradient for decoder.decoder.0.weight: 0.014036037027835846\n",
      "Gradient for decoder.decoder.0.bias: 1.1608678601726652e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0007061464712023735\n",
      "Gradient for decoder.decoder.1.bias: 0.0005253646522760391\n",
      "Gradient for decoder.decoder.3.weight: 0.01311903353780508\n",
      "Gradient for decoder.decoder.3.bias: 9.931214184355497e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.000475582288345322\n",
      "Gradient for decoder.decoder.4.bias: 0.00041242095176130533\n",
      "Gradient for decoder.decoder.6.weight: 0.0007190466276369989\n",
      "Gradient for decoder.decoder.6.bias: 4.426501254783943e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.013469737023115158\n",
      "Gradient for encoder.encoder.0.bias: 2.1348913956109605e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0014203297905623913\n",
      "Gradient for encoder.encoder.1.bias: 0.001370375626720488\n",
      "Gradient for encoder.encoder.3.weight: 0.029913701117038727\n",
      "Gradient for encoder.encoder.3.bias: 2.234370743980918e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0053344168700277805\n",
      "Gradient for encoder.encoder.4.bias: 0.005070515908300877\n",
      "Gradient for encoder.mean.weight: 0.06813093274831772\n",
      "Gradient for encoder.mean.bias: 0.003682034555822611\n",
      "Gradient for encoder.log_var.weight: 0.0360148549079895\n",
      "Gradient for encoder.log_var.bias: 0.0018422551220282912\n",
      "Gradient for decoder.decoder.0.weight: 0.013937631621956825\n",
      "Gradient for decoder.decoder.0.bias: 1.177307279442985e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0007301967707462609\n",
      "Gradient for decoder.decoder.1.bias: 0.0005638420698232949\n",
      "Gradient for decoder.decoder.3.weight: 0.01265731267631054\n",
      "Gradient for decoder.decoder.3.bias: 1.0008213008338984e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0005818265490233898\n",
      "Gradient for decoder.decoder.4.bias: 0.000573028635699302\n",
      "Gradient for decoder.decoder.6.weight: 0.0007292571826837957\n",
      "Gradient for decoder.decoder.6.bias: 4.4135806092526764e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.010892054066061974\n",
      "Gradient for encoder.encoder.0.bias: 1.746307612404685e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0011157168773934245\n",
      "Gradient for encoder.encoder.1.bias: 0.001100493362173438\n",
      "Gradient for encoder.encoder.3.weight: 0.024379823356866837\n",
      "Gradient for encoder.encoder.3.bias: 2.2207610750335505e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.005115870852023363\n",
      "Gradient for encoder.encoder.4.bias: 0.005023232661187649\n",
      "Gradient for encoder.mean.weight: 0.06397281587123871\n",
      "Gradient for encoder.mean.bias: 0.003657614579424262\n",
      "Gradient for encoder.log_var.weight: 0.03455332666635513\n",
      "Gradient for encoder.log_var.bias: 0.0018603886710479856\n",
      "Gradient for decoder.decoder.0.weight: 0.013696063309907913\n",
      "Gradient for decoder.decoder.0.bias: 1.1360250934400185e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0007396854343824089\n",
      "Gradient for decoder.decoder.1.bias: 0.0005401516682468355\n",
      "Gradient for decoder.decoder.3.weight: 0.012505038641393185\n",
      "Gradient for decoder.decoder.3.bias: 9.647137255708316e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00046610788558609784\n",
      "Gradient for decoder.decoder.4.bias: 0.0004451524873729795\n",
      "Gradient for decoder.decoder.6.weight: 0.0007592501933686435\n",
      "Gradient for decoder.decoder.6.bias: 4.764050754602067e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.018801793456077576\n",
      "Gradient for encoder.encoder.0.bias: 3.5624999478178765e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0021979683078825474\n",
      "Gradient for encoder.encoder.1.bias: 0.0015706295380368829\n",
      "Gradient for encoder.encoder.3.weight: 0.04081465303897858\n",
      "Gradient for encoder.encoder.3.bias: 2.426014389378395e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.004559964407235384\n",
      "Gradient for encoder.encoder.4.bias: 0.0036274443846195936\n",
      "Gradient for encoder.mean.weight: 0.06324402987957001\n",
      "Gradient for encoder.mean.bias: 0.0023042745888233185\n",
      "Gradient for encoder.log_var.weight: 0.036920346319675446\n",
      "Gradient for encoder.log_var.bias: 0.0016178812365978956\n",
      "Gradient for decoder.decoder.0.weight: 0.01028409693390131\n",
      "Gradient for decoder.decoder.0.bias: 9.34394436824526e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005599166033789515\n",
      "Gradient for decoder.decoder.1.bias: 0.00041889515705406666\n",
      "Gradient for decoder.decoder.3.weight: 0.00934224296361208\n",
      "Gradient for decoder.decoder.3.bias: 8.310103299935534e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0004599009407684207\n",
      "Gradient for decoder.decoder.4.bias: 0.0005011202301830053\n",
      "Gradient for decoder.decoder.6.weight: 0.0007755631231702864\n",
      "Gradient for decoder.decoder.6.bias: 6.0153826780151576e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.011989844962954521\n",
      "Gradient for encoder.encoder.0.bias: 1.5255989180285034e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0013513125013560057\n",
      "Gradient for encoder.encoder.1.bias: 0.0011657575378194451\n",
      "Gradient for encoder.encoder.3.weight: 0.02687360905110836\n",
      "Gradient for encoder.encoder.3.bias: 2.2986083869636076e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.004545812960714102\n",
      "Gradient for encoder.encoder.4.bias: 0.004302231129258871\n",
      "Gradient for encoder.mean.weight: 0.059907060116529465\n",
      "Gradient for encoder.mean.bias: 0.0031284086871892214\n",
      "Gradient for encoder.log_var.weight: 0.036298997700214386\n",
      "Gradient for encoder.log_var.bias: 0.001933432649821043\n",
      "Gradient for decoder.decoder.0.weight: 0.018051940947771072\n",
      "Gradient for decoder.decoder.0.bias: 1.6586577944455172e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0009019923163577914\n",
      "Gradient for decoder.decoder.1.bias: 0.0007296445546671748\n",
      "Gradient for decoder.decoder.3.weight: 0.01677708514034748\n",
      "Gradient for decoder.decoder.3.bias: 1.668613025529453e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0009061685996130109\n",
      "Gradient for decoder.decoder.4.bias: 0.0010442569619044662\n",
      "Gradient for decoder.decoder.6.weight: 0.0009451461373828351\n",
      "Gradient for decoder.decoder.6.bias: 7.256062235683203e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.00855002086609602\n",
      "Gradient for encoder.encoder.0.bias: 1.6034795019548298e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0009813295910134912\n",
      "Gradient for encoder.encoder.1.bias: 0.0008031765464693308\n",
      "Gradient for encoder.encoder.3.weight: 0.019668392837047577\n",
      "Gradient for encoder.encoder.3.bias: 1.968671337060357e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.003908414393663406\n",
      "Gradient for encoder.encoder.4.bias: 0.0039055736269801855\n",
      "Gradient for encoder.mean.weight: 0.05375748127698898\n",
      "Gradient for encoder.mean.bias: 0.003113020211458206\n",
      "Gradient for encoder.log_var.weight: 0.033939942717552185\n",
      "Gradient for encoder.log_var.bias: 0.0019131442531943321\n",
      "Gradient for decoder.decoder.0.weight: 0.013729115948081017\n",
      "Gradient for decoder.decoder.0.bias: 1.1182809539489469e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0006856032996438444\n",
      "Gradient for decoder.decoder.1.bias: 0.0005245338543318212\n",
      "Gradient for decoder.decoder.3.weight: 0.012582575902342796\n",
      "Gradient for decoder.decoder.3.bias: 1.0634679248333612e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0004559058288577944\n",
      "Gradient for decoder.decoder.4.bias: 0.00044147527660243213\n",
      "Gradient for decoder.decoder.6.weight: 0.0006617925246246159\n",
      "Gradient for decoder.decoder.6.bias: 3.6674642615253106e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.015451756305992603\n",
      "Gradient for encoder.encoder.0.bias: 1.9881020441037123e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0016395250568166375\n",
      "Gradient for encoder.encoder.1.bias: 0.0012184556107968092\n",
      "Gradient for encoder.encoder.3.weight: 0.03270683437585831\n",
      "Gradient for encoder.encoder.3.bias: 2.1683128903493554e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.004780671093612909\n",
      "Gradient for encoder.encoder.4.bias: 0.004481148906052113\n",
      "Gradient for encoder.mean.weight: 0.06749173253774643\n",
      "Gradient for encoder.mean.bias: 0.002995315007865429\n",
      "Gradient for encoder.log_var.weight: 0.03447280079126358\n",
      "Gradient for encoder.log_var.bias: 0.0014981692656874657\n",
      "Gradient for decoder.decoder.0.weight: 0.017486276105046272\n",
      "Gradient for decoder.decoder.0.bias: 1.4904703860008084e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0008516889647580683\n",
      "Gradient for decoder.decoder.1.bias: 0.0006895976839587092\n",
      "Gradient for decoder.decoder.3.weight: 0.016355477273464203\n",
      "Gradient for decoder.decoder.3.bias: 1.1438523045415039e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.00061590172117576\n",
      "Gradient for decoder.decoder.4.bias: 0.0005297925090417266\n",
      "Gradient for decoder.decoder.6.weight: 0.0007716035470366478\n",
      "Gradient for decoder.decoder.6.bias: 4.0955950680654496e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.012607002630829811\n",
      "Gradient for encoder.encoder.0.bias: 2.0896707975115447e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0014189132489264011\n",
      "Gradient for encoder.encoder.1.bias: 0.0013266156893223524\n",
      "Gradient for encoder.encoder.3.weight: 0.03001418150961399\n",
      "Gradient for encoder.encoder.3.bias: 2.1539464656328278e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.004511463921517134\n",
      "Gradient for encoder.encoder.4.bias: 0.0035844692029058933\n",
      "Gradient for encoder.mean.weight: 0.06040053814649582\n",
      "Gradient for encoder.mean.bias: 0.002656869823113084\n",
      "Gradient for encoder.log_var.weight: 0.03646720573306084\n",
      "Gradient for encoder.log_var.bias: 0.0015627609100192785\n",
      "Gradient for decoder.decoder.0.weight: 0.013832200318574905\n",
      "Gradient for decoder.decoder.0.bias: 1.1653876474948532e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0007205618312582374\n",
      "Gradient for decoder.decoder.1.bias: 0.0005459170206449926\n",
      "Gradient for decoder.decoder.3.weight: 0.013527250848710537\n",
      "Gradient for decoder.decoder.3.bias: 1.0303138897604924e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0004757893329951912\n",
      "Gradient for decoder.decoder.4.bias: 0.0004076586046721786\n",
      "Gradient for decoder.decoder.6.weight: 0.0007376172579824924\n",
      "Gradient for decoder.decoder.6.bias: 4.5018063246970996e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.020933926105499268\n",
      "Gradient for encoder.encoder.0.bias: 3.231428319372398e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0019623071420937777\n",
      "Gradient for encoder.encoder.1.bias: 0.0016822682227939367\n",
      "Gradient for encoder.encoder.3.weight: 0.04320087283849716\n",
      "Gradient for encoder.encoder.3.bias: 3.128315662070946e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.006634630262851715\n",
      "Gradient for encoder.encoder.4.bias: 0.006175193469971418\n",
      "Gradient for encoder.mean.weight: 0.08753064274787903\n",
      "Gradient for encoder.mean.bias: 0.004391471389681101\n",
      "Gradient for encoder.log_var.weight: 0.04706653580069542\n",
      "Gradient for encoder.log_var.bias: 0.0022596793714910746\n",
      "Gradient for decoder.decoder.0.weight: 0.010320611298084259\n",
      "Gradient for decoder.decoder.0.bias: 8.362834036379496e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005418959190137684\n",
      "Gradient for decoder.decoder.1.bias: 0.00046516393194906414\n",
      "Gradient for decoder.decoder.3.weight: 0.009957187809050083\n",
      "Gradient for decoder.decoder.3.bias: 9.712868703770638e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0005970247439108789\n",
      "Gradient for decoder.decoder.4.bias: 0.0007046350510790944\n",
      "Gradient for decoder.decoder.6.weight: 0.0006933108088560402\n",
      "Gradient for decoder.decoder.6.bias: 4.6920671593397856e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.05076449736952782\n",
      "Gradient for encoder.encoder.0.bias: 5.4334498705843615e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0019680727273225784\n",
      "Gradient for encoder.encoder.1.bias: 0.0022214646451175213\n",
      "Gradient for encoder.encoder.3.weight: 0.04611856862902641\n",
      "Gradient for encoder.encoder.3.bias: 6.191754886586409e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.01026254054158926\n",
      "Gradient for encoder.encoder.4.bias: 0.013880923390388489\n",
      "Gradient for encoder.mean.weight: 0.13156943023204803\n",
      "Gradient for encoder.mean.bias: 0.009103942662477493\n",
      "Gradient for encoder.log_var.weight: 0.08469250053167343\n",
      "Gradient for encoder.log_var.bias: 0.005878145340830088\n",
      "Gradient for decoder.decoder.0.weight: 0.04171416163444519\n",
      "Gradient for decoder.decoder.0.bias: 2.504186857876789e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0016691790660843253\n",
      "Gradient for decoder.decoder.1.bias: 0.0014355505118146539\n",
      "Gradient for decoder.decoder.3.weight: 0.03588439151644707\n",
      "Gradient for decoder.decoder.3.bias: 2.509887575552483e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0012111128307878971\n",
      "Gradient for decoder.decoder.4.bias: 0.0010392745025455952\n",
      "Gradient for decoder.decoder.6.weight: 0.002135663293302059\n",
      "Gradient for decoder.decoder.6.bias: 0.00012821407290175557\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/3, Train Loss: 0.0763, Val Loss: 0.3247\n",
      "Training VAE for class 4...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training VAE Epoch:  11%|█▏        | 9/79 [00:00<00:01, 37.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient for encoder.encoder.0.weight: 0.01788310706615448\n",
      "Gradient for encoder.encoder.0.bias: 2.7648067862928727e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0024405168369412422\n",
      "Gradient for encoder.encoder.1.bias: 0.001849489752203226\n",
      "Gradient for encoder.encoder.3.weight: 0.04926378279924393\n",
      "Gradient for encoder.encoder.3.bias: 4.5984727137238224e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.012501651421189308\n",
      "Gradient for encoder.encoder.4.bias: 0.011981159448623657\n",
      "Gradient for encoder.mean.weight: 0.15857988595962524\n",
      "Gradient for encoder.mean.bias: 0.0070284330286085606\n",
      "Gradient for encoder.log_var.weight: 0.09519943594932556\n",
      "Gradient for encoder.log_var.bias: 0.004095454700291157\n",
      "Gradient for decoder.decoder.0.weight: 0.01209644228219986\n",
      "Gradient for decoder.decoder.0.bias: 1.0562901942012815e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0006315440405160189\n",
      "Gradient for decoder.decoder.1.bias: 0.000495435728225857\n",
      "Gradient for decoder.decoder.3.weight: 0.011418898589909077\n",
      "Gradient for decoder.decoder.3.bias: 1.1634863211762436e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0007139385561458766\n",
      "Gradient for decoder.decoder.4.bias: 0.0007931679720059037\n",
      "Gradient for decoder.decoder.6.weight: 0.0007750459481030703\n",
      "Gradient for decoder.decoder.6.bias: 5.951333150733262e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.014486969448626041\n",
      "Gradient for encoder.encoder.0.bias: 1.997646839613232e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.001557657727971673\n",
      "Gradient for encoder.encoder.1.bias: 0.0011193787213414907\n",
      "Gradient for encoder.encoder.3.weight: 0.03432317078113556\n",
      "Gradient for encoder.encoder.3.bias: 2.5684473992093615e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.007169710472226143\n",
      "Gradient for encoder.encoder.4.bias: 0.005649205297231674\n",
      "Gradient for encoder.mean.weight: 0.08708808571100235\n",
      "Gradient for encoder.mean.bias: 0.003467198694124818\n",
      "Gradient for encoder.log_var.weight: 0.060846079140901566\n",
      "Gradient for encoder.log_var.bias: 0.0023052573669701815\n",
      "Gradient for decoder.decoder.0.weight: 0.014274733141064644\n",
      "Gradient for decoder.decoder.0.bias: 1.1327556947993145e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0007158721564337611\n",
      "Gradient for decoder.decoder.1.bias: 0.000524262257385999\n",
      "Gradient for decoder.decoder.3.weight: 0.012634644284844398\n",
      "Gradient for decoder.decoder.3.bias: 1.3114948016479389e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0008285320946015418\n",
      "Gradient for decoder.decoder.4.bias: 0.0009719792287796736\n",
      "Gradient for decoder.decoder.6.weight: 0.000801621878053993\n",
      "Gradient for decoder.decoder.6.bias: 6.442794983740896e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.01776750013232231\n",
      "Gradient for encoder.encoder.0.bias: 3.065506182231559e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.002553151920437813\n",
      "Gradient for encoder.encoder.1.bias: 0.0018552475376054645\n",
      "Gradient for encoder.encoder.3.weight: 0.047587767243385315\n",
      "Gradient for encoder.encoder.3.bias: 3.1002581057926193e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.009238715283572674\n",
      "Gradient for encoder.encoder.4.bias: 0.007812228985130787\n",
      "Gradient for encoder.mean.weight: 0.12011771649122238\n",
      "Gradient for encoder.mean.bias: 0.005214333068579435\n",
      "Gradient for encoder.log_var.weight: 0.07635938376188278\n",
      "Gradient for encoder.log_var.bias: 0.003453731769695878\n",
      "Gradient for decoder.decoder.0.weight: 0.011948911473155022\n",
      "Gradient for decoder.decoder.0.bias: 1.0024533286800974e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0005334278102964163\n",
      "Gradient for decoder.decoder.1.bias: 0.00045286319800652564\n",
      "Gradient for decoder.decoder.3.weight: 0.01106877252459526\n",
      "Gradient for decoder.decoder.3.bias: 1.822499651193965e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0013876206940039992\n",
      "Gradient for decoder.decoder.4.bias: 0.0017840672517195344\n",
      "Gradient for decoder.decoder.6.weight: 0.0010592761682346463\n",
      "Gradient for decoder.decoder.6.bias: 0.00010487357940291986\n",
      "Gradient for encoder.encoder.0.weight: 0.014260724186897278\n",
      "Gradient for encoder.encoder.0.bias: 1.805826148337797e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.001355577609501779\n",
      "Gradient for encoder.encoder.1.bias: 0.0010415810393169522\n",
      "Gradient for encoder.encoder.3.weight: 0.028202885761857033\n",
      "Gradient for encoder.encoder.3.bias: 2.4656260366739957e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.005507840774953365\n",
      "Gradient for encoder.encoder.4.bias: 0.005316188558936119\n",
      "Gradient for encoder.mean.weight: 0.0698016956448555\n",
      "Gradient for encoder.mean.bias: 0.003957975190132856\n",
      "Gradient for encoder.log_var.weight: 0.042506322264671326\n",
      "Gradient for encoder.log_var.bias: 0.002310100244358182\n",
      "Gradient for decoder.decoder.0.weight: 0.0143210981041193\n",
      "Gradient for decoder.decoder.0.bias: 1.1464374588543436e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0007366073550656438\n",
      "Gradient for decoder.decoder.1.bias: 0.0005752781289629638\n",
      "Gradient for decoder.decoder.3.weight: 0.013912913389503956\n",
      "Gradient for decoder.decoder.3.bias: 1.373989533259845e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0009418284171260893\n",
      "Gradient for decoder.decoder.4.bias: 0.0011220327578485012\n",
      "Gradient for decoder.decoder.6.weight: 0.0008581248112022877\n",
      "Gradient for decoder.decoder.6.bias: 7.106660632416606e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.014134140685200691\n",
      "Gradient for encoder.encoder.0.bias: 2.0488307231336655e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0015298875514417887\n",
      "Gradient for encoder.encoder.1.bias: 0.0012239814968779683\n",
      "Gradient for encoder.encoder.3.weight: 0.031860895454883575\n",
      "Gradient for encoder.encoder.3.bias: 2.3063212450935566e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.005255580879747868\n",
      "Gradient for encoder.encoder.4.bias: 0.004209315869957209\n",
      "Gradient for encoder.mean.weight: 0.07583556324243546\n",
      "Gradient for encoder.mean.bias: 0.0033747032284736633\n",
      "Gradient for encoder.log_var.weight: 0.043431416153907776\n",
      "Gradient for encoder.log_var.bias: 0.0020432937890291214\n",
      "Gradient for decoder.decoder.0.weight: 0.013838006183505058\n",
      "Gradient for decoder.decoder.0.bias: 1.0317298404505237e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0006463102181442082\n",
      "Gradient for decoder.decoder.1.bias: 0.0004911482683382928\n",
      "Gradient for decoder.decoder.3.weight: 0.012446082197129726\n",
      "Gradient for decoder.decoder.3.bias: 1.3165819823246494e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0010288115590810776\n",
      "Gradient for decoder.decoder.4.bias: 0.0012596359010785818\n",
      "Gradient for decoder.decoder.6.weight: 0.0008573271334171295\n",
      "Gradient for decoder.decoder.6.bias: 7.52880732761696e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.017379719763994217\n",
      "Gradient for encoder.encoder.0.bias: 2.3216430514172437e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0016367142088711262\n",
      "Gradient for encoder.encoder.1.bias: 0.0013492506695911288\n",
      "Gradient for encoder.encoder.3.weight: 0.035161472856998444\n",
      "Gradient for encoder.encoder.3.bias: 3.0219801661068857e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0070025259628891945\n",
      "Gradient for encoder.encoder.4.bias: 0.006668347865343094\n",
      "Gradient for encoder.mean.weight: 0.09595892578363419\n",
      "Gradient for encoder.mean.bias: 0.0047365776263177395\n",
      "Gradient for encoder.log_var.weight: 0.049714166671037674\n",
      "Gradient for encoder.log_var.bias: 0.003015069756656885\n",
      "Gradient for decoder.decoder.0.weight: 0.012653913348913193\n",
      "Gradient for decoder.decoder.0.bias: 1.1349340217625681e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0005989393102936447\n",
      "Gradient for decoder.decoder.1.bias: 0.0005068866885267198\n",
      "Gradient for decoder.decoder.3.weight: 0.011519470252096653\n",
      "Gradient for decoder.decoder.3.bias: 1.1832222701624318e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0006705020205117762\n",
      "Gradient for decoder.decoder.4.bias: 0.0007778340950608253\n",
      "Gradient for decoder.decoder.6.weight: 0.0007512013544328511\n",
      "Gradient for decoder.decoder.6.bias: 6.110798130976036e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.013908417895436287\n",
      "Gradient for encoder.encoder.0.bias: 1.9595814554351776e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0017070785397663713\n",
      "Gradient for encoder.encoder.1.bias: 0.001404084381647408\n",
      "Gradient for encoder.encoder.3.weight: 0.03547586128115654\n",
      "Gradient for encoder.encoder.3.bias: 3.4683075855745926e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.008171504363417625\n",
      "Gradient for encoder.encoder.4.bias: 0.008006756193935871\n",
      "Gradient for encoder.mean.weight: 0.10641564428806305\n",
      "Gradient for encoder.mean.bias: 0.005698109045624733\n",
      "Gradient for encoder.log_var.weight: 0.05924210324883461\n",
      "Gradient for encoder.log_var.bias: 0.003372558392584324\n",
      "Gradient for decoder.decoder.0.weight: 0.012937432155013084\n",
      "Gradient for decoder.decoder.0.bias: 1.0253160126483252e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0007082669762894511\n",
      "Gradient for decoder.decoder.1.bias: 0.0005069111357443035\n",
      "Gradient for decoder.decoder.3.weight: 0.012296286411583424\n",
      "Gradient for decoder.decoder.3.bias: 1.2824384609810835e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0009932925458997488\n",
      "Gradient for decoder.decoder.4.bias: 0.0012673254823312163\n",
      "Gradient for decoder.decoder.6.weight: 0.0008564718882553279\n",
      "Gradient for decoder.decoder.6.bias: 7.495706813642755e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.014292683452367783\n",
      "Gradient for encoder.encoder.0.bias: 2.126171808058963e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0013564168475568295\n",
      "Gradient for encoder.encoder.1.bias: 0.0010705433087423444\n",
      "Gradient for encoder.encoder.3.weight: 0.03169245645403862\n",
      "Gradient for encoder.encoder.3.bias: 2.4040441859440875e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.005652096588164568\n",
      "Gradient for encoder.encoder.4.bias: 0.004958843346685171\n",
      "Gradient for encoder.mean.weight: 0.0777011439204216\n",
      "Gradient for encoder.mean.bias: 0.004256660584360361\n",
      "Gradient for encoder.log_var.weight: 0.04297008737921715\n",
      "Gradient for encoder.log_var.bias: 0.0023856121115386486\n",
      "Gradient for decoder.decoder.0.weight: 0.013237766921520233\n",
      "Gradient for decoder.decoder.0.bias: 1.1073147260232119e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0006619867635890841\n",
      "Gradient for decoder.decoder.1.bias: 0.0005039734533056617\n",
      "Gradient for decoder.decoder.3.weight: 0.012189161963760853\n",
      "Gradient for decoder.decoder.3.bias: 1.0996473870372725e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0007379923481494188\n",
      "Gradient for decoder.decoder.4.bias: 0.0008739166660234332\n",
      "Gradient for decoder.decoder.6.weight: 0.00078824651427567\n",
      "Gradient for decoder.decoder.6.bias: 6.779833347536623e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.01455067191272974\n",
      "Gradient for encoder.encoder.0.bias: 2.233608263624287e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.001370065612718463\n",
      "Gradient for encoder.encoder.1.bias: 0.0011327940737828612\n",
      "Gradient for encoder.encoder.3.weight: 0.029159776866436005\n",
      "Gradient for encoder.encoder.3.bias: 2.0164955816248664e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.005128954071551561\n",
      "Gradient for encoder.encoder.4.bias: 0.004016176797449589\n",
      "Gradient for encoder.mean.weight: 0.0673818588256836\n",
      "Gradient for encoder.mean.bias: 0.003138383850455284\n",
      "Gradient for encoder.log_var.weight: 0.03902006521821022\n",
      "Gradient for encoder.log_var.bias: 0.0018956789281219244\n",
      "Gradient for decoder.decoder.0.weight: 0.014306521974503994\n",
      "Gradient for decoder.decoder.0.bias: 1.1553922402152139e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0007480938802473247\n",
      "Gradient for decoder.decoder.1.bias: 0.0005662512267008424\n",
      "Gradient for decoder.decoder.3.weight: 0.013150673359632492\n",
      "Gradient for decoder.decoder.3.bias: 1.0970332281479145e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0006269085570238531\n",
      "Gradient for decoder.decoder.4.bias: 0.0007489028503187001\n",
      "Gradient for decoder.decoder.6.weight: 0.0007227590540423989\n",
      "Gradient for decoder.decoder.6.bias: 5.5397915275534615e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.010639156214892864\n",
      "Gradient for encoder.encoder.0.bias: 1.3145532405667293e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0012992025585845113\n",
      "Gradient for encoder.encoder.1.bias: 0.0010598854860290885\n",
      "Gradient for encoder.encoder.3.weight: 0.025438304990530014\n",
      "Gradient for encoder.encoder.3.bias: 2.2221760542784352e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.00418432243168354\n",
      "Gradient for encoder.encoder.4.bias: 0.00437404727563262\n",
      "Gradient for encoder.mean.weight: 0.058767564594745636\n",
      "Gradient for encoder.mean.bias: 0.003704637521877885\n",
      "Gradient for encoder.log_var.weight: 0.03430391475558281\n",
      "Gradient for encoder.log_var.bias: 0.0023215939290821552\n",
      "Gradient for decoder.decoder.0.weight: 0.01676478236913681\n",
      "Gradient for decoder.decoder.0.bias: 1.348711142767911e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0007785283960402012\n",
      "Gradient for decoder.decoder.1.bias: 0.0006842708098702133\n",
      "Gradient for decoder.decoder.3.weight: 0.014673144556581974\n",
      "Gradient for decoder.decoder.3.bias: 1.2294930351597344e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0005731512792408466\n",
      "Gradient for decoder.decoder.4.bias: 0.0005680078756995499\n",
      "Gradient for decoder.decoder.6.weight: 0.0006809314363636076\n",
      "Gradient for decoder.decoder.6.bias: 4.114419425604865e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.01680685766041279\n",
      "Gradient for encoder.encoder.0.bias: 2.4720630056873638e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.001498678931966424\n",
      "Gradient for encoder.encoder.1.bias: 0.0012838373659178615\n",
      "Gradient for encoder.encoder.3.weight: 0.03132868930697441\n",
      "Gradient for encoder.encoder.3.bias: 2.238508822749452e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.00498499209061265\n",
      "Gradient for encoder.encoder.4.bias: 0.004514850210398436\n",
      "Gradient for encoder.mean.weight: 0.06426350772380829\n",
      "Gradient for encoder.mean.bias: 0.0035059296060353518\n",
      "Gradient for encoder.log_var.weight: 0.04510849714279175\n",
      "Gradient for encoder.log_var.bias: 0.0025510890409350395\n",
      "Gradient for decoder.decoder.0.weight: 0.011127485893666744\n",
      "Gradient for decoder.decoder.0.bias: 9.230342185029272e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005358633934520185\n",
      "Gradient for decoder.decoder.1.bias: 0.0003899739822372794\n",
      "Gradient for decoder.decoder.3.weight: 0.010403099469840527\n",
      "Gradient for decoder.decoder.3.bias: 1.4330577002841238e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0009733279002830386\n",
      "Gradient for decoder.decoder.4.bias: 0.0012206919491291046\n",
      "Gradient for decoder.decoder.6.weight: 0.0008159190183505416\n",
      "Gradient for decoder.decoder.6.bias: 7.352584361797199e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.022613484412431717\n",
      "Gradient for encoder.encoder.0.bias: 3.3484152950347124e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.002517628250643611\n",
      "Gradient for encoder.encoder.1.bias: 0.0016560169169679284\n",
      "Gradient for encoder.encoder.3.weight: 0.05209639295935631\n",
      "Gradient for encoder.encoder.3.bias: 3.2982605535636367e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0075923544354736805\n",
      "Gradient for encoder.encoder.4.bias: 0.007272575981914997\n",
      "Gradient for encoder.mean.weight: 0.09883419424295425\n",
      "Gradient for encoder.mean.bias: 0.005082357209175825\n",
      "Gradient for encoder.log_var.weight: 0.048960283398628235\n",
      "Gradient for encoder.log_var.bias: 0.0028760707937180996\n",
      "Gradient for decoder.decoder.0.weight: 0.010820315219461918\n",
      "Gradient for decoder.decoder.0.bias: 9.267248773925374e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.000587577058468014\n",
      "Gradient for decoder.decoder.1.bias: 0.0004366926441434771\n",
      "Gradient for decoder.decoder.3.weight: 0.010154894553124905\n",
      "Gradient for decoder.decoder.3.bias: 1.430422585935176e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0010074767051264644\n",
      "Gradient for decoder.decoder.4.bias: 0.001280154101550579\n",
      "Gradient for decoder.decoder.6.weight: 0.0008411864982917905\n",
      "Gradient for decoder.decoder.6.bias: 7.921701035229489e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.020922604948282242\n",
      "Gradient for encoder.encoder.0.bias: 3.128860018297708e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0022340542636811733\n",
      "Gradient for encoder.encoder.1.bias: 0.0015999034512788057\n",
      "Gradient for encoder.encoder.3.weight: 0.04666543006896973\n",
      "Gradient for encoder.encoder.3.bias: 2.7886407072408304e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.005920568481087685\n",
      "Gradient for encoder.encoder.4.bias: 0.005145267583429813\n",
      "Gradient for encoder.mean.weight: 0.07690560072660446\n",
      "Gradient for encoder.mean.bias: 0.003443400375545025\n",
      "Gradient for encoder.log_var.weight: 0.040163200348615646\n",
      "Gradient for encoder.log_var.bias: 0.002140468219295144\n",
      "Gradient for decoder.decoder.0.weight: 0.010157372802495956\n",
      "Gradient for decoder.decoder.0.bias: 8.186218369843345e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005180096486583352\n",
      "Gradient for decoder.decoder.1.bias: 0.0004091624286957085\n",
      "Gradient for decoder.decoder.3.weight: 0.009546182118356228\n",
      "Gradient for decoder.decoder.3.bias: 1.018565579102848e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0006674440228380263\n",
      "Gradient for decoder.decoder.4.bias: 0.000777321052737534\n",
      "Gradient for decoder.decoder.6.weight: 0.0006958440062589943\n",
      "Gradient for decoder.decoder.6.bias: 5.3589275921694934e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.015447273850440979\n",
      "Gradient for encoder.encoder.0.bias: 2.5183414381624303e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0014914654893800616\n",
      "Gradient for encoder.encoder.1.bias: 0.0012578488094732165\n",
      "Gradient for encoder.encoder.3.weight: 0.031855884939432144\n",
      "Gradient for encoder.encoder.3.bias: 2.158553474851388e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.004770718980580568\n",
      "Gradient for encoder.encoder.4.bias: 0.004025816917419434\n",
      "Gradient for encoder.mean.weight: 0.06525047868490219\n",
      "Gradient for encoder.mean.bias: 0.0023925311397761106\n",
      "Gradient for encoder.log_var.weight: 0.03240334615111351\n",
      "Gradient for encoder.log_var.bias: 0.0018730734009295702\n",
      "Gradient for decoder.decoder.0.weight: 0.01073105726391077\n",
      "Gradient for decoder.decoder.0.bias: 9.40196323573339e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.000562933855690062\n",
      "Gradient for decoder.decoder.1.bias: 0.000427122664405033\n",
      "Gradient for decoder.decoder.3.weight: 0.009951035492122173\n",
      "Gradient for decoder.decoder.3.bias: 1.1751397077652825e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0008165928302332759\n",
      "Gradient for decoder.decoder.4.bias: 0.0010327582713216543\n",
      "Gradient for decoder.decoder.6.weight: 0.0007631359621882439\n",
      "Gradient for decoder.decoder.6.bias: 6.444899190682918e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.015478501096367836\n",
      "Gradient for encoder.encoder.0.bias: 2.6415619691633196e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.001503556501120329\n",
      "Gradient for encoder.encoder.1.bias: 0.001142408000305295\n",
      "Gradient for encoder.encoder.3.weight: 0.0308902096003294\n",
      "Gradient for encoder.encoder.3.bias: 2.217451777752899e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.006953604985028505\n",
      "Gradient for encoder.encoder.4.bias: 0.0050210305489599705\n",
      "Gradient for encoder.mean.weight: 0.09317418187856674\n",
      "Gradient for encoder.mean.bias: 0.003067872952669859\n",
      "Gradient for encoder.log_var.weight: 0.05939099192619324\n",
      "Gradient for encoder.log_var.bias: 0.0017451989697292447\n",
      "Gradient for decoder.decoder.0.weight: 0.010676632635295391\n",
      "Gradient for decoder.decoder.0.bias: 8.897998310386512e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005303581128828228\n",
      "Gradient for decoder.decoder.1.bias: 0.00042346472037024796\n",
      "Gradient for decoder.decoder.3.weight: 0.009881612844765186\n",
      "Gradient for decoder.decoder.3.bias: 1.5533199726469604e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0011334342416375875\n",
      "Gradient for decoder.decoder.4.bias: 0.0014586237957701087\n",
      "Gradient for decoder.decoder.6.weight: 0.0008527270401827991\n",
      "Gradient for decoder.decoder.6.bias: 8.203633478842676e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.019985057413578033\n",
      "Gradient for encoder.encoder.0.bias: 3.76977303540027e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.001512780087068677\n",
      "Gradient for encoder.encoder.1.bias: 0.0012911275262013078\n",
      "Gradient for encoder.encoder.3.weight: 0.03227809816598892\n",
      "Gradient for encoder.encoder.3.bias: 2.586731384646157e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.004903548397123814\n",
      "Gradient for encoder.encoder.4.bias: 0.004953302443027496\n",
      "Gradient for encoder.mean.weight: 0.06660780310630798\n",
      "Gradient for encoder.mean.bias: 0.004299830179661512\n",
      "Gradient for encoder.log_var.weight: 0.039895642548799515\n",
      "Gradient for encoder.log_var.bias: 0.002622363856062293\n",
      "Gradient for decoder.decoder.0.weight: 0.010026181116700172\n",
      "Gradient for decoder.decoder.0.bias: 8.408753554567383e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0004926950205117464\n",
      "Gradient for decoder.decoder.1.bias: 0.0003975522122345865\n",
      "Gradient for decoder.decoder.3.weight: 0.009184516035020351\n",
      "Gradient for decoder.decoder.3.bias: 1.0803994504593462e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0008055243524722755\n",
      "Gradient for decoder.decoder.4.bias: 0.0010309090139344335\n",
      "Gradient for decoder.decoder.6.weight: 0.0006993221468292177\n",
      "Gradient for decoder.decoder.6.bias: 5.832931128679775e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training VAE Epoch:  34%|███▍      | 27/79 [00:00<00:00, 65.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient for encoder.encoder.0.weight: 0.022653883323073387\n",
      "Gradient for encoder.encoder.0.bias: 3.5825481470297404e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0019321450963616371\n",
      "Gradient for encoder.encoder.1.bias: 0.0015173378633335233\n",
      "Gradient for encoder.encoder.3.weight: 0.04453917592763901\n",
      "Gradient for encoder.encoder.3.bias: 2.9837743387162163e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.006046721711754799\n",
      "Gradient for encoder.encoder.4.bias: 0.007279648445546627\n",
      "Gradient for encoder.mean.weight: 0.08249978721141815\n",
      "Gradient for encoder.mean.bias: 0.0058617498725652695\n",
      "Gradient for encoder.log_var.weight: 0.05341946706175804\n",
      "Gradient for encoder.log_var.bias: 0.004104522056877613\n",
      "Gradient for decoder.decoder.0.weight: 0.009537739679217339\n",
      "Gradient for decoder.decoder.0.bias: 7.156820969189681e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.00045887319720350206\n",
      "Gradient for decoder.decoder.1.bias: 0.0003586083184927702\n",
      "Gradient for decoder.decoder.3.weight: 0.008754945360124111\n",
      "Gradient for decoder.decoder.3.bias: 1.3296602707768557e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0010500018252059817\n",
      "Gradient for decoder.decoder.4.bias: 0.0013264167355373502\n",
      "Gradient for decoder.decoder.6.weight: 0.0008002279209904373\n",
      "Gradient for decoder.decoder.6.bias: 7.251545321196318e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.017266428098082542\n",
      "Gradient for encoder.encoder.0.bias: 3.4468632809092625e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0019352748058736324\n",
      "Gradient for encoder.encoder.1.bias: 0.0017139142146334052\n",
      "Gradient for encoder.encoder.3.weight: 0.03679228201508522\n",
      "Gradient for encoder.encoder.3.bias: 2.412855748534781e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.005322115030139685\n",
      "Gradient for encoder.encoder.4.bias: 0.005893760826438665\n",
      "Gradient for encoder.mean.weight: 0.07538880407810211\n",
      "Gradient for encoder.mean.bias: 0.004988537635654211\n",
      "Gradient for encoder.log_var.weight: 0.04115760698914528\n",
      "Gradient for encoder.log_var.bias: 0.0032193223014473915\n",
      "Gradient for decoder.decoder.0.weight: 0.009975130669772625\n",
      "Gradient for decoder.decoder.0.bias: 8.111611382588535e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.000486149889184162\n",
      "Gradient for decoder.decoder.1.bias: 0.0003960070898756385\n",
      "Gradient for decoder.decoder.3.weight: 0.009090503677725792\n",
      "Gradient for decoder.decoder.3.bias: 1.4733131381561293e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0011562828440219164\n",
      "Gradient for decoder.decoder.4.bias: 0.0015133609995245934\n",
      "Gradient for decoder.decoder.6.weight: 0.0008482213015668094\n",
      "Gradient for decoder.decoder.6.bias: 8.26629766379483e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.01723271980881691\n",
      "Gradient for encoder.encoder.0.bias: 2.3186593270385636e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0017922658007591963\n",
      "Gradient for encoder.encoder.1.bias: 0.0011735452571883798\n",
      "Gradient for encoder.encoder.3.weight: 0.03720211982727051\n",
      "Gradient for encoder.encoder.3.bias: 2.1085400092601958e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0061290995217859745\n",
      "Gradient for encoder.encoder.4.bias: 0.004064700100570917\n",
      "Gradient for encoder.mean.weight: 0.07930847257375717\n",
      "Gradient for encoder.mean.bias: 0.00267972843721509\n",
      "Gradient for encoder.log_var.weight: 0.04862075671553612\n",
      "Gradient for encoder.log_var.bias: 0.0017887784633785486\n",
      "Gradient for decoder.decoder.0.weight: 0.011753929778933525\n",
      "Gradient for decoder.decoder.0.bias: 1.0026186825218275e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0005976380198262632\n",
      "Gradient for decoder.decoder.1.bias: 0.0004968682769685984\n",
      "Gradient for decoder.decoder.3.weight: 0.010699658654630184\n",
      "Gradient for decoder.decoder.3.bias: 1.0142611750474373e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.000573389173951\n",
      "Gradient for decoder.decoder.4.bias: 0.0006423983722925186\n",
      "Gradient for decoder.decoder.6.weight: 0.0006302337278611958\n",
      "Gradient for decoder.decoder.6.bias: 4.568244912661612e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.01977246254682541\n",
      "Gradient for encoder.encoder.0.bias: 2.957294825689516e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.001374375307932496\n",
      "Gradient for encoder.encoder.1.bias: 0.0010408279486000538\n",
      "Gradient for encoder.encoder.3.weight: 0.029159745201468468\n",
      "Gradient for encoder.encoder.3.bias: 2.8142765895466937e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0054110088385641575\n",
      "Gradient for encoder.encoder.4.bias: 0.0067085446789860725\n",
      "Gradient for encoder.mean.weight: 0.0718977078795433\n",
      "Gradient for encoder.mean.bias: 0.0047625149600207806\n",
      "Gradient for encoder.log_var.weight: 0.047750912606716156\n",
      "Gradient for encoder.log_var.bias: 0.00390152377076447\n",
      "Gradient for decoder.decoder.0.weight: 0.01079747173935175\n",
      "Gradient for decoder.decoder.0.bias: 8.730208916896132e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.000537521846126765\n",
      "Gradient for decoder.decoder.1.bias: 0.00044707668712362647\n",
      "Gradient for decoder.decoder.3.weight: 0.010405060835182667\n",
      "Gradient for decoder.decoder.3.bias: 1.3765762141293436e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0009389278129674494\n",
      "Gradient for decoder.decoder.4.bias: 0.0012111219111829996\n",
      "Gradient for decoder.decoder.6.weight: 0.0007356721325777471\n",
      "Gradient for decoder.decoder.6.bias: 6.572745041921735e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.014356369152665138\n",
      "Gradient for encoder.encoder.0.bias: 2.4846263935174306e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0015174713917076588\n",
      "Gradient for encoder.encoder.1.bias: 0.0012799467658624053\n",
      "Gradient for encoder.encoder.3.weight: 0.03358575329184532\n",
      "Gradient for encoder.encoder.3.bias: 2.4859619918160547e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.005002875346690416\n",
      "Gradient for encoder.encoder.4.bias: 0.004811691120266914\n",
      "Gradient for encoder.mean.weight: 0.0688662976026535\n",
      "Gradient for encoder.mean.bias: 0.0036811514291912317\n",
      "Gradient for encoder.log_var.weight: 0.03363701328635216\n",
      "Gradient for encoder.log_var.bias: 0.002035542158409953\n",
      "Gradient for decoder.decoder.0.weight: 0.011395703069865704\n",
      "Gradient for decoder.decoder.0.bias: 9.436205983259782e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0006055610137991607\n",
      "Gradient for decoder.decoder.1.bias: 0.00042970723006874323\n",
      "Gradient for decoder.decoder.3.weight: 0.010723340325057507\n",
      "Gradient for decoder.decoder.3.bias: 9.867604650048989e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0004526973934844136\n",
      "Gradient for decoder.decoder.4.bias: 0.0005129338824190199\n",
      "Gradient for decoder.decoder.6.weight: 0.000596563215367496\n",
      "Gradient for decoder.decoder.6.bias: 4.1835533920675516e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.015965435653924942\n",
      "Gradient for encoder.encoder.0.bias: 2.141993180049262e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0013641971163451672\n",
      "Gradient for encoder.encoder.1.bias: 0.001172805787064135\n",
      "Gradient for encoder.encoder.3.weight: 0.030802519991993904\n",
      "Gradient for encoder.encoder.3.bias: 2.628071371635343e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.005952432751655579\n",
      "Gradient for encoder.encoder.4.bias: 0.006421494297683239\n",
      "Gradient for encoder.mean.weight: 0.08071573823690414\n",
      "Gradient for encoder.mean.bias: 0.00542973168194294\n",
      "Gradient for encoder.log_var.weight: 0.04494689777493477\n",
      "Gradient for encoder.log_var.bias: 0.0031027398072183132\n",
      "Gradient for decoder.decoder.0.weight: 0.011435780674219131\n",
      "Gradient for decoder.decoder.0.bias: 9.074353768401267e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005745133385062218\n",
      "Gradient for decoder.decoder.1.bias: 0.00044564250856637955\n",
      "Gradient for decoder.decoder.3.weight: 0.010629893280565739\n",
      "Gradient for decoder.decoder.3.bias: 1.0499864172563989e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0007039371994324028\n",
      "Gradient for decoder.decoder.4.bias: 0.0008706363732926548\n",
      "Gradient for decoder.decoder.6.weight: 0.0006346862646751106\n",
      "Gradient for decoder.decoder.6.bias: 5.078994217910804e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.02104981802403927\n",
      "Gradient for encoder.encoder.0.bias: 3.4419685851494464e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.001978564076125622\n",
      "Gradient for encoder.encoder.1.bias: 0.0015317918732762337\n",
      "Gradient for encoder.encoder.3.weight: 0.04365670308470726\n",
      "Gradient for encoder.encoder.3.bias: 3.133850956515971e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.006731237750500441\n",
      "Gradient for encoder.encoder.4.bias: 0.008029595017433167\n",
      "Gradient for encoder.mean.weight: 0.09277883917093277\n",
      "Gradient for encoder.mean.bias: 0.006481348071247339\n",
      "Gradient for encoder.log_var.weight: 0.054858237504959106\n",
      "Gradient for encoder.log_var.bias: 0.004036124795675278\n",
      "Gradient for decoder.decoder.0.weight: 0.00972968339920044\n",
      "Gradient for decoder.decoder.0.bias: 8.460936812282327e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0004952275194227695\n",
      "Gradient for decoder.decoder.1.bias: 0.00036600587191060185\n",
      "Gradient for decoder.decoder.3.weight: 0.008480856195092201\n",
      "Gradient for decoder.decoder.3.bias: 1.3199072390612798e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0009619514457881451\n",
      "Gradient for decoder.decoder.4.bias: 0.001238164259120822\n",
      "Gradient for decoder.decoder.6.weight: 0.0007473465520888567\n",
      "Gradient for decoder.decoder.6.bias: 7.017674943199381e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.014744019135832787\n",
      "Gradient for encoder.encoder.0.bias: 2.3343762686756087e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0017516979714855552\n",
      "Gradient for encoder.encoder.1.bias: 0.0013864283682778478\n",
      "Gradient for encoder.encoder.3.weight: 0.037028685212135315\n",
      "Gradient for encoder.encoder.3.bias: 2.1758128632143325e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.004811550490558147\n",
      "Gradient for encoder.encoder.4.bias: 0.004241972230374813\n",
      "Gradient for encoder.mean.weight: 0.06560137867927551\n",
      "Gradient for encoder.mean.bias: 0.003364888485521078\n",
      "Gradient for encoder.log_var.weight: 0.03806789591908455\n",
      "Gradient for encoder.log_var.bias: 0.0017962891142815351\n",
      "Gradient for decoder.decoder.0.weight: 0.011581097729504108\n",
      "Gradient for decoder.decoder.0.bias: 9.985309801230358e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005734955193474889\n",
      "Gradient for decoder.decoder.1.bias: 0.0004662085557356477\n",
      "Gradient for decoder.decoder.3.weight: 0.010940364561975002\n",
      "Gradient for decoder.decoder.3.bias: 1.0963208119108003e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0006512755062431097\n",
      "Gradient for decoder.decoder.4.bias: 0.0007317144190892577\n",
      "Gradient for decoder.decoder.6.weight: 0.0006380395498126745\n",
      "Gradient for decoder.decoder.6.bias: 4.828683449886739e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.011496391147375107\n",
      "Gradient for encoder.encoder.0.bias: 2.0162614633445486e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0011727552628144622\n",
      "Gradient for encoder.encoder.1.bias: 0.0011402149684727192\n",
      "Gradient for encoder.encoder.3.weight: 0.027222225442528725\n",
      "Gradient for encoder.encoder.3.bias: 2.389888842380117e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.006041211076080799\n",
      "Gradient for encoder.encoder.4.bias: 0.00509526627138257\n",
      "Gradient for encoder.mean.weight: 0.07520236074924469\n",
      "Gradient for encoder.mean.bias: 0.003478964325040579\n",
      "Gradient for encoder.log_var.weight: 0.04449310153722763\n",
      "Gradient for encoder.log_var.bias: 0.002278912113979459\n",
      "Gradient for decoder.decoder.0.weight: 0.011727064847946167\n",
      "Gradient for decoder.decoder.0.bias: 8.438833659640821e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005633831606246531\n",
      "Gradient for decoder.decoder.1.bias: 0.00047957710921764374\n",
      "Gradient for decoder.decoder.3.weight: 0.010924700647592545\n",
      "Gradient for decoder.decoder.3.bias: 9.376841664243685e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0004909215494990349\n",
      "Gradient for decoder.decoder.4.bias: 0.0005299667245708406\n",
      "Gradient for decoder.decoder.6.weight: 0.000549563963431865\n",
      "Gradient for decoder.decoder.6.bias: 3.559799733920954e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.016503291204571724\n",
      "Gradient for encoder.encoder.0.bias: 1.9602718753786164e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.001731709809973836\n",
      "Gradient for encoder.encoder.1.bias: 0.0013587577268481255\n",
      "Gradient for encoder.encoder.3.weight: 0.035541363060474396\n",
      "Gradient for encoder.encoder.3.bias: 2.5119203939105716e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.005060156341642141\n",
      "Gradient for encoder.encoder.4.bias: 0.005686214659363031\n",
      "Gradient for encoder.mean.weight: 0.0708175078034401\n",
      "Gradient for encoder.mean.bias: 0.004495829809457064\n",
      "Gradient for encoder.log_var.weight: 0.043870046734809875\n",
      "Gradient for encoder.log_var.bias: 0.003336492460221052\n",
      "Gradient for decoder.decoder.0.weight: 0.012879036366939545\n",
      "Gradient for decoder.decoder.0.bias: 1.16549186968129e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0006566506344825029\n",
      "Gradient for decoder.decoder.1.bias: 0.0005307947285473347\n",
      "Gradient for decoder.decoder.3.weight: 0.011600486002862453\n",
      "Gradient for decoder.decoder.3.bias: 1.246263925391844e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0007794896373525262\n",
      "Gradient for decoder.decoder.4.bias: 0.0009628956322558224\n",
      "Gradient for decoder.decoder.6.weight: 0.0006455192342400551\n",
      "Gradient for decoder.decoder.6.bias: 5.215300552663393e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.015521152876317501\n",
      "Gradient for encoder.encoder.0.bias: 2.5112413884476048e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.001638547400943935\n",
      "Gradient for encoder.encoder.1.bias: 0.0012650338467210531\n",
      "Gradient for encoder.encoder.3.weight: 0.033258892595767975\n",
      "Gradient for encoder.encoder.3.bias: 2.0140149270542196e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.005004027858376503\n",
      "Gradient for encoder.encoder.4.bias: 0.004915976896882057\n",
      "Gradient for encoder.mean.weight: 0.06932879984378815\n",
      "Gradient for encoder.mean.bias: 0.003417921019718051\n",
      "Gradient for encoder.log_var.weight: 0.040714628994464874\n",
      "Gradient for encoder.log_var.bias: 0.0027522356249392033\n",
      "Gradient for decoder.decoder.0.weight: 0.012079318054020405\n",
      "Gradient for decoder.decoder.0.bias: 1.0299287117598865e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0006357610109262168\n",
      "Gradient for decoder.decoder.1.bias: 0.0005047517479397357\n",
      "Gradient for decoder.decoder.3.weight: 0.011318786069750786\n",
      "Gradient for decoder.decoder.3.bias: 1.1123604815033161e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0008206944912672043\n",
      "Gradient for decoder.decoder.4.bias: 0.0010186107829213142\n",
      "Gradient for decoder.decoder.6.weight: 0.0006547396187670529\n",
      "Gradient for decoder.decoder.6.bias: 5.591935769189149e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.016495561227202415\n",
      "Gradient for encoder.encoder.0.bias: 1.9580562865550988e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0016135892365127802\n",
      "Gradient for encoder.encoder.1.bias: 0.001558122574351728\n",
      "Gradient for encoder.encoder.3.weight: 0.032939113676548004\n",
      "Gradient for encoder.encoder.3.bias: 2.898503381754125e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.008450988680124283\n",
      "Gradient for encoder.encoder.4.bias: 0.005731015000492334\n",
      "Gradient for encoder.mean.weight: 0.10263878107070923\n",
      "Gradient for encoder.mean.bias: 0.0033832849003374577\n",
      "Gradient for encoder.log_var.weight: 0.0611240416765213\n",
      "Gradient for encoder.log_var.bias: 0.0017202545423060656\n",
      "Gradient for decoder.decoder.0.weight: 0.014374648220837116\n",
      "Gradient for decoder.decoder.0.bias: 1.175863295621582e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0007759935688227415\n",
      "Gradient for decoder.decoder.1.bias: 0.0005580896395258605\n",
      "Gradient for decoder.decoder.3.weight: 0.013265653513371944\n",
      "Gradient for decoder.decoder.3.bias: 1.145624914378196e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0006795394001528621\n",
      "Gradient for decoder.decoder.4.bias: 0.0007690087077207863\n",
      "Gradient for decoder.decoder.6.weight: 0.000571750570088625\n",
      "Gradient for decoder.decoder.6.bias: 3.756525256903842e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.011837114579975605\n",
      "Gradient for encoder.encoder.0.bias: 2.210529849444587e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0010113228345289826\n",
      "Gradient for encoder.encoder.1.bias: 0.0009655854082666337\n",
      "Gradient for encoder.encoder.3.weight: 0.023189205676317215\n",
      "Gradient for encoder.encoder.3.bias: 3.3661212706093124e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.009639285504817963\n",
      "Gradient for encoder.encoder.4.bias: 0.008550290949642658\n",
      "Gradient for encoder.mean.weight: 0.12424582988023758\n",
      "Gradient for encoder.mean.bias: 0.005211760755628347\n",
      "Gradient for encoder.log_var.weight: 0.07497764378786087\n",
      "Gradient for encoder.log_var.bias: 0.003126947209239006\n",
      "Gradient for decoder.decoder.0.weight: 0.011412154883146286\n",
      "Gradient for decoder.decoder.0.bias: 9.399887118677341e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005875953356735408\n",
      "Gradient for decoder.decoder.1.bias: 0.00046311374171637\n",
      "Gradient for decoder.decoder.3.weight: 0.01098702009767294\n",
      "Gradient for decoder.decoder.3.bias: 9.54469281388981e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0005933799548074603\n",
      "Gradient for decoder.decoder.4.bias: 0.0006709506269544363\n",
      "Gradient for decoder.decoder.6.weight: 0.0005406796117313206\n",
      "Gradient for decoder.decoder.6.bias: 3.696040585055016e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.017326606437563896\n",
      "Gradient for encoder.encoder.0.bias: 2.7414164688321918e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0017341722268611193\n",
      "Gradient for encoder.encoder.1.bias: 0.0015112627297639847\n",
      "Gradient for encoder.encoder.3.weight: 0.03728345036506653\n",
      "Gradient for encoder.encoder.3.bias: 2.583799563193878e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.006193900015205145\n",
      "Gradient for encoder.encoder.4.bias: 0.0052080522291362286\n",
      "Gradient for encoder.mean.weight: 0.07821319252252579\n",
      "Gradient for encoder.mean.bias: 0.0029467912390828133\n",
      "Gradient for encoder.log_var.weight: 0.049421168863773346\n",
      "Gradient for encoder.log_var.bias: 0.002272527664899826\n",
      "Gradient for decoder.decoder.0.weight: 0.010610423982143402\n",
      "Gradient for decoder.decoder.0.bias: 9.041708354251554e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005591921508312225\n",
      "Gradient for decoder.decoder.1.bias: 0.00043915948481298983\n",
      "Gradient for decoder.decoder.3.weight: 0.010486122220754623\n",
      "Gradient for decoder.decoder.3.bias: 8.183748817502945e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0004038970510009676\n",
      "Gradient for decoder.decoder.4.bias: 0.0003897489805240184\n",
      "Gradient for decoder.decoder.6.weight: 0.0005257065640762448\n",
      "Gradient for decoder.decoder.6.bias: 2.9043831091257744e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.015106415376067162\n",
      "Gradient for encoder.encoder.0.bias: 2.492010590937621e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0018927804194390774\n",
      "Gradient for encoder.encoder.1.bias: 0.001645276672206819\n",
      "Gradient for encoder.encoder.3.weight: 0.03924163803458214\n",
      "Gradient for encoder.encoder.3.bias: 2.0494694830119897e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.004177639726549387\n",
      "Gradient for encoder.encoder.4.bias: 0.0037195750046521425\n",
      "Gradient for encoder.mean.weight: 0.059435851871967316\n",
      "Gradient for encoder.mean.bias: 0.00282531906850636\n",
      "Gradient for encoder.log_var.weight: 0.0340762697160244\n",
      "Gradient for encoder.log_var.bias: 0.0017979498952627182\n",
      "Gradient for decoder.decoder.0.weight: 0.011941526085138321\n",
      "Gradient for decoder.decoder.0.bias: 1.0543222545011943e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0006436021067202091\n",
      "Gradient for decoder.decoder.1.bias: 0.00048626860370859504\n",
      "Gradient for decoder.decoder.3.weight: 0.011202368885278702\n",
      "Gradient for decoder.decoder.3.bias: 1.0265430172573531e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0005512625211849809\n",
      "Gradient for decoder.decoder.4.bias: 0.0006376716191880405\n",
      "Gradient for decoder.decoder.6.weight: 0.0005311262793838978\n",
      "Gradient for decoder.decoder.6.bias: 3.4863827750086784e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.013271607458591461\n",
      "Gradient for encoder.encoder.0.bias: 1.9090716854575085e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0012326345313340425\n",
      "Gradient for encoder.encoder.1.bias: 0.0009603437501937151\n",
      "Gradient for encoder.encoder.3.weight: 0.025462672114372253\n",
      "Gradient for encoder.encoder.3.bias: 1.9084933633450873e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.003965811803936958\n",
      "Gradient for encoder.encoder.4.bias: 0.0033038270194083452\n",
      "Gradient for encoder.mean.weight: 0.053220491856336594\n",
      "Gradient for encoder.mean.bias: 0.0027324743568897247\n",
      "Gradient for encoder.log_var.weight: 0.03214947134256363\n",
      "Gradient for encoder.log_var.bias: 0.0015680117066949606\n",
      "Gradient for decoder.decoder.0.weight: 0.01205422356724739\n",
      "Gradient for decoder.decoder.0.bias: 1.0414843987227584e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0006047890055924654\n",
      "Gradient for decoder.decoder.1.bias: 0.0004988836008124053\n",
      "Gradient for decoder.decoder.3.weight: 0.010972650721669197\n",
      "Gradient for decoder.decoder.3.bias: 8.631826503568973e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00039294210728257895\n",
      "Gradient for decoder.decoder.4.bias: 0.0003843649465125054\n",
      "Gradient for decoder.decoder.6.weight: 0.0005171617376618087\n",
      "Gradient for decoder.decoder.6.bias: 3.138019746984355e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.015341335907578468\n",
      "Gradient for encoder.encoder.0.bias: 2.813773693211008e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0015997833106666803\n",
      "Gradient for encoder.encoder.1.bias: 0.001435481826774776\n",
      "Gradient for encoder.encoder.3.weight: 0.03171221911907196\n",
      "Gradient for encoder.encoder.3.bias: 2.1853899245805053e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.004573196172714233\n",
      "Gradient for encoder.encoder.4.bias: 0.004539782647043467\n",
      "Gradient for encoder.mean.weight: 0.05927770584821701\n",
      "Gradient for encoder.mean.bias: 0.003614994930103421\n",
      "Gradient for encoder.log_var.weight: 0.03615159913897514\n",
      "Gradient for encoder.log_var.bias: 0.0026152459904551506\n",
      "Gradient for decoder.decoder.0.weight: 0.010695293545722961\n",
      "Gradient for decoder.decoder.0.bias: 9.342920881394434e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0004931456060148776\n",
      "Gradient for decoder.decoder.1.bias: 0.0004117569187656045\n",
      "Gradient for decoder.decoder.3.weight: 0.010053652338683605\n",
      "Gradient for decoder.decoder.3.bias: 9.498887093561947e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0005246922373771667\n",
      "Gradient for decoder.decoder.4.bias: 0.000575879355892539\n",
      "Gradient for decoder.decoder.6.weight: 0.0005452943732962012\n",
      "Gradient for decoder.decoder.6.bias: 3.952685801777989e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training VAE Epoch:  56%|█████▌    | 44/79 [00:00<00:00, 74.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient for encoder.encoder.0.weight: 0.03700783848762512\n",
      "Gradient for encoder.encoder.0.bias: 7.070857788171736e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0035101210232824087\n",
      "Gradient for encoder.encoder.1.bias: 0.0022241584956645966\n",
      "Gradient for encoder.encoder.3.weight: 0.0763712227344513\n",
      "Gradient for encoder.encoder.3.bias: 4.2520389986755447e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.011628624983131886\n",
      "Gradient for encoder.encoder.4.bias: 0.009849490597844124\n",
      "Gradient for encoder.mean.weight: 0.14509563148021698\n",
      "Gradient for encoder.mean.bias: 0.006004166789352894\n",
      "Gradient for encoder.log_var.weight: 0.08666470646858215\n",
      "Gradient for encoder.log_var.bias: 0.0035933731123805046\n",
      "Gradient for decoder.decoder.0.weight: 0.0071511222049593925\n",
      "Gradient for decoder.decoder.0.bias: 6.193238283325186e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0003800430567935109\n",
      "Gradient for decoder.decoder.1.bias: 0.0002853337209671736\n",
      "Gradient for decoder.decoder.3.weight: 0.006965557113289833\n",
      "Gradient for decoder.decoder.3.bias: 1.0734856753513711e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0008629217627458274\n",
      "Gradient for decoder.decoder.4.bias: 0.0010986534180119634\n",
      "Gradient for decoder.decoder.6.weight: 0.0006460965960286558\n",
      "Gradient for decoder.decoder.6.bias: 5.886092912987806e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.019681166857481003\n",
      "Gradient for encoder.encoder.0.bias: 3.572209889002309e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.001586258178576827\n",
      "Gradient for encoder.encoder.1.bias: 0.0013020370388403535\n",
      "Gradient for encoder.encoder.3.weight: 0.03701002895832062\n",
      "Gradient for encoder.encoder.3.bias: 2.389735076491206e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.005060160998255014\n",
      "Gradient for encoder.encoder.4.bias: 0.004648164380341768\n",
      "Gradient for encoder.mean.weight: 0.06683729588985443\n",
      "Gradient for encoder.mean.bias: 0.0031999240163713694\n",
      "Gradient for encoder.log_var.weight: 0.04263733699917793\n",
      "Gradient for encoder.log_var.bias: 0.002004497218877077\n",
      "Gradient for decoder.decoder.0.weight: 0.009840759448707104\n",
      "Gradient for decoder.decoder.0.bias: 8.224380898536054e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005053540808148682\n",
      "Gradient for decoder.decoder.1.bias: 0.0003851859364658594\n",
      "Gradient for decoder.decoder.3.weight: 0.00965024996548891\n",
      "Gradient for decoder.decoder.3.bias: 7.726524281492786e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0004501348012126982\n",
      "Gradient for decoder.decoder.4.bias: 0.0005145659088157117\n",
      "Gradient for decoder.decoder.6.weight: 0.0005156233673915267\n",
      "Gradient for decoder.decoder.6.bias: 3.3740292565198615e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.0165909044444561\n",
      "Gradient for encoder.encoder.0.bias: 2.961537959311755e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0017932102782651782\n",
      "Gradient for encoder.encoder.1.bias: 0.0011970165651291609\n",
      "Gradient for encoder.encoder.3.weight: 0.03585800901055336\n",
      "Gradient for encoder.encoder.3.bias: 2.014250016779684e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.005136819556355476\n",
      "Gradient for encoder.encoder.4.bias: 0.0044656661339104176\n",
      "Gradient for encoder.mean.weight: 0.06550557911396027\n",
      "Gradient for encoder.mean.bias: 0.003108114004135132\n",
      "Gradient for encoder.log_var.weight: 0.03759344294667244\n",
      "Gradient for encoder.log_var.bias: 0.0017887118738144636\n",
      "Gradient for decoder.decoder.0.weight: 0.008886801078915596\n",
      "Gradient for decoder.decoder.0.bias: 7.089213244215742e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0004460916097741574\n",
      "Gradient for decoder.decoder.1.bias: 0.0003408776829019189\n",
      "Gradient for decoder.decoder.3.weight: 0.008243241347372532\n",
      "Gradient for decoder.decoder.3.bias: 1.1088325396757526e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0008754779119044542\n",
      "Gradient for decoder.decoder.4.bias: 0.0010856060544028878\n",
      "Gradient for decoder.decoder.6.weight: 0.0006232001469470561\n",
      "Gradient for decoder.decoder.6.bias: 5.387818600866012e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.019124776124954224\n",
      "Gradient for encoder.encoder.0.bias: 2.283528227620124e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0017104421276599169\n",
      "Gradient for encoder.encoder.1.bias: 0.0011034357594326138\n",
      "Gradient for encoder.encoder.3.weight: 0.03599897027015686\n",
      "Gradient for encoder.encoder.3.bias: 2.0668729228123794e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.004573078826069832\n",
      "Gradient for encoder.encoder.4.bias: 0.0033582167234271765\n",
      "Gradient for encoder.mean.weight: 0.06279274821281433\n",
      "Gradient for encoder.mean.bias: 0.00257920497097075\n",
      "Gradient for encoder.log_var.weight: 0.03223324939608574\n",
      "Gradient for encoder.log_var.bias: 0.0015603628708049655\n",
      "Gradient for decoder.decoder.0.weight: 0.011071878485381603\n",
      "Gradient for decoder.decoder.0.bias: 9.150045998662648e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005520919803529978\n",
      "Gradient for decoder.decoder.1.bias: 0.00042019502143375576\n",
      "Gradient for decoder.decoder.3.weight: 0.00984612200409174\n",
      "Gradient for decoder.decoder.3.bias: 8.693854663954781e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00046601402573287487\n",
      "Gradient for decoder.decoder.4.bias: 0.0005099589470773935\n",
      "Gradient for decoder.decoder.6.weight: 0.0005111672799102962\n",
      "Gradient for decoder.decoder.6.bias: 3.199156344635412e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.01262901071459055\n",
      "Gradient for encoder.encoder.0.bias: 2.320077290007827e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0015853075310587883\n",
      "Gradient for encoder.encoder.1.bias: 0.0013259899569675326\n",
      "Gradient for encoder.encoder.3.weight: 0.03384305164217949\n",
      "Gradient for encoder.encoder.3.bias: 2.632645490496799e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.007631715387105942\n",
      "Gradient for encoder.encoder.4.bias: 0.0064396983943879604\n",
      "Gradient for encoder.mean.weight: 0.10134701430797577\n",
      "Gradient for encoder.mean.bias: 0.004472778178751469\n",
      "Gradient for encoder.log_var.weight: 0.053167685866355896\n",
      "Gradient for encoder.log_var.bias: 0.0025036598090082407\n",
      "Gradient for decoder.decoder.0.weight: 0.011220247484743595\n",
      "Gradient for decoder.decoder.0.bias: 1.0132673866625197e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0005499450489878654\n",
      "Gradient for decoder.decoder.1.bias: 0.00042826178832910955\n",
      "Gradient for decoder.decoder.3.weight: 0.010457554832100868\n",
      "Gradient for decoder.decoder.3.bias: 1.0147199747123636e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0005305193481035531\n",
      "Gradient for decoder.decoder.4.bias: 0.0005949535989202559\n",
      "Gradient for decoder.decoder.6.weight: 0.0005109758931212127\n",
      "Gradient for decoder.decoder.6.bias: 3.394055238459259e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.010678738355636597\n",
      "Gradient for encoder.encoder.0.bias: 2.222165160215006e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0014472734183073044\n",
      "Gradient for encoder.encoder.1.bias: 0.0017487790901213884\n",
      "Gradient for encoder.encoder.3.weight: 0.03419742360711098\n",
      "Gradient for encoder.encoder.3.bias: 3.462657660602275e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.01481556799262762\n",
      "Gradient for encoder.encoder.4.bias: 0.009154211729764938\n",
      "Gradient for encoder.mean.weight: 0.18737764656543732\n",
      "Gradient for encoder.mean.bias: 0.004774366971105337\n",
      "Gradient for encoder.log_var.weight: 0.10966484993696213\n",
      "Gradient for encoder.log_var.bias: 0.002725317608565092\n",
      "Gradient for decoder.decoder.0.weight: 0.012218236923217773\n",
      "Gradient for decoder.decoder.0.bias: 9.603059319962526e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0006167081301100552\n",
      "Gradient for decoder.decoder.1.bias: 0.00045388989383354783\n",
      "Gradient for decoder.decoder.3.weight: 0.011188899166882038\n",
      "Gradient for decoder.decoder.3.bias: 8.045960425695498e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00048516556853428483\n",
      "Gradient for decoder.decoder.4.bias: 0.0004968149005435407\n",
      "Gradient for decoder.decoder.6.weight: 0.0005442597321234643\n",
      "Gradient for decoder.decoder.6.bias: 3.950636164518073e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.019191639497876167\n",
      "Gradient for encoder.encoder.0.bias: 2.3744211458121e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.002057322533801198\n",
      "Gradient for encoder.encoder.1.bias: 0.0013945401879027486\n",
      "Gradient for encoder.encoder.3.weight: 0.04096144437789917\n",
      "Gradient for encoder.encoder.3.bias: 2.253600361878938e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0044583966955542564\n",
      "Gradient for encoder.encoder.4.bias: 0.0038367698434740305\n",
      "Gradient for encoder.mean.weight: 0.05968647822737694\n",
      "Gradient for encoder.mean.bias: 0.002656107535585761\n",
      "Gradient for encoder.log_var.weight: 0.03493274375796318\n",
      "Gradient for encoder.log_var.bias: 0.0015493270475417376\n",
      "Gradient for decoder.decoder.0.weight: 0.011785093694925308\n",
      "Gradient for decoder.decoder.0.bias: 1.0126542659971705e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0005530244670808315\n",
      "Gradient for decoder.decoder.1.bias: 0.00047301597078330815\n",
      "Gradient for decoder.decoder.3.weight: 0.011025156825780869\n",
      "Gradient for decoder.decoder.3.bias: 8.287780184357274e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0004044809902552515\n",
      "Gradient for decoder.decoder.4.bias: 0.00038435214082710445\n",
      "Gradient for decoder.decoder.6.weight: 0.00047286678454838693\n",
      "Gradient for decoder.decoder.6.bias: 2.6699945010477677e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.016266562044620514\n",
      "Gradient for encoder.encoder.0.bias: 3.21347740084299e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0013325270265340805\n",
      "Gradient for encoder.encoder.1.bias: 0.0011347222607582808\n",
      "Gradient for encoder.encoder.3.weight: 0.02876056730747223\n",
      "Gradient for encoder.encoder.3.bias: 2.164477902466544e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.003802332328632474\n",
      "Gradient for encoder.encoder.4.bias: 0.004051821306347847\n",
      "Gradient for encoder.mean.weight: 0.05383822321891785\n",
      "Gradient for encoder.mean.bias: 0.0034989912528544664\n",
      "Gradient for encoder.log_var.weight: 0.03534013777971268\n",
      "Gradient for encoder.log_var.bias: 0.0022522336803376675\n",
      "Gradient for decoder.decoder.0.weight: 0.008264578878879547\n",
      "Gradient for decoder.decoder.0.bias: 7.965109821705951e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.00041707433410920203\n",
      "Gradient for decoder.decoder.1.bias: 0.0003553569258656353\n",
      "Gradient for decoder.decoder.3.weight: 0.007782963570207357\n",
      "Gradient for decoder.decoder.3.bias: 1.0674806871779907e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0007002984057180583\n",
      "Gradient for decoder.decoder.4.bias: 0.0008861915557645261\n",
      "Gradient for decoder.decoder.6.weight: 0.0005384052637964487\n",
      "Gradient for decoder.decoder.6.bias: 4.528829231276177e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.01850331574678421\n",
      "Gradient for encoder.encoder.0.bias: 2.294934728364062e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0022014505229890347\n",
      "Gradient for encoder.encoder.1.bias: 0.0016933695878833532\n",
      "Gradient for encoder.encoder.3.weight: 0.04225197806954384\n",
      "Gradient for encoder.encoder.3.bias: 2.3664870063555554e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.005691066849976778\n",
      "Gradient for encoder.encoder.4.bias: 0.004515910986810923\n",
      "Gradient for encoder.mean.weight: 0.078008271753788\n",
      "Gradient for encoder.mean.bias: 0.003444791305810213\n",
      "Gradient for encoder.log_var.weight: 0.044654130935668945\n",
      "Gradient for encoder.log_var.bias: 0.0019544900860637426\n",
      "Gradient for decoder.decoder.0.weight: 0.013220652006566525\n",
      "Gradient for decoder.decoder.0.bias: 1.1319847142976514e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0007177829975262284\n",
      "Gradient for decoder.decoder.1.bias: 0.0005368216661736369\n",
      "Gradient for decoder.decoder.3.weight: 0.012400579638779163\n",
      "Gradient for decoder.decoder.3.bias: 8.969761738919502e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00044667726615443826\n",
      "Gradient for decoder.decoder.4.bias: 0.00039272665162570775\n",
      "Gradient for decoder.decoder.6.weight: 0.0005279026227071881\n",
      "Gradient for decoder.decoder.6.bias: 3.3631753467489034e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.0215058084577322\n",
      "Gradient for encoder.encoder.0.bias: 3.860699954172375e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.002436593407765031\n",
      "Gradient for encoder.encoder.1.bias: 0.0015025942120701075\n",
      "Gradient for encoder.encoder.3.weight: 0.050812866538763046\n",
      "Gradient for encoder.encoder.3.bias: 3.084253408225379e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.009440701454877853\n",
      "Gradient for encoder.encoder.4.bias: 0.007709607947617769\n",
      "Gradient for encoder.mean.weight: 0.12241453677415848\n",
      "Gradient for encoder.mean.bias: 0.0038600503467023373\n",
      "Gradient for encoder.log_var.weight: 0.06804663687944412\n",
      "Gradient for encoder.log_var.bias: 0.00206326344050467\n",
      "Gradient for decoder.decoder.0.weight: 0.007628806866705418\n",
      "Gradient for decoder.decoder.0.bias: 6.796545271026133e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.00039252484566532075\n",
      "Gradient for decoder.decoder.1.bias: 0.00034325011074543\n",
      "Gradient for decoder.decoder.3.weight: 0.007360437419265509\n",
      "Gradient for decoder.decoder.3.bias: 8.269394891069481e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0005599020514637232\n",
      "Gradient for decoder.decoder.4.bias: 0.0006616483442485332\n",
      "Gradient for decoder.decoder.6.weight: 0.0004987075226381421\n",
      "Gradient for decoder.decoder.6.bias: 3.696878411574289e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.01440365705639124\n",
      "Gradient for encoder.encoder.0.bias: 2.1773515282430544e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0012922656023874879\n",
      "Gradient for encoder.encoder.1.bias: 0.0009467236814089119\n",
      "Gradient for encoder.encoder.3.weight: 0.028084758669137955\n",
      "Gradient for encoder.encoder.3.bias: 2.087353762059152e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0056291259825229645\n",
      "Gradient for encoder.encoder.4.bias: 0.004313907586038113\n",
      "Gradient for encoder.mean.weight: 0.07537827640771866\n",
      "Gradient for encoder.mean.bias: 0.002774927532300353\n",
      "Gradient for encoder.log_var.weight: 0.03717469796538353\n",
      "Gradient for encoder.log_var.bias: 0.0015766130527481437\n",
      "Gradient for decoder.decoder.0.weight: 0.011255140416324139\n",
      "Gradient for decoder.decoder.0.bias: 9.715950266553364e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005561223952099681\n",
      "Gradient for decoder.decoder.1.bias: 0.00044930988224223256\n",
      "Gradient for decoder.decoder.3.weight: 0.01065724529325962\n",
      "Gradient for decoder.decoder.3.bias: 8.5883467004777e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0003985212242696434\n",
      "Gradient for decoder.decoder.4.bias: 0.0004062954103574157\n",
      "Gradient for decoder.decoder.6.weight: 0.0004883289220742881\n",
      "Gradient for decoder.decoder.6.bias: 2.9984572393004782e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.010524129495024681\n",
      "Gradient for encoder.encoder.0.bias: 1.7582152747608326e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0012878522975370288\n",
      "Gradient for encoder.encoder.1.bias: 0.0012015162501484156\n",
      "Gradient for encoder.encoder.3.weight: 0.02773217484354973\n",
      "Gradient for encoder.encoder.3.bias: 2.430409762332886e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0066497232764959335\n",
      "Gradient for encoder.encoder.4.bias: 0.006309996359050274\n",
      "Gradient for encoder.mean.weight: 0.08539217710494995\n",
      "Gradient for encoder.mean.bias: 0.004906641785055399\n",
      "Gradient for encoder.log_var.weight: 0.048134494572877884\n",
      "Gradient for encoder.log_var.bias: 0.003151894547045231\n",
      "Gradient for decoder.decoder.0.weight: 0.011781608685851097\n",
      "Gradient for decoder.decoder.0.bias: 9.152773677856274e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.00058964011259377\n",
      "Gradient for decoder.decoder.1.bias: 0.0004693657683674246\n",
      "Gradient for decoder.decoder.3.weight: 0.011165565811097622\n",
      "Gradient for decoder.decoder.3.bias: 1.0885709000874044e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0007016591844148934\n",
      "Gradient for decoder.decoder.4.bias: 0.0008536953828297555\n",
      "Gradient for decoder.decoder.6.weight: 0.0005592391826212406\n",
      "Gradient for decoder.decoder.6.bias: 4.504577736952342e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.016106540337204933\n",
      "Gradient for encoder.encoder.0.bias: 2.931827003394005e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.001390268444083631\n",
      "Gradient for encoder.encoder.1.bias: 0.0012427540495991707\n",
      "Gradient for encoder.encoder.3.weight: 0.030098268762230873\n",
      "Gradient for encoder.encoder.3.bias: 2.6214724835327274e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.004528038203716278\n",
      "Gradient for encoder.encoder.4.bias: 0.004933701362460852\n",
      "Gradient for encoder.mean.weight: 0.060814425349235535\n",
      "Gradient for encoder.mean.bias: 0.00355735095217824\n",
      "Gradient for encoder.log_var.weight: 0.036057423800230026\n",
      "Gradient for encoder.log_var.bias: 0.00228775292634964\n",
      "Gradient for decoder.decoder.0.weight: 0.008688176050782204\n",
      "Gradient for decoder.decoder.0.bias: 7.52091722233672e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0004657478420995176\n",
      "Gradient for decoder.decoder.1.bias: 0.0003656805492937565\n",
      "Gradient for decoder.decoder.3.weight: 0.008317502215504646\n",
      "Gradient for decoder.decoder.3.bias: 8.403003293189215e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0005434048362076283\n",
      "Gradient for decoder.decoder.4.bias: 0.0006198984920047224\n",
      "Gradient for decoder.decoder.6.weight: 0.0004726374172605574\n",
      "Gradient for decoder.decoder.6.bias: 3.4685785067267716e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.011545822955667973\n",
      "Gradient for encoder.encoder.0.bias: 1.6416784598405343e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0011732556158676744\n",
      "Gradient for encoder.encoder.1.bias: 0.0009750492754392326\n",
      "Gradient for encoder.encoder.3.weight: 0.02464289963245392\n",
      "Gradient for encoder.encoder.3.bias: 1.7160962928475243e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.004358116537332535\n",
      "Gradient for encoder.encoder.4.bias: 0.003896481590345502\n",
      "Gradient for encoder.mean.weight: 0.059109292924404144\n",
      "Gradient for encoder.mean.bias: 0.0031894727144390345\n",
      "Gradient for encoder.log_var.weight: 0.03425951674580574\n",
      "Gradient for encoder.log_var.bias: 0.001889409264549613\n",
      "Gradient for decoder.decoder.0.weight: 0.013511678203940392\n",
      "Gradient for decoder.decoder.0.bias: 1.0458083010700392e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0006496484274975955\n",
      "Gradient for decoder.decoder.1.bias: 0.0005247099325060844\n",
      "Gradient for decoder.decoder.3.weight: 0.012946052476763725\n",
      "Gradient for decoder.decoder.3.bias: 8.964955167112265e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0004700833233073354\n",
      "Gradient for decoder.decoder.4.bias: 0.0004650024347938597\n",
      "Gradient for decoder.decoder.6.weight: 0.0004856023588217795\n",
      "Gradient for decoder.decoder.6.bias: 2.9232554879854433e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.020061878487467766\n",
      "Gradient for encoder.encoder.0.bias: 3.958090105671275e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.001805408508516848\n",
      "Gradient for encoder.encoder.1.bias: 0.0013792020035907626\n",
      "Gradient for encoder.encoder.3.weight: 0.03577178716659546\n",
      "Gradient for encoder.encoder.3.bias: 2.3004395610648487e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.004674786701798439\n",
      "Gradient for encoder.encoder.4.bias: 0.004836364649236202\n",
      "Gradient for encoder.mean.weight: 0.06518375128507614\n",
      "Gradient for encoder.mean.bias: 0.004010844975709915\n",
      "Gradient for encoder.log_var.weight: 0.03838250786066055\n",
      "Gradient for encoder.log_var.bias: 0.002463129349052906\n",
      "Gradient for decoder.decoder.0.weight: 0.0077523039653897285\n",
      "Gradient for decoder.decoder.0.bias: 6.317961431800967e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0003640114446170628\n",
      "Gradient for decoder.decoder.1.bias: 0.00030145817436277866\n",
      "Gradient for decoder.decoder.3.weight: 0.007233704440295696\n",
      "Gradient for decoder.decoder.3.bias: 7.108000993349961e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.000479872920550406\n",
      "Gradient for decoder.decoder.4.bias: 0.0005826129345223308\n",
      "Gradient for decoder.decoder.6.weight: 0.000503643648698926\n",
      "Gradient for decoder.decoder.6.bias: 3.8840076740598306e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.01760958321392536\n",
      "Gradient for encoder.encoder.0.bias: 2.839301710411135e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0020938038360327482\n",
      "Gradient for encoder.encoder.1.bias: 0.0015503119211643934\n",
      "Gradient for encoder.encoder.3.weight: 0.04158134385943413\n",
      "Gradient for encoder.encoder.3.bias: 2.545359756300769e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.007356168236583471\n",
      "Gradient for encoder.encoder.4.bias: 0.005401100032031536\n",
      "Gradient for encoder.mean.weight: 0.10003054887056351\n",
      "Gradient for encoder.mean.bias: 0.0031234005000442266\n",
      "Gradient for encoder.log_var.weight: 0.052858226001262665\n",
      "Gradient for encoder.log_var.bias: 0.0016995397163555026\n",
      "Gradient for decoder.decoder.0.weight: 0.010007590986788273\n",
      "Gradient for decoder.decoder.0.bias: 8.591357486542606e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005080849514342844\n",
      "Gradient for decoder.decoder.1.bias: 0.00041554670315235853\n",
      "Gradient for decoder.decoder.3.weight: 0.009538580663502216\n",
      "Gradient for decoder.decoder.3.bias: 7.8677883652567e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00042305447277612984\n",
      "Gradient for decoder.decoder.4.bias: 0.0004131796886213124\n",
      "Gradient for decoder.decoder.6.weight: 0.00046248346916399896\n",
      "Gradient for decoder.decoder.6.bias: 3.076968278037384e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.008159189485013485\n",
      "Gradient for encoder.encoder.0.bias: 1.2029572650507081e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0010979693615809083\n",
      "Gradient for encoder.encoder.1.bias: 0.000983137171715498\n",
      "Gradient for encoder.encoder.3.weight: 0.023318545892834663\n",
      "Gradient for encoder.encoder.3.bias: 2.9337915430360795e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.009317385964095592\n",
      "Gradient for encoder.encoder.4.bias: 0.006769388914108276\n",
      "Gradient for encoder.mean.weight: 0.12514595687389374\n",
      "Gradient for encoder.mean.bias: 0.004017655737698078\n",
      "Gradient for encoder.log_var.weight: 0.06753117591142654\n",
      "Gradient for encoder.log_var.bias: 0.0024471613578498363\n",
      "Gradient for decoder.decoder.0.weight: 0.016068873926997185\n",
      "Gradient for decoder.decoder.0.bias: 1.336388222306084e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0007963103707879782\n",
      "Gradient for decoder.decoder.1.bias: 0.0006700808880850673\n",
      "Gradient for decoder.decoder.3.weight: 0.014901302754878998\n",
      "Gradient for decoder.decoder.3.bias: 1.1327119103787808e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0006240337388589978\n",
      "Gradient for decoder.decoder.4.bias: 0.0006420033168978989\n",
      "Gradient for decoder.decoder.6.weight: 0.0005246309447102249\n",
      "Gradient for decoder.decoder.6.bias: 3.0042716389289126e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training VAE Epoch:  78%|███████▊  | 62/79 [00:00<00:00, 78.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient for encoder.encoder.0.weight: 0.01262988243252039\n",
      "Gradient for encoder.encoder.0.bias: 1.6512187450690163e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0013837002916261554\n",
      "Gradient for encoder.encoder.1.bias: 0.001297822454944253\n",
      "Gradient for encoder.encoder.3.weight: 0.029217325150966644\n",
      "Gradient for encoder.encoder.3.bias: 1.9441552534527062e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0051720766350626945\n",
      "Gradient for encoder.encoder.4.bias: 0.0038459114730358124\n",
      "Gradient for encoder.mean.weight: 0.07052268087863922\n",
      "Gradient for encoder.mean.bias: 0.0025660649407655\n",
      "Gradient for encoder.log_var.weight: 0.039546478539705276\n",
      "Gradient for encoder.log_var.bias: 0.0017202068120241165\n",
      "Gradient for decoder.decoder.0.weight: 0.015895791351795197\n",
      "Gradient for decoder.decoder.0.bias: 1.271936722613276e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0008420448866672814\n",
      "Gradient for decoder.decoder.1.bias: 0.0006387737230397761\n",
      "Gradient for decoder.decoder.3.weight: 0.015295770950615406\n",
      "Gradient for decoder.decoder.3.bias: 1.1529795868048254e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0006222041556611657\n",
      "Gradient for decoder.decoder.4.bias: 0.000585026282351464\n",
      "Gradient for decoder.decoder.6.weight: 0.0005617727874778211\n",
      "Gradient for decoder.decoder.6.bias: 3.4886441426351666e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.010814053006470203\n",
      "Gradient for encoder.encoder.0.bias: 1.697190131488835e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0009692126186564565\n",
      "Gradient for encoder.encoder.1.bias: 0.0009279260993935168\n",
      "Gradient for encoder.encoder.3.weight: 0.02209431491792202\n",
      "Gradient for encoder.encoder.3.bias: 1.5624228300037402e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0037120096385478973\n",
      "Gradient for encoder.encoder.4.bias: 0.0035203970037400723\n",
      "Gradient for encoder.mean.weight: 0.04952267184853554\n",
      "Gradient for encoder.mean.bias: 0.002615575445815921\n",
      "Gradient for encoder.log_var.weight: 0.027470320463180542\n",
      "Gradient for encoder.log_var.bias: 0.0014497516676783562\n",
      "Gradient for decoder.decoder.0.weight: 0.012012390419840813\n",
      "Gradient for decoder.decoder.0.bias: 1.043653843901815e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0005769532290287316\n",
      "Gradient for decoder.decoder.1.bias: 0.000496518739964813\n",
      "Gradient for decoder.decoder.3.weight: 0.011302740313112736\n",
      "Gradient for decoder.decoder.3.bias: 8.326371536693244e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00040285338764078915\n",
      "Gradient for decoder.decoder.4.bias: 0.0003712249163072556\n",
      "Gradient for decoder.decoder.6.weight: 0.000453155575087294\n",
      "Gradient for decoder.decoder.6.bias: 2.2469483155873604e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.023386599496006966\n",
      "Gradient for encoder.encoder.0.bias: 3.4529067105548705e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0030895599629729986\n",
      "Gradient for encoder.encoder.1.bias: 0.0022501584608107805\n",
      "Gradient for encoder.encoder.3.weight: 0.05998237803578377\n",
      "Gradient for encoder.encoder.3.bias: 2.950326649653334e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.007628689054399729\n",
      "Gradient for encoder.encoder.4.bias: 0.006277558859437704\n",
      "Gradient for encoder.mean.weight: 0.10258661955595016\n",
      "Gradient for encoder.mean.bias: 0.0033712228760123253\n",
      "Gradient for encoder.log_var.weight: 0.0563877634704113\n",
      "Gradient for encoder.log_var.bias: 0.0017278548330068588\n",
      "Gradient for decoder.decoder.0.weight: 0.01186350267380476\n",
      "Gradient for decoder.decoder.0.bias: 9.63503304918234e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005764996749348938\n",
      "Gradient for decoder.decoder.1.bias: 0.0005245241918601096\n",
      "Gradient for decoder.decoder.3.weight: 0.011348698288202286\n",
      "Gradient for decoder.decoder.3.bias: 9.059585720505581e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0004582504916470498\n",
      "Gradient for decoder.decoder.4.bias: 0.00046279330854304135\n",
      "Gradient for decoder.decoder.6.weight: 0.0005521679413504899\n",
      "Gradient for decoder.decoder.6.bias: 4.1229810449294746e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.011153609491884708\n",
      "Gradient for encoder.encoder.0.bias: 2.0994064126034218e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0011041935067623854\n",
      "Gradient for encoder.encoder.1.bias: 0.0010729784844443202\n",
      "Gradient for encoder.encoder.3.weight: 0.02362179011106491\n",
      "Gradient for encoder.encoder.3.bias: 2.4106219798092354e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.005141571629792452\n",
      "Gradient for encoder.encoder.4.bias: 0.00526551203802228\n",
      "Gradient for encoder.mean.weight: 0.06410602480173111\n",
      "Gradient for encoder.mean.bias: 0.0037098736502230167\n",
      "Gradient for encoder.log_var.weight: 0.044638220220804214\n",
      "Gradient for encoder.log_var.bias: 0.0023576589301228523\n",
      "Gradient for decoder.decoder.0.weight: 0.011330359615385532\n",
      "Gradient for decoder.decoder.0.bias: 9.360150848847226e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005814149044454098\n",
      "Gradient for decoder.decoder.1.bias: 0.00047550315503031015\n",
      "Gradient for decoder.decoder.3.weight: 0.010829644277691841\n",
      "Gradient for decoder.decoder.3.bias: 8.562302256098775e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0003696929197758436\n",
      "Gradient for decoder.decoder.4.bias: 0.0003092135302722454\n",
      "Gradient for decoder.decoder.6.weight: 0.000488436664454639\n",
      "Gradient for decoder.decoder.6.bias: 2.9191178327891976e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.017914194613695145\n",
      "Gradient for encoder.encoder.0.bias: 2.3613720354087597e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0017786102835088968\n",
      "Gradient for encoder.encoder.1.bias: 0.0013065533712506294\n",
      "Gradient for encoder.encoder.3.weight: 0.03897342085838318\n",
      "Gradient for encoder.encoder.3.bias: 2.0361461128270975e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.007381330244243145\n",
      "Gradient for encoder.encoder.4.bias: 0.005304364021867514\n",
      "Gradient for encoder.mean.weight: 0.09971343725919724\n",
      "Gradient for encoder.mean.bias: 0.003015189664438367\n",
      "Gradient for encoder.log_var.weight: 0.05088219791650772\n",
      "Gradient for encoder.log_var.bias: 0.0016810705419629812\n",
      "Gradient for decoder.decoder.0.weight: 0.01019190438091755\n",
      "Gradient for decoder.decoder.0.bias: 8.189612182851747e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005038332310505211\n",
      "Gradient for decoder.decoder.1.bias: 0.0004092474118806422\n",
      "Gradient for decoder.decoder.3.weight: 0.009544837288558483\n",
      "Gradient for decoder.decoder.3.bias: 7.236229671025995e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0004180740797892213\n",
      "Gradient for decoder.decoder.4.bias: 0.0004294461105018854\n",
      "Gradient for decoder.decoder.6.weight: 0.0004470228450372815\n",
      "Gradient for decoder.decoder.6.bias: 2.490469159965869e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.015047842636704445\n",
      "Gradient for encoder.encoder.0.bias: 2.941602864070525e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0016744454624131322\n",
      "Gradient for encoder.encoder.1.bias: 0.001364077441394329\n",
      "Gradient for encoder.encoder.3.weight: 0.036389078944921494\n",
      "Gradient for encoder.encoder.3.bias: 3.335018927685951e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.007774407975375652\n",
      "Gradient for encoder.encoder.4.bias: 0.007238582707941532\n",
      "Gradient for encoder.mean.weight: 0.10387012362480164\n",
      "Gradient for encoder.mean.bias: 0.004170991014689207\n",
      "Gradient for encoder.log_var.weight: 0.061339110136032104\n",
      "Gradient for encoder.log_var.bias: 0.0026037658099085093\n",
      "Gradient for decoder.decoder.0.weight: 0.009167474694550037\n",
      "Gradient for decoder.decoder.0.bias: 7.94931967473822e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.00046752026537433267\n",
      "Gradient for decoder.decoder.1.bias: 0.00037933324347250164\n",
      "Gradient for decoder.decoder.3.weight: 0.008477644994854927\n",
      "Gradient for decoder.decoder.3.bias: 7.489409092897858e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00029523851117119193\n",
      "Gradient for decoder.decoder.4.bias: 0.000272538309218362\n",
      "Gradient for decoder.decoder.6.weight: 0.00042394318734295666\n",
      "Gradient for decoder.decoder.6.bias: 2.5404320695088245e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.012251421809196472\n",
      "Gradient for encoder.encoder.0.bias: 2.1582166609412923e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0011469352757558227\n",
      "Gradient for encoder.encoder.1.bias: 0.0011585025349631906\n",
      "Gradient for encoder.encoder.3.weight: 0.023486414924263954\n",
      "Gradient for encoder.encoder.3.bias: 2.012818661745186e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0053309244103729725\n",
      "Gradient for encoder.encoder.4.bias: 0.004377423785626888\n",
      "Gradient for encoder.mean.weight: 0.06790711730718613\n",
      "Gradient for encoder.mean.bias: 0.003244456136599183\n",
      "Gradient for encoder.log_var.weight: 0.0398595854640007\n",
      "Gradient for encoder.log_var.bias: 0.0017100409604609013\n",
      "Gradient for decoder.decoder.0.weight: 0.010223224759101868\n",
      "Gradient for decoder.decoder.0.bias: 8.996009492889812e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005232942057773471\n",
      "Gradient for decoder.decoder.1.bias: 0.0003966376243624836\n",
      "Gradient for decoder.decoder.3.weight: 0.009274795651435852\n",
      "Gradient for decoder.decoder.3.bias: 9.332269679251937e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0005723703652620316\n",
      "Gradient for decoder.decoder.4.bias: 0.00069120351690799\n",
      "Gradient for decoder.decoder.6.weight: 0.000495842017699033\n",
      "Gradient for decoder.decoder.6.bias: 3.6042361898580566e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.015696564689278603\n",
      "Gradient for encoder.encoder.0.bias: 2.135153338855833e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0010038750478997827\n",
      "Gradient for encoder.encoder.1.bias: 0.0008776718750596046\n",
      "Gradient for encoder.encoder.3.weight: 0.02294158563017845\n",
      "Gradient for encoder.encoder.3.bias: 2.2184028225513686e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0036008397582918406\n",
      "Gradient for encoder.encoder.4.bias: 0.004126740153878927\n",
      "Gradient for encoder.mean.weight: 0.04795418679714203\n",
      "Gradient for encoder.mean.bias: 0.003419239306822419\n",
      "Gradient for encoder.log_var.weight: 0.026065737009048462\n",
      "Gradient for encoder.log_var.bias: 0.001967980992048979\n",
      "Gradient for decoder.decoder.0.weight: 0.010192150250077248\n",
      "Gradient for decoder.decoder.0.bias: 8.597424161482792e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.000488867808599025\n",
      "Gradient for decoder.decoder.1.bias: 0.0004138614749535918\n",
      "Gradient for decoder.decoder.3.weight: 0.009582330472767353\n",
      "Gradient for decoder.decoder.3.bias: 7.432761350845141e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0003555889707058668\n",
      "Gradient for decoder.decoder.4.bias: 0.0003044557524845004\n",
      "Gradient for decoder.decoder.6.weight: 0.0004434980801306665\n",
      "Gradient for decoder.decoder.6.bias: 2.3586673705722205e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.012609308585524559\n",
      "Gradient for encoder.encoder.0.bias: 1.7345767183707395e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.001407090574502945\n",
      "Gradient for encoder.encoder.1.bias: 0.0009969479870051146\n",
      "Gradient for encoder.encoder.3.weight: 0.030899981036782265\n",
      "Gradient for encoder.encoder.3.bias: 1.807510668916379e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.00473010865971446\n",
      "Gradient for encoder.encoder.4.bias: 0.00323469378054142\n",
      "Gradient for encoder.mean.weight: 0.06078588590025902\n",
      "Gradient for encoder.mean.bias: 0.002721944823861122\n",
      "Gradient for encoder.log_var.weight: 0.03534683212637901\n",
      "Gradient for encoder.log_var.bias: 0.0016567326383665204\n",
      "Gradient for decoder.decoder.0.weight: 0.011946680955588818\n",
      "Gradient for decoder.decoder.0.bias: 1.0252985266356873e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0006170573178678751\n",
      "Gradient for decoder.decoder.1.bias: 0.00047241177526302636\n",
      "Gradient for decoder.decoder.3.weight: 0.011027892120182514\n",
      "Gradient for decoder.decoder.3.bias: 8.173356436103063e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0004215893568471074\n",
      "Gradient for decoder.decoder.4.bias: 0.0003473414108157158\n",
      "Gradient for decoder.decoder.6.weight: 0.0004464139055926353\n",
      "Gradient for decoder.decoder.6.bias: 2.1576648578047752e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.015281038358807564\n",
      "Gradient for encoder.encoder.0.bias: 2.2247610004244578e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0012568176025524735\n",
      "Gradient for encoder.encoder.1.bias: 0.001066706725396216\n",
      "Gradient for encoder.encoder.3.weight: 0.02525683492422104\n",
      "Gradient for encoder.encoder.3.bias: 1.662330134655221e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.003007654333487153\n",
      "Gradient for encoder.encoder.4.bias: 0.0030354498885571957\n",
      "Gradient for encoder.mean.weight: 0.041753385215997696\n",
      "Gradient for encoder.mean.bias: 0.002254133578389883\n",
      "Gradient for encoder.log_var.weight: 0.02378341555595398\n",
      "Gradient for encoder.log_var.bias: 0.0012695402838289738\n",
      "Gradient for decoder.decoder.0.weight: 0.010705394670367241\n",
      "Gradient for decoder.decoder.0.bias: 9.170758596965811e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005370925064198673\n",
      "Gradient for decoder.decoder.1.bias: 0.00043534464202821255\n",
      "Gradient for decoder.decoder.3.weight: 0.010163621045649052\n",
      "Gradient for decoder.decoder.3.bias: 8.813313273625667e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0005360928480513394\n",
      "Gradient for decoder.decoder.4.bias: 0.0006084969500079751\n",
      "Gradient for decoder.decoder.6.weight: 0.0004738385323435068\n",
      "Gradient for decoder.decoder.6.bias: 3.309276871732436e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.010870597325265408\n",
      "Gradient for encoder.encoder.0.bias: 2.1247299059057312e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0014145271852612495\n",
      "Gradient for encoder.encoder.1.bias: 0.0015417102258652449\n",
      "Gradient for encoder.encoder.3.weight: 0.030387159436941147\n",
      "Gradient for encoder.encoder.3.bias: 2.3684976202531516e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.006353993434458971\n",
      "Gradient for encoder.encoder.4.bias: 0.004802606534212828\n",
      "Gradient for encoder.mean.weight: 0.08537402749061584\n",
      "Gradient for encoder.mean.bias: 0.003244142048060894\n",
      "Gradient for encoder.log_var.weight: 0.04890168830752373\n",
      "Gradient for encoder.log_var.bias: 0.0018978486768901348\n",
      "Gradient for decoder.decoder.0.weight: 0.01036536879837513\n",
      "Gradient for decoder.decoder.0.bias: 8.724514860558585e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005299408221617341\n",
      "Gradient for decoder.decoder.1.bias: 0.00043943774653598666\n",
      "Gradient for decoder.decoder.3.weight: 0.010006635449826717\n",
      "Gradient for decoder.decoder.3.bias: 7.976596466674479e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0004570296441670507\n",
      "Gradient for decoder.decoder.4.bias: 0.00047872186405584216\n",
      "Gradient for decoder.decoder.6.weight: 0.0004546426353044808\n",
      "Gradient for decoder.decoder.6.bias: 2.9894204999436624e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.01562480442225933\n",
      "Gradient for encoder.encoder.0.bias: 2.4681390611847043e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0018024902092292905\n",
      "Gradient for encoder.encoder.1.bias: 0.0016426675720140338\n",
      "Gradient for encoder.encoder.3.weight: 0.040884677320718765\n",
      "Gradient for encoder.encoder.3.bias: 2.5793056579459517e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.00657348707318306\n",
      "Gradient for encoder.encoder.4.bias: 0.006617459002882242\n",
      "Gradient for encoder.mean.weight: 0.08127711713314056\n",
      "Gradient for encoder.mean.bias: 0.004656246863305569\n",
      "Gradient for encoder.log_var.weight: 0.05412108823657036\n",
      "Gradient for encoder.log_var.bias: 0.0031968841794878244\n",
      "Gradient for decoder.decoder.0.weight: 0.010391518473625183\n",
      "Gradient for decoder.decoder.0.bias: 8.554335712007699e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.000515250489115715\n",
      "Gradient for decoder.decoder.1.bias: 0.0004100662481505424\n",
      "Gradient for decoder.decoder.3.weight: 0.009881142526865005\n",
      "Gradient for decoder.decoder.3.bias: 7.243805555390281e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0003572390414774418\n",
      "Gradient for decoder.decoder.4.bias: 0.0003073640400543809\n",
      "Gradient for decoder.decoder.6.weight: 0.0004603409906849265\n",
      "Gradient for decoder.decoder.6.bias: 2.4495753677911125e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.011764959432184696\n",
      "Gradient for encoder.encoder.0.bias: 1.4055591759931652e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0010927702533081174\n",
      "Gradient for encoder.encoder.1.bias: 0.0008380821091122925\n",
      "Gradient for encoder.encoder.3.weight: 0.022485122084617615\n",
      "Gradient for encoder.encoder.3.bias: 1.6711594608143088e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.00411246856674552\n",
      "Gradient for encoder.encoder.4.bias: 0.0032109459862113\n",
      "Gradient for encoder.mean.weight: 0.051420845091342926\n",
      "Gradient for encoder.mean.bias: 0.0023797443136572838\n",
      "Gradient for encoder.log_var.weight: 0.030834103003144264\n",
      "Gradient for encoder.log_var.bias: 0.0015615698648616672\n",
      "Gradient for decoder.decoder.0.weight: 0.011082018725574017\n",
      "Gradient for decoder.decoder.0.bias: 8.422629954596417e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.000570441538002342\n",
      "Gradient for decoder.decoder.1.bias: 0.0004356582649052143\n",
      "Gradient for decoder.decoder.3.weight: 0.010625855065882206\n",
      "Gradient for decoder.decoder.3.bias: 8.722336741762149e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00045695388689637184\n",
      "Gradient for decoder.decoder.4.bias: 0.0004319684230722487\n",
      "Gradient for decoder.decoder.6.weight: 0.0004498710623010993\n",
      "Gradient for decoder.decoder.6.bias: 2.326850881217979e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.01222888845950365\n",
      "Gradient for encoder.encoder.0.bias: 2.468973116231954e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0008911050972528756\n",
      "Gradient for encoder.encoder.1.bias: 0.0008359510102309287\n",
      "Gradient for encoder.encoder.3.weight: 0.01968107745051384\n",
      "Gradient for encoder.encoder.3.bias: 2.2571954028105523e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.004607455804944038\n",
      "Gradient for encoder.encoder.4.bias: 0.005342324264347553\n",
      "Gradient for encoder.mean.weight: 0.0636972114443779\n",
      "Gradient for encoder.mean.bias: 0.003681338159367442\n",
      "Gradient for encoder.log_var.weight: 0.03554636612534523\n",
      "Gradient for encoder.log_var.bias: 0.002387548564001918\n",
      "Gradient for decoder.decoder.0.weight: 0.009229786694049835\n",
      "Gradient for decoder.decoder.0.bias: 7.820557396120975e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.00045677655725739896\n",
      "Gradient for decoder.decoder.1.bias: 0.0003414338279981166\n",
      "Gradient for decoder.decoder.3.weight: 0.008756703697144985\n",
      "Gradient for decoder.decoder.3.bias: 9.494437180901372e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0006671692826785147\n",
      "Gradient for decoder.decoder.4.bias: 0.0008343830122612417\n",
      "Gradient for decoder.decoder.6.weight: 0.0005048852763138711\n",
      "Gradient for decoder.decoder.6.bias: 4.308800271246582e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.016596989706158638\n",
      "Gradient for encoder.encoder.0.bias: 2.561275497248161e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0018601880874484777\n",
      "Gradient for encoder.encoder.1.bias: 0.0015917842974886298\n",
      "Gradient for encoder.encoder.3.weight: 0.036483146250247955\n",
      "Gradient for encoder.encoder.3.bias: 2.662394193997386e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.006117513868957758\n",
      "Gradient for encoder.encoder.4.bias: 0.006115310825407505\n",
      "Gradient for encoder.mean.weight: 0.08081025630235672\n",
      "Gradient for encoder.mean.bias: 0.00442255474627018\n",
      "Gradient for encoder.log_var.weight: 0.04847811162471771\n",
      "Gradient for encoder.log_var.bias: 0.003060336224734783\n",
      "Gradient for decoder.decoder.0.weight: 0.010548383928835392\n",
      "Gradient for decoder.decoder.0.bias: 8.635119702615768e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0004993464099243283\n",
      "Gradient for decoder.decoder.1.bias: 0.0004221285635139793\n",
      "Gradient for decoder.decoder.3.weight: 0.00957496277987957\n",
      "Gradient for decoder.decoder.3.bias: 8.037217419376574e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0003988110984209925\n",
      "Gradient for decoder.decoder.4.bias: 0.00042710782145150006\n",
      "Gradient for decoder.decoder.6.weight: 0.00045210515963844955\n",
      "Gradient for decoder.decoder.6.bias: 2.8727101380354725e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.010775144211947918\n",
      "Gradient for encoder.encoder.0.bias: 1.815218982070821e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0009669289574958384\n",
      "Gradient for encoder.encoder.1.bias: 0.0009751616744324565\n",
      "Gradient for encoder.encoder.3.weight: 0.02047562599182129\n",
      "Gradient for encoder.encoder.3.bias: 1.7628015713810896e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.005209986120462418\n",
      "Gradient for encoder.encoder.4.bias: 0.0036599752493202686\n",
      "Gradient for encoder.mean.weight: 0.07044728845357895\n",
      "Gradient for encoder.mean.bias: 0.0027360492385923862\n",
      "Gradient for encoder.log_var.weight: 0.036968134343624115\n",
      "Gradient for encoder.log_var.bias: 0.0014962229179218411\n",
      "Gradient for decoder.decoder.0.weight: 0.010850793682038784\n",
      "Gradient for decoder.decoder.0.bias: 9.366325770532313e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.00055117771262303\n",
      "Gradient for decoder.decoder.1.bias: 0.00043894286500290036\n",
      "Gradient for decoder.decoder.3.weight: 0.009854890406131744\n",
      "Gradient for decoder.decoder.3.bias: 9.220163521561631e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00046409733477048576\n",
      "Gradient for decoder.decoder.4.bias: 0.000520441448315978\n",
      "Gradient for decoder.decoder.6.weight: 0.0004358530859462917\n",
      "Gradient for decoder.decoder.6.bias: 2.978757220262196e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.02047581598162651\n",
      "Gradient for encoder.encoder.0.bias: 2.7353322731848984e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.002322839107364416\n",
      "Gradient for encoder.encoder.1.bias: 0.0016143290558829904\n",
      "Gradient for encoder.encoder.3.weight: 0.046949248760938644\n",
      "Gradient for encoder.encoder.3.bias: 3.2038402486556095e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.00709026912227273\n",
      "Gradient for encoder.encoder.4.bias: 0.00692330626770854\n",
      "Gradient for encoder.mean.weight: 0.09071434289216995\n",
      "Gradient for encoder.mean.bias: 0.0044791679829359055\n",
      "Gradient for encoder.log_var.weight: 0.05360053479671478\n",
      "Gradient for encoder.log_var.bias: 0.0027050157077610493\n",
      "Gradient for decoder.decoder.0.weight: 0.011225542053580284\n",
      "Gradient for decoder.decoder.0.bias: 9.198882627847738e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.000543793838005513\n",
      "Gradient for decoder.decoder.1.bias: 0.00044035891187377274\n",
      "Gradient for decoder.decoder.3.weight: 0.01024622842669487\n",
      "Gradient for decoder.decoder.3.bias: 8.162635845021526e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00036631760303862393\n",
      "Gradient for decoder.decoder.4.bias: 0.00032553059281781316\n",
      "Gradient for decoder.decoder.6.weight: 0.00044095353223383427\n",
      "Gradient for decoder.decoder.6.bias: 2.4800507162581198e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient for encoder.encoder.0.weight: 0.012960953637957573\n",
      "Gradient for encoder.encoder.0.bias: 2.3030407442226064e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0015851136995479465\n",
      "Gradient for encoder.encoder.1.bias: 0.001310775289312005\n",
      "Gradient for encoder.encoder.3.weight: 0.03312017768621445\n",
      "Gradient for encoder.encoder.3.bias: 2.112269664733546e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0051663159392774105\n",
      "Gradient for encoder.encoder.4.bias: 0.003923697397112846\n",
      "Gradient for encoder.mean.weight: 0.06849667429924011\n",
      "Gradient for encoder.mean.bias: 0.002501773415133357\n",
      "Gradient for encoder.log_var.weight: 0.038048673421144485\n",
      "Gradient for encoder.log_var.bias: 0.0015847408212721348\n",
      "Gradient for decoder.decoder.0.weight: 0.012903332710266113\n",
      "Gradient for decoder.decoder.0.bias: 1.1051080189838913e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0006239440408535302\n",
      "Gradient for decoder.decoder.1.bias: 0.000484267104184255\n",
      "Gradient for decoder.decoder.3.weight: 0.011856925673782825\n",
      "Gradient for decoder.decoder.3.bias: 9.610304219087595e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00040683516999706626\n",
      "Gradient for decoder.decoder.4.bias: 0.00036467250902205706\n",
      "Gradient for decoder.decoder.6.weight: 0.00042955129174515605\n",
      "Gradient for decoder.decoder.6.bias: 2.4195218429667875e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.011933461762964725\n",
      "Gradient for encoder.encoder.0.bias: 1.9908753465247564e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.00112587318290025\n",
      "Gradient for encoder.encoder.1.bias: 0.0007246397435665131\n",
      "Gradient for encoder.encoder.3.weight: 0.02258160710334778\n",
      "Gradient for encoder.encoder.3.bias: 1.4005577253506374e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0034059996251016855\n",
      "Gradient for encoder.encoder.4.bias: 0.0031192589085549116\n",
      "Gradient for encoder.mean.weight: 0.04473039135336876\n",
      "Gradient for encoder.mean.bias: 0.00262017035856843\n",
      "Gradient for encoder.log_var.weight: 0.02650817111134529\n",
      "Gradient for encoder.log_var.bias: 0.0017118940595537424\n",
      "Gradient for decoder.decoder.0.weight: 0.00989152304828167\n",
      "Gradient for decoder.decoder.0.bias: 7.933854961894582e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005328590050339699\n",
      "Gradient for decoder.decoder.1.bias: 0.00040011078817769885\n",
      "Gradient for decoder.decoder.3.weight: 0.009312886744737625\n",
      "Gradient for decoder.decoder.3.bias: 7.53002590836438e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.000427422346547246\n",
      "Gradient for decoder.decoder.4.bias: 0.0005005000857636333\n",
      "Gradient for decoder.decoder.6.weight: 0.00043038505828008056\n",
      "Gradient for decoder.decoder.6.bias: 2.6056803108076565e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.016568049788475037\n",
      "Gradient for encoder.encoder.0.bias: 2.587916513030475e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0021628665272146463\n",
      "Gradient for encoder.encoder.1.bias: 0.0015351054025813937\n",
      "Gradient for encoder.encoder.3.weight: 0.04326460883021355\n",
      "Gradient for encoder.encoder.3.bias: 2.1846599529418143e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.004578566178679466\n",
      "Gradient for encoder.encoder.4.bias: 0.003876953385770321\n",
      "Gradient for encoder.mean.weight: 0.06268874555826187\n",
      "Gradient for encoder.mean.bias: 0.0028219169471412897\n",
      "Gradient for encoder.log_var.weight: 0.03904817998409271\n",
      "Gradient for encoder.log_var.bias: 0.0018563492922112346\n",
      "Gradient for decoder.decoder.0.weight: 0.01384296827018261\n",
      "Gradient for decoder.decoder.0.bias: 1.197526106055946e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0007057687034830451\n",
      "Gradient for decoder.decoder.1.bias: 0.0005819250363856554\n",
      "Gradient for decoder.decoder.3.weight: 0.012711593881249428\n",
      "Gradient for decoder.decoder.3.bias: 9.702292441682303e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00047171537880785763\n",
      "Gradient for decoder.decoder.4.bias: 0.00043931559775955975\n",
      "Gradient for decoder.decoder.6.weight: 0.0005041984259150922\n",
      "Gradient for decoder.decoder.6.bias: 3.221250881324522e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.021680867299437523\n",
      "Gradient for encoder.encoder.0.bias: 4.3833582596963794e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0030533461831510067\n",
      "Gradient for encoder.encoder.1.bias: 0.0026774222496896982\n",
      "Gradient for encoder.encoder.3.weight: 0.061023689806461334\n",
      "Gradient for encoder.encoder.3.bias: 3.3665864540566304e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.00862193014472723\n",
      "Gradient for encoder.encoder.4.bias: 0.008558465167880058\n",
      "Gradient for encoder.mean.weight: 0.10975437611341476\n",
      "Gradient for encoder.mean.bias: 0.005280175246298313\n",
      "Gradient for encoder.log_var.weight: 0.06147799640893936\n",
      "Gradient for encoder.log_var.bias: 0.002478312700986862\n",
      "Gradient for decoder.decoder.0.weight: 0.008842620067298412\n",
      "Gradient for decoder.decoder.0.bias: 7.780059929629601e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0004905665991827846\n",
      "Gradient for decoder.decoder.1.bias: 0.00036723617813549936\n",
      "Gradient for decoder.decoder.3.weight: 0.008326069451868534\n",
      "Gradient for decoder.decoder.3.bias: 6.576812705549884e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00033470671041868627\n",
      "Gradient for decoder.decoder.4.bias: 0.00033819241798482835\n",
      "Gradient for decoder.decoder.6.weight: 0.0004496559558901936\n",
      "Gradient for decoder.decoder.6.bias: 3.144463335047476e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.013025755062699318\n",
      "Gradient for encoder.encoder.0.bias: 1.9070226300876847e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0013523789821192622\n",
      "Gradient for encoder.encoder.1.bias: 0.001420772634446621\n",
      "Gradient for encoder.encoder.3.weight: 0.028645509853959084\n",
      "Gradient for encoder.encoder.3.bias: 2.5129431868720076e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.00796449277549982\n",
      "Gradient for encoder.encoder.4.bias: 0.005900316406041384\n",
      "Gradient for encoder.mean.weight: 0.10153581947088242\n",
      "Gradient for encoder.mean.bias: 0.002684064209461212\n",
      "Gradient for encoder.log_var.weight: 0.06638734042644501\n",
      "Gradient for encoder.log_var.bias: 0.0017537359381094575\n",
      "Gradient for decoder.decoder.0.weight: 0.010897738859057426\n",
      "Gradient for decoder.decoder.0.bias: 9.52959725020186e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005364575190469623\n",
      "Gradient for decoder.decoder.1.bias: 0.0004075094184372574\n",
      "Gradient for decoder.decoder.3.weight: 0.010024703107774258\n",
      "Gradient for decoder.decoder.3.bias: 9.308349230296997e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0003788813774008304\n",
      "Gradient for decoder.decoder.4.bias: 0.0003915375273209065\n",
      "Gradient for decoder.decoder.6.weight: 0.000410852866480127\n",
      "Gradient for decoder.decoder.6.bias: 2.4810566173982807e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.01865575462579727\n",
      "Gradient for encoder.encoder.0.bias: 3.562456926675672e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0021231716964393854\n",
      "Gradient for encoder.encoder.1.bias: 0.0019051673589274287\n",
      "Gradient for encoder.encoder.3.weight: 0.041700270026922226\n",
      "Gradient for encoder.encoder.3.bias: 2.444585367467056e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.005084814969450235\n",
      "Gradient for encoder.encoder.4.bias: 0.004752188455313444\n",
      "Gradient for encoder.mean.weight: 0.06647258996963501\n",
      "Gradient for encoder.mean.bias: 0.0030414853245019913\n",
      "Gradient for encoder.log_var.weight: 0.041149768978357315\n",
      "Gradient for encoder.log_var.bias: 0.0016683650901541114\n",
      "Gradient for decoder.decoder.0.weight: 0.008348370902240276\n",
      "Gradient for decoder.decoder.0.bias: 7.177412830738916e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.00042571782250888646\n",
      "Gradient for decoder.decoder.1.bias: 0.00032521935645490885\n",
      "Gradient for decoder.decoder.3.weight: 0.007920926436781883\n",
      "Gradient for decoder.decoder.3.bias: 5.962329935327304e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00030719180358573794\n",
      "Gradient for decoder.decoder.4.bias: 0.00027637812308967113\n",
      "Gradient for decoder.decoder.6.weight: 0.0004501520888879895\n",
      "Gradient for decoder.decoder.6.bias: 2.7353848054190166e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.022116195410490036\n",
      "Gradient for encoder.encoder.0.bias: 3.411965501798342e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0021516242995858192\n",
      "Gradient for encoder.encoder.1.bias: 0.0020431457087397575\n",
      "Gradient for encoder.encoder.3.weight: 0.04837127774953842\n",
      "Gradient for encoder.encoder.3.bias: 3.626923761324008e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.00871045421808958\n",
      "Gradient for encoder.encoder.4.bias: 0.009202556684613228\n",
      "Gradient for encoder.mean.weight: 0.1155470609664917\n",
      "Gradient for encoder.mean.bias: 0.006622484885156155\n",
      "Gradient for encoder.log_var.weight: 0.06949188560247421\n",
      "Gradient for encoder.log_var.bias: 0.004780546762049198\n",
      "Gradient for decoder.decoder.0.weight: 0.009124754928052425\n",
      "Gradient for decoder.decoder.0.bias: 8.476571528026611e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0004712045774795115\n",
      "Gradient for decoder.decoder.1.bias: 0.0003627669648267329\n",
      "Gradient for decoder.decoder.3.weight: 0.008451887406408787\n",
      "Gradient for decoder.decoder.3.bias: 6.620411163726914e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.000298457161989063\n",
      "Gradient for decoder.decoder.4.bias: 0.0002534156374167651\n",
      "Gradient for decoder.decoder.6.weight: 0.0004267865151632577\n",
      "Gradient for decoder.decoder.6.bias: 2.1968835426378064e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.01084729004651308\n",
      "Gradient for encoder.encoder.0.bias: 1.4022938192581602e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0009556968580000103\n",
      "Gradient for encoder.encoder.1.bias: 0.0008070961339399219\n",
      "Gradient for encoder.encoder.3.weight: 0.020458564162254333\n",
      "Gradient for encoder.encoder.3.bias: 1.6172474470721454e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0037937930319458246\n",
      "Gradient for encoder.encoder.4.bias: 0.003207153407856822\n",
      "Gradient for encoder.mean.weight: 0.05109386891126633\n",
      "Gradient for encoder.mean.bias: 0.0023577397223562002\n",
      "Gradient for encoder.log_var.weight: 0.02601367048919201\n",
      "Gradient for encoder.log_var.bias: 0.0012762690894305706\n",
      "Gradient for decoder.decoder.0.weight: 0.01209363341331482\n",
      "Gradient for decoder.decoder.0.bias: 9.839837278313723e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0006292467005550861\n",
      "Gradient for decoder.decoder.1.bias: 0.0005034420755691826\n",
      "Gradient for decoder.decoder.3.weight: 0.011279689148068428\n",
      "Gradient for decoder.decoder.3.bias: 8.760896869075552e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.000550096679944545\n",
      "Gradient for decoder.decoder.4.bias: 0.0005954147782176733\n",
      "Gradient for decoder.decoder.6.weight: 0.0005707929376512766\n",
      "Gradient for decoder.decoder.6.bias: 4.277740663383156e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.013461988419294357\n",
      "Gradient for encoder.encoder.0.bias: 1.843073263452233e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0015399049734696746\n",
      "Gradient for encoder.encoder.1.bias: 0.0012206854298710823\n",
      "Gradient for encoder.encoder.3.weight: 0.03177757188677788\n",
      "Gradient for encoder.encoder.3.bias: 2.3508062163557497e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0056182644329965115\n",
      "Gradient for encoder.encoder.4.bias: 0.005481491796672344\n",
      "Gradient for encoder.mean.weight: 0.07447289675474167\n",
      "Gradient for encoder.mean.bias: 0.004168249201029539\n",
      "Gradient for encoder.log_var.weight: 0.03956189006567001\n",
      "Gradient for encoder.log_var.bias: 0.0019563264213502407\n",
      "Gradient for decoder.decoder.0.weight: 0.012592006474733353\n",
      "Gradient for decoder.decoder.0.bias: 1.0910294195864978e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0006650478462688625\n",
      "Gradient for decoder.decoder.1.bias: 0.0005282016354613006\n",
      "Gradient for decoder.decoder.3.weight: 0.012056580744683743\n",
      "Gradient for decoder.decoder.3.bias: 9.72070340887754e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0005710534169338644\n",
      "Gradient for decoder.decoder.4.bias: 0.0005634304252453148\n",
      "Gradient for decoder.decoder.6.weight: 0.0005430092569440603\n",
      "Gradient for decoder.decoder.6.bias: 3.5211403883295134e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.022879891097545624\n",
      "Gradient for encoder.encoder.0.bias: 3.9590858369464854e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.002310794312506914\n",
      "Gradient for encoder.encoder.1.bias: 0.0017906585708260536\n",
      "Gradient for encoder.encoder.3.weight: 0.049130503088235855\n",
      "Gradient for encoder.encoder.3.bias: 3.6304548256538283e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.008241510018706322\n",
      "Gradient for encoder.encoder.4.bias: 0.00878117885440588\n",
      "Gradient for encoder.mean.weight: 0.10501664876937866\n",
      "Gradient for encoder.mean.bias: 0.00635070726275444\n",
      "Gradient for encoder.log_var.weight: 0.06711078435182571\n",
      "Gradient for encoder.log_var.bias: 0.0037387872580438852\n",
      "Gradient for decoder.decoder.0.weight: 0.00855202879756689\n",
      "Gradient for decoder.decoder.0.bias: 7.962091402857752e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.00043497979640960693\n",
      "Gradient for decoder.decoder.1.bias: 0.00036888933391310275\n",
      "Gradient for decoder.decoder.3.weight: 0.00822097435593605\n",
      "Gradient for decoder.decoder.3.bias: 7.977293131622432e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0003800644481088966\n",
      "Gradient for decoder.decoder.4.bias: 0.0004034782468806952\n",
      "Gradient for decoder.decoder.6.weight: 0.00041563567356206477\n",
      "Gradient for decoder.decoder.6.bias: 2.4477707484038547e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.0148085355758667\n",
      "Gradient for encoder.encoder.0.bias: 2.4008205146142103e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.001288777682930231\n",
      "Gradient for encoder.encoder.1.bias: 0.0012660473585128784\n",
      "Gradient for encoder.encoder.3.weight: 0.029201148077845573\n",
      "Gradient for encoder.encoder.3.bias: 2.603357251995675e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.005446937866508961\n",
      "Gradient for encoder.encoder.4.bias: 0.0064092339016497135\n",
      "Gradient for encoder.mean.weight: 0.07118940353393555\n",
      "Gradient for encoder.mean.bias: 0.004597606603056192\n",
      "Gradient for encoder.log_var.weight: 0.04090515896677971\n",
      "Gradient for encoder.log_var.bias: 0.002806606236845255\n",
      "Gradient for decoder.decoder.0.weight: 0.010761345736682415\n",
      "Gradient for decoder.decoder.0.bias: 9.4349410229011e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005185339250601828\n",
      "Gradient for decoder.decoder.1.bias: 0.00040298159001395106\n",
      "Gradient for decoder.decoder.3.weight: 0.00992715172469616\n",
      "Gradient for decoder.decoder.3.bias: 8.31039889681584e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0004600842949002981\n",
      "Gradient for decoder.decoder.4.bias: 0.0005331946304067969\n",
      "Gradient for decoder.decoder.6.weight: 0.00042756268521770835\n",
      "Gradient for decoder.decoder.6.bias: 2.7369560484657995e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.03713115304708481\n",
      "Gradient for encoder.encoder.0.bias: 7.636442866942872e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0025116209872066975\n",
      "Gradient for encoder.encoder.1.bias: 0.0021099501755088568\n",
      "Gradient for encoder.encoder.3.weight: 0.050677113234996796\n",
      "Gradient for encoder.encoder.3.bias: 5.425488946997348e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.011522363871335983\n",
      "Gradient for encoder.encoder.4.bias: 0.011871494352817535\n",
      "Gradient for encoder.mean.weight: 0.14536824822425842\n",
      "Gradient for encoder.mean.bias: 0.00782863050699234\n",
      "Gradient for encoder.log_var.weight: 0.08883529156446457\n",
      "Gradient for encoder.log_var.bias: 0.005087981931865215\n",
      "Gradient for decoder.decoder.0.weight: 0.024506721645593643\n",
      "Gradient for decoder.decoder.0.bias: 1.4882596544030235e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0010347474599257112\n",
      "Gradient for decoder.decoder.1.bias: 0.0009046518243849277\n",
      "Gradient for decoder.decoder.3.weight: 0.021179908886551857\n",
      "Gradient for decoder.decoder.3.bias: 1.6411565162410824e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0008416108903475106\n",
      "Gradient for decoder.decoder.4.bias: 0.0008821245864965022\n",
      "Gradient for decoder.decoder.6.weight: 0.001003943500109017\n",
      "Gradient for decoder.decoder.6.bias: 6.005926479701884e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3, Train Loss: 0.0500, Val Loss: 0.2417\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training VAE Epoch:   0%|          | 0/79 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient for encoder.encoder.0.weight: 0.01849343627691269\n",
      "Gradient for encoder.encoder.0.bias: 3.2795512833194707e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0018435787642374635\n",
      "Gradient for encoder.encoder.1.bias: 0.0013304197927936912\n",
      "Gradient for encoder.encoder.3.weight: 0.0375797338783741\n",
      "Gradient for encoder.encoder.3.bias: 2.742049087789411e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.00594315305352211\n",
      "Gradient for encoder.encoder.4.bias: 0.005658407229930162\n",
      "Gradient for encoder.mean.weight: 0.0775197371840477\n",
      "Gradient for encoder.mean.bias: 0.002895309356972575\n",
      "Gradient for encoder.log_var.weight: 0.04792029410600662\n",
      "Gradient for encoder.log_var.bias: 0.0014819263014942408\n",
      "Gradient for decoder.decoder.0.weight: 0.008255105465650558\n",
      "Gradient for decoder.decoder.0.bias: 7.70227284729863e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0003991827252320945\n",
      "Gradient for decoder.decoder.1.bias: 0.0003292644105385989\n",
      "Gradient for decoder.decoder.3.weight: 0.007743676193058491\n",
      "Gradient for decoder.decoder.3.bias: 6.689301890183685e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0002735968737397343\n",
      "Gradient for decoder.decoder.4.bias: 0.00022899983741808683\n",
      "Gradient for decoder.decoder.6.weight: 0.0003995233273599297\n",
      "Gradient for decoder.decoder.6.bias: 2.2876665752846748e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training VAE Epoch:  11%|█▏        | 9/79 [00:00<00:02, 34.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient for encoder.encoder.0.weight: 0.01204587984830141\n",
      "Gradient for encoder.encoder.0.bias: 1.6164614785596498e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0012602320639416575\n",
      "Gradient for encoder.encoder.1.bias: 0.0010633168276399374\n",
      "Gradient for encoder.encoder.3.weight: 0.02717263624072075\n",
      "Gradient for encoder.encoder.3.bias: 1.8661440448486388e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.005143380258232355\n",
      "Gradient for encoder.encoder.4.bias: 0.0038983041886240244\n",
      "Gradient for encoder.mean.weight: 0.06944669038057327\n",
      "Gradient for encoder.mean.bias: 0.0031340562272816896\n",
      "Gradient for encoder.log_var.weight: 0.03627829626202583\n",
      "Gradient for encoder.log_var.bias: 0.0016778422286733985\n",
      "Gradient for decoder.decoder.0.weight: 0.0123252859339118\n",
      "Gradient for decoder.decoder.0.bias: 9.666671629826595e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0006127493106760085\n",
      "Gradient for decoder.decoder.1.bias: 0.0004986531566828489\n",
      "Gradient for decoder.decoder.3.weight: 0.011527769267559052\n",
      "Gradient for decoder.decoder.3.bias: 8.983484789393259e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.000510502839460969\n",
      "Gradient for decoder.decoder.4.bias: 0.0005278587341308594\n",
      "Gradient for decoder.decoder.6.weight: 0.0004711624060291797\n",
      "Gradient for decoder.decoder.6.bias: 2.6385814635432325e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.01381385326385498\n",
      "Gradient for encoder.encoder.0.bias: 2.0892881175127442e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0013225183356553316\n",
      "Gradient for encoder.encoder.1.bias: 0.0011676831636577845\n",
      "Gradient for encoder.encoder.3.weight: 0.02910712920129299\n",
      "Gradient for encoder.encoder.3.bias: 2.2636816032761686e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.004490223713219166\n",
      "Gradient for encoder.encoder.4.bias: 0.004749036394059658\n",
      "Gradient for encoder.mean.weight: 0.05993116647005081\n",
      "Gradient for encoder.mean.bias: 0.003970520105212927\n",
      "Gradient for encoder.log_var.weight: 0.0329565592110157\n",
      "Gradient for encoder.log_var.bias: 0.0021559428423643112\n",
      "Gradient for decoder.decoder.0.weight: 0.01103148516267538\n",
      "Gradient for decoder.decoder.0.bias: 8.801066819774661e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005303355283103883\n",
      "Gradient for decoder.decoder.1.bias: 0.00043130008270964026\n",
      "Gradient for decoder.decoder.3.weight: 0.010262425988912582\n",
      "Gradient for decoder.decoder.3.bias: 7.674610946750704e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0003836708201561123\n",
      "Gradient for decoder.decoder.4.bias: 0.00033681513741612434\n",
      "Gradient for decoder.decoder.6.weight: 0.0003958834568038583\n",
      "Gradient for decoder.decoder.6.bias: 1.6068890545284376e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.009967830963432789\n",
      "Gradient for encoder.encoder.0.bias: 1.3828037673246918e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0011953094508498907\n",
      "Gradient for encoder.encoder.1.bias: 0.0009849811904132366\n",
      "Gradient for encoder.encoder.3.weight: 0.025744078680872917\n",
      "Gradient for encoder.encoder.3.bias: 2.9054800232408695e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.006903607863932848\n",
      "Gradient for encoder.encoder.4.bias: 0.007644887547940016\n",
      "Gradient for encoder.mean.weight: 0.09134665131568909\n",
      "Gradient for encoder.mean.bias: 0.00609624246135354\n",
      "Gradient for encoder.log_var.weight: 0.05084206908941269\n",
      "Gradient for encoder.log_var.bias: 0.0031900587491691113\n",
      "Gradient for decoder.decoder.0.weight: 0.014452571980655193\n",
      "Gradient for decoder.decoder.0.bias: 1.0363688379699809e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0006836115499027073\n",
      "Gradient for decoder.decoder.1.bias: 0.0005562508013099432\n",
      "Gradient for decoder.decoder.3.weight: 0.013125328347086906\n",
      "Gradient for decoder.decoder.3.bias: 1.0595692379045119e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0006321054534055293\n",
      "Gradient for decoder.decoder.4.bias: 0.0006266689742915332\n",
      "Gradient for decoder.decoder.6.weight: 0.0004976969794370234\n",
      "Gradient for decoder.decoder.6.bias: 2.8118176487623714e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.010780385695397854\n",
      "Gradient for encoder.encoder.0.bias: 1.9283774230216544e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0010417774319648743\n",
      "Gradient for encoder.encoder.1.bias: 0.0011051131878048182\n",
      "Gradient for encoder.encoder.3.weight: 0.023006156086921692\n",
      "Gradient for encoder.encoder.3.bias: 2.333781223828879e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.00598796596750617\n",
      "Gradient for encoder.encoder.4.bias: 0.005458706524223089\n",
      "Gradient for encoder.mean.weight: 0.07908283174037933\n",
      "Gradient for encoder.mean.bias: 0.004475765861570835\n",
      "Gradient for encoder.log_var.weight: 0.04927008971571922\n",
      "Gradient for encoder.log_var.bias: 0.0023691649548709393\n",
      "Gradient for decoder.decoder.0.weight: 0.012933322228491306\n",
      "Gradient for decoder.decoder.0.bias: 1.1169955932421871e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0006550849648192525\n",
      "Gradient for decoder.decoder.1.bias: 0.0004799696907866746\n",
      "Gradient for decoder.decoder.3.weight: 0.011893357150256634\n",
      "Gradient for decoder.decoder.3.bias: 9.23261189722524e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0004117888165637851\n",
      "Gradient for decoder.decoder.4.bias: 0.00038316872087307274\n",
      "Gradient for decoder.decoder.6.weight: 0.0004063812375534326\n",
      "Gradient for decoder.decoder.6.bias: 1.7652209862717427e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.01515472773462534\n",
      "Gradient for encoder.encoder.0.bias: 2.3096153461965585e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0012107943184673786\n",
      "Gradient for encoder.encoder.1.bias: 0.0009610148845240474\n",
      "Gradient for encoder.encoder.3.weight: 0.02831459604203701\n",
      "Gradient for encoder.encoder.3.bias: 2.5791310753753294e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.006076916120946407\n",
      "Gradient for encoder.encoder.4.bias: 0.00566621869802475\n",
      "Gradient for encoder.mean.weight: 0.07506976276636124\n",
      "Gradient for encoder.mean.bias: 0.004339111037552357\n",
      "Gradient for encoder.log_var.weight: 0.04538996145129204\n",
      "Gradient for encoder.log_var.bias: 0.002162665594369173\n",
      "Gradient for decoder.decoder.0.weight: 0.009895913302898407\n",
      "Gradient for decoder.decoder.0.bias: 8.449013016997853e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.000525556446518749\n",
      "Gradient for decoder.decoder.1.bias: 0.00037723599234595895\n",
      "Gradient for decoder.decoder.3.weight: 0.009135771542787552\n",
      "Gradient for decoder.decoder.3.bias: 7.084288711212139e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0003916780697181821\n",
      "Gradient for decoder.decoder.4.bias: 0.00044032270670868456\n",
      "Gradient for decoder.decoder.6.weight: 0.00041917001362890005\n",
      "Gradient for decoder.decoder.6.bias: 2.4288356144097634e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.03513145446777344\n",
      "Gradient for encoder.encoder.0.bias: 4.9660209971991165e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0034433079417794943\n",
      "Gradient for encoder.encoder.1.bias: 0.0025179535150527954\n",
      "Gradient for encoder.encoder.3.weight: 0.07637698948383331\n",
      "Gradient for encoder.encoder.3.bias: 4.0282024937887684e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.012185271829366684\n",
      "Gradient for encoder.encoder.4.bias: 0.010929197072982788\n",
      "Gradient for encoder.mean.weight: 0.1635703593492508\n",
      "Gradient for encoder.mean.bias: 0.006091248709708452\n",
      "Gradient for encoder.log_var.weight: 0.09675683826208115\n",
      "Gradient for encoder.log_var.bias: 0.003697895212098956\n",
      "Gradient for decoder.decoder.0.weight: 0.008662799373269081\n",
      "Gradient for decoder.decoder.0.bias: 7.428023474087553e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.00047616695519536734\n",
      "Gradient for decoder.decoder.1.bias: 0.0003421498986426741\n",
      "Gradient for decoder.decoder.3.weight: 0.008249272592365742\n",
      "Gradient for decoder.decoder.3.bias: 6.892469928132527e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00039730852586217225\n",
      "Gradient for decoder.decoder.4.bias: 0.0004590276221279055\n",
      "Gradient for decoder.decoder.6.weight: 0.00045253761345520616\n",
      "Gradient for decoder.decoder.6.bias: 3.283584374003112e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.009962525218725204\n",
      "Gradient for encoder.encoder.0.bias: 2.1137269018423055e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0010662657441571355\n",
      "Gradient for encoder.encoder.1.bias: 0.001150582917034626\n",
      "Gradient for encoder.encoder.3.weight: 0.02341415174305439\n",
      "Gradient for encoder.encoder.3.bias: 2.5007995674286576e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.006670238915830851\n",
      "Gradient for encoder.encoder.4.bias: 0.006375910248607397\n",
      "Gradient for encoder.mean.weight: 0.08357327431440353\n",
      "Gradient for encoder.mean.bias: 0.004497218411415815\n",
      "Gradient for encoder.log_var.weight: 0.05384351313114166\n",
      "Gradient for encoder.log_var.bias: 0.0030150171369314194\n",
      "Gradient for decoder.decoder.0.weight: 0.009573356248438358\n",
      "Gradient for decoder.decoder.0.bias: 7.822464204165769e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.000493186351377517\n",
      "Gradient for decoder.decoder.1.bias: 0.0003798484685830772\n",
      "Gradient for decoder.decoder.3.weight: 0.008821273222565651\n",
      "Gradient for decoder.decoder.3.bias: 9.158905578399157e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0005077538662590086\n",
      "Gradient for decoder.decoder.4.bias: 0.0006056380807422101\n",
      "Gradient for decoder.decoder.6.weight: 0.00046426811604760587\n",
      "Gradient for decoder.decoder.6.bias: 3.637780173448846e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.013082127086818218\n",
      "Gradient for encoder.encoder.0.bias: 2.2181942047061476e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0012313429033383727\n",
      "Gradient for encoder.encoder.1.bias: 0.0011634978000074625\n",
      "Gradient for encoder.encoder.3.weight: 0.02621782384812832\n",
      "Gradient for encoder.encoder.3.bias: 1.7143647612627433e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.004314302001148462\n",
      "Gradient for encoder.encoder.4.bias: 0.0035832172725349665\n",
      "Gradient for encoder.mean.weight: 0.06155385822057724\n",
      "Gradient for encoder.mean.bias: 0.0025689243339002132\n",
      "Gradient for encoder.log_var.weight: 0.03147337958216667\n",
      "Gradient for encoder.log_var.bias: 0.0016552439192309976\n",
      "Gradient for decoder.decoder.0.weight: 0.010027474723756313\n",
      "Gradient for decoder.decoder.0.bias: 7.939875840135002e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.00048652634723111987\n",
      "Gradient for decoder.decoder.1.bias: 0.0003857320989482105\n",
      "Gradient for decoder.decoder.3.weight: 0.009137004613876343\n",
      "Gradient for decoder.decoder.3.bias: 7.78584696714546e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00044172207708470523\n",
      "Gradient for decoder.decoder.4.bias: 0.0004925189423374832\n",
      "Gradient for decoder.decoder.6.weight: 0.00040596548933535814\n",
      "Gradient for decoder.decoder.6.bias: 2.4476814360241406e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.013247162103652954\n",
      "Gradient for encoder.encoder.0.bias: 1.855635610448214e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0012052523670718074\n",
      "Gradient for encoder.encoder.1.bias: 0.001092050690203905\n",
      "Gradient for encoder.encoder.3.weight: 0.02426409162580967\n",
      "Gradient for encoder.encoder.3.bias: 1.705937613394326e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.004292858764529228\n",
      "Gradient for encoder.encoder.4.bias: 0.0037486630026251078\n",
      "Gradient for encoder.mean.weight: 0.05965898558497429\n",
      "Gradient for encoder.mean.bias: 0.0027241145726293325\n",
      "Gradient for encoder.log_var.weight: 0.03499756380915642\n",
      "Gradient for encoder.log_var.bias: 0.0020517653319984674\n",
      "Gradient for decoder.decoder.0.weight: 0.012675008736550808\n",
      "Gradient for decoder.decoder.0.bias: 1.0477648609841239e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0006877175765112042\n",
      "Gradient for decoder.decoder.1.bias: 0.0005210442468523979\n",
      "Gradient for decoder.decoder.3.weight: 0.012521428987383842\n",
      "Gradient for decoder.decoder.3.bias: 9.105790427232918e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.000491935177706182\n",
      "Gradient for decoder.decoder.4.bias: 0.0004481887153815478\n",
      "Gradient for decoder.decoder.6.weight: 0.00046620561624877155\n",
      "Gradient for decoder.decoder.6.bias: 2.6224166504107416e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.013692822307348251\n",
      "Gradient for encoder.encoder.0.bias: 1.97152849601423e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0013899513287469745\n",
      "Gradient for encoder.encoder.1.bias: 0.0010352077661082149\n",
      "Gradient for encoder.encoder.3.weight: 0.02897394821047783\n",
      "Gradient for encoder.encoder.3.bias: 1.7341368618861708e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.005543083418160677\n",
      "Gradient for encoder.encoder.4.bias: 0.0036027205642312765\n",
      "Gradient for encoder.mean.weight: 0.07125940918922424\n",
      "Gradient for encoder.mean.bias: 0.0027571655809879303\n",
      "Gradient for encoder.log_var.weight: 0.04440167173743248\n",
      "Gradient for encoder.log_var.bias: 0.001611826941370964\n",
      "Gradient for decoder.decoder.0.weight: 0.010064815171062946\n",
      "Gradient for decoder.decoder.0.bias: 8.408261586989596e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005158443236723542\n",
      "Gradient for decoder.decoder.1.bias: 0.000407564511988312\n",
      "Gradient for decoder.decoder.3.weight: 0.009240834973752499\n",
      "Gradient for decoder.decoder.3.bias: 7.284082365055511e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00033084710594266653\n",
      "Gradient for decoder.decoder.4.bias: 0.0002781144285108894\n",
      "Gradient for decoder.decoder.6.weight: 0.0004318393184803426\n",
      "Gradient for decoder.decoder.6.bias: 2.303842848050408e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.01378784328699112\n",
      "Gradient for encoder.encoder.0.bias: 1.7699378421220935e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0012041276786476374\n",
      "Gradient for encoder.encoder.1.bias: 0.000966062129009515\n",
      "Gradient for encoder.encoder.3.weight: 0.026009147986769676\n",
      "Gradient for encoder.encoder.3.bias: 2.0107522591406024e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.004209290724247694\n",
      "Gradient for encoder.encoder.4.bias: 0.004113773349672556\n",
      "Gradient for encoder.mean.weight: 0.05789577588438988\n",
      "Gradient for encoder.mean.bias: 0.003518616547808051\n",
      "Gradient for encoder.log_var.weight: 0.029008643701672554\n",
      "Gradient for encoder.log_var.bias: 0.001952245132997632\n",
      "Gradient for decoder.decoder.0.weight: 0.012327109463512897\n",
      "Gradient for decoder.decoder.0.bias: 9.42474848164565e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0006308199372142553\n",
      "Gradient for decoder.decoder.1.bias: 0.0004898752667941153\n",
      "Gradient for decoder.decoder.3.weight: 0.011330842971801758\n",
      "Gradient for decoder.decoder.3.bias: 1.1815738665266196e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0008796161273494363\n",
      "Gradient for decoder.decoder.4.bias: 0.0010339475702494383\n",
      "Gradient for decoder.decoder.6.weight: 0.0006593139260075986\n",
      "Gradient for decoder.decoder.6.bias: 5.293020876706578e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.013018614612519741\n",
      "Gradient for encoder.encoder.0.bias: 2.665885567854076e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0013127943966537714\n",
      "Gradient for encoder.encoder.1.bias: 0.0010714158415794373\n",
      "Gradient for encoder.encoder.3.weight: 0.0285714752972126\n",
      "Gradient for encoder.encoder.3.bias: 2.3871055132573815e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0065580494701862335\n",
      "Gradient for encoder.encoder.4.bias: 0.005420942325145006\n",
      "Gradient for encoder.mean.weight: 0.08478157222270966\n",
      "Gradient for encoder.mean.bias: 0.00351804425008595\n",
      "Gradient for encoder.log_var.weight: 0.051584113389253616\n",
      "Gradient for encoder.log_var.bias: 0.002310819225385785\n",
      "Gradient for decoder.decoder.0.weight: 0.009021203964948654\n",
      "Gradient for decoder.decoder.0.bias: 7.51713344349092e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0004694612289313227\n",
      "Gradient for decoder.decoder.1.bias: 0.00036963712773285806\n",
      "Gradient for decoder.decoder.3.weight: 0.008404986001551151\n",
      "Gradient for decoder.decoder.3.bias: 6.338028712971067e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0003167674003634602\n",
      "Gradient for decoder.decoder.4.bias: 0.00029550312319770455\n",
      "Gradient for decoder.decoder.6.weight: 0.00045185888302512467\n",
      "Gradient for decoder.decoder.6.bias: 2.897848935390357e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.009652845561504364\n",
      "Gradient for encoder.encoder.0.bias: 1.7396535600955332e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0009238983620889485\n",
      "Gradient for encoder.encoder.1.bias: 0.0008809604914858937\n",
      "Gradient for encoder.encoder.3.weight: 0.02044057659804821\n",
      "Gradient for encoder.encoder.3.bias: 2.172700352964796e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.006662581115961075\n",
      "Gradient for encoder.encoder.4.bias: 0.005518929101526737\n",
      "Gradient for encoder.mean.weight: 0.09158586710691452\n",
      "Gradient for encoder.mean.bias: 0.003490455448627472\n",
      "Gradient for encoder.log_var.weight: 0.051629211753606796\n",
      "Gradient for encoder.log_var.bias: 0.0021697361953556538\n",
      "Gradient for decoder.decoder.0.weight: 0.011107023805379868\n",
      "Gradient for decoder.decoder.0.bias: 1.0169075997934485e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0005287957028485835\n",
      "Gradient for decoder.decoder.1.bias: 0.0004358402802608907\n",
      "Gradient for decoder.decoder.3.weight: 0.01020884606987238\n",
      "Gradient for decoder.decoder.3.bias: 8.989288480254487e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00038506987038999796\n",
      "Gradient for decoder.decoder.4.bias: 0.00032884450047276914\n",
      "Gradient for decoder.decoder.6.weight: 0.0004097771306987852\n",
      "Gradient for decoder.decoder.6.bias: 2.006901013373863e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.010949946008622646\n",
      "Gradient for encoder.encoder.0.bias: 1.8741072929651104e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0010696758981794119\n",
      "Gradient for encoder.encoder.1.bias: 0.0011996491812169552\n",
      "Gradient for encoder.encoder.3.weight: 0.02409655973315239\n",
      "Gradient for encoder.encoder.3.bias: 2.711464386351281e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.006310820113867521\n",
      "Gradient for encoder.encoder.4.bias: 0.00582289882004261\n",
      "Gradient for encoder.mean.weight: 0.08941986411809921\n",
      "Gradient for encoder.mean.bias: 0.004178731702268124\n",
      "Gradient for encoder.log_var.weight: 0.05005168542265892\n",
      "Gradient for encoder.log_var.bias: 0.0027455841191112995\n",
      "Gradient for decoder.decoder.0.weight: 0.012442399747669697\n",
      "Gradient for decoder.decoder.0.bias: 1.028986479356675e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0005774135352112353\n",
      "Gradient for decoder.decoder.1.bias: 0.0005033464403823018\n",
      "Gradient for decoder.decoder.3.weight: 0.011477485299110413\n",
      "Gradient for decoder.decoder.3.bias: 8.902724391024464e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00041008705738931894\n",
      "Gradient for decoder.decoder.4.bias: 0.00039743544766679406\n",
      "Gradient for decoder.decoder.6.weight: 0.00043476882274262607\n",
      "Gradient for decoder.decoder.6.bias: 2.47156076511601e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.018033884465694427\n",
      "Gradient for encoder.encoder.0.bias: 2.5246450763294348e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0016678634565323591\n",
      "Gradient for encoder.encoder.1.bias: 0.0011157356202602386\n",
      "Gradient for encoder.encoder.3.weight: 0.03599519655108452\n",
      "Gradient for encoder.encoder.3.bias: 2.0967563796325805e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.004461544565856457\n",
      "Gradient for encoder.encoder.4.bias: 0.0038773594424128532\n",
      "Gradient for encoder.mean.weight: 0.057080041617155075\n",
      "Gradient for encoder.mean.bias: 0.0032055990304797888\n",
      "Gradient for encoder.log_var.weight: 0.031746938824653625\n",
      "Gradient for encoder.log_var.bias: 0.0020131857600063086\n",
      "Gradient for decoder.decoder.0.weight: 0.008856767788529396\n",
      "Gradient for decoder.decoder.0.bias: 7.281408809234335e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.00044004517258144915\n",
      "Gradient for decoder.decoder.1.bias: 0.0003475696430541575\n",
      "Gradient for decoder.decoder.3.weight: 0.008325464092195034\n",
      "Gradient for decoder.decoder.3.bias: 7.526532175283762e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0004324782348703593\n",
      "Gradient for decoder.decoder.4.bias: 0.0004953581956215203\n",
      "Gradient for decoder.decoder.6.weight: 0.0004102658713236451\n",
      "Gradient for decoder.decoder.6.bias: 2.5854295017779805e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.019382311031222343\n",
      "Gradient for encoder.encoder.0.bias: 2.8983315747410643e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0025849132798612118\n",
      "Gradient for encoder.encoder.1.bias: 0.0019222209230065346\n",
      "Gradient for encoder.encoder.3.weight: 0.04810778796672821\n",
      "Gradient for encoder.encoder.3.bias: 2.6470722835902905e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.005998639389872551\n",
      "Gradient for encoder.encoder.4.bias: 0.0057059298269450665\n",
      "Gradient for encoder.mean.weight: 0.07554980367422104\n",
      "Gradient for encoder.mean.bias: 0.0031751967035233974\n",
      "Gradient for encoder.log_var.weight: 0.04033183678984642\n",
      "Gradient for encoder.log_var.bias: 0.0018182831117883325\n",
      "Gradient for decoder.decoder.0.weight: 0.008543209172785282\n",
      "Gradient for decoder.decoder.0.bias: 7.098238663516554e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0004165271238889545\n",
      "Gradient for decoder.decoder.1.bias: 0.00034661919926293194\n",
      "Gradient for decoder.decoder.3.weight: 0.008114549331367016\n",
      "Gradient for decoder.decoder.3.bias: 6.743728492297763e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0003204612003173679\n",
      "Gradient for decoder.decoder.4.bias: 0.0002960630226880312\n",
      "Gradient for decoder.decoder.6.weight: 0.00042607358773238957\n",
      "Gradient for decoder.decoder.6.bias: 2.4800921892165206e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training VAE Epoch:  34%|███▍      | 27/79 [00:00<00:00, 62.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient for encoder.encoder.0.weight: 0.011134158819913864\n",
      "Gradient for encoder.encoder.0.bias: 1.992450995857986e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0010085268877446651\n",
      "Gradient for encoder.encoder.1.bias: 0.000846240611281246\n",
      "Gradient for encoder.encoder.3.weight: 0.02194218896329403\n",
      "Gradient for encoder.encoder.3.bias: 2.4101759477090923e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.005506920628249645\n",
      "Gradient for encoder.encoder.4.bias: 0.005914531648159027\n",
      "Gradient for encoder.mean.weight: 0.07443880289793015\n",
      "Gradient for encoder.mean.bias: 0.004643674939870834\n",
      "Gradient for encoder.log_var.weight: 0.04851941764354706\n",
      "Gradient for encoder.log_var.bias: 0.0031585157848894596\n",
      "Gradient for decoder.decoder.0.weight: 0.010333708487451077\n",
      "Gradient for decoder.decoder.0.bias: 9.154783875420236e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005451320903375745\n",
      "Gradient for decoder.decoder.1.bias: 0.0004483694792725146\n",
      "Gradient for decoder.decoder.3.weight: 0.009559041820466518\n",
      "Gradient for decoder.decoder.3.bias: 7.519978389991522e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.000389256194466725\n",
      "Gradient for decoder.decoder.4.bias: 0.00036902070860378444\n",
      "Gradient for decoder.decoder.6.weight: 0.0004425753722898662\n",
      "Gradient for decoder.decoder.6.bias: 2.724315709201619e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.010500212199985981\n",
      "Gradient for encoder.encoder.0.bias: 1.522455425617686e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0010887865209951997\n",
      "Gradient for encoder.encoder.1.bias: 0.0009936983697116375\n",
      "Gradient for encoder.encoder.3.weight: 0.02160070277750492\n",
      "Gradient for encoder.encoder.3.bias: 2.0952697910026075e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.004853834863752127\n",
      "Gradient for encoder.encoder.4.bias: 0.004100393038243055\n",
      "Gradient for encoder.mean.weight: 0.06509565562009811\n",
      "Gradient for encoder.mean.bias: 0.002904229098930955\n",
      "Gradient for encoder.log_var.weight: 0.038611676543951035\n",
      "Gradient for encoder.log_var.bias: 0.001529502565972507\n",
      "Gradient for decoder.decoder.0.weight: 0.011401970870792866\n",
      "Gradient for decoder.decoder.0.bias: 9.179661197844524e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005773568991571665\n",
      "Gradient for decoder.decoder.1.bias: 0.0004700976423919201\n",
      "Gradient for decoder.decoder.3.weight: 0.01038367673754692\n",
      "Gradient for decoder.decoder.3.bias: 7.668320145537422e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.000397438183426857\n",
      "Gradient for decoder.decoder.4.bias: 0.0003638059424702078\n",
      "Gradient for decoder.decoder.6.weight: 0.00042529479833319783\n",
      "Gradient for decoder.decoder.6.bias: 2.3624097593710758e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.023266376927495003\n",
      "Gradient for encoder.encoder.0.bias: 2.704861334912323e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0021701441146433353\n",
      "Gradient for encoder.encoder.1.bias: 0.0015576874138787389\n",
      "Gradient for encoder.encoder.3.weight: 0.04326426982879639\n",
      "Gradient for encoder.encoder.3.bias: 3.0415167606712146e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.006156051065772772\n",
      "Gradient for encoder.encoder.4.bias: 0.006870835553854704\n",
      "Gradient for encoder.mean.weight: 0.08496732264757156\n",
      "Gradient for encoder.mean.bias: 0.004740516189485788\n",
      "Gradient for encoder.log_var.weight: 0.05434218421578407\n",
      "Gradient for encoder.log_var.bias: 0.0035387836396694183\n",
      "Gradient for decoder.decoder.0.weight: 0.01207922026515007\n",
      "Gradient for decoder.decoder.0.bias: 1.0792230303868777e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0005822382518090308\n",
      "Gradient for decoder.decoder.1.bias: 0.0004884988302364945\n",
      "Gradient for decoder.decoder.3.weight: 0.011185229755938053\n",
      "Gradient for decoder.decoder.3.bias: 8.337983775641433e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0003626332036219537\n",
      "Gradient for decoder.decoder.4.bias: 0.000336439348757267\n",
      "Gradient for decoder.decoder.6.weight: 0.00044728588545694947\n",
      "Gradient for decoder.decoder.6.bias: 2.7232383217778988e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.010791667737066746\n",
      "Gradient for encoder.encoder.0.bias: 1.653746063701167e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0008890516473911703\n",
      "Gradient for encoder.encoder.1.bias: 0.0008644062327221036\n",
      "Gradient for encoder.encoder.3.weight: 0.01980411820113659\n",
      "Gradient for encoder.encoder.3.bias: 1.44205467011993e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0030447246972471476\n",
      "Gradient for encoder.encoder.4.bias: 0.0030589234083890915\n",
      "Gradient for encoder.mean.weight: 0.046821657568216324\n",
      "Gradient for encoder.mean.bias: 0.00249264994636178\n",
      "Gradient for encoder.log_var.weight: 0.02560410276055336\n",
      "Gradient for encoder.log_var.bias: 0.0015208160039037466\n",
      "Gradient for decoder.decoder.0.weight: 0.010702821426093578\n",
      "Gradient for decoder.decoder.0.bias: 8.714049620772713e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005588229396380484\n",
      "Gradient for decoder.decoder.1.bias: 0.0004146035644225776\n",
      "Gradient for decoder.decoder.3.weight: 0.010589657351374626\n",
      "Gradient for decoder.decoder.3.bias: 7.625921422116377e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00039080955320969224\n",
      "Gradient for decoder.decoder.4.bias: 0.00035012851003557444\n",
      "Gradient for decoder.decoder.6.weight: 0.00041130915633402765\n",
      "Gradient for decoder.decoder.6.bias: 1.9894150682375766e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.009148637764155865\n",
      "Gradient for encoder.encoder.0.bias: 1.5567606231892128e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0007853752467781305\n",
      "Gradient for encoder.encoder.1.bias: 0.0006755829672329128\n",
      "Gradient for encoder.encoder.3.weight: 0.01808321103453636\n",
      "Gradient for encoder.encoder.3.bias: 1.6054142737420563e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0038846381939947605\n",
      "Gradient for encoder.encoder.4.bias: 0.003110213903710246\n",
      "Gradient for encoder.mean.weight: 0.049310266971588135\n",
      "Gradient for encoder.mean.bias: 0.0022935718297958374\n",
      "Gradient for encoder.log_var.weight: 0.03020131029188633\n",
      "Gradient for encoder.log_var.bias: 0.0015812631463631988\n",
      "Gradient for decoder.decoder.0.weight: 0.011378669179975986\n",
      "Gradient for decoder.decoder.0.bias: 9.89186579869461e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0006081637111492455\n",
      "Gradient for decoder.decoder.1.bias: 0.0004527347336988896\n",
      "Gradient for decoder.decoder.3.weight: 0.010613877326250076\n",
      "Gradient for decoder.decoder.3.bias: 7.465186108168709e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00036848324816673994\n",
      "Gradient for decoder.decoder.4.bias: 0.00031984024099074304\n",
      "Gradient for decoder.decoder.6.weight: 0.00042090023634955287\n",
      "Gradient for decoder.decoder.6.bias: 2.4518285499652848e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.014519103802740574\n",
      "Gradient for encoder.encoder.0.bias: 2.3916780014787697e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0010036140447482467\n",
      "Gradient for encoder.encoder.1.bias: 0.0008658060687594116\n",
      "Gradient for encoder.encoder.3.weight: 0.021970292553305626\n",
      "Gradient for encoder.encoder.3.bias: 1.956987766282836e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.004086223430931568\n",
      "Gradient for encoder.encoder.4.bias: 0.0035175569355487823\n",
      "Gradient for encoder.mean.weight: 0.05546524375677109\n",
      "Gradient for encoder.mean.bias: 0.002639265963807702\n",
      "Gradient for encoder.log_var.weight: 0.02858351357281208\n",
      "Gradient for encoder.log_var.bias: 0.0014272253029048443\n",
      "Gradient for decoder.decoder.0.weight: 0.00911702960729599\n",
      "Gradient for decoder.decoder.0.bias: 7.95708152145913e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0004615013604052365\n",
      "Gradient for decoder.decoder.1.bias: 0.000369721237802878\n",
      "Gradient for decoder.decoder.3.weight: 0.008443807251751423\n",
      "Gradient for decoder.decoder.3.bias: 6.994237827795402e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00030377914663404226\n",
      "Gradient for decoder.decoder.4.bias: 0.00029676328995265067\n",
      "Gradient for decoder.decoder.6.weight: 0.0004278839915059507\n",
      "Gradient for decoder.decoder.6.bias: 2.561243854870554e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.013315540738403797\n",
      "Gradient for encoder.encoder.0.bias: 1.8479575508711932e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0009050972876138985\n",
      "Gradient for encoder.encoder.1.bias: 0.0008481325930915773\n",
      "Gradient for encoder.encoder.3.weight: 0.018476353958249092\n",
      "Gradient for encoder.encoder.3.bias: 2.5236981948673076e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0042971535585820675\n",
      "Gradient for encoder.encoder.4.bias: 0.005413189064711332\n",
      "Gradient for encoder.mean.weight: 0.05665281414985657\n",
      "Gradient for encoder.mean.bias: 0.003964005038142204\n",
      "Gradient for encoder.log_var.weight: 0.0326041616499424\n",
      "Gradient for encoder.log_var.bias: 0.0024847148451954126\n",
      "Gradient for decoder.decoder.0.weight: 0.010053585283458233\n",
      "Gradient for decoder.decoder.0.bias: 8.362337211575976e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005102934082970023\n",
      "Gradient for decoder.decoder.1.bias: 0.00039685904630459845\n",
      "Gradient for decoder.decoder.3.weight: 0.009503604844212532\n",
      "Gradient for decoder.decoder.3.bias: 7.657481593259519e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00033391063334420323\n",
      "Gradient for decoder.decoder.4.bias: 0.00028891093097627163\n",
      "Gradient for decoder.decoder.6.weight: 0.0004512517189141363\n",
      "Gradient for decoder.decoder.6.bias: 2.7584570489125326e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.009747530333697796\n",
      "Gradient for encoder.encoder.0.bias: 1.8806272511495692e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0010724017629399896\n",
      "Gradient for encoder.encoder.1.bias: 0.0010053926380351186\n",
      "Gradient for encoder.encoder.3.weight: 0.02242501825094223\n",
      "Gradient for encoder.encoder.3.bias: 1.63079161286106e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0035115559585392475\n",
      "Gradient for encoder.encoder.4.bias: 0.003576278453692794\n",
      "Gradient for encoder.mean.weight: 0.04952617362141609\n",
      "Gradient for encoder.mean.bias: 0.002945266431197524\n",
      "Gradient for encoder.log_var.weight: 0.03146756440401077\n",
      "Gradient for encoder.log_var.bias: 0.0018841290147975087\n",
      "Gradient for decoder.decoder.0.weight: 0.011183748953044415\n",
      "Gradient for decoder.decoder.0.bias: 7.907489940617296e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0006085172644816339\n",
      "Gradient for decoder.decoder.1.bias: 0.00041472906013950706\n",
      "Gradient for decoder.decoder.3.weight: 0.010794875212013721\n",
      "Gradient for decoder.decoder.3.bias: 7.725179523854209e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0003851622750516981\n",
      "Gradient for decoder.decoder.4.bias: 0.0003381063579581678\n",
      "Gradient for decoder.decoder.6.weight: 0.0004381502512842417\n",
      "Gradient for decoder.decoder.6.bias: 2.6443427486810833e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.013344457373023033\n",
      "Gradient for encoder.encoder.0.bias: 1.9064909373422978e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0011780929053202271\n",
      "Gradient for encoder.encoder.1.bias: 0.0010135677875950933\n",
      "Gradient for encoder.encoder.3.weight: 0.026040315628051758\n",
      "Gradient for encoder.encoder.3.bias: 1.6093595900379398e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0032576886005699635\n",
      "Gradient for encoder.encoder.4.bias: 0.0031839224975556135\n",
      "Gradient for encoder.mean.weight: 0.04718107730150223\n",
      "Gradient for encoder.mean.bias: 0.002368952613323927\n",
      "Gradient for encoder.log_var.weight: 0.025518905371427536\n",
      "Gradient for encoder.log_var.bias: 0.0016265292651951313\n",
      "Gradient for decoder.decoder.0.weight: 0.010283326730132103\n",
      "Gradient for decoder.decoder.0.bias: 8.618444846675288e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005201203748583794\n",
      "Gradient for decoder.decoder.1.bias: 0.0004298028361517936\n",
      "Gradient for decoder.decoder.3.weight: 0.009540176950395107\n",
      "Gradient for decoder.decoder.3.bias: 9.451390364789702e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0004341572930570692\n",
      "Gradient for decoder.decoder.4.bias: 0.00048534359666518867\n",
      "Gradient for decoder.decoder.6.weight: 0.00045162078458815813\n",
      "Gradient for decoder.decoder.6.bias: 3.1968440453056246e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.01544317789375782\n",
      "Gradient for encoder.encoder.0.bias: 2.2679882277776287e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0010126394918188453\n",
      "Gradient for encoder.encoder.1.bias: 0.0007718074484728277\n",
      "Gradient for encoder.encoder.3.weight: 0.022375576198101044\n",
      "Gradient for encoder.encoder.3.bias: 1.8104913401817413e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.003429639618843794\n",
      "Gradient for encoder.encoder.4.bias: 0.0032725969795137644\n",
      "Gradient for encoder.mean.weight: 0.04859575256705284\n",
      "Gradient for encoder.mean.bias: 0.002219258574768901\n",
      "Gradient for encoder.log_var.weight: 0.028034670278429985\n",
      "Gradient for encoder.log_var.bias: 0.0014224679907783866\n",
      "Gradient for decoder.decoder.0.weight: 0.008879849687218666\n",
      "Gradient for decoder.decoder.0.bias: 7.736790375023617e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0004405223880894482\n",
      "Gradient for decoder.decoder.1.bias: 0.00036963410093449056\n",
      "Gradient for decoder.decoder.3.weight: 0.008248935453593731\n",
      "Gradient for decoder.decoder.3.bias: 7.660394540920379e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00038478715578094125\n",
      "Gradient for decoder.decoder.4.bias: 0.00042253825813531876\n",
      "Gradient for decoder.decoder.6.weight: 0.00040403628372587264\n",
      "Gradient for decoder.decoder.6.bias: 2.3695472918916494e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.01018550619482994\n",
      "Gradient for encoder.encoder.0.bias: 1.7406364544170216e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0008528607431799173\n",
      "Gradient for encoder.encoder.1.bias: 0.0007978186476975679\n",
      "Gradient for encoder.encoder.3.weight: 0.01966450735926628\n",
      "Gradient for encoder.encoder.3.bias: 1.8054317763027683e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.004351342096924782\n",
      "Gradient for encoder.encoder.4.bias: 0.003853789297863841\n",
      "Gradient for encoder.mean.weight: 0.058548565953969955\n",
      "Gradient for encoder.mean.bias: 0.0026884814724326134\n",
      "Gradient for encoder.log_var.weight: 0.0345170795917511\n",
      "Gradient for encoder.log_var.bias: 0.001885614707134664\n",
      "Gradient for decoder.decoder.0.weight: 0.009890480898320675\n",
      "Gradient for decoder.decoder.0.bias: 8.343947754951841e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005171145894564688\n",
      "Gradient for decoder.decoder.1.bias: 0.0003857591364067048\n",
      "Gradient for decoder.decoder.3.weight: 0.009603568352758884\n",
      "Gradient for decoder.decoder.3.bias: 7.209897262550058e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00039541537989862263\n",
      "Gradient for decoder.decoder.4.bias: 0.0004209715116303414\n",
      "Gradient for decoder.decoder.6.weight: 0.00042376757482998073\n",
      "Gradient for decoder.decoder.6.bias: 2.514737207093276e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.012587634846568108\n",
      "Gradient for encoder.encoder.0.bias: 2.4731118195009394e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0010254717199131846\n",
      "Gradient for encoder.encoder.1.bias: 0.0008768201805651188\n",
      "Gradient for encoder.encoder.3.weight: 0.022408727556467056\n",
      "Gradient for encoder.encoder.3.bias: 1.7516632588865377e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.00322311301715672\n",
      "Gradient for encoder.encoder.4.bias: 0.003208249108865857\n",
      "Gradient for encoder.mean.weight: 0.0459214523434639\n",
      "Gradient for encoder.mean.bias: 0.0023444490507245064\n",
      "Gradient for encoder.log_var.weight: 0.029022470116615295\n",
      "Gradient for encoder.log_var.bias: 0.0012873534578830004\n",
      "Gradient for decoder.decoder.0.weight: 0.008330632001161575\n",
      "Gradient for decoder.decoder.0.bias: 6.428279436532236e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.00040939802420325577\n",
      "Gradient for decoder.decoder.1.bias: 0.00035385575029067695\n",
      "Gradient for decoder.decoder.3.weight: 0.008228790014982224\n",
      "Gradient for decoder.decoder.3.bias: 6.903293214843842e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0004131005553063005\n",
      "Gradient for decoder.decoder.4.bias: 0.00047701012226752937\n",
      "Gradient for decoder.decoder.6.weight: 0.00047489875578321517\n",
      "Gradient for decoder.decoder.6.bias: 3.6032532079843804e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.01092838030308485\n",
      "Gradient for encoder.encoder.0.bias: 1.4212439385097309e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0009363456629216671\n",
      "Gradient for encoder.encoder.1.bias: 0.0008527637110091746\n",
      "Gradient for encoder.encoder.3.weight: 0.021162545308470726\n",
      "Gradient for encoder.encoder.3.bias: 1.4597868747134868e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0029937163926661015\n",
      "Gradient for encoder.encoder.4.bias: 0.0024884070735424757\n",
      "Gradient for encoder.mean.weight: 0.04349146783351898\n",
      "Gradient for encoder.mean.bias: 0.0020073221530765295\n",
      "Gradient for encoder.log_var.weight: 0.0226962361484766\n",
      "Gradient for encoder.log_var.bias: 0.001138688181526959\n",
      "Gradient for decoder.decoder.0.weight: 0.013197279535233974\n",
      "Gradient for decoder.decoder.0.bias: 1.0886427176393099e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0006518562440760434\n",
      "Gradient for decoder.decoder.1.bias: 0.0005329285631887615\n",
      "Gradient for decoder.decoder.3.weight: 0.012334086000919342\n",
      "Gradient for decoder.decoder.3.bias: 9.462649414038182e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0005173057434149086\n",
      "Gradient for decoder.decoder.4.bias: 0.0005453816265799105\n",
      "Gradient for decoder.decoder.6.weight: 0.00047838216414675117\n",
      "Gradient for decoder.decoder.6.bias: 2.8320639103185385e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.008458463475108147\n",
      "Gradient for encoder.encoder.0.bias: 1.754657877328647e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.000759847229346633\n",
      "Gradient for encoder.encoder.1.bias: 0.00074355723336339\n",
      "Gradient for encoder.encoder.3.weight: 0.016307225450873375\n",
      "Gradient for encoder.encoder.3.bias: 1.6798507029847087e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.004437484312802553\n",
      "Gradient for encoder.encoder.4.bias: 0.003696893807500601\n",
      "Gradient for encoder.mean.weight: 0.0601164884865284\n",
      "Gradient for encoder.mean.bias: 0.0025232103653252125\n",
      "Gradient for encoder.log_var.weight: 0.033048953860998154\n",
      "Gradient for encoder.log_var.bias: 0.0013699698029085994\n",
      "Gradient for decoder.decoder.0.weight: 0.009959458373486996\n",
      "Gradient for decoder.decoder.0.bias: 8.482373137219668e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005300246411934495\n",
      "Gradient for decoder.decoder.1.bias: 0.00040104129584506154\n",
      "Gradient for decoder.decoder.3.weight: 0.009663150645792484\n",
      "Gradient for decoder.decoder.3.bias: 7.056482481671011e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0003932823019567877\n",
      "Gradient for decoder.decoder.4.bias: 0.000377176096662879\n",
      "Gradient for decoder.decoder.6.weight: 0.00048339489148929715\n",
      "Gradient for decoder.decoder.6.bias: 3.455184196354821e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.014441910199820995\n",
      "Gradient for encoder.encoder.0.bias: 1.9944407236849315e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0018209628760814667\n",
      "Gradient for encoder.encoder.1.bias: 0.0014269226230680943\n",
      "Gradient for encoder.encoder.3.weight: 0.034171707928180695\n",
      "Gradient for encoder.encoder.3.bias: 1.837449359332055e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0045130616053938866\n",
      "Gradient for encoder.encoder.4.bias: 0.0037345062009990215\n",
      "Gradient for encoder.mean.weight: 0.06138460338115692\n",
      "Gradient for encoder.mean.bias: 0.0025629810988903046\n",
      "Gradient for encoder.log_var.weight: 0.03495918959379196\n",
      "Gradient for encoder.log_var.bias: 0.0015398411778733134\n",
      "Gradient for decoder.decoder.0.weight: 0.012776855379343033\n",
      "Gradient for decoder.decoder.0.bias: 1.1086868229037705e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.000659776502288878\n",
      "Gradient for decoder.decoder.1.bias: 0.0005212360993027687\n",
      "Gradient for decoder.decoder.3.weight: 0.011780022643506527\n",
      "Gradient for decoder.decoder.3.bias: 1.0392071231324351e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0005044183926656842\n",
      "Gradient for decoder.decoder.4.bias: 0.0005014308844693005\n",
      "Gradient for decoder.decoder.6.weight: 0.0005114144878461957\n",
      "Gradient for decoder.decoder.6.bias: 3.4236312785651535e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.02039583958685398\n",
      "Gradient for encoder.encoder.0.bias: 2.73601020311931e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0014744154177606106\n",
      "Gradient for encoder.encoder.1.bias: 0.0010557082714512944\n",
      "Gradient for encoder.encoder.3.weight: 0.03254810348153114\n",
      "Gradient for encoder.encoder.3.bias: 1.9313266264031625e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0038738478906452656\n",
      "Gradient for encoder.encoder.4.bias: 0.0037287953309714794\n",
      "Gradient for encoder.mean.weight: 0.05097418278455734\n",
      "Gradient for encoder.mean.bias: 0.002578320913016796\n",
      "Gradient for encoder.log_var.weight: 0.03234568610787392\n",
      "Gradient for encoder.log_var.bias: 0.0016443978529423475\n",
      "Gradient for decoder.decoder.0.weight: 0.008582123555243015\n",
      "Gradient for decoder.decoder.0.bias: 7.119265593713564e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.00043923541670665145\n",
      "Gradient for decoder.decoder.1.bias: 0.00033759328653104603\n",
      "Gradient for decoder.decoder.3.weight: 0.008236476220190525\n",
      "Gradient for decoder.decoder.3.bias: 6.544571135025379e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00032813232974149287\n",
      "Gradient for decoder.decoder.4.bias: 0.00032284052576869726\n",
      "Gradient for decoder.decoder.6.weight: 0.0004142691905144602\n",
      "Gradient for decoder.decoder.6.bias: 2.438289266137872e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.009531110525131226\n",
      "Gradient for encoder.encoder.0.bias: 1.6057096624555456e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0008835207554511726\n",
      "Gradient for encoder.encoder.1.bias: 0.0008783511002548039\n",
      "Gradient for encoder.encoder.3.weight: 0.019292190670967102\n",
      "Gradient for encoder.encoder.3.bias: 1.6852473583295335e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.00335865281522274\n",
      "Gradient for encoder.encoder.4.bias: 0.003093200735747814\n",
      "Gradient for encoder.mean.weight: 0.047579843550920486\n",
      "Gradient for encoder.mean.bias: 0.0024180265609174967\n",
      "Gradient for encoder.log_var.weight: 0.025704223662614822\n",
      "Gradient for encoder.log_var.bias: 0.0013632846530526876\n",
      "Gradient for decoder.decoder.0.weight: 0.01099740993231535\n",
      "Gradient for decoder.decoder.0.bias: 9.581089394083975e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005345413228496909\n",
      "Gradient for decoder.decoder.1.bias: 0.00040711736073717475\n",
      "Gradient for decoder.decoder.3.weight: 0.010349822230637074\n",
      "Gradient for decoder.decoder.3.bias: 8.08800179608049e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0003914790286216885\n",
      "Gradient for decoder.decoder.4.bias: 0.00033879189868457615\n",
      "Gradient for decoder.decoder.6.weight: 0.0004352687974460423\n",
      "Gradient for decoder.decoder.6.bias: 2.3062966647557914e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training VAE Epoch:  57%|█████▋    | 45/79 [00:00<00:00, 73.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient for encoder.encoder.0.weight: 0.009926377795636654\n",
      "Gradient for encoder.encoder.0.bias: 1.978647627687291e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0010399504099041224\n",
      "Gradient for encoder.encoder.1.bias: 0.000849083298817277\n",
      "Gradient for encoder.encoder.3.weight: 0.020691214129328728\n",
      "Gradient for encoder.encoder.3.bias: 2.001547122487679e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.004205551464110613\n",
      "Gradient for encoder.encoder.4.bias: 0.004352571442723274\n",
      "Gradient for encoder.mean.weight: 0.05594481900334358\n",
      "Gradient for encoder.mean.bias: 0.003065358381718397\n",
      "Gradient for encoder.log_var.weight: 0.035687416791915894\n",
      "Gradient for encoder.log_var.bias: 0.0021561847534030676\n",
      "Gradient for decoder.decoder.0.weight: 0.009415991604328156\n",
      "Gradient for decoder.decoder.0.bias: 7.695608039703927e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005183446919545531\n",
      "Gradient for decoder.decoder.1.bias: 0.0003963782510254532\n",
      "Gradient for decoder.decoder.3.weight: 0.00904414989054203\n",
      "Gradient for decoder.decoder.3.bias: 6.909562505486022e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0003460264706518501\n",
      "Gradient for decoder.decoder.4.bias: 0.0003145791415590793\n",
      "Gradient for decoder.decoder.6.weight: 0.00043439926230348647\n",
      "Gradient for decoder.decoder.6.bias: 2.5411349270143546e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.009035364724695683\n",
      "Gradient for encoder.encoder.0.bias: 1.5042370127282823e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0009436570107936859\n",
      "Gradient for encoder.encoder.1.bias: 0.0009111396502703428\n",
      "Gradient for encoder.encoder.3.weight: 0.02027316577732563\n",
      "Gradient for encoder.encoder.3.bias: 1.757724937823113e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0043967184610664845\n",
      "Gradient for encoder.encoder.4.bias: 0.003846691222861409\n",
      "Gradient for encoder.mean.weight: 0.05499379336833954\n",
      "Gradient for encoder.mean.bias: 0.002733873436227441\n",
      "Gradient for encoder.log_var.weight: 0.03421691060066223\n",
      "Gradient for encoder.log_var.bias: 0.001496535143814981\n",
      "Gradient for decoder.decoder.0.weight: 0.010463620536029339\n",
      "Gradient for decoder.decoder.0.bias: 8.531750306239871e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005275272415019572\n",
      "Gradient for decoder.decoder.1.bias: 0.00041191745549440384\n",
      "Gradient for decoder.decoder.3.weight: 0.009651494212448597\n",
      "Gradient for decoder.decoder.3.bias: 6.951410974620487e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0003775541845243424\n",
      "Gradient for decoder.decoder.4.bias: 0.00032405281672254205\n",
      "Gradient for decoder.decoder.6.weight: 0.0004555567284114659\n",
      "Gradient for decoder.decoder.6.bias: 2.8258280508453026e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.01497679390013218\n",
      "Gradient for encoder.encoder.0.bias: 1.9686665492235633e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0012465942418202758\n",
      "Gradient for encoder.encoder.1.bias: 0.001047302852384746\n",
      "Gradient for encoder.encoder.3.weight: 0.026390695944428444\n",
      "Gradient for encoder.encoder.3.bias: 2.7751384523710954e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.004774524364620447\n",
      "Gradient for encoder.encoder.4.bias: 0.005572330206632614\n",
      "Gradient for encoder.mean.weight: 0.06323125213384628\n",
      "Gradient for encoder.mean.bias: 0.004172447137534618\n",
      "Gradient for encoder.log_var.weight: 0.044243793934583664\n",
      "Gradient for encoder.log_var.bias: 0.002994025591760874\n",
      "Gradient for decoder.decoder.0.weight: 0.011259322054684162\n",
      "Gradient for decoder.decoder.0.bias: 9.075919876755378e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005956867826171219\n",
      "Gradient for decoder.decoder.1.bias: 0.00047399074537679553\n",
      "Gradient for decoder.decoder.3.weight: 0.011130415834486485\n",
      "Gradient for decoder.decoder.3.bias: 9.987943805356281e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0005172111559659243\n",
      "Gradient for decoder.decoder.4.bias: 0.0005323057994246483\n",
      "Gradient for decoder.decoder.6.weight: 0.0004841400950681418\n",
      "Gradient for decoder.decoder.6.bias: 3.111754995188676e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.008653069846332073\n",
      "Gradient for encoder.encoder.0.bias: 1.2965285095534185e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0007496069301851094\n",
      "Gradient for encoder.encoder.1.bias: 0.0006687932182103395\n",
      "Gradient for encoder.encoder.3.weight: 0.015202820301055908\n",
      "Gradient for encoder.encoder.3.bias: 1.5473797243537035e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0029797102324664593\n",
      "Gradient for encoder.encoder.4.bias: 0.0028732765931636095\n",
      "Gradient for encoder.mean.weight: 0.04069975018501282\n",
      "Gradient for encoder.mean.bias: 0.0021031696815043688\n",
      "Gradient for encoder.log_var.weight: 0.027624547481536865\n",
      "Gradient for encoder.log_var.bias: 0.0014735059812664986\n",
      "Gradient for decoder.decoder.0.weight: 0.011700130067765713\n",
      "Gradient for decoder.decoder.0.bias: 9.475448203843939e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.000602987187448889\n",
      "Gradient for decoder.decoder.1.bias: 0.0004865305672865361\n",
      "Gradient for decoder.decoder.3.weight: 0.011760354042053223\n",
      "Gradient for decoder.decoder.3.bias: 8.818992064396625e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00047888755216263235\n",
      "Gradient for decoder.decoder.4.bias: 0.0004552632162813097\n",
      "Gradient for decoder.decoder.6.weight: 0.00047244562301784754\n",
      "Gradient for decoder.decoder.6.bias: 2.4819877580739558e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.011134388856589794\n",
      "Gradient for encoder.encoder.0.bias: 1.4961849467698407e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.001092733582481742\n",
      "Gradient for encoder.encoder.1.bias: 0.0008464378188364208\n",
      "Gradient for encoder.encoder.3.weight: 0.022196179255843163\n",
      "Gradient for encoder.encoder.3.bias: 1.5314040313629818e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0036639466416090727\n",
      "Gradient for encoder.encoder.4.bias: 0.003067537909373641\n",
      "Gradient for encoder.mean.weight: 0.049056317657232285\n",
      "Gradient for encoder.mean.bias: 0.002242365386337042\n",
      "Gradient for encoder.log_var.weight: 0.02834230288863182\n",
      "Gradient for encoder.log_var.bias: 0.0013779076980426908\n",
      "Gradient for decoder.decoder.0.weight: 0.012527700513601303\n",
      "Gradient for decoder.decoder.0.bias: 9.683162605078621e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0006481779273599386\n",
      "Gradient for decoder.decoder.1.bias: 0.0004949291469529271\n",
      "Gradient for decoder.decoder.3.weight: 0.01154798548668623\n",
      "Gradient for decoder.decoder.3.bias: 9.262086930750257e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00042070262134075165\n",
      "Gradient for decoder.decoder.4.bias: 0.00038325716741383076\n",
      "Gradient for decoder.decoder.6.weight: 0.00042441938421688974\n",
      "Gradient for decoder.decoder.6.bias: 2.1395308067440055e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.017640257254242897\n",
      "Gradient for encoder.encoder.0.bias: 2.7833442148295084e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0019897257443517447\n",
      "Gradient for encoder.encoder.1.bias: 0.0020860638469457626\n",
      "Gradient for encoder.encoder.3.weight: 0.04292484000325203\n",
      "Gradient for encoder.encoder.3.bias: 3.9873904178477915e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.008928174152970314\n",
      "Gradient for encoder.encoder.4.bias: 0.01117003709077835\n",
      "Gradient for encoder.mean.weight: 0.1160433366894722\n",
      "Gradient for encoder.mean.bias: 0.00880963634699583\n",
      "Gradient for encoder.log_var.weight: 0.07216840982437134\n",
      "Gradient for encoder.log_var.bias: 0.0059177386574447155\n",
      "Gradient for decoder.decoder.0.weight: 0.009596534073352814\n",
      "Gradient for decoder.decoder.0.bias: 8.849113108944096e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0004556367639452219\n",
      "Gradient for decoder.decoder.1.bias: 0.0003857718256767839\n",
      "Gradient for decoder.decoder.3.weight: 0.009083330631256104\n",
      "Gradient for decoder.decoder.3.bias: 8.088129471728323e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0003954752755817026\n",
      "Gradient for decoder.decoder.4.bias: 0.00043833290692418814\n",
      "Gradient for decoder.decoder.6.weight: 0.0004080871003679931\n",
      "Gradient for decoder.decoder.6.bias: 2.3546532247564755e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.005864087026566267\n",
      "Gradient for encoder.encoder.0.bias: 1.0295776384228184e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0005136033287271857\n",
      "Gradient for encoder.encoder.1.bias: 0.0006478475988842547\n",
      "Gradient for encoder.encoder.3.weight: 0.011365559883415699\n",
      "Gradient for encoder.encoder.3.bias: 1.727266385476156e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.005010254215449095\n",
      "Gradient for encoder.encoder.4.bias: 0.003628987353295088\n",
      "Gradient for encoder.mean.weight: 0.066372349858284\n",
      "Gradient for encoder.mean.bias: 0.0025414638221263885\n",
      "Gradient for encoder.log_var.weight: 0.04010336101055145\n",
      "Gradient for encoder.log_var.bias: 0.0013925150269642472\n",
      "Gradient for decoder.decoder.0.weight: 0.014973251149058342\n",
      "Gradient for decoder.decoder.0.bias: 1.184472797621794e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0007452315185219049\n",
      "Gradient for decoder.decoder.1.bias: 0.0005975572858005762\n",
      "Gradient for decoder.decoder.3.weight: 0.01397460326552391\n",
      "Gradient for decoder.decoder.3.bias: 1.1163607538389186e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0005793471354991198\n",
      "Gradient for decoder.decoder.4.bias: 0.0005380121874623001\n",
      "Gradient for decoder.decoder.6.weight: 0.0004813746199943125\n",
      "Gradient for decoder.decoder.6.bias: 2.83603512798436e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.012315512634813786\n",
      "Gradient for encoder.encoder.0.bias: 1.7766302318200644e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0015012046787887812\n",
      "Gradient for encoder.encoder.1.bias: 0.001368893776088953\n",
      "Gradient for encoder.encoder.3.weight: 0.02865571528673172\n",
      "Gradient for encoder.encoder.3.bias: 1.955698103461856e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.005915324203670025\n",
      "Gradient for encoder.encoder.4.bias: 0.004502376541495323\n",
      "Gradient for encoder.mean.weight: 0.07858893275260925\n",
      "Gradient for encoder.mean.bias: 0.0031578296329826117\n",
      "Gradient for encoder.log_var.weight: 0.047557055950164795\n",
      "Gradient for encoder.log_var.bias: 0.0020752244163304567\n",
      "Gradient for decoder.decoder.0.weight: 0.011365017853677273\n",
      "Gradient for decoder.decoder.0.bias: 1.0027263047662771e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0005832784227095544\n",
      "Gradient for decoder.decoder.1.bias: 0.00045682446216233075\n",
      "Gradient for decoder.decoder.3.weight: 0.0106743099167943\n",
      "Gradient for decoder.decoder.3.bias: 8.325463235481223e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00041102070827037096\n",
      "Gradient for decoder.decoder.4.bias: 0.00038334555574692786\n",
      "Gradient for decoder.decoder.6.weight: 0.00045041259727440774\n",
      "Gradient for decoder.decoder.6.bias: 2.127139850927051e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.011708318255841732\n",
      "Gradient for encoder.encoder.0.bias: 1.789160139487045e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0009287428692914546\n",
      "Gradient for encoder.encoder.1.bias: 0.0008291524718515575\n",
      "Gradient for encoder.encoder.3.weight: 0.01833750493824482\n",
      "Gradient for encoder.encoder.3.bias: 1.622222772779125e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.003384371753782034\n",
      "Gradient for encoder.encoder.4.bias: 0.0025763758458197117\n",
      "Gradient for encoder.mean.weight: 0.04544968903064728\n",
      "Gradient for encoder.mean.bias: 0.001973319798707962\n",
      "Gradient for encoder.log_var.weight: 0.02482043206691742\n",
      "Gradient for encoder.log_var.bias: 0.0012343383859843016\n",
      "Gradient for decoder.decoder.0.weight: 0.010870513506233692\n",
      "Gradient for decoder.decoder.0.bias: 9.259128186389631e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0006033962708897889\n",
      "Gradient for decoder.decoder.1.bias: 0.0004569987941067666\n",
      "Gradient for decoder.decoder.3.weight: 0.010622591711580753\n",
      "Gradient for decoder.decoder.3.bias: 8.356818015364809e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0004497940244618803\n",
      "Gradient for decoder.decoder.4.bias: 0.0004734884132631123\n",
      "Gradient for decoder.decoder.6.weight: 0.00042949820635840297\n",
      "Gradient for decoder.decoder.6.bias: 2.670435787877068e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.013384940102696419\n",
      "Gradient for encoder.encoder.0.bias: 2.3858548817146108e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0013414969434961677\n",
      "Gradient for encoder.encoder.1.bias: 0.0010305908508598804\n",
      "Gradient for encoder.encoder.3.weight: 0.027232907712459564\n",
      "Gradient for encoder.encoder.3.bias: 1.9322601851889942e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.006027159281075001\n",
      "Gradient for encoder.encoder.4.bias: 0.004367351531982422\n",
      "Gradient for encoder.mean.weight: 0.0796842947602272\n",
      "Gradient for encoder.mean.bias: 0.0026821689680218697\n",
      "Gradient for encoder.log_var.weight: 0.04969755560159683\n",
      "Gradient for encoder.log_var.bias: 0.0015684571117162704\n",
      "Gradient for decoder.decoder.0.weight: 0.009672774001955986\n",
      "Gradient for decoder.decoder.0.bias: 7.834714127463727e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005049688625149429\n",
      "Gradient for decoder.decoder.1.bias: 0.0003887491475325078\n",
      "Gradient for decoder.decoder.3.weight: 0.008929017931222916\n",
      "Gradient for decoder.decoder.3.bias: 6.443095362795859e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0003276841889601201\n",
      "Gradient for decoder.decoder.4.bias: 0.0003096568980254233\n",
      "Gradient for decoder.decoder.6.weight: 0.0003984913928434253\n",
      "Gradient for decoder.decoder.6.bias: 2.134014903276693e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.012833031825721264\n",
      "Gradient for encoder.encoder.0.bias: 1.8164924425745355e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0010023486101999879\n",
      "Gradient for encoder.encoder.1.bias: 0.0008434633491560817\n",
      "Gradient for encoder.encoder.3.weight: 0.02147621288895607\n",
      "Gradient for encoder.encoder.3.bias: 1.8719041594561503e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.00423324853181839\n",
      "Gradient for encoder.encoder.4.bias: 0.003620912553742528\n",
      "Gradient for encoder.mean.weight: 0.05596045404672623\n",
      "Gradient for encoder.mean.bias: 0.0023639113642275333\n",
      "Gradient for encoder.log_var.weight: 0.03606828674674034\n",
      "Gradient for encoder.log_var.bias: 0.0015487041091546416\n",
      "Gradient for decoder.decoder.0.weight: 0.009204226545989513\n",
      "Gradient for decoder.decoder.0.bias: 7.866726714489403e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.00045680307084694505\n",
      "Gradient for decoder.decoder.1.bias: 0.00037107933894731104\n",
      "Gradient for decoder.decoder.3.weight: 0.008251211605966091\n",
      "Gradient for decoder.decoder.3.bias: 6.494792897937529e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0003187103720847517\n",
      "Gradient for decoder.decoder.4.bias: 0.0002745366364251822\n",
      "Gradient for decoder.decoder.6.weight: 0.00047165804426185787\n",
      "Gradient for decoder.decoder.6.bias: 3.145426308037713e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.008400035090744495\n",
      "Gradient for encoder.encoder.0.bias: 1.5195570496340238e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.000833907222840935\n",
      "Gradient for encoder.encoder.1.bias: 0.0010518759954720736\n",
      "Gradient for encoder.encoder.3.weight: 0.01827804557979107\n",
      "Gradient for encoder.encoder.3.bias: 1.810748356811942e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.004876032471656799\n",
      "Gradient for encoder.encoder.4.bias: 0.003846501698717475\n",
      "Gradient for encoder.mean.weight: 0.06773871928453445\n",
      "Gradient for encoder.mean.bias: 0.0028272722847759724\n",
      "Gradient for encoder.log_var.weight: 0.03419836610555649\n",
      "Gradient for encoder.log_var.bias: 0.0016844826750457287\n",
      "Gradient for decoder.decoder.0.weight: 0.011543246917426586\n",
      "Gradient for decoder.decoder.0.bias: 9.371271814107018e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005862793186679482\n",
      "Gradient for decoder.decoder.1.bias: 0.00043447999632917345\n",
      "Gradient for decoder.decoder.3.weight: 0.010613219812512398\n",
      "Gradient for decoder.decoder.3.bias: 8.377015053850911e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00036278527113609016\n",
      "Gradient for decoder.decoder.4.bias: 0.00034565868554636836\n",
      "Gradient for decoder.decoder.6.weight: 0.0004208267782814801\n",
      "Gradient for decoder.decoder.6.bias: 2.1424040824058466e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.010128902271389961\n",
      "Gradient for encoder.encoder.0.bias: 1.6740549918514702e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0011166920885443687\n",
      "Gradient for encoder.encoder.1.bias: 0.0009806278394535184\n",
      "Gradient for encoder.encoder.3.weight: 0.022373657673597336\n",
      "Gradient for encoder.encoder.3.bias: 1.5704350320167038e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0034748599864542484\n",
      "Gradient for encoder.encoder.4.bias: 0.0030227669049054384\n",
      "Gradient for encoder.mean.weight: 0.04956851527094841\n",
      "Gradient for encoder.mean.bias: 0.0018753968179225922\n",
      "Gradient for encoder.log_var.weight: 0.02681555040180683\n",
      "Gradient for encoder.log_var.bias: 0.0012650907738134265\n",
      "Gradient for decoder.decoder.0.weight: 0.011693158186972141\n",
      "Gradient for decoder.decoder.0.bias: 9.540290085707781e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005666472716256976\n",
      "Gradient for decoder.decoder.1.bias: 0.0004764942859765142\n",
      "Gradient for decoder.decoder.3.weight: 0.010658136568963528\n",
      "Gradient for decoder.decoder.3.bias: 9.156463781634372e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0005021695396862924\n",
      "Gradient for decoder.decoder.4.bias: 0.0005609617801383138\n",
      "Gradient for decoder.decoder.6.weight: 0.0004691214708145708\n",
      "Gradient for decoder.decoder.6.bias: 2.8261574698262848e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.010685617104172707\n",
      "Gradient for encoder.encoder.0.bias: 1.5030603497945272e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.000979717238806188\n",
      "Gradient for encoder.encoder.1.bias: 0.0007960477378219366\n",
      "Gradient for encoder.encoder.3.weight: 0.021076571196317673\n",
      "Gradient for encoder.encoder.3.bias: 1.541990840570051e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0033509046770632267\n",
      "Gradient for encoder.encoder.4.bias: 0.0026021061930805445\n",
      "Gradient for encoder.mean.weight: 0.04962356761097908\n",
      "Gradient for encoder.mean.bias: 0.002072745468467474\n",
      "Gradient for encoder.log_var.weight: 0.02548672817647457\n",
      "Gradient for encoder.log_var.bias: 0.001110138138756156\n",
      "Gradient for decoder.decoder.0.weight: 0.011998922564089298\n",
      "Gradient for decoder.decoder.0.bias: 1.0967397823247182e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0006506465142592788\n",
      "Gradient for decoder.decoder.1.bias: 0.00047437596367672086\n",
      "Gradient for decoder.decoder.3.weight: 0.011166014708578587\n",
      "Gradient for decoder.decoder.3.bias: 8.324671507686787e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.000392236455809325\n",
      "Gradient for decoder.decoder.4.bias: 0.0003531202091835439\n",
      "Gradient for decoder.decoder.6.weight: 0.0004404719511512667\n",
      "Gradient for decoder.decoder.6.bias: 2.277889689139556e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.007926147431135178\n",
      "Gradient for encoder.encoder.0.bias: 1.2521690281874776e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0008066987502388656\n",
      "Gradient for encoder.encoder.1.bias: 0.0008973058429546654\n",
      "Gradient for encoder.encoder.3.weight: 0.017464637756347656\n",
      "Gradient for encoder.encoder.3.bias: 1.9315661570207254e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.007078275550156832\n",
      "Gradient for encoder.encoder.4.bias: 0.004368966445326805\n",
      "Gradient for encoder.mean.weight: 0.09535186737775803\n",
      "Gradient for encoder.mean.bias: 0.0023463494144380093\n",
      "Gradient for encoder.log_var.weight: 0.053696226328611374\n",
      "Gradient for encoder.log_var.bias: 0.0014650687808170915\n",
      "Gradient for decoder.decoder.0.weight: 0.013755938969552517\n",
      "Gradient for decoder.decoder.0.bias: 1.2589322639922074e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0007071537547744811\n",
      "Gradient for decoder.decoder.1.bias: 0.0005784677923657\n",
      "Gradient for decoder.decoder.3.weight: 0.012965759262442589\n",
      "Gradient for decoder.decoder.3.bias: 1.0226388486023197e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.00047209675540216267\n",
      "Gradient for decoder.decoder.4.bias: 0.0004176827205810696\n",
      "Gradient for decoder.decoder.6.weight: 0.0004344340995885432\n",
      "Gradient for decoder.decoder.6.bias: 2.09139925573254e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.011526296846568584\n",
      "Gradient for encoder.encoder.0.bias: 2.0372285455816375e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0011692134430631995\n",
      "Gradient for encoder.encoder.1.bias: 0.0011694784043356776\n",
      "Gradient for encoder.encoder.3.weight: 0.025200944393873215\n",
      "Gradient for encoder.encoder.3.bias: 2.1562063245994523e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0049925255589187145\n",
      "Gradient for encoder.encoder.4.bias: 0.004892668221145868\n",
      "Gradient for encoder.mean.weight: 0.06847698986530304\n",
      "Gradient for encoder.mean.bias: 0.004047995898872614\n",
      "Gradient for encoder.log_var.weight: 0.03543087840080261\n",
      "Gradient for encoder.log_var.bias: 0.002241488778963685\n",
      "Gradient for decoder.decoder.0.weight: 0.00982178095728159\n",
      "Gradient for decoder.decoder.0.bias: 8.184798672150606e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.00047704734606668353\n",
      "Gradient for decoder.decoder.1.bias: 0.0003911251260433346\n",
      "Gradient for decoder.decoder.3.weight: 0.009012006223201752\n",
      "Gradient for decoder.decoder.3.bias: 6.80531325736311e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00039426455623470247\n",
      "Gradient for decoder.decoder.4.bias: 0.000380971614504233\n",
      "Gradient for decoder.decoder.6.weight: 0.0004077993507962674\n",
      "Gradient for decoder.decoder.6.bias: 2.34182571148267e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.012362237088382244\n",
      "Gradient for encoder.encoder.0.bias: 2.0218805796279327e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.00116790272295475\n",
      "Gradient for encoder.encoder.1.bias: 0.001048827776685357\n",
      "Gradient for encoder.encoder.3.weight: 0.02466335892677307\n",
      "Gradient for encoder.encoder.3.bias: 2.1882066991718574e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.004547977354377508\n",
      "Gradient for encoder.encoder.4.bias: 0.0048546870239079\n",
      "Gradient for encoder.mean.weight: 0.06310977786779404\n",
      "Gradient for encoder.mean.bias: 0.003888844046741724\n",
      "Gradient for encoder.log_var.weight: 0.03876282647252083\n",
      "Gradient for encoder.log_var.bias: 0.002323674038052559\n",
      "Gradient for decoder.decoder.0.weight: 0.01127176359295845\n",
      "Gradient for decoder.decoder.0.bias: 9.252336397036487e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005634061526507139\n",
      "Gradient for decoder.decoder.1.bias: 0.00042649981332942843\n",
      "Gradient for decoder.decoder.3.weight: 0.011087668128311634\n",
      "Gradient for decoder.decoder.3.bias: 7.64055901880667e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00036217394517734647\n",
      "Gradient for decoder.decoder.4.bias: 0.00033625439391471446\n",
      "Gradient for decoder.decoder.6.weight: 0.0004218550166115165\n",
      "Gradient for decoder.decoder.6.bias: 2.059191137959715e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training VAE Epoch:  77%|███████▋  | 61/79 [00:00<00:00, 75.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient for encoder.encoder.0.weight: 0.014163633808493614\n",
      "Gradient for encoder.encoder.0.bias: 2.389637099309283e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0015121561009436846\n",
      "Gradient for encoder.encoder.1.bias: 0.0012758636148646474\n",
      "Gradient for encoder.encoder.3.weight: 0.03387409448623657\n",
      "Gradient for encoder.encoder.3.bias: 2.5332416719869855e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.007193400524556637\n",
      "Gradient for encoder.encoder.4.bias: 0.006261696107685566\n",
      "Gradient for encoder.mean.weight: 0.09351260960102081\n",
      "Gradient for encoder.mean.bias: 0.0038914824835956097\n",
      "Gradient for encoder.log_var.weight: 0.05018380656838417\n",
      "Gradient for encoder.log_var.bias: 0.0025036418810486794\n",
      "Gradient for decoder.decoder.0.weight: 0.010012294165790081\n",
      "Gradient for decoder.decoder.0.bias: 8.519682875851586e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005116303800605237\n",
      "Gradient for decoder.decoder.1.bias: 0.00038874760502949357\n",
      "Gradient for decoder.decoder.3.weight: 0.009463898837566376\n",
      "Gradient for decoder.decoder.3.bias: 8.01353705615071e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0003503615444060415\n",
      "Gradient for decoder.decoder.4.bias: 0.00029245056794025004\n",
      "Gradient for decoder.decoder.6.weight: 0.000493384781293571\n",
      "Gradient for decoder.decoder.6.bias: 3.409306373214349e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.01611185632646084\n",
      "Gradient for encoder.encoder.0.bias: 2.4106720092342826e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0016587207792326808\n",
      "Gradient for encoder.encoder.1.bias: 0.0012735319323837757\n",
      "Gradient for encoder.encoder.3.weight: 0.033295441418886185\n",
      "Gradient for encoder.encoder.3.bias: 2.264525927886396e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.005344694014638662\n",
      "Gradient for encoder.encoder.4.bias: 0.005001790355890989\n",
      "Gradient for encoder.mean.weight: 0.07318690419197083\n",
      "Gradient for encoder.mean.bias: 0.0034694073256105185\n",
      "Gradient for encoder.log_var.weight: 0.044038526713848114\n",
      "Gradient for encoder.log_var.bias: 0.0023692178074270487\n",
      "Gradient for decoder.decoder.0.weight: 0.010224889032542706\n",
      "Gradient for decoder.decoder.0.bias: 9.656356964038437e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005140739376656711\n",
      "Gradient for decoder.decoder.1.bias: 0.0004539653891697526\n",
      "Gradient for decoder.decoder.3.weight: 0.009795060381293297\n",
      "Gradient for decoder.decoder.3.bias: 7.540891522328508e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0003315859939903021\n",
      "Gradient for decoder.decoder.4.bias: 0.00028794034733437\n",
      "Gradient for decoder.decoder.6.weight: 0.00043190314318053424\n",
      "Gradient for decoder.decoder.6.bias: 2.3143506041378714e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.007349678780883551\n",
      "Gradient for encoder.encoder.0.bias: 1.2401745429213573e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0009017772972583771\n",
      "Gradient for encoder.encoder.1.bias: 0.0009032413363456726\n",
      "Gradient for encoder.encoder.3.weight: 0.01920359581708908\n",
      "Gradient for encoder.encoder.3.bias: 1.7681311970108027e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.005464156158268452\n",
      "Gradient for encoder.encoder.4.bias: 0.003997548017650843\n",
      "Gradient for encoder.mean.weight: 0.0720331221818924\n",
      "Gradient for encoder.mean.bias: 0.002818232635036111\n",
      "Gradient for encoder.log_var.weight: 0.04312238097190857\n",
      "Gradient for encoder.log_var.bias: 0.0014315129956230521\n",
      "Gradient for decoder.decoder.0.weight: 0.01313746627420187\n",
      "Gradient for decoder.decoder.0.bias: 1.1197530402906608e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0006345426081679761\n",
      "Gradient for decoder.decoder.1.bias: 0.000504746101796627\n",
      "Gradient for decoder.decoder.3.weight: 0.012261372059583664\n",
      "Gradient for decoder.decoder.3.bias: 8.951790003708382e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00046059678425081074\n",
      "Gradient for decoder.decoder.4.bias: 0.0003968399832956493\n",
      "Gradient for decoder.decoder.6.weight: 0.0004658890247810632\n",
      "Gradient for decoder.decoder.6.bias: 2.4965069314930588e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.012257646769285202\n",
      "Gradient for encoder.encoder.0.bias: 1.6281379022764497e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.000995777198113501\n",
      "Gradient for encoder.encoder.1.bias: 0.0007720182184129953\n",
      "Gradient for encoder.encoder.3.weight: 0.021134691312909126\n",
      "Gradient for encoder.encoder.3.bias: 1.2840503660349611e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0025619431398808956\n",
      "Gradient for encoder.encoder.4.bias: 0.0020511110778898\n",
      "Gradient for encoder.mean.weight: 0.03932629153132439\n",
      "Gradient for encoder.mean.bias: 0.001755002187564969\n",
      "Gradient for encoder.log_var.weight: 0.02288176864385605\n",
      "Gradient for encoder.log_var.bias: 0.0010517275659367442\n",
      "Gradient for decoder.decoder.0.weight: 0.009947873651981354\n",
      "Gradient for decoder.decoder.0.bias: 8.396948414368666e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005018982919864357\n",
      "Gradient for decoder.decoder.1.bias: 0.0003921305760741234\n",
      "Gradient for decoder.decoder.3.weight: 0.00896529946476221\n",
      "Gradient for decoder.decoder.3.bias: 7.563210474570425e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0003807753964792937\n",
      "Gradient for decoder.decoder.4.bias: 0.00041096037602983415\n",
      "Gradient for decoder.decoder.6.weight: 0.00040757196256890893\n",
      "Gradient for decoder.decoder.6.bias: 2.407446845609229e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.015253329649567604\n",
      "Gradient for encoder.encoder.0.bias: 2.4405843665475935e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0013524700189009309\n",
      "Gradient for encoder.encoder.1.bias: 0.0011446024291217327\n",
      "Gradient for encoder.encoder.3.weight: 0.028944894671440125\n",
      "Gradient for encoder.encoder.3.bias: 2.2864127258159783e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.00463427510112524\n",
      "Gradient for encoder.encoder.4.bias: 0.0050491769798099995\n",
      "Gradient for encoder.mean.weight: 0.06396247446537018\n",
      "Gradient for encoder.mean.bias: 0.004157782532274723\n",
      "Gradient for encoder.log_var.weight: 0.04058841988444328\n",
      "Gradient for encoder.log_var.bias: 0.0026552474591881037\n",
      "Gradient for decoder.decoder.0.weight: 0.009520637802779675\n",
      "Gradient for decoder.decoder.0.bias: 8.12930833760106e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.00048237567534670234\n",
      "Gradient for decoder.decoder.1.bias: 0.0003705260169226676\n",
      "Gradient for decoder.decoder.3.weight: 0.009103531017899513\n",
      "Gradient for decoder.decoder.3.bias: 7.102034932371382e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0003334073699079454\n",
      "Gradient for decoder.decoder.4.bias: 0.00028323126025497913\n",
      "Gradient for decoder.decoder.6.weight: 0.0004255152598489076\n",
      "Gradient for decoder.decoder.6.bias: 2.4056525944615714e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.011235598474740982\n",
      "Gradient for encoder.encoder.0.bias: 1.923517768676053e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0009852229850366712\n",
      "Gradient for encoder.encoder.1.bias: 0.0009517153957858682\n",
      "Gradient for encoder.encoder.3.weight: 0.020660795271396637\n",
      "Gradient for encoder.encoder.3.bias: 1.6919489420619271e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0032979780808091164\n",
      "Gradient for encoder.encoder.4.bias: 0.0034856621641665697\n",
      "Gradient for encoder.mean.weight: 0.04302673414349556\n",
      "Gradient for encoder.mean.bias: 0.0025230254977941513\n",
      "Gradient for encoder.log_var.weight: 0.02509148232638836\n",
      "Gradient for encoder.log_var.bias: 0.0016948000993579626\n",
      "Gradient for decoder.decoder.0.weight: 0.009964235126972198\n",
      "Gradient for decoder.decoder.0.bias: 7.483100944449816e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005000403616577387\n",
      "Gradient for decoder.decoder.1.bias: 0.00037379187415353954\n",
      "Gradient for decoder.decoder.3.weight: 0.009133605286478996\n",
      "Gradient for decoder.decoder.3.bias: 6.094377780208049e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00032996301888488233\n",
      "Gradient for decoder.decoder.4.bias: 0.0002859559317585081\n",
      "Gradient for decoder.decoder.6.weight: 0.00042495623347349465\n",
      "Gradient for decoder.decoder.6.bias: 2.2763451852370054e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.012302457354962826\n",
      "Gradient for encoder.encoder.0.bias: 1.6854276654876266e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0009533320553600788\n",
      "Gradient for encoder.encoder.1.bias: 0.0007134298211894929\n",
      "Gradient for encoder.encoder.3.weight: 0.01955389603972435\n",
      "Gradient for encoder.encoder.3.bias: 1.9263116102230526e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.004599485546350479\n",
      "Gradient for encoder.encoder.4.bias: 0.003884168341755867\n",
      "Gradient for encoder.mean.weight: 0.06078193336725235\n",
      "Gradient for encoder.mean.bias: 0.002135140122845769\n",
      "Gradient for encoder.log_var.weight: 0.03661336004734039\n",
      "Gradient for encoder.log_var.bias: 0.001241333899088204\n",
      "Gradient for decoder.decoder.0.weight: 0.010875236243009567\n",
      "Gradient for decoder.decoder.0.bias: 1.0068760408765698e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0005547520122490823\n",
      "Gradient for decoder.decoder.1.bias: 0.00045386937563307583\n",
      "Gradient for decoder.decoder.3.weight: 0.010188263840973377\n",
      "Gradient for decoder.decoder.3.bias: 8.313213312183265e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00035823346115648746\n",
      "Gradient for decoder.decoder.4.bias: 0.000308019487420097\n",
      "Gradient for decoder.decoder.6.weight: 0.00040360205457545817\n",
      "Gradient for decoder.decoder.6.bias: 2.1390886104200035e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.008693593554198742\n",
      "Gradient for encoder.encoder.0.bias: 1.4114669502629518e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.000864664267282933\n",
      "Gradient for encoder.encoder.1.bias: 0.0008377851918339729\n",
      "Gradient for encoder.encoder.3.weight: 0.018247270956635475\n",
      "Gradient for encoder.encoder.3.bias: 1.4292655947656385e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.003982808906584978\n",
      "Gradient for encoder.encoder.4.bias: 0.0027759952936321497\n",
      "Gradient for encoder.mean.weight: 0.055427033454179764\n",
      "Gradient for encoder.mean.bias: 0.0019464167999103665\n",
      "Gradient for encoder.log_var.weight: 0.032315272837877274\n",
      "Gradient for encoder.log_var.bias: 0.001197655452415347\n",
      "Gradient for decoder.decoder.0.weight: 0.01206129975616932\n",
      "Gradient for decoder.decoder.0.bias: 1.0578546372208564e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.000553298625163734\n",
      "Gradient for decoder.decoder.1.bias: 0.00042385453707538545\n",
      "Gradient for decoder.decoder.3.weight: 0.010783004574477673\n",
      "Gradient for decoder.decoder.3.bias: 8.726684652682337e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0004078415804542601\n",
      "Gradient for decoder.decoder.4.bias: 0.00037064123898744583\n",
      "Gradient for decoder.decoder.6.weight: 0.0004186099977232516\n",
      "Gradient for decoder.decoder.6.bias: 2.1611518604913726e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.012889283709228039\n",
      "Gradient for encoder.encoder.0.bias: 1.693688939097271e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0011637385468930006\n",
      "Gradient for encoder.encoder.1.bias: 0.001002377481199801\n",
      "Gradient for encoder.encoder.3.weight: 0.0243651382625103\n",
      "Gradient for encoder.encoder.3.bias: 1.660568210715141e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0036019189283251762\n",
      "Gradient for encoder.encoder.4.bias: 0.0029647403862327337\n",
      "Gradient for encoder.mean.weight: 0.05064408853650093\n",
      "Gradient for encoder.mean.bias: 0.0018380178371444345\n",
      "Gradient for encoder.log_var.weight: 0.030208831652998924\n",
      "Gradient for encoder.log_var.bias: 0.0010763485915958881\n",
      "Gradient for decoder.decoder.0.weight: 0.011627355590462685\n",
      "Gradient for decoder.decoder.0.bias: 9.968281061700779e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.00055519217858091\n",
      "Gradient for decoder.decoder.1.bias: 0.00042197981383651495\n",
      "Gradient for decoder.decoder.3.weight: 0.010360045358538628\n",
      "Gradient for decoder.decoder.3.bias: 9.82825210105176e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00038760839379392564\n",
      "Gradient for decoder.decoder.4.bias: 0.0003947647928725928\n",
      "Gradient for decoder.decoder.6.weight: 0.0004894058220088482\n",
      "Gradient for decoder.decoder.6.bias: 3.4176056942669675e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.018413890153169632\n",
      "Gradient for encoder.encoder.0.bias: 3.660552763684599e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0011020413367077708\n",
      "Gradient for encoder.encoder.1.bias: 0.0011097355745732784\n",
      "Gradient for encoder.encoder.3.weight: 0.025976402685046196\n",
      "Gradient for encoder.encoder.3.bias: 2.6789176432728823e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.005187319591641426\n",
      "Gradient for encoder.encoder.4.bias: 0.005806474946439266\n",
      "Gradient for encoder.mean.weight: 0.06825850903987885\n",
      "Gradient for encoder.mean.bias: 0.004753746557980776\n",
      "Gradient for encoder.log_var.weight: 0.04358885437250137\n",
      "Gradient for encoder.log_var.bias: 0.0029574306681752205\n",
      "Gradient for decoder.decoder.0.weight: 0.0076256366446614265\n",
      "Gradient for decoder.decoder.0.bias: 5.7634411132490015e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0004062190419062972\n",
      "Gradient for decoder.decoder.1.bias: 0.0003190981224179268\n",
      "Gradient for decoder.decoder.3.weight: 0.007787629496306181\n",
      "Gradient for decoder.decoder.3.bias: 7.167344495684347e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0004763068864122033\n",
      "Gradient for decoder.decoder.4.bias: 0.0005642648320645094\n",
      "Gradient for decoder.decoder.6.weight: 0.0004610774340108037\n",
      "Gradient for decoder.decoder.6.bias: 3.3890901249833405e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.013805615715682507\n",
      "Gradient for encoder.encoder.0.bias: 2.529544976259679e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.001188646536320448\n",
      "Gradient for encoder.encoder.1.bias: 0.0010173487244173884\n",
      "Gradient for encoder.encoder.3.weight: 0.027129868045449257\n",
      "Gradient for encoder.encoder.3.bias: 1.965961282657247e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.005795993376523256\n",
      "Gradient for encoder.encoder.4.bias: 0.004501090385019779\n",
      "Gradient for encoder.mean.weight: 0.0766143724322319\n",
      "Gradient for encoder.mean.bias: 0.0024354325141757727\n",
      "Gradient for encoder.log_var.weight: 0.04580986499786377\n",
      "Gradient for encoder.log_var.bias: 0.001512189395725727\n",
      "Gradient for decoder.decoder.0.weight: 0.00920209288597107\n",
      "Gradient for decoder.decoder.0.bias: 7.904878834841256e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0004650540358852595\n",
      "Gradient for decoder.decoder.1.bias: 0.0003623802913352847\n",
      "Gradient for decoder.decoder.3.weight: 0.008686669170856476\n",
      "Gradient for decoder.decoder.3.bias: 6.494088600206283e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0003189758863300085\n",
      "Gradient for decoder.decoder.4.bias: 0.00027648831019178033\n",
      "Gradient for decoder.decoder.6.weight: 0.00042935123201459646\n",
      "Gradient for decoder.decoder.6.bias: 2.2568865460925736e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.009189861826598644\n",
      "Gradient for encoder.encoder.0.bias: 1.3769174168898335e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0007066483958624303\n",
      "Gradient for encoder.encoder.1.bias: 0.0007578660733997822\n",
      "Gradient for encoder.encoder.3.weight: 0.015783732756972313\n",
      "Gradient for encoder.encoder.3.bias: 1.9240596615954786e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0054929605685174465\n",
      "Gradient for encoder.encoder.4.bias: 0.004191428888589144\n",
      "Gradient for encoder.mean.weight: 0.07066091895103455\n",
      "Gradient for encoder.mean.bias: 0.0025443201884627342\n",
      "Gradient for encoder.log_var.weight: 0.04804399982094765\n",
      "Gradient for encoder.log_var.bias: 0.0015517654828727245\n",
      "Gradient for decoder.decoder.0.weight: 0.011695067398250103\n",
      "Gradient for decoder.decoder.0.bias: 1.0929320642949492e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0005788679118268192\n",
      "Gradient for decoder.decoder.1.bias: 0.0004355863493401557\n",
      "Gradient for decoder.decoder.3.weight: 0.010591311380267143\n",
      "Gradient for decoder.decoder.3.bias: 9.723169491770989e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0003760413092095405\n",
      "Gradient for decoder.decoder.4.bias: 0.000357987912138924\n",
      "Gradient for decoder.decoder.6.weight: 0.0004098807112313807\n",
      "Gradient for decoder.decoder.6.bias: 2.4206463422160596e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.013879025354981422\n",
      "Gradient for encoder.encoder.0.bias: 2.5096546368841288e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0013483586953952909\n",
      "Gradient for encoder.encoder.1.bias: 0.0011146754259243608\n",
      "Gradient for encoder.encoder.3.weight: 0.027006464079022408\n",
      "Gradient for encoder.encoder.3.bias: 1.8724094497102328e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0034790586214512587\n",
      "Gradient for encoder.encoder.4.bias: 0.0031317046377807856\n",
      "Gradient for encoder.mean.weight: 0.04685165360569954\n",
      "Gradient for encoder.mean.bias: 0.0019266768358647823\n",
      "Gradient for encoder.log_var.weight: 0.023572424426674843\n",
      "Gradient for encoder.log_var.bias: 0.001145415473729372\n",
      "Gradient for decoder.decoder.0.weight: 0.008100003935396671\n",
      "Gradient for decoder.decoder.0.bias: 7.093321069406855e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.00042211555410176516\n",
      "Gradient for decoder.decoder.1.bias: 0.0003575905866455287\n",
      "Gradient for decoder.decoder.3.weight: 0.007451266516000032\n",
      "Gradient for decoder.decoder.3.bias: 6.186248735495781e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00025660201208665967\n",
      "Gradient for decoder.decoder.4.bias: 0.00022051355335861444\n",
      "Gradient for decoder.decoder.6.weight: 0.00046676432248204947\n",
      "Gradient for decoder.decoder.6.bias: 3.250673398724757e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.013646529987454414\n",
      "Gradient for encoder.encoder.0.bias: 2.054498411674377e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0010087473783642054\n",
      "Gradient for encoder.encoder.1.bias: 0.0009338577510789037\n",
      "Gradient for encoder.encoder.3.weight: 0.023625807836651802\n",
      "Gradient for encoder.encoder.3.bias: 2.4801458109457997e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.005401343107223511\n",
      "Gradient for encoder.encoder.4.bias: 0.005830877926200628\n",
      "Gradient for encoder.mean.weight: 0.0702160969376564\n",
      "Gradient for encoder.mean.bias: 0.004350336268544197\n",
      "Gradient for encoder.log_var.weight: 0.04405071958899498\n",
      "Gradient for encoder.log_var.bias: 0.0026494525372982025\n",
      "Gradient for decoder.decoder.0.weight: 0.00971037894487381\n",
      "Gradient for decoder.decoder.0.bias: 8.786994049048147e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.00046732419286854565\n",
      "Gradient for decoder.decoder.1.bias: 0.00037551060086116195\n",
      "Gradient for decoder.decoder.3.weight: 0.00923692062497139\n",
      "Gradient for decoder.decoder.3.bias: 7.47545220169954e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0003389835765119642\n",
      "Gradient for decoder.decoder.4.bias: 0.0003010534564964473\n",
      "Gradient for decoder.decoder.6.weight: 0.0004977232310920954\n",
      "Gradient for decoder.decoder.6.bias: 3.31040246237535e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.012768651358783245\n",
      "Gradient for encoder.encoder.0.bias: 1.4783141724650228e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0009241349762305617\n",
      "Gradient for encoder.encoder.1.bias: 0.0008650730014778674\n",
      "Gradient for encoder.encoder.3.weight: 0.02161896601319313\n",
      "Gradient for encoder.encoder.3.bias: 1.7217383074807913e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.004382340237498283\n",
      "Gradient for encoder.encoder.4.bias: 0.0033008812461048365\n",
      "Gradient for encoder.mean.weight: 0.05860595405101776\n",
      "Gradient for encoder.mean.bias: 0.002253805985674262\n",
      "Gradient for encoder.log_var.weight: 0.03330503776669502\n",
      "Gradient for encoder.log_var.bias: 0.001370353507809341\n",
      "Gradient for decoder.decoder.0.weight: 0.013315136544406414\n",
      "Gradient for decoder.decoder.0.bias: 1.174339375742406e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0007000654586590827\n",
      "Gradient for decoder.decoder.1.bias: 0.0005500377737917006\n",
      "Gradient for decoder.decoder.3.weight: 0.01267481129616499\n",
      "Gradient for decoder.decoder.3.bias: 9.202449219314346e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00047398844617418945\n",
      "Gradient for decoder.decoder.4.bias: 0.00043926623766310513\n",
      "Gradient for decoder.decoder.6.weight: 0.0004665038431994617\n",
      "Gradient for decoder.decoder.6.bias: 2.5429477318539284e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.009064032696187496\n",
      "Gradient for encoder.encoder.0.bias: 1.544816011223027e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0007617159280925989\n",
      "Gradient for encoder.encoder.1.bias: 0.0008257880108430982\n",
      "Gradient for encoder.encoder.3.weight: 0.01579347997903824\n",
      "Gradient for encoder.encoder.3.bias: 1.4857129415624115e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.004008457995951176\n",
      "Gradient for encoder.encoder.4.bias: 0.0033623280469328165\n",
      "Gradient for encoder.mean.weight: 0.0535484254360199\n",
      "Gradient for encoder.mean.bias: 0.0023389868438243866\n",
      "Gradient for encoder.log_var.weight: 0.03323720395565033\n",
      "Gradient for encoder.log_var.bias: 0.0016402353066951036\n",
      "Gradient for decoder.decoder.0.weight: 0.009771040640771389\n",
      "Gradient for decoder.decoder.0.bias: 8.140058765926383e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005508140893653035\n",
      "Gradient for decoder.decoder.1.bias: 0.0004176980000920594\n",
      "Gradient for decoder.decoder.3.weight: 0.009868037886917591\n",
      "Gradient for decoder.decoder.3.bias: 7.500904064539071e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0004546098061837256\n",
      "Gradient for decoder.decoder.4.bias: 0.00047188985627144575\n",
      "Gradient for decoder.decoder.6.weight: 0.0004401216865517199\n",
      "Gradient for decoder.decoder.6.bias: 2.6614627131493762e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient for encoder.encoder.0.weight: 0.009793735109269619\n",
      "Gradient for encoder.encoder.0.bias: 1.709992737686239e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.000903174455743283\n",
      "Gradient for encoder.encoder.1.bias: 0.000862624030560255\n",
      "Gradient for encoder.encoder.3.weight: 0.019221927970647812\n",
      "Gradient for encoder.encoder.3.bias: 1.6716307504882622e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.004041507374495268\n",
      "Gradient for encoder.encoder.4.bias: 0.0031527047976851463\n",
      "Gradient for encoder.mean.weight: 0.054472003132104874\n",
      "Gradient for encoder.mean.bias: 0.0023829147685319185\n",
      "Gradient for encoder.log_var.weight: 0.028719749301671982\n",
      "Gradient for encoder.log_var.bias: 0.0013389079831540585\n",
      "Gradient for decoder.decoder.0.weight: 0.010004510171711445\n",
      "Gradient for decoder.decoder.0.bias: 8.300316683973463e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005865549319423735\n",
      "Gradient for decoder.decoder.1.bias: 0.00039346670382656157\n",
      "Gradient for decoder.decoder.3.weight: 0.009693345054984093\n",
      "Gradient for decoder.decoder.3.bias: 6.856305800884144e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0003339784743729979\n",
      "Gradient for decoder.decoder.4.bias: 0.00028079014737159014\n",
      "Gradient for decoder.decoder.6.weight: 0.000416578259319067\n",
      "Gradient for decoder.decoder.6.bias: 1.8145939975511283e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.007967669516801834\n",
      "Gradient for encoder.encoder.0.bias: 1.3430641147837985e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0009964886121451855\n",
      "Gradient for encoder.encoder.1.bias: 0.0008503452991135418\n",
      "Gradient for encoder.encoder.3.weight: 0.02115371823310852\n",
      "Gradient for encoder.encoder.3.bias: 1.9338976253724383e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0043988279066979885\n",
      "Gradient for encoder.encoder.4.bias: 0.004355556331574917\n",
      "Gradient for encoder.mean.weight: 0.059799350798130035\n",
      "Gradient for encoder.mean.bias: 0.003140814835205674\n",
      "Gradient for encoder.log_var.weight: 0.03400086238980293\n",
      "Gradient for encoder.log_var.bias: 0.0018139125313609838\n",
      "Gradient for decoder.decoder.0.weight: 0.012042379006743431\n",
      "Gradient for decoder.decoder.0.bias: 1.0056339788677704e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0006324461428448558\n",
      "Gradient for decoder.decoder.1.bias: 0.0004703174636233598\n",
      "Gradient for decoder.decoder.3.weight: 0.011477876454591751\n",
      "Gradient for decoder.decoder.3.bias: 9.997986466503406e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0005624013138003647\n",
      "Gradient for decoder.decoder.4.bias: 0.0005945567972958088\n",
      "Gradient for decoder.decoder.6.weight: 0.0005326898535713553\n",
      "Gradient for decoder.decoder.6.bias: 3.725406713783741e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.012947681359946728\n",
      "Gradient for encoder.encoder.0.bias: 1.7757269613061233e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.001209582551382482\n",
      "Gradient for encoder.encoder.1.bias: 0.0010413348209112883\n",
      "Gradient for encoder.encoder.3.weight: 0.025645514950156212\n",
      "Gradient for encoder.encoder.3.bias: 2.258629949736246e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0057527413591742516\n",
      "Gradient for encoder.encoder.4.bias: 0.0060523576103150845\n",
      "Gradient for encoder.mean.weight: 0.07340987026691437\n",
      "Gradient for encoder.mean.bias: 0.004533299710601568\n",
      "Gradient for encoder.log_var.weight: 0.04812205582857132\n",
      "Gradient for encoder.log_var.bias: 0.0029689616058021784\n",
      "Gradient for decoder.decoder.0.weight: 0.011660447344183922\n",
      "Gradient for decoder.decoder.0.bias: 9.733665262690039e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0006157263997010887\n",
      "Gradient for decoder.decoder.1.bias: 0.0004924127133563161\n",
      "Gradient for decoder.decoder.3.weight: 0.011039909906685352\n",
      "Gradient for decoder.decoder.3.bias: 7.945091806682569e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0004296539700590074\n",
      "Gradient for decoder.decoder.4.bias: 0.00039246727828867733\n",
      "Gradient for decoder.decoder.6.weight: 0.00044670593342743814\n",
      "Gradient for decoder.decoder.6.bias: 2.045899054792244e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.014813406392931938\n",
      "Gradient for encoder.encoder.0.bias: 2.7739661262460302e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0015393967041745782\n",
      "Gradient for encoder.encoder.1.bias: 0.0011911161709576845\n",
      "Gradient for encoder.encoder.3.weight: 0.03142715245485306\n",
      "Gradient for encoder.encoder.3.bias: 2.1463858468351305e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.004898515995591879\n",
      "Gradient for encoder.encoder.4.bias: 0.003926525358110666\n",
      "Gradient for encoder.mean.weight: 0.062960684299469\n",
      "Gradient for encoder.mean.bias: 0.002870949450880289\n",
      "Gradient for encoder.log_var.weight: 0.036282554268836975\n",
      "Gradient for encoder.log_var.bias: 0.0012748573208227754\n",
      "Gradient for decoder.decoder.0.weight: 0.008020702749490738\n",
      "Gradient for decoder.decoder.0.bias: 6.908569549768373e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0004063376982230693\n",
      "Gradient for decoder.decoder.1.bias: 0.00031886552460491657\n",
      "Gradient for decoder.decoder.3.weight: 0.007244340144097805\n",
      "Gradient for decoder.decoder.3.bias: 6.835104010560755e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.000387826090445742\n",
      "Gradient for decoder.decoder.4.bias: 0.000444414938101545\n",
      "Gradient for decoder.decoder.6.weight: 0.00044805926154367626\n",
      "Gradient for decoder.decoder.6.bias: 3.006776751135476e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.010877872817218304\n",
      "Gradient for encoder.encoder.0.bias: 1.663333706880543e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0008738524047657847\n",
      "Gradient for encoder.encoder.1.bias: 0.0007290177163667977\n",
      "Gradient for encoder.encoder.3.weight: 0.019044047221541405\n",
      "Gradient for encoder.encoder.3.bias: 1.6645616829347176e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.004165340680629015\n",
      "Gradient for encoder.encoder.4.bias: 0.0036633401177823544\n",
      "Gradient for encoder.mean.weight: 0.05343881621956825\n",
      "Gradient for encoder.mean.bias: 0.002485399367287755\n",
      "Gradient for encoder.log_var.weight: 0.0311408881098032\n",
      "Gradient for encoder.log_var.bias: 0.0013932827860116959\n",
      "Gradient for decoder.decoder.0.weight: 0.010591167956590652\n",
      "Gradient for decoder.decoder.0.bias: 9.524785821168891e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005079282564111054\n",
      "Gradient for decoder.decoder.1.bias: 0.0004093560273759067\n",
      "Gradient for decoder.decoder.3.weight: 0.00973649974912405\n",
      "Gradient for decoder.decoder.3.bias: 9.174633275321753e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0003525502106640488\n",
      "Gradient for decoder.decoder.4.bias: 0.00030981158488430083\n",
      "Gradient for decoder.decoder.6.weight: 0.00042667839443311095\n",
      "Gradient for decoder.decoder.6.bias: 2.0591645807144232e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.008879493921995163\n",
      "Gradient for encoder.encoder.0.bias: 1.2957369552313303e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0006706942222081125\n",
      "Gradient for encoder.encoder.1.bias: 0.0005828624125570059\n",
      "Gradient for encoder.encoder.3.weight: 0.013917148113250732\n",
      "Gradient for encoder.encoder.3.bias: 1.1421363854680067e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0027485659811645746\n",
      "Gradient for encoder.encoder.4.bias: 0.002309946808964014\n",
      "Gradient for encoder.mean.weight: 0.03897456079721451\n",
      "Gradient for encoder.mean.bias: 0.0019240622641518712\n",
      "Gradient for encoder.log_var.weight: 0.021975792944431305\n",
      "Gradient for encoder.log_var.bias: 0.001059498405084014\n",
      "Gradient for decoder.decoder.0.weight: 0.010030873119831085\n",
      "Gradient for decoder.decoder.0.bias: 7.847777289127222e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005164901376701891\n",
      "Gradient for decoder.decoder.1.bias: 0.00037840197910554707\n",
      "Gradient for decoder.decoder.3.weight: 0.009825094603002071\n",
      "Gradient for decoder.decoder.3.bias: 9.064528988522724e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0006113573326729238\n",
      "Gradient for decoder.decoder.4.bias: 0.0007246949826367199\n",
      "Gradient for decoder.decoder.6.weight: 0.00048059970140457153\n",
      "Gradient for decoder.decoder.6.bias: 3.643423042376526e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.009458423592150211\n",
      "Gradient for encoder.encoder.0.bias: 1.3449190545966605e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0008035538485273719\n",
      "Gradient for encoder.encoder.1.bias: 0.0009025534382089972\n",
      "Gradient for encoder.encoder.3.weight: 0.017234886065125465\n",
      "Gradient for encoder.encoder.3.bias: 1.4934647962761005e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.003540129167959094\n",
      "Gradient for encoder.encoder.4.bias: 0.0029262739699333906\n",
      "Gradient for encoder.mean.weight: 0.048373568803071976\n",
      "Gradient for encoder.mean.bias: 0.0022423244081437588\n",
      "Gradient for encoder.log_var.weight: 0.026008516550064087\n",
      "Gradient for encoder.log_var.bias: 0.0013409546809270978\n",
      "Gradient for decoder.decoder.0.weight: 0.013054175302386284\n",
      "Gradient for decoder.decoder.0.bias: 1.0317987436669895e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0006329474272206426\n",
      "Gradient for decoder.decoder.1.bias: 0.0005302010104060173\n",
      "Gradient for decoder.decoder.3.weight: 0.011819957755506039\n",
      "Gradient for decoder.decoder.3.bias: 8.664413631009893e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0005664191558025777\n",
      "Gradient for decoder.decoder.4.bias: 0.0006338452221825719\n",
      "Gradient for decoder.decoder.6.weight: 0.0005483187851496041\n",
      "Gradient for decoder.decoder.6.bias: 3.769376053242013e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.016567951068282127\n",
      "Gradient for encoder.encoder.0.bias: 2.404717223958297e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0015874370001256466\n",
      "Gradient for encoder.encoder.1.bias: 0.0012011694489046931\n",
      "Gradient for encoder.encoder.3.weight: 0.03258746117353439\n",
      "Gradient for encoder.encoder.3.bias: 1.924845421941157e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.00452832505106926\n",
      "Gradient for encoder.encoder.4.bias: 0.003959228750318289\n",
      "Gradient for encoder.mean.weight: 0.06251156330108643\n",
      "Gradient for encoder.mean.bias: 0.002158943796530366\n",
      "Gradient for encoder.log_var.weight: 0.03525448963046074\n",
      "Gradient for encoder.log_var.bias: 0.0014288254315033555\n",
      "Gradient for decoder.decoder.0.weight: 0.010973489843308926\n",
      "Gradient for decoder.decoder.0.bias: 8.763153397373102e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005658181617036462\n",
      "Gradient for decoder.decoder.1.bias: 0.0004425014485605061\n",
      "Gradient for decoder.decoder.3.weight: 0.010220861993730068\n",
      "Gradient for decoder.decoder.3.bias: 7.399574702970924e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0004096556513104588\n",
      "Gradient for decoder.decoder.4.bias: 0.0004139390657655895\n",
      "Gradient for decoder.decoder.6.weight: 0.0004571029276121408\n",
      "Gradient for decoder.decoder.6.bias: 3.229928552173078e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.009172388352453709\n",
      "Gradient for encoder.encoder.0.bias: 1.4613374746397234e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0007942933007143438\n",
      "Gradient for encoder.encoder.1.bias: 0.0007531279698014259\n",
      "Gradient for encoder.encoder.3.weight: 0.01723763905465603\n",
      "Gradient for encoder.encoder.3.bias: 1.6029912119908118e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.003281662240624428\n",
      "Gradient for encoder.encoder.4.bias: 0.003254711627960205\n",
      "Gradient for encoder.mean.weight: 0.042051639407873154\n",
      "Gradient for encoder.mean.bias: 0.0022955876775085926\n",
      "Gradient for encoder.log_var.weight: 0.024785244837403297\n",
      "Gradient for encoder.log_var.bias: 0.0014208720531314611\n",
      "Gradient for decoder.decoder.0.weight: 0.010194736532866955\n",
      "Gradient for decoder.decoder.0.bias: 8.108137078410849e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005211163661442697\n",
      "Gradient for decoder.decoder.1.bias: 0.00044645348680205643\n",
      "Gradient for decoder.decoder.3.weight: 0.009618463926017284\n",
      "Gradient for decoder.decoder.3.bias: 6.95198482114634e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00035028610727749765\n",
      "Gradient for decoder.decoder.4.bias: 0.0002998948621097952\n",
      "Gradient for decoder.decoder.6.weight: 0.00043478378211148083\n",
      "Gradient for decoder.decoder.6.bias: 2.586568552942481e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.012688462622463703\n",
      "Gradient for encoder.encoder.0.bias: 2.474042498645801e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0008454637136310339\n",
      "Gradient for encoder.encoder.1.bias: 0.0009061283199116588\n",
      "Gradient for encoder.encoder.3.weight: 0.019559167325496674\n",
      "Gradient for encoder.encoder.3.bias: 2.0026200142631012e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.002758020767942071\n",
      "Gradient for encoder.encoder.4.bias: 0.0033789777662605047\n",
      "Gradient for encoder.mean.weight: 0.03867625817656517\n",
      "Gradient for encoder.mean.bias: 0.0028717683162540197\n",
      "Gradient for encoder.log_var.weight: 0.026758847758173943\n",
      "Gradient for encoder.log_var.bias: 0.0019500200869515538\n",
      "Gradient for decoder.decoder.0.weight: 0.008811078034341335\n",
      "Gradient for decoder.decoder.0.bias: 7.97832147569899e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.00044826086377725005\n",
      "Gradient for decoder.decoder.1.bias: 0.00034315302036702633\n",
      "Gradient for decoder.decoder.3.weight: 0.008219311945140362\n",
      "Gradient for decoder.decoder.3.bias: 7.253193184952877e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0003013418463524431\n",
      "Gradient for decoder.decoder.4.bias: 0.00027514409157447517\n",
      "Gradient for decoder.decoder.6.weight: 0.0004243783769197762\n",
      "Gradient for decoder.decoder.6.bias: 2.5800971343414858e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.009963913820683956\n",
      "Gradient for encoder.encoder.0.bias: 1.540823198198371e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.001124569564126432\n",
      "Gradient for encoder.encoder.1.bias: 0.0011428601574152708\n",
      "Gradient for encoder.encoder.3.weight: 0.02252652682363987\n",
      "Gradient for encoder.encoder.3.bias: 1.675329736050557e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0036049415357410908\n",
      "Gradient for encoder.encoder.4.bias: 0.003807527245953679\n",
      "Gradient for encoder.mean.weight: 0.04936540126800537\n",
      "Gradient for encoder.mean.bias: 0.003075891174376011\n",
      "Gradient for encoder.log_var.weight: 0.032956141978502274\n",
      "Gradient for encoder.log_var.bias: 0.002121486933901906\n",
      "Gradient for decoder.decoder.0.weight: 0.01082433108240366\n",
      "Gradient for decoder.decoder.0.bias: 9.947240947605351e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005453872145153582\n",
      "Gradient for decoder.decoder.1.bias: 0.0004197241796646267\n",
      "Gradient for decoder.decoder.3.weight: 0.009815206751227379\n",
      "Gradient for decoder.decoder.3.bias: 9.871226058777438e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0005608617793768644\n",
      "Gradient for decoder.decoder.4.bias: 0.000641485268715769\n",
      "Gradient for decoder.decoder.6.weight: 0.0004900795174762607\n",
      "Gradient for decoder.decoder.6.bias: 3.5335291613591835e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.17199622094631195\n",
      "Gradient for encoder.encoder.0.bias: 2.762731432515153e-10\n",
      "Gradient for encoder.encoder.1.weight: 0.011973160319030285\n",
      "Gradient for encoder.encoder.1.bias: 0.010175533592700958\n",
      "Gradient for encoder.encoder.3.weight: 0.26997309923171997\n",
      "Gradient for encoder.encoder.3.bias: 1.191030940539406e-09\n",
      "Gradient for encoder.encoder.4.weight: 0.01687220111489296\n",
      "Gradient for encoder.encoder.4.bias: 0.015610462054610252\n",
      "Gradient for encoder.mean.weight: 0.23736800253391266\n",
      "Gradient for encoder.mean.bias: 0.008737628348171711\n",
      "Gradient for encoder.log_var.weight: 0.1514202207326889\n",
      "Gradient for encoder.log_var.bias: 0.005952267907559872\n",
      "Gradient for decoder.decoder.0.weight: 0.024378953501582146\n",
      "Gradient for decoder.decoder.0.bias: 1.543780658863625e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0010688790353015065\n",
      "Gradient for decoder.decoder.1.bias: 0.000904922722838819\n",
      "Gradient for decoder.decoder.3.weight: 0.021373411640524864\n",
      "Gradient for decoder.decoder.3.bias: 1.2246481606581483e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0007288093329407275\n",
      "Gradient for decoder.decoder.4.bias: 0.0006037084967829287\n",
      "Gradient for decoder.decoder.6.weight: 0.0011902119731530547\n",
      "Gradient for decoder.decoder.6.bias: 7.653339707758278e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/3, Train Loss: 0.0490, Val Loss: 0.2414\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training VAE Epoch:   1%|▏         | 1/79 [00:00<00:14,  5.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient for encoder.encoder.0.weight: 0.020159704610705376\n",
      "Gradient for encoder.encoder.0.bias: 3.438703835567658e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0016057398170232773\n",
      "Gradient for encoder.encoder.1.bias: 0.0012979676248505712\n",
      "Gradient for encoder.encoder.3.weight: 0.03579004108905792\n",
      "Gradient for encoder.encoder.3.bias: 2.560585909971991e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.005389553029090166\n",
      "Gradient for encoder.encoder.4.bias: 0.004875815473496914\n",
      "Gradient for encoder.mean.weight: 0.07238533347845078\n",
      "Gradient for encoder.mean.bias: 0.0034969812259078026\n",
      "Gradient for encoder.log_var.weight: 0.042349182069301605\n",
      "Gradient for encoder.log_var.bias: 0.002062448300421238\n",
      "Gradient for decoder.decoder.0.weight: 0.008454390801489353\n",
      "Gradient for decoder.decoder.0.bias: 7.191600093214845e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.00042739565833471715\n",
      "Gradient for decoder.decoder.1.bias: 0.0003272599424235523\n",
      "Gradient for decoder.decoder.3.weight: 0.008073000237345695\n",
      "Gradient for decoder.decoder.3.bias: 6.649834849437042e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0002953328366857022\n",
      "Gradient for decoder.decoder.4.bias: 0.0002781334624160081\n",
      "Gradient for decoder.decoder.6.weight: 0.0004095538461115211\n",
      "Gradient for decoder.decoder.6.bias: 2.3010466975392774e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.025923170149326324\n",
      "Gradient for encoder.encoder.0.bias: 3.177939855714129e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0029437197372317314\n",
      "Gradient for encoder.encoder.1.bias: 0.0028619912918657064\n",
      "Gradient for encoder.encoder.3.weight: 0.06370128691196442\n",
      "Gradient for encoder.encoder.3.bias: 3.3617991723744467e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.009224283508956432\n",
      "Gradient for encoder.encoder.4.bias: 0.007285331375896931\n",
      "Gradient for encoder.mean.weight: 0.12396319955587387\n",
      "Gradient for encoder.mean.bias: 0.0038141082040965557\n",
      "Gradient for encoder.log_var.weight: 0.07016090303659439\n",
      "Gradient for encoder.log_var.bias: 0.002183855976909399\n",
      "Gradient for decoder.decoder.0.weight: 0.010293473489582539\n",
      "Gradient for decoder.decoder.0.bias: 8.59592952373589e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.000544004316907376\n",
      "Gradient for decoder.decoder.1.bias: 0.0004323371103964746\n",
      "Gradient for decoder.decoder.3.weight: 0.009251167997717857\n",
      "Gradient for decoder.decoder.3.bias: 7.953537828342405e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0003194374148733914\n",
      "Gradient for decoder.decoder.4.bias: 0.00029006224940530956\n",
      "Gradient for decoder.decoder.6.weight: 0.0004941311781294644\n",
      "Gradient for decoder.decoder.6.bias: 3.354028012836352e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training VAE Epoch:  11%|█▏        | 9/79 [00:00<00:01, 36.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient for encoder.encoder.0.weight: 0.03849543631076813\n",
      "Gradient for encoder.encoder.0.bias: 4.000867345754777e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.003549143671989441\n",
      "Gradient for encoder.encoder.1.bias: 0.0032703662291169167\n",
      "Gradient for encoder.encoder.3.weight: 0.07799915224313736\n",
      "Gradient for encoder.encoder.3.bias: 3.3423583345459917e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.008525596000254154\n",
      "Gradient for encoder.encoder.4.bias: 0.00731756491586566\n",
      "Gradient for encoder.mean.weight: 0.11667488515377045\n",
      "Gradient for encoder.mean.bias: 0.00413021445274353\n",
      "Gradient for encoder.log_var.weight: 0.06502071022987366\n",
      "Gradient for encoder.log_var.bias: 0.0025315035600215197\n",
      "Gradient for decoder.decoder.0.weight: 0.01076704915612936\n",
      "Gradient for decoder.decoder.0.bias: 8.765232983876103e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005524206208065152\n",
      "Gradient for decoder.decoder.1.bias: 0.0004575741186272353\n",
      "Gradient for decoder.decoder.3.weight: 0.010221684351563454\n",
      "Gradient for decoder.decoder.3.bias: 7.116623262914956e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0003618125047069043\n",
      "Gradient for decoder.decoder.4.bias: 0.00031412491807714105\n",
      "Gradient for decoder.decoder.6.weight: 0.00042596616549417377\n",
      "Gradient for decoder.decoder.6.bias: 2.2043472199584357e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.025285406038165092\n",
      "Gradient for encoder.encoder.0.bias: 2.7455473658455354e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0022452163975685835\n",
      "Gradient for encoder.encoder.1.bias: 0.002058418234810233\n",
      "Gradient for encoder.encoder.3.weight: 0.050594378262758255\n",
      "Gradient for encoder.encoder.3.bias: 3.2818031625581057e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.006169915199279785\n",
      "Gradient for encoder.encoder.4.bias: 0.0068410178646445274\n",
      "Gradient for encoder.mean.weight: 0.08709896355867386\n",
      "Gradient for encoder.mean.bias: 0.004523868672549725\n",
      "Gradient for encoder.log_var.weight: 0.053119461983442307\n",
      "Gradient for encoder.log_var.bias: 0.0031236845534294844\n",
      "Gradient for decoder.decoder.0.weight: 0.01387451309710741\n",
      "Gradient for decoder.decoder.0.bias: 1.180232023223482e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0006805883604101837\n",
      "Gradient for decoder.decoder.1.bias: 0.0005656359135173261\n",
      "Gradient for decoder.decoder.3.weight: 0.012838500551879406\n",
      "Gradient for decoder.decoder.3.bias: 1.0877258121988476e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0006127616507001221\n",
      "Gradient for decoder.decoder.4.bias: 0.0006575388833880424\n",
      "Gradient for decoder.decoder.6.weight: 0.0005423563998192549\n",
      "Gradient for decoder.decoder.6.bias: 3.59973892045673e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.016975250095129013\n",
      "Gradient for encoder.encoder.0.bias: 2.576024983602654e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0015488695353269577\n",
      "Gradient for encoder.encoder.1.bias: 0.0018602790078148246\n",
      "Gradient for encoder.encoder.3.weight: 0.034306395798921585\n",
      "Gradient for encoder.encoder.3.bias: 3.119142444329981e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.00749942334368825\n",
      "Gradient for encoder.encoder.4.bias: 0.008309081196784973\n",
      "Gradient for encoder.mean.weight: 0.10183270275592804\n",
      "Gradient for encoder.mean.bias: 0.005571751389652491\n",
      "Gradient for encoder.log_var.weight: 0.0683414489030838\n",
      "Gradient for encoder.log_var.bias: 0.0038351337425410748\n",
      "Gradient for decoder.decoder.0.weight: 0.011984375305473804\n",
      "Gradient for decoder.decoder.0.bias: 1.0272459965987579e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0005682078190147877\n",
      "Gradient for decoder.decoder.1.bias: 0.0004830543475691229\n",
      "Gradient for decoder.decoder.3.weight: 0.01120021566748619\n",
      "Gradient for decoder.decoder.3.bias: 1.043856320825931e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0006193426670506597\n",
      "Gradient for decoder.decoder.4.bias: 0.0006970447720959783\n",
      "Gradient for decoder.decoder.6.weight: 0.0005673790583387017\n",
      "Gradient for decoder.decoder.6.bias: 4.131687092012726e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.021231772378087044\n",
      "Gradient for encoder.encoder.0.bias: 2.8904757060077557e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0017159867566078901\n",
      "Gradient for encoder.encoder.1.bias: 0.001657034968957305\n",
      "Gradient for encoder.encoder.3.weight: 0.038283251225948334\n",
      "Gradient for encoder.encoder.3.bias: 2.5092969369033824e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.004806706681847572\n",
      "Gradient for encoder.encoder.4.bias: 0.004592972807586193\n",
      "Gradient for encoder.mean.weight: 0.06556645780801773\n",
      "Gradient for encoder.mean.bias: 0.003421163186430931\n",
      "Gradient for encoder.log_var.weight: 0.04376823082566261\n",
      "Gradient for encoder.log_var.bias: 0.001986157614737749\n",
      "Gradient for decoder.decoder.0.weight: 0.010837984271347523\n",
      "Gradient for decoder.decoder.0.bias: 8.901178405462673e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005650700768455863\n",
      "Gradient for decoder.decoder.1.bias: 0.0004505550896283239\n",
      "Gradient for decoder.decoder.3.weight: 0.0104138795286417\n",
      "Gradient for decoder.decoder.3.bias: 7.694171688665818e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00042043006396852434\n",
      "Gradient for decoder.decoder.4.bias: 0.00045057112583890557\n",
      "Gradient for decoder.decoder.6.weight: 0.00040860215085558593\n",
      "Gradient for decoder.decoder.6.bias: 2.4072840460576117e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.020901940762996674\n",
      "Gradient for encoder.encoder.0.bias: 2.339112237237373e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0015126909129321575\n",
      "Gradient for encoder.encoder.1.bias: 0.0013144424883648753\n",
      "Gradient for encoder.encoder.3.weight: 0.038025032728910446\n",
      "Gradient for encoder.encoder.3.bias: 2.4129381825943597e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.004227121826261282\n",
      "Gradient for encoder.encoder.4.bias: 0.004137333016842604\n",
      "Gradient for encoder.mean.weight: 0.05541710928082466\n",
      "Gradient for encoder.mean.bias: 0.0032648302149027586\n",
      "Gradient for encoder.log_var.weight: 0.032388538122177124\n",
      "Gradient for encoder.log_var.bias: 0.0019257200183346868\n",
      "Gradient for decoder.decoder.0.weight: 0.011594542302191257\n",
      "Gradient for decoder.decoder.0.bias: 1.0182514553758182e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0005681083421222866\n",
      "Gradient for decoder.decoder.1.bias: 0.00047301387530751526\n",
      "Gradient for decoder.decoder.3.weight: 0.010938349179923534\n",
      "Gradient for decoder.decoder.3.bias: 8.97599147786643e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0004724332538899034\n",
      "Gradient for decoder.decoder.4.bias: 0.0005491530173458159\n",
      "Gradient for decoder.decoder.6.weight: 0.00047617958625778556\n",
      "Gradient for decoder.decoder.6.bias: 3.106204530922696e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.026790523901581764\n",
      "Gradient for encoder.encoder.0.bias: 2.65739479032856e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.002074776217341423\n",
      "Gradient for encoder.encoder.1.bias: 0.0014874216867610812\n",
      "Gradient for encoder.encoder.3.weight: 0.04907802492380142\n",
      "Gradient for encoder.encoder.3.bias: 2.7209345887513336e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.006493211258202791\n",
      "Gradient for encoder.encoder.4.bias: 0.00521751819178462\n",
      "Gradient for encoder.mean.weight: 0.08819227665662766\n",
      "Gradient for encoder.mean.bias: 0.00377452140673995\n",
      "Gradient for encoder.log_var.weight: 0.04441731423139572\n",
      "Gradient for encoder.log_var.bias: 0.002058056415989995\n",
      "Gradient for decoder.decoder.0.weight: 0.013091451488435268\n",
      "Gradient for decoder.decoder.0.bias: 1.0044777509765623e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.000726667232811451\n",
      "Gradient for decoder.decoder.1.bias: 0.0005544094601646066\n",
      "Gradient for decoder.decoder.3.weight: 0.012385162524878979\n",
      "Gradient for decoder.decoder.3.bias: 8.47701422945768e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.000463197473436594\n",
      "Gradient for decoder.decoder.4.bias: 0.00042631541145965457\n",
      "Gradient for decoder.decoder.6.weight: 0.0004813885025214404\n",
      "Gradient for decoder.decoder.6.bias: 2.89255131065147e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.028779055923223495\n",
      "Gradient for encoder.encoder.0.bias: 2.5605531583927643e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.002185405930504203\n",
      "Gradient for encoder.encoder.1.bias: 0.0016962394583970308\n",
      "Gradient for encoder.encoder.3.weight: 0.05122572183609009\n",
      "Gradient for encoder.encoder.3.bias: 3.2594865695401154e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.00798072014003992\n",
      "Gradient for encoder.encoder.4.bias: 0.007254765834659338\n",
      "Gradient for encoder.mean.weight: 0.10424868017435074\n",
      "Gradient for encoder.mean.bias: 0.004557890817523003\n",
      "Gradient for encoder.log_var.weight: 0.055211734026670456\n",
      "Gradient for encoder.log_var.bias: 0.002497478388249874\n",
      "Gradient for decoder.decoder.0.weight: 0.012657314538955688\n",
      "Gradient for decoder.decoder.0.bias: 1.1093918839133465e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0006623383378610015\n",
      "Gradient for decoder.decoder.1.bias: 0.0005237921723164618\n",
      "Gradient for decoder.decoder.3.weight: 0.012194559909403324\n",
      "Gradient for decoder.decoder.3.bias: 8.857474476098304e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0004676907556131482\n",
      "Gradient for decoder.decoder.4.bias: 0.00043599624768830836\n",
      "Gradient for decoder.decoder.6.weight: 0.0005023158737458289\n",
      "Gradient for decoder.decoder.6.bias: 3.113259663223289e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.03865297511219978\n",
      "Gradient for encoder.encoder.0.bias: 4.7165996802656096e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.002513672923669219\n",
      "Gradient for encoder.encoder.1.bias: 0.00223919446580112\n",
      "Gradient for encoder.encoder.3.weight: 0.0573698952794075\n",
      "Gradient for encoder.encoder.3.bias: 3.870508358261304e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.008614843711256981\n",
      "Gradient for encoder.encoder.4.bias: 0.008340530097484589\n",
      "Gradient for encoder.mean.weight: 0.1110442504286766\n",
      "Gradient for encoder.mean.bias: 0.004724523983895779\n",
      "Gradient for encoder.log_var.weight: 0.0684071034193039\n",
      "Gradient for encoder.log_var.bias: 0.0032012290321290493\n",
      "Gradient for decoder.decoder.0.weight: 0.009175893850624561\n",
      "Gradient for decoder.decoder.0.bias: 7.449760947020323e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0004781872557941824\n",
      "Gradient for decoder.decoder.1.bias: 0.0003898894356098026\n",
      "Gradient for decoder.decoder.3.weight: 0.008880157954990864\n",
      "Gradient for decoder.decoder.3.bias: 7.019038822386747e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00034286786103621125\n",
      "Gradient for decoder.decoder.4.bias: 0.0003225365071557462\n",
      "Gradient for decoder.decoder.6.weight: 0.00040186301339417696\n",
      "Gradient for decoder.decoder.6.bias: 1.894555134640541e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.02340085245668888\n",
      "Gradient for encoder.encoder.0.bias: 3.5490738820032064e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0024477681145071983\n",
      "Gradient for encoder.encoder.1.bias: 0.0018513210816308856\n",
      "Gradient for encoder.encoder.3.weight: 0.0483974888920784\n",
      "Gradient for encoder.encoder.3.bias: 3.081024879669769e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.006864579394459724\n",
      "Gradient for encoder.encoder.4.bias: 0.006562101189047098\n",
      "Gradient for encoder.mean.weight: 0.08765526860952377\n",
      "Gradient for encoder.mean.bias: 0.00422339141368866\n",
      "Gradient for encoder.log_var.weight: 0.04934011399745941\n",
      "Gradient for encoder.log_var.bias: 0.0023777412716299295\n",
      "Gradient for decoder.decoder.0.weight: 0.00902203656733036\n",
      "Gradient for decoder.decoder.0.bias: 7.759218267899826e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.00046478386502712965\n",
      "Gradient for decoder.decoder.1.bias: 0.00039472751086577773\n",
      "Gradient for decoder.decoder.3.weight: 0.008466001600027084\n",
      "Gradient for decoder.decoder.3.bias: 6.843943467504943e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00039380695670843124\n",
      "Gradient for decoder.decoder.4.bias: 0.00043350900523364544\n",
      "Gradient for decoder.decoder.6.weight: 0.0004578395455610007\n",
      "Gradient for decoder.decoder.6.bias: 3.106397343799472e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.032684434205293655\n",
      "Gradient for encoder.encoder.0.bias: 4.0153075309135033e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.002250243676826358\n",
      "Gradient for encoder.encoder.1.bias: 0.0016328331548720598\n",
      "Gradient for encoder.encoder.3.weight: 0.04967039078474045\n",
      "Gradient for encoder.encoder.3.bias: 3.3699026902311857e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0061559733003377914\n",
      "Gradient for encoder.encoder.4.bias: 0.005974103696644306\n",
      "Gradient for encoder.mean.weight: 0.0913180559873581\n",
      "Gradient for encoder.mean.bias: 0.004226048942655325\n",
      "Gradient for encoder.log_var.weight: 0.05897907167673111\n",
      "Gradient for encoder.log_var.bias: 0.002707862062379718\n",
      "Gradient for decoder.decoder.0.weight: 0.009366534650325775\n",
      "Gradient for decoder.decoder.0.bias: 8.20663051404047e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.000490126374643296\n",
      "Gradient for decoder.decoder.1.bias: 0.0003852832887787372\n",
      "Gradient for decoder.decoder.3.weight: 0.00877367053180933\n",
      "Gradient for decoder.decoder.3.bias: 7.232162785308915e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00035374192520976067\n",
      "Gradient for decoder.decoder.4.bias: 0.0003083512419834733\n",
      "Gradient for decoder.decoder.6.weight: 0.00044323340989649296\n",
      "Gradient for decoder.decoder.6.bias: 2.4130093152052723e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.029030125588178635\n",
      "Gradient for encoder.encoder.0.bias: 3.398557824052517e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0017368777189403772\n",
      "Gradient for encoder.encoder.1.bias: 0.001540861907415092\n",
      "Gradient for encoder.encoder.3.weight: 0.039532504975795746\n",
      "Gradient for encoder.encoder.3.bias: 2.3537044535615337e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.004792974330484867\n",
      "Gradient for encoder.encoder.4.bias: 0.004521843045949936\n",
      "Gradient for encoder.mean.weight: 0.06493061780929565\n",
      "Gradient for encoder.mean.bias: 0.003818894736468792\n",
      "Gradient for encoder.log_var.weight: 0.03856992721557617\n",
      "Gradient for encoder.log_var.bias: 0.00216631218791008\n",
      "Gradient for decoder.decoder.0.weight: 0.00927889533340931\n",
      "Gradient for decoder.decoder.0.bias: 7.480049912800268e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.00044480981887318194\n",
      "Gradient for decoder.decoder.1.bias: 0.0003717030049301684\n",
      "Gradient for decoder.decoder.3.weight: 0.008336606435477734\n",
      "Gradient for decoder.decoder.3.bias: 6.910450683905722e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0002972919901367277\n",
      "Gradient for decoder.decoder.4.bias: 0.0002872960758395493\n",
      "Gradient for decoder.decoder.6.weight: 0.000425442325649783\n",
      "Gradient for decoder.decoder.6.bias: 2.64866048382828e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.01856260746717453\n",
      "Gradient for encoder.encoder.0.bias: 2.2637119609369982e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0015967233339324594\n",
      "Gradient for encoder.encoder.1.bias: 0.0014937641099095345\n",
      "Gradient for encoder.encoder.3.weight: 0.0346633680164814\n",
      "Gradient for encoder.encoder.3.bias: 2.7151847437068e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.005849690642207861\n",
      "Gradient for encoder.encoder.4.bias: 0.006558818276971579\n",
      "Gradient for encoder.mean.weight: 0.07752054184675217\n",
      "Gradient for encoder.mean.bias: 0.004911550786346197\n",
      "Gradient for encoder.log_var.weight: 0.043109726160764694\n",
      "Gradient for encoder.log_var.bias: 0.0027597309090197086\n",
      "Gradient for decoder.decoder.0.weight: 0.01210988499224186\n",
      "Gradient for decoder.decoder.0.bias: 1.016045511614827e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0006498237489722669\n",
      "Gradient for decoder.decoder.1.bias: 0.00047382127377204597\n",
      "Gradient for decoder.decoder.3.weight: 0.010932422243058681\n",
      "Gradient for decoder.decoder.3.bias: 9.285403695935557e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0005848573055118322\n",
      "Gradient for decoder.decoder.4.bias: 0.000656645221170038\n",
      "Gradient for decoder.decoder.6.weight: 0.0005279887700453401\n",
      "Gradient for decoder.decoder.6.bias: 3.6440324038267136e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.019752293825149536\n",
      "Gradient for encoder.encoder.0.bias: 2.430473357295515e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0013414241839200258\n",
      "Gradient for encoder.encoder.1.bias: 0.0010663752909749746\n",
      "Gradient for encoder.encoder.3.weight: 0.029548101127147675\n",
      "Gradient for encoder.encoder.3.bias: 2.2926269216405615e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.005190580617636442\n",
      "Gradient for encoder.encoder.4.bias: 0.004735334310680628\n",
      "Gradient for encoder.mean.weight: 0.07153042405843735\n",
      "Gradient for encoder.mean.bias: 0.0028563030064105988\n",
      "Gradient for encoder.log_var.weight: 0.03609420359134674\n",
      "Gradient for encoder.log_var.bias: 0.0019026519730687141\n",
      "Gradient for decoder.decoder.0.weight: 0.012186292558908463\n",
      "Gradient for decoder.decoder.0.bias: 1.139655939064177e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0006421805592253804\n",
      "Gradient for decoder.decoder.1.bias: 0.0005380777292884886\n",
      "Gradient for decoder.decoder.3.weight: 0.011708522215485573\n",
      "Gradient for decoder.decoder.3.bias: 1.0093818142431488e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0005411092424765229\n",
      "Gradient for decoder.decoder.4.bias: 0.0005509605398401618\n",
      "Gradient for decoder.decoder.6.weight: 0.0005067745223641396\n",
      "Gradient for decoder.decoder.6.bias: 3.2673662644810975e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.029526185244321823\n",
      "Gradient for encoder.encoder.0.bias: 3.958360722533527e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0023922750260680914\n",
      "Gradient for encoder.encoder.1.bias: 0.002179698320105672\n",
      "Gradient for encoder.encoder.3.weight: 0.05165359750390053\n",
      "Gradient for encoder.encoder.3.bias: 2.7212840314483344e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.004822568502277136\n",
      "Gradient for encoder.encoder.4.bias: 0.005166268441826105\n",
      "Gradient for encoder.mean.weight: 0.0678166002035141\n",
      "Gradient for encoder.mean.bias: 0.0032725168857723475\n",
      "Gradient for encoder.log_var.weight: 0.0348031111061573\n",
      "Gradient for encoder.log_var.bias: 0.0015182419447228312\n",
      "Gradient for decoder.decoder.0.weight: 0.008667528629302979\n",
      "Gradient for decoder.decoder.0.bias: 8.022767866711078e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.00044254225213080645\n",
      "Gradient for decoder.decoder.1.bias: 0.0003612323198467493\n",
      "Gradient for decoder.decoder.3.weight: 0.008200595155358315\n",
      "Gradient for decoder.decoder.3.bias: 6.896137827450133e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00030976932612247765\n",
      "Gradient for decoder.decoder.4.bias: 0.000317146914312616\n",
      "Gradient for decoder.decoder.6.weight: 0.0004278512205928564\n",
      "Gradient for decoder.decoder.6.bias: 2.469913124514278e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training VAE Epoch:  22%|██▏       | 17/79 [00:00<00:01, 51.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient for encoder.encoder.0.weight: 0.02048056572675705\n",
      "Gradient for encoder.encoder.0.bias: 3.0799418571092474e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0016136446502059698\n",
      "Gradient for encoder.encoder.1.bias: 0.0011591154616326094\n",
      "Gradient for encoder.encoder.3.weight: 0.03455192223191261\n",
      "Gradient for encoder.encoder.3.bias: 3.121226055391446e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.006676132790744305\n",
      "Gradient for encoder.encoder.4.bias: 0.006973089184612036\n",
      "Gradient for encoder.mean.weight: 0.09064159542322159\n",
      "Gradient for encoder.mean.bias: 0.004495161585509777\n",
      "Gradient for encoder.log_var.weight: 0.050293345004320145\n",
      "Gradient for encoder.log_var.bias: 0.002511162543669343\n",
      "Gradient for decoder.decoder.0.weight: 0.008695664815604687\n",
      "Gradient for decoder.decoder.0.bias: 7.399895279869284e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0004309806099627167\n",
      "Gradient for decoder.decoder.1.bias: 0.0003380322887096554\n",
      "Gradient for decoder.decoder.3.weight: 0.00810497161000967\n",
      "Gradient for decoder.decoder.3.bias: 7.424686560009164e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00031094139558263123\n",
      "Gradient for decoder.decoder.4.bias: 0.00026850998983718455\n",
      "Gradient for decoder.decoder.6.weight: 0.0004090790171176195\n",
      "Gradient for decoder.decoder.6.bias: 2.0833451344515197e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.011933625675737858\n",
      "Gradient for encoder.encoder.0.bias: 1.803517057918924e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0010484601370990276\n",
      "Gradient for encoder.encoder.1.bias: 0.001053563435561955\n",
      "Gradient for encoder.encoder.3.weight: 0.023664550855755806\n",
      "Gradient for encoder.encoder.3.bias: 2.8000354812540706e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.008475194685161114\n",
      "Gradient for encoder.encoder.4.bias: 0.007139902561903\n",
      "Gradient for encoder.mean.weight: 0.11733130365610123\n",
      "Gradient for encoder.mean.bias: 0.003964490722864866\n",
      "Gradient for encoder.log_var.weight: 0.07161787897348404\n",
      "Gradient for encoder.log_var.bias: 0.002360805869102478\n",
      "Gradient for decoder.decoder.0.weight: 0.010586107149720192\n",
      "Gradient for decoder.decoder.0.bias: 9.049474364308807e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005535817472264171\n",
      "Gradient for decoder.decoder.1.bias: 0.0004502093652263284\n",
      "Gradient for decoder.decoder.3.weight: 0.010244439356029034\n",
      "Gradient for decoder.decoder.3.bias: 7.35916605432152e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0003651764418464154\n",
      "Gradient for decoder.decoder.4.bias: 0.0003129892284050584\n",
      "Gradient for decoder.decoder.6.weight: 0.00044023466762155294\n",
      "Gradient for decoder.decoder.6.bias: 2.6413244995637797e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training VAE Epoch:  32%|███▏      | 25/79 [00:00<00:00, 60.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient for encoder.encoder.0.weight: 0.015997350215911865\n",
      "Gradient for encoder.encoder.0.bias: 2.5186621885331384e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.001656936015933752\n",
      "Gradient for encoder.encoder.1.bias: 0.0015053094830363989\n",
      "Gradient for encoder.encoder.3.weight: 0.036117617040872574\n",
      "Gradient for encoder.encoder.3.bias: 2.976975332913412e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.005799886304885149\n",
      "Gradient for encoder.encoder.4.bias: 0.006548974197357893\n",
      "Gradient for encoder.mean.weight: 0.07539177685976028\n",
      "Gradient for encoder.mean.bias: 0.005220071412622929\n",
      "Gradient for encoder.log_var.weight: 0.03828638792037964\n",
      "Gradient for encoder.log_var.bias: 0.002382625825703144\n",
      "Gradient for decoder.decoder.0.weight: 0.010718542151153088\n",
      "Gradient for decoder.decoder.0.bias: 8.277143553891975e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.000548430485650897\n",
      "Gradient for decoder.decoder.1.bias: 0.0004608596791513264\n",
      "Gradient for decoder.decoder.3.weight: 0.010159389115869999\n",
      "Gradient for decoder.decoder.3.bias: 7.644239408133302e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0003515212156344205\n",
      "Gradient for decoder.decoder.4.bias: 0.0002968636981677264\n",
      "Gradient for decoder.decoder.6.weight: 0.0004364450869616121\n",
      "Gradient for decoder.decoder.6.bias: 2.3541411792393774e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.013458131812512875\n",
      "Gradient for encoder.encoder.0.bias: 1.9664618891579444e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0009858891135081649\n",
      "Gradient for encoder.encoder.1.bias: 0.0010722435545176268\n",
      "Gradient for encoder.encoder.3.weight: 0.02131560817360878\n",
      "Gradient for encoder.encoder.3.bias: 2.1763271740304901e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.004790407605469227\n",
      "Gradient for encoder.encoder.4.bias: 0.004628531634807587\n",
      "Gradient for encoder.mean.weight: 0.06753566861152649\n",
      "Gradient for encoder.mean.bias: 0.0033393690828233957\n",
      "Gradient for encoder.log_var.weight: 0.04498853534460068\n",
      "Gradient for encoder.log_var.bias: 0.0019979069475084543\n",
      "Gradient for decoder.decoder.0.weight: 0.010658270679414272\n",
      "Gradient for decoder.decoder.0.bias: 9.273890683170194e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005531013594008982\n",
      "Gradient for decoder.decoder.1.bias: 0.00044505996629595757\n",
      "Gradient for decoder.decoder.3.weight: 0.010243287310004234\n",
      "Gradient for decoder.decoder.3.bias: 8.344234331270073e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0003874833055306226\n",
      "Gradient for decoder.decoder.4.bias: 0.0003298771916888654\n",
      "Gradient for decoder.decoder.6.weight: 0.0004434084694366902\n",
      "Gradient for decoder.decoder.6.bias: 2.3133512513595633e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.017006753012537956\n",
      "Gradient for encoder.encoder.0.bias: 2.5177929185993264e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0013388327788561583\n",
      "Gradient for encoder.encoder.1.bias: 0.0013744771713390946\n",
      "Gradient for encoder.encoder.3.weight: 0.02709517627954483\n",
      "Gradient for encoder.encoder.3.bias: 2.1362867030916277e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.003998051397502422\n",
      "Gradient for encoder.encoder.4.bias: 0.003922417294234037\n",
      "Gradient for encoder.mean.weight: 0.05650259181857109\n",
      "Gradient for encoder.mean.bias: 0.00302433455362916\n",
      "Gradient for encoder.log_var.weight: 0.032544806599617004\n",
      "Gradient for encoder.log_var.bias: 0.0019216727232560515\n",
      "Gradient for decoder.decoder.0.weight: 0.010521969757974148\n",
      "Gradient for decoder.decoder.0.bias: 9.119278943092723e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005387178971432149\n",
      "Gradient for decoder.decoder.1.bias: 0.00043800222920253873\n",
      "Gradient for decoder.decoder.3.weight: 0.009567259810864925\n",
      "Gradient for decoder.decoder.3.bias: 7.10075331866733e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00033692255965434015\n",
      "Gradient for decoder.decoder.4.bias: 0.00028977516922168434\n",
      "Gradient for decoder.decoder.6.weight: 0.0004105560074094683\n",
      "Gradient for decoder.decoder.6.bias: 1.8173848729929887e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.015952760353684425\n",
      "Gradient for encoder.encoder.0.bias: 2.7292999457695366e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0012259711511433125\n",
      "Gradient for encoder.encoder.1.bias: 0.0009718365618027747\n",
      "Gradient for encoder.encoder.3.weight: 0.025367310270667076\n",
      "Gradient for encoder.encoder.3.bias: 2.547270450126149e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.005062068812549114\n",
      "Gradient for encoder.encoder.4.bias: 0.006031869910657406\n",
      "Gradient for encoder.mean.weight: 0.0706397145986557\n",
      "Gradient for encoder.mean.bias: 0.004429390653967857\n",
      "Gradient for encoder.log_var.weight: 0.04003973305225372\n",
      "Gradient for encoder.log_var.bias: 0.002936967648565769\n",
      "Gradient for decoder.decoder.0.weight: 0.008800900541245937\n",
      "Gradient for decoder.decoder.0.bias: 7.876875540713257e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0004500672221183777\n",
      "Gradient for decoder.decoder.1.bias: 0.00034873149706982076\n",
      "Gradient for decoder.decoder.3.weight: 0.008429232984781265\n",
      "Gradient for decoder.decoder.3.bias: 7.274982699589927e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00031510411645285785\n",
      "Gradient for decoder.decoder.4.bias: 0.0002885692229028791\n",
      "Gradient for decoder.decoder.6.weight: 0.00043113756692036986\n",
      "Gradient for decoder.decoder.6.bias: 2.61993809544947e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.017474761232733727\n",
      "Gradient for encoder.encoder.0.bias: 3.0951293611414243e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0014099470572546124\n",
      "Gradient for encoder.encoder.1.bias: 0.0012273357715457678\n",
      "Gradient for encoder.encoder.3.weight: 0.03153271973133087\n",
      "Gradient for encoder.encoder.3.bias: 2.1690471641022668e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.006232498679310083\n",
      "Gradient for encoder.encoder.4.bias: 0.005063931457698345\n",
      "Gradient for encoder.mean.weight: 0.09250212460756302\n",
      "Gradient for encoder.mean.bias: 0.003276555333286524\n",
      "Gradient for encoder.log_var.weight: 0.04411012679338455\n",
      "Gradient for encoder.log_var.bias: 0.001886301557533443\n",
      "Gradient for decoder.decoder.0.weight: 0.008026768453419209\n",
      "Gradient for decoder.decoder.0.bias: 6.565412102865764e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.00039292266592383385\n",
      "Gradient for decoder.decoder.1.bias: 0.0003339532413519919\n",
      "Gradient for decoder.decoder.3.weight: 0.007757668383419514\n",
      "Gradient for decoder.decoder.3.bias: 8.415723673493858e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0005362944211810827\n",
      "Gradient for decoder.decoder.4.bias: 0.0006675705662928522\n",
      "Gradient for decoder.decoder.6.weight: 0.0004380554019007832\n",
      "Gradient for decoder.decoder.6.bias: 3.2257325074169785e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.015146282501518726\n",
      "Gradient for encoder.encoder.0.bias: 2.2338486962980575e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0012901134323328733\n",
      "Gradient for encoder.encoder.1.bias: 0.0012169259134680033\n",
      "Gradient for encoder.encoder.3.weight: 0.0283929705619812\n",
      "Gradient for encoder.encoder.3.bias: 2.3270960158860987e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.005158616695553064\n",
      "Gradient for encoder.encoder.4.bias: 0.004917920101433992\n",
      "Gradient for encoder.mean.weight: 0.07257916778326035\n",
      "Gradient for encoder.mean.bias: 0.003139163600280881\n",
      "Gradient for encoder.log_var.weight: 0.039160944521427155\n",
      "Gradient for encoder.log_var.bias: 0.001978658838197589\n",
      "Gradient for decoder.decoder.0.weight: 0.009648569859564304\n",
      "Gradient for decoder.decoder.0.bias: 7.740105778530904e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.00047901328071020544\n",
      "Gradient for decoder.decoder.1.bias: 0.0003596715978346765\n",
      "Gradient for decoder.decoder.3.weight: 0.009202680550515652\n",
      "Gradient for decoder.decoder.3.bias: 7.17200188127265e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00040800293209031224\n",
      "Gradient for decoder.decoder.4.bias: 0.0004172214830759913\n",
      "Gradient for decoder.decoder.6.weight: 0.00041887673432938755\n",
      "Gradient for decoder.decoder.6.bias: 2.563154157542158e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.010594148188829422\n",
      "Gradient for encoder.encoder.0.bias: 1.6718930059833603e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0008862074464559555\n",
      "Gradient for encoder.encoder.1.bias: 0.000918300065677613\n",
      "Gradient for encoder.encoder.3.weight: 0.018719956278800964\n",
      "Gradient for encoder.encoder.3.bias: 1.6478871045499943e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.004246192052960396\n",
      "Gradient for encoder.encoder.4.bias: 0.003909319639205933\n",
      "Gradient for encoder.mean.weight: 0.06004027649760246\n",
      "Gradient for encoder.mean.bias: 0.0028868606314063072\n",
      "Gradient for encoder.log_var.weight: 0.030147703364491463\n",
      "Gradient for encoder.log_var.bias: 0.0016025827499106526\n",
      "Gradient for decoder.decoder.0.weight: 0.011797687970101833\n",
      "Gradient for decoder.decoder.0.bias: 9.777259557530726e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005936441011726856\n",
      "Gradient for decoder.decoder.1.bias: 0.000499752932228148\n",
      "Gradient for decoder.decoder.3.weight: 0.01093209721148014\n",
      "Gradient for decoder.decoder.3.bias: 8.655966915460667e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0003901613235939294\n",
      "Gradient for decoder.decoder.4.bias: 0.000346030225045979\n",
      "Gradient for decoder.decoder.6.weight: 0.0004425838415045291\n",
      "Gradient for decoder.decoder.6.bias: 2.267614945594687e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.008745578117668629\n",
      "Gradient for encoder.encoder.0.bias: 1.4170240501820697e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0009517024154774845\n",
      "Gradient for encoder.encoder.1.bias: 0.0010749638313427567\n",
      "Gradient for encoder.encoder.3.weight: 0.021058931946754456\n",
      "Gradient for encoder.encoder.3.bias: 1.7362108972740486e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.004553369712084532\n",
      "Gradient for encoder.encoder.4.bias: 0.0037492045667022467\n",
      "Gradient for encoder.mean.weight: 0.06252550333738327\n",
      "Gradient for encoder.mean.bias: 0.0029522788245230913\n",
      "Gradient for encoder.log_var.weight: 0.037327129393815994\n",
      "Gradient for encoder.log_var.bias: 0.0014435729244723916\n",
      "Gradient for decoder.decoder.0.weight: 0.010869347490370274\n",
      "Gradient for decoder.decoder.0.bias: 8.647184357446491e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005785382818430662\n",
      "Gradient for decoder.decoder.1.bias: 0.0004700087883975357\n",
      "Gradient for decoder.decoder.3.weight: 0.010725151747465134\n",
      "Gradient for decoder.decoder.3.bias: 8.015018509999194e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00037836210685782135\n",
      "Gradient for decoder.decoder.4.bias: 0.0003472770331427455\n",
      "Gradient for decoder.decoder.6.weight: 0.000399256736272946\n",
      "Gradient for decoder.decoder.6.bias: 2.0200221115374006e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.0146747762337327\n",
      "Gradient for encoder.encoder.0.bias: 2.2369888927342707e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0012146019143983722\n",
      "Gradient for encoder.encoder.1.bias: 0.0011946491431444883\n",
      "Gradient for encoder.encoder.3.weight: 0.026635557413101196\n",
      "Gradient for encoder.encoder.3.bias: 2.0111223797414368e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.004362581763416529\n",
      "Gradient for encoder.encoder.4.bias: 0.003576138522475958\n",
      "Gradient for encoder.mean.weight: 0.05842914804816246\n",
      "Gradient for encoder.mean.bias: 0.002723203506320715\n",
      "Gradient for encoder.log_var.weight: 0.035836659371852875\n",
      "Gradient for encoder.log_var.bias: 0.0013706681784242392\n",
      "Gradient for decoder.decoder.0.weight: 0.010496638715267181\n",
      "Gradient for decoder.decoder.0.bias: 9.511064158473914e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005290675326250494\n",
      "Gradient for decoder.decoder.1.bias: 0.0004620588442776352\n",
      "Gradient for decoder.decoder.3.weight: 0.009754705242812634\n",
      "Gradient for decoder.decoder.3.bias: 9.062495198719489e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00034909791429527104\n",
      "Gradient for decoder.decoder.4.bias: 0.0003555291623342782\n",
      "Gradient for decoder.decoder.6.weight: 0.00047765093040652573\n",
      "Gradient for decoder.decoder.6.bias: 3.099054083577357e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.01442676316946745\n",
      "Gradient for encoder.encoder.0.bias: 1.5487014448645198e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0015019981656223536\n",
      "Gradient for encoder.encoder.1.bias: 0.001297215698286891\n",
      "Gradient for encoder.encoder.3.weight: 0.03166733682155609\n",
      "Gradient for encoder.encoder.3.bias: 1.8282653169165997e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.00392079446464777\n",
      "Gradient for encoder.encoder.4.bias: 0.0035366625525057316\n",
      "Gradient for encoder.mean.weight: 0.05613550916314125\n",
      "Gradient for encoder.mean.bias: 0.0025092405267059803\n",
      "Gradient for encoder.log_var.weight: 0.03443993628025055\n",
      "Gradient for encoder.log_var.bias: 0.0016498675104230642\n",
      "Gradient for decoder.decoder.0.weight: 0.013583685271441936\n",
      "Gradient for decoder.decoder.0.bias: 1.205767707901373e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0007128635770641267\n",
      "Gradient for decoder.decoder.1.bias: 0.0005518433754332364\n",
      "Gradient for decoder.decoder.3.weight: 0.013213482685387135\n",
      "Gradient for decoder.decoder.3.bias: 9.102873316235716e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0005197615246288478\n",
      "Gradient for decoder.decoder.4.bias: 0.0004863654903601855\n",
      "Gradient for decoder.decoder.6.weight: 0.00046527659287676215\n",
      "Gradient for decoder.decoder.6.bias: 2.299110019521322e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.009340004995465279\n",
      "Gradient for encoder.encoder.0.bias: 1.4025417112428773e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0009165675728581846\n",
      "Gradient for encoder.encoder.1.bias: 0.00101191783323884\n",
      "Gradient for encoder.encoder.3.weight: 0.01978112757205963\n",
      "Gradient for encoder.encoder.3.bias: 1.993493148333414e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.004306099843233824\n",
      "Gradient for encoder.encoder.4.bias: 0.0049547236412763596\n",
      "Gradient for encoder.mean.weight: 0.06161145865917206\n",
      "Gradient for encoder.mean.bias: 0.003965449053794146\n",
      "Gradient for encoder.log_var.weight: 0.0368422269821167\n",
      "Gradient for encoder.log_var.bias: 0.002211617538705468\n",
      "Gradient for decoder.decoder.0.weight: 0.012493767775595188\n",
      "Gradient for decoder.decoder.0.bias: 1.0383996440488374e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0006262737442739308\n",
      "Gradient for decoder.decoder.1.bias: 0.00047673890367150307\n",
      "Gradient for decoder.decoder.3.weight: 0.011731574311852455\n",
      "Gradient for decoder.decoder.3.bias: 9.74774982953619e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0004432261339388788\n",
      "Gradient for decoder.decoder.4.bias: 0.00041593602509237826\n",
      "Gradient for decoder.decoder.6.weight: 0.00045902462443336844\n",
      "Gradient for decoder.decoder.6.bias: 2.5754856324056163e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.012587888166308403\n",
      "Gradient for encoder.encoder.0.bias: 1.6614574299689266e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.001149142743088305\n",
      "Gradient for encoder.encoder.1.bias: 0.0011896163923665881\n",
      "Gradient for encoder.encoder.3.weight: 0.025662561878561974\n",
      "Gradient for encoder.encoder.3.bias: 2.2189745874090505e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.004592263139784336\n",
      "Gradient for encoder.encoder.4.bias: 0.005468327086418867\n",
      "Gradient for encoder.mean.weight: 0.062128085643053055\n",
      "Gradient for encoder.mean.bias: 0.004200329072773457\n",
      "Gradient for encoder.log_var.weight: 0.04103349894285202\n",
      "Gradient for encoder.log_var.bias: 0.0030492322985082865\n",
      "Gradient for decoder.decoder.0.weight: 0.012021996080875397\n",
      "Gradient for decoder.decoder.0.bias: 1.041004019097791e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0006395099335350096\n",
      "Gradient for decoder.decoder.1.bias: 0.0004997698706574738\n",
      "Gradient for decoder.decoder.3.weight: 0.01151395495980978\n",
      "Gradient for decoder.decoder.3.bias: 9.086679325642777e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0005764688830822706\n",
      "Gradient for decoder.decoder.4.bias: 0.000601793231908232\n",
      "Gradient for decoder.decoder.6.weight: 0.0005688045057468116\n",
      "Gradient for decoder.decoder.6.bias: 4.002732384833507e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.011461932212114334\n",
      "Gradient for encoder.encoder.0.bias: 2.1739431435574552e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0010616111103445292\n",
      "Gradient for encoder.encoder.1.bias: 0.0010133255273103714\n",
      "Gradient for encoder.encoder.3.weight: 0.021050723269581795\n",
      "Gradient for encoder.encoder.3.bias: 1.9801600636970562e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0048765381798148155\n",
      "Gradient for encoder.encoder.4.bias: 0.004302402026951313\n",
      "Gradient for encoder.mean.weight: 0.06889727711677551\n",
      "Gradient for encoder.mean.bias: 0.003207532921805978\n",
      "Gradient for encoder.log_var.weight: 0.03758705407381058\n",
      "Gradient for encoder.log_var.bias: 0.0016202405095100403\n",
      "Gradient for decoder.decoder.0.weight: 0.010232528671622276\n",
      "Gradient for decoder.decoder.0.bias: 8.521503641611972e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.00047167250886559486\n",
      "Gradient for decoder.decoder.1.bias: 0.0003935610584449023\n",
      "Gradient for decoder.decoder.3.weight: 0.009580533020198345\n",
      "Gradient for decoder.decoder.3.bias: 7.892830833355902e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00035039265640079975\n",
      "Gradient for decoder.decoder.4.bias: 0.00032770170946605504\n",
      "Gradient for decoder.decoder.6.weight: 0.00045767732081003487\n",
      "Gradient for decoder.decoder.6.bias: 2.951633905468043e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.01635737530887127\n",
      "Gradient for encoder.encoder.0.bias: 2.5418734825310985e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0012469514040276408\n",
      "Gradient for encoder.encoder.1.bias: 0.001028889906592667\n",
      "Gradient for encoder.encoder.3.weight: 0.026273466646671295\n",
      "Gradient for encoder.encoder.3.bias: 2.8881277924774906e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0049228486604988575\n",
      "Gradient for encoder.encoder.4.bias: 0.005160489585250616\n",
      "Gradient for encoder.mean.weight: 0.06775982677936554\n",
      "Gradient for encoder.mean.bias: 0.0041085234843194485\n",
      "Gradient for encoder.log_var.weight: 0.037029165774583817\n",
      "Gradient for encoder.log_var.bias: 0.0021866962779313326\n",
      "Gradient for decoder.decoder.0.weight: 0.009215445257723331\n",
      "Gradient for decoder.decoder.0.bias: 7.684969327570457e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0004710322245955467\n",
      "Gradient for decoder.decoder.1.bias: 0.00036821162211708724\n",
      "Gradient for decoder.decoder.3.weight: 0.008675544522702694\n",
      "Gradient for decoder.decoder.3.bias: 7.054998946154356e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0003586229286156595\n",
      "Gradient for decoder.decoder.4.bias: 0.00034708782914094627\n",
      "Gradient for decoder.decoder.6.weight: 0.00041392253478989005\n",
      "Gradient for decoder.decoder.6.bias: 2.1455403839354403e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training VAE Epoch:  42%|████▏     | 33/79 [00:00<00:00, 66.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient for encoder.encoder.0.weight: 0.011030164547264576\n",
      "Gradient for encoder.encoder.0.bias: 2.0810282316818807e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0013073566369712353\n",
      "Gradient for encoder.encoder.1.bias: 0.0011098238173872232\n",
      "Gradient for encoder.encoder.3.weight: 0.02576400525867939\n",
      "Gradient for encoder.encoder.3.bias: 2.1180419917943283e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.005301522556692362\n",
      "Gradient for encoder.encoder.4.bias: 0.004411990754306316\n",
      "Gradient for encoder.mean.weight: 0.07458347827196121\n",
      "Gradient for encoder.mean.bias: 0.0028874590061604977\n",
      "Gradient for encoder.log_var.weight: 0.04366154968738556\n",
      "Gradient for encoder.log_var.bias: 0.001639506546780467\n",
      "Gradient for decoder.decoder.0.weight: 0.011625918559730053\n",
      "Gradient for decoder.decoder.0.bias: 1.0665776595253362e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0005608308711089194\n",
      "Gradient for decoder.decoder.1.bias: 0.00046445487532764673\n",
      "Gradient for decoder.decoder.3.weight: 0.010649189352989197\n",
      "Gradient for decoder.decoder.3.bias: 9.93963730766545e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0005680954782292247\n",
      "Gradient for decoder.decoder.4.bias: 0.000592277676332742\n",
      "Gradient for decoder.decoder.6.weight: 0.0005548374028876424\n",
      "Gradient for decoder.decoder.6.bias: 4.025407542940229e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.02224055677652359\n",
      "Gradient for encoder.encoder.0.bias: 3.0964758535034775e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0014885920099914074\n",
      "Gradient for encoder.encoder.1.bias: 0.0013648963067680597\n",
      "Gradient for encoder.encoder.3.weight: 0.03437405452132225\n",
      "Gradient for encoder.encoder.3.bias: 2.1195666055628948e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.004102516919374466\n",
      "Gradient for encoder.encoder.4.bias: 0.0043851835653185844\n",
      "Gradient for encoder.mean.weight: 0.05834488943219185\n",
      "Gradient for encoder.mean.bias: 0.0033009920734912157\n",
      "Gradient for encoder.log_var.weight: 0.028701897710561752\n",
      "Gradient for encoder.log_var.bias: 0.0017581443535163999\n",
      "Gradient for decoder.decoder.0.weight: 0.01027063187211752\n",
      "Gradient for decoder.decoder.0.bias: 9.00559765648623e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0004951943410560489\n",
      "Gradient for decoder.decoder.1.bias: 0.0004016832390334457\n",
      "Gradient for decoder.decoder.3.weight: 0.009764336980879307\n",
      "Gradient for decoder.decoder.3.bias: 8.43405414951981e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0003690888697747141\n",
      "Gradient for decoder.decoder.4.bias: 0.0003514012205414474\n",
      "Gradient for decoder.decoder.6.weight: 0.0004410262918099761\n",
      "Gradient for decoder.decoder.6.bias: 2.698486605368089e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training VAE Epoch:  52%|█████▏    | 41/79 [00:00<00:00, 70.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient for encoder.encoder.0.weight: 0.00988343171775341\n",
      "Gradient for encoder.encoder.0.bias: 1.5252715757085866e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0007864499348215759\n",
      "Gradient for encoder.encoder.1.bias: 0.0007325934711843729\n",
      "Gradient for encoder.encoder.3.weight: 0.016598908230662346\n",
      "Gradient for encoder.encoder.3.bias: 1.6095538790672492e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.003418500069528818\n",
      "Gradient for encoder.encoder.4.bias: 0.0032243747264146805\n",
      "Gradient for encoder.mean.weight: 0.045638807117938995\n",
      "Gradient for encoder.mean.bias: 0.0026593664661049843\n",
      "Gradient for encoder.log_var.weight: 0.029354892671108246\n",
      "Gradient for encoder.log_var.bias: 0.0013055658200755715\n",
      "Gradient for decoder.decoder.0.weight: 0.011670957319438457\n",
      "Gradient for decoder.decoder.0.bias: 1.0384533510876537e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0006247114506550133\n",
      "Gradient for decoder.decoder.1.bias: 0.0004738338466268033\n",
      "Gradient for decoder.decoder.3.weight: 0.010795642621815205\n",
      "Gradient for decoder.decoder.3.bias: 8.782286009534346e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0004055732279084623\n",
      "Gradient for decoder.decoder.4.bias: 0.00037255731876939535\n",
      "Gradient for decoder.decoder.6.weight: 0.0004401269252412021\n",
      "Gradient for decoder.decoder.6.bias: 2.025184039666783e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.013380011543631554\n",
      "Gradient for encoder.encoder.0.bias: 2.7977732977579883e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0009199978085234761\n",
      "Gradient for encoder.encoder.1.bias: 0.0010324616450816393\n",
      "Gradient for encoder.encoder.3.weight: 0.02012673020362854\n",
      "Gradient for encoder.encoder.3.bias: 1.9349530311352225e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.00392697611823678\n",
      "Gradient for encoder.encoder.4.bias: 0.0038981097750365734\n",
      "Gradient for encoder.mean.weight: 0.05221821740269661\n",
      "Gradient for encoder.mean.bias: 0.0031294459477066994\n",
      "Gradient for encoder.log_var.weight: 0.029407085850834846\n",
      "Gradient for encoder.log_var.bias: 0.0017135352827608585\n",
      "Gradient for decoder.decoder.0.weight: 0.008696491830050945\n",
      "Gradient for decoder.decoder.0.bias: 6.750854042447685e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.00043881559395231307\n",
      "Gradient for decoder.decoder.1.bias: 0.00034605644759722054\n",
      "Gradient for decoder.decoder.3.weight: 0.007958885282278061\n",
      "Gradient for decoder.decoder.3.bias: 6.304583244354234e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0003745374269783497\n",
      "Gradient for decoder.decoder.4.bias: 0.00041064672404900193\n",
      "Gradient for decoder.decoder.6.weight: 0.00044557848013937473\n",
      "Gradient for decoder.decoder.6.bias: 2.935669181169942e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.00982721522450447\n",
      "Gradient for encoder.encoder.0.bias: 1.446621034767448e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0007080246577970684\n",
      "Gradient for encoder.encoder.1.bias: 0.000660110090393573\n",
      "Gradient for encoder.encoder.3.weight: 0.014526722021400928\n",
      "Gradient for encoder.encoder.3.bias: 1.4562623329439361e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0032464799005538225\n",
      "Gradient for encoder.encoder.4.bias: 0.0034710951149463654\n",
      "Gradient for encoder.mean.weight: 0.047244440764188766\n",
      "Gradient for encoder.mean.bias: 0.0027275108732283115\n",
      "Gradient for encoder.log_var.weight: 0.03140152618288994\n",
      "Gradient for encoder.log_var.bias: 0.0015418962575495243\n",
      "Gradient for decoder.decoder.0.weight: 0.0118311308324337\n",
      "Gradient for decoder.decoder.0.bias: 1.0880513157118799e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.000578771869186312\n",
      "Gradient for decoder.decoder.1.bias: 0.0005157768027856946\n",
      "Gradient for decoder.decoder.3.weight: 0.011541825719177723\n",
      "Gradient for decoder.decoder.3.bias: 8.716152105625596e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0004042467044200748\n",
      "Gradient for decoder.decoder.4.bias: 0.0003605819947551936\n",
      "Gradient for decoder.decoder.6.weight: 0.00044071170850656927\n",
      "Gradient for decoder.decoder.6.bias: 2.3536404114565812e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.014023270457983017\n",
      "Gradient for encoder.encoder.0.bias: 2.7185717219047056e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.00106532103382051\n",
      "Gradient for encoder.encoder.1.bias: 0.0009150718688033521\n",
      "Gradient for encoder.encoder.3.weight: 0.022624997422099113\n",
      "Gradient for encoder.encoder.3.bias: 2.0753543328311252e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0045907325111329556\n",
      "Gradient for encoder.encoder.4.bias: 0.004458147566765547\n",
      "Gradient for encoder.mean.weight: 0.06500928848981857\n",
      "Gradient for encoder.mean.bias: 0.002951095113530755\n",
      "Gradient for encoder.log_var.weight: 0.032967206090688705\n",
      "Gradient for encoder.log_var.bias: 0.0015412616776302457\n",
      "Gradient for decoder.decoder.0.weight: 0.008253812789916992\n",
      "Gradient for decoder.decoder.0.bias: 6.900893745331871e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.00043278903467580676\n",
      "Gradient for decoder.decoder.1.bias: 0.0003253363538533449\n",
      "Gradient for decoder.decoder.3.weight: 0.007982242852449417\n",
      "Gradient for decoder.decoder.3.bias: 8.18835693694453e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00047852128045633435\n",
      "Gradient for decoder.decoder.4.bias: 0.0005979406996630132\n",
      "Gradient for decoder.decoder.6.weight: 0.00045801696251146495\n",
      "Gradient for decoder.decoder.6.bias: 3.479848965071142e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.007839592173695564\n",
      "Gradient for encoder.encoder.0.bias: 1.4036411789819514e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0005967604229226708\n",
      "Gradient for encoder.encoder.1.bias: 0.000695427821483463\n",
      "Gradient for encoder.encoder.3.weight: 0.013281292282044888\n",
      "Gradient for encoder.encoder.3.bias: 1.5994763846727267e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.004007855895906687\n",
      "Gradient for encoder.encoder.4.bias: 0.003898821072652936\n",
      "Gradient for encoder.mean.weight: 0.05239863321185112\n",
      "Gradient for encoder.mean.bias: 0.0030884831212460995\n",
      "Gradient for encoder.log_var.weight: 0.033711012452840805\n",
      "Gradient for encoder.log_var.bias: 0.001814303221181035\n",
      "Gradient for decoder.decoder.0.weight: 0.01227282639592886\n",
      "Gradient for decoder.decoder.0.bias: 1.0829344365692606e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0006364590954035521\n",
      "Gradient for decoder.decoder.1.bias: 0.0005301318597048521\n",
      "Gradient for decoder.decoder.3.weight: 0.011925878934562206\n",
      "Gradient for decoder.decoder.3.bias: 9.01522259622034e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00043703673873096704\n",
      "Gradient for decoder.decoder.4.bias: 0.00039775585173629224\n",
      "Gradient for decoder.decoder.6.weight: 0.00043509522220119834\n",
      "Gradient for decoder.decoder.6.bias: 1.7967568055610172e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.008742007426917553\n",
      "Gradient for encoder.encoder.0.bias: 1.2455206137296226e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0006241240771487355\n",
      "Gradient for encoder.encoder.1.bias: 0.0005588867352344096\n",
      "Gradient for encoder.encoder.3.weight: 0.012625150382518768\n",
      "Gradient for encoder.encoder.3.bias: 1.454248388377266e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0029220811557024717\n",
      "Gradient for encoder.encoder.4.bias: 0.0027539869770407677\n",
      "Gradient for encoder.mean.weight: 0.04081706702709198\n",
      "Gradient for encoder.mean.bias: 0.0021195998415350914\n",
      "Gradient for encoder.log_var.weight: 0.02723355032503605\n",
      "Gradient for encoder.log_var.bias: 0.0013853326672688127\n",
      "Gradient for decoder.decoder.0.weight: 0.01200575940310955\n",
      "Gradient for decoder.decoder.0.bias: 1.0529353083876813e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0006135171861387789\n",
      "Gradient for decoder.decoder.1.bias: 0.0004980382509529591\n",
      "Gradient for decoder.decoder.3.weight: 0.011109764687716961\n",
      "Gradient for decoder.decoder.3.bias: 9.220822716482502e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.000394600530853495\n",
      "Gradient for decoder.decoder.4.bias: 0.00036254944279789925\n",
      "Gradient for decoder.decoder.6.weight: 0.0004228079633321613\n",
      "Gradient for decoder.decoder.6.bias: 2.267947274958715e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.00831648614257574\n",
      "Gradient for encoder.encoder.0.bias: 1.409531259072283e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0009094295091927052\n",
      "Gradient for encoder.encoder.1.bias: 0.0009051741799339652\n",
      "Gradient for encoder.encoder.3.weight: 0.01953986845910549\n",
      "Gradient for encoder.encoder.3.bias: 2.1144437589715182e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.004618706181645393\n",
      "Gradient for encoder.encoder.4.bias: 0.005604508798569441\n",
      "Gradient for encoder.mean.weight: 0.06491611152887344\n",
      "Gradient for encoder.mean.bias: 0.004217016976326704\n",
      "Gradient for encoder.log_var.weight: 0.03660818561911583\n",
      "Gradient for encoder.log_var.bias: 0.002330525079742074\n",
      "Gradient for decoder.decoder.0.weight: 0.011598733253777027\n",
      "Gradient for decoder.decoder.0.bias: 9.69333641132053e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005717205931432545\n",
      "Gradient for decoder.decoder.1.bias: 0.0004840557521674782\n",
      "Gradient for decoder.decoder.3.weight: 0.011372361332178116\n",
      "Gradient for decoder.decoder.3.bias: 8.302366433232677e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00045483739813789725\n",
      "Gradient for decoder.decoder.4.bias: 0.0004293529491405934\n",
      "Gradient for decoder.decoder.6.weight: 0.0004586826544255018\n",
      "Gradient for decoder.decoder.6.bias: 2.5312427169410512e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.016883285716176033\n",
      "Gradient for encoder.encoder.0.bias: 2.525852270396367e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0012740993406623602\n",
      "Gradient for encoder.encoder.1.bias: 0.001167981536127627\n",
      "Gradient for encoder.encoder.3.weight: 0.026893986389040947\n",
      "Gradient for encoder.encoder.3.bias: 2.3662602433027757e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.005220733117312193\n",
      "Gradient for encoder.encoder.4.bias: 0.004874141421169043\n",
      "Gradient for encoder.mean.weight: 0.0710686445236206\n",
      "Gradient for encoder.mean.bias: 0.0032605647575110197\n",
      "Gradient for encoder.log_var.weight: 0.044018249958753586\n",
      "Gradient for encoder.log_var.bias: 0.0020258277654647827\n",
      "Gradient for decoder.decoder.0.weight: 0.009787630289793015\n",
      "Gradient for decoder.decoder.0.bias: 8.107601395801467e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0004935539909638464\n",
      "Gradient for decoder.decoder.1.bias: 0.0004242235154379159\n",
      "Gradient for decoder.decoder.3.weight: 0.008918066509068012\n",
      "Gradient for decoder.decoder.3.bias: 7.868418416823175e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0003566466912161559\n",
      "Gradient for decoder.decoder.4.bias: 0.0003479383303783834\n",
      "Gradient for decoder.decoder.6.weight: 0.0004136658099014312\n",
      "Gradient for decoder.decoder.6.bias: 2.588266579550691e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.010118676349520683\n",
      "Gradient for encoder.encoder.0.bias: 1.695781882971037e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.001163001055829227\n",
      "Gradient for encoder.encoder.1.bias: 0.0012503815814852715\n",
      "Gradient for encoder.encoder.3.weight: 0.02465423010289669\n",
      "Gradient for encoder.encoder.3.bias: 2.5315904927936117e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.005954086780548096\n",
      "Gradient for encoder.encoder.4.bias: 0.007288902997970581\n",
      "Gradient for encoder.mean.weight: 0.081322580575943\n",
      "Gradient for encoder.mean.bias: 0.005498213227838278\n",
      "Gradient for encoder.log_var.weight: 0.05230902135372162\n",
      "Gradient for encoder.log_var.bias: 0.003548087552189827\n",
      "Gradient for decoder.decoder.0.weight: 0.011036609299480915\n",
      "Gradient for decoder.decoder.0.bias: 9.411745688359119e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005171489901840687\n",
      "Gradient for decoder.decoder.1.bias: 0.0004372471012175083\n",
      "Gradient for decoder.decoder.3.weight: 0.010343851521611214\n",
      "Gradient for decoder.decoder.3.bias: 8.488776348514193e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00039671931881457567\n",
      "Gradient for decoder.decoder.4.bias: 0.0003405425522942096\n",
      "Gradient for decoder.decoder.6.weight: 0.0004586064605973661\n",
      "Gradient for decoder.decoder.6.bias: 2.5599281798349693e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.00800628587603569\n",
      "Gradient for encoder.encoder.0.bias: 1.5530091102000654e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0008355077006854117\n",
      "Gradient for encoder.encoder.1.bias: 0.0007522228406742215\n",
      "Gradient for encoder.encoder.3.weight: 0.01841016300022602\n",
      "Gradient for encoder.encoder.3.bias: 1.6577256234384663e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.004144785925745964\n",
      "Gradient for encoder.encoder.4.bias: 0.003384622512385249\n",
      "Gradient for encoder.mean.weight: 0.05560918152332306\n",
      "Gradient for encoder.mean.bias: 0.0021359387319535017\n",
      "Gradient for encoder.log_var.weight: 0.028445515781641006\n",
      "Gradient for encoder.log_var.bias: 0.0012184277875348926\n",
      "Gradient for decoder.decoder.0.weight: 0.009273066185414791\n",
      "Gradient for decoder.decoder.0.bias: 8.511735760663441e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0004733136738650501\n",
      "Gradient for decoder.decoder.1.bias: 0.0003623253433033824\n",
      "Gradient for decoder.decoder.3.weight: 0.008917152881622314\n",
      "Gradient for decoder.decoder.3.bias: 6.658759654776247e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00033765845000743866\n",
      "Gradient for decoder.decoder.4.bias: 0.0003124203940387815\n",
      "Gradient for decoder.decoder.6.weight: 0.00048215690185315907\n",
      "Gradient for decoder.decoder.6.bias: 3.487689536996186e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.007504557725042105\n",
      "Gradient for encoder.encoder.0.bias: 1.3830456745134168e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0006709789158776402\n",
      "Gradient for encoder.encoder.1.bias: 0.0006909044459462166\n",
      "Gradient for encoder.encoder.3.weight: 0.01446179673075676\n",
      "Gradient for encoder.encoder.3.bias: 1.5821022270046114e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.004168747924268246\n",
      "Gradient for encoder.encoder.4.bias: 0.0036600599996745586\n",
      "Gradient for encoder.mean.weight: 0.05564305931329727\n",
      "Gradient for encoder.mean.bias: 0.002492210129275918\n",
      "Gradient for encoder.log_var.weight: 0.030727075412869453\n",
      "Gradient for encoder.log_var.bias: 0.0013553219614550471\n",
      "Gradient for decoder.decoder.0.weight: 0.009968213737010956\n",
      "Gradient for decoder.decoder.0.bias: 8.435823567465306e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005282299825921655\n",
      "Gradient for decoder.decoder.1.bias: 0.0004079468490090221\n",
      "Gradient for decoder.decoder.3.weight: 0.009519191458821297\n",
      "Gradient for decoder.decoder.3.bias: 8.309302551579023e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0005070918705314398\n",
      "Gradient for decoder.decoder.4.bias: 0.0005687750526703894\n",
      "Gradient for decoder.decoder.6.weight: 0.0004580079985316843\n",
      "Gradient for decoder.decoder.6.bias: 3.0715615139342844e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.008338074199855328\n",
      "Gradient for encoder.encoder.0.bias: 1.6024508109335756e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0009533885167911649\n",
      "Gradient for encoder.encoder.1.bias: 0.0008554577943868935\n",
      "Gradient for encoder.encoder.3.weight: 0.020508084446191788\n",
      "Gradient for encoder.encoder.3.bias: 2.081677746845756e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0046703447587788105\n",
      "Gradient for encoder.encoder.4.bias: 0.005657305475324392\n",
      "Gradient for encoder.mean.weight: 0.06508606672286987\n",
      "Gradient for encoder.mean.bias: 0.004443083889782429\n",
      "Gradient for encoder.log_var.weight: 0.03605535626411438\n",
      "Gradient for encoder.log_var.bias: 0.0026928307488560677\n",
      "Gradient for decoder.decoder.0.weight: 0.009876581840217113\n",
      "Gradient for decoder.decoder.0.bias: 7.792884393342803e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005309004336595535\n",
      "Gradient for decoder.decoder.1.bias: 0.0004085554974153638\n",
      "Gradient for decoder.decoder.3.weight: 0.00939620565623045\n",
      "Gradient for decoder.decoder.3.bias: 6.684031800263668e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00031750230118632317\n",
      "Gradient for decoder.decoder.4.bias: 0.0002975123352371156\n",
      "Gradient for decoder.decoder.6.weight: 0.000455024215625599\n",
      "Gradient for decoder.decoder.6.bias: 3.107491647824645e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.007905671373009682\n",
      "Gradient for encoder.encoder.0.bias: 1.2696275454582295e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0007380351889878511\n",
      "Gradient for encoder.encoder.1.bias: 0.0008440138190053403\n",
      "Gradient for encoder.encoder.3.weight: 0.01604793220758438\n",
      "Gradient for encoder.encoder.3.bias: 1.790591563910482e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.004363074898719788\n",
      "Gradient for encoder.encoder.4.bias: 0.0042463005520403385\n",
      "Gradient for encoder.mean.weight: 0.06181729957461357\n",
      "Gradient for encoder.mean.bias: 0.0029201186262071133\n",
      "Gradient for encoder.log_var.weight: 0.03608708456158638\n",
      "Gradient for encoder.log_var.bias: 0.0015700606163591146\n",
      "Gradient for decoder.decoder.0.weight: 0.011420725844800472\n",
      "Gradient for decoder.decoder.0.bias: 1.048695574823455e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0005842027603648603\n",
      "Gradient for decoder.decoder.1.bias: 0.00045431338367052376\n",
      "Gradient for decoder.decoder.3.weight: 0.010836162604391575\n",
      "Gradient for decoder.decoder.3.bias: 9.960991059765334e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0003954300482291728\n",
      "Gradient for decoder.decoder.4.bias: 0.0003348247264511883\n",
      "Gradient for decoder.decoder.6.weight: 0.0004703180165961385\n",
      "Gradient for decoder.decoder.6.bias: 3.020856274815742e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.010411505587399006\n",
      "Gradient for encoder.encoder.0.bias: 1.7154503512140096e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0008662220789119601\n",
      "Gradient for encoder.encoder.1.bias: 0.000994333648122847\n",
      "Gradient for encoder.encoder.3.weight: 0.01972329616546631\n",
      "Gradient for encoder.encoder.3.bias: 1.90087931506433e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.004304573405534029\n",
      "Gradient for encoder.encoder.4.bias: 0.004147805739194155\n",
      "Gradient for encoder.mean.weight: 0.05881328508257866\n",
      "Gradient for encoder.mean.bias: 0.0031592438463121653\n",
      "Gradient for encoder.log_var.weight: 0.03485746681690216\n",
      "Gradient for encoder.log_var.bias: 0.0018135358113795519\n",
      "Gradient for decoder.decoder.0.weight: 0.010706118308007717\n",
      "Gradient for decoder.decoder.0.bias: 8.760683151143311e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005311436834745109\n",
      "Gradient for decoder.decoder.1.bias: 0.0004089587600901723\n",
      "Gradient for decoder.decoder.3.weight: 0.010016278363764286\n",
      "Gradient for decoder.decoder.3.bias: 8.550769120541091e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0005573505768552423\n",
      "Gradient for decoder.decoder.4.bias: 0.0006523241172544658\n",
      "Gradient for decoder.decoder.6.weight: 0.0004769176885019988\n",
      "Gradient for decoder.decoder.6.bias: 3.522007318679243e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training VAE Epoch:  62%|██████▏   | 49/79 [00:00<00:00, 72.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient for encoder.encoder.0.weight: 0.009513122029602528\n",
      "Gradient for encoder.encoder.0.bias: 1.66958374209214e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0006541074253618717\n",
      "Gradient for encoder.encoder.1.bias: 0.0006043037283234298\n",
      "Gradient for encoder.encoder.3.weight: 0.014012683182954788\n",
      "Gradient for encoder.encoder.3.bias: 1.5841851441766863e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0036238401662558317\n",
      "Gradient for encoder.encoder.4.bias: 0.003508697496727109\n",
      "Gradient for encoder.mean.weight: 0.04918298125267029\n",
      "Gradient for encoder.mean.bias: 0.00306198769249022\n",
      "Gradient for encoder.log_var.weight: 0.02949986420571804\n",
      "Gradient for encoder.log_var.bias: 0.0018484180327504873\n",
      "Gradient for decoder.decoder.0.weight: 0.00952491071075201\n",
      "Gradient for decoder.decoder.0.bias: 8.149816238534058e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.00044497038470581174\n",
      "Gradient for decoder.decoder.1.bias: 0.0003878608695231378\n",
      "Gradient for decoder.decoder.3.weight: 0.00876076053828001\n",
      "Gradient for decoder.decoder.3.bias: 7.993566919495265e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00036121776793152094\n",
      "Gradient for decoder.decoder.4.bias: 0.00037333433283492923\n",
      "Gradient for decoder.decoder.6.weight: 0.0004157376824878156\n",
      "Gradient for decoder.decoder.6.bias: 2.3864458853495307e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.016242779791355133\n",
      "Gradient for encoder.encoder.0.bias: 2.0826559227193897e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.001365915173664689\n",
      "Gradient for encoder.encoder.1.bias: 0.0010512692388147116\n",
      "Gradient for encoder.encoder.3.weight: 0.027771977707743645\n",
      "Gradient for encoder.encoder.3.bias: 2.223500689124691e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.005991964600980282\n",
      "Gradient for encoder.encoder.4.bias: 0.004741104785352945\n",
      "Gradient for encoder.mean.weight: 0.08059875667095184\n",
      "Gradient for encoder.mean.bias: 0.003057905239984393\n",
      "Gradient for encoder.log_var.weight: 0.04433778300881386\n",
      "Gradient for encoder.log_var.bias: 0.0017826564144343138\n",
      "Gradient for decoder.decoder.0.weight: 0.010548694990575314\n",
      "Gradient for decoder.decoder.0.bias: 1.0534875055645543e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0005624309414997697\n",
      "Gradient for decoder.decoder.1.bias: 0.00046621073852293193\n",
      "Gradient for decoder.decoder.3.weight: 0.009716206230223179\n",
      "Gradient for decoder.decoder.3.bias: 9.471520789894328e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0003367265744600445\n",
      "Gradient for decoder.decoder.4.bias: 0.0003017734852619469\n",
      "Gradient for decoder.decoder.6.weight: 0.00044294839608483016\n",
      "Gradient for decoder.decoder.6.bias: 2.7513258828548715e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training VAE Epoch:  72%|███████▏  | 57/79 [00:00<00:00, 73.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient for encoder.encoder.0.weight: 0.007845936343073845\n",
      "Gradient for encoder.encoder.0.bias: 1.2349592702631806e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0006987526430748403\n",
      "Gradient for encoder.encoder.1.bias: 0.0008545880555175245\n",
      "Gradient for encoder.encoder.3.weight: 0.014703076332807541\n",
      "Gradient for encoder.encoder.3.bias: 1.8606367835349857e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0037841389421373606\n",
      "Gradient for encoder.encoder.4.bias: 0.004227818455547094\n",
      "Gradient for encoder.mean.weight: 0.05082884803414345\n",
      "Gradient for encoder.mean.bias: 0.0035760104656219482\n",
      "Gradient for encoder.log_var.weight: 0.032659973949193954\n",
      "Gradient for encoder.log_var.bias: 0.002600584179162979\n",
      "Gradient for decoder.decoder.0.weight: 0.012216153554618359\n",
      "Gradient for decoder.decoder.0.bias: 9.204394191275611e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.000597133010160178\n",
      "Gradient for decoder.decoder.1.bias: 0.0005097539979033172\n",
      "Gradient for decoder.decoder.3.weight: 0.012266522273421288\n",
      "Gradient for decoder.decoder.3.bias: 1.024688806028351e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0006172193097881973\n",
      "Gradient for decoder.decoder.4.bias: 0.0006362154381349683\n",
      "Gradient for decoder.decoder.6.weight: 0.0005204619956202805\n",
      "Gradient for decoder.decoder.6.bias: 2.9202827136032283e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.006444023922085762\n",
      "Gradient for encoder.encoder.0.bias: 1.3052923325540533e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0007199278916232288\n",
      "Gradient for encoder.encoder.1.bias: 0.0008757449686527252\n",
      "Gradient for encoder.encoder.3.weight: 0.015387455932796001\n",
      "Gradient for encoder.encoder.3.bias: 1.5976790723737366e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.003905120538547635\n",
      "Gradient for encoder.encoder.4.bias: 0.0033763141836971045\n",
      "Gradient for encoder.mean.weight: 0.050144582986831665\n",
      "Gradient for encoder.mean.bias: 0.002781990449875593\n",
      "Gradient for encoder.log_var.weight: 0.030631661415100098\n",
      "Gradient for encoder.log_var.bias: 0.0014381187502294779\n",
      "Gradient for decoder.decoder.0.weight: 0.012428425252437592\n",
      "Gradient for decoder.decoder.0.bias: 1.0208071193895663e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0006220883806236088\n",
      "Gradient for decoder.decoder.1.bias: 0.00047527943388558924\n",
      "Gradient for decoder.decoder.3.weight: 0.011541837826371193\n",
      "Gradient for decoder.decoder.3.bias: 8.86293746726885e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0004208030295558274\n",
      "Gradient for decoder.decoder.4.bias: 0.00038907714770175517\n",
      "Gradient for decoder.decoder.6.weight: 0.0004319892614148557\n",
      "Gradient for decoder.decoder.6.bias: 2.2061472918721847e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.01074418518692255\n",
      "Gradient for encoder.encoder.0.bias: 1.5475443843060432e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0007799454615451396\n",
      "Gradient for encoder.encoder.1.bias: 0.000652350194286555\n",
      "Gradient for encoder.encoder.3.weight: 0.016751118004322052\n",
      "Gradient for encoder.encoder.3.bias: 1.7463328005895562e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0034568067640066147\n",
      "Gradient for encoder.encoder.4.bias: 0.0034080769401043653\n",
      "Gradient for encoder.mean.weight: 0.047019120305776596\n",
      "Gradient for encoder.mean.bias: 0.00239283568225801\n",
      "Gradient for encoder.log_var.weight: 0.027184685692191124\n",
      "Gradient for encoder.log_var.bias: 0.001470688614062965\n",
      "Gradient for decoder.decoder.0.weight: 0.009964707307517529\n",
      "Gradient for decoder.decoder.0.bias: 8.859270955730025e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0004895826568827033\n",
      "Gradient for decoder.decoder.1.bias: 0.0003963580238632858\n",
      "Gradient for decoder.decoder.3.weight: 0.009479974396526814\n",
      "Gradient for decoder.decoder.3.bias: 7.999902823518923e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00045545658213086426\n",
      "Gradient for decoder.decoder.4.bias: 0.0005246506771072745\n",
      "Gradient for decoder.decoder.6.weight: 0.0004897917388007045\n",
      "Gradient for decoder.decoder.6.bias: 3.726078648469411e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.014294007793068886\n",
      "Gradient for encoder.encoder.0.bias: 2.1748722614511884e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0009438734268769622\n",
      "Gradient for encoder.encoder.1.bias: 0.0008399674552492797\n",
      "Gradient for encoder.encoder.3.weight: 0.02046019956469536\n",
      "Gradient for encoder.encoder.3.bias: 1.9038377818691998e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0037872749380767345\n",
      "Gradient for encoder.encoder.4.bias: 0.004047693219035864\n",
      "Gradient for encoder.mean.weight: 0.04952239990234375\n",
      "Gradient for encoder.mean.bias: 0.0032296250574290752\n",
      "Gradient for encoder.log_var.weight: 0.03154847398400307\n",
      "Gradient for encoder.log_var.bias: 0.0021541824098676443\n",
      "Gradient for decoder.decoder.0.weight: 0.00828179344534874\n",
      "Gradient for decoder.decoder.0.bias: 7.325925976964243e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.00042494910303503275\n",
      "Gradient for decoder.decoder.1.bias: 0.0003550281107891351\n",
      "Gradient for decoder.decoder.3.weight: 0.007722855545580387\n",
      "Gradient for decoder.decoder.3.bias: 7.302228960393009e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00042952204239554703\n",
      "Gradient for decoder.decoder.4.bias: 0.0004949136637151241\n",
      "Gradient for decoder.decoder.6.weight: 0.0004464430967345834\n",
      "Gradient for decoder.decoder.6.bias: 3.1831543310545385e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.010026928037405014\n",
      "Gradient for encoder.encoder.0.bias: 1.7375616570558527e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.000893911812454462\n",
      "Gradient for encoder.encoder.1.bias: 0.0010110122384503484\n",
      "Gradient for encoder.encoder.3.weight: 0.01940440572798252\n",
      "Gradient for encoder.encoder.3.bias: 1.7625566284262817e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0028518280014395714\n",
      "Gradient for encoder.encoder.4.bias: 0.00348696974106133\n",
      "Gradient for encoder.mean.weight: 0.038406357169151306\n",
      "Gradient for encoder.mean.bias: 0.0026965662837028503\n",
      "Gradient for encoder.log_var.weight: 0.02463112585246563\n",
      "Gradient for encoder.log_var.bias: 0.0017906598513945937\n",
      "Gradient for decoder.decoder.0.weight: 0.009877295233309269\n",
      "Gradient for decoder.decoder.0.bias: 8.016921154707646e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0004461764183361083\n",
      "Gradient for decoder.decoder.1.bias: 0.00041118173976428807\n",
      "Gradient for decoder.decoder.3.weight: 0.00920684915035963\n",
      "Gradient for decoder.decoder.3.bias: 7.80983888670761e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0004424274666234851\n",
      "Gradient for decoder.decoder.4.bias: 0.0004693344235420227\n",
      "Gradient for decoder.decoder.6.weight: 0.00042027811286970973\n",
      "Gradient for decoder.decoder.6.bias: 2.4567434593336657e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.016138780862092972\n",
      "Gradient for encoder.encoder.0.bias: 2.131266690907907e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0014652146492153406\n",
      "Gradient for encoder.encoder.1.bias: 0.0010594431078061461\n",
      "Gradient for encoder.encoder.3.weight: 0.032397281378507614\n",
      "Gradient for encoder.encoder.3.bias: 2.290065220789117e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0064191813580691814\n",
      "Gradient for encoder.encoder.4.bias: 0.006564129609614611\n",
      "Gradient for encoder.mean.weight: 0.08482766151428223\n",
      "Gradient for encoder.mean.bias: 0.004853499121963978\n",
      "Gradient for encoder.log_var.weight: 0.05311384052038193\n",
      "Gradient for encoder.log_var.bias: 0.003121859859675169\n",
      "Gradient for decoder.decoder.0.weight: 0.009213708341121674\n",
      "Gradient for decoder.decoder.0.bias: 7.200804535978378e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0004456951282918453\n",
      "Gradient for decoder.decoder.1.bias: 0.0003502850595396012\n",
      "Gradient for decoder.decoder.3.weight: 0.008907254785299301\n",
      "Gradient for decoder.decoder.3.bias: 7.090331793913052e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00039538880810141563\n",
      "Gradient for decoder.decoder.4.bias: 0.0004366197099443525\n",
      "Gradient for decoder.decoder.6.weight: 0.0004287294577807188\n",
      "Gradient for decoder.decoder.6.bias: 2.5301871573901735e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.013108731247484684\n",
      "Gradient for encoder.encoder.0.bias: 1.819730824359489e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0010111808078363538\n",
      "Gradient for encoder.encoder.1.bias: 0.0007469076081179082\n",
      "Gradient for encoder.encoder.3.weight: 0.02238916978240013\n",
      "Gradient for encoder.encoder.3.bias: 2.0628181107706922e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.004206452984362841\n",
      "Gradient for encoder.encoder.4.bias: 0.003953748382627964\n",
      "Gradient for encoder.mean.weight: 0.057733602821826935\n",
      "Gradient for encoder.mean.bias: 0.002821272937580943\n",
      "Gradient for encoder.log_var.weight: 0.03553365543484688\n",
      "Gradient for encoder.log_var.bias: 0.0018012921791523695\n",
      "Gradient for decoder.decoder.0.weight: 0.010152444243431091\n",
      "Gradient for decoder.decoder.0.bias: 8.380922345008202e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005365640390664339\n",
      "Gradient for decoder.decoder.1.bias: 0.0004331055097281933\n",
      "Gradient for decoder.decoder.3.weight: 0.009660654701292515\n",
      "Gradient for decoder.decoder.3.bias: 7.320249267861456e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0003581712662708014\n",
      "Gradient for decoder.decoder.4.bias: 0.0003165598027408123\n",
      "Gradient for decoder.decoder.6.weight: 0.00041926646372303367\n",
      "Gradient for decoder.decoder.6.bias: 1.899002745631151e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.011645368300378323\n",
      "Gradient for encoder.encoder.0.bias: 1.7084975795222945e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.000976507377345115\n",
      "Gradient for encoder.encoder.1.bias: 0.0008196523413062096\n",
      "Gradient for encoder.encoder.3.weight: 0.019260305911302567\n",
      "Gradient for encoder.encoder.3.bias: 1.7267230700834801e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0037164108362048864\n",
      "Gradient for encoder.encoder.4.bias: 0.004035592079162598\n",
      "Gradient for encoder.mean.weight: 0.04885011911392212\n",
      "Gradient for encoder.mean.bias: 0.003400105517357588\n",
      "Gradient for encoder.log_var.weight: 0.03355857729911804\n",
      "Gradient for encoder.log_var.bias: 0.0023622734006494284\n",
      "Gradient for decoder.decoder.0.weight: 0.011484267190098763\n",
      "Gradient for decoder.decoder.0.bias: 9.219126156922997e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005940153496339917\n",
      "Gradient for decoder.decoder.1.bias: 0.0004821844049729407\n",
      "Gradient for decoder.decoder.3.weight: 0.010598881170153618\n",
      "Gradient for decoder.decoder.3.bias: 8.240986365537495e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0003858065465465188\n",
      "Gradient for decoder.decoder.4.bias: 0.0003527096414472908\n",
      "Gradient for decoder.decoder.6.weight: 0.0004208766622468829\n",
      "Gradient for decoder.decoder.6.bias: 2.2260079276748e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.01126144640147686\n",
      "Gradient for encoder.encoder.0.bias: 1.526116039096692e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0008875662460923195\n",
      "Gradient for encoder.encoder.1.bias: 0.000857702863868326\n",
      "Gradient for encoder.encoder.3.weight: 0.01898079179227352\n",
      "Gradient for encoder.encoder.3.bias: 1.6817860992723865e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.003489477327093482\n",
      "Gradient for encoder.encoder.4.bias: 0.004011624958366156\n",
      "Gradient for encoder.mean.weight: 0.05011894926428795\n",
      "Gradient for encoder.mean.bias: 0.0033888923935592175\n",
      "Gradient for encoder.log_var.weight: 0.0313609316945076\n",
      "Gradient for encoder.log_var.bias: 0.002439232310280204\n",
      "Gradient for decoder.decoder.0.weight: 0.011625261977314949\n",
      "Gradient for decoder.decoder.0.bias: 9.623239705103259e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005460525280795991\n",
      "Gradient for decoder.decoder.1.bias: 0.0004490290302783251\n",
      "Gradient for decoder.decoder.3.weight: 0.010690578259527683\n",
      "Gradient for decoder.decoder.3.bias: 9.104607345822302e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0004723730671685189\n",
      "Gradient for decoder.decoder.4.bias: 0.0004638752725441009\n",
      "Gradient for decoder.decoder.6.weight: 0.0004490920400712639\n",
      "Gradient for decoder.decoder.6.bias: 2.4377433874178678e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.01567383110523224\n",
      "Gradient for encoder.encoder.0.bias: 2.4479925031517524e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0012368224561214447\n",
      "Gradient for encoder.encoder.1.bias: 0.0012569236569106579\n",
      "Gradient for encoder.encoder.3.weight: 0.025797953829169273\n",
      "Gradient for encoder.encoder.3.bias: 1.9449622468137306e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.004523167852312326\n",
      "Gradient for encoder.encoder.4.bias: 0.004219650290906429\n",
      "Gradient for encoder.mean.weight: 0.06171135976910591\n",
      "Gradient for encoder.mean.bias: 0.00296658743172884\n",
      "Gradient for encoder.log_var.weight: 0.03130544722080231\n",
      "Gradient for encoder.log_var.bias: 0.001580316573381424\n",
      "Gradient for decoder.decoder.0.weight: 0.010815223678946495\n",
      "Gradient for decoder.decoder.0.bias: 8.095270981334224e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005241214530542493\n",
      "Gradient for decoder.decoder.1.bias: 0.0004244988376740366\n",
      "Gradient for decoder.decoder.3.weight: 0.00999755784869194\n",
      "Gradient for decoder.decoder.3.bias: 8.039242882507125e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0003608259139582515\n",
      "Gradient for decoder.decoder.4.bias: 0.00035402458161115646\n",
      "Gradient for decoder.decoder.6.weight: 0.000452566659078002\n",
      "Gradient for decoder.decoder.6.bias: 2.9504804842872545e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.013335905969142914\n",
      "Gradient for encoder.encoder.0.bias: 2.1483278697664865e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0010110309813171625\n",
      "Gradient for encoder.encoder.1.bias: 0.0008300648769363761\n",
      "Gradient for encoder.encoder.3.weight: 0.02194121852517128\n",
      "Gradient for encoder.encoder.3.bias: 1.7142259833846651e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0037949855905026197\n",
      "Gradient for encoder.encoder.4.bias: 0.003637247020378709\n",
      "Gradient for encoder.mean.weight: 0.0495934933423996\n",
      "Gradient for encoder.mean.bias: 0.0024193122517317533\n",
      "Gradient for encoder.log_var.weight: 0.03229096904397011\n",
      "Gradient for encoder.log_var.bias: 0.0015154420398175716\n",
      "Gradient for decoder.decoder.0.weight: 0.00757767865434289\n",
      "Gradient for decoder.decoder.0.bias: 6.592856122145108e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0004052252334076911\n",
      "Gradient for decoder.decoder.1.bias: 0.0003167093964293599\n",
      "Gradient for decoder.decoder.3.weight: 0.007428469602018595\n",
      "Gradient for decoder.decoder.3.bias: 6.035989763564231e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0002999358403030783\n",
      "Gradient for decoder.decoder.4.bias: 0.0003028397914022207\n",
      "Gradient for decoder.decoder.6.weight: 0.0003992306883446872\n",
      "Gradient for decoder.decoder.6.bias: 2.1233707229839638e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.010749953798949718\n",
      "Gradient for encoder.encoder.0.bias: 1.921084645528648e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.000862585031427443\n",
      "Gradient for encoder.encoder.1.bias: 0.0008339209016412497\n",
      "Gradient for encoder.encoder.3.weight: 0.019035566598176956\n",
      "Gradient for encoder.encoder.3.bias: 1.6048926076983605e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.004065240267664194\n",
      "Gradient for encoder.encoder.4.bias: 0.0033618558663874865\n",
      "Gradient for encoder.mean.weight: 0.05256456881761551\n",
      "Gradient for encoder.mean.bias: 0.002242034301161766\n",
      "Gradient for encoder.log_var.weight: 0.032516807317733765\n",
      "Gradient for encoder.log_var.bias: 0.0014638738939538598\n",
      "Gradient for decoder.decoder.0.weight: 0.009314263239502907\n",
      "Gradient for decoder.decoder.0.bias: 7.545757768623318e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.00044755954877473414\n",
      "Gradient for decoder.decoder.1.bias: 0.0003696077037602663\n",
      "Gradient for decoder.decoder.3.weight: 0.008556936867535114\n",
      "Gradient for decoder.decoder.3.bias: 6.88373802404385e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0003065645869355649\n",
      "Gradient for decoder.decoder.4.bias: 0.00027985498309135437\n",
      "Gradient for decoder.decoder.6.weight: 0.00043328924220986664\n",
      "Gradient for decoder.decoder.6.bias: 2.767032310657669e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.00702024158090353\n",
      "Gradient for encoder.encoder.0.bias: 1.1710304601009192e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0007599633536301553\n",
      "Gradient for encoder.encoder.1.bias: 0.0008227094658650458\n",
      "Gradient for encoder.encoder.3.weight: 0.017028724774718285\n",
      "Gradient for encoder.encoder.3.bias: 1.758095891091216e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0062950728461146355\n",
      "Gradient for encoder.encoder.4.bias: 0.004541702102869749\n",
      "Gradient for encoder.mean.weight: 0.08537022024393082\n",
      "Gradient for encoder.mean.bias: 0.0028120826464146376\n",
      "Gradient for encoder.log_var.weight: 0.053545501083135605\n",
      "Gradient for encoder.log_var.bias: 0.0018263868987560272\n",
      "Gradient for decoder.decoder.0.weight: 0.011551677249372005\n",
      "Gradient for decoder.decoder.0.bias: 9.981446918994052e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0006259178626351058\n",
      "Gradient for decoder.decoder.1.bias: 0.00046589187695644796\n",
      "Gradient for decoder.decoder.3.weight: 0.01114687416702509\n",
      "Gradient for decoder.decoder.3.bias: 8.32272306627857e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00043283787090331316\n",
      "Gradient for decoder.decoder.4.bias: 0.0003516209253575653\n",
      "Gradient for decoder.decoder.6.weight: 0.000493098923470825\n",
      "Gradient for decoder.decoder.6.bias: 3.072636900469661e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.006936963181942701\n",
      "Gradient for encoder.encoder.0.bias: 1.1485922456200282e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.000749478058423847\n",
      "Gradient for encoder.encoder.1.bias: 0.0007124986150301993\n",
      "Gradient for encoder.encoder.3.weight: 0.015962935984134674\n",
      "Gradient for encoder.encoder.3.bias: 1.8392169731651364e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.005027933977544308\n",
      "Gradient for encoder.encoder.4.bias: 0.0046599130146205425\n",
      "Gradient for encoder.mean.weight: 0.0677400678396225\n",
      "Gradient for encoder.mean.bias: 0.0024740397930145264\n",
      "Gradient for encoder.log_var.weight: 0.04581401124596596\n",
      "Gradient for encoder.log_var.bias: 0.0017968406900763512\n",
      "Gradient for decoder.decoder.0.weight: 0.011766291223466396\n",
      "Gradient for decoder.decoder.0.bias: 1.0992648458163501e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0006529252277687192\n",
      "Gradient for decoder.decoder.1.bias: 0.0004941755323670805\n",
      "Gradient for decoder.decoder.3.weight: 0.011782869696617126\n",
      "Gradient for decoder.decoder.3.bias: 9.73539096560394e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0004220771079417318\n",
      "Gradient for decoder.decoder.4.bias: 0.00035580137046054006\n",
      "Gradient for decoder.decoder.6.weight: 0.0004227972822263837\n",
      "Gradient for decoder.decoder.6.bias: 1.984593654924538e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training VAE Epoch:  84%|████████▎ | 66/79 [00:01<00:00, 76.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient for encoder.encoder.0.weight: 0.013966197147965431\n",
      "Gradient for encoder.encoder.0.bias: 2.3145639918564775e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0012204460799694061\n",
      "Gradient for encoder.encoder.1.bias: 0.0011021511163562536\n",
      "Gradient for encoder.encoder.3.weight: 0.025917349383234978\n",
      "Gradient for encoder.encoder.3.bias: 2.017556677280652e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0046262904070317745\n",
      "Gradient for encoder.encoder.4.bias: 0.004816384986042976\n",
      "Gradient for encoder.mean.weight: 0.06378162652254105\n",
      "Gradient for encoder.mean.bias: 0.0038363898638635874\n",
      "Gradient for encoder.log_var.weight: 0.04203499108552933\n",
      "Gradient for encoder.log_var.bias: 0.0027172702830284834\n",
      "Gradient for decoder.decoder.0.weight: 0.010154922492802143\n",
      "Gradient for decoder.decoder.0.bias: 8.487771596676907e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005236520664766431\n",
      "Gradient for decoder.decoder.1.bias: 0.00039597428985871375\n",
      "Gradient for decoder.decoder.3.weight: 0.00969384890049696\n",
      "Gradient for decoder.decoder.3.bias: 7.389653472467117e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00040986097883433104\n",
      "Gradient for decoder.decoder.4.bias: 0.00047358678421005607\n",
      "Gradient for decoder.decoder.6.weight: 0.0004323957546148449\n",
      "Gradient for decoder.decoder.6.bias: 2.8488577299867757e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.010107822716236115\n",
      "Gradient for encoder.encoder.0.bias: 1.3652098548866398e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0007298688287846744\n",
      "Gradient for encoder.encoder.1.bias: 0.0006541460170410573\n",
      "Gradient for encoder.encoder.3.weight: 0.015320139937102795\n",
      "Gradient for encoder.encoder.3.bias: 1.602922378163285e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.003995837643742561\n",
      "Gradient for encoder.encoder.4.bias: 0.00324708828702569\n",
      "Gradient for encoder.mean.weight: 0.05095333978533745\n",
      "Gradient for encoder.mean.bias: 0.0024055512621998787\n",
      "Gradient for encoder.log_var.weight: 0.030061248689889908\n",
      "Gradient for encoder.log_var.bias: 0.0013534834142774343\n",
      "Gradient for decoder.decoder.0.weight: 0.010965307243168354\n",
      "Gradient for decoder.decoder.0.bias: 9.751819490810831e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.000566217815503478\n",
      "Gradient for decoder.decoder.1.bias: 0.00045879173558205366\n",
      "Gradient for decoder.decoder.3.weight: 0.010066177695989609\n",
      "Gradient for decoder.decoder.3.bias: 8.469967088808872e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0003925722558051348\n",
      "Gradient for decoder.decoder.4.bias: 0.00035321101313456893\n",
      "Gradient for decoder.decoder.6.weight: 0.00045369163854047656\n",
      "Gradient for decoder.decoder.6.bias: 2.718889845709782e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.014383853413164616\n",
      "Gradient for encoder.encoder.0.bias: 2.3297291179558144e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0010893745347857475\n",
      "Gradient for encoder.encoder.1.bias: 0.0009149964316748083\n",
      "Gradient for encoder.encoder.3.weight: 0.02334088832139969\n",
      "Gradient for encoder.encoder.3.bias: 2.711952329370604e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.006091078277677298\n",
      "Gradient for encoder.encoder.4.bias: 0.0060819401405751705\n",
      "Gradient for encoder.mean.weight: 0.08468666672706604\n",
      "Gradient for encoder.mean.bias: 0.005068476311862469\n",
      "Gradient for encoder.log_var.weight: 0.049664802849292755\n",
      "Gradient for encoder.log_var.bias: 0.003392082406207919\n",
      "Gradient for decoder.decoder.0.weight: 0.00832400657236576\n",
      "Gradient for decoder.decoder.0.bias: 6.935046287237512e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0004087252600584179\n",
      "Gradient for decoder.decoder.1.bias: 0.00036971375811845064\n",
      "Gradient for decoder.decoder.3.weight: 0.008082817308604717\n",
      "Gradient for decoder.decoder.3.bias: 8.512594101839355e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0005271532572805882\n",
      "Gradient for decoder.decoder.4.bias: 0.0006174857844598591\n",
      "Gradient for decoder.decoder.6.weight: 0.0004574403283186257\n",
      "Gradient for decoder.decoder.6.bias: 3.241566082579084e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient for encoder.encoder.0.weight: 0.015720505267381668\n",
      "Gradient for encoder.encoder.0.bias: 2.307345807472938e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0012215194292366505\n",
      "Gradient for encoder.encoder.1.bias: 0.0010630071628838778\n",
      "Gradient for encoder.encoder.3.weight: 0.026840804144740105\n",
      "Gradient for encoder.encoder.3.bias: 2.248189412412671e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.005990961566567421\n",
      "Gradient for encoder.encoder.4.bias: 0.005050595849752426\n",
      "Gradient for encoder.mean.weight: 0.08267369866371155\n",
      "Gradient for encoder.mean.bias: 0.003089337609708309\n",
      "Gradient for encoder.log_var.weight: 0.04268541559576988\n",
      "Gradient for encoder.log_var.bias: 0.0017359902849420905\n",
      "Gradient for decoder.decoder.0.weight: 0.00912680197507143\n",
      "Gradient for decoder.decoder.0.bias: 7.723839623441364e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0004673067305702716\n",
      "Gradient for decoder.decoder.1.bias: 0.00038127502193674445\n",
      "Gradient for decoder.decoder.3.weight: 0.008679724298417568\n",
      "Gradient for decoder.decoder.3.bias: 6.60316037959241e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0003053992404602468\n",
      "Gradient for decoder.decoder.4.bias: 0.0002687316737137735\n",
      "Gradient for decoder.decoder.6.weight: 0.00040854825056158006\n",
      "Gradient for decoder.decoder.6.bias: 2.1456671674968675e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.005283351056277752\n",
      "Gradient for encoder.encoder.0.bias: 8.838694533219726e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.000561598630156368\n",
      "Gradient for encoder.encoder.1.bias: 0.0006710414309054613\n",
      "Gradient for encoder.encoder.3.weight: 0.012209410779178143\n",
      "Gradient for encoder.encoder.3.bias: 1.36451155929862e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0037451989483088255\n",
      "Gradient for encoder.encoder.4.bias: 0.002965432358905673\n",
      "Gradient for encoder.mean.weight: 0.0539233535528183\n",
      "Gradient for encoder.mean.bias: 0.002261238405480981\n",
      "Gradient for encoder.log_var.weight: 0.029011480510234833\n",
      "Gradient for encoder.log_var.bias: 0.001214745920151472\n",
      "Gradient for decoder.decoder.0.weight: 0.014394156634807587\n",
      "Gradient for decoder.decoder.0.bias: 1.0732266464419382e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0007219121907837689\n",
      "Gradient for decoder.decoder.1.bias: 0.0005757450126111507\n",
      "Gradient for decoder.decoder.3.weight: 0.013508710078895092\n",
      "Gradient for decoder.decoder.3.bias: 1.137448607524405e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0006520097958855331\n",
      "Gradient for decoder.decoder.4.bias: 0.0006676478078588843\n",
      "Gradient for decoder.decoder.6.weight: 0.0005454229540191591\n",
      "Gradient for decoder.decoder.6.bias: 3.734141864697449e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.012233013287186623\n",
      "Gradient for encoder.encoder.0.bias: 2.2641990712890525e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0012448144843801856\n",
      "Gradient for encoder.encoder.1.bias: 0.0010515493340790272\n",
      "Gradient for encoder.encoder.3.weight: 0.026437900960445404\n",
      "Gradient for encoder.encoder.3.bias: 2.4164523160230544e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.005189891438931227\n",
      "Gradient for encoder.encoder.4.bias: 0.0053765554912388325\n",
      "Gradient for encoder.mean.weight: 0.0711452066898346\n",
      "Gradient for encoder.mean.bias: 0.003950580954551697\n",
      "Gradient for encoder.log_var.weight: 0.04421866312623024\n",
      "Gradient for encoder.log_var.bias: 0.002518793335184455\n",
      "Gradient for decoder.decoder.0.weight: 0.007708411198109388\n",
      "Gradient for decoder.decoder.0.bias: 6.693992582462727e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0003685906995087862\n",
      "Gradient for decoder.decoder.1.bias: 0.00028835723060183227\n",
      "Gradient for decoder.decoder.3.weight: 0.007302423473447561\n",
      "Gradient for decoder.decoder.3.bias: 6.564614823956205e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00034120125928893685\n",
      "Gradient for decoder.decoder.4.bias: 0.0003791550698224455\n",
      "Gradient for decoder.decoder.6.weight: 0.0004696579708252102\n",
      "Gradient for decoder.decoder.6.bias: 3.505597487674095e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.015642818063497543\n",
      "Gradient for encoder.encoder.0.bias: 3.112576862918104e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0010744977043941617\n",
      "Gradient for encoder.encoder.1.bias: 0.0009823980508372188\n",
      "Gradient for encoder.encoder.3.weight: 0.021999651566147804\n",
      "Gradient for encoder.encoder.3.bias: 2.354149375438652e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.005125804804265499\n",
      "Gradient for encoder.encoder.4.bias: 0.005953071638941765\n",
      "Gradient for encoder.mean.weight: 0.07006342709064484\n",
      "Gradient for encoder.mean.bias: 0.004769966006278992\n",
      "Gradient for encoder.log_var.weight: 0.041641440242528915\n",
      "Gradient for encoder.log_var.bias: 0.0029054286424070597\n",
      "Gradient for decoder.decoder.0.weight: 0.00689335260540247\n",
      "Gradient for decoder.decoder.0.bias: 5.749935944043827e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.00035884007229469717\n",
      "Gradient for decoder.decoder.1.bias: 0.00029022753005847335\n",
      "Gradient for decoder.decoder.3.weight: 0.006493817083537579\n",
      "Gradient for decoder.decoder.3.bias: 8.007126905962281e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0006015225080773234\n",
      "Gradient for decoder.decoder.4.bias: 0.000745193799957633\n",
      "Gradient for decoder.decoder.6.weight: 0.0004899448831565678\n",
      "Gradient for decoder.decoder.6.bias: 4.1864081140374765e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.014148253947496414\n",
      "Gradient for encoder.encoder.0.bias: 2.2045084507871238e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0010559152578935027\n",
      "Gradient for encoder.encoder.1.bias: 0.0008620084263384342\n",
      "Gradient for encoder.encoder.3.weight: 0.02247314713895321\n",
      "Gradient for encoder.encoder.3.bias: 1.687535527983286e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.004734746180474758\n",
      "Gradient for encoder.encoder.4.bias: 0.003541775746271014\n",
      "Gradient for encoder.mean.weight: 0.05971439927816391\n",
      "Gradient for encoder.mean.bias: 0.0019358856370672584\n",
      "Gradient for encoder.log_var.weight: 0.039696983993053436\n",
      "Gradient for encoder.log_var.bias: 0.001161273685283959\n",
      "Gradient for decoder.decoder.0.weight: 0.0079481927677989\n",
      "Gradient for decoder.decoder.0.bias: 6.433693161556064e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.00040055433055385947\n",
      "Gradient for decoder.decoder.1.bias: 0.00031025262433104217\n",
      "Gradient for decoder.decoder.3.weight: 0.007687235716730356\n",
      "Gradient for decoder.decoder.3.bias: 5.856896911904386e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.000322468375088647\n",
      "Gradient for decoder.decoder.4.bias: 0.00034483810304664075\n",
      "Gradient for decoder.decoder.6.weight: 0.00040306939627043903\n",
      "Gradient for decoder.decoder.6.bias: 2.2930851628188975e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.01204555295407772\n",
      "Gradient for encoder.encoder.0.bias: 1.7890241371665283e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.000814970291685313\n",
      "Gradient for encoder.encoder.1.bias: 0.0006942974869161844\n",
      "Gradient for encoder.encoder.3.weight: 0.01781451888382435\n",
      "Gradient for encoder.encoder.3.bias: 1.592213305645629e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.003123409580439329\n",
      "Gradient for encoder.encoder.4.bias: 0.002903836779296398\n",
      "Gradient for encoder.mean.weight: 0.04225988686084747\n",
      "Gradient for encoder.mean.bias: 0.002180627780035138\n",
      "Gradient for encoder.log_var.weight: 0.026967842131853104\n",
      "Gradient for encoder.log_var.bias: 0.0012058019638061523\n",
      "Gradient for decoder.decoder.0.weight: 0.00903908722102642\n",
      "Gradient for decoder.decoder.0.bias: 7.221467868134823e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.00045111944200471044\n",
      "Gradient for decoder.decoder.1.bias: 0.0003444124013185501\n",
      "Gradient for decoder.decoder.3.weight: 0.008436670526862144\n",
      "Gradient for decoder.decoder.3.bias: 6.36145927601639e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0003983171482104808\n",
      "Gradient for decoder.decoder.4.bias: 0.0004401776532176882\n",
      "Gradient for decoder.decoder.6.weight: 0.000412641151342541\n",
      "Gradient for decoder.decoder.6.bias: 2.4174796635634266e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.012924769893288612\n",
      "Gradient for encoder.encoder.0.bias: 2.1118554821564217e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0008691217517480254\n",
      "Gradient for encoder.encoder.1.bias: 0.0006999052711762488\n",
      "Gradient for encoder.encoder.3.weight: 0.017108846455812454\n",
      "Gradient for encoder.encoder.3.bias: 1.6417568693416484e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.003249464323744178\n",
      "Gradient for encoder.encoder.4.bias: 0.003077190602198243\n",
      "Gradient for encoder.mean.weight: 0.04685031622648239\n",
      "Gradient for encoder.mean.bias: 0.0023195992689579725\n",
      "Gradient for encoder.log_var.weight: 0.022887270897626877\n",
      "Gradient for encoder.log_var.bias: 0.0012866780161857605\n",
      "Gradient for decoder.decoder.0.weight: 0.008141954429447651\n",
      "Gradient for decoder.decoder.0.bias: 7.495446624483648e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.00040790459024719894\n",
      "Gradient for decoder.decoder.1.bias: 0.0003190821735188365\n",
      "Gradient for decoder.decoder.3.weight: 0.007503487169742584\n",
      "Gradient for decoder.decoder.3.bias: 7.255245015880263e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00040446571074426174\n",
      "Gradient for decoder.decoder.4.bias: 0.0004766788042616099\n",
      "Gradient for decoder.decoder.6.weight: 0.00044612062629312277\n",
      "Gradient for decoder.decoder.6.bias: 3.4864253393607214e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.007086665369570255\n",
      "Gradient for encoder.encoder.0.bias: 1.1227747030717605e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0008376454934477806\n",
      "Gradient for encoder.encoder.1.bias: 0.0007438008324243128\n",
      "Gradient for encoder.encoder.3.weight: 0.01825549826025963\n",
      "Gradient for encoder.encoder.3.bias: 1.6092310817228395e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.005421173293143511\n",
      "Gradient for encoder.encoder.4.bias: 0.0038898014463484287\n",
      "Gradient for encoder.mean.weight: 0.07495655119419098\n",
      "Gradient for encoder.mean.bias: 0.002779497066512704\n",
      "Gradient for encoder.log_var.weight: 0.03970015421509743\n",
      "Gradient for encoder.log_var.bias: 0.0015970012173056602\n",
      "Gradient for decoder.decoder.0.weight: 0.01307464949786663\n",
      "Gradient for decoder.decoder.0.bias: 1.114107833766198e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0006545509677380323\n",
      "Gradient for decoder.decoder.1.bias: 0.0005555967218242586\n",
      "Gradient for decoder.decoder.3.weight: 0.011985993944108486\n",
      "Gradient for decoder.decoder.3.bias: 1.1377275510593421e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0005736913299188018\n",
      "Gradient for decoder.decoder.4.bias: 0.0006408512126654387\n",
      "Gradient for decoder.decoder.6.weight: 0.0004943723906762898\n",
      "Gradient for decoder.decoder.6.bias: 3.1902432965580374e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.00844447873532772\n",
      "Gradient for encoder.encoder.0.bias: 1.3461370039491438e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0006810081540606916\n",
      "Gradient for encoder.encoder.1.bias: 0.0006540789036080241\n",
      "Gradient for encoder.encoder.3.weight: 0.014495140872895718\n",
      "Gradient for encoder.encoder.3.bias: 1.5890760929337944e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.003609943436458707\n",
      "Gradient for encoder.encoder.4.bias: 0.0034211683087050915\n",
      "Gradient for encoder.mean.weight: 0.0520951971411705\n",
      "Gradient for encoder.mean.bias: 0.002223544055595994\n",
      "Gradient for encoder.log_var.weight: 0.028954993933439255\n",
      "Gradient for encoder.log_var.bias: 0.001239464501850307\n",
      "Gradient for decoder.decoder.0.weight: 0.01131481770426035\n",
      "Gradient for decoder.decoder.0.bias: 9.990227395340057e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005665035569109023\n",
      "Gradient for decoder.decoder.1.bias: 0.0004520050424616784\n",
      "Gradient for decoder.decoder.3.weight: 0.010709483176469803\n",
      "Gradient for decoder.decoder.3.bias: 8.849861121706937e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00040051693213172257\n",
      "Gradient for decoder.decoder.4.bias: 0.00034816659172065556\n",
      "Gradient for decoder.decoder.6.weight: 0.000430283515015617\n",
      "Gradient for decoder.decoder.6.bias: 2.1446263417601585e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.006246601231396198\n",
      "Gradient for encoder.encoder.0.bias: 9.907799407293805e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.000737783033400774\n",
      "Gradient for encoder.encoder.1.bias: 0.0007321782177314162\n",
      "Gradient for encoder.encoder.3.weight: 0.015612920746207237\n",
      "Gradient for encoder.encoder.3.bias: 1.5716410117772028e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0037785503081977367\n",
      "Gradient for encoder.encoder.4.bias: 0.003350258804857731\n",
      "Gradient for encoder.mean.weight: 0.051546476781368256\n",
      "Gradient for encoder.mean.bias: 0.0025021452456712723\n",
      "Gradient for encoder.log_var.weight: 0.035154130309820175\n",
      "Gradient for encoder.log_var.bias: 0.0015667590778321028\n",
      "Gradient for decoder.decoder.0.weight: 0.014356494881212711\n",
      "Gradient for decoder.decoder.0.bias: 1.1317569104107861e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0007137514767237008\n",
      "Gradient for decoder.decoder.1.bias: 0.000582639710046351\n",
      "Gradient for decoder.decoder.3.weight: 0.013305255211889744\n",
      "Gradient for decoder.decoder.3.bias: 1.1132176430672658e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0006368336034938693\n",
      "Gradient for decoder.decoder.4.bias: 0.0006435761461034417\n",
      "Gradient for decoder.decoder.6.weight: 0.0005325552774593234\n",
      "Gradient for decoder.decoder.6.bias: 3.581984856282361e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.009034398011863232\n",
      "Gradient for encoder.encoder.0.bias: 1.3258910462610185e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0005826476844958961\n",
      "Gradient for encoder.encoder.1.bias: 0.0006798621616326272\n",
      "Gradient for encoder.encoder.3.weight: 0.012475435622036457\n",
      "Gradient for encoder.encoder.3.bias: 1.6731273311254569e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.004593918565660715\n",
      "Gradient for encoder.encoder.4.bias: 0.0032262529712170362\n",
      "Gradient for encoder.mean.weight: 0.05998215451836586\n",
      "Gradient for encoder.mean.bias: 0.0019274496007710695\n",
      "Gradient for encoder.log_var.weight: 0.03984101861715317\n",
      "Gradient for encoder.log_var.bias: 0.0012657548068091273\n",
      "Gradient for decoder.decoder.0.weight: 0.01252824254333973\n",
      "Gradient for decoder.decoder.0.bias: 9.976141440715125e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005977059481665492\n",
      "Gradient for decoder.decoder.1.bias: 0.0004950639558956027\n",
      "Gradient for decoder.decoder.3.weight: 0.011374208144843578\n",
      "Gradient for decoder.decoder.3.bias: 9.138542700348751e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0004213706706650555\n",
      "Gradient for decoder.decoder.4.bias: 0.00040571161662228405\n",
      "Gradient for decoder.decoder.6.weight: 0.00044130143942311406\n",
      "Gradient for decoder.decoder.6.bias: 2.4869501430657692e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.030840648338198662\n",
      "Gradient for encoder.encoder.0.bias: 5.529476529431143e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0014125118032097816\n",
      "Gradient for encoder.encoder.1.bias: 0.0012142033083364367\n",
      "Gradient for encoder.encoder.3.weight: 0.030151963233947754\n",
      "Gradient for encoder.encoder.3.bias: 2.8447530442399227e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.006019240710884333\n",
      "Gradient for encoder.encoder.4.bias: 0.005917438771575689\n",
      "Gradient for encoder.mean.weight: 0.07249654829502106\n",
      "Gradient for encoder.mean.bias: 0.004554817918688059\n",
      "Gradient for encoder.log_var.weight: 0.04898162558674812\n",
      "Gradient for encoder.log_var.bias: 0.003123884554952383\n",
      "Gradient for decoder.decoder.0.weight: 0.03187435492873192\n",
      "Gradient for decoder.decoder.0.bias: 1.9001378248617584e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0013200807152315974\n",
      "Gradient for decoder.decoder.1.bias: 0.0011515337973833084\n",
      "Gradient for decoder.decoder.3.weight: 0.028440607711672783\n",
      "Gradient for decoder.decoder.3.bias: 2.23232127227746e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0009802529821172357\n",
      "Gradient for decoder.decoder.4.bias: 0.0009063288453035057\n",
      "Gradient for decoder.decoder.6.weight: 0.0011684912024065852\n",
      "Gradient for decoder.decoder.6.bias: 6.43161911284551e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/3, Train Loss: 0.0490, Val Loss: 0.2361\n",
      "Training VAE for class 5...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training VAE Epoch:  11%|█▏        | 9/79 [00:00<00:01, 35.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient for encoder.encoder.0.weight: 0.008920952677726746\n",
      "Gradient for encoder.encoder.0.bias: 1.4278155914537738e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0005787773989140987\n",
      "Gradient for encoder.encoder.1.bias: 0.0006422101869247854\n",
      "Gradient for encoder.encoder.3.weight: 0.012897576205432415\n",
      "Gradient for encoder.encoder.3.bias: 1.5747789183784278e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.004003886599093676\n",
      "Gradient for encoder.encoder.4.bias: 0.0028726537711918354\n",
      "Gradient for encoder.mean.weight: 0.055154409259557724\n",
      "Gradient for encoder.mean.bias: 0.0022591506130993366\n",
      "Gradient for encoder.log_var.weight: 0.030740689486265182\n",
      "Gradient for encoder.log_var.bias: 0.0013415240682661533\n",
      "Gradient for decoder.decoder.0.weight: 0.010938694700598717\n",
      "Gradient for decoder.decoder.0.bias: 9.029027525642164e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005666552460752428\n",
      "Gradient for decoder.decoder.1.bias: 0.00047400820767506957\n",
      "Gradient for decoder.decoder.3.weight: 0.010607501491904259\n",
      "Gradient for decoder.decoder.3.bias: 8.865084361042719e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0006479673902504146\n",
      "Gradient for decoder.decoder.4.bias: 0.0007278056000359356\n",
      "Gradient for decoder.decoder.6.weight: 0.0006597096216864884\n",
      "Gradient for decoder.decoder.6.bias: 5.4643045586999506e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.007772964425384998\n",
      "Gradient for encoder.encoder.0.bias: 1.1694773621728771e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0005677563021890819\n",
      "Gradient for encoder.encoder.1.bias: 0.0006585627561435103\n",
      "Gradient for encoder.encoder.3.weight: 0.012068923562765121\n",
      "Gradient for encoder.encoder.3.bias: 1.4069456710785744e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0035147282760590315\n",
      "Gradient for encoder.encoder.4.bias: 0.002371903508901596\n",
      "Gradient for encoder.mean.weight: 0.05533108860254288\n",
      "Gradient for encoder.mean.bias: 0.0019108428386971354\n",
      "Gradient for encoder.log_var.weight: 0.027850890532135963\n",
      "Gradient for encoder.log_var.bias: 0.001072428422048688\n",
      "Gradient for decoder.decoder.0.weight: 0.01349387876689434\n",
      "Gradient for decoder.decoder.0.bias: 1.172316965725173e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0006713854381814599\n",
      "Gradient for decoder.decoder.1.bias: 0.0005739493644796312\n",
      "Gradient for decoder.decoder.3.weight: 0.012182687409222126\n",
      "Gradient for decoder.decoder.3.bias: 1.3631089312848843e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0009332625777460635\n",
      "Gradient for decoder.decoder.4.bias: 0.0011302611092105508\n",
      "Gradient for decoder.decoder.6.weight: 0.0007165747229009867\n",
      "Gradient for decoder.decoder.6.bias: 6.001007204758935e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.00903311651200056\n",
      "Gradient for encoder.encoder.0.bias: 1.7026857354607294e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.000679022807162255\n",
      "Gradient for encoder.encoder.1.bias: 0.0007639139075763524\n",
      "Gradient for encoder.encoder.3.weight: 0.014567773789167404\n",
      "Gradient for encoder.encoder.3.bias: 2.1218654611132592e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0043274881318211555\n",
      "Gradient for encoder.encoder.4.bias: 0.004250938538461924\n",
      "Gradient for encoder.mean.weight: 0.06053702160716057\n",
      "Gradient for encoder.mean.bias: 0.0031791594810783863\n",
      "Gradient for encoder.log_var.weight: 0.03017660602927208\n",
      "Gradient for encoder.log_var.bias: 0.0018373464699834585\n",
      "Gradient for decoder.decoder.0.weight: 0.01098228245973587\n",
      "Gradient for decoder.decoder.0.bias: 9.716575460894106e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005342144868336618\n",
      "Gradient for decoder.decoder.1.bias: 0.0004399060271680355\n",
      "Gradient for decoder.decoder.3.weight: 0.010556752793490887\n",
      "Gradient for decoder.decoder.3.bias: 1.3665919784688896e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0008943292195908725\n",
      "Gradient for decoder.decoder.4.bias: 0.0011129857739433646\n",
      "Gradient for decoder.decoder.6.weight: 0.0006933874683454633\n",
      "Gradient for decoder.decoder.6.bias: 5.90541421843227e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.010411305353045464\n",
      "Gradient for encoder.encoder.0.bias: 1.4952062157846946e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0006979394238442183\n",
      "Gradient for encoder.encoder.1.bias: 0.0006472754175774753\n",
      "Gradient for encoder.encoder.3.weight: 0.015216118656098843\n",
      "Gradient for encoder.encoder.3.bias: 1.7311105326989207e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.00403948500752449\n",
      "Gradient for encoder.encoder.4.bias: 0.0030019197147339582\n",
      "Gradient for encoder.mean.weight: 0.05653229355812073\n",
      "Gradient for encoder.mean.bias: 0.0020547597669065\n",
      "Gradient for encoder.log_var.weight: 0.028987428173422813\n",
      "Gradient for encoder.log_var.bias: 0.0012500149896368384\n",
      "Gradient for decoder.decoder.0.weight: 0.012737352401018143\n",
      "Gradient for decoder.decoder.0.bias: 1.0002783323859177e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0006351863848976791\n",
      "Gradient for decoder.decoder.1.bias: 0.0005275264848023653\n",
      "Gradient for decoder.decoder.3.weight: 0.01257994119077921\n",
      "Gradient for decoder.decoder.3.bias: 1.6482430698072648e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0012078705476596951\n",
      "Gradient for decoder.decoder.4.bias: 0.001482093590311706\n",
      "Gradient for decoder.decoder.6.weight: 0.0008260724134743214\n",
      "Gradient for decoder.decoder.6.bias: 7.125871343305334e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.00810288917273283\n",
      "Gradient for encoder.encoder.0.bias: 1.2179158723202299e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.000681886391248554\n",
      "Gradient for encoder.encoder.1.bias: 0.0007052149740047753\n",
      "Gradient for encoder.encoder.3.weight: 0.014751406386494637\n",
      "Gradient for encoder.encoder.3.bias: 1.8366402843028595e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.005254494026303291\n",
      "Gradient for encoder.encoder.4.bias: 0.004068578593432903\n",
      "Gradient for encoder.mean.weight: 0.07246138900518417\n",
      "Gradient for encoder.mean.bias: 0.0029299925081431866\n",
      "Gradient for encoder.log_var.weight: 0.038456324487924576\n",
      "Gradient for encoder.log_var.bias: 0.0016552031738683581\n",
      "Gradient for decoder.decoder.0.weight: 0.014291280880570412\n",
      "Gradient for decoder.decoder.0.bias: 1.1793775678281548e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0006469926447607577\n",
      "Gradient for decoder.decoder.1.bias: 0.0005695138825103641\n",
      "Gradient for decoder.decoder.3.weight: 0.01351785846054554\n",
      "Gradient for decoder.decoder.3.bias: 1.7985811451293188e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0012450877111405134\n",
      "Gradient for decoder.decoder.4.bias: 0.0015439304988831282\n",
      "Gradient for decoder.decoder.6.weight: 0.0008094081422314048\n",
      "Gradient for decoder.decoder.6.bias: 6.993003626121208e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.008567897602915764\n",
      "Gradient for encoder.encoder.0.bias: 1.298088286166843e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0005716436426155269\n",
      "Gradient for encoder.encoder.1.bias: 0.0005977263208478689\n",
      "Gradient for encoder.encoder.3.weight: 0.012329299002885818\n",
      "Gradient for encoder.encoder.3.bias: 1.5510735751345095e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0034579625353217125\n",
      "Gradient for encoder.encoder.4.bias: 0.0030770667362958193\n",
      "Gradient for encoder.mean.weight: 0.0471944697201252\n",
      "Gradient for encoder.mean.bias: 0.0024634695146232843\n",
      "Gradient for encoder.log_var.weight: 0.029891086742281914\n",
      "Gradient for encoder.log_var.bias: 0.0014935758663341403\n",
      "Gradient for decoder.decoder.0.weight: 0.012075649574398994\n",
      "Gradient for decoder.decoder.0.bias: 1.1207717393046934e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.000580935797188431\n",
      "Gradient for decoder.decoder.1.bias: 0.0005545695894397795\n",
      "Gradient for decoder.decoder.3.weight: 0.011869526468217373\n",
      "Gradient for decoder.decoder.3.bias: 1.3521127273374844e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.001023224089294672\n",
      "Gradient for decoder.decoder.4.bias: 0.0012908023782074451\n",
      "Gradient for decoder.decoder.6.weight: 0.0007229293114505708\n",
      "Gradient for decoder.decoder.6.bias: 6.209824641700834e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.011024338193237782\n",
      "Gradient for encoder.encoder.0.bias: 1.7430735674284215e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0006369123584590852\n",
      "Gradient for encoder.encoder.1.bias: 0.0007688410114496946\n",
      "Gradient for encoder.encoder.3.weight: 0.014368178322911263\n",
      "Gradient for encoder.encoder.3.bias: 1.5994607027725039e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.003674723906442523\n",
      "Gradient for encoder.encoder.4.bias: 0.0030481060966849327\n",
      "Gradient for encoder.mean.weight: 0.04725467041134834\n",
      "Gradient for encoder.mean.bias: 0.0022371478844434023\n",
      "Gradient for encoder.log_var.weight: 0.034841738641262054\n",
      "Gradient for encoder.log_var.bias: 0.001298998249694705\n",
      "Gradient for decoder.decoder.0.weight: 0.010397822596132755\n",
      "Gradient for decoder.decoder.0.bias: 8.790398964286794e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0004878580220974982\n",
      "Gradient for decoder.decoder.1.bias: 0.00040045386413112283\n",
      "Gradient for decoder.decoder.3.weight: 0.009631861932575703\n",
      "Gradient for decoder.decoder.3.bias: 8.778840154821665e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0007015165174379945\n",
      "Gradient for decoder.decoder.4.bias: 0.0008090377668850124\n",
      "Gradient for decoder.decoder.6.weight: 0.0006454575923271477\n",
      "Gradient for decoder.decoder.6.bias: 5.121023059473373e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.012491478584706783\n",
      "Gradient for encoder.encoder.0.bias: 2.069210254529441e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.000767888268455863\n",
      "Gradient for encoder.encoder.1.bias: 0.0006955366116017103\n",
      "Gradient for encoder.encoder.3.weight: 0.016275253146886826\n",
      "Gradient for encoder.encoder.3.bias: 1.9019939789810536e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0037532965652644634\n",
      "Gradient for encoder.encoder.4.bias: 0.004066526889801025\n",
      "Gradient for encoder.mean.weight: 0.05397937074303627\n",
      "Gradient for encoder.mean.bias: 0.0029646554030478\n",
      "Gradient for encoder.log_var.weight: 0.02409026026725769\n",
      "Gradient for encoder.log_var.bias: 0.0015594513388350606\n",
      "Gradient for decoder.decoder.0.weight: 0.009897449985146523\n",
      "Gradient for decoder.decoder.0.bias: 8.579756349824663e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005162230227142572\n",
      "Gradient for decoder.decoder.1.bias: 0.00041145714931190014\n",
      "Gradient for decoder.decoder.3.weight: 0.009217128157615662\n",
      "Gradient for decoder.decoder.3.bias: 1.163916740765103e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0008524589939042926\n",
      "Gradient for decoder.decoder.4.bias: 0.0010170884197577834\n",
      "Gradient for decoder.decoder.6.weight: 0.0008000039961189032\n",
      "Gradient for decoder.decoder.6.bias: 7.082570664351806e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.0069027007557451725\n",
      "Gradient for encoder.encoder.0.bias: 1.1486309299535424e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0006273253820836544\n",
      "Gradient for encoder.encoder.1.bias: 0.0007525442633777857\n",
      "Gradient for encoder.encoder.3.weight: 0.013659561052918434\n",
      "Gradient for encoder.encoder.3.bias: 1.312931846575438e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.004168279003351927\n",
      "Gradient for encoder.encoder.4.bias: 0.002485626144334674\n",
      "Gradient for encoder.mean.weight: 0.06335894018411636\n",
      "Gradient for encoder.mean.bias: 0.001907959464006126\n",
      "Gradient for encoder.log_var.weight: 0.029035573825240135\n",
      "Gradient for encoder.log_var.bias: 0.0011709367390722036\n",
      "Gradient for decoder.decoder.0.weight: 0.013900485821068287\n",
      "Gradient for decoder.decoder.0.bias: 1.2471861043916732e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0006614627200178802\n",
      "Gradient for decoder.decoder.1.bias: 0.0005733535508625209\n",
      "Gradient for decoder.decoder.3.weight: 0.01323765330016613\n",
      "Gradient for decoder.decoder.3.bias: 1.829752183102329e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0012889818754047155\n",
      "Gradient for decoder.decoder.4.bias: 0.0016048566903918982\n",
      "Gradient for decoder.decoder.6.weight: 0.0008697359589859843\n",
      "Gradient for decoder.decoder.6.bias: 7.686477329116315e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.010005254298448563\n",
      "Gradient for encoder.encoder.0.bias: 1.645609690181793e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0007593439077027142\n",
      "Gradient for encoder.encoder.1.bias: 0.0008172259549610317\n",
      "Gradient for encoder.encoder.3.weight: 0.016550062224268913\n",
      "Gradient for encoder.encoder.3.bias: 1.4042841889327917e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.004298133309930563\n",
      "Gradient for encoder.encoder.4.bias: 0.0026049320586025715\n",
      "Gradient for encoder.mean.weight: 0.06209615617990494\n",
      "Gradient for encoder.mean.bias: 0.001978300977498293\n",
      "Gradient for encoder.log_var.weight: 0.03216115012764931\n",
      "Gradient for encoder.log_var.bias: 0.0012100855819880962\n",
      "Gradient for decoder.decoder.0.weight: 0.010562991723418236\n",
      "Gradient for decoder.decoder.0.bias: 8.863507844347751e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.000553739897441119\n",
      "Gradient for decoder.decoder.1.bias: 0.00046266670688055456\n",
      "Gradient for decoder.decoder.3.weight: 0.010327804833650589\n",
      "Gradient for decoder.decoder.3.bias: 1.1117757409140339e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0008450601599179208\n",
      "Gradient for decoder.decoder.4.bias: 0.0010484970407560468\n",
      "Gradient for decoder.decoder.6.weight: 0.0007197513477876782\n",
      "Gradient for decoder.decoder.6.bias: 6.091816976550035e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.00929719116538763\n",
      "Gradient for encoder.encoder.0.bias: 1.526034160148626e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0005707697127945721\n",
      "Gradient for encoder.encoder.1.bias: 0.0006109319510869682\n",
      "Gradient for encoder.encoder.3.weight: 0.01287199929356575\n",
      "Gradient for encoder.encoder.3.bias: 1.7076792757642067e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.003014808986335993\n",
      "Gradient for encoder.encoder.4.bias: 0.0031562205404043198\n",
      "Gradient for encoder.mean.weight: 0.04310845583677292\n",
      "Gradient for encoder.mean.bias: 0.00247711269184947\n",
      "Gradient for encoder.log_var.weight: 0.02528618648648262\n",
      "Gradient for encoder.log_var.bias: 0.0015131162945181131\n",
      "Gradient for decoder.decoder.0.weight: 0.010120107792317867\n",
      "Gradient for decoder.decoder.0.bias: 8.828925091020068e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005518307443708181\n",
      "Gradient for decoder.decoder.1.bias: 0.0004578326770570129\n",
      "Gradient for decoder.decoder.3.weight: 0.009635323658585548\n",
      "Gradient for decoder.decoder.3.bias: 1.3136804144497916e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0010450005065649748\n",
      "Gradient for decoder.decoder.4.bias: 0.0012930396478623152\n",
      "Gradient for decoder.decoder.6.weight: 0.000744720222428441\n",
      "Gradient for decoder.decoder.6.bias: 6.289281736826524e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.007797385100275278\n",
      "Gradient for encoder.encoder.0.bias: 1.1744091810150792e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0006922637112438679\n",
      "Gradient for encoder.encoder.1.bias: 0.0008832565508782864\n",
      "Gradient for encoder.encoder.3.weight: 0.015269989147782326\n",
      "Gradient for encoder.encoder.3.bias: 1.9368597004021382e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0038960371166467667\n",
      "Gradient for encoder.encoder.4.bias: 0.005133563652634621\n",
      "Gradient for encoder.mean.weight: 0.0532083660364151\n",
      "Gradient for encoder.mean.bias: 0.0038927155546844006\n",
      "Gradient for encoder.log_var.weight: 0.033152688294649124\n",
      "Gradient for encoder.log_var.bias: 0.0025764170568436384\n",
      "Gradient for decoder.decoder.0.weight: 0.012386067770421505\n",
      "Gradient for decoder.decoder.0.bias: 9.195662981076325e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005946336896158755\n",
      "Gradient for decoder.decoder.1.bias: 0.00051182258175686\n",
      "Gradient for decoder.decoder.3.weight: 0.011618104763329029\n",
      "Gradient for decoder.decoder.3.bias: 1.4374661183591542e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0011882801773026586\n",
      "Gradient for decoder.decoder.4.bias: 0.0014503319980576634\n",
      "Gradient for decoder.decoder.6.weight: 0.0008721002377569675\n",
      "Gradient for decoder.decoder.6.bias: 7.602373807458207e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.008308877237141132\n",
      "Gradient for encoder.encoder.0.bias: 1.286641279629741e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0006816774257458746\n",
      "Gradient for encoder.encoder.1.bias: 0.0008864066330716014\n",
      "Gradient for encoder.encoder.3.weight: 0.015475377440452576\n",
      "Gradient for encoder.encoder.3.bias: 1.6413376213719744e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0034914191346615553\n",
      "Gradient for encoder.encoder.4.bias: 0.0035720441956073046\n",
      "Gradient for encoder.mean.weight: 0.049767713993787766\n",
      "Gradient for encoder.mean.bias: 0.0027613677084445953\n",
      "Gradient for encoder.log_var.weight: 0.031243178993463516\n",
      "Gradient for encoder.log_var.bias: 0.0018148095114156604\n",
      "Gradient for decoder.decoder.0.weight: 0.013564801774919033\n",
      "Gradient for decoder.decoder.0.bias: 1.135131086349439e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0006530322134494781\n",
      "Gradient for decoder.decoder.1.bias: 0.0005635535344481468\n",
      "Gradient for decoder.decoder.3.weight: 0.013311401940882206\n",
      "Gradient for decoder.decoder.3.bias: 1.3184879577021746e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0009000964928418398\n",
      "Gradient for decoder.decoder.4.bias: 0.0010748649947345257\n",
      "Gradient for decoder.decoder.6.weight: 0.000689951702952385\n",
      "Gradient for decoder.decoder.6.bias: 5.324414451024495e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.015140409581363201\n",
      "Gradient for encoder.encoder.0.bias: 2.3673544027880133e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0008078407263383269\n",
      "Gradient for encoder.encoder.1.bias: 0.0007153582409955561\n",
      "Gradient for encoder.encoder.3.weight: 0.0166675616055727\n",
      "Gradient for encoder.encoder.3.bias: 1.8601893636560618e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.003350998507812619\n",
      "Gradient for encoder.encoder.4.bias: 0.0027846177108585835\n",
      "Gradient for encoder.mean.weight: 0.04587341472506523\n",
      "Gradient for encoder.mean.bias: 0.0021304418332874775\n",
      "Gradient for encoder.log_var.weight: 0.02296745777130127\n",
      "Gradient for encoder.log_var.bias: 0.001290895277634263\n",
      "Gradient for decoder.decoder.0.weight: 0.009773317724466324\n",
      "Gradient for decoder.decoder.0.bias: 8.892905162261044e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.00048781343502923846\n",
      "Gradient for decoder.decoder.1.bias: 0.0003972846898250282\n",
      "Gradient for decoder.decoder.3.weight: 0.009281761012971401\n",
      "Gradient for decoder.decoder.3.bias: 9.147779062024242e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00044905877439305186\n",
      "Gradient for decoder.decoder.4.bias: 0.0004623407730832696\n",
      "Gradient for decoder.decoder.6.weight: 0.0006277120555751026\n",
      "Gradient for decoder.decoder.6.bias: 4.973425529897213e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.01470775343477726\n",
      "Gradient for encoder.encoder.0.bias: 2.275595857581525e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0009973589330911636\n",
      "Gradient for encoder.encoder.1.bias: 0.0011164686875417829\n",
      "Gradient for encoder.encoder.3.weight: 0.020685754716396332\n",
      "Gradient for encoder.encoder.3.bias: 1.93541752069315e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.004713480826467276\n",
      "Gradient for encoder.encoder.4.bias: 0.004064935725182295\n",
      "Gradient for encoder.mean.weight: 0.0644788146018982\n",
      "Gradient for encoder.mean.bias: 0.0029270979575812817\n",
      "Gradient for encoder.log_var.weight: 0.03336823731660843\n",
      "Gradient for encoder.log_var.bias: 0.002034297212958336\n",
      "Gradient for decoder.decoder.0.weight: 0.00927045103162527\n",
      "Gradient for decoder.decoder.0.bias: 8.409055396452203e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0004708232299890369\n",
      "Gradient for decoder.decoder.1.bias: 0.00036937513505108654\n",
      "Gradient for decoder.decoder.3.weight: 0.008884813636541367\n",
      "Gradient for decoder.decoder.3.bias: 9.179506460510467e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0005672919214703143\n",
      "Gradient for decoder.decoder.4.bias: 0.0006612520664930344\n",
      "Gradient for decoder.decoder.6.weight: 0.0006249287980608642\n",
      "Gradient for decoder.decoder.6.bias: 4.741447264677845e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.010199588723480701\n",
      "Gradient for encoder.encoder.0.bias: 1.9823750280201224e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0007493607117794454\n",
      "Gradient for encoder.encoder.1.bias: 0.0006282681715674698\n",
      "Gradient for encoder.encoder.3.weight: 0.01660197786986828\n",
      "Gradient for encoder.encoder.3.bias: 1.7741033642160176e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.004343732725828886\n",
      "Gradient for encoder.encoder.4.bias: 0.004028144758194685\n",
      "Gradient for encoder.mean.weight: 0.058818086981773376\n",
      "Gradient for encoder.mean.bias: 0.0027682154905050993\n",
      "Gradient for encoder.log_var.weight: 0.034932296723127365\n",
      "Gradient for encoder.log_var.bias: 0.0015617837198078632\n",
      "Gradient for decoder.decoder.0.weight: 0.009148940443992615\n",
      "Gradient for decoder.decoder.0.bias: 8.096067566354392e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.000457790243672207\n",
      "Gradient for decoder.decoder.1.bias: 0.00038654450327157974\n",
      "Gradient for decoder.decoder.3.weight: 0.00886120181530714\n",
      "Gradient for decoder.decoder.3.bias: 8.80681985671039e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0005080602131783962\n",
      "Gradient for decoder.decoder.4.bias: 0.0005729369004257023\n",
      "Gradient for decoder.decoder.6.weight: 0.0006393409566953778\n",
      "Gradient for decoder.decoder.6.bias: 5.0278504204470664e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training VAE Epoch:  32%|███▏      | 25/79 [00:00<00:00, 60.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient for encoder.encoder.0.weight: 0.008932330645620823\n",
      "Gradient for encoder.encoder.0.bias: 1.4383708633880499e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0006598631734959781\n",
      "Gradient for encoder.encoder.1.bias: 0.0005809045396745205\n",
      "Gradient for encoder.encoder.3.weight: 0.013923556543886662\n",
      "Gradient for encoder.encoder.3.bias: 1.51119824987056e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0034831862431019545\n",
      "Gradient for encoder.encoder.4.bias: 0.0030166790820658207\n",
      "Gradient for encoder.mean.weight: 0.047428812831640244\n",
      "Gradient for encoder.mean.bias: 0.0025558448396623135\n",
      "Gradient for encoder.log_var.weight: 0.02836957573890686\n",
      "Gradient for encoder.log_var.bias: 0.00172551185823977\n",
      "Gradient for decoder.decoder.0.weight: 0.011826767586171627\n",
      "Gradient for decoder.decoder.0.bias: 1.0283048024195551e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0005784739041700959\n",
      "Gradient for decoder.decoder.1.bias: 0.00044376266305334866\n",
      "Gradient for decoder.decoder.3.weight: 0.010970622301101685\n",
      "Gradient for decoder.decoder.3.bias: 1.3541587295939905e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0010453929426148534\n",
      "Gradient for decoder.decoder.4.bias: 0.0012985271168872714\n",
      "Gradient for decoder.decoder.6.weight: 0.0008929636678658426\n",
      "Gradient for decoder.decoder.6.bias: 8.019454253371805e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.0112379165366292\n",
      "Gradient for encoder.encoder.0.bias: 1.7948528080458104e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0008233704720623791\n",
      "Gradient for encoder.encoder.1.bias: 0.0007249996997416019\n",
      "Gradient for encoder.encoder.3.weight: 0.017988715320825577\n",
      "Gradient for encoder.encoder.3.bias: 1.571593410965022e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0031773580703884363\n",
      "Gradient for encoder.encoder.4.bias: 0.002635431010276079\n",
      "Gradient for encoder.mean.weight: 0.04388883337378502\n",
      "Gradient for encoder.mean.bias: 0.0021161669865250587\n",
      "Gradient for encoder.log_var.weight: 0.027941254898905754\n",
      "Gradient for encoder.log_var.bias: 0.0014992927899584174\n",
      "Gradient for decoder.decoder.0.weight: 0.011274016462266445\n",
      "Gradient for decoder.decoder.0.bias: 9.945564510838167e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005554220406338573\n",
      "Gradient for decoder.decoder.1.bias: 0.00041725256596691906\n",
      "Gradient for decoder.decoder.3.weight: 0.010562431998550892\n",
      "Gradient for decoder.decoder.3.bias: 1.1613131289944789e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0008802172378636897\n",
      "Gradient for decoder.decoder.4.bias: 0.0010419280733913183\n",
      "Gradient for decoder.decoder.6.weight: 0.0007255462696775794\n",
      "Gradient for decoder.decoder.6.bias: 5.7993183872895315e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.008872812613844872\n",
      "Gradient for encoder.encoder.0.bias: 1.4087539294826978e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0006527193472720683\n",
      "Gradient for encoder.encoder.1.bias: 0.000710469379555434\n",
      "Gradient for encoder.encoder.3.weight: 0.014411919750273228\n",
      "Gradient for encoder.encoder.3.bias: 1.372339464289496e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0029491521418094635\n",
      "Gradient for encoder.encoder.4.bias: 0.002190569182857871\n",
      "Gradient for encoder.mean.weight: 0.04540187865495682\n",
      "Gradient for encoder.mean.bias: 0.0016828268999233842\n",
      "Gradient for encoder.log_var.weight: 0.02276500128209591\n",
      "Gradient for encoder.log_var.bias: 0.0010560904629528522\n",
      "Gradient for decoder.decoder.0.weight: 0.012267492711544037\n",
      "Gradient for decoder.decoder.0.bias: 9.577318105247201e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0006066096248105168\n",
      "Gradient for decoder.decoder.1.bias: 0.0005280197947286069\n",
      "Gradient for decoder.decoder.3.weight: 0.011958747170865536\n",
      "Gradient for decoder.decoder.3.bias: 1.161615248435055e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0007697369437664747\n",
      "Gradient for decoder.decoder.4.bias: 0.000944008759688586\n",
      "Gradient for decoder.decoder.6.weight: 0.0007190078031271696\n",
      "Gradient for decoder.decoder.6.bias: 5.804877946502529e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.009184150025248528\n",
      "Gradient for encoder.encoder.0.bias: 1.4097203439311645e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0006292109610512853\n",
      "Gradient for encoder.encoder.1.bias: 0.0006146083469502628\n",
      "Gradient for encoder.encoder.3.weight: 0.013653147034347057\n",
      "Gradient for encoder.encoder.3.bias: 1.6222251320030523e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.003417010884732008\n",
      "Gradient for encoder.encoder.4.bias: 0.002778017660602927\n",
      "Gradient for encoder.mean.weight: 0.04610736295580864\n",
      "Gradient for encoder.mean.bias: 0.0022416096180677414\n",
      "Gradient for encoder.log_var.weight: 0.023425085470080376\n",
      "Gradient for encoder.log_var.bias: 0.0013029570691287518\n",
      "Gradient for decoder.decoder.0.weight: 0.011557762511074543\n",
      "Gradient for decoder.decoder.0.bias: 1.0118449828011578e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0006093928241170943\n",
      "Gradient for decoder.decoder.1.bias: 0.0005008236621506512\n",
      "Gradient for decoder.decoder.3.weight: 0.011759578250348568\n",
      "Gradient for decoder.decoder.3.bias: 1.2218125122753776e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0008174244430847466\n",
      "Gradient for decoder.decoder.4.bias: 0.0009810643969103694\n",
      "Gradient for decoder.decoder.6.weight: 0.0006737696239724755\n",
      "Gradient for decoder.decoder.6.bias: 4.8181667807511985e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.009324201382696629\n",
      "Gradient for encoder.encoder.0.bias: 1.6108968325934114e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0006542917108163238\n",
      "Gradient for encoder.encoder.1.bias: 0.0006633431185036898\n",
      "Gradient for encoder.encoder.3.weight: 0.01432847697287798\n",
      "Gradient for encoder.encoder.3.bias: 1.368038182736342e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0026554656215012074\n",
      "Gradient for encoder.encoder.4.bias: 0.002545042894780636\n",
      "Gradient for encoder.mean.weight: 0.03824540600180626\n",
      "Gradient for encoder.mean.bias: 0.0021899351850152016\n",
      "Gradient for encoder.log_var.weight: 0.022746631875634193\n",
      "Gradient for encoder.log_var.bias: 0.0014989178162068129\n",
      "Gradient for decoder.decoder.0.weight: 0.009739646688103676\n",
      "Gradient for decoder.decoder.0.bias: 8.965596320908986e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0004943609819747508\n",
      "Gradient for decoder.decoder.1.bias: 0.00040034393896348774\n",
      "Gradient for decoder.decoder.3.weight: 0.009201026521623135\n",
      "Gradient for decoder.decoder.3.bias: 8.849634913765669e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0004921797662973404\n",
      "Gradient for decoder.decoder.4.bias: 0.0005639913724735379\n",
      "Gradient for decoder.decoder.6.weight: 0.0005678408779203892\n",
      "Gradient for decoder.decoder.6.bias: 3.711981844389811e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.009956208989024162\n",
      "Gradient for encoder.encoder.0.bias: 1.687488516977087e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0007269051857292652\n",
      "Gradient for encoder.encoder.1.bias: 0.0008888589800335467\n",
      "Gradient for encoder.encoder.3.weight: 0.015496497042477131\n",
      "Gradient for encoder.encoder.3.bias: 1.559268408835024e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0037585643585771322\n",
      "Gradient for encoder.encoder.4.bias: 0.0029730310197919607\n",
      "Gradient for encoder.mean.weight: 0.05388486385345459\n",
      "Gradient for encoder.mean.bias: 0.0024500619620084763\n",
      "Gradient for encoder.log_var.weight: 0.026866573840379715\n",
      "Gradient for encoder.log_var.bias: 0.0015062671154737473\n",
      "Gradient for decoder.decoder.0.weight: 0.010507365688681602\n",
      "Gradient for decoder.decoder.0.bias: 9.463184402758174e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005170308868400753\n",
      "Gradient for decoder.decoder.1.bias: 0.0004242222639732063\n",
      "Gradient for decoder.decoder.3.weight: 0.010051405988633633\n",
      "Gradient for decoder.decoder.3.bias: 8.450603411480628e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00046614345046691597\n",
      "Gradient for decoder.decoder.4.bias: 0.0004840759211219847\n",
      "Gradient for decoder.decoder.6.weight: 0.0006103752530179918\n",
      "Gradient for decoder.decoder.6.bias: 4.0451177483191714e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.006401461083441973\n",
      "Gradient for encoder.encoder.0.bias: 9.940175418887698e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.0005736787570640445\n",
      "Gradient for encoder.encoder.1.bias: 0.000688185216858983\n",
      "Gradient for encoder.encoder.3.weight: 0.013113505207002163\n",
      "Gradient for encoder.encoder.3.bias: 1.2917091007924597e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0035309032537043095\n",
      "Gradient for encoder.encoder.4.bias: 0.0024315700866281986\n",
      "Gradient for encoder.mean.weight: 0.04958892613649368\n",
      "Gradient for encoder.mean.bias: 0.001817940385080874\n",
      "Gradient for encoder.log_var.weight: 0.027547284960746765\n",
      "Gradient for encoder.log_var.bias: 0.001148745883256197\n",
      "Gradient for decoder.decoder.0.weight: 0.014103533700108528\n",
      "Gradient for decoder.decoder.0.bias: 1.1329633758938584e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0007239871192723513\n",
      "Gradient for decoder.decoder.1.bias: 0.0005985556053929031\n",
      "Gradient for decoder.decoder.3.weight: 0.012902234680950642\n",
      "Gradient for decoder.decoder.3.bias: 1.3311156343842612e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0008469927706755698\n",
      "Gradient for decoder.decoder.4.bias: 0.0009896602714434266\n",
      "Gradient for decoder.decoder.6.weight: 0.0006856909021735191\n",
      "Gradient for decoder.decoder.6.bias: 4.8629677621647716e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.006326983217149973\n",
      "Gradient for encoder.encoder.0.bias: 1.0467237319955469e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0005762299406342208\n",
      "Gradient for encoder.encoder.1.bias: 0.0005939622642472386\n",
      "Gradient for encoder.encoder.3.weight: 0.012583348900079727\n",
      "Gradient for encoder.encoder.3.bias: 1.3036981216796306e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0027273495215922594\n",
      "Gradient for encoder.encoder.4.bias: 0.0024597959127277136\n",
      "Gradient for encoder.mean.weight: 0.040602490305900574\n",
      "Gradient for encoder.mean.bias: 0.00192504923325032\n",
      "Gradient for encoder.log_var.weight: 0.02413342334330082\n",
      "Gradient for encoder.log_var.bias: 0.001357349450699985\n",
      "Gradient for decoder.decoder.0.weight: 0.014264380559325218\n",
      "Gradient for decoder.decoder.0.bias: 1.1390768883678959e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0007502174121327698\n",
      "Gradient for decoder.decoder.1.bias: 0.000609803362749517\n",
      "Gradient for decoder.decoder.3.weight: 0.01382992509752512\n",
      "Gradient for decoder.decoder.3.bias: 1.5836915112643624e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0010799028677865863\n",
      "Gradient for decoder.decoder.4.bias: 0.0013079325435683131\n",
      "Gradient for decoder.decoder.6.weight: 0.0008128035115078092\n",
      "Gradient for decoder.decoder.6.bias: 6.691581074846908e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.007078528869897127\n",
      "Gradient for encoder.encoder.0.bias: 1.0819688027463581e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.000500617956276983\n",
      "Gradient for encoder.encoder.1.bias: 0.000496057968121022\n",
      "Gradient for encoder.encoder.3.weight: 0.010882285423576832\n",
      "Gradient for encoder.encoder.3.bias: 1.5363811611823763e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0029695541597902775\n",
      "Gradient for encoder.encoder.4.bias: 0.0029196885880082846\n",
      "Gradient for encoder.mean.weight: 0.039292898029088974\n",
      "Gradient for encoder.mean.bias: 0.0018422302091494203\n",
      "Gradient for encoder.log_var.weight: 0.023322293534874916\n",
      "Gradient for encoder.log_var.bias: 0.0012602645438164473\n",
      "Gradient for decoder.decoder.0.weight: 0.01405698899179697\n",
      "Gradient for decoder.decoder.0.bias: 1.206641592199631e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0006967197405174375\n",
      "Gradient for decoder.decoder.1.bias: 0.0005362272495403886\n",
      "Gradient for decoder.decoder.3.weight: 0.013292409479618073\n",
      "Gradient for decoder.decoder.3.bias: 1.397049836926456e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0010470786364749074\n",
      "Gradient for decoder.decoder.4.bias: 0.0012483455939218402\n",
      "Gradient for decoder.decoder.6.weight: 0.0007849382818676531\n",
      "Gradient for decoder.decoder.6.bias: 6.193386798258871e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.008916342630982399\n",
      "Gradient for encoder.encoder.0.bias: 1.49090496892601e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0006203596713021398\n",
      "Gradient for encoder.encoder.1.bias: 0.0006384962471202016\n",
      "Gradient for encoder.encoder.3.weight: 0.013287604786455631\n",
      "Gradient for encoder.encoder.3.bias: 1.4071105391977312e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0029777162708342075\n",
      "Gradient for encoder.encoder.4.bias: 0.0021118768490850925\n",
      "Gradient for encoder.mean.weight: 0.042872171849012375\n",
      "Gradient for encoder.mean.bias: 0.0016749334754422307\n",
      "Gradient for encoder.log_var.weight: 0.020394375547766685\n",
      "Gradient for encoder.log_var.bias: 0.0011699526803568006\n",
      "Gradient for decoder.decoder.0.weight: 0.012221147306263447\n",
      "Gradient for decoder.decoder.0.bias: 1.0729756666494339e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0006261266535148025\n",
      "Gradient for decoder.decoder.1.bias: 0.0004808038065675646\n",
      "Gradient for decoder.decoder.3.weight: 0.011670427396893501\n",
      "Gradient for decoder.decoder.3.bias: 9.511370163695076e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0006344274734146893\n",
      "Gradient for decoder.decoder.4.bias: 0.0006648778216913342\n",
      "Gradient for decoder.decoder.6.weight: 0.0006384698790498078\n",
      "Gradient for decoder.decoder.6.bias: 4.143921614740975e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.010351549834012985\n",
      "Gradient for encoder.encoder.0.bias: 1.6747719530640914e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0006835884414613247\n",
      "Gradient for encoder.encoder.1.bias: 0.0005961687420494854\n",
      "Gradient for encoder.encoder.3.weight: 0.015503084287047386\n",
      "Gradient for encoder.encoder.3.bias: 1.5311253653838008e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.003973060287535191\n",
      "Gradient for encoder.encoder.4.bias: 0.0028102777432650328\n",
      "Gradient for encoder.mean.weight: 0.055267203599214554\n",
      "Gradient for encoder.mean.bias: 0.001799496472813189\n",
      "Gradient for encoder.log_var.weight: 0.02943224087357521\n",
      "Gradient for encoder.log_var.bias: 0.001376574975438416\n",
      "Gradient for decoder.decoder.0.weight: 0.01100307609885931\n",
      "Gradient for decoder.decoder.0.bias: 8.847752391849539e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005616105627268553\n",
      "Gradient for decoder.decoder.1.bias: 0.00046779291005805135\n",
      "Gradient for decoder.decoder.3.weight: 0.010690920986235142\n",
      "Gradient for decoder.decoder.3.bias: 1.1493699741960128e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0007193394703790545\n",
      "Gradient for decoder.decoder.4.bias: 0.0009003151790238917\n",
      "Gradient for decoder.decoder.6.weight: 0.0007161018438637257\n",
      "Gradient for decoder.decoder.6.bias: 5.67974457226228e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.008245427161455154\n",
      "Gradient for encoder.encoder.0.bias: 1.699716756231595e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0008300938061438501\n",
      "Gradient for encoder.encoder.1.bias: 0.0009259426733478904\n",
      "Gradient for encoder.encoder.3.weight: 0.018208391964435577\n",
      "Gradient for encoder.encoder.3.bias: 1.8788427758043014e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.004597513470798731\n",
      "Gradient for encoder.encoder.4.bias: 0.004548745229840279\n",
      "Gradient for encoder.mean.weight: 0.06513863801956177\n",
      "Gradient for encoder.mean.bias: 0.003474841360002756\n",
      "Gradient for encoder.log_var.weight: 0.03832396864891052\n",
      "Gradient for encoder.log_var.bias: 0.002567709656432271\n",
      "Gradient for decoder.decoder.0.weight: 0.010664592497050762\n",
      "Gradient for decoder.decoder.0.bias: 9.99364202503017e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.000519025488756597\n",
      "Gradient for decoder.decoder.1.bias: 0.0004164718266110867\n",
      "Gradient for decoder.decoder.3.weight: 0.009808081202208996\n",
      "Gradient for decoder.decoder.3.bias: 9.091172953334947e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0003902451426256448\n",
      "Gradient for decoder.decoder.4.bias: 0.00036947414628230035\n",
      "Gradient for decoder.decoder.6.weight: 0.0005710168043151498\n",
      "Gradient for decoder.decoder.6.bias: 3.3633605198701844e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.008305717259645462\n",
      "Gradient for encoder.encoder.0.bias: 1.5579478679361713e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0005599138094112277\n",
      "Gradient for encoder.encoder.1.bias: 0.0005768825649283826\n",
      "Gradient for encoder.encoder.3.weight: 0.01201330590993166\n",
      "Gradient for encoder.encoder.3.bias: 1.2498294066354276e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.002446077298372984\n",
      "Gradient for encoder.encoder.4.bias: 0.0021054912358522415\n",
      "Gradient for encoder.mean.weight: 0.03563481196761131\n",
      "Gradient for encoder.mean.bias: 0.001834329916164279\n",
      "Gradient for encoder.log_var.weight: 0.020194372162222862\n",
      "Gradient for encoder.log_var.bias: 0.001076440792530775\n",
      "Gradient for decoder.decoder.0.weight: 0.009972389787435532\n",
      "Gradient for decoder.decoder.0.bias: 7.532042350932855e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005081931012682617\n",
      "Gradient for decoder.decoder.1.bias: 0.0003847530751954764\n",
      "Gradient for decoder.decoder.3.weight: 0.00981496274471283\n",
      "Gradient for decoder.decoder.3.bias: 7.011955599489639e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0003518711600918323\n",
      "Gradient for decoder.decoder.4.bias: 0.0003057960420846939\n",
      "Gradient for decoder.decoder.6.weight: 0.0005580692668445408\n",
      "Gradient for decoder.decoder.6.bias: 3.111384648946114e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.011395357549190521\n",
      "Gradient for encoder.encoder.0.bias: 1.9209691129451478e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0007578388322144747\n",
      "Gradient for encoder.encoder.1.bias: 0.0006549129029735923\n",
      "Gradient for encoder.encoder.3.weight: 0.016771387308835983\n",
      "Gradient for encoder.encoder.3.bias: 1.7622182879595272e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.003692113794386387\n",
      "Gradient for encoder.encoder.4.bias: 0.00365046551451087\n",
      "Gradient for encoder.mean.weight: 0.0501767136156559\n",
      "Gradient for encoder.mean.bias: 0.002969013061374426\n",
      "Gradient for encoder.log_var.weight: 0.02900860086083412\n",
      "Gradient for encoder.log_var.bias: 0.001675238716416061\n",
      "Gradient for decoder.decoder.0.weight: 0.010436832904815674\n",
      "Gradient for decoder.decoder.0.bias: 7.66849569955319e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005166172632016242\n",
      "Gradient for decoder.decoder.1.bias: 0.0003934120759367943\n",
      "Gradient for decoder.decoder.3.weight: 0.010203469544649124\n",
      "Gradient for decoder.decoder.3.bias: 8.412272961555445e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0005926497397013009\n",
      "Gradient for decoder.decoder.4.bias: 0.0006481814780272543\n",
      "Gradient for decoder.decoder.6.weight: 0.0006817557150498033\n",
      "Gradient for decoder.decoder.6.bias: 4.929361239192076e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.006432752590626478\n",
      "Gradient for encoder.encoder.0.bias: 9.807837701714117e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.0005691687692888081\n",
      "Gradient for encoder.encoder.1.bias: 0.0004768378275912255\n",
      "Gradient for encoder.encoder.3.weight: 0.012448100373148918\n",
      "Gradient for encoder.encoder.3.bias: 1.466130966631951e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.003889122512191534\n",
      "Gradient for encoder.encoder.4.bias: 0.0035196866374462843\n",
      "Gradient for encoder.mean.weight: 0.055494703352451324\n",
      "Gradient for encoder.mean.bias: 0.002428088802844286\n",
      "Gradient for encoder.log_var.weight: 0.029183927923440933\n",
      "Gradient for encoder.log_var.bias: 0.0013669467298313975\n",
      "Gradient for decoder.decoder.0.weight: 0.012610829435288906\n",
      "Gradient for decoder.decoder.0.bias: 1.093077503511175e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0006171927088871598\n",
      "Gradient for decoder.decoder.1.bias: 0.0005139279528521001\n",
      "Gradient for decoder.decoder.3.weight: 0.011467228643596172\n",
      "Gradient for decoder.decoder.3.bias: 9.511044035681593e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0005612742970697582\n",
      "Gradient for decoder.decoder.4.bias: 0.0005654966225847602\n",
      "Gradient for decoder.decoder.6.weight: 0.0006292758625932038\n",
      "Gradient for decoder.decoder.6.bias: 3.6150740925222635e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.010391419753432274\n",
      "Gradient for encoder.encoder.0.bias: 1.6297886651361893e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.000536447623744607\n",
      "Gradient for encoder.encoder.1.bias: 0.0005370671860873699\n",
      "Gradient for encoder.encoder.3.weight: 0.012494724243879318\n",
      "Gradient for encoder.encoder.3.bias: 1.7841118860051353e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0035610643681138754\n",
      "Gradient for encoder.encoder.4.bias: 0.003914946690201759\n",
      "Gradient for encoder.mean.weight: 0.04983353614807129\n",
      "Gradient for encoder.mean.bias: 0.0030040903948247433\n",
      "Gradient for encoder.log_var.weight: 0.03159313648939133\n",
      "Gradient for encoder.log_var.bias: 0.0020483643747866154\n",
      "Gradient for decoder.decoder.0.weight: 0.0107142124325037\n",
      "Gradient for decoder.decoder.0.bias: 9.237893089375504e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005378195201046765\n",
      "Gradient for decoder.decoder.1.bias: 0.000450706371339038\n",
      "Gradient for decoder.decoder.3.weight: 0.009926780126988888\n",
      "Gradient for decoder.decoder.3.bias: 8.777951282512575e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00044521709787659347\n",
      "Gradient for decoder.decoder.4.bias: 0.0004382351762615144\n",
      "Gradient for decoder.decoder.6.weight: 0.000571755925193429\n",
      "Gradient for decoder.decoder.6.bias: 3.299318632343784e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training VAE Epoch:  52%|█████▏    | 41/79 [00:00<00:00, 68.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient for encoder.encoder.0.weight: 0.008811800740659237\n",
      "Gradient for encoder.encoder.0.bias: 1.4610286938609995e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0005837450735270977\n",
      "Gradient for encoder.encoder.1.bias: 0.0006471422384493053\n",
      "Gradient for encoder.encoder.3.weight: 0.013730608858168125\n",
      "Gradient for encoder.encoder.3.bias: 1.415051825714997e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0028504948131740093\n",
      "Gradient for encoder.encoder.4.bias: 0.0024644171353429556\n",
      "Gradient for encoder.mean.weight: 0.040441934019327164\n",
      "Gradient for encoder.mean.bias: 0.0020273863337934017\n",
      "Gradient for encoder.log_var.weight: 0.022294968366622925\n",
      "Gradient for encoder.log_var.bias: 0.001126428716816008\n",
      "Gradient for decoder.decoder.0.weight: 0.012044415809214115\n",
      "Gradient for decoder.decoder.0.bias: 9.313200211025219e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0006062147440388799\n",
      "Gradient for decoder.decoder.1.bias: 0.0004805611970368773\n",
      "Gradient for decoder.decoder.3.weight: 0.0113358860835433\n",
      "Gradient for decoder.decoder.3.bias: 7.294144455105567e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00043452484533190727\n",
      "Gradient for decoder.decoder.4.bias: 0.0003930209204554558\n",
      "Gradient for decoder.decoder.6.weight: 0.0006228697602637112\n",
      "Gradient for decoder.decoder.6.bias: 3.9496389945270494e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.0064971609972417355\n",
      "Gradient for encoder.encoder.0.bias: 1.2478313521357975e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0007364911725744605\n",
      "Gradient for encoder.encoder.1.bias: 0.0008426649146713316\n",
      "Gradient for encoder.encoder.3.weight: 0.015806950628757477\n",
      "Gradient for encoder.encoder.3.bias: 1.604613109051911e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0039401366375386715\n",
      "Gradient for encoder.encoder.4.bias: 0.0031080227345228195\n",
      "Gradient for encoder.mean.weight: 0.055081602185964584\n",
      "Gradient for encoder.mean.bias: 0.0024916587863117456\n",
      "Gradient for encoder.log_var.weight: 0.030096296221017838\n",
      "Gradient for encoder.log_var.bias: 0.00165093585383147\n",
      "Gradient for decoder.decoder.0.weight: 0.014110458083450794\n",
      "Gradient for decoder.decoder.0.bias: 1.2003524563208856e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0007440254557877779\n",
      "Gradient for decoder.decoder.1.bias: 0.0005954094231128693\n",
      "Gradient for decoder.decoder.3.weight: 0.013867106288671494\n",
      "Gradient for decoder.decoder.3.bias: 1.2532126725250947e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0006993874558247626\n",
      "Gradient for decoder.decoder.4.bias: 0.0007911194115877151\n",
      "Gradient for decoder.decoder.6.weight: 0.0006454214453697205\n",
      "Gradient for decoder.decoder.6.bias: 4.076276673004031e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.007075498811900616\n",
      "Gradient for encoder.encoder.0.bias: 1.19723987668241e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.00047615484800189734\n",
      "Gradient for encoder.encoder.1.bias: 0.00047015107702463865\n",
      "Gradient for encoder.encoder.3.weight: 0.010325760580599308\n",
      "Gradient for encoder.encoder.3.bias: 1.3131297438295775e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0027969060465693474\n",
      "Gradient for encoder.encoder.4.bias: 0.0026651970110833645\n",
      "Gradient for encoder.mean.weight: 0.040336426347494125\n",
      "Gradient for encoder.mean.bias: 0.0021779441740363836\n",
      "Gradient for encoder.log_var.weight: 0.019129354506731033\n",
      "Gradient for encoder.log_var.bias: 0.001163606415502727\n",
      "Gradient for decoder.decoder.0.weight: 0.012907876633107662\n",
      "Gradient for decoder.decoder.0.bias: 1.1266049898539521e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0006671719602309167\n",
      "Gradient for decoder.decoder.1.bias: 0.0005118543049320579\n",
      "Gradient for decoder.decoder.3.weight: 0.012389103882014751\n",
      "Gradient for decoder.decoder.3.bias: 1.1013415179839114e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0005722524947486818\n",
      "Gradient for decoder.decoder.4.bias: 0.0006165667437016964\n",
      "Gradient for decoder.decoder.6.weight: 0.0006376588135026395\n",
      "Gradient for decoder.decoder.6.bias: 4.08830055675935e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.010588795877993107\n",
      "Gradient for encoder.encoder.0.bias: 1.648270409049246e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0006613046862185001\n",
      "Gradient for encoder.encoder.1.bias: 0.000688863277900964\n",
      "Gradient for encoder.encoder.3.weight: 0.014663049951195717\n",
      "Gradient for encoder.encoder.3.bias: 1.514474656794107e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0034292496275156736\n",
      "Gradient for encoder.encoder.4.bias: 0.002882992848753929\n",
      "Gradient for encoder.mean.weight: 0.04544585943222046\n",
      "Gradient for encoder.mean.bias: 0.0017699978780001402\n",
      "Gradient for encoder.log_var.weight: 0.026089899241924286\n",
      "Gradient for encoder.log_var.bias: 0.0011493893107399344\n",
      "Gradient for decoder.decoder.0.weight: 0.011051536537706852\n",
      "Gradient for decoder.decoder.0.bias: 8.808353352263154e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005301014753058553\n",
      "Gradient for decoder.decoder.1.bias: 0.0004526102857198566\n",
      "Gradient for decoder.decoder.3.weight: 0.010214870795607567\n",
      "Gradient for decoder.decoder.3.bias: 1.0723345128527129e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0007155230850912631\n",
      "Gradient for decoder.decoder.4.bias: 0.0008639671141281724\n",
      "Gradient for decoder.decoder.6.weight: 0.0007309154607355595\n",
      "Gradient for decoder.decoder.6.bias: 5.4468218877445906e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.008411125279963017\n",
      "Gradient for encoder.encoder.0.bias: 1.4567650905017437e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0006436477997340262\n",
      "Gradient for encoder.encoder.1.bias: 0.0006793855573050678\n",
      "Gradient for encoder.encoder.3.weight: 0.014508807100355625\n",
      "Gradient for encoder.encoder.3.bias: 1.6062691454710176e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.003731468692421913\n",
      "Gradient for encoder.encoder.4.bias: 0.00409933365881443\n",
      "Gradient for encoder.mean.weight: 0.05281258001923561\n",
      "Gradient for encoder.mean.bias: 0.0031463466584682465\n",
      "Gradient for encoder.log_var.weight: 0.029398461803793907\n",
      "Gradient for encoder.log_var.bias: 0.002004429465159774\n",
      "Gradient for decoder.decoder.0.weight: 0.01119059044867754\n",
      "Gradient for decoder.decoder.0.bias: 9.172668180568166e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005943931173533201\n",
      "Gradient for decoder.decoder.1.bias: 0.0004293113888707012\n",
      "Gradient for decoder.decoder.3.weight: 0.010675383731722832\n",
      "Gradient for decoder.decoder.3.bias: 7.809789620560892e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00039834826020523906\n",
      "Gradient for decoder.decoder.4.bias: 0.000333462463459\n",
      "Gradient for decoder.decoder.6.weight: 0.00061205611564219\n",
      "Gradient for decoder.decoder.6.bias: 3.461008964222856e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.013704396784305573\n",
      "Gradient for encoder.encoder.0.bias: 2.319166213238244e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0006865590112283826\n",
      "Gradient for encoder.encoder.1.bias: 0.0006474474794231355\n",
      "Gradient for encoder.encoder.3.weight: 0.015350352972745895\n",
      "Gradient for encoder.encoder.3.bias: 1.8385903910456136e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0034926501102745533\n",
      "Gradient for encoder.encoder.4.bias: 0.0030894216615706682\n",
      "Gradient for encoder.mean.weight: 0.047225866466760635\n",
      "Gradient for encoder.mean.bias: 0.001986537128686905\n",
      "Gradient for encoder.log_var.weight: 0.025808926671743393\n",
      "Gradient for encoder.log_var.bias: 0.0013092114822939038\n",
      "Gradient for decoder.decoder.0.weight: 0.008865554817020893\n",
      "Gradient for decoder.decoder.0.bias: 7.857627742913209e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.00044428309774957597\n",
      "Gradient for decoder.decoder.1.bias: 0.0003553781134542078\n",
      "Gradient for decoder.decoder.3.weight: 0.008455131202936172\n",
      "Gradient for decoder.decoder.3.bias: 8.025743264417073e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.000298753147944808\n",
      "Gradient for decoder.decoder.4.bias: 0.0002748871629592031\n",
      "Gradient for decoder.decoder.6.weight: 0.0006705388077534735\n",
      "Gradient for decoder.decoder.6.bias: 4.802472176379524e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.006638715043663979\n",
      "Gradient for encoder.encoder.0.bias: 1.1774396561914369e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.000546634488273412\n",
      "Gradient for encoder.encoder.1.bias: 0.0005726951640099287\n",
      "Gradient for encoder.encoder.3.weight: 0.012159908190369606\n",
      "Gradient for encoder.encoder.3.bias: 1.2542558658346081e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.002864179899916053\n",
      "Gradient for encoder.encoder.4.bias: 0.002422094577923417\n",
      "Gradient for encoder.mean.weight: 0.04174652323126793\n",
      "Gradient for encoder.mean.bias: 0.0019398692529648542\n",
      "Gradient for encoder.log_var.weight: 0.02251262590289116\n",
      "Gradient for encoder.log_var.bias: 0.0012815879890695214\n",
      "Gradient for decoder.decoder.0.weight: 0.012574094347655773\n",
      "Gradient for decoder.decoder.0.bias: 1.0505489533851886e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.000664018327370286\n",
      "Gradient for decoder.decoder.1.bias: 0.0005258878227323294\n",
      "Gradient for decoder.decoder.3.weight: 0.012305024079978466\n",
      "Gradient for decoder.decoder.3.bias: 9.38295968699876e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0005184332258068025\n",
      "Gradient for decoder.decoder.4.bias: 0.00047121153329499066\n",
      "Gradient for decoder.decoder.6.weight: 0.0006136143347248435\n",
      "Gradient for decoder.decoder.6.bias: 3.371085040271282e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.009404229000210762\n",
      "Gradient for encoder.encoder.0.bias: 1.4953925250860145e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0007401765906251967\n",
      "Gradient for encoder.encoder.1.bias: 0.0006978818564675748\n",
      "Gradient for encoder.encoder.3.weight: 0.015643302351236343\n",
      "Gradient for encoder.encoder.3.bias: 1.9408341600524182e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.004164120648056269\n",
      "Gradient for encoder.encoder.4.bias: 0.004622125998139381\n",
      "Gradient for encoder.mean.weight: 0.05526093766093254\n",
      "Gradient for encoder.mean.bias: 0.00341682112775743\n",
      "Gradient for encoder.log_var.weight: 0.03184547275304794\n",
      "Gradient for encoder.log_var.bias: 0.0018653490114957094\n",
      "Gradient for decoder.decoder.0.weight: 0.01104519609361887\n",
      "Gradient for decoder.decoder.0.bias: 8.836092968422804e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.000541267276275903\n",
      "Gradient for decoder.decoder.1.bias: 0.0004492078733164817\n",
      "Gradient for decoder.decoder.3.weight: 0.01008867658674717\n",
      "Gradient for decoder.decoder.3.bias: 7.911470784049968e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0003975900181103498\n",
      "Gradient for decoder.decoder.4.bias: 0.0003550850669853389\n",
      "Gradient for decoder.decoder.6.weight: 0.0006276313215494156\n",
      "Gradient for decoder.decoder.6.bias: 3.608785118558444e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.00622477987781167\n",
      "Gradient for encoder.encoder.0.bias: 1.1090807092162258e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.00044885705574415624\n",
      "Gradient for encoder.encoder.1.bias: 0.0004395256983116269\n",
      "Gradient for encoder.encoder.3.weight: 0.009703024290502071\n",
      "Gradient for encoder.encoder.3.bias: 1.3761124184608065e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0030163314659148455\n",
      "Gradient for encoder.encoder.4.bias: 0.0032828091643750668\n",
      "Gradient for encoder.mean.weight: 0.040770966559648514\n",
      "Gradient for encoder.mean.bias: 0.0024944799952208996\n",
      "Gradient for encoder.log_var.weight: 0.027747036889195442\n",
      "Gradient for encoder.log_var.bias: 0.0017475240165367723\n",
      "Gradient for decoder.decoder.0.weight: 0.012469141744077206\n",
      "Gradient for decoder.decoder.0.bias: 1.1414272998999664e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0006638357299380004\n",
      "Gradient for decoder.decoder.1.bias: 0.0005095486412756145\n",
      "Gradient for decoder.decoder.3.weight: 0.01157008670270443\n",
      "Gradient for decoder.decoder.3.bias: 1.1150030204687411e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0004179782990831882\n",
      "Gradient for decoder.decoder.4.bias: 0.00038305565249174833\n",
      "Gradient for decoder.decoder.6.weight: 0.0006378501420840621\n",
      "Gradient for decoder.decoder.6.bias: 3.932910112780519e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.011352100409567356\n",
      "Gradient for encoder.encoder.0.bias: 1.4944252432758098e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0005758798215538263\n",
      "Gradient for encoder.encoder.1.bias: 0.0006230557919479907\n",
      "Gradient for encoder.encoder.3.weight: 0.012639446184039116\n",
      "Gradient for encoder.encoder.3.bias: 1.3663024878152186e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0024870785418897867\n",
      "Gradient for encoder.encoder.4.bias: 0.0026469898875802755\n",
      "Gradient for encoder.mean.weight: 0.03425053134560585\n",
      "Gradient for encoder.mean.bias: 0.001999682979658246\n",
      "Gradient for encoder.log_var.weight: 0.021707553416490555\n",
      "Gradient for encoder.log_var.bias: 0.0013695507077500224\n",
      "Gradient for decoder.decoder.0.weight: 0.010827657766640186\n",
      "Gradient for decoder.decoder.0.bias: 9.693151836742686e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005692015984095633\n",
      "Gradient for decoder.decoder.1.bias: 0.00045272489660419524\n",
      "Gradient for decoder.decoder.3.weight: 0.010091888718307018\n",
      "Gradient for decoder.decoder.3.bias: 9.700665271061837e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0006293532205745578\n",
      "Gradient for decoder.decoder.4.bias: 0.0007180436514317989\n",
      "Gradient for decoder.decoder.6.weight: 0.0007512086885981262\n",
      "Gradient for decoder.decoder.6.bias: 5.4809843277325854e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.00882675964385271\n",
      "Gradient for encoder.encoder.0.bias: 1.655964081137551e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0005104686133563519\n",
      "Gradient for encoder.encoder.1.bias: 0.0005182831664569676\n",
      "Gradient for encoder.encoder.3.weight: 0.011167926713824272\n",
      "Gradient for encoder.encoder.3.bias: 1.224834123014773e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0024190028198063374\n",
      "Gradient for encoder.encoder.4.bias: 0.001868683029897511\n",
      "Gradient for encoder.mean.weight: 0.03257829323410988\n",
      "Gradient for encoder.mean.bias: 0.0013080385979264975\n",
      "Gradient for encoder.log_var.weight: 0.018346542492508888\n",
      "Gradient for encoder.log_var.bias: 0.0008953561773523688\n",
      "Gradient for decoder.decoder.0.weight: 0.009574019350111485\n",
      "Gradient for decoder.decoder.0.bias: 7.34824492920616e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0004976342897862196\n",
      "Gradient for decoder.decoder.1.bias: 0.0003990946861449629\n",
      "Gradient for decoder.decoder.3.weight: 0.008925060741603374\n",
      "Gradient for decoder.decoder.3.bias: 7.54450113493732e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00036667147651314735\n",
      "Gradient for decoder.decoder.4.bias: 0.00038428042898885906\n",
      "Gradient for decoder.decoder.6.weight: 0.0006250260048545897\n",
      "Gradient for decoder.decoder.6.bias: 4.0793886000756174e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.010365928523242474\n",
      "Gradient for encoder.encoder.0.bias: 1.8267278314998414e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0005302448407746851\n",
      "Gradient for encoder.encoder.1.bias: 0.0006703752442263067\n",
      "Gradient for encoder.encoder.3.weight: 0.011033901013433933\n",
      "Gradient for encoder.encoder.3.bias: 1.3234402462813932e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.002305753994733095\n",
      "Gradient for encoder.encoder.4.bias: 0.0023353910073637962\n",
      "Gradient for encoder.mean.weight: 0.03299321234226227\n",
      "Gradient for encoder.mean.bias: 0.0017710276879370213\n",
      "Gradient for encoder.log_var.weight: 0.0194887463003397\n",
      "Gradient for encoder.log_var.bias: 0.0013520077336579561\n",
      "Gradient for decoder.decoder.0.weight: 0.008695519529283047\n",
      "Gradient for decoder.decoder.0.bias: 7.308627314461802e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.00041422765934839845\n",
      "Gradient for decoder.decoder.1.bias: 0.000341172912158072\n",
      "Gradient for decoder.decoder.3.weight: 0.008385058492422104\n",
      "Gradient for decoder.decoder.3.bias: 9.043731041824543e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0006806901074014604\n",
      "Gradient for decoder.decoder.4.bias: 0.0008542098803445697\n",
      "Gradient for decoder.decoder.6.weight: 0.00077292590867728\n",
      "Gradient for decoder.decoder.6.bias: 6.6857181082014e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.00831661932170391\n",
      "Gradient for encoder.encoder.0.bias: 1.3897757944469902e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.000639664416667074\n",
      "Gradient for encoder.encoder.1.bias: 0.0006340502295643091\n",
      "Gradient for encoder.encoder.3.weight: 0.013081725686788559\n",
      "Gradient for encoder.encoder.3.bias: 1.4796340541689545e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0032688810024410486\n",
      "Gradient for encoder.encoder.4.bias: 0.0028108495753258467\n",
      "Gradient for encoder.mean.weight: 0.04400398209691048\n",
      "Gradient for encoder.mean.bias: 0.001978036481887102\n",
      "Gradient for encoder.log_var.weight: 0.02416827529668808\n",
      "Gradient for encoder.log_var.bias: 0.001314055873081088\n",
      "Gradient for decoder.decoder.0.weight: 0.010976488701999187\n",
      "Gradient for decoder.decoder.0.bias: 9.606201251122215e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005715652368962765\n",
      "Gradient for decoder.decoder.1.bias: 0.0005014729686081409\n",
      "Gradient for decoder.decoder.3.weight: 0.010129394941031933\n",
      "Gradient for decoder.decoder.3.bias: 8.120563249613966e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0003723677946254611\n",
      "Gradient for decoder.decoder.4.bias: 0.00032862715306691825\n",
      "Gradient for decoder.decoder.6.weight: 0.0006369901238940656\n",
      "Gradient for decoder.decoder.6.bias: 4.145808270550333e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.006964311935007572\n",
      "Gradient for encoder.encoder.0.bias: 1.2786421227373168e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0006737366784363985\n",
      "Gradient for encoder.encoder.1.bias: 0.0006702262908220291\n",
      "Gradient for encoder.encoder.3.weight: 0.01465404499322176\n",
      "Gradient for encoder.encoder.3.bias: 1.2553333372800068e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.003049514489248395\n",
      "Gradient for encoder.encoder.4.bias: 0.0025292220525443554\n",
      "Gradient for encoder.mean.weight: 0.04170046001672745\n",
      "Gradient for encoder.mean.bias: 0.002071826718747616\n",
      "Gradient for encoder.log_var.weight: 0.025437593460083008\n",
      "Gradient for encoder.log_var.bias: 0.0011406680569052696\n",
      "Gradient for decoder.decoder.0.weight: 0.011811181902885437\n",
      "Gradient for decoder.decoder.0.bias: 1.0141249645601036e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0006695559131912887\n",
      "Gradient for decoder.decoder.1.bias: 0.0005099956761114299\n",
      "Gradient for decoder.decoder.3.weight: 0.012119896709918976\n",
      "Gradient for decoder.decoder.3.bias: 1.0068688244269097e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.00051628373330459\n",
      "Gradient for decoder.decoder.4.bias: 0.0005217789439484477\n",
      "Gradient for decoder.decoder.6.weight: 0.000683210208080709\n",
      "Gradient for decoder.decoder.6.bias: 4.412719135871157e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.006580006796866655\n",
      "Gradient for encoder.encoder.0.bias: 1.1113651665617397e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.000599551887717098\n",
      "Gradient for encoder.encoder.1.bias: 0.0006166242528706789\n",
      "Gradient for encoder.encoder.3.weight: 0.013447166420519352\n",
      "Gradient for encoder.encoder.3.bias: 1.2056236564639278e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.00278595183044672\n",
      "Gradient for encoder.encoder.4.bias: 0.002293496858328581\n",
      "Gradient for encoder.mean.weight: 0.041223011910915375\n",
      "Gradient for encoder.mean.bias: 0.001805391046218574\n",
      "Gradient for encoder.log_var.weight: 0.02246871031820774\n",
      "Gradient for encoder.log_var.bias: 0.001007845625281334\n",
      "Gradient for decoder.decoder.0.weight: 0.013485437259078026\n",
      "Gradient for decoder.decoder.0.bias: 1.1505377900400404e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0007226411835290492\n",
      "Gradient for decoder.decoder.1.bias: 0.0005434126942418516\n",
      "Gradient for decoder.decoder.3.weight: 0.013303120620548725\n",
      "Gradient for decoder.decoder.3.bias: 1.1511756825566266e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.000768219237215817\n",
      "Gradient for decoder.decoder.4.bias: 0.0008247133810073137\n",
      "Gradient for decoder.decoder.6.weight: 0.0007584185805171728\n",
      "Gradient for decoder.decoder.6.bias: 4.917724436381832e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training VAE Epoch:  72%|███████▏  | 57/79 [00:00<00:00, 72.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient for encoder.encoder.0.weight: 0.010943436995148659\n",
      "Gradient for encoder.encoder.0.bias: 1.668710135349638e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.00069176044780761\n",
      "Gradient for encoder.encoder.1.bias: 0.000621694780420512\n",
      "Gradient for encoder.encoder.3.weight: 0.014940831810235977\n",
      "Gradient for encoder.encoder.3.bias: 1.5239058626104196e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.002753444481641054\n",
      "Gradient for encoder.encoder.4.bias: 0.0024870887864381075\n",
      "Gradient for encoder.mean.weight: 0.04169599339365959\n",
      "Gradient for encoder.mean.bias: 0.0020060325041413307\n",
      "Gradient for encoder.log_var.weight: 0.02516440860927105\n",
      "Gradient for encoder.log_var.bias: 0.0013504605740308762\n",
      "Gradient for decoder.decoder.0.weight: 0.011050499975681305\n",
      "Gradient for decoder.decoder.0.bias: 9.221109986690124e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005384855903685093\n",
      "Gradient for decoder.decoder.1.bias: 0.0004442409554030746\n",
      "Gradient for decoder.decoder.3.weight: 0.010336017236113548\n",
      "Gradient for decoder.decoder.3.bias: 8.17470049985225e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00046881826710887253\n",
      "Gradient for decoder.decoder.4.bias: 0.0004886036040261388\n",
      "Gradient for decoder.decoder.6.weight: 0.0006512754480354488\n",
      "Gradient for decoder.decoder.6.bias: 3.7710426113335416e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.00793593842536211\n",
      "Gradient for encoder.encoder.0.bias: 1.2811288488401296e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0005648473743349314\n",
      "Gradient for encoder.encoder.1.bias: 0.0006467258208431304\n",
      "Gradient for encoder.encoder.3.weight: 0.012409493327140808\n",
      "Gradient for encoder.encoder.3.bias: 1.1951190037606807e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0026549508329480886\n",
      "Gradient for encoder.encoder.4.bias: 0.0021951780654489994\n",
      "Gradient for encoder.mean.weight: 0.03940058499574661\n",
      "Gradient for encoder.mean.bias: 0.0017665621126070619\n",
      "Gradient for encoder.log_var.weight: 0.021270252764225006\n",
      "Gradient for encoder.log_var.bias: 0.0011500143446028233\n",
      "Gradient for decoder.decoder.0.weight: 0.010995513759553432\n",
      "Gradient for decoder.decoder.0.bias: 9.73762806499856e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005412260070443153\n",
      "Gradient for decoder.decoder.1.bias: 0.000446940102847293\n",
      "Gradient for decoder.decoder.3.weight: 0.010233491659164429\n",
      "Gradient for decoder.decoder.3.bias: 8.251965083472257e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0004079697246197611\n",
      "Gradient for decoder.decoder.4.bias: 0.00040006512426771224\n",
      "Gradient for decoder.decoder.6.weight: 0.0006441179430112243\n",
      "Gradient for decoder.decoder.6.bias: 4.241823990014382e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.005980507005006075\n",
      "Gradient for encoder.encoder.0.bias: 1.099821882871721e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.00043625052785500884\n",
      "Gradient for encoder.encoder.1.bias: 0.0004050034040119499\n",
      "Gradient for encoder.encoder.3.weight: 0.00951955933123827\n",
      "Gradient for encoder.encoder.3.bias: 1.2976614227611094e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0025314348749816418\n",
      "Gradient for encoder.encoder.4.bias: 0.002303495304659009\n",
      "Gradient for encoder.mean.weight: 0.040271345525979996\n",
      "Gradient for encoder.mean.bias: 0.0016638749511912465\n",
      "Gradient for encoder.log_var.weight: 0.0244235061109066\n",
      "Gradient for encoder.log_var.bias: 0.0011806446127593517\n",
      "Gradient for decoder.decoder.0.weight: 0.013893790543079376\n",
      "Gradient for decoder.decoder.0.bias: 1.1227443280636962e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.000754610518924892\n",
      "Gradient for decoder.decoder.1.bias: 0.0005420456291176379\n",
      "Gradient for decoder.decoder.3.weight: 0.013008433394134045\n",
      "Gradient for decoder.decoder.3.bias: 1.0093886837481136e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0006002592854201794\n",
      "Gradient for decoder.decoder.4.bias: 0.000578424078412354\n",
      "Gradient for decoder.decoder.6.weight: 0.0006855286192148924\n",
      "Gradient for decoder.decoder.6.bias: 3.9454618672607467e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.006778424605727196\n",
      "Gradient for encoder.encoder.0.bias: 1.2698669372979143e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0007774826954118907\n",
      "Gradient for encoder.encoder.1.bias: 0.0008654253906570375\n",
      "Gradient for encoder.encoder.3.weight: 0.01647098734974861\n",
      "Gradient for encoder.encoder.3.bias: 1.6111816047992278e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0037826604675501585\n",
      "Gradient for encoder.encoder.4.bias: 0.004351516719907522\n",
      "Gradient for encoder.mean.weight: 0.05243833363056183\n",
      "Gradient for encoder.mean.bias: 0.0034676287323236465\n",
      "Gradient for encoder.log_var.weight: 0.0329124741256237\n",
      "Gradient for encoder.log_var.bias: 0.0023710373789072037\n",
      "Gradient for decoder.decoder.0.weight: 0.012227710336446762\n",
      "Gradient for decoder.decoder.0.bias: 1.053250750504553e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0006030599470250309\n",
      "Gradient for decoder.decoder.1.bias: 0.0005008330917917192\n",
      "Gradient for decoder.decoder.3.weight: 0.011922934092581272\n",
      "Gradient for decoder.decoder.3.bias: 1.0506933517673289e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0006724423728883266\n",
      "Gradient for decoder.decoder.4.bias: 0.0006895860424265265\n",
      "Gradient for decoder.decoder.6.weight: 0.000809511577244848\n",
      "Gradient for decoder.decoder.6.bias: 5.9671321650967e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.006600048393011093\n",
      "Gradient for encoder.encoder.0.bias: 1.1756603503221275e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.000476320885354653\n",
      "Gradient for encoder.encoder.1.bias: 0.000511280435603112\n",
      "Gradient for encoder.encoder.3.weight: 0.010508053004741669\n",
      "Gradient for encoder.encoder.3.bias: 1.180473496731338e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0027878331020474434\n",
      "Gradient for encoder.encoder.4.bias: 0.0018987772054970264\n",
      "Gradient for encoder.mean.weight: 0.038877736777067184\n",
      "Gradient for encoder.mean.bias: 0.0014472303446382284\n",
      "Gradient for encoder.log_var.weight: 0.022709205746650696\n",
      "Gradient for encoder.log_var.bias: 0.000967570289503783\n",
      "Gradient for decoder.decoder.0.weight: 0.012189201079308987\n",
      "Gradient for decoder.decoder.0.bias: 1.0124921734355752e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0006281589739955962\n",
      "Gradient for decoder.decoder.1.bias: 0.0004936201730743051\n",
      "Gradient for decoder.decoder.3.weight: 0.011648263782262802\n",
      "Gradient for decoder.decoder.3.bias: 7.989855305146065e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00042846909491345286\n",
      "Gradient for decoder.decoder.4.bias: 0.00034656975185498595\n",
      "Gradient for decoder.decoder.6.weight: 0.0006232997984625399\n",
      "Gradient for decoder.decoder.6.bias: 3.2622312573948875e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.007363867945969105\n",
      "Gradient for encoder.encoder.0.bias: 1.291049732399241e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.000496112450491637\n",
      "Gradient for encoder.encoder.1.bias: 0.00063381961081177\n",
      "Gradient for encoder.encoder.3.weight: 0.01066161785274744\n",
      "Gradient for encoder.encoder.3.bias: 1.2121544046284072e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0024313898757100105\n",
      "Gradient for encoder.encoder.4.bias: 0.001972443424165249\n",
      "Gradient for encoder.mean.weight: 0.03647497668862343\n",
      "Gradient for encoder.mean.bias: 0.0015570773975923657\n",
      "Gradient for encoder.log_var.weight: 0.021409908309578896\n",
      "Gradient for encoder.log_var.bias: 0.0010353602701798081\n",
      "Gradient for decoder.decoder.0.weight: 0.011977126821875572\n",
      "Gradient for decoder.decoder.0.bias: 9.459161925962078e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0006071458919905126\n",
      "Gradient for decoder.decoder.1.bias: 0.0004865823430009186\n",
      "Gradient for decoder.decoder.3.weight: 0.010837031528353691\n",
      "Gradient for decoder.decoder.3.bias: 7.183487832351787e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0004290897340979427\n",
      "Gradient for decoder.decoder.4.bias: 0.0003930332895833999\n",
      "Gradient for decoder.decoder.6.weight: 0.0006880224100314081\n",
      "Gradient for decoder.decoder.6.bias: 4.602243279805407e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.010277630761265755\n",
      "Gradient for encoder.encoder.0.bias: 1.5179781043261897e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0005757181206718087\n",
      "Gradient for encoder.encoder.1.bias: 0.0006530887330882251\n",
      "Gradient for encoder.encoder.3.weight: 0.013573900796473026\n",
      "Gradient for encoder.encoder.3.bias: 1.37503189390209e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0027618820313364267\n",
      "Gradient for encoder.encoder.4.bias: 0.0025881363544613123\n",
      "Gradient for encoder.mean.weight: 0.039232369512319565\n",
      "Gradient for encoder.mean.bias: 0.0021625645458698273\n",
      "Gradient for encoder.log_var.weight: 0.023669371381402016\n",
      "Gradient for encoder.log_var.bias: 0.0012045943876728415\n",
      "Gradient for decoder.decoder.0.weight: 0.011084243655204773\n",
      "Gradient for decoder.decoder.0.bias: 9.490400132428078e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005236993893049657\n",
      "Gradient for decoder.decoder.1.bias: 0.0004006953095085919\n",
      "Gradient for decoder.decoder.3.weight: 0.01022375002503395\n",
      "Gradient for decoder.decoder.3.bias: 8.693445963103841e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0005040869582444429\n",
      "Gradient for decoder.decoder.4.bias: 0.0004944910760968924\n",
      "Gradient for decoder.decoder.6.weight: 0.0007390545797534287\n",
      "Gradient for decoder.decoder.6.bias: 5.177065031602979e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.007686300668865442\n",
      "Gradient for encoder.encoder.0.bias: 1.265236179714968e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.000621784245595336\n",
      "Gradient for encoder.encoder.1.bias: 0.0006076217396184802\n",
      "Gradient for encoder.encoder.3.weight: 0.014116710983216763\n",
      "Gradient for encoder.encoder.3.bias: 1.3822318289946622e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.00337266200222075\n",
      "Gradient for encoder.encoder.4.bias: 0.00245968671515584\n",
      "Gradient for encoder.mean.weight: 0.04956268146634102\n",
      "Gradient for encoder.mean.bias: 0.0016705802408978343\n",
      "Gradient for encoder.log_var.weight: 0.025399988517165184\n",
      "Gradient for encoder.log_var.bias: 0.0012709557777270675\n",
      "Gradient for decoder.decoder.0.weight: 0.012463783845305443\n",
      "Gradient for decoder.decoder.0.bias: 1.0416301848836795e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0006178997573442757\n",
      "Gradient for decoder.decoder.1.bias: 0.00045832982868887484\n",
      "Gradient for decoder.decoder.3.weight: 0.011529145762324333\n",
      "Gradient for decoder.decoder.3.bias: 1.00129127211801e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.00046907211071811616\n",
      "Gradient for decoder.decoder.4.bias: 0.0004973578616045415\n",
      "Gradient for decoder.decoder.6.weight: 0.0006727406289428473\n",
      "Gradient for decoder.decoder.6.bias: 3.887587445206009e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.007628701161593199\n",
      "Gradient for encoder.encoder.0.bias: 1.3787634228767942e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0006355553632602096\n",
      "Gradient for encoder.encoder.1.bias: 0.0005400099325925112\n",
      "Gradient for encoder.encoder.3.weight: 0.01420301292091608\n",
      "Gradient for encoder.encoder.3.bias: 1.3606304971602867e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0025567864067852497\n",
      "Gradient for encoder.encoder.4.bias: 0.002340362872928381\n",
      "Gradient for encoder.mean.weight: 0.03811368718743324\n",
      "Gradient for encoder.mean.bias: 0.0019241438712924719\n",
      "Gradient for encoder.log_var.weight: 0.023567399010062218\n",
      "Gradient for encoder.log_var.bias: 0.001193598727695644\n",
      "Gradient for decoder.decoder.0.weight: 0.010436099953949451\n",
      "Gradient for decoder.decoder.0.bias: 9.135761591672065e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.000540899287443608\n",
      "Gradient for decoder.decoder.1.bias: 0.0004084688553120941\n",
      "Gradient for decoder.decoder.3.weight: 0.009950133971869946\n",
      "Gradient for decoder.decoder.3.bias: 8.55474580063742e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00040181016083806753\n",
      "Gradient for decoder.decoder.4.bias: 0.0003653928288258612\n",
      "Gradient for decoder.decoder.6.weight: 0.0006096690776757896\n",
      "Gradient for decoder.decoder.6.bias: 3.2248855859506875e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.008947109803557396\n",
      "Gradient for encoder.encoder.0.bias: 1.5372361369947463e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0005904972204007208\n",
      "Gradient for encoder.encoder.1.bias: 0.0005739963962696493\n",
      "Gradient for encoder.encoder.3.weight: 0.012467222288250923\n",
      "Gradient for encoder.encoder.3.bias: 1.3948522892270887e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.002848268486559391\n",
      "Gradient for encoder.encoder.4.bias: 0.002681140322238207\n",
      "Gradient for encoder.mean.weight: 0.040651414543390274\n",
      "Gradient for encoder.mean.bias: 0.001981416717171669\n",
      "Gradient for encoder.log_var.weight: 0.025221211835741997\n",
      "Gradient for encoder.log_var.bias: 0.0012979223392903805\n",
      "Gradient for decoder.decoder.0.weight: 0.009909801185131073\n",
      "Gradient for decoder.decoder.0.bias: 8.244843696658677e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005178057472221553\n",
      "Gradient for decoder.decoder.1.bias: 0.0004053112934343517\n",
      "Gradient for decoder.decoder.3.weight: 0.009406392462551594\n",
      "Gradient for decoder.decoder.3.bias: 9.48313857995764e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0005459127714857459\n",
      "Gradient for decoder.decoder.4.bias: 0.0006783915450796485\n",
      "Gradient for decoder.decoder.6.weight: 0.0006733389454893768\n",
      "Gradient for decoder.decoder.6.bias: 4.968130815541372e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.008912287652492523\n",
      "Gradient for encoder.encoder.0.bias: 1.580485395336062e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0005702913040295243\n",
      "Gradient for encoder.encoder.1.bias: 0.0005366434925235808\n",
      "Gradient for encoder.encoder.3.weight: 0.01269766315817833\n",
      "Gradient for encoder.encoder.3.bias: 1.2886332279027357e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0030485426541417837\n",
      "Gradient for encoder.encoder.4.bias: 0.0026443330571055412\n",
      "Gradient for encoder.mean.weight: 0.041740112006664276\n",
      "Gradient for encoder.mean.bias: 0.0018136725993826985\n",
      "Gradient for encoder.log_var.weight: 0.024693218991160393\n",
      "Gradient for encoder.log_var.bias: 0.001302580931223929\n",
      "Gradient for decoder.decoder.0.weight: 0.00993316899985075\n",
      "Gradient for decoder.decoder.0.bias: 8.406694090856703e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005050314939580858\n",
      "Gradient for decoder.decoder.1.bias: 0.00042060899431817234\n",
      "Gradient for decoder.decoder.3.weight: 0.009337416850030422\n",
      "Gradient for decoder.decoder.3.bias: 7.301748788934859e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00034145929384976625\n",
      "Gradient for decoder.decoder.4.bias: 0.0002933297655545175\n",
      "Gradient for decoder.decoder.6.weight: 0.0006416765972971916\n",
      "Gradient for decoder.decoder.6.bias: 4.0029321098700166e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.006443441845476627\n",
      "Gradient for encoder.encoder.0.bias: 9.952175368532767e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.0005087279132567346\n",
      "Gradient for encoder.encoder.1.bias: 0.0005579226999543607\n",
      "Gradient for encoder.encoder.3.weight: 0.010895098559558392\n",
      "Gradient for encoder.encoder.3.bias: 1.4423701122368016e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.002633321564644575\n",
      "Gradient for encoder.encoder.4.bias: 0.0021860580891370773\n",
      "Gradient for encoder.mean.weight: 0.037321511656045914\n",
      "Gradient for encoder.mean.bias: 0.0017156637040898204\n",
      "Gradient for encoder.log_var.weight: 0.022075682878494263\n",
      "Gradient for encoder.log_var.bias: 0.001255897688679397\n",
      "Gradient for decoder.decoder.0.weight: 0.013435544446110725\n",
      "Gradient for decoder.decoder.0.bias: 1.142859834546428e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0006611992139369249\n",
      "Gradient for decoder.decoder.1.bias: 0.0005220376187935472\n",
      "Gradient for decoder.decoder.3.weight: 0.01245968509465456\n",
      "Gradient for decoder.decoder.3.bias: 1.0623388974062564e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0005361288785934448\n",
      "Gradient for decoder.decoder.4.bias: 0.0005143110756762326\n",
      "Gradient for decoder.decoder.6.weight: 0.0006667681154794991\n",
      "Gradient for decoder.decoder.6.bias: 3.767346788663417e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.010396130383014679\n",
      "Gradient for encoder.encoder.0.bias: 1.740165476993294e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0006784198340028524\n",
      "Gradient for encoder.encoder.1.bias: 0.0006251077866181731\n",
      "Gradient for encoder.encoder.3.weight: 0.015078130178153515\n",
      "Gradient for encoder.encoder.3.bias: 1.9723486732736717e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.003406650386750698\n",
      "Gradient for encoder.encoder.4.bias: 0.0038218048866838217\n",
      "Gradient for encoder.mean.weight: 0.044796232134103775\n",
      "Gradient for encoder.mean.bias: 0.0027453252114355564\n",
      "Gradient for encoder.log_var.weight: 0.03320534527301788\n",
      "Gradient for encoder.log_var.bias: 0.002048076596111059\n",
      "Gradient for decoder.decoder.0.weight: 0.010580368340015411\n",
      "Gradient for decoder.decoder.0.bias: 1.0273044914743679e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0005089115584269166\n",
      "Gradient for decoder.decoder.1.bias: 0.00041438249172642827\n",
      "Gradient for decoder.decoder.3.weight: 0.009967206045985222\n",
      "Gradient for decoder.decoder.3.bias: 9.130404765578248e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0003925616038031876\n",
      "Gradient for decoder.decoder.4.bias: 0.0003801202983595431\n",
      "Gradient for decoder.decoder.6.weight: 0.0006541830953210592\n",
      "Gradient for decoder.decoder.6.bias: 3.9559185097459704e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.007412228733301163\n",
      "Gradient for encoder.encoder.0.bias: 1.1307010015781938e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0005561638390645385\n",
      "Gradient for encoder.encoder.1.bias: 0.0005402994574978948\n",
      "Gradient for encoder.encoder.3.weight: 0.011949322186410427\n",
      "Gradient for encoder.encoder.3.bias: 1.2581158337354736e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.003332090098410845\n",
      "Gradient for encoder.encoder.4.bias: 0.002749322447925806\n",
      "Gradient for encoder.mean.weight: 0.045885179191827774\n",
      "Gradient for encoder.mean.bias: 0.0017760819755494595\n",
      "Gradient for encoder.log_var.weight: 0.029565289616584778\n",
      "Gradient for encoder.log_var.bias: 0.0011519790859892964\n",
      "Gradient for decoder.decoder.0.weight: 0.010906479321420193\n",
      "Gradient for decoder.decoder.0.bias: 9.421292218592114e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.000562484550755471\n",
      "Gradient for decoder.decoder.1.bias: 0.0004372377588879317\n",
      "Gradient for decoder.decoder.3.weight: 0.009997332468628883\n",
      "Gradient for decoder.decoder.3.bias: 8.209311702644939e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0003771224874071777\n",
      "Gradient for decoder.decoder.4.bias: 0.0003494184638839215\n",
      "Gradient for decoder.decoder.6.weight: 0.0006791380583308637\n",
      "Gradient for decoder.decoder.6.bias: 4.337671634857543e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.005625568795949221\n",
      "Gradient for encoder.encoder.0.bias: 9.743393591943317e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.0005766164977103472\n",
      "Gradient for encoder.encoder.1.bias: 0.0006296356441453099\n",
      "Gradient for encoder.encoder.3.weight: 0.01264696940779686\n",
      "Gradient for encoder.encoder.3.bias: 1.3356481198822934e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0038758222945034504\n",
      "Gradient for encoder.encoder.4.bias: 0.002862000372260809\n",
      "Gradient for encoder.mean.weight: 0.05510716140270233\n",
      "Gradient for encoder.mean.bias: 0.0021074581891298294\n",
      "Gradient for encoder.log_var.weight: 0.031859658658504486\n",
      "Gradient for encoder.log_var.bias: 0.0012459845747798681\n",
      "Gradient for decoder.decoder.0.weight: 0.01414837222546339\n",
      "Gradient for decoder.decoder.0.bias: 1.270178684453782e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0007058130577206612\n",
      "Gradient for decoder.decoder.1.bias: 0.0005759437917731702\n",
      "Gradient for decoder.decoder.3.weight: 0.012986494228243828\n",
      "Gradient for decoder.decoder.3.bias: 1.1110572184502843e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0005025844438932836\n",
      "Gradient for decoder.decoder.4.bias: 0.00043992832070216537\n",
      "Gradient for decoder.decoder.6.weight: 0.0006625693058595061\n",
      "Gradient for decoder.decoder.6.bias: 4.218141839373857e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.01192273199558258\n",
      "Gradient for encoder.encoder.0.bias: 2.0758766233752723e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0006242090603336692\n",
      "Gradient for encoder.encoder.1.bias: 0.0006250097067095339\n",
      "Gradient for encoder.encoder.3.weight: 0.013923869468271732\n",
      "Gradient for encoder.encoder.3.bias: 1.3994073955192476e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0022796005941927433\n",
      "Gradient for encoder.encoder.4.bias: 0.002200385555624962\n",
      "Gradient for encoder.mean.weight: 0.03329126164317131\n",
      "Gradient for encoder.mean.bias: 0.0017947028391063213\n",
      "Gradient for encoder.log_var.weight: 0.019058719277381897\n",
      "Gradient for encoder.log_var.bias: 0.0011943239951506257\n",
      "Gradient for decoder.decoder.0.weight: 0.008143392391502857\n",
      "Gradient for decoder.decoder.0.bias: 7.879637914376403e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0004116794152650982\n",
      "Gradient for decoder.decoder.1.bias: 0.00034566709655337036\n",
      "Gradient for decoder.decoder.3.weight: 0.007519118953496218\n",
      "Gradient for decoder.decoder.3.bias: 8.022529862650174e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00041228963527828455\n",
      "Gradient for decoder.decoder.4.bias: 0.00046350399497896433\n",
      "Gradient for decoder.decoder.6.weight: 0.0006486219353973866\n",
      "Gradient for decoder.decoder.6.bias: 4.687045657192357e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training VAE Epoch:  95%|█████████▍| 75/79 [00:01<00:00, 77.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient for encoder.encoder.0.weight: 0.007266859523952007\n",
      "Gradient for encoder.encoder.0.bias: 1.1393011534188702e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0005927575402893126\n",
      "Gradient for encoder.encoder.1.bias: 0.0005065525183454156\n",
      "Gradient for encoder.encoder.3.weight: 0.01293892040848732\n",
      "Gradient for encoder.encoder.3.bias: 1.3016070166127491e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0031536694150418043\n",
      "Gradient for encoder.encoder.4.bias: 0.002611231990158558\n",
      "Gradient for encoder.mean.weight: 0.04364491254091263\n",
      "Gradient for encoder.mean.bias: 0.001999005675315857\n",
      "Gradient for encoder.log_var.weight: 0.026108544319868088\n",
      "Gradient for encoder.log_var.bias: 0.001381618669256568\n",
      "Gradient for decoder.decoder.0.weight: 0.012639225460588932\n",
      "Gradient for decoder.decoder.0.bias: 1.0307923264951668e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0006442140438593924\n",
      "Gradient for decoder.decoder.1.bias: 0.000506835465785116\n",
      "Gradient for decoder.decoder.3.weight: 0.011708734557032585\n",
      "Gradient for decoder.decoder.3.bias: 8.498560882808093e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00046281557297334075\n",
      "Gradient for decoder.decoder.4.bias: 0.00039033417124301195\n",
      "Gradient for decoder.decoder.6.weight: 0.0006820405833423138\n",
      "Gradient for decoder.decoder.6.bias: 3.786266825045459e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.005638801958411932\n",
      "Gradient for encoder.encoder.0.bias: 1.0896001115257015e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0007991818711161613\n",
      "Gradient for encoder.encoder.1.bias: 0.0008869598968885839\n",
      "Gradient for encoder.encoder.3.weight: 0.017645778134465218\n",
      "Gradient for encoder.encoder.3.bias: 1.7256654438746466e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.004857457708567381\n",
      "Gradient for encoder.encoder.4.bias: 0.00438432302325964\n",
      "Gradient for encoder.mean.weight: 0.06490878760814667\n",
      "Gradient for encoder.mean.bias: 0.003263880033046007\n",
      "Gradient for encoder.log_var.weight: 0.04028245061635971\n",
      "Gradient for encoder.log_var.bias: 0.00224477075971663\n",
      "Gradient for decoder.decoder.0.weight: 0.01494938600808382\n",
      "Gradient for decoder.decoder.0.bias: 1.3021654587941356e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0008421239326708019\n",
      "Gradient for decoder.decoder.1.bias: 0.0005680579924955964\n",
      "Gradient for decoder.decoder.3.weight: 0.013921369798481464\n",
      "Gradient for decoder.decoder.3.bias: 1.1248776909944525e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.00047979585360735655\n",
      "Gradient for decoder.decoder.4.bias: 0.0004250064375810325\n",
      "Gradient for decoder.decoder.6.weight: 0.0006545238429680467\n",
      "Gradient for decoder.decoder.6.bias: 3.4772660001181066e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.005401382688432932\n",
      "Gradient for encoder.encoder.0.bias: 8.873231142902949e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.0005977156106382608\n",
      "Gradient for encoder.encoder.1.bias: 0.0005859144148416817\n",
      "Gradient for encoder.encoder.3.weight: 0.013921620324254036\n",
      "Gradient for encoder.encoder.3.bias: 1.3878513616116805e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.004620587453246117\n",
      "Gradient for encoder.encoder.4.bias: 0.003033421467989683\n",
      "Gradient for encoder.mean.weight: 0.06622388958930969\n",
      "Gradient for encoder.mean.bias: 0.0018758595688268542\n",
      "Gradient for encoder.log_var.weight: 0.0366845577955246\n",
      "Gradient for encoder.log_var.bias: 0.001365573494695127\n",
      "Gradient for decoder.decoder.0.weight: 0.014943934045732021\n",
      "Gradient for decoder.decoder.0.bias: 1.273433719584105e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.000751130108255893\n",
      "Gradient for decoder.decoder.1.bias: 0.0006110370741225779\n",
      "Gradient for decoder.decoder.3.weight: 0.014425139874219894\n",
      "Gradient for decoder.decoder.3.bias: 1.1967700441761764e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0007147837313823402\n",
      "Gradient for decoder.decoder.4.bias: 0.0008375400793738663\n",
      "Gradient for decoder.decoder.6.weight: 0.0007479341584257782\n",
      "Gradient for decoder.decoder.6.bias: 5.081511699245311e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.008341618813574314\n",
      "Gradient for encoder.encoder.0.bias: 1.3896937420265765e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0005912501364946365\n",
      "Gradient for encoder.encoder.1.bias: 0.0005026617436669767\n",
      "Gradient for encoder.encoder.3.weight: 0.012863858602941036\n",
      "Gradient for encoder.encoder.3.bias: 1.521862497133597e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.003853454487398267\n",
      "Gradient for encoder.encoder.4.bias: 0.0036598413717001677\n",
      "Gradient for encoder.mean.weight: 0.055315207690000534\n",
      "Gradient for encoder.mean.bias: 0.002994252135977149\n",
      "Gradient for encoder.log_var.weight: 0.032007984817028046\n",
      "Gradient for encoder.log_var.bias: 0.0016936104511842132\n",
      "Gradient for decoder.decoder.0.weight: 0.012194332666695118\n",
      "Gradient for decoder.decoder.0.bias: 1.1106016800654928e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0005866350256837904\n",
      "Gradient for decoder.decoder.1.bias: 0.00048351753503084183\n",
      "Gradient for decoder.decoder.3.weight: 0.01136649027466774\n",
      "Gradient for decoder.decoder.3.bias: 1.0944990053163295e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0003961336624342948\n",
      "Gradient for decoder.decoder.4.bias: 0.0003618195478338748\n",
      "Gradient for decoder.decoder.6.weight: 0.0006567715900018811\n",
      "Gradient for decoder.decoder.6.bias: 4.0458206058247015e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.0056258137337863445\n",
      "Gradient for encoder.encoder.0.bias: 8.661116962516147e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.0005768780829384923\n",
      "Gradient for encoder.encoder.1.bias: 0.0006480395677499473\n",
      "Gradient for encoder.encoder.3.weight: 0.012811468914151192\n",
      "Gradient for encoder.encoder.3.bias: 1.3097710416243302e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.00340336374938488\n",
      "Gradient for encoder.encoder.4.bias: 0.0029947925359010696\n",
      "Gradient for encoder.mean.weight: 0.04979342594742775\n",
      "Gradient for encoder.mean.bias: 0.0024575733114033937\n",
      "Gradient for encoder.log_var.weight: 0.02531161531805992\n",
      "Gradient for encoder.log_var.bias: 0.0015024635940790176\n",
      "Gradient for decoder.decoder.0.weight: 0.015512919053435326\n",
      "Gradient for decoder.decoder.0.bias: 1.3336480531034312e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.00076717184856534\n",
      "Gradient for decoder.decoder.1.bias: 0.0006348707829602063\n",
      "Gradient for decoder.decoder.3.weight: 0.014632767997682095\n",
      "Gradient for decoder.decoder.3.bias: 1.4798171021901396e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0008460805402137339\n",
      "Gradient for decoder.decoder.4.bias: 0.0009930138476192951\n",
      "Gradient for decoder.decoder.6.weight: 0.0007950564613565803\n",
      "Gradient for decoder.decoder.6.bias: 5.633631371892989e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.00978566613048315\n",
      "Gradient for encoder.encoder.0.bias: 1.418714538209409e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0007295965915545821\n",
      "Gradient for encoder.encoder.1.bias: 0.0006961460458114743\n",
      "Gradient for encoder.encoder.3.weight: 0.015790710225701332\n",
      "Gradient for encoder.encoder.3.bias: 1.5666272445979956e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.003772101365029812\n",
      "Gradient for encoder.encoder.4.bias: 0.002871379256248474\n",
      "Gradient for encoder.mean.weight: 0.05226192623376846\n",
      "Gradient for encoder.mean.bias: 0.0022110980935394764\n",
      "Gradient for encoder.log_var.weight: 0.030629774555563927\n",
      "Gradient for encoder.log_var.bias: 0.0016249308828264475\n",
      "Gradient for decoder.decoder.0.weight: 0.012797452509403229\n",
      "Gradient for decoder.decoder.0.bias: 1.053600748313066e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0005940967821516097\n",
      "Gradient for decoder.decoder.1.bias: 0.00047494220780208707\n",
      "Gradient for decoder.decoder.3.weight: 0.0116036431863904\n",
      "Gradient for decoder.decoder.3.bias: 9.380927978863696e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00043298781383782625\n",
      "Gradient for decoder.decoder.4.bias: 0.0003647809207905084\n",
      "Gradient for decoder.decoder.6.weight: 0.0006651278818026185\n",
      "Gradient for decoder.decoder.6.bias: 3.959488094551489e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.0057870084419846535\n",
      "Gradient for encoder.encoder.0.bias: 1.0182818997728216e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0005964536685496569\n",
      "Gradient for encoder.encoder.1.bias: 0.0006397855468094349\n",
      "Gradient for encoder.encoder.3.weight: 0.012744326144456863\n",
      "Gradient for encoder.encoder.3.bias: 1.3124749898008048e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.003373897634446621\n",
      "Gradient for encoder.encoder.4.bias: 0.0025745180901139975\n",
      "Gradient for encoder.mean.weight: 0.04687697812914848\n",
      "Gradient for encoder.mean.bias: 0.002127061365172267\n",
      "Gradient for encoder.log_var.weight: 0.027427807450294495\n",
      "Gradient for encoder.log_var.bias: 0.0013225419679656625\n",
      "Gradient for decoder.decoder.0.weight: 0.014751766808331013\n",
      "Gradient for decoder.decoder.0.bias: 1.3256339082001745e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0008257530862465501\n",
      "Gradient for decoder.decoder.1.bias: 0.0005648318328894675\n",
      "Gradient for decoder.decoder.3.weight: 0.014360739849507809\n",
      "Gradient for decoder.decoder.3.bias: 1.0876794603875695e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0005710964323952794\n",
      "Gradient for decoder.decoder.4.bias: 0.0005354643799364567\n",
      "Gradient for decoder.decoder.6.weight: 0.0006953625124879181\n",
      "Gradient for decoder.decoder.6.bias: 3.976035077357665e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.005504441447556019\n",
      "Gradient for encoder.encoder.0.bias: 9.671789411025422e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.0004257141554262489\n",
      "Gradient for encoder.encoder.1.bias: 0.0005078745307400823\n",
      "Gradient for encoder.encoder.3.weight: 0.009828571230173111\n",
      "Gradient for encoder.encoder.3.bias: 1.141156683037714e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.003566250205039978\n",
      "Gradient for encoder.encoder.4.bias: 0.002316118683665991\n",
      "Gradient for encoder.mean.weight: 0.048476435244083405\n",
      "Gradient for encoder.mean.bias: 0.0016927319811657071\n",
      "Gradient for encoder.log_var.weight: 0.024254631251096725\n",
      "Gradient for encoder.log_var.bias: 0.0011621015146374702\n",
      "Gradient for decoder.decoder.0.weight: 0.013526530005037785\n",
      "Gradient for decoder.decoder.0.bias: 1.1289841284067847e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0007073124288581312\n",
      "Gradient for decoder.decoder.1.bias: 0.000527277821674943\n",
      "Gradient for decoder.decoder.3.weight: 0.012638723477721214\n",
      "Gradient for decoder.decoder.3.bias: 1.0682316836652106e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0004967601271346211\n",
      "Gradient for decoder.decoder.4.bias: 0.0004933556774631143\n",
      "Gradient for decoder.decoder.6.weight: 0.0006270516314543784\n",
      "Gradient for decoder.decoder.6.bias: 3.6658657336374745e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.007001562975347042\n",
      "Gradient for encoder.encoder.0.bias: 1.1768288600555454e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0006281604873947799\n",
      "Gradient for encoder.encoder.1.bias: 0.0006903113680891693\n",
      "Gradient for encoder.encoder.3.weight: 0.013538729399442673\n",
      "Gradient for encoder.encoder.3.bias: 1.349154954422005e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.003514711046591401\n",
      "Gradient for encoder.encoder.4.bias: 0.002780268434435129\n",
      "Gradient for encoder.mean.weight: 0.0500757209956646\n",
      "Gradient for encoder.mean.bias: 0.0021422230638563633\n",
      "Gradient for encoder.log_var.weight: 0.02965775690972805\n",
      "Gradient for encoder.log_var.bias: 0.0014502662234008312\n",
      "Gradient for decoder.decoder.0.weight: 0.012930612079799175\n",
      "Gradient for decoder.decoder.0.bias: 1.0807905959087094e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0006288020522333682\n",
      "Gradient for decoder.decoder.1.bias: 0.000533741491381079\n",
      "Gradient for decoder.decoder.3.weight: 0.012024154886603355\n",
      "Gradient for decoder.decoder.3.bias: 9.37766878039703e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0005863946280442178\n",
      "Gradient for decoder.decoder.4.bias: 0.000595845456700772\n",
      "Gradient for decoder.decoder.6.weight: 0.0006700238445773721\n",
      "Gradient for decoder.decoder.6.bias: 3.805315282079391e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.007443612907081842\n",
      "Gradient for encoder.encoder.0.bias: 1.3010666329027476e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0005766511312685907\n",
      "Gradient for encoder.encoder.1.bias: 0.0006703872350044549\n",
      "Gradient for encoder.encoder.3.weight: 0.012615322135388851\n",
      "Gradient for encoder.encoder.3.bias: 1.3471103399442796e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0033292267471551895\n",
      "Gradient for encoder.encoder.4.bias: 0.002846976974979043\n",
      "Gradient for encoder.mean.weight: 0.04358013719320297\n",
      "Gradient for encoder.mean.bias: 0.002051472431048751\n",
      "Gradient for encoder.log_var.weight: 0.028175972402095795\n",
      "Gradient for encoder.log_var.bias: 0.0012533619301393628\n",
      "Gradient for decoder.decoder.0.weight: 0.013715764507651329\n",
      "Gradient for decoder.decoder.0.bias: 1.1549379508313251e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0006901055458001792\n",
      "Gradient for decoder.decoder.1.bias: 0.000522912188898772\n",
      "Gradient for decoder.decoder.3.weight: 0.01249687559902668\n",
      "Gradient for decoder.decoder.3.bias: 8.617237479136008e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0004846322408411652\n",
      "Gradient for decoder.decoder.4.bias: 0.00042425945866853\n",
      "Gradient for decoder.decoder.6.weight: 0.0006914448458701372\n",
      "Gradient for decoder.decoder.6.bias: 4.385966531117447e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.006564491428434849\n",
      "Gradient for encoder.encoder.0.bias: 1.0574337412638801e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0005525192827917635\n",
      "Gradient for encoder.encoder.1.bias: 0.0005504357977770269\n",
      "Gradient for encoder.encoder.3.weight: 0.012496798299252987\n",
      "Gradient for encoder.encoder.3.bias: 1.2960595097144534e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.003094117157161236\n",
      "Gradient for encoder.encoder.4.bias: 0.002486875280737877\n",
      "Gradient for encoder.mean.weight: 0.04261626675724983\n",
      "Gradient for encoder.mean.bias: 0.0018973711412400007\n",
      "Gradient for encoder.log_var.weight: 0.026227831840515137\n",
      "Gradient for encoder.log_var.bias: 0.001354915089905262\n",
      "Gradient for decoder.decoder.0.weight: 0.012718611396849155\n",
      "Gradient for decoder.decoder.0.bias: 1.0262811434014196e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0006597536848857999\n",
      "Gradient for decoder.decoder.1.bias: 0.0004919838975183666\n",
      "Gradient for decoder.decoder.3.weight: 0.012401534244418144\n",
      "Gradient for decoder.decoder.3.bias: 9.281755919410273e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0004644853761419654\n",
      "Gradient for decoder.decoder.4.bias: 0.00043830100912600756\n",
      "Gradient for decoder.decoder.6.weight: 0.0007185622816905379\n",
      "Gradient for decoder.decoder.6.bias: 4.9760128604248166e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.009835446253418922\n",
      "Gradient for encoder.encoder.0.bias: 1.5077449705414026e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.000493306783027947\n",
      "Gradient for encoder.encoder.1.bias: 0.0005013949703425169\n",
      "Gradient for encoder.encoder.3.weight: 0.010927999392151833\n",
      "Gradient for encoder.encoder.3.bias: 1.4326748121185062e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.002640973776578903\n",
      "Gradient for encoder.encoder.4.bias: 0.002467590384185314\n",
      "Gradient for encoder.mean.weight: 0.03934408724308014\n",
      "Gradient for encoder.mean.bias: 0.0017219162546098232\n",
      "Gradient for encoder.log_var.weight: 0.022480597719550133\n",
      "Gradient for encoder.log_var.bias: 0.0015160116599872708\n",
      "Gradient for decoder.decoder.0.weight: 0.01087214332073927\n",
      "Gradient for decoder.decoder.0.bias: 9.287129398849459e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005776245961897075\n",
      "Gradient for decoder.decoder.1.bias: 0.0004583239497151226\n",
      "Gradient for decoder.decoder.3.weight: 0.010375605896115303\n",
      "Gradient for decoder.decoder.3.bias: 8.521175431930317e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.000409767497330904\n",
      "Gradient for decoder.decoder.4.bias: 0.00039846348227001727\n",
      "Gradient for decoder.decoder.6.weight: 0.0006686736014671624\n",
      "Gradient for decoder.decoder.6.bias: 3.911686144419946e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.004048042930662632\n",
      "Gradient for encoder.encoder.0.bias: 7.1845923307889414e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.0004317762504797429\n",
      "Gradient for encoder.encoder.1.bias: 0.0005962034338153899\n",
      "Gradient for encoder.encoder.3.weight: 0.009514403529465199\n",
      "Gradient for encoder.encoder.3.bias: 1.311761393951727e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.004510003142058849\n",
      "Gradient for encoder.encoder.4.bias: 0.002873373916372657\n",
      "Gradient for encoder.mean.weight: 0.0650208443403244\n",
      "Gradient for encoder.mean.bias: 0.0022203573025763035\n",
      "Gradient for encoder.log_var.weight: 0.03638319671154022\n",
      "Gradient for encoder.log_var.bias: 0.0012425265740603209\n",
      "Gradient for decoder.decoder.0.weight: 0.015763942152261734\n",
      "Gradient for decoder.decoder.0.bias: 1.268557203726317e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0008810194558463991\n",
      "Gradient for decoder.decoder.1.bias: 0.000671901972964406\n",
      "Gradient for decoder.decoder.3.weight: 0.015466513112187386\n",
      "Gradient for decoder.decoder.3.bias: 1.2680501093598195e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0005798149504698813\n",
      "Gradient for decoder.decoder.4.bias: 0.0005407867720350623\n",
      "Gradient for decoder.decoder.6.weight: 0.0006938775186426938\n",
      "Gradient for decoder.decoder.6.bias: 4.036046448163688e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.010207289829850197\n",
      "Gradient for encoder.encoder.0.bias: 1.763013346423037e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0006067380309104919\n",
      "Gradient for encoder.encoder.1.bias: 0.0005445369170047343\n",
      "Gradient for encoder.encoder.3.weight: 0.013227110728621483\n",
      "Gradient for encoder.encoder.3.bias: 1.4611656329321931e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.003423230955377221\n",
      "Gradient for encoder.encoder.4.bias: 0.0024853225331753492\n",
      "Gradient for encoder.mean.weight: 0.04655389115214348\n",
      "Gradient for encoder.mean.bias: 0.0017270317766815424\n",
      "Gradient for encoder.log_var.weight: 0.023838303983211517\n",
      "Gradient for encoder.log_var.bias: 0.0013049936387687922\n",
      "Gradient for decoder.decoder.0.weight: 0.010074568912386894\n",
      "Gradient for decoder.decoder.0.bias: 8.20522885747188e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0004803621268365532\n",
      "Gradient for decoder.decoder.1.bias: 0.00040497235022485256\n",
      "Gradient for decoder.decoder.3.weight: 0.009433384984731674\n",
      "Gradient for decoder.decoder.3.bias: 6.894444043448189e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00031599204521626234\n",
      "Gradient for decoder.decoder.4.bias: 0.00028796889819204807\n",
      "Gradient for decoder.decoder.6.weight: 0.0007061575306579471\n",
      "Gradient for decoder.decoder.6.bias: 4.808924131793901e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.00810372643172741\n",
      "Gradient for encoder.encoder.0.bias: 1.2490153009081517e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.00042702574864961207\n",
      "Gradient for encoder.encoder.1.bias: 0.00046420920989476144\n",
      "Gradient for encoder.encoder.3.weight: 0.009244739077985287\n",
      "Gradient for encoder.encoder.3.bias: 1.1334994054479353e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.002436441835016012\n",
      "Gradient for encoder.encoder.4.bias: 0.002019077306613326\n",
      "Gradient for encoder.mean.weight: 0.036122895777225494\n",
      "Gradient for encoder.mean.bias: 0.0014899373054504395\n",
      "Gradient for encoder.log_var.weight: 0.023663511499762535\n",
      "Gradient for encoder.log_var.bias: 0.0013315194519236684\n",
      "Gradient for decoder.decoder.0.weight: 0.01087766420096159\n",
      "Gradient for decoder.decoder.0.bias: 9.11783357149254e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005286196828819811\n",
      "Gradient for decoder.decoder.1.bias: 0.000418506795540452\n",
      "Gradient for decoder.decoder.3.weight: 0.01000590343028307\n",
      "Gradient for decoder.decoder.3.bias: 9.745236562164195e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0004957746132276952\n",
      "Gradient for decoder.decoder.4.bias: 0.000581664324272424\n",
      "Gradient for decoder.decoder.6.weight: 0.0006793011561967432\n",
      "Gradient for decoder.decoder.6.bias: 4.606562288245186e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.05666622519493103\n",
      "Gradient for encoder.encoder.0.bias: 1.2555867456853775e-10\n",
      "Gradient for encoder.encoder.1.weight: 0.004007480572909117\n",
      "Gradient for encoder.encoder.1.bias: 0.0031963568180799484\n",
      "Gradient for encoder.encoder.3.weight: 0.08184501528739929\n",
      "Gradient for encoder.encoder.3.bias: 5.242745682032535e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.012947260402143002\n",
      "Gradient for encoder.encoder.4.bias: 0.011732321232557297\n",
      "Gradient for encoder.mean.weight: 0.17484194040298462\n",
      "Gradient for encoder.mean.bias: 0.006649497896432877\n",
      "Gradient for encoder.log_var.weight: 0.10418367385864258\n",
      "Gradient for encoder.log_var.bias: 0.004340025130659342\n",
      "Gradient for decoder.decoder.0.weight: 0.03154430538415909\n",
      "Gradient for decoder.decoder.0.bias: 1.8661269751696352e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0012000649003311992\n",
      "Gradient for decoder.decoder.1.bias: 0.0010491436114534736\n",
      "Gradient for decoder.decoder.3.weight: 0.02724396623671055\n",
      "Gradient for decoder.decoder.3.bias: 2.4177881918774347e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0012145891087129712\n",
      "Gradient for decoder.decoder.4.bias: 0.0013161407550796866\n",
      "Gradient for decoder.decoder.6.weight: 0.0018577625742182136\n",
      "Gradient for decoder.decoder.6.bias: 0.00010421741899335757\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3, Train Loss: 0.0699, Val Loss: 0.2932\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training VAE Epoch:   1%|▏         | 1/79 [00:00<00:14,  5.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient for encoder.encoder.0.weight: 0.007494853809475899\n",
      "Gradient for encoder.encoder.0.bias: 1.312534542857735e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0009407110046595335\n",
      "Gradient for encoder.encoder.1.bias: 0.0007824500207789242\n",
      "Gradient for encoder.encoder.3.weight: 0.02009006403386593\n",
      "Gradient for encoder.encoder.3.bias: 1.5905728123488672e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.004364929161965847\n",
      "Gradient for encoder.encoder.4.bias: 0.003161323256790638\n",
      "Gradient for encoder.mean.weight: 0.057938866317272186\n",
      "Gradient for encoder.mean.bias: 0.002344194334000349\n",
      "Gradient for encoder.log_var.weight: 0.03461313992738724\n",
      "Gradient for encoder.log_var.bias: 0.0014018900692462921\n",
      "Gradient for decoder.decoder.0.weight: 0.01377405971288681\n",
      "Gradient for decoder.decoder.0.bias: 1.1359749946260322e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0006786140147596598\n",
      "Gradient for decoder.decoder.1.bias: 0.0005751921562477946\n",
      "Gradient for decoder.decoder.3.weight: 0.012995941564440727\n",
      "Gradient for decoder.decoder.3.bias: 1.1484013739959664e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.000713473535142839\n",
      "Gradient for decoder.decoder.4.bias: 0.0007591377361677587\n",
      "Gradient for decoder.decoder.6.weight: 0.0008226771024055779\n",
      "Gradient for decoder.decoder.6.bias: 5.881195102119818e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.007419308181852102\n",
      "Gradient for encoder.encoder.0.bias: 1.1883852409078077e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0009083419572561979\n",
      "Gradient for encoder.encoder.1.bias: 0.0007959772483445704\n",
      "Gradient for encoder.encoder.3.weight: 0.01940588466823101\n",
      "Gradient for encoder.encoder.3.bias: 1.6586601536694445e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.004850791767239571\n",
      "Gradient for encoder.encoder.4.bias: 0.003949515987187624\n",
      "Gradient for encoder.mean.weight: 0.06718739867210388\n",
      "Gradient for encoder.mean.bias: 0.0025793048553168774\n",
      "Gradient for encoder.log_var.weight: 0.041176073253154755\n",
      "Gradient for encoder.log_var.bias: 0.001718977466225624\n",
      "Gradient for decoder.decoder.0.weight: 0.013682288117706776\n",
      "Gradient for decoder.decoder.0.bias: 1.0951318324403658e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0006828884943388402\n",
      "Gradient for decoder.decoder.1.bias: 0.000535183004103601\n",
      "Gradient for decoder.decoder.3.weight: 0.012915975414216518\n",
      "Gradient for decoder.decoder.3.bias: 1.0218745988277433e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0005090428167022765\n",
      "Gradient for decoder.decoder.4.bias: 0.00044484203681349754\n",
      "Gradient for decoder.decoder.6.weight: 0.0006867112242616713\n",
      "Gradient for decoder.decoder.6.bias: 3.683902832563035e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training VAE Epoch:  11%|█▏        | 9/79 [00:00<00:01, 37.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient for encoder.encoder.0.weight: 0.008780970238149166\n",
      "Gradient for encoder.encoder.0.bias: 1.3520672428879443e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0009721929091028869\n",
      "Gradient for encoder.encoder.1.bias: 0.0009132503182627261\n",
      "Gradient for encoder.encoder.3.weight: 0.020993301644921303\n",
      "Gradient for encoder.encoder.3.bias: 1.6286086368388908e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.005231727380305529\n",
      "Gradient for encoder.encoder.4.bias: 0.004381538834422827\n",
      "Gradient for encoder.mean.weight: 0.07144182920455933\n",
      "Gradient for encoder.mean.bias: 0.0025770526845008135\n",
      "Gradient for encoder.log_var.weight: 0.038843266665935516\n",
      "Gradient for encoder.log_var.bias: 0.0016652068588882685\n",
      "Gradient for decoder.decoder.0.weight: 0.012197199277579784\n",
      "Gradient for decoder.decoder.0.bias: 9.954683605206682e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005739032640121877\n",
      "Gradient for decoder.decoder.1.bias: 0.000484611839056015\n",
      "Gradient for decoder.decoder.3.weight: 0.011693931184709072\n",
      "Gradient for decoder.decoder.3.bias: 9.144210388889462e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0004240367852617055\n",
      "Gradient for decoder.decoder.4.bias: 0.0003843047597911209\n",
      "Gradient for decoder.decoder.6.weight: 0.0006714834016747773\n",
      "Gradient for decoder.decoder.6.bias: 4.007084498880431e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.017906274646520615\n",
      "Gradient for encoder.encoder.0.bias: 2.8874567667425133e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0011919863754883409\n",
      "Gradient for encoder.encoder.1.bias: 0.0008187151397578418\n",
      "Gradient for encoder.encoder.3.weight: 0.024639414623379707\n",
      "Gradient for encoder.encoder.3.bias: 2.2156161627595594e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.004805525299161673\n",
      "Gradient for encoder.encoder.4.bias: 0.004602561239153147\n",
      "Gradient for encoder.mean.weight: 0.06665767729282379\n",
      "Gradient for encoder.mean.bias: 0.0034566421527415514\n",
      "Gradient for encoder.log_var.weight: 0.037564024329185486\n",
      "Gradient for encoder.log_var.bias: 0.002087836852297187\n",
      "Gradient for decoder.decoder.0.weight: 0.009441842325031757\n",
      "Gradient for decoder.decoder.0.bias: 8.582249494404337e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0004376138676889241\n",
      "Gradient for decoder.decoder.1.bias: 0.00039298823685385287\n",
      "Gradient for decoder.decoder.3.weight: 0.008639020845293999\n",
      "Gradient for decoder.decoder.3.bias: 7.323409240145295e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0003155499289277941\n",
      "Gradient for decoder.decoder.4.bias: 0.00026353265275247395\n",
      "Gradient for decoder.decoder.6.weight: 0.0007139188819564879\n",
      "Gradient for decoder.decoder.6.bias: 5.086917371954769e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.014030080288648605\n",
      "Gradient for encoder.encoder.0.bias: 2.083049531476089e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0007945474935695529\n",
      "Gradient for encoder.encoder.1.bias: 0.000716415757779032\n",
      "Gradient for encoder.encoder.3.weight: 0.017961028963327408\n",
      "Gradient for encoder.encoder.3.bias: 1.8767562504073965e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.003625808749347925\n",
      "Gradient for encoder.encoder.4.bias: 0.003763085464015603\n",
      "Gradient for encoder.mean.weight: 0.04964892566204071\n",
      "Gradient for encoder.mean.bias: 0.0030393495690077543\n",
      "Gradient for encoder.log_var.weight: 0.029222801327705383\n",
      "Gradient for encoder.log_var.bias: 0.001684532850049436\n",
      "Gradient for decoder.decoder.0.weight: 0.00907158013433218\n",
      "Gradient for decoder.decoder.0.bias: 8.31203161855143e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.00044638485996983945\n",
      "Gradient for decoder.decoder.1.bias: 0.00036451630876399577\n",
      "Gradient for decoder.decoder.3.weight: 0.008408748544752598\n",
      "Gradient for decoder.decoder.3.bias: 6.788810485991448e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0003067404904868454\n",
      "Gradient for decoder.decoder.4.bias: 0.0002598115534055978\n",
      "Gradient for decoder.decoder.6.weight: 0.0006735742790624499\n",
      "Gradient for decoder.decoder.6.bias: 4.0040878957370296e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.009115530177950859\n",
      "Gradient for encoder.encoder.0.bias: 1.5196593983191065e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0007065005484037101\n",
      "Gradient for encoder.encoder.1.bias: 0.0006616254104301333\n",
      "Gradient for encoder.encoder.3.weight: 0.014981396496295929\n",
      "Gradient for encoder.encoder.3.bias: 1.7612186709037303e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.003700549015775323\n",
      "Gradient for encoder.encoder.4.bias: 0.004139209631830454\n",
      "Gradient for encoder.mean.weight: 0.05155358463525772\n",
      "Gradient for encoder.mean.bias: 0.0029330176766961813\n",
      "Gradient for encoder.log_var.weight: 0.035717450082302094\n",
      "Gradient for encoder.log_var.bias: 0.0021963552571833134\n",
      "Gradient for decoder.decoder.0.weight: 0.012353266589343548\n",
      "Gradient for decoder.decoder.0.bias: 1.0438979541893545e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0006049142684787512\n",
      "Gradient for decoder.decoder.1.bias: 0.0004808188241440803\n",
      "Gradient for decoder.decoder.3.weight: 0.012010928243398666\n",
      "Gradient for decoder.decoder.3.bias: 1.004397329196216e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0005384489777497947\n",
      "Gradient for decoder.decoder.4.bias: 0.000525143404956907\n",
      "Gradient for decoder.decoder.6.weight: 0.0006837985129095614\n",
      "Gradient for decoder.decoder.6.bias: 3.5501125239534304e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.006289534270763397\n",
      "Gradient for encoder.encoder.0.bias: 9.750199779501312e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.0005658604204654694\n",
      "Gradient for encoder.encoder.1.bias: 0.0005408182041719556\n",
      "Gradient for encoder.encoder.3.weight: 0.012745277024805546\n",
      "Gradient for encoder.encoder.3.bias: 1.6037328409712615e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0037587773986160755\n",
      "Gradient for encoder.encoder.4.bias: 0.0031389365904033184\n",
      "Gradient for encoder.mean.weight: 0.05037897452712059\n",
      "Gradient for encoder.mean.bias: 0.0021060360595583916\n",
      "Gradient for encoder.log_var.weight: 0.03366394340991974\n",
      "Gradient for encoder.log_var.bias: 0.0014149668859317899\n",
      "Gradient for decoder.decoder.0.weight: 0.015337826684117317\n",
      "Gradient for decoder.decoder.0.bias: 1.2091860845941937e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0008009515004232526\n",
      "Gradient for decoder.decoder.1.bias: 0.0006351745105348527\n",
      "Gradient for decoder.decoder.3.weight: 0.014756639488041401\n",
      "Gradient for decoder.decoder.3.bias: 1.111870040482188e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0007006577216088772\n",
      "Gradient for decoder.decoder.4.bias: 0.0006803793366998434\n",
      "Gradient for decoder.decoder.6.weight: 0.0007451257552020252\n",
      "Gradient for decoder.decoder.6.bias: 4.403706407174468e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.01071338914334774\n",
      "Gradient for encoder.encoder.0.bias: 1.7085343556599852e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0007272993680089712\n",
      "Gradient for encoder.encoder.1.bias: 0.000689521140884608\n",
      "Gradient for encoder.encoder.3.weight: 0.01584896631538868\n",
      "Gradient for encoder.encoder.3.bias: 1.657004256028216e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0032947477884590626\n",
      "Gradient for encoder.encoder.4.bias: 0.0033543214667588472\n",
      "Gradient for encoder.mean.weight: 0.04403567686676979\n",
      "Gradient for encoder.mean.bias: 0.0024434372317045927\n",
      "Gradient for encoder.log_var.weight: 0.02460426837205887\n",
      "Gradient for encoder.log_var.bias: 0.0013212630292400718\n",
      "Gradient for decoder.decoder.0.weight: 0.011964571662247181\n",
      "Gradient for decoder.decoder.0.bias: 1.0133426736613771e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0006454020622186363\n",
      "Gradient for decoder.decoder.1.bias: 0.0005042906850576401\n",
      "Gradient for decoder.decoder.3.weight: 0.01200035959482193\n",
      "Gradient for decoder.decoder.3.bias: 8.778928278774245e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0004653353535104543\n",
      "Gradient for decoder.decoder.4.bias: 0.00038301071617752314\n",
      "Gradient for decoder.decoder.6.weight: 0.0006908526411280036\n",
      "Gradient for decoder.decoder.6.bias: 3.8889975257916376e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.0155919985845685\n",
      "Gradient for encoder.encoder.0.bias: 2.3506184845811795e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0009002283331938088\n",
      "Gradient for encoder.encoder.1.bias: 0.0007735000108368695\n",
      "Gradient for encoder.encoder.3.weight: 0.018824486061930656\n",
      "Gradient for encoder.encoder.3.bias: 2.0205823125785116e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0038670427165925503\n",
      "Gradient for encoder.encoder.4.bias: 0.004007055424153805\n",
      "Gradient for encoder.mean.weight: 0.05342751368880272\n",
      "Gradient for encoder.mean.bias: 0.0032434510067105293\n",
      "Gradient for encoder.log_var.weight: 0.025899376720190048\n",
      "Gradient for encoder.log_var.bias: 0.0016208312008529902\n",
      "Gradient for decoder.decoder.0.weight: 0.010150078684091568\n",
      "Gradient for decoder.decoder.0.bias: 8.587345418087367e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005505215958692133\n",
      "Gradient for decoder.decoder.1.bias: 0.0004068730631843209\n",
      "Gradient for decoder.decoder.3.weight: 0.00956135056912899\n",
      "Gradient for decoder.decoder.3.bias: 8.328501777121744e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00048376256017945707\n",
      "Gradient for decoder.decoder.4.bias: 0.0005556537071242929\n",
      "Gradient for decoder.decoder.6.weight: 0.000686165876686573\n",
      "Gradient for decoder.decoder.6.bias: 4.397052543936297e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.014359683729708195\n",
      "Gradient for encoder.encoder.0.bias: 2.317315957178767e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0010782303288578987\n",
      "Gradient for encoder.encoder.1.bias: 0.0008117261459119618\n",
      "Gradient for encoder.encoder.3.weight: 0.021797243505716324\n",
      "Gradient for encoder.encoder.3.bias: 2.538864951606712e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.005827576387673616\n",
      "Gradient for encoder.encoder.4.bias: 0.005341424606740475\n",
      "Gradient for encoder.mean.weight: 0.07802946865558624\n",
      "Gradient for encoder.mean.bias: 0.002977892756462097\n",
      "Gradient for encoder.log_var.weight: 0.04313121363520622\n",
      "Gradient for encoder.log_var.bias: 0.001967041287571192\n",
      "Gradient for decoder.decoder.0.weight: 0.009578151628375053\n",
      "Gradient for decoder.decoder.0.bias: 8.658870842559452e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.00046773787471465766\n",
      "Gradient for decoder.decoder.1.bias: 0.0003806210297625512\n",
      "Gradient for decoder.decoder.3.weight: 0.00878080539405346\n",
      "Gradient for decoder.decoder.3.bias: 7.721127903703717e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00036995179834775627\n",
      "Gradient for decoder.decoder.4.bias: 0.00040793282096274197\n",
      "Gradient for decoder.decoder.6.weight: 0.0006696804193779826\n",
      "Gradient for decoder.decoder.6.bias: 4.376044307718985e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.008241702802479267\n",
      "Gradient for encoder.encoder.0.bias: 1.334429528682124e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0007007799576967955\n",
      "Gradient for encoder.encoder.1.bias: 0.0008097016834653914\n",
      "Gradient for encoder.encoder.3.weight: 0.015081949532032013\n",
      "Gradient for encoder.encoder.3.bias: 1.620768519394744e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0036494890227913857\n",
      "Gradient for encoder.encoder.4.bias: 0.0037399339489638805\n",
      "Gradient for encoder.mean.weight: 0.04803706333041191\n",
      "Gradient for encoder.mean.bias: 0.002606053836643696\n",
      "Gradient for encoder.log_var.weight: 0.029116518795490265\n",
      "Gradient for encoder.log_var.bias: 0.0017730282852426171\n",
      "Gradient for decoder.decoder.0.weight: 0.013695862144231796\n",
      "Gradient for decoder.decoder.0.bias: 1.1869347171789002e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.000717427465133369\n",
      "Gradient for decoder.decoder.1.bias: 0.0005484325811266899\n",
      "Gradient for decoder.decoder.3.weight: 0.012459808960556984\n",
      "Gradient for decoder.decoder.3.bias: 1.2421945416729585e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0006234762258827686\n",
      "Gradient for decoder.decoder.4.bias: 0.0006613571313209832\n",
      "Gradient for decoder.decoder.6.weight: 0.0008359589264728129\n",
      "Gradient for decoder.decoder.6.bias: 6.011494042468257e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.008195285685360432\n",
      "Gradient for encoder.encoder.0.bias: 1.4062515041324275e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.000677590724080801\n",
      "Gradient for encoder.encoder.1.bias: 0.0007373667322099209\n",
      "Gradient for encoder.encoder.3.weight: 0.015382451936602592\n",
      "Gradient for encoder.encoder.3.bias: 1.436915308961062e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0034392927773296833\n",
      "Gradient for encoder.encoder.4.bias: 0.0027860936243087053\n",
      "Gradient for encoder.mean.weight: 0.04967011138796806\n",
      "Gradient for encoder.mean.bias: 0.0020884587429463863\n",
      "Gradient for encoder.log_var.weight: 0.028700152412056923\n",
      "Gradient for encoder.log_var.bias: 0.001424552989192307\n",
      "Gradient for decoder.decoder.0.weight: 0.011337374337017536\n",
      "Gradient for decoder.decoder.0.bias: 9.948494805733787e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005584759055636823\n",
      "Gradient for decoder.decoder.1.bias: 0.0004480148199945688\n",
      "Gradient for decoder.decoder.3.weight: 0.011092534288764\n",
      "Gradient for decoder.decoder.3.bias: 7.88771409299116e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0004165115824434906\n",
      "Gradient for decoder.decoder.4.bias: 0.0003473761898931116\n",
      "Gradient for decoder.decoder.6.weight: 0.0007295112009160221\n",
      "Gradient for decoder.decoder.6.bias: 4.9512113037053496e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.00759192556142807\n",
      "Gradient for encoder.encoder.0.bias: 1.1116376916198156e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0004642057465389371\n",
      "Gradient for encoder.encoder.1.bias: 0.0005656913854181767\n",
      "Gradient for encoder.encoder.3.weight: 0.010468713007867336\n",
      "Gradient for encoder.encoder.3.bias: 1.4180226437510157e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.002897395519539714\n",
      "Gradient for encoder.encoder.4.bias: 0.0027691104914993048\n",
      "Gradient for encoder.mean.weight: 0.041706640273332596\n",
      "Gradient for encoder.mean.bias: 0.0020962159615010023\n",
      "Gradient for encoder.log_var.weight: 0.025780310854315758\n",
      "Gradient for encoder.log_var.bias: 0.001391196739859879\n",
      "Gradient for decoder.decoder.0.weight: 0.0138216782361269\n",
      "Gradient for decoder.decoder.0.bias: 1.1484351664092785e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0007177978986874223\n",
      "Gradient for decoder.decoder.1.bias: 0.0005779851344414055\n",
      "Gradient for decoder.decoder.3.weight: 0.013369102030992508\n",
      "Gradient for decoder.decoder.3.bias: 1.0004732459156784e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0005156146944500506\n",
      "Gradient for decoder.decoder.4.bias: 0.0004406183143146336\n",
      "Gradient for decoder.decoder.6.weight: 0.0007402124465443194\n",
      "Gradient for decoder.decoder.6.bias: 4.6194923925213516e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.009481708519160748\n",
      "Gradient for encoder.encoder.0.bias: 1.5414612294928354e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0007694842061027884\n",
      "Gradient for encoder.encoder.1.bias: 0.0007906857645139098\n",
      "Gradient for encoder.encoder.3.weight: 0.01696031168103218\n",
      "Gradient for encoder.encoder.3.bias: 1.764676044180291e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0036375971976667643\n",
      "Gradient for encoder.encoder.4.bias: 0.0037987709511071444\n",
      "Gradient for encoder.mean.weight: 0.050244297832250595\n",
      "Gradient for encoder.mean.bias: 0.0028290310874581337\n",
      "Gradient for encoder.log_var.weight: 0.03255850449204445\n",
      "Gradient for encoder.log_var.bias: 0.0019581648521125317\n",
      "Gradient for decoder.decoder.0.weight: 0.010749628767371178\n",
      "Gradient for decoder.decoder.0.bias: 8.655541561264357e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005553620867431164\n",
      "Gradient for decoder.decoder.1.bias: 0.0004414534196257591\n",
      "Gradient for decoder.decoder.3.weight: 0.010547145269811153\n",
      "Gradient for decoder.decoder.3.bias: 8.093536951747637e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0003716154315043241\n",
      "Gradient for decoder.decoder.4.bias: 0.00034295517252758145\n",
      "Gradient for decoder.decoder.6.weight: 0.0006714233895763755\n",
      "Gradient for decoder.decoder.6.bias: 3.6641533370129764e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.00914018601179123\n",
      "Gradient for encoder.encoder.0.bias: 1.3432304747651447e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0007432690472342074\n",
      "Gradient for encoder.encoder.1.bias: 0.0007451571291312575\n",
      "Gradient for encoder.encoder.3.weight: 0.015311013907194138\n",
      "Gradient for encoder.encoder.3.bias: 1.600437699034174e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.003347827820107341\n",
      "Gradient for encoder.encoder.4.bias: 0.00295589049346745\n",
      "Gradient for encoder.mean.weight: 0.04429594799876213\n",
      "Gradient for encoder.mean.bias: 0.002234892686828971\n",
      "Gradient for encoder.log_var.weight: 0.029087988659739494\n",
      "Gradient for encoder.log_var.bias: 0.0017520870314911008\n",
      "Gradient for decoder.decoder.0.weight: 0.012033415026962757\n",
      "Gradient for decoder.decoder.0.bias: 1.1491012308351145e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0006113803829066455\n",
      "Gradient for decoder.decoder.1.bias: 0.0004673748626373708\n",
      "Gradient for decoder.decoder.3.weight: 0.0115165701135993\n",
      "Gradient for decoder.decoder.3.bias: 1.2472062271839945e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0006462921155616641\n",
      "Gradient for decoder.decoder.4.bias: 0.0007117804489098489\n",
      "Gradient for decoder.decoder.6.weight: 0.0007547890418209136\n",
      "Gradient for decoder.decoder.6.bias: 4.8941165005089715e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.008992004208266735\n",
      "Gradient for encoder.encoder.0.bias: 1.234144644118862e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0007680776761844754\n",
      "Gradient for encoder.encoder.1.bias: 0.0006995061994530261\n",
      "Gradient for encoder.encoder.3.weight: 0.01610007882118225\n",
      "Gradient for encoder.encoder.3.bias: 1.593197240801203e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.003050795290619135\n",
      "Gradient for encoder.encoder.4.bias: 0.002980508841574192\n",
      "Gradient for encoder.mean.weight: 0.04503842070698738\n",
      "Gradient for encoder.mean.bias: 0.0020737797021865845\n",
      "Gradient for encoder.log_var.weight: 0.026919277384877205\n",
      "Gradient for encoder.log_var.bias: 0.001498713972978294\n",
      "Gradient for decoder.decoder.0.weight: 0.014002549462020397\n",
      "Gradient for decoder.decoder.0.bias: 1.0761664476222066e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0006688961875624955\n",
      "Gradient for decoder.decoder.1.bias: 0.000550014607142657\n",
      "Gradient for decoder.decoder.3.weight: 0.013188215903937817\n",
      "Gradient for decoder.decoder.3.bias: 1.1238483060838078e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0006609770352952182\n",
      "Gradient for decoder.decoder.4.bias: 0.0006768913008272648\n",
      "Gradient for decoder.decoder.6.weight: 0.000797009386587888\n",
      "Gradient for decoder.decoder.6.bias: 5.1018025260418653e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training VAE Epoch:  22%|██▏       | 17/79 [00:00<00:01, 52.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient for encoder.encoder.0.weight: 0.015907669439911842\n",
      "Gradient for encoder.encoder.0.bias: 2.5927796368230283e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.00123298610560596\n",
      "Gradient for encoder.encoder.1.bias: 0.0009737578802742064\n",
      "Gradient for encoder.encoder.3.weight: 0.026011381298303604\n",
      "Gradient for encoder.encoder.3.bias: 2.570514079369701e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.005756620317697525\n",
      "Gradient for encoder.encoder.4.bias: 0.005724970251321793\n",
      "Gradient for encoder.mean.weight: 0.07984686642885208\n",
      "Gradient for encoder.mean.bias: 0.004482501186430454\n",
      "Gradient for encoder.log_var.weight: 0.041672226041555405\n",
      "Gradient for encoder.log_var.bias: 0.0023475128691643476\n",
      "Gradient for decoder.decoder.0.weight: 0.009906616061925888\n",
      "Gradient for decoder.decoder.0.bias: 8.988840921597685e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005326098180375993\n",
      "Gradient for decoder.decoder.1.bias: 0.0004230563063174486\n",
      "Gradient for decoder.decoder.3.weight: 0.009204182773828506\n",
      "Gradient for decoder.decoder.3.bias: 7.831933712676431e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0003830011992249638\n",
      "Gradient for decoder.decoder.4.bias: 0.00039352691965177655\n",
      "Gradient for decoder.decoder.6.weight: 0.0006229794234968722\n",
      "Gradient for decoder.decoder.6.bias: 3.360773189342581e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.007495615631341934\n",
      "Gradient for encoder.encoder.0.bias: 1.3350748458151873e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0006183943478390574\n",
      "Gradient for encoder.encoder.1.bias: 0.000755293935071677\n",
      "Gradient for encoder.encoder.3.weight: 0.013707784004509449\n",
      "Gradient for encoder.encoder.3.bias: 1.346882050334841e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.004050406161695719\n",
      "Gradient for encoder.encoder.4.bias: 0.002808796940371394\n",
      "Gradient for encoder.mean.weight: 0.059434082359075546\n",
      "Gradient for encoder.mean.bias: 0.0020180228166282177\n",
      "Gradient for encoder.log_var.weight: 0.033012330532073975\n",
      "Gradient for encoder.log_var.bias: 0.001315026544034481\n",
      "Gradient for decoder.decoder.0.weight: 0.012128660455346107\n",
      "Gradient for decoder.decoder.0.bias: 1.126196497169829e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0005989797064103186\n",
      "Gradient for decoder.decoder.1.bias: 0.00047394042485393584\n",
      "Gradient for decoder.decoder.3.weight: 0.011172743514180183\n",
      "Gradient for decoder.decoder.3.bias: 1.0750543510962274e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.000428416853537783\n",
      "Gradient for decoder.decoder.4.bias: 0.0004343146865721792\n",
      "Gradient for decoder.decoder.6.weight: 0.0006456779083237052\n",
      "Gradient for decoder.decoder.6.bias: 3.6707653634948656e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training VAE Epoch:  32%|███▏      | 25/79 [00:00<00:00, 61.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient for encoder.encoder.0.weight: 0.012382958084344864\n",
      "Gradient for encoder.encoder.0.bias: 2.1152092230525277e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.000770479382481426\n",
      "Gradient for encoder.encoder.1.bias: 0.0006644220557063818\n",
      "Gradient for encoder.encoder.3.weight: 0.016857998445630074\n",
      "Gradient for encoder.encoder.3.bias: 1.711977365426165e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0037080091424286366\n",
      "Gradient for encoder.encoder.4.bias: 0.0032712635584175587\n",
      "Gradient for encoder.mean.weight: 0.052046362310647964\n",
      "Gradient for encoder.mean.bias: 0.0026534562930464745\n",
      "Gradient for encoder.log_var.weight: 0.030686145648360252\n",
      "Gradient for encoder.log_var.bias: 0.0015786922303959727\n",
      "Gradient for decoder.decoder.0.weight: 0.010633853264153004\n",
      "Gradient for decoder.decoder.0.bias: 1.0143894058067815e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0005213134572841227\n",
      "Gradient for decoder.decoder.1.bias: 0.00043788939365185797\n",
      "Gradient for decoder.decoder.3.weight: 0.009672385640442371\n",
      "Gradient for decoder.decoder.3.bias: 9.485598417846575e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0003289868764113635\n",
      "Gradient for decoder.decoder.4.bias: 0.00034719755058176816\n",
      "Gradient for decoder.decoder.6.weight: 0.0006469560321420431\n",
      "Gradient for decoder.decoder.6.bias: 3.433228994254023e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.006685845088213682\n",
      "Gradient for encoder.encoder.0.bias: 1.074815150076125e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0005564638995565474\n",
      "Gradient for encoder.encoder.1.bias: 0.0005806462722830474\n",
      "Gradient for encoder.encoder.3.weight: 0.012251886539161205\n",
      "Gradient for encoder.encoder.3.bias: 1.470352312127332e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.004043461289256811\n",
      "Gradient for encoder.encoder.4.bias: 0.002886193571612239\n",
      "Gradient for encoder.mean.weight: 0.05669417604804039\n",
      "Gradient for encoder.mean.bias: 0.0019167984137311578\n",
      "Gradient for encoder.log_var.weight: 0.03238412365317345\n",
      "Gradient for encoder.log_var.bias: 0.001184874214231968\n",
      "Gradient for decoder.decoder.0.weight: 0.013178674504160881\n",
      "Gradient for decoder.decoder.0.bias: 1.0691568463894185e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0006500300369225442\n",
      "Gradient for decoder.decoder.1.bias: 0.0005266841617412865\n",
      "Gradient for decoder.decoder.3.weight: 0.013180124573409557\n",
      "Gradient for decoder.decoder.3.bias: 9.331411338076023e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00047913467278704047\n",
      "Gradient for decoder.decoder.4.bias: 0.00041082268580794334\n",
      "Gradient for decoder.decoder.6.weight: 0.0007160000968724489\n",
      "Gradient for decoder.decoder.6.bias: 3.737419319804758e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.008400565013289452\n",
      "Gradient for encoder.encoder.0.bias: 1.3144233965145524e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0006517896545119584\n",
      "Gradient for encoder.encoder.1.bias: 0.0006345294532366097\n",
      "Gradient for encoder.encoder.3.weight: 0.014449532143771648\n",
      "Gradient for encoder.encoder.3.bias: 1.2649278846588174e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.00313115818426013\n",
      "Gradient for encoder.encoder.4.bias: 0.002391814487054944\n",
      "Gradient for encoder.mean.weight: 0.0443180687725544\n",
      "Gradient for encoder.mean.bias: 0.0018948039505630732\n",
      "Gradient for encoder.log_var.weight: 0.026128316298127174\n",
      "Gradient for encoder.log_var.bias: 0.0010484064696356654\n",
      "Gradient for decoder.decoder.0.weight: 0.012668897397816181\n",
      "Gradient for decoder.decoder.0.bias: 1.0651461657129602e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0006758585222996771\n",
      "Gradient for decoder.decoder.1.bias: 0.0004921656218357384\n",
      "Gradient for decoder.decoder.3.weight: 0.012234881520271301\n",
      "Gradient for decoder.decoder.3.bias: 8.87172835195571e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0004858245956711471\n",
      "Gradient for decoder.decoder.4.bias: 0.00043021858436986804\n",
      "Gradient for decoder.decoder.6.weight: 0.0007116207852959633\n",
      "Gradient for decoder.decoder.6.bias: 4.0117483877111226e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.011092589236795902\n",
      "Gradient for encoder.encoder.0.bias: 1.6625097132294542e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0006039449363015592\n",
      "Gradient for encoder.encoder.1.bias: 0.0005587470950558782\n",
      "Gradient for encoder.encoder.3.weight: 0.013372745364904404\n",
      "Gradient for encoder.encoder.3.bias: 1.6444368089452155e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.002897784812375903\n",
      "Gradient for encoder.encoder.4.bias: 0.002974048489704728\n",
      "Gradient for encoder.mean.weight: 0.04250580444931984\n",
      "Gradient for encoder.mean.bias: 0.0025470072869211435\n",
      "Gradient for encoder.log_var.weight: 0.02268366888165474\n",
      "Gradient for encoder.log_var.bias: 0.00142373435664922\n",
      "Gradient for decoder.decoder.0.weight: 0.010320127941668034\n",
      "Gradient for decoder.decoder.0.bias: 8.10332773104605e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005007587606087327\n",
      "Gradient for decoder.decoder.1.bias: 0.0004309370997361839\n",
      "Gradient for decoder.decoder.3.weight: 0.009984448552131653\n",
      "Gradient for decoder.decoder.3.bias: 7.942207308486715e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0004581530811265111\n",
      "Gradient for decoder.decoder.4.bias: 0.0004988273722119629\n",
      "Gradient for decoder.decoder.6.weight: 0.0006826518219895661\n",
      "Gradient for decoder.decoder.6.bias: 4.276887921150774e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.011837726458907127\n",
      "Gradient for encoder.encoder.0.bias: 2.278054481164027e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0009575773729011416\n",
      "Gradient for encoder.encoder.1.bias: 0.0007511380827054381\n",
      "Gradient for encoder.encoder.3.weight: 0.02106105536222458\n",
      "Gradient for encoder.encoder.3.bias: 2.2934264209961697e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.00559835322201252\n",
      "Gradient for encoder.encoder.4.bias: 0.0053257723338902\n",
      "Gradient for encoder.mean.weight: 0.07747305184602737\n",
      "Gradient for encoder.mean.bias: 0.0034771354403346777\n",
      "Gradient for encoder.log_var.weight: 0.042668312788009644\n",
      "Gradient for encoder.log_var.bias: 0.0021061873994767666\n",
      "Gradient for decoder.decoder.0.weight: 0.009411577135324478\n",
      "Gradient for decoder.decoder.0.bias: 8.694103770245931e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0004606330767273903\n",
      "Gradient for decoder.decoder.1.bias: 0.0003919395967386663\n",
      "Gradient for decoder.decoder.3.weight: 0.008758441545069218\n",
      "Gradient for decoder.decoder.3.bias: 9.808479722872576e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0006645428948104382\n",
      "Gradient for decoder.decoder.4.bias: 0.0008101945859380066\n",
      "Gradient for decoder.decoder.6.weight: 0.0008376348996534944\n",
      "Gradient for decoder.decoder.6.bias: 6.983834464335814e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.005941187962889671\n",
      "Gradient for encoder.encoder.0.bias: 9.39345042721973e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.000496166932862252\n",
      "Gradient for encoder.encoder.1.bias: 0.0006449513603001833\n",
      "Gradient for encoder.encoder.3.weight: 0.011036466807126999\n",
      "Gradient for encoder.encoder.3.bias: 1.4228165867713471e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.003724557813256979\n",
      "Gradient for encoder.encoder.4.bias: 0.0027299721259623766\n",
      "Gradient for encoder.mean.weight: 0.05802033469080925\n",
      "Gradient for encoder.mean.bias: 0.002149854553863406\n",
      "Gradient for encoder.log_var.weight: 0.030653569847345352\n",
      "Gradient for encoder.log_var.bias: 0.0012635592138394713\n",
      "Gradient for decoder.decoder.0.weight: 0.014854971319437027\n",
      "Gradient for decoder.decoder.0.bias: 1.3197500037254173e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.000718996743671596\n",
      "Gradient for decoder.decoder.1.bias: 0.0006577408639714122\n",
      "Gradient for decoder.decoder.3.weight: 0.01348092034459114\n",
      "Gradient for decoder.decoder.3.bias: 1.018757161963535e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.000488601450342685\n",
      "Gradient for decoder.decoder.4.bias: 0.00041731298551894724\n",
      "Gradient for decoder.decoder.6.weight: 0.0006937172147445381\n",
      "Gradient for decoder.decoder.6.bias: 4.1052848246181384e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.012809640727937222\n",
      "Gradient for encoder.encoder.0.bias: 1.9884534990799452e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0006822186405770481\n",
      "Gradient for encoder.encoder.1.bias: 0.0007167126750573516\n",
      "Gradient for encoder.encoder.3.weight: 0.015074514783918858\n",
      "Gradient for encoder.encoder.3.bias: 1.611673988710649e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0032253300305455923\n",
      "Gradient for encoder.encoder.4.bias: 0.003257782431319356\n",
      "Gradient for encoder.mean.weight: 0.0448220893740654\n",
      "Gradient for encoder.mean.bias: 0.0025618658401072025\n",
      "Gradient for encoder.log_var.weight: 0.02410559356212616\n",
      "Gradient for encoder.log_var.bias: 0.0014977231621742249\n",
      "Gradient for decoder.decoder.0.weight: 0.010098001919686794\n",
      "Gradient for decoder.decoder.0.bias: 9.072331080828278e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0004897608305327594\n",
      "Gradient for decoder.decoder.1.bias: 0.0003946451470255852\n",
      "Gradient for decoder.decoder.3.weight: 0.009862234815955162\n",
      "Gradient for decoder.decoder.3.bias: 9.747994772490998e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0004453695728443563\n",
      "Gradient for decoder.decoder.4.bias: 0.0004937230842188001\n",
      "Gradient for decoder.decoder.6.weight: 0.0006816351087763906\n",
      "Gradient for decoder.decoder.6.bias: 4.1961964598158374e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.005125903524458408\n",
      "Gradient for encoder.encoder.0.bias: 9.00032999517908e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.0005799613427370787\n",
      "Gradient for encoder.encoder.1.bias: 0.0006969232927076519\n",
      "Gradient for encoder.encoder.3.weight: 0.012581424787640572\n",
      "Gradient for encoder.encoder.3.bias: 1.574236019319386e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.004292177967727184\n",
      "Gradient for encoder.encoder.4.bias: 0.0038063956890255213\n",
      "Gradient for encoder.mean.weight: 0.062185779213905334\n",
      "Gradient for encoder.mean.bias: 0.0028530287090688944\n",
      "Gradient for encoder.log_var.weight: 0.03460657596588135\n",
      "Gradient for encoder.log_var.bias: 0.0017416446935385466\n",
      "Gradient for decoder.decoder.0.weight: 0.015592394396662712\n",
      "Gradient for decoder.decoder.0.bias: 1.269043620188981e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0007744834292680025\n",
      "Gradient for decoder.decoder.1.bias: 0.0006245929398573935\n",
      "Gradient for decoder.decoder.3.weight: 0.01471220888197422\n",
      "Gradient for decoder.decoder.3.bias: 1.2086685818868403e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0005174164543859661\n",
      "Gradient for decoder.decoder.4.bias: 0.0004791221290361136\n",
      "Gradient for decoder.decoder.6.weight: 0.0006871750811114907\n",
      "Gradient for decoder.decoder.6.bias: 4.036039536003955e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.012214000336825848\n",
      "Gradient for encoder.encoder.0.bias: 1.9609121618135994e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0007577745709568262\n",
      "Gradient for encoder.encoder.1.bias: 0.0006543283816426992\n",
      "Gradient for encoder.encoder.3.weight: 0.015501787886023521\n",
      "Gradient for encoder.encoder.3.bias: 1.8958121184020627e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.003332579042762518\n",
      "Gradient for encoder.encoder.4.bias: 0.0031700984109193087\n",
      "Gradient for encoder.mean.weight: 0.04767250269651413\n",
      "Gradient for encoder.mean.bias: 0.0026140979025512934\n",
      "Gradient for encoder.log_var.weight: 0.023429948836565018\n",
      "Gradient for encoder.log_var.bias: 0.001305940793827176\n",
      "Gradient for decoder.decoder.0.weight: 0.01105943787842989\n",
      "Gradient for decoder.decoder.0.bias: 9.020305336004952e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005698190070688725\n",
      "Gradient for decoder.decoder.1.bias: 0.00045255516306497157\n",
      "Gradient for decoder.decoder.3.weight: 0.010838453657925129\n",
      "Gradient for decoder.decoder.3.bias: 9.055318994644068e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0004189111350569874\n",
      "Gradient for decoder.decoder.4.bias: 0.00038104981649667025\n",
      "Gradient for decoder.decoder.6.weight: 0.0006630935240536928\n",
      "Gradient for decoder.decoder.6.bias: 3.822226426564157e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.006393984891474247\n",
      "Gradient for encoder.encoder.0.bias: 1.1707640065750091e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0005738105974160135\n",
      "Gradient for encoder.encoder.1.bias: 0.0006017801351845264\n",
      "Gradient for encoder.encoder.3.weight: 0.01285704318434\n",
      "Gradient for encoder.encoder.3.bias: 1.378505365412508e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0034655085764825344\n",
      "Gradient for encoder.encoder.4.bias: 0.0030290083959698677\n",
      "Gradient for encoder.mean.weight: 0.0510614849627018\n",
      "Gradient for encoder.mean.bias: 0.0023708606604486704\n",
      "Gradient for encoder.log_var.weight: 0.028043080121278763\n",
      "Gradient for encoder.log_var.bias: 0.0013518333435058594\n",
      "Gradient for decoder.decoder.0.weight: 0.013299000449478626\n",
      "Gradient for decoder.decoder.0.bias: 1.0236128611396111e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0006592936115339398\n",
      "Gradient for decoder.decoder.1.bias: 0.0005464219721034169\n",
      "Gradient for decoder.decoder.3.weight: 0.012826877646148205\n",
      "Gradient for decoder.decoder.3.bias: 8.597656614428573e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00045156359556131065\n",
      "Gradient for decoder.decoder.4.bias: 0.0003948522498831153\n",
      "Gradient for decoder.decoder.6.weight: 0.0006738511146977544\n",
      "Gradient for decoder.decoder.6.bias: 3.777789243031293e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.006464546080678701\n",
      "Gradient for encoder.encoder.0.bias: 1.0422729519732332e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0005013694753870368\n",
      "Gradient for encoder.encoder.1.bias: 0.0005264438805170357\n",
      "Gradient for encoder.encoder.3.weight: 0.011574458330869675\n",
      "Gradient for encoder.encoder.3.bias: 1.2194342757787524e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0033091579098254442\n",
      "Gradient for encoder.encoder.4.bias: 0.002225378295406699\n",
      "Gradient for encoder.mean.weight: 0.04454805701971054\n",
      "Gradient for encoder.mean.bias: 0.0017056280048564076\n",
      "Gradient for encoder.log_var.weight: 0.029299523681402206\n",
      "Gradient for encoder.log_var.bias: 0.0011327872052788734\n",
      "Gradient for decoder.decoder.0.weight: 0.014374312944710255\n",
      "Gradient for decoder.decoder.0.bias: 1.2349808675704566e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0007168083102442324\n",
      "Gradient for decoder.decoder.1.bias: 0.000582271080929786\n",
      "Gradient for decoder.decoder.3.weight: 0.013175099156796932\n",
      "Gradient for decoder.decoder.3.bias: 1.1148662548698951e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0004336704150773585\n",
      "Gradient for decoder.decoder.4.bias: 0.00039304656093008816\n",
      "Gradient for decoder.decoder.6.weight: 0.0006594262085855007\n",
      "Gradient for decoder.decoder.6.bias: 3.3871263440232724e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.006783447228372097\n",
      "Gradient for encoder.encoder.0.bias: 1.0941204539594018e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0005808646674267948\n",
      "Gradient for encoder.encoder.1.bias: 0.0006464296602644026\n",
      "Gradient for encoder.encoder.3.weight: 0.012347105890512466\n",
      "Gradient for encoder.encoder.3.bias: 1.1663205123912945e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.002766075311228633\n",
      "Gradient for encoder.encoder.4.bias: 0.0019287634640932083\n",
      "Gradient for encoder.mean.weight: 0.04273172840476036\n",
      "Gradient for encoder.mean.bias: 0.0016760921571403742\n",
      "Gradient for encoder.log_var.weight: 0.02181997522711754\n",
      "Gradient for encoder.log_var.bias: 0.0010546990670263767\n",
      "Gradient for decoder.decoder.0.weight: 0.01347573846578598\n",
      "Gradient for decoder.decoder.0.bias: 1.1159329016408037e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.000676377268973738\n",
      "Gradient for decoder.decoder.1.bias: 0.0005091559723950922\n",
      "Gradient for decoder.decoder.3.weight: 0.012360542081296444\n",
      "Gradient for decoder.decoder.3.bias: 1.0951205914322415e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.00046252598986029625\n",
      "Gradient for decoder.decoder.4.bias: 0.00042997338459827006\n",
      "Gradient for decoder.decoder.6.weight: 0.0007047684048302472\n",
      "Gradient for decoder.decoder.6.bias: 4.465780875761993e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.009425174444913864\n",
      "Gradient for encoder.encoder.0.bias: 1.5836082445375155e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.00045540090650320053\n",
      "Gradient for encoder.encoder.1.bias: 0.0004970775335095823\n",
      "Gradient for encoder.encoder.3.weight: 0.0101983193308115\n",
      "Gradient for encoder.encoder.3.bias: 1.396117388363649e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0028083946090191603\n",
      "Gradient for encoder.encoder.4.bias: 0.0027003325521945953\n",
      "Gradient for encoder.mean.weight: 0.04270588234066963\n",
      "Gradient for encoder.mean.bias: 0.0021628006361424923\n",
      "Gradient for encoder.log_var.weight: 0.023561274632811546\n",
      "Gradient for encoder.log_var.bias: 0.0012374944053590298\n",
      "Gradient for decoder.decoder.0.weight: 0.010797949507832527\n",
      "Gradient for decoder.decoder.0.bias: 1.0449961729275259e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0005535786040127277\n",
      "Gradient for decoder.decoder.1.bias: 0.0004720936412923038\n",
      "Gradient for decoder.decoder.3.weight: 0.010499042458832264\n",
      "Gradient for decoder.decoder.3.bias: 1.106917127402518e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0006934177363291383\n",
      "Gradient for decoder.decoder.4.bias: 0.0008446348365396261\n",
      "Gradient for decoder.decoder.6.weight: 0.0007199868559837341\n",
      "Gradient for decoder.decoder.6.bias: 5.585174585576169e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.006251432467252016\n",
      "Gradient for encoder.encoder.0.bias: 1.0982379936019804e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0004765867779497057\n",
      "Gradient for encoder.encoder.1.bias: 0.0005419444642029703\n",
      "Gradient for encoder.encoder.3.weight: 0.010779459029436111\n",
      "Gradient for encoder.encoder.3.bias: 1.3898183992555602e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.002859386382624507\n",
      "Gradient for encoder.encoder.4.bias: 0.002355313627049327\n",
      "Gradient for encoder.mean.weight: 0.03957965597510338\n",
      "Gradient for encoder.mean.bias: 0.0018121020402759314\n",
      "Gradient for encoder.log_var.weight: 0.026230085641145706\n",
      "Gradient for encoder.log_var.bias: 0.0012692702002823353\n",
      "Gradient for decoder.decoder.0.weight: 0.012568436563014984\n",
      "Gradient for decoder.decoder.0.bias: 9.758319846620012e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0006025669863447547\n",
      "Gradient for decoder.decoder.1.bias: 0.0004831493424717337\n",
      "Gradient for decoder.decoder.3.weight: 0.011603831313550472\n",
      "Gradient for decoder.decoder.3.bias: 8.39510891359474e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00040077095036394894\n",
      "Gradient for decoder.decoder.4.bias: 0.00035806267987936735\n",
      "Gradient for decoder.decoder.6.weight: 0.0006661684601567686\n",
      "Gradient for decoder.decoder.6.bias: 3.75008094124496e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training VAE Epoch:  42%|████▏     | 33/79 [00:00<00:00, 66.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient for encoder.encoder.0.weight: 0.012042396701872349\n",
      "Gradient for encoder.encoder.0.bias: 1.6485547302269588e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0004893071600235999\n",
      "Gradient for encoder.encoder.1.bias: 0.0004661259881686419\n",
      "Gradient for encoder.encoder.3.weight: 0.010575860738754272\n",
      "Gradient for encoder.encoder.3.bias: 1.353555739713741e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.002528398297727108\n",
      "Gradient for encoder.encoder.4.bias: 0.0023902656976133585\n",
      "Gradient for encoder.mean.weight: 0.03702458739280701\n",
      "Gradient for encoder.mean.bias: 0.0016749247442930937\n",
      "Gradient for encoder.log_var.weight: 0.022049641236662865\n",
      "Gradient for encoder.log_var.bias: 0.0010835244320333004\n",
      "Gradient for decoder.decoder.0.weight: 0.009654362685978413\n",
      "Gradient for decoder.decoder.0.bias: 7.657363632063152e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0004882512439507991\n",
      "Gradient for decoder.decoder.1.bias: 0.0003857931587845087\n",
      "Gradient for decoder.decoder.3.weight: 0.009150920435786247\n",
      "Gradient for decoder.decoder.3.bias: 9.048529286959095e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0005598848219960928\n",
      "Gradient for decoder.decoder.4.bias: 0.0006621620268560946\n",
      "Gradient for decoder.decoder.6.weight: 0.0006993494462221861\n",
      "Gradient for decoder.decoder.6.bias: 4.9383383156964555e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.005088364705443382\n",
      "Gradient for encoder.encoder.0.bias: 9.010825072208739e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.0005156806437298656\n",
      "Gradient for encoder.encoder.1.bias: 0.0006382688297890127\n",
      "Gradient for encoder.encoder.3.weight: 0.011168221943080425\n",
      "Gradient for encoder.encoder.3.bias: 1.4157157390837227e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0034243259578943253\n",
      "Gradient for encoder.encoder.4.bias: 0.003273854497820139\n",
      "Gradient for encoder.mean.weight: 0.04971681162714958\n",
      "Gradient for encoder.mean.bias: 0.002548565622419119\n",
      "Gradient for encoder.log_var.weight: 0.030992623418569565\n",
      "Gradient for encoder.log_var.bias: 0.0014569970080628991\n",
      "Gradient for decoder.decoder.0.weight: 0.012387854047119617\n",
      "Gradient for decoder.decoder.0.bias: 1.0126485761041693e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0006200824864208698\n",
      "Gradient for decoder.decoder.1.bias: 0.0004904456436634064\n",
      "Gradient for decoder.decoder.3.weight: 0.011766972951591015\n",
      "Gradient for decoder.decoder.3.bias: 7.951400649020002e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00040638918289914727\n",
      "Gradient for decoder.decoder.4.bias: 0.00036092152004130185\n",
      "Gradient for decoder.decoder.6.weight: 0.0006584087968803942\n",
      "Gradient for decoder.decoder.6.bias: 3.550884503056295e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training VAE Epoch:  52%|█████▏    | 41/79 [00:00<00:00, 68.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient for encoder.encoder.0.weight: 0.006476386915892363\n",
      "Gradient for encoder.encoder.0.bias: 1.0121092332282533e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.00044687261106446385\n",
      "Gradient for encoder.encoder.1.bias: 0.00046873866813257337\n",
      "Gradient for encoder.encoder.3.weight: 0.009861327707767487\n",
      "Gradient for encoder.encoder.3.bias: 1.0773182346213162e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0024095952976495028\n",
      "Gradient for encoder.encoder.4.bias: 0.0021654602605849504\n",
      "Gradient for encoder.mean.weight: 0.033825211226940155\n",
      "Gradient for encoder.mean.bias: 0.0017971040215343237\n",
      "Gradient for encoder.log_var.weight: 0.020904531702399254\n",
      "Gradient for encoder.log_var.bias: 0.0011417848290875554\n",
      "Gradient for decoder.decoder.0.weight: 0.013481264002621174\n",
      "Gradient for decoder.decoder.0.bias: 1.1938525168453396e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0006823836592957377\n",
      "Gradient for decoder.decoder.1.bias: 0.0005327746039256454\n",
      "Gradient for decoder.decoder.3.weight: 0.012725974433124065\n",
      "Gradient for decoder.decoder.3.bias: 1.0654494647655e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.000563149806112051\n",
      "Gradient for decoder.decoder.4.bias: 0.0005756277241744101\n",
      "Gradient for decoder.decoder.6.weight: 0.0007710020872764289\n",
      "Gradient for decoder.decoder.6.bias: 5.232292824075557e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.007953137159347534\n",
      "Gradient for encoder.encoder.0.bias: 1.3313895125266484e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0006046125199645758\n",
      "Gradient for encoder.encoder.1.bias: 0.0005990448407828808\n",
      "Gradient for encoder.encoder.3.weight: 0.013026040978729725\n",
      "Gradient for encoder.encoder.3.bias: 1.3419863831298784e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.00299982656724751\n",
      "Gradient for encoder.encoder.4.bias: 0.0027717624325305223\n",
      "Gradient for encoder.mean.weight: 0.04100488871335983\n",
      "Gradient for encoder.mean.bias: 0.0018347580917179585\n",
      "Gradient for encoder.log_var.weight: 0.024552879855036736\n",
      "Gradient for encoder.log_var.bias: 0.0011724444339051843\n",
      "Gradient for decoder.decoder.0.weight: 0.012375587597489357\n",
      "Gradient for decoder.decoder.0.bias: 1.059898072086618e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0006265151896513999\n",
      "Gradient for decoder.decoder.1.bias: 0.0005141993169672787\n",
      "Gradient for decoder.decoder.3.weight: 0.011711177416145802\n",
      "Gradient for decoder.decoder.3.bias: 9.561112318534626e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00043455936247482896\n",
      "Gradient for decoder.decoder.4.bias: 0.00035894985194317997\n",
      "Gradient for decoder.decoder.6.weight: 0.000720782030839473\n",
      "Gradient for decoder.decoder.6.bias: 4.7832229029154405e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.0074285175651311874\n",
      "Gradient for encoder.encoder.0.bias: 1.2054616853329758e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0005905561847612262\n",
      "Gradient for encoder.encoder.1.bias: 0.0005671889521181583\n",
      "Gradient for encoder.encoder.3.weight: 0.013273424468934536\n",
      "Gradient for encoder.encoder.3.bias: 1.2826303907864656e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0029468145221471786\n",
      "Gradient for encoder.encoder.4.bias: 0.0025246059522032738\n",
      "Gradient for encoder.mean.weight: 0.04413183033466339\n",
      "Gradient for encoder.mean.bias: 0.0021341778337955475\n",
      "Gradient for encoder.log_var.weight: 0.02582169696688652\n",
      "Gradient for encoder.log_var.bias: 0.0014185999752953649\n",
      "Gradient for decoder.decoder.0.weight: 0.013068486005067825\n",
      "Gradient for decoder.decoder.0.bias: 1.157495072012793e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0006952485418878496\n",
      "Gradient for decoder.decoder.1.bias: 0.0005595065304078162\n",
      "Gradient for decoder.decoder.3.weight: 0.01244680117815733\n",
      "Gradient for decoder.decoder.3.bias: 9.604250034156436e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0004675670061260462\n",
      "Gradient for decoder.decoder.4.bias: 0.00044191660708747804\n",
      "Gradient for decoder.decoder.6.weight: 0.000680886791087687\n",
      "Gradient for decoder.decoder.6.bias: 3.776218727580272e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.005138428416103125\n",
      "Gradient for encoder.encoder.0.bias: 9.093725772402195e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.0004216379311401397\n",
      "Gradient for encoder.encoder.1.bias: 0.0005471095792017877\n",
      "Gradient for encoder.encoder.3.weight: 0.008912978693842888\n",
      "Gradient for encoder.encoder.3.bias: 1.2584423780825915e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0031506225932389498\n",
      "Gradient for encoder.encoder.4.bias: 0.002498206915333867\n",
      "Gradient for encoder.mean.weight: 0.04807713255286217\n",
      "Gradient for encoder.mean.bias: 0.001838847529143095\n",
      "Gradient for encoder.log_var.weight: 0.024610958993434906\n",
      "Gradient for encoder.log_var.bias: 0.0013901167549192905\n",
      "Gradient for decoder.decoder.0.weight: 0.014737119898200035\n",
      "Gradient for decoder.decoder.0.bias: 1.302862123742088e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0007100021466612816\n",
      "Gradient for decoder.decoder.1.bias: 0.000656195217743516\n",
      "Gradient for decoder.decoder.3.weight: 0.013190163299441338\n",
      "Gradient for decoder.decoder.3.bias: 1.0823966029027687e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.00048683449858799577\n",
      "Gradient for decoder.decoder.4.bias: 0.00043056640424765646\n",
      "Gradient for decoder.decoder.6.weight: 0.0007475624443031847\n",
      "Gradient for decoder.decoder.6.bias: 5.10493409819901e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.0083067137748003\n",
      "Gradient for encoder.encoder.0.bias: 1.33592312559494e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0006525138160213828\n",
      "Gradient for encoder.encoder.1.bias: 0.0006716672796756029\n",
      "Gradient for encoder.encoder.3.weight: 0.013931376859545708\n",
      "Gradient for encoder.encoder.3.bias: 1.445221303741917e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0031185580883175135\n",
      "Gradient for encoder.encoder.4.bias: 0.0028430980164557695\n",
      "Gradient for encoder.mean.weight: 0.042718902230262756\n",
      "Gradient for encoder.mean.bias: 0.0023533024359494448\n",
      "Gradient for encoder.log_var.weight: 0.023462483659386635\n",
      "Gradient for encoder.log_var.bias: 0.001330939237959683\n",
      "Gradient for decoder.decoder.0.weight: 0.01158987171947956\n",
      "Gradient for decoder.decoder.0.bias: 9.979082143951601e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005678700981661677\n",
      "Gradient for decoder.decoder.1.bias: 0.0004900144413113594\n",
      "Gradient for decoder.decoder.3.weight: 0.010947249829769135\n",
      "Gradient for decoder.decoder.3.bias: 8.745850571534319e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0004181071708444506\n",
      "Gradient for decoder.decoder.4.bias: 0.00040609430288895965\n",
      "Gradient for decoder.decoder.6.weight: 0.000698512012604624\n",
      "Gradient for decoder.decoder.6.bias: 4.145177808823064e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.005687289871275425\n",
      "Gradient for encoder.encoder.0.bias: 8.714539506682328e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.000481955474242568\n",
      "Gradient for encoder.encoder.1.bias: 0.0005257701850496233\n",
      "Gradient for encoder.encoder.3.weight: 0.01081021223217249\n",
      "Gradient for encoder.encoder.3.bias: 1.1955855749867794e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0036515328101813793\n",
      "Gradient for encoder.encoder.4.bias: 0.0025064488872885704\n",
      "Gradient for encoder.mean.weight: 0.04733029752969742\n",
      "Gradient for encoder.mean.bias: 0.0016391209792345762\n",
      "Gradient for encoder.log_var.weight: 0.03056536428630352\n",
      "Gradient for encoder.log_var.bias: 0.0011125992750748992\n",
      "Gradient for decoder.decoder.0.weight: 0.014659167267382145\n",
      "Gradient for decoder.decoder.0.bias: 1.1866896354462142e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.000757383240852505\n",
      "Gradient for decoder.decoder.1.bias: 0.0006004456081427634\n",
      "Gradient for decoder.decoder.3.weight: 0.013922915793955326\n",
      "Gradient for decoder.decoder.3.bias: 1.1142366890259936e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0006473578396253288\n",
      "Gradient for decoder.decoder.4.bias: 0.0006376355304382741\n",
      "Gradient for decoder.decoder.6.weight: 0.0007284680032171309\n",
      "Gradient for decoder.decoder.6.bias: 4.060170613229275e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.0066225542686879635\n",
      "Gradient for encoder.encoder.0.bias: 1.0126976514313046e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0004892901051789522\n",
      "Gradient for encoder.encoder.1.bias: 0.0004625236033461988\n",
      "Gradient for encoder.encoder.3.weight: 0.010665185749530792\n",
      "Gradient for encoder.encoder.3.bias: 1.3585506331015296e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0028727813623845577\n",
      "Gradient for encoder.encoder.4.bias: 0.0027954501565545797\n",
      "Gradient for encoder.mean.weight: 0.03998859226703644\n",
      "Gradient for encoder.mean.bias: 0.0019393725087866187\n",
      "Gradient for encoder.log_var.weight: 0.022167347371578217\n",
      "Gradient for encoder.log_var.bias: 0.0011124389711767435\n",
      "Gradient for decoder.decoder.0.weight: 0.01428203471004963\n",
      "Gradient for decoder.decoder.0.bias: 1.1109566044886776e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0007493577431887388\n",
      "Gradient for decoder.decoder.1.bias: 0.0006051816162653267\n",
      "Gradient for decoder.decoder.3.weight: 0.013293717056512833\n",
      "Gradient for decoder.decoder.3.bias: 1.2646438063423915e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0007510697469115257\n",
      "Gradient for decoder.decoder.4.bias: 0.0008198374998755753\n",
      "Gradient for decoder.decoder.6.weight: 0.0008211291278712451\n",
      "Gradient for decoder.decoder.6.bias: 5.8712113968795165e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.007892542518675327\n",
      "Gradient for encoder.encoder.0.bias: 1.4454758570647819e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0005631695385091007\n",
      "Gradient for encoder.encoder.1.bias: 0.0005654625128954649\n",
      "Gradient for encoder.encoder.3.weight: 0.01229190919548273\n",
      "Gradient for encoder.encoder.3.bias: 1.4117836066862566e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.003072648076340556\n",
      "Gradient for encoder.encoder.4.bias: 0.003107677446678281\n",
      "Gradient for encoder.mean.weight: 0.04460809752345085\n",
      "Gradient for encoder.mean.bias: 0.0026504734996706247\n",
      "Gradient for encoder.log_var.weight: 0.024633510038256645\n",
      "Gradient for encoder.log_var.bias: 0.0016375490231439471\n",
      "Gradient for decoder.decoder.0.weight: 0.011414838023483753\n",
      "Gradient for decoder.decoder.0.bias: 1.0522090143627594e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0005795255419798195\n",
      "Gradient for decoder.decoder.1.bias: 0.00046257241046987474\n",
      "Gradient for decoder.decoder.3.weight: 0.011000094003975391\n",
      "Gradient for decoder.decoder.3.bias: 8.925437472440123e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00047393637942150235\n",
      "Gradient for decoder.decoder.4.bias: 0.00044139186502434313\n",
      "Gradient for decoder.decoder.6.weight: 0.0007073439192026854\n",
      "Gradient for decoder.decoder.6.bias: 4.6558037865906954e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.008531929925084114\n",
      "Gradient for encoder.encoder.0.bias: 1.3520685439305513e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0005283065838739276\n",
      "Gradient for encoder.encoder.1.bias: 0.0005820102524012327\n",
      "Gradient for encoder.encoder.3.weight: 0.011426500044763088\n",
      "Gradient for encoder.encoder.3.bias: 1.5793875929315249e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.002889941679313779\n",
      "Gradient for encoder.encoder.4.bias: 0.003125357674434781\n",
      "Gradient for encoder.mean.weight: 0.04284936562180519\n",
      "Gradient for encoder.mean.bias: 0.0022757945116609335\n",
      "Gradient for encoder.log_var.weight: 0.024846723303198814\n",
      "Gradient for encoder.log_var.bias: 0.0014296643203124404\n",
      "Gradient for decoder.decoder.0.weight: 0.011558950878679752\n",
      "Gradient for decoder.decoder.0.bias: 9.670126505101351e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0006112539558671415\n",
      "Gradient for decoder.decoder.1.bias: 0.0004904004745185375\n",
      "Gradient for decoder.decoder.3.weight: 0.010935298167169094\n",
      "Gradient for decoder.decoder.3.bias: 8.496750525388563e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00042529363417997956\n",
      "Gradient for decoder.decoder.4.bias: 0.0004239451664034277\n",
      "Gradient for decoder.decoder.6.weight: 0.0006822536233812571\n",
      "Gradient for decoder.decoder.6.bias: 4.076413461007178e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.006518910173326731\n",
      "Gradient for encoder.encoder.0.bias: 9.733802305844641e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.0005067016463726759\n",
      "Gradient for encoder.encoder.1.bias: 0.0005513299838639796\n",
      "Gradient for encoder.encoder.3.weight: 0.010781090706586838\n",
      "Gradient for encoder.encoder.3.bias: 1.1356564300069039e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0025907831732183695\n",
      "Gradient for encoder.encoder.4.bias: 0.0023359782062470913\n",
      "Gradient for encoder.mean.weight: 0.035930510610342026\n",
      "Gradient for encoder.mean.bias: 0.0019629455637186766\n",
      "Gradient for encoder.log_var.weight: 0.023541104048490524\n",
      "Gradient for encoder.log_var.bias: 0.0014212640235200524\n",
      "Gradient for decoder.decoder.0.weight: 0.014196965843439102\n",
      "Gradient for decoder.decoder.0.bias: 1.1474826644430891e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0006718615768477321\n",
      "Gradient for decoder.decoder.1.bias: 0.0005669003585353494\n",
      "Gradient for decoder.decoder.3.weight: 0.012792756780982018\n",
      "Gradient for decoder.decoder.3.bias: 1.0070549255614125e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0006598578183911741\n",
      "Gradient for decoder.decoder.4.bias: 0.0006914195255376399\n",
      "Gradient for decoder.decoder.6.weight: 0.000809798832051456\n",
      "Gradient for decoder.decoder.6.bias: 5.594114918494597e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.0058868951164186\n",
      "Gradient for encoder.encoder.0.bias: 9.207285107948326e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.00046096130972728133\n",
      "Gradient for encoder.encoder.1.bias: 0.0005133748636581004\n",
      "Gradient for encoder.encoder.3.weight: 0.010122961364686489\n",
      "Gradient for encoder.encoder.3.bias: 1.1802758770329547e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.002742817159742117\n",
      "Gradient for encoder.encoder.4.bias: 0.002242809161543846\n",
      "Gradient for encoder.mean.weight: 0.03835603594779968\n",
      "Gradient for encoder.mean.bias: 0.0018388908356428146\n",
      "Gradient for encoder.log_var.weight: 0.0203703586012125\n",
      "Gradient for encoder.log_var.bias: 0.0011150084901601076\n",
      "Gradient for decoder.decoder.0.weight: 0.013883141800761223\n",
      "Gradient for decoder.decoder.0.bias: 1.1369524766102757e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.000692596600856632\n",
      "Gradient for decoder.decoder.1.bias: 0.0005542872822843492\n",
      "Gradient for decoder.decoder.3.weight: 0.013352133333683014\n",
      "Gradient for decoder.decoder.3.bias: 1.273030708626166e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0005372323212213814\n",
      "Gradient for decoder.decoder.4.bias: 0.0005035362555645406\n",
      "Gradient for decoder.decoder.6.weight: 0.000672688998747617\n",
      "Gradient for decoder.decoder.6.bias: 3.525123611325398e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.01048407331109047\n",
      "Gradient for encoder.encoder.0.bias: 1.4066535262979851e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0005714906146749854\n",
      "Gradient for encoder.encoder.1.bias: 0.0005675078136846423\n",
      "Gradient for encoder.encoder.3.weight: 0.012263360433280468\n",
      "Gradient for encoder.encoder.3.bias: 1.3474125981627338e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0030623653437942266\n",
      "Gradient for encoder.encoder.4.bias: 0.002711550099775195\n",
      "Gradient for encoder.mean.weight: 0.041096579283475876\n",
      "Gradient for encoder.mean.bias: 0.002076192991808057\n",
      "Gradient for encoder.log_var.weight: 0.02288072369992733\n",
      "Gradient for encoder.log_var.bias: 0.001368259429000318\n",
      "Gradient for decoder.decoder.0.weight: 0.012054982595145702\n",
      "Gradient for decoder.decoder.0.bias: 1.0256594185076295e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.000669900153297931\n",
      "Gradient for decoder.decoder.1.bias: 0.00051428860751912\n",
      "Gradient for decoder.decoder.3.weight: 0.011634319089353085\n",
      "Gradient for decoder.decoder.3.bias: 8.8900199701758e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00044790180982090533\n",
      "Gradient for decoder.decoder.4.bias: 0.000452006293926388\n",
      "Gradient for decoder.decoder.6.weight: 0.0006947641959413886\n",
      "Gradient for decoder.decoder.6.bias: 4.04164420615416e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.006439555436372757\n",
      "Gradient for encoder.encoder.0.bias: 1.132899503375473e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0005379821523092687\n",
      "Gradient for encoder.encoder.1.bias: 0.000655600568279624\n",
      "Gradient for encoder.encoder.3.weight: 0.011854062788188457\n",
      "Gradient for encoder.encoder.3.bias: 1.3675013899039357e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.003052121726796031\n",
      "Gradient for encoder.encoder.4.bias: 0.0031583786476403475\n",
      "Gradient for encoder.mean.weight: 0.042837195098400116\n",
      "Gradient for encoder.mean.bias: 0.0027896135579794645\n",
      "Gradient for encoder.log_var.weight: 0.024136947467923164\n",
      "Gradient for encoder.log_var.bias: 0.0014769213739782572\n",
      "Gradient for decoder.decoder.0.weight: 0.011522122658789158\n",
      "Gradient for decoder.decoder.0.bias: 9.171436526900223e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005792083102278411\n",
      "Gradient for decoder.decoder.1.bias: 0.00045166705967858434\n",
      "Gradient for decoder.decoder.3.weight: 0.010773962363600731\n",
      "Gradient for decoder.decoder.3.bias: 7.872162643973724e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00039663739153183997\n",
      "Gradient for decoder.decoder.4.bias: 0.00035951516474597156\n",
      "Gradient for decoder.decoder.6.weight: 0.0006791453342884779\n",
      "Gradient for decoder.decoder.6.bias: 4.2650233808672056e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training VAE Epoch:  62%|██████▏   | 49/79 [00:00<00:00, 69.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient for encoder.encoder.0.weight: 0.00930961687117815\n",
      "Gradient for encoder.encoder.0.bias: 1.5714384654641478e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0005806225235573947\n",
      "Gradient for encoder.encoder.1.bias: 0.0005280733457766473\n",
      "Gradient for encoder.encoder.3.weight: 0.012386929243803024\n",
      "Gradient for encoder.encoder.3.bias: 1.5720377777306282e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.003096327418461442\n",
      "Gradient for encoder.encoder.4.bias: 0.00310303526930511\n",
      "Gradient for encoder.mean.weight: 0.04409055411815643\n",
      "Gradient for encoder.mean.bias: 0.0023333458229899406\n",
      "Gradient for encoder.log_var.weight: 0.024089917540550232\n",
      "Gradient for encoder.log_var.bias: 0.0013308263150975108\n",
      "Gradient for decoder.decoder.0.weight: 0.00872029084712267\n",
      "Gradient for decoder.decoder.0.bias: 7.609465835223261e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.00041472181328572333\n",
      "Gradient for decoder.decoder.1.bias: 0.0003360032569617033\n",
      "Gradient for decoder.decoder.3.weight: 0.008072900585830212\n",
      "Gradient for decoder.decoder.3.bias: 8.315506616618507e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00044197918032296\n",
      "Gradient for decoder.decoder.4.bias: 0.0005062278360128403\n",
      "Gradient for decoder.decoder.6.weight: 0.0006488732760772109\n",
      "Gradient for decoder.decoder.6.bias: 3.950909376726486e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.006071379873901606\n",
      "Gradient for encoder.encoder.0.bias: 1.1579727628163727e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0005436928477138281\n",
      "Gradient for encoder.encoder.1.bias: 0.000668465974740684\n",
      "Gradient for encoder.encoder.3.weight: 0.011508741416037083\n",
      "Gradient for encoder.encoder.3.bias: 1.206945238196866e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0031070972327142954\n",
      "Gradient for encoder.encoder.4.bias: 0.0026768853422254324\n",
      "Gradient for encoder.mean.weight: 0.046859003603458405\n",
      "Gradient for encoder.mean.bias: 0.002081396523863077\n",
      "Gradient for encoder.log_var.weight: 0.024627143517136574\n",
      "Gradient for encoder.log_var.bias: 0.001123933820053935\n",
      "Gradient for decoder.decoder.0.weight: 0.011432192288339138\n",
      "Gradient for decoder.decoder.0.bias: 9.931139244301335e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005824978579767048\n",
      "Gradient for decoder.decoder.1.bias: 0.000477251538541168\n",
      "Gradient for decoder.decoder.3.weight: 0.011098484508693218\n",
      "Gradient for decoder.decoder.3.bias: 1.254845255482806e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0007497163023799658\n",
      "Gradient for decoder.decoder.4.bias: 0.000897920283023268\n",
      "Gradient for decoder.decoder.6.weight: 0.0007497653132304549\n",
      "Gradient for decoder.decoder.6.bias: 6.019663123879582e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training VAE Epoch:  72%|███████▏  | 57/79 [00:00<00:00, 71.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient for encoder.encoder.0.weight: 0.010029724799096584\n",
      "Gradient for encoder.encoder.0.bias: 1.423612790152351e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0006582398782484233\n",
      "Gradient for encoder.encoder.1.bias: 0.0006115936557762325\n",
      "Gradient for encoder.encoder.3.weight: 0.013760394416749477\n",
      "Gradient for encoder.encoder.3.bias: 1.2169676377737915e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.002265827264636755\n",
      "Gradient for encoder.encoder.4.bias: 0.001823310973122716\n",
      "Gradient for encoder.mean.weight: 0.03581470996141434\n",
      "Gradient for encoder.mean.bias: 0.0011435194173827767\n",
      "Gradient for encoder.log_var.weight: 0.01694471575319767\n",
      "Gradient for encoder.log_var.bias: 0.0008009289740584791\n",
      "Gradient for decoder.decoder.0.weight: 0.013113600201904774\n",
      "Gradient for decoder.decoder.0.bias: 1.1346658335131821e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0006522551993839443\n",
      "Gradient for decoder.decoder.1.bias: 0.0005033959751017392\n",
      "Gradient for decoder.decoder.3.weight: 0.012691441923379898\n",
      "Gradient for decoder.decoder.3.bias: 1.1394502702488651e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0007455258746631444\n",
      "Gradient for decoder.decoder.4.bias: 0.0008180606528185308\n",
      "Gradient for decoder.decoder.6.weight: 0.0008434844785369933\n",
      "Gradient for decoder.decoder.6.bias: 5.815863187308423e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.005599222145974636\n",
      "Gradient for encoder.encoder.0.bias: 8.812506280264643e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.0003872864763252437\n",
      "Gradient for encoder.encoder.1.bias: 0.0004553792532533407\n",
      "Gradient for encoder.encoder.3.weight: 0.008156226016581059\n",
      "Gradient for encoder.encoder.3.bias: 1.2667822346656976e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0033085369504988194\n",
      "Gradient for encoder.encoder.4.bias: 0.003040476469323039\n",
      "Gradient for encoder.mean.weight: 0.04609786346554756\n",
      "Gradient for encoder.mean.bias: 0.002175946719944477\n",
      "Gradient for encoder.log_var.weight: 0.02601390704512596\n",
      "Gradient for encoder.log_var.bias: 0.001189150265417993\n",
      "Gradient for decoder.decoder.0.weight: 0.013012516312301159\n",
      "Gradient for decoder.decoder.0.bias: 1.087930787124769e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0006210988503880799\n",
      "Gradient for decoder.decoder.1.bias: 0.0005586629849858582\n",
      "Gradient for decoder.decoder.3.weight: 0.011980557814240456\n",
      "Gradient for decoder.decoder.3.bias: 9.715290377743102e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.000543451402336359\n",
      "Gradient for decoder.decoder.4.bias: 0.0005173294921405613\n",
      "Gradient for decoder.decoder.6.weight: 0.0006841575959697366\n",
      "Gradient for decoder.decoder.6.bias: 3.966897929785773e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.006559351924806833\n",
      "Gradient for encoder.encoder.0.bias: 1.0848179993194762e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.00047443233779631555\n",
      "Gradient for encoder.encoder.1.bias: 0.00046835211105644703\n",
      "Gradient for encoder.encoder.3.weight: 0.010599895380437374\n",
      "Gradient for encoder.encoder.3.bias: 1.2072086386094583e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0027730290312319994\n",
      "Gradient for encoder.encoder.4.bias: 0.0021901170257478952\n",
      "Gradient for encoder.mean.weight: 0.03816184028983116\n",
      "Gradient for encoder.mean.bias: 0.001619323855265975\n",
      "Gradient for encoder.log_var.weight: 0.02042977325618267\n",
      "Gradient for encoder.log_var.bias: 0.0009694732143543661\n",
      "Gradient for decoder.decoder.0.weight: 0.010727941989898682\n",
      "Gradient for decoder.decoder.0.bias: 8.565215203759635e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005465190624818206\n",
      "Gradient for decoder.decoder.1.bias: 0.000416574883274734\n",
      "Gradient for decoder.decoder.3.weight: 0.009965886361896992\n",
      "Gradient for decoder.decoder.3.bias: 1.1054369225549365e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0006526182987727225\n",
      "Gradient for decoder.decoder.4.bias: 0.0008143152226693928\n",
      "Gradient for decoder.decoder.6.weight: 0.0007302372832782567\n",
      "Gradient for decoder.decoder.6.bias: 5.64543079235591e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.005857429001480341\n",
      "Gradient for encoder.encoder.0.bias: 1.0620472383482404e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0004398196469992399\n",
      "Gradient for encoder.encoder.1.bias: 0.0005486926529556513\n",
      "Gradient for encoder.encoder.3.weight: 0.010123160667717457\n",
      "Gradient for encoder.encoder.3.bias: 1.1144123124307015e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.002626876812428236\n",
      "Gradient for encoder.encoder.4.bias: 0.0018770473543554544\n",
      "Gradient for encoder.mean.weight: 0.040237993001937866\n",
      "Gradient for encoder.mean.bias: 0.0011988761834800243\n",
      "Gradient for encoder.log_var.weight: 0.022239360958337784\n",
      "Gradient for encoder.log_var.bias: 0.0008335824823006988\n",
      "Gradient for decoder.decoder.0.weight: 0.014566406607627869\n",
      "Gradient for decoder.decoder.0.bias: 1.2981538066725307e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0006355927907861769\n",
      "Gradient for decoder.decoder.1.bias: 0.000565540452953428\n",
      "Gradient for decoder.decoder.3.weight: 0.013103456236422062\n",
      "Gradient for decoder.decoder.3.bias: 1.027530283082001e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.00046257508802227676\n",
      "Gradient for decoder.decoder.4.bias: 0.00043206935515627265\n",
      "Gradient for decoder.decoder.6.weight: 0.0007131146849133074\n",
      "Gradient for decoder.decoder.6.bias: 4.5908629545010626e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.005351994186639786\n",
      "Gradient for encoder.encoder.0.bias: 1.0135558191348704e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0004137975920457393\n",
      "Gradient for encoder.encoder.1.bias: 0.0005218250444158912\n",
      "Gradient for encoder.encoder.3.weight: 0.009261402301490307\n",
      "Gradient for encoder.encoder.3.bias: 1.0172621772719381e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0025475339498370886\n",
      "Gradient for encoder.encoder.4.bias: 0.0016028218669816852\n",
      "Gradient for encoder.mean.weight: 0.039838217198848724\n",
      "Gradient for encoder.mean.bias: 0.0012087151408195496\n",
      "Gradient for encoder.log_var.weight: 0.02568560279905796\n",
      "Gradient for encoder.log_var.bias: 0.0009269368019886315\n",
      "Gradient for decoder.decoder.0.weight: 0.012402459047734737\n",
      "Gradient for decoder.decoder.0.bias: 1.0359154506422996e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0005836521158926189\n",
      "Gradient for decoder.decoder.1.bias: 0.00048543853336013854\n",
      "Gradient for decoder.decoder.3.weight: 0.011399595998227596\n",
      "Gradient for decoder.decoder.3.bias: 8.954114533166191e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0004574712074827403\n",
      "Gradient for decoder.decoder.4.bias: 0.0005010933382436633\n",
      "Gradient for decoder.decoder.6.weight: 0.0006384848966263235\n",
      "Gradient for decoder.decoder.6.bias: 3.9526057662442327e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.013002301566302776\n",
      "Gradient for encoder.encoder.0.bias: 2.3130086387879167e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0007834052667021751\n",
      "Gradient for encoder.encoder.1.bias: 0.0007549775764346123\n",
      "Gradient for encoder.encoder.3.weight: 0.016649754717946053\n",
      "Gradient for encoder.encoder.3.bias: 1.7862224199749477e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0042019197717309\n",
      "Gradient for encoder.encoder.4.bias: 0.0035610636696219444\n",
      "Gradient for encoder.mean.weight: 0.059019699692726135\n",
      "Gradient for encoder.mean.bias: 0.002407737774774432\n",
      "Gradient for encoder.log_var.weight: 0.03411959484219551\n",
      "Gradient for encoder.log_var.bias: 0.0016059563495218754\n",
      "Gradient for decoder.decoder.0.weight: 0.008462616242468357\n",
      "Gradient for decoder.decoder.0.bias: 7.103462262847415e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.00045134281390346587\n",
      "Gradient for decoder.decoder.1.bias: 0.0003405116149224341\n",
      "Gradient for decoder.decoder.3.weight: 0.00799501035362482\n",
      "Gradient for decoder.decoder.3.bias: 1.0886629098205702e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0008595443214289844\n",
      "Gradient for decoder.decoder.4.bias: 0.0010636168299242854\n",
      "Gradient for decoder.decoder.6.weight: 0.0007987167336978018\n",
      "Gradient for decoder.decoder.6.bias: 6.778356328140944e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.0052816616371273994\n",
      "Gradient for encoder.encoder.0.bias: 9.652928630032864e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.0003357742971275002\n",
      "Gradient for encoder.encoder.1.bias: 0.0004310640797484666\n",
      "Gradient for encoder.encoder.3.weight: 0.007168604526668787\n",
      "Gradient for encoder.encoder.3.bias: 9.969771536111338e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.0024745448026806116\n",
      "Gradient for encoder.encoder.4.bias: 0.0018144618952646852\n",
      "Gradient for encoder.mean.weight: 0.03638947010040283\n",
      "Gradient for encoder.mean.bias: 0.0012892469530925155\n",
      "Gradient for encoder.log_var.weight: 0.018233856186270714\n",
      "Gradient for encoder.log_var.bias: 0.0008494268404319882\n",
      "Gradient for decoder.decoder.0.weight: 0.012749380432069302\n",
      "Gradient for decoder.decoder.0.bias: 1.0848506815097636e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0006389409536495805\n",
      "Gradient for decoder.decoder.1.bias: 0.0005454508354887366\n",
      "Gradient for decoder.decoder.3.weight: 0.012186847627162933\n",
      "Gradient for decoder.decoder.3.bias: 9.420340202348498e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00048192995018325746\n",
      "Gradient for decoder.decoder.4.bias: 0.0004891845746897161\n",
      "Gradient for decoder.decoder.6.weight: 0.0006642848020419478\n",
      "Gradient for decoder.decoder.6.bias: 3.823450970230624e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.009096627123653889\n",
      "Gradient for encoder.encoder.0.bias: 1.7660045301126637e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.00045814752229489386\n",
      "Gradient for encoder.encoder.1.bias: 0.0004444731748662889\n",
      "Gradient for encoder.encoder.3.weight: 0.010414245538413525\n",
      "Gradient for encoder.encoder.3.bias: 1.3436553258916462e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0026906330604106188\n",
      "Gradient for encoder.encoder.4.bias: 0.002491647843271494\n",
      "Gradient for encoder.mean.weight: 0.03694687783718109\n",
      "Gradient for encoder.mean.bias: 0.0017093745991587639\n",
      "Gradient for encoder.log_var.weight: 0.020886749029159546\n",
      "Gradient for encoder.log_var.bias: 0.001085677184164524\n",
      "Gradient for decoder.decoder.0.weight: 0.009223654866218567\n",
      "Gradient for decoder.decoder.0.bias: 7.818191927189133e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.00046341362758539617\n",
      "Gradient for decoder.decoder.1.bias: 0.0003851189976558089\n",
      "Gradient for decoder.decoder.3.weight: 0.008789503946900368\n",
      "Gradient for decoder.decoder.3.bias: 1.099508054047682e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0007538608624599874\n",
      "Gradient for decoder.decoder.4.bias: 0.0009469538927078247\n",
      "Gradient for decoder.decoder.6.weight: 0.000725587538909167\n",
      "Gradient for decoder.decoder.6.bias: 5.8602960052667186e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.00496465852484107\n",
      "Gradient for encoder.encoder.0.bias: 8.516286634230319e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.0004057210171595216\n",
      "Gradient for encoder.encoder.1.bias: 0.0005319766933098435\n",
      "Gradient for encoder.encoder.3.weight: 0.008893950842320919\n",
      "Gradient for encoder.encoder.3.bias: 1.0978683240292497e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0026223415043205023\n",
      "Gradient for encoder.encoder.4.bias: 0.0018571702530607581\n",
      "Gradient for encoder.mean.weight: 0.038210608065128326\n",
      "Gradient for encoder.mean.bias: 0.001347822486422956\n",
      "Gradient for encoder.log_var.weight: 0.02112860418856144\n",
      "Gradient for encoder.log_var.bias: 0.0008628054056316614\n",
      "Gradient for decoder.decoder.0.weight: 0.014110543765127659\n",
      "Gradient for decoder.decoder.0.bias: 1.118005896194596e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0007452895515598357\n",
      "Gradient for decoder.decoder.1.bias: 0.0005553608061745763\n",
      "Gradient for decoder.decoder.3.weight: 0.013908535242080688\n",
      "Gradient for decoder.decoder.3.bias: 1.0547981932340633e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0004843389615416527\n",
      "Gradient for decoder.decoder.4.bias: 0.0004193025815766305\n",
      "Gradient for decoder.decoder.6.weight: 0.000677269883453846\n",
      "Gradient for decoder.decoder.6.bias: 3.7570738641079515e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.005875172093510628\n",
      "Gradient for encoder.encoder.0.bias: 8.676983610789168e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.0004279475542716682\n",
      "Gradient for encoder.encoder.1.bias: 0.0005694317515008152\n",
      "Gradient for encoder.encoder.3.weight: 0.00956754107028246\n",
      "Gradient for encoder.encoder.3.bias: 1.0689259200002965e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0027426916640251875\n",
      "Gradient for encoder.encoder.4.bias: 0.0019548931159079075\n",
      "Gradient for encoder.mean.weight: 0.04107436165213585\n",
      "Gradient for encoder.mean.bias: 0.0014452586183324456\n",
      "Gradient for encoder.log_var.weight: 0.02166510745882988\n",
      "Gradient for encoder.log_var.bias: 0.0008605903713032603\n",
      "Gradient for decoder.decoder.0.weight: 0.015002558939158916\n",
      "Gradient for decoder.decoder.0.bias: 1.3666273668277995e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0006626342656090856\n",
      "Gradient for decoder.decoder.1.bias: 0.0006004940951243043\n",
      "Gradient for decoder.decoder.3.weight: 0.013432551175355911\n",
      "Gradient for decoder.decoder.3.bias: 1.2881315458734832e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.000690479704644531\n",
      "Gradient for decoder.decoder.4.bias: 0.0007537594065070152\n",
      "Gradient for decoder.decoder.6.weight: 0.0007716494728811085\n",
      "Gradient for decoder.decoder.6.bias: 4.9957543524215e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.006703576538711786\n",
      "Gradient for encoder.encoder.0.bias: 1.1533621280257478e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0004716205003205687\n",
      "Gradient for encoder.encoder.1.bias: 0.00047638503019697964\n",
      "Gradient for encoder.encoder.3.weight: 0.011334815993905067\n",
      "Gradient for encoder.encoder.3.bias: 1.198311033734356e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.003422873094677925\n",
      "Gradient for encoder.encoder.4.bias: 0.00236756750382483\n",
      "Gradient for encoder.mean.weight: 0.044931624084711075\n",
      "Gradient for encoder.mean.bias: 0.0018075950210914016\n",
      "Gradient for encoder.log_var.weight: 0.025218108668923378\n",
      "Gradient for encoder.log_var.bias: 0.0010281205177307129\n",
      "Gradient for decoder.decoder.0.weight: 0.012600318528711796\n",
      "Gradient for decoder.decoder.0.bias: 1.1078815642662221e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0006079199956730008\n",
      "Gradient for decoder.decoder.1.bias: 0.0005254119751043618\n",
      "Gradient for decoder.decoder.3.weight: 0.011836816556751728\n",
      "Gradient for decoder.decoder.3.bias: 9.251349686323351e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00042027534800581634\n",
      "Gradient for decoder.decoder.4.bias: 0.00036994152469560504\n",
      "Gradient for decoder.decoder.6.weight: 0.0006863955641165376\n",
      "Gradient for decoder.decoder.6.bias: 4.153914414928295e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.012746664695441723\n",
      "Gradient for encoder.encoder.0.bias: 2.180937895557289e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.000744588440284133\n",
      "Gradient for encoder.encoder.1.bias: 0.0006475859554484487\n",
      "Gradient for encoder.encoder.3.weight: 0.016069462522864342\n",
      "Gradient for encoder.encoder.3.bias: 1.7155919740385883e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.003446224145591259\n",
      "Gradient for encoder.encoder.4.bias: 0.0030400031246244907\n",
      "Gradient for encoder.mean.weight: 0.04652886092662811\n",
      "Gradient for encoder.mean.bias: 0.002107141073793173\n",
      "Gradient for encoder.log_var.weight: 0.027952110394835472\n",
      "Gradient for encoder.log_var.bias: 0.0012985016219317913\n",
      "Gradient for decoder.decoder.0.weight: 0.00867399200797081\n",
      "Gradient for decoder.decoder.0.bias: 8.218906111245872e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0004282501176930964\n",
      "Gradient for decoder.decoder.1.bias: 0.0003472149255685508\n",
      "Gradient for decoder.decoder.3.weight: 0.008113906718790531\n",
      "Gradient for decoder.decoder.3.bias: 8.489963593261152e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0004320296866353601\n",
      "Gradient for decoder.decoder.4.bias: 0.000507166376337409\n",
      "Gradient for decoder.decoder.6.weight: 0.0006195820751599967\n",
      "Gradient for decoder.decoder.6.bias: 3.829565685009584e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.008789686486124992\n",
      "Gradient for encoder.encoder.0.bias: 1.519764002144708e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0005659580347128212\n",
      "Gradient for encoder.encoder.1.bias: 0.000634553434792906\n",
      "Gradient for encoder.encoder.3.weight: 0.011612016707658768\n",
      "Gradient for encoder.encoder.3.bias: 1.2166537222135787e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.002641946543008089\n",
      "Gradient for encoder.encoder.4.bias: 0.002203403739258647\n",
      "Gradient for encoder.mean.weight: 0.03785018250346184\n",
      "Gradient for encoder.mean.bias: 0.00157434050925076\n",
      "Gradient for encoder.log_var.weight: 0.02041563205420971\n",
      "Gradient for encoder.log_var.bias: 0.0009377187234349549\n",
      "Gradient for decoder.decoder.0.weight: 0.01061159186065197\n",
      "Gradient for decoder.decoder.0.bias: 8.94638876869358e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005430986057035625\n",
      "Gradient for decoder.decoder.1.bias: 0.00044535219785757363\n",
      "Gradient for decoder.decoder.3.weight: 0.010170426219701767\n",
      "Gradient for decoder.decoder.3.bias: 8.700928172400424e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00048089431948028505\n",
      "Gradient for decoder.decoder.4.bias: 0.0005333073204383254\n",
      "Gradient for decoder.decoder.6.weight: 0.0006645509856753051\n",
      "Gradient for decoder.decoder.6.bias: 4.317265847930685e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.004582798574119806\n",
      "Gradient for encoder.encoder.0.bias: 7.607056477787477e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.0003769119211938232\n",
      "Gradient for encoder.encoder.1.bias: 0.0004251714562997222\n",
      "Gradient for encoder.encoder.3.weight: 0.00860344897955656\n",
      "Gradient for encoder.encoder.3.bias: 1.1438155977927522e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.003636426292359829\n",
      "Gradient for encoder.encoder.4.bias: 0.0023615544196218252\n",
      "Gradient for encoder.mean.weight: 0.05405273661017418\n",
      "Gradient for encoder.mean.bias: 0.001523809041827917\n",
      "Gradient for encoder.log_var.weight: 0.031869351863861084\n",
      "Gradient for encoder.log_var.bias: 0.0008895020582713187\n",
      "Gradient for decoder.decoder.0.weight: 0.013699553906917572\n",
      "Gradient for decoder.decoder.0.bias: 1.251217046638331e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0006930663366802037\n",
      "Gradient for decoder.decoder.1.bias: 0.0005793588934466243\n",
      "Gradient for decoder.decoder.3.weight: 0.01316296961158514\n",
      "Gradient for decoder.decoder.3.bias: 1.0630564484248595e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0004723868041764945\n",
      "Gradient for decoder.decoder.4.bias: 0.00041914687608368695\n",
      "Gradient for decoder.decoder.6.weight: 0.0006722747348248959\n",
      "Gradient for decoder.decoder.6.bias: 3.939519592677243e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.009686801582574844\n",
      "Gradient for encoder.encoder.0.bias: 1.4156608177384733e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0006115682190284133\n",
      "Gradient for encoder.encoder.1.bias: 0.0005411611055023968\n",
      "Gradient for encoder.encoder.3.weight: 0.013979529030621052\n",
      "Gradient for encoder.encoder.3.bias: 1.3958077749176567e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.003242265433073044\n",
      "Gradient for encoder.encoder.4.bias: 0.00247927475720644\n",
      "Gradient for encoder.mean.weight: 0.044673528522253036\n",
      "Gradient for encoder.mean.bias: 0.0014986494788900018\n",
      "Gradient for encoder.log_var.weight: 0.022153157740831375\n",
      "Gradient for encoder.log_var.bias: 0.0009143356583081186\n",
      "Gradient for decoder.decoder.0.weight: 0.010289369150996208\n",
      "Gradient for decoder.decoder.0.bias: 9.069181516885294e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0004948555724695325\n",
      "Gradient for decoder.decoder.1.bias: 0.00038616484380327165\n",
      "Gradient for decoder.decoder.3.weight: 0.009605019353330135\n",
      "Gradient for decoder.decoder.3.bias: 7.768191645496358e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0003671168233267963\n",
      "Gradient for decoder.decoder.4.bias: 0.00032758465385995805\n",
      "Gradient for decoder.decoder.6.weight: 0.0006658881902694702\n",
      "Gradient for decoder.decoder.6.bias: 3.6796318454435095e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.005056820809841156\n",
      "Gradient for encoder.encoder.0.bias: 9.117468065256151e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.00043229959555901587\n",
      "Gradient for encoder.encoder.1.bias: 0.0005718638421967626\n",
      "Gradient for encoder.encoder.3.weight: 0.009918201714754105\n",
      "Gradient for encoder.encoder.3.bias: 1.096034304981508e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.003360506845638156\n",
      "Gradient for encoder.encoder.4.bias: 0.0023683863691985607\n",
      "Gradient for encoder.mean.weight: 0.044644106179475784\n",
      "Gradient for encoder.mean.bias: 0.0017004079418256879\n",
      "Gradient for encoder.log_var.weight: 0.027901312336325645\n",
      "Gradient for encoder.log_var.bias: 0.0011956827947869897\n",
      "Gradient for decoder.decoder.0.weight: 0.014804203063249588\n",
      "Gradient for decoder.decoder.0.bias: 1.3397095932621284e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0006938105216249824\n",
      "Gradient for decoder.decoder.1.bias: 0.0006052071694284678\n",
      "Gradient for decoder.decoder.3.weight: 0.01359571609646082\n",
      "Gradient for decoder.decoder.3.bias: 1.2745851596385194e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0006958584999665618\n",
      "Gradient for decoder.decoder.4.bias: 0.0007147793658077717\n",
      "Gradient for decoder.decoder.6.weight: 0.0007234241929836571\n",
      "Gradient for decoder.decoder.6.bias: 4.312251985538751e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training VAE Epoch:  92%|█████████▏| 73/79 [00:01<00:00, 74.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient for encoder.encoder.0.weight: 0.006719599012285471\n",
      "Gradient for encoder.encoder.0.bias: 1.2159055880200942e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0004255380481481552\n",
      "Gradient for encoder.encoder.1.bias: 0.0003546876832842827\n",
      "Gradient for encoder.encoder.3.weight: 0.008849738165736198\n",
      "Gradient for encoder.encoder.3.bias: 1.1398589710998053e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0022741251159459352\n",
      "Gradient for encoder.encoder.4.bias: 0.0017429693834856153\n",
      "Gradient for encoder.mean.weight: 0.032258424907922745\n",
      "Gradient for encoder.mean.bias: 0.001392947742715478\n",
      "Gradient for encoder.log_var.weight: 0.018820704892277718\n",
      "Gradient for encoder.log_var.bias: 0.0008189318468794227\n",
      "Gradient for decoder.decoder.0.weight: 0.01100747287273407\n",
      "Gradient for decoder.decoder.0.bias: 8.879647711568239e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005269186804071069\n",
      "Gradient for decoder.decoder.1.bias: 0.0004339854058343917\n",
      "Gradient for decoder.decoder.3.weight: 0.0101109454408288\n",
      "Gradient for decoder.decoder.3.bias: 8.200251588874607e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0003701060195453465\n",
      "Gradient for decoder.decoder.4.bias: 0.0003275734488852322\n",
      "Gradient for decoder.decoder.6.weight: 0.0005965795717202127\n",
      "Gradient for decoder.decoder.6.bias: 3.2360712793888524e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.009539778344333172\n",
      "Gradient for encoder.encoder.0.bias: 1.4996755573482012e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.000572033051867038\n",
      "Gradient for encoder.encoder.1.bias: 0.0006691832677461207\n",
      "Gradient for encoder.encoder.3.weight: 0.011468561366200447\n",
      "Gradient for encoder.encoder.3.bias: 1.3248258046161254e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.00277907052077353\n",
      "Gradient for encoder.encoder.4.bias: 0.0021626988891512156\n",
      "Gradient for encoder.mean.weight: 0.040616925805807114\n",
      "Gradient for encoder.mean.bias: 0.0018968981457874179\n",
      "Gradient for encoder.log_var.weight: 0.02027830481529236\n",
      "Gradient for encoder.log_var.bias: 0.0010769992368295789\n",
      "Gradient for decoder.decoder.0.weight: 0.009745295159518719\n",
      "Gradient for decoder.decoder.0.bias: 8.205017915097201e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.000475465931231156\n",
      "Gradient for decoder.decoder.1.bias: 0.00038754395791329443\n",
      "Gradient for decoder.decoder.3.weight: 0.009191121906042099\n",
      "Gradient for decoder.decoder.3.bias: 1.0206526596112653e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0006921548629179597\n",
      "Gradient for decoder.decoder.4.bias: 0.0008482821867801249\n",
      "Gradient for decoder.decoder.6.weight: 0.0006900718435645103\n",
      "Gradient for decoder.decoder.6.bias: 5.425604831543751e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.007371930871158838\n",
      "Gradient for encoder.encoder.0.bias: 1.154208412873503e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0004533344763331115\n",
      "Gradient for encoder.encoder.1.bias: 0.0004797895671799779\n",
      "Gradient for encoder.encoder.3.weight: 0.010375840589404106\n",
      "Gradient for encoder.encoder.3.bias: 1.148531963979238e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0028479956090450287\n",
      "Gradient for encoder.encoder.4.bias: 0.0020028918515890837\n",
      "Gradient for encoder.mean.weight: 0.04177311807870865\n",
      "Gradient for encoder.mean.bias: 0.0015204729279503226\n",
      "Gradient for encoder.log_var.weight: 0.01852332055568695\n",
      "Gradient for encoder.log_var.bias: 0.0009050744120031595\n",
      "Gradient for decoder.decoder.0.weight: 0.011598884128034115\n",
      "Gradient for decoder.decoder.0.bias: 9.139566187199577e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005669870297424495\n",
      "Gradient for decoder.decoder.1.bias: 0.0004852543643210083\n",
      "Gradient for decoder.decoder.3.weight: 0.011120819486677647\n",
      "Gradient for decoder.decoder.3.bias: 9.171900045013004e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00042327182018198073\n",
      "Gradient for decoder.decoder.4.bias: 0.000372660142602399\n",
      "Gradient for decoder.decoder.6.weight: 0.0006333963247016072\n",
      "Gradient for decoder.decoder.6.bias: 3.1342002330347896e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.00971777830272913\n",
      "Gradient for encoder.encoder.0.bias: 1.5709751208237144e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0005359041388146579\n",
      "Gradient for encoder.encoder.1.bias: 0.0005051445332355797\n",
      "Gradient for encoder.encoder.3.weight: 0.011749934405088425\n",
      "Gradient for encoder.encoder.3.bias: 1.2439735352920422e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0024077659472823143\n",
      "Gradient for encoder.encoder.4.bias: 0.001973599661141634\n",
      "Gradient for encoder.mean.weight: 0.034588079899549484\n",
      "Gradient for encoder.mean.bias: 0.0014379043132066727\n",
      "Gradient for encoder.log_var.weight: 0.017893169075250626\n",
      "Gradient for encoder.log_var.bias: 0.0008540546405129135\n",
      "Gradient for decoder.decoder.0.weight: 0.010202446021139622\n",
      "Gradient for decoder.decoder.0.bias: 8.639855497705184e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.00047639780677855015\n",
      "Gradient for decoder.decoder.1.bias: 0.00039697359898127615\n",
      "Gradient for decoder.decoder.3.weight: 0.009601706638932228\n",
      "Gradient for decoder.decoder.3.bias: 8.229458781094934e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0003903521574102342\n",
      "Gradient for decoder.decoder.4.bias: 0.0003957238222938031\n",
      "Gradient for decoder.decoder.6.weight: 0.0006214114255271852\n",
      "Gradient for decoder.decoder.6.bias: 3.3245534723391756e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.005847027990967035\n",
      "Gradient for encoder.encoder.0.bias: 9.813961275584315e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.00037239972152747214\n",
      "Gradient for encoder.encoder.1.bias: 0.0004154586640652269\n",
      "Gradient for encoder.encoder.3.weight: 0.008225641213357449\n",
      "Gradient for encoder.encoder.3.bias: 1.0518552001625991e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0024302720557898283\n",
      "Gradient for encoder.encoder.4.bias: 0.0018500786973163486\n",
      "Gradient for encoder.mean.weight: 0.03691399469971657\n",
      "Gradient for encoder.mean.bias: 0.0013990516308695078\n",
      "Gradient for encoder.log_var.weight: 0.01859857328236103\n",
      "Gradient for encoder.log_var.bias: 0.0008275482687167823\n",
      "Gradient for decoder.decoder.0.weight: 0.013861770741641521\n",
      "Gradient for decoder.decoder.0.bias: 1.2743853194940868e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0006538886809721589\n",
      "Gradient for decoder.decoder.1.bias: 0.0005718111642636359\n",
      "Gradient for decoder.decoder.3.weight: 0.012888738885521889\n",
      "Gradient for decoder.decoder.3.bias: 1.2997947163029266e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0005768701666966081\n",
      "Gradient for decoder.decoder.4.bias: 0.0005867484724149108\n",
      "Gradient for decoder.decoder.6.weight: 0.0007167405565269291\n",
      "Gradient for decoder.decoder.6.bias: 4.514035754255019e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.006200884003192186\n",
      "Gradient for encoder.encoder.0.bias: 1.06956292780791e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.00043045569327659905\n",
      "Gradient for encoder.encoder.1.bias: 0.00045623554615303874\n",
      "Gradient for encoder.encoder.3.weight: 0.009422652423381805\n",
      "Gradient for encoder.encoder.3.bias: 1.126388149419455e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0028786957263946533\n",
      "Gradient for encoder.encoder.4.bias: 0.002094532595947385\n",
      "Gradient for encoder.mean.weight: 0.03946458175778389\n",
      "Gradient for encoder.mean.bias: 0.0015184219228103757\n",
      "Gradient for encoder.log_var.weight: 0.022027991712093353\n",
      "Gradient for encoder.log_var.bias: 0.0010282424045726657\n",
      "Gradient for decoder.decoder.0.weight: 0.012090155854821205\n",
      "Gradient for decoder.decoder.0.bias: 9.611178519719488e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0006219289498403668\n",
      "Gradient for decoder.decoder.1.bias: 0.0004792556574102491\n",
      "Gradient for decoder.decoder.3.weight: 0.01131353247910738\n",
      "Gradient for decoder.decoder.3.bias: 9.586686305906866e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00042064054287038743\n",
      "Gradient for decoder.decoder.4.bias: 0.00040758776594884694\n",
      "Gradient for decoder.decoder.6.weight: 0.000642797676846385\n",
      "Gradient for decoder.decoder.6.bias: 4.0432551031699404e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.008421861566603184\n",
      "Gradient for encoder.encoder.0.bias: 1.2663362546072587e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0004889772390015423\n",
      "Gradient for encoder.encoder.1.bias: 0.0005453766789287329\n",
      "Gradient for encoder.encoder.3.weight: 0.010216929018497467\n",
      "Gradient for encoder.encoder.3.bias: 1.2069280297399843e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.002593808574602008\n",
      "Gradient for encoder.encoder.4.bias: 0.0017601610161364079\n",
      "Gradient for encoder.mean.weight: 0.03582719340920448\n",
      "Gradient for encoder.mean.bias: 0.001244286191649735\n",
      "Gradient for encoder.log_var.weight: 0.021158622577786446\n",
      "Gradient for encoder.log_var.bias: 0.00087251968216151\n",
      "Gradient for decoder.decoder.0.weight: 0.011089194566011429\n",
      "Gradient for decoder.decoder.0.bias: 8.99076715854541e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005510932533070445\n",
      "Gradient for decoder.decoder.1.bias: 0.0004847599775530398\n",
      "Gradient for decoder.decoder.3.weight: 0.011084116995334625\n",
      "Gradient for decoder.decoder.3.bias: 8.679878343853531e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00043143719085492194\n",
      "Gradient for decoder.decoder.4.bias: 0.0004196323570795357\n",
      "Gradient for decoder.decoder.6.weight: 0.0006268150173127651\n",
      "Gradient for decoder.decoder.6.bias: 3.443522655288689e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.011892206035554409\n",
      "Gradient for encoder.encoder.0.bias: 2.1519626358657007e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0008015861385501921\n",
      "Gradient for encoder.encoder.1.bias: 0.0006607457180507481\n",
      "Gradient for encoder.encoder.3.weight: 0.017677227035164833\n",
      "Gradient for encoder.encoder.3.bias: 1.8208645702344484e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.004461673554033041\n",
      "Gradient for encoder.encoder.4.bias: 0.003965659532696009\n",
      "Gradient for encoder.mean.weight: 0.06051269918680191\n",
      "Gradient for encoder.mean.bias: 0.0024217399768531322\n",
      "Gradient for encoder.log_var.weight: 0.035889480262994766\n",
      "Gradient for encoder.log_var.bias: 0.0014184584142640233\n",
      "Gradient for decoder.decoder.0.weight: 0.009267324581742287\n",
      "Gradient for decoder.decoder.0.bias: 7.61981727714911e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.000495779444463551\n",
      "Gradient for decoder.decoder.1.bias: 0.00037617143243551254\n",
      "Gradient for decoder.decoder.3.weight: 0.009003475308418274\n",
      "Gradient for decoder.decoder.3.bias: 7.198423801479947e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.000355289172148332\n",
      "Gradient for decoder.decoder.4.bias: 0.00036273006116971374\n",
      "Gradient for decoder.decoder.6.weight: 0.0006259723450057209\n",
      "Gradient for decoder.decoder.6.bias: 3.482712781988084e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.0039811343885958195\n",
      "Gradient for encoder.encoder.0.bias: 7.090668330267391e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.0004430300905369222\n",
      "Gradient for encoder.encoder.1.bias: 0.0005667207879014313\n",
      "Gradient for encoder.encoder.3.weight: 0.008987895213067532\n",
      "Gradient for encoder.encoder.3.bias: 1.2878090260848296e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0038471235893666744\n",
      "Gradient for encoder.encoder.4.bias: 0.0027861406560987234\n",
      "Gradient for encoder.mean.weight: 0.05180714279413223\n",
      "Gradient for encoder.mean.bias: 0.002004683483392\n",
      "Gradient for encoder.log_var.weight: 0.03311632573604584\n",
      "Gradient for encoder.log_var.bias: 0.001105465809814632\n",
      "Gradient for decoder.decoder.0.weight: 0.015345989726483822\n",
      "Gradient for decoder.decoder.0.bias: 1.4001816373010456e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0007786608184687793\n",
      "Gradient for decoder.decoder.1.bias: 0.0006271602469496429\n",
      "Gradient for decoder.decoder.3.weight: 0.014772079885005951\n",
      "Gradient for decoder.decoder.3.bias: 1.1897641205571574e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0005412346217781305\n",
      "Gradient for decoder.decoder.4.bias: 0.00044222676660865545\n",
      "Gradient for decoder.decoder.6.weight: 0.0006658998900093138\n",
      "Gradient for decoder.decoder.6.bias: 3.748804738279432e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.007270242087543011\n",
      "Gradient for encoder.encoder.0.bias: 1.2967745800784858e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0005438881344161928\n",
      "Gradient for encoder.encoder.1.bias: 0.0006141611374914646\n",
      "Gradient for encoder.encoder.3.weight: 0.011637002229690552\n",
      "Gradient for encoder.encoder.3.bias: 1.204345512206828e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0024615537840873003\n",
      "Gradient for encoder.encoder.4.bias: 0.0019527667900547385\n",
      "Gradient for encoder.mean.weight: 0.03734498843550682\n",
      "Gradient for encoder.mean.bias: 0.0015874368837103248\n",
      "Gradient for encoder.log_var.weight: 0.01911810413002968\n",
      "Gradient for encoder.log_var.bias: 0.0008096006349660456\n",
      "Gradient for decoder.decoder.0.weight: 0.010708394460380077\n",
      "Gradient for decoder.decoder.0.bias: 9.517306387429869e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005485157016664743\n",
      "Gradient for decoder.decoder.1.bias: 0.0004783185722772032\n",
      "Gradient for decoder.decoder.3.weight: 0.0108081866055727\n",
      "Gradient for decoder.decoder.3.bias: 8.039396232062401e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00038190625491552055\n",
      "Gradient for decoder.decoder.4.bias: 0.0003578748437575996\n",
      "Gradient for decoder.decoder.6.weight: 0.0006275588530115783\n",
      "Gradient for decoder.decoder.6.bias: 3.279734664829448e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.008506735786795616\n",
      "Gradient for encoder.encoder.0.bias: 1.4911596263322835e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0004923573578707874\n",
      "Gradient for encoder.encoder.1.bias: 0.0005323875229805708\n",
      "Gradient for encoder.encoder.3.weight: 0.011142369359731674\n",
      "Gradient for encoder.encoder.3.bias: 1.168845020771414e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.002356607234105468\n",
      "Gradient for encoder.encoder.4.bias: 0.0019597287755459547\n",
      "Gradient for encoder.mean.weight: 0.035944268107414246\n",
      "Gradient for encoder.mean.bias: 0.0013008733512833714\n",
      "Gradient for encoder.log_var.weight: 0.018227500841021538\n",
      "Gradient for encoder.log_var.bias: 0.0009042116580531001\n",
      "Gradient for decoder.decoder.0.weight: 0.01037939079105854\n",
      "Gradient for decoder.decoder.0.bias: 9.220717245295162e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.000548787007573992\n",
      "Gradient for decoder.decoder.1.bias: 0.00040744568104855716\n",
      "Gradient for decoder.decoder.3.weight: 0.009683165699243546\n",
      "Gradient for decoder.decoder.3.bias: 8.355913183599739e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0003835054812952876\n",
      "Gradient for decoder.decoder.4.bias: 0.00036864602589048445\n",
      "Gradient for decoder.decoder.6.weight: 0.0006469524814747274\n",
      "Gradient for decoder.decoder.6.bias: 3.450188523856923e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.006955200806260109\n",
      "Gradient for encoder.encoder.0.bias: 1.1753227731337024e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.000549713964574039\n",
      "Gradient for encoder.encoder.1.bias: 0.0005740244523622096\n",
      "Gradient for encoder.encoder.3.weight: 0.012462638318538666\n",
      "Gradient for encoder.encoder.3.bias: 1.2399549442765334e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.002981511177495122\n",
      "Gradient for encoder.encoder.4.bias: 0.0023609045892953873\n",
      "Gradient for encoder.mean.weight: 0.04265863075852394\n",
      "Gradient for encoder.mean.bias: 0.0018568291561678052\n",
      "Gradient for encoder.log_var.weight: 0.02630981244146824\n",
      "Gradient for encoder.log_var.bias: 0.0010725976899266243\n",
      "Gradient for decoder.decoder.0.weight: 0.014650297351181507\n",
      "Gradient for decoder.decoder.0.bias: 1.4390351410487057e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0007241380517370999\n",
      "Gradient for decoder.decoder.1.bias: 0.0006002632435411215\n",
      "Gradient for decoder.decoder.3.weight: 0.01334636565297842\n",
      "Gradient for decoder.decoder.3.bias: 1.4164996953169862e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0007454233127646148\n",
      "Gradient for decoder.decoder.4.bias: 0.0008152996306307614\n",
      "Gradient for decoder.decoder.6.weight: 0.000824331829790026\n",
      "Gradient for decoder.decoder.6.bias: 5.938285539741628e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.007275950629264116\n",
      "Gradient for encoder.encoder.0.bias: 1.3071259352681608e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.00047071318840608\n",
      "Gradient for encoder.encoder.1.bias: 0.0005488974275067449\n",
      "Gradient for encoder.encoder.3.weight: 0.010982776060700417\n",
      "Gradient for encoder.encoder.3.bias: 1.2013429140367293e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0029953995253890753\n",
      "Gradient for encoder.encoder.4.bias: 0.002375312615185976\n",
      "Gradient for encoder.mean.weight: 0.04167638719081879\n",
      "Gradient for encoder.mean.bias: 0.0017992258071899414\n",
      "Gradient for encoder.log_var.weight: 0.02278432808816433\n",
      "Gradient for encoder.log_var.bias: 0.0010421989718452096\n",
      "Gradient for decoder.decoder.0.weight: 0.011171305552124977\n",
      "Gradient for decoder.decoder.0.bias: 9.323651573023284e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005533365183509886\n",
      "Gradient for decoder.decoder.1.bias: 0.00046020859736017883\n",
      "Gradient for decoder.decoder.3.weight: 0.010437189601361752\n",
      "Gradient for decoder.decoder.3.bias: 8.873723977842474e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00046078296145424247\n",
      "Gradient for decoder.decoder.4.bias: 0.00046565697994083166\n",
      "Gradient for decoder.decoder.6.weight: 0.0006419943529181182\n",
      "Gradient for decoder.decoder.6.bias: 3.855420072795823e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.04608375206589699\n",
      "Gradient for encoder.encoder.0.bias: 6.515459005651536e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0015008217887952924\n",
      "Gradient for encoder.encoder.1.bias: 0.0016657214146107435\n",
      "Gradient for encoder.encoder.3.weight: 0.031001297757029533\n",
      "Gradient for encoder.encoder.3.bias: 3.151540695078836e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0054186261259019375\n",
      "Gradient for encoder.encoder.4.bias: 0.005357091315090656\n",
      "Gradient for encoder.mean.weight: 0.07278012484312057\n",
      "Gradient for encoder.mean.bias: 0.0032605957239866257\n",
      "Gradient for encoder.log_var.weight: 0.03896933048963547\n",
      "Gradient for encoder.log_var.bias: 0.0021543656475842\n",
      "Gradient for decoder.decoder.0.weight: 0.022257504984736443\n",
      "Gradient for decoder.decoder.0.bias: 1.5208169446001563e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0009692037710919976\n",
      "Gradient for decoder.decoder.1.bias: 0.0008439462399110198\n",
      "Gradient for decoder.decoder.3.weight: 0.02043520286679268\n",
      "Gradient for decoder.decoder.3.bias: 1.2750039912745592e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.000654620467685163\n",
      "Gradient for decoder.decoder.4.bias: 0.0005571875371970236\n",
      "Gradient for decoder.decoder.6.weight: 0.0015784219140186906\n",
      "Gradient for decoder.decoder.6.bias: 9.035257244249806e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/3, Train Loss: 0.0685, Val Loss: 0.2916\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training VAE Epoch:   1%|▏         | 1/79 [00:00<00:14,  5.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient for encoder.encoder.0.weight: 0.014676314778625965\n",
      "Gradient for encoder.encoder.0.bias: 2.5612706400224283e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0008046011789701879\n",
      "Gradient for encoder.encoder.1.bias: 0.0006927876966074109\n",
      "Gradient for encoder.encoder.3.weight: 0.016779689118266106\n",
      "Gradient for encoder.encoder.3.bias: 1.6751827702776723e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.003765192348510027\n",
      "Gradient for encoder.encoder.4.bias: 0.003201235318556428\n",
      "Gradient for encoder.mean.weight: 0.05117783322930336\n",
      "Gradient for encoder.mean.bias: 0.0019757223781198263\n",
      "Gradient for encoder.log_var.weight: 0.0265140812844038\n",
      "Gradient for encoder.log_var.bias: 0.001167783048003912\n",
      "Gradient for decoder.decoder.0.weight: 0.008611203171312809\n",
      "Gradient for decoder.decoder.0.bias: 7.173431987306245e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.00044197935494594276\n",
      "Gradient for decoder.decoder.1.bias: 0.0003412851656321436\n",
      "Gradient for decoder.decoder.3.weight: 0.008322895504534245\n",
      "Gradient for decoder.decoder.3.bias: 7.0368204319049e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00037189904833212495\n",
      "Gradient for decoder.decoder.4.bias: 0.00042220266186632216\n",
      "Gradient for decoder.decoder.6.weight: 0.00063803989905864\n",
      "Gradient for decoder.decoder.6.bias: 4.124374390812591e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.007229352369904518\n",
      "Gradient for encoder.encoder.0.bias: 1.195920012325713e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0005469488096423447\n",
      "Gradient for encoder.encoder.1.bias: 0.0006730100139975548\n",
      "Gradient for encoder.encoder.3.weight: 0.012181916274130344\n",
      "Gradient for encoder.encoder.3.bias: 1.1850036230054428e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0036425411235541105\n",
      "Gradient for encoder.encoder.4.bias: 0.0025114212185144424\n",
      "Gradient for encoder.mean.weight: 0.05085407570004463\n",
      "Gradient for encoder.mean.bias: 0.0020306238438934088\n",
      "Gradient for encoder.log_var.weight: 0.033230118453502655\n",
      "Gradient for encoder.log_var.bias: 0.00117669312749058\n",
      "Gradient for decoder.decoder.0.weight: 0.012354040518403053\n",
      "Gradient for decoder.decoder.0.bias: 9.796052163890678e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0006301242392510176\n",
      "Gradient for decoder.decoder.1.bias: 0.0005045367288403213\n",
      "Gradient for decoder.decoder.3.weight: 0.012371138669550419\n",
      "Gradient for decoder.decoder.3.bias: 8.871271078847442e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0004284844035282731\n",
      "Gradient for decoder.decoder.4.bias: 0.00037290542968548834\n",
      "Gradient for decoder.decoder.6.weight: 0.0006535464199259877\n",
      "Gradient for decoder.decoder.6.bias: 3.7184734537731856e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training VAE Epoch:  11%|█▏        | 9/79 [00:00<00:01, 35.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient for encoder.encoder.0.weight: 0.010824156925082207\n",
      "Gradient for encoder.encoder.0.bias: 2.055355538543857e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0006993270944803953\n",
      "Gradient for encoder.encoder.1.bias: 0.0005899136303924024\n",
      "Gradient for encoder.encoder.3.weight: 0.014398125000298023\n",
      "Gradient for encoder.encoder.3.bias: 1.705184743405752e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0028158496133983135\n",
      "Gradient for encoder.encoder.4.bias: 0.0023484828416258097\n",
      "Gradient for encoder.mean.weight: 0.03992934897542\n",
      "Gradient for encoder.mean.bias: 0.0016132693272083998\n",
      "Gradient for encoder.log_var.weight: 0.02068490721285343\n",
      "Gradient for encoder.log_var.bias: 0.0009644291130825877\n",
      "Gradient for decoder.decoder.0.weight: 0.009395492263138294\n",
      "Gradient for decoder.decoder.0.bias: 8.125340678066806e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.00046411342918872833\n",
      "Gradient for decoder.decoder.1.bias: 0.00038025842513889074\n",
      "Gradient for decoder.decoder.3.weight: 0.008981316350400448\n",
      "Gradient for decoder.decoder.3.bias: 8.18906747968029e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0004691288631875068\n",
      "Gradient for decoder.decoder.4.bias: 0.000507493270561099\n",
      "Gradient for decoder.decoder.6.weight: 0.00065692636417225\n",
      "Gradient for decoder.decoder.6.bias: 4.230004196870141e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.010117736645042896\n",
      "Gradient for encoder.encoder.0.bias: 1.4407326026644185e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.00048264357610605657\n",
      "Gradient for encoder.encoder.1.bias: 0.0004560424422379583\n",
      "Gradient for encoder.encoder.3.weight: 0.01048041507601738\n",
      "Gradient for encoder.encoder.3.bias: 1.3953942168409839e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0035736002027988434\n",
      "Gradient for encoder.encoder.4.bias: 0.0023672753013670444\n",
      "Gradient for encoder.mean.weight: 0.050065185874700546\n",
      "Gradient for encoder.mean.bias: 0.00176363461650908\n",
      "Gradient for encoder.log_var.weight: 0.028309928253293037\n",
      "Gradient for encoder.log_var.bias: 0.0010118255158886313\n",
      "Gradient for decoder.decoder.0.weight: 0.010253515094518661\n",
      "Gradient for decoder.decoder.0.bias: 8.819080188349204e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005109814228489995\n",
      "Gradient for decoder.decoder.1.bias: 0.0004243045987095684\n",
      "Gradient for decoder.decoder.3.weight: 0.009658626280725002\n",
      "Gradient for decoder.decoder.3.bias: 8.251771488332338e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00041108072036877275\n",
      "Gradient for decoder.decoder.4.bias: 0.0004278382402844727\n",
      "Gradient for decoder.decoder.6.weight: 0.0006730684544891119\n",
      "Gradient for decoder.decoder.6.bias: 4.4967830035602674e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.007895938120782375\n",
      "Gradient for encoder.encoder.0.bias: 1.3639488843919523e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0006185539532452822\n",
      "Gradient for encoder.encoder.1.bias: 0.0006251843878999352\n",
      "Gradient for encoder.encoder.3.weight: 0.013460624031722546\n",
      "Gradient for encoder.encoder.3.bias: 1.3527472197960577e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0037417979910969734\n",
      "Gradient for encoder.encoder.4.bias: 0.00246755825355649\n",
      "Gradient for encoder.mean.weight: 0.0495317205786705\n",
      "Gradient for encoder.mean.bias: 0.0017874548211693764\n",
      "Gradient for encoder.log_var.weight: 0.02774949185550213\n",
      "Gradient for encoder.log_var.bias: 0.001080318121239543\n",
      "Gradient for decoder.decoder.0.weight: 0.012915579602122307\n",
      "Gradient for decoder.decoder.0.bias: 1.1386133008661758e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0006428453489206731\n",
      "Gradient for decoder.decoder.1.bias: 0.0005237528821453452\n",
      "Gradient for decoder.decoder.3.weight: 0.012174071744084358\n",
      "Gradient for decoder.decoder.3.bias: 1.0102852582294375e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.000554762315005064\n",
      "Gradient for decoder.decoder.4.bias: 0.0005329697160050273\n",
      "Gradient for decoder.decoder.6.weight: 0.0006954147247597575\n",
      "Gradient for decoder.decoder.6.bias: 4.150189124629833e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.008787787519395351\n",
      "Gradient for encoder.encoder.0.bias: 1.3744475176047377e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0006605541566386819\n",
      "Gradient for encoder.encoder.1.bias: 0.0006691962480545044\n",
      "Gradient for encoder.encoder.3.weight: 0.014637941494584084\n",
      "Gradient for encoder.encoder.3.bias: 1.5638293437980622e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0033804650884121656\n",
      "Gradient for encoder.encoder.4.bias: 0.0029554569628089666\n",
      "Gradient for encoder.mean.weight: 0.045363422483205795\n",
      "Gradient for encoder.mean.bias: 0.0023052000906318426\n",
      "Gradient for encoder.log_var.weight: 0.027544673532247543\n",
      "Gradient for encoder.log_var.bias: 0.0014247553190216422\n",
      "Gradient for decoder.decoder.0.weight: 0.011950849555432796\n",
      "Gradient for decoder.decoder.0.bias: 1.0008600892508213e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0006354543147608638\n",
      "Gradient for decoder.decoder.1.bias: 0.0004790856910403818\n",
      "Gradient for decoder.decoder.3.weight: 0.011173861101269722\n",
      "Gradient for decoder.decoder.3.bias: 1.0153354546016402e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.000616139848716557\n",
      "Gradient for decoder.decoder.4.bias: 0.0006576073355972767\n",
      "Gradient for decoder.decoder.6.weight: 0.0006972437840886414\n",
      "Gradient for decoder.decoder.6.bias: 4.4537820940604433e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.008151831105351448\n",
      "Gradient for encoder.encoder.0.bias: 1.2972120773391271e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.000673057627864182\n",
      "Gradient for encoder.encoder.1.bias: 0.0007745854090899229\n",
      "Gradient for encoder.encoder.3.weight: 0.013981935568153858\n",
      "Gradient for encoder.encoder.3.bias: 1.4235358725134262e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0034862945321947336\n",
      "Gradient for encoder.encoder.4.bias: 0.002768180565908551\n",
      "Gradient for encoder.mean.weight: 0.0485353022813797\n",
      "Gradient for encoder.mean.bias: 0.0023111412301659584\n",
      "Gradient for encoder.log_var.weight: 0.027620214968919754\n",
      "Gradient for encoder.log_var.bias: 0.0014769462868571281\n",
      "Gradient for decoder.decoder.0.weight: 0.01415242813527584\n",
      "Gradient for decoder.decoder.0.bias: 1.1005121119955774e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0007534525939263403\n",
      "Gradient for decoder.decoder.1.bias: 0.0005585502367466688\n",
      "Gradient for decoder.decoder.3.weight: 0.013578995130956173\n",
      "Gradient for decoder.decoder.3.bias: 1.0778939546485233e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0004889018600806594\n",
      "Gradient for decoder.decoder.4.bias: 0.00041731956298463047\n",
      "Gradient for decoder.decoder.6.weight: 0.0006902929744683206\n",
      "Gradient for decoder.decoder.6.bias: 4.353621261543594e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.012482083402574062\n",
      "Gradient for encoder.encoder.0.bias: 1.6655486018146703e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0006288528675213456\n",
      "Gradient for encoder.encoder.1.bias: 0.0005771794822067022\n",
      "Gradient for encoder.encoder.3.weight: 0.013537063263356686\n",
      "Gradient for encoder.encoder.3.bias: 1.518044162596155e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.003296758746728301\n",
      "Gradient for encoder.encoder.4.bias: 0.0026666298508644104\n",
      "Gradient for encoder.mean.weight: 0.04648444801568985\n",
      "Gradient for encoder.mean.bias: 0.002193855820223689\n",
      "Gradient for encoder.log_var.weight: 0.024155467748641968\n",
      "Gradient for encoder.log_var.bias: 0.0011894204653799534\n",
      "Gradient for decoder.decoder.0.weight: 0.011185388080775738\n",
      "Gradient for decoder.decoder.0.bias: 9.758847896446099e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005439299857243896\n",
      "Gradient for decoder.decoder.1.bias: 0.0004543400136753917\n",
      "Gradient for decoder.decoder.3.weight: 0.010249829851090908\n",
      "Gradient for decoder.decoder.3.bias: 9.449270532702059e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0005689183017238975\n",
      "Gradient for decoder.decoder.4.bias: 0.0005886529106646776\n",
      "Gradient for decoder.decoder.6.weight: 0.0007227009045891464\n",
      "Gradient for decoder.decoder.6.bias: 4.298728526919149e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.009643574245274067\n",
      "Gradient for encoder.encoder.0.bias: 1.7755607747971247e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0005824854597449303\n",
      "Gradient for encoder.encoder.1.bias: 0.0006454565445892513\n",
      "Gradient for encoder.encoder.3.weight: 0.012735569849610329\n",
      "Gradient for encoder.encoder.3.bias: 1.41808370601737e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0035794617142528296\n",
      "Gradient for encoder.encoder.4.bias: 0.002640578430145979\n",
      "Gradient for encoder.mean.weight: 0.049454301595687866\n",
      "Gradient for encoder.mean.bias: 0.0019225477008149028\n",
      "Gradient for encoder.log_var.weight: 0.022966472432017326\n",
      "Gradient for encoder.log_var.bias: 0.0012134466087445617\n",
      "Gradient for decoder.decoder.0.weight: 0.009987601079046726\n",
      "Gradient for decoder.decoder.0.bias: 8.555649938513099e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005388371064327657\n",
      "Gradient for decoder.decoder.1.bias: 0.0004267949261702597\n",
      "Gradient for decoder.decoder.3.weight: 0.009700858034193516\n",
      "Gradient for decoder.decoder.3.bias: 7.535724821927658e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00044774427078664303\n",
      "Gradient for decoder.decoder.4.bias: 0.00048674712888896465\n",
      "Gradient for decoder.decoder.6.weight: 0.0006021346198394895\n",
      "Gradient for decoder.decoder.6.bias: 3.3326668926747516e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.007216417696326971\n",
      "Gradient for encoder.encoder.0.bias: 1.1989254207478428e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.00045490480260923505\n",
      "Gradient for encoder.encoder.1.bias: 0.0005227812798693776\n",
      "Gradient for encoder.encoder.3.weight: 0.010061097331345081\n",
      "Gradient for encoder.encoder.3.bias: 1.240817171233033e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.002893810160458088\n",
      "Gradient for encoder.encoder.4.bias: 0.0020174153614789248\n",
      "Gradient for encoder.mean.weight: 0.04098226875066757\n",
      "Gradient for encoder.mean.bias: 0.0015560761094093323\n",
      "Gradient for encoder.log_var.weight: 0.0223018117249012\n",
      "Gradient for encoder.log_var.bias: 0.0010180057724937797\n",
      "Gradient for decoder.decoder.0.weight: 0.012655298225581646\n",
      "Gradient for decoder.decoder.0.bias: 1.0200712496910569e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0006531527615152299\n",
      "Gradient for decoder.decoder.1.bias: 0.0004904249217361212\n",
      "Gradient for decoder.decoder.3.weight: 0.012193757109344006\n",
      "Gradient for decoder.decoder.3.bias: 9.083297308754013e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00045349745778366923\n",
      "Gradient for decoder.decoder.4.bias: 0.0004039180348627269\n",
      "Gradient for decoder.decoder.6.weight: 0.0006625460810028017\n",
      "Gradient for decoder.decoder.6.bias: 3.839452983811498e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.004997582640498877\n",
      "Gradient for encoder.encoder.0.bias: 8.601184001144624e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.0005798533093184233\n",
      "Gradient for encoder.encoder.1.bias: 0.0006042780005373061\n",
      "Gradient for encoder.encoder.3.weight: 0.012742598541080952\n",
      "Gradient for encoder.encoder.3.bias: 1.5857852531109273e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.004060747567564249\n",
      "Gradient for encoder.encoder.4.bias: 0.003870179411023855\n",
      "Gradient for encoder.mean.weight: 0.0568106435239315\n",
      "Gradient for encoder.mean.bias: 0.0027609446551650763\n",
      "Gradient for encoder.log_var.weight: 0.032861195504665375\n",
      "Gradient for encoder.log_var.bias: 0.0018055853433907032\n",
      "Gradient for decoder.decoder.0.weight: 0.01641811989247799\n",
      "Gradient for decoder.decoder.0.bias: 1.3721931924060016e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0007905824459157884\n",
      "Gradient for decoder.decoder.1.bias: 0.0006323716370388865\n",
      "Gradient for decoder.decoder.3.weight: 0.015112681314349174\n",
      "Gradient for decoder.decoder.3.bias: 1.3273121490797735e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0008563731098547578\n",
      "Gradient for decoder.decoder.4.bias: 0.0009191245771944523\n",
      "Gradient for decoder.decoder.6.weight: 0.0008225257624872029\n",
      "Gradient for decoder.decoder.6.bias: 6.109049718361348e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.012269871309399605\n",
      "Gradient for encoder.encoder.0.bias: 2.0698460306833866e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0007412132108584046\n",
      "Gradient for encoder.encoder.1.bias: 0.0006664444808848202\n",
      "Gradient for encoder.encoder.3.weight: 0.01566847413778305\n",
      "Gradient for encoder.encoder.3.bias: 1.7134839380705813e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0037754469085484743\n",
      "Gradient for encoder.encoder.4.bias: 0.003640033770352602\n",
      "Gradient for encoder.mean.weight: 0.05192485824227333\n",
      "Gradient for encoder.mean.bias: 0.0025834664702415466\n",
      "Gradient for encoder.log_var.weight: 0.0298311784863472\n",
      "Gradient for encoder.log_var.bias: 0.0016222582198679447\n",
      "Gradient for decoder.decoder.0.weight: 0.010150644928216934\n",
      "Gradient for decoder.decoder.0.bias: 8.577197979642293e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0004915897152386606\n",
      "Gradient for decoder.decoder.1.bias: 0.0004160265380050987\n",
      "Gradient for decoder.decoder.3.weight: 0.00969288032501936\n",
      "Gradient for decoder.decoder.3.bias: 8.176660737380104e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0004112764436285943\n",
      "Gradient for decoder.decoder.4.bias: 0.00044761758181266487\n",
      "Gradient for decoder.decoder.6.weight: 0.0006453002570196986\n",
      "Gradient for decoder.decoder.6.bias: 4.073147283634171e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.005956729408353567\n",
      "Gradient for encoder.encoder.0.bias: 9.53175559315067e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.0004358221485745162\n",
      "Gradient for encoder.encoder.1.bias: 0.0004998315125703812\n",
      "Gradient for encoder.encoder.3.weight: 0.009931307286024094\n",
      "Gradient for encoder.encoder.3.bias: 1.2250875314201437e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0031145953107625246\n",
      "Gradient for encoder.encoder.4.bias: 0.0020477555226534605\n",
      "Gradient for encoder.mean.weight: 0.0456390455365181\n",
      "Gradient for encoder.mean.bias: 0.0014427764108404517\n",
      "Gradient for encoder.log_var.weight: 0.025632090866565704\n",
      "Gradient for encoder.log_var.bias: 0.0009067176142707467\n",
      "Gradient for decoder.decoder.0.weight: 0.015423341654241085\n",
      "Gradient for decoder.decoder.0.bias: 1.2696743656448461e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0007663638098165393\n",
      "Gradient for decoder.decoder.1.bias: 0.0006257957429625094\n",
      "Gradient for decoder.decoder.3.weight: 0.015029127709567547\n",
      "Gradient for decoder.decoder.3.bias: 1.2099836410595088e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0007400361355394125\n",
      "Gradient for decoder.decoder.4.bias: 0.0007691507344134152\n",
      "Gradient for decoder.decoder.6.weight: 0.0007450465927831829\n",
      "Gradient for decoder.decoder.6.bias: 4.764387631439604e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.007712363265454769\n",
      "Gradient for encoder.encoder.0.bias: 1.1234927918546411e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.000490912760142237\n",
      "Gradient for encoder.encoder.1.bias: 0.0004953098832629621\n",
      "Gradient for encoder.encoder.3.weight: 0.011038517579436302\n",
      "Gradient for encoder.encoder.3.bias: 1.2856177233899757e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0025834606494754553\n",
      "Gradient for encoder.encoder.4.bias: 0.0015958958538249135\n",
      "Gradient for encoder.mean.weight: 0.036363616585731506\n",
      "Gradient for encoder.mean.bias: 0.0012361228000372648\n",
      "Gradient for encoder.log_var.weight: 0.023488782346248627\n",
      "Gradient for encoder.log_var.bias: 0.000870274961926043\n",
      "Gradient for decoder.decoder.0.weight: 0.015212750993669033\n",
      "Gradient for decoder.decoder.0.bias: 1.2052295272901858e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0007688638870604336\n",
      "Gradient for decoder.decoder.1.bias: 0.0005838533979840577\n",
      "Gradient for decoder.decoder.3.weight: 0.014220446348190308\n",
      "Gradient for decoder.decoder.3.bias: 1.1424554358097083e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0008030569879338145\n",
      "Gradient for decoder.decoder.4.bias: 0.0009356008376926184\n",
      "Gradient for decoder.decoder.6.weight: 0.0008512228378094733\n",
      "Gradient for decoder.decoder.6.bias: 6.60035148030147e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.012122788466513157\n",
      "Gradient for encoder.encoder.0.bias: 1.8980808244584146e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0005335318273864686\n",
      "Gradient for encoder.encoder.1.bias: 0.0005720060435123742\n",
      "Gradient for encoder.encoder.3.weight: 0.011860544793307781\n",
      "Gradient for encoder.encoder.3.bias: 1.5505501049783987e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.003039647825062275\n",
      "Gradient for encoder.encoder.4.bias: 0.0029687946662306786\n",
      "Gradient for encoder.mean.weight: 0.04259059578180313\n",
      "Gradient for encoder.mean.bias: 0.0023993095383048058\n",
      "Gradient for encoder.log_var.weight: 0.024578189477324486\n",
      "Gradient for encoder.log_var.bias: 0.0015042837476357818\n",
      "Gradient for decoder.decoder.0.weight: 0.010626902803778648\n",
      "Gradient for decoder.decoder.0.bias: 8.467662682143384e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005180545267648995\n",
      "Gradient for decoder.decoder.1.bias: 0.0004147222498431802\n",
      "Gradient for decoder.decoder.3.weight: 0.010119005106389523\n",
      "Gradient for decoder.decoder.3.bias: 8.457345934687055e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00046128054964356124\n",
      "Gradient for decoder.decoder.4.bias: 0.0005063981516286731\n",
      "Gradient for decoder.decoder.6.weight: 0.0006392213399522007\n",
      "Gradient for decoder.decoder.6.bias: 3.934804044547491e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.0068847620859742165\n",
      "Gradient for encoder.encoder.0.bias: 1.1634186669606805e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0004218731774017215\n",
      "Gradient for encoder.encoder.1.bias: 0.0004680780111812055\n",
      "Gradient for encoder.encoder.3.weight: 0.009666966274380684\n",
      "Gradient for encoder.encoder.3.bias: 1.3766179862706451e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.002740447875112295\n",
      "Gradient for encoder.encoder.4.bias: 0.0026743332855403423\n",
      "Gradient for encoder.mean.weight: 0.039339177310466766\n",
      "Gradient for encoder.mean.bias: 0.0021893149241805077\n",
      "Gradient for encoder.log_var.weight: 0.02296883799135685\n",
      "Gradient for encoder.log_var.bias: 0.001377730630338192\n",
      "Gradient for decoder.decoder.0.weight: 0.012289954349398613\n",
      "Gradient for decoder.decoder.0.bias: 1.0615008871894815e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0006406200118362904\n",
      "Gradient for decoder.decoder.1.bias: 0.000520101108122617\n",
      "Gradient for decoder.decoder.3.weight: 0.011602607555687428\n",
      "Gradient for decoder.decoder.3.bias: 8.358048975143362e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0004342946922406554\n",
      "Gradient for decoder.decoder.4.bias: 0.0004024170048069209\n",
      "Gradient for decoder.decoder.6.weight: 0.0006797202513553202\n",
      "Gradient for decoder.decoder.6.bias: 4.29753890784923e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.005730814766138792\n",
      "Gradient for encoder.encoder.0.bias: 1.0530742076964028e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0004811864346265793\n",
      "Gradient for encoder.encoder.1.bias: 0.0005512197967618704\n",
      "Gradient for encoder.encoder.3.weight: 0.010041095316410065\n",
      "Gradient for encoder.encoder.3.bias: 1.1780852682274912e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0034883753396570683\n",
      "Gradient for encoder.encoder.4.bias: 0.002206011675298214\n",
      "Gradient for encoder.mean.weight: 0.049902621656656265\n",
      "Gradient for encoder.mean.bias: 0.0015543407062068582\n",
      "Gradient for encoder.log_var.weight: 0.02524535171687603\n",
      "Gradient for encoder.log_var.bias: 0.000961070298217237\n",
      "Gradient for decoder.decoder.0.weight: 0.013670436106622219\n",
      "Gradient for decoder.decoder.0.bias: 1.1358088775059727e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0006773240165784955\n",
      "Gradient for decoder.decoder.1.bias: 0.0005494754877872765\n",
      "Gradient for decoder.decoder.3.weight: 0.01270842831581831\n",
      "Gradient for decoder.decoder.3.bias: 1.0180935955395043e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.00046310131438076496\n",
      "Gradient for decoder.decoder.4.bias: 0.0004189570026937872\n",
      "Gradient for decoder.decoder.6.weight: 0.0006078375154174864\n",
      "Gradient for decoder.decoder.6.bias: 2.995485920109786e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training VAE Epoch:  32%|███▏      | 25/79 [00:00<00:00, 58.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient for encoder.encoder.0.weight: 0.00843095313757658\n",
      "Gradient for encoder.encoder.0.bias: 1.2550139746880795e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0005820705555379391\n",
      "Gradient for encoder.encoder.1.bias: 0.0004692044167313725\n",
      "Gradient for encoder.encoder.3.weight: 0.012190813198685646\n",
      "Gradient for encoder.encoder.3.bias: 1.2903390855800723e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.002997317584231496\n",
      "Gradient for encoder.encoder.4.bias: 0.0021290236618369818\n",
      "Gradient for encoder.mean.weight: 0.04371526837348938\n",
      "Gradient for encoder.mean.bias: 0.0017444394761696458\n",
      "Gradient for encoder.log_var.weight: 0.022237060591578484\n",
      "Gradient for encoder.log_var.bias: 0.001114542013965547\n",
      "Gradient for decoder.decoder.0.weight: 0.012416239827871323\n",
      "Gradient for decoder.decoder.0.bias: 1.0211312351238178e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0005969756166450679\n",
      "Gradient for decoder.decoder.1.bias: 0.0005001085228286684\n",
      "Gradient for decoder.decoder.3.weight: 0.011400723829865456\n",
      "Gradient for decoder.decoder.3.bias: 8.894591313479694e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0004298329004086554\n",
      "Gradient for decoder.decoder.4.bias: 0.0004364580672699958\n",
      "Gradient for decoder.decoder.6.weight: 0.0006337434169836342\n",
      "Gradient for decoder.decoder.6.bias: 3.5092227335553616e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.0055112992413342\n",
      "Gradient for encoder.encoder.0.bias: 9.120402350015766e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.00037641834933310747\n",
      "Gradient for encoder.encoder.1.bias: 0.0004781401657965034\n",
      "Gradient for encoder.encoder.3.weight: 0.008622584864497185\n",
      "Gradient for encoder.encoder.3.bias: 1.3121456698961254e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0028347675688564777\n",
      "Gradient for encoder.encoder.4.bias: 0.0022281729616224766\n",
      "Gradient for encoder.mean.weight: 0.043018270283937454\n",
      "Gradient for encoder.mean.bias: 0.0017656569834798574\n",
      "Gradient for encoder.log_var.weight: 0.023133836686611176\n",
      "Gradient for encoder.log_var.bias: 0.001126687740907073\n",
      "Gradient for decoder.decoder.0.weight: 0.01367930881679058\n",
      "Gradient for decoder.decoder.0.bias: 1.2280952643717313e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0006715160561725497\n",
      "Gradient for decoder.decoder.1.bias: 0.0005371116567403078\n",
      "Gradient for decoder.decoder.3.weight: 0.01297620590776205\n",
      "Gradient for decoder.decoder.3.bias: 1.0346901113678086e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.000493341707624495\n",
      "Gradient for decoder.decoder.4.bias: 0.00043932360131293535\n",
      "Gradient for decoder.decoder.6.weight: 0.0007053025183267891\n",
      "Gradient for decoder.decoder.6.bias: 4.5872053306084126e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.010416505858302116\n",
      "Gradient for encoder.encoder.0.bias: 1.7417598613400642e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0006139627657830715\n",
      "Gradient for encoder.encoder.1.bias: 0.0006334344507195055\n",
      "Gradient for encoder.encoder.3.weight: 0.014507627114653587\n",
      "Gradient for encoder.encoder.3.bias: 1.4456517927197154e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0033749560825526714\n",
      "Gradient for encoder.encoder.4.bias: 0.00273180496878922\n",
      "Gradient for encoder.mean.weight: 0.04725847765803337\n",
      "Gradient for encoder.mean.bias: 0.0019306540489196777\n",
      "Gradient for encoder.log_var.weight: 0.024587482213974\n",
      "Gradient for encoder.log_var.bias: 0.001190718961879611\n",
      "Gradient for decoder.decoder.0.weight: 0.010290518403053284\n",
      "Gradient for decoder.decoder.0.bias: 8.491988362502312e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0004958741483278573\n",
      "Gradient for decoder.decoder.1.bias: 0.0004085525870323181\n",
      "Gradient for decoder.decoder.3.weight: 0.00926508940756321\n",
      "Gradient for decoder.decoder.3.bias: 8.121450734144275e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0003801089187618345\n",
      "Gradient for decoder.decoder.4.bias: 0.0003647083940450102\n",
      "Gradient for decoder.decoder.6.weight: 0.0006534892600029707\n",
      "Gradient for decoder.decoder.6.bias: 3.379270856385119e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.008055553771555424\n",
      "Gradient for encoder.encoder.0.bias: 1.3563172286679137e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0006496209534816444\n",
      "Gradient for encoder.encoder.1.bias: 0.0007189603638835251\n",
      "Gradient for encoder.encoder.3.weight: 0.013916787691414356\n",
      "Gradient for encoder.encoder.3.bias: 1.5318073198766768e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0038820989429950714\n",
      "Gradient for encoder.encoder.4.bias: 0.0033189491368830204\n",
      "Gradient for encoder.mean.weight: 0.054845571517944336\n",
      "Gradient for encoder.mean.bias: 0.0027718276251107454\n",
      "Gradient for encoder.log_var.weight: 0.030204731971025467\n",
      "Gradient for encoder.log_var.bias: 0.0018691449658945203\n",
      "Gradient for decoder.decoder.0.weight: 0.01310732215642929\n",
      "Gradient for decoder.decoder.0.bias: 1.205998773068373e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0006736473878845572\n",
      "Gradient for decoder.decoder.1.bias: 0.0005305193481035531\n",
      "Gradient for decoder.decoder.3.weight: 0.011957474052906036\n",
      "Gradient for decoder.decoder.3.bias: 8.956481389876814e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00047676643589511514\n",
      "Gradient for decoder.decoder.4.bias: 0.00042150879744440317\n",
      "Gradient for decoder.decoder.6.weight: 0.0006790928891859949\n",
      "Gradient for decoder.decoder.6.bias: 3.853192538372241e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.010315550491213799\n",
      "Gradient for encoder.encoder.0.bias: 1.9244147941854806e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0006812507635913789\n",
      "Gradient for encoder.encoder.1.bias: 0.0006782846176065505\n",
      "Gradient for encoder.encoder.3.weight: 0.01523881871253252\n",
      "Gradient for encoder.encoder.3.bias: 1.582769193486655e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0033179016318172216\n",
      "Gradient for encoder.encoder.4.bias: 0.0032665643375366926\n",
      "Gradient for encoder.mean.weight: 0.0450228750705719\n",
      "Gradient for encoder.mean.bias: 0.0025876574218273163\n",
      "Gradient for encoder.log_var.weight: 0.029408015310764313\n",
      "Gradient for encoder.log_var.bias: 0.0015744214178994298\n",
      "Gradient for decoder.decoder.0.weight: 0.00783560425043106\n",
      "Gradient for decoder.decoder.0.bias: 6.752606113158421e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.00041085778502747416\n",
      "Gradient for decoder.decoder.1.bias: 0.00030392897315323353\n",
      "Gradient for decoder.decoder.3.weight: 0.007352231070399284\n",
      "Gradient for decoder.decoder.3.bias: 6.837306415485855e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0003999609616585076\n",
      "Gradient for decoder.decoder.4.bias: 0.00044301265734247863\n",
      "Gradient for decoder.decoder.6.weight: 0.0005907191662117839\n",
      "Gradient for decoder.decoder.6.bias: 3.729488162207417e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.005023033823817968\n",
      "Gradient for encoder.encoder.0.bias: 9.177737562982013e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.0005628193612210453\n",
      "Gradient for encoder.encoder.1.bias: 0.0005767715629190207\n",
      "Gradient for encoder.encoder.3.weight: 0.012298810295760632\n",
      "Gradient for encoder.encoder.3.bias: 1.2404766103202292e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.003794935531914234\n",
      "Gradient for encoder.encoder.4.bias: 0.0026087553706020117\n",
      "Gradient for encoder.mean.weight: 0.052553582936525345\n",
      "Gradient for encoder.mean.bias: 0.0017119895201176405\n",
      "Gradient for encoder.log_var.weight: 0.029914967715740204\n",
      "Gradient for encoder.log_var.bias: 0.0011303359642624855\n",
      "Gradient for decoder.decoder.0.weight: 0.016154028475284576\n",
      "Gradient for decoder.decoder.0.bias: 1.2991674402940134e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0008435792988166213\n",
      "Gradient for decoder.decoder.1.bias: 0.0006801934796385467\n",
      "Gradient for decoder.decoder.3.weight: 0.01629713922739029\n",
      "Gradient for decoder.decoder.3.bias: 1.3190828984654956e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0006513753323815763\n",
      "Gradient for decoder.decoder.4.bias: 0.0006035379483364522\n",
      "Gradient for decoder.decoder.6.weight: 0.0007037780014798045\n",
      "Gradient for decoder.decoder.6.bias: 3.821077916654758e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.007338095922023058\n",
      "Gradient for encoder.encoder.0.bias: 1.1460367377313929e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0005836633499711752\n",
      "Gradient for encoder.encoder.1.bias: 0.0005299635813571513\n",
      "Gradient for encoder.encoder.3.weight: 0.012909160926938057\n",
      "Gradient for encoder.encoder.3.bias: 1.245370750968533e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0028147497214376926\n",
      "Gradient for encoder.encoder.4.bias: 0.0022612237371504307\n",
      "Gradient for encoder.mean.weight: 0.03885998949408531\n",
      "Gradient for encoder.mean.bias: 0.0017711888067424297\n",
      "Gradient for encoder.log_var.weight: 0.021485909819602966\n",
      "Gradient for encoder.log_var.bias: 0.0011256670113652945\n",
      "Gradient for decoder.decoder.0.weight: 0.012236088514328003\n",
      "Gradient for decoder.decoder.0.bias: 9.600589073732735e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005934584769420326\n",
      "Gradient for decoder.decoder.1.bias: 0.0004854716535191983\n",
      "Gradient for decoder.decoder.3.weight: 0.011656895279884338\n",
      "Gradient for decoder.decoder.3.bias: 9.007448953379793e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0004292016092222184\n",
      "Gradient for decoder.decoder.4.bias: 0.0004204030556138605\n",
      "Gradient for decoder.decoder.6.weight: 0.0006628227420151234\n",
      "Gradient for decoder.decoder.6.bias: 3.4446049539837986e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.005926703568547964\n",
      "Gradient for encoder.encoder.0.bias: 8.98312587510608e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.0004381432372611016\n",
      "Gradient for encoder.encoder.1.bias: 0.0004870746342930943\n",
      "Gradient for encoder.encoder.3.weight: 0.009628123603761196\n",
      "Gradient for encoder.encoder.3.bias: 1.1932890786603423e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.00241167563945055\n",
      "Gradient for encoder.encoder.4.bias: 0.002087363740429282\n",
      "Gradient for encoder.mean.weight: 0.03692888468503952\n",
      "Gradient for encoder.mean.bias: 0.001677409396506846\n",
      "Gradient for encoder.log_var.weight: 0.019165705889463425\n",
      "Gradient for encoder.log_var.bias: 0.0011729277903214097\n",
      "Gradient for decoder.decoder.0.weight: 0.012413578107953072\n",
      "Gradient for decoder.decoder.0.bias: 1.0381650400459463e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0006371779018081725\n",
      "Gradient for decoder.decoder.1.bias: 0.0005116986576467752\n",
      "Gradient for decoder.decoder.3.weight: 0.011822936125099659\n",
      "Gradient for decoder.decoder.3.bias: 9.436473130675083e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0004386156506370753\n",
      "Gradient for decoder.decoder.4.bias: 0.0003872268134728074\n",
      "Gradient for decoder.decoder.6.weight: 0.0006934364791959524\n",
      "Gradient for decoder.decoder.6.bias: 4.010523480246775e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.008695055730640888\n",
      "Gradient for encoder.encoder.0.bias: 1.4611329507419057e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0006770733161829412\n",
      "Gradient for encoder.encoder.1.bias: 0.0005294382572174072\n",
      "Gradient for encoder.encoder.3.weight: 0.014728793874382973\n",
      "Gradient for encoder.encoder.3.bias: 1.351950218442255e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.002834400860592723\n",
      "Gradient for encoder.encoder.4.bias: 0.002460728632286191\n",
      "Gradient for encoder.mean.weight: 0.039170362055301666\n",
      "Gradient for encoder.mean.bias: 0.002049726899713278\n",
      "Gradient for encoder.log_var.weight: 0.02494759112596512\n",
      "Gradient for encoder.log_var.bias: 0.0013082794612273574\n",
      "Gradient for decoder.decoder.0.weight: 0.01182993408292532\n",
      "Gradient for decoder.decoder.0.bias: 1.0556635426928196e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0005978966364637017\n",
      "Gradient for decoder.decoder.1.bias: 0.0004819815221708268\n",
      "Gradient for decoder.decoder.3.weight: 0.011018713936209679\n",
      "Gradient for decoder.decoder.3.bias: 8.514036003992587e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0003944420604966581\n",
      "Gradient for decoder.decoder.4.bias: 0.00034023658372461796\n",
      "Gradient for decoder.decoder.6.weight: 0.0007113810279406607\n",
      "Gradient for decoder.decoder.6.bias: 4.676205571740866e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.008343495428562164\n",
      "Gradient for encoder.encoder.0.bias: 1.3700502538016579e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0005209814407862723\n",
      "Gradient for encoder.encoder.1.bias: 0.0005252695991657674\n",
      "Gradient for encoder.encoder.3.weight: 0.011935579590499401\n",
      "Gradient for encoder.encoder.3.bias: 1.2055330345095427e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.002546330215409398\n",
      "Gradient for encoder.encoder.4.bias: 0.0019383140606805682\n",
      "Gradient for encoder.mean.weight: 0.03767795488238335\n",
      "Gradient for encoder.mean.bias: 0.0013861081097275019\n",
      "Gradient for encoder.log_var.weight: 0.023533755913376808\n",
      "Gradient for encoder.log_var.bias: 0.0011148038320243359\n",
      "Gradient for decoder.decoder.0.weight: 0.011588579043745995\n",
      "Gradient for decoder.decoder.0.bias: 9.399098166440467e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005560721619985998\n",
      "Gradient for decoder.decoder.1.bias: 0.00048128172056749463\n",
      "Gradient for decoder.decoder.3.weight: 0.010737905278801918\n",
      "Gradient for decoder.decoder.3.bias: 9.035407838586806e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0004193735949229449\n",
      "Gradient for decoder.decoder.4.bias: 0.0004124997358303517\n",
      "Gradient for decoder.decoder.6.weight: 0.0006304878043010831\n",
      "Gradient for decoder.decoder.6.bias: 3.5130444302922115e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.010299941524863243\n",
      "Gradient for encoder.encoder.0.bias: 1.701635186923678e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0006756874499842525\n",
      "Gradient for encoder.encoder.1.bias: 0.0006713616894558072\n",
      "Gradient for encoder.encoder.3.weight: 0.014833393506705761\n",
      "Gradient for encoder.encoder.3.bias: 1.318703618524708e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0025185479316860437\n",
      "Gradient for encoder.encoder.4.bias: 0.002275801030918956\n",
      "Gradient for encoder.mean.weight: 0.03525593876838684\n",
      "Gradient for encoder.mean.bias: 0.00172576738987118\n",
      "Gradient for encoder.log_var.weight: 0.022219369187951088\n",
      "Gradient for encoder.log_var.bias: 0.0011299705365672708\n",
      "Gradient for decoder.decoder.0.weight: 0.009926865808665752\n",
      "Gradient for decoder.decoder.0.bias: 8.952244501259088e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0004709236091002822\n",
      "Gradient for decoder.decoder.1.bias: 0.00041521870298311114\n",
      "Gradient for decoder.decoder.3.weight: 0.009388431906700134\n",
      "Gradient for decoder.decoder.3.bias: 8.585245708792044e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0003332523920107633\n",
      "Gradient for decoder.decoder.4.bias: 0.0003227601700928062\n",
      "Gradient for decoder.decoder.6.weight: 0.0006193790468387306\n",
      "Gradient for decoder.decoder.6.bias: 3.1497627787757665e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.005997293163090944\n",
      "Gradient for encoder.encoder.0.bias: 9.834722446144806e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.0004905555979348719\n",
      "Gradient for encoder.encoder.1.bias: 0.0005279708420857787\n",
      "Gradient for encoder.encoder.3.weight: 0.010753657668828964\n",
      "Gradient for encoder.encoder.3.bias: 1.4317512453398962e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0031086707022041082\n",
      "Gradient for encoder.encoder.4.bias: 0.002840932458639145\n",
      "Gradient for encoder.mean.weight: 0.04677824676036835\n",
      "Gradient for encoder.mean.bias: 0.002503960393369198\n",
      "Gradient for encoder.log_var.weight: 0.02585143782198429\n",
      "Gradient for encoder.log_var.bias: 0.0016335718100890517\n",
      "Gradient for decoder.decoder.0.weight: 0.012564674019813538\n",
      "Gradient for decoder.decoder.0.bias: 1.1578528413824785e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0005979001289233565\n",
      "Gradient for decoder.decoder.1.bias: 0.0004919847124256194\n",
      "Gradient for decoder.decoder.3.weight: 0.01181881781667471\n",
      "Gradient for decoder.decoder.3.bias: 9.980107018581208e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0004236276145093143\n",
      "Gradient for decoder.decoder.4.bias: 0.00039366132114082575\n",
      "Gradient for decoder.decoder.6.weight: 0.0006506588542833924\n",
      "Gradient for decoder.decoder.6.bias: 3.718487641890533e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.006325562950223684\n",
      "Gradient for encoder.encoder.0.bias: 1.1900773769224493e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0005648030783049762\n",
      "Gradient for encoder.encoder.1.bias: 0.0005585606559179723\n",
      "Gradient for encoder.encoder.3.weight: 0.012329009361565113\n",
      "Gradient for encoder.encoder.3.bias: 1.2931831994134058e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0032258769497275352\n",
      "Gradient for encoder.encoder.4.bias: 0.0027290929574519396\n",
      "Gradient for encoder.mean.weight: 0.04388348013162613\n",
      "Gradient for encoder.mean.bias: 0.002052214927971363\n",
      "Gradient for encoder.log_var.weight: 0.02451500855386257\n",
      "Gradient for encoder.log_var.bias: 0.0012300043599680066\n",
      "Gradient for decoder.decoder.0.weight: 0.013369977474212646\n",
      "Gradient for decoder.decoder.0.bias: 1.0379763715206991e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0006207507103681564\n",
      "Gradient for decoder.decoder.1.bias: 0.0005085343145765364\n",
      "Gradient for decoder.decoder.3.weight: 0.012247168458998203\n",
      "Gradient for decoder.decoder.3.bias: 8.764785425219301e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00041700058500282466\n",
      "Gradient for decoder.decoder.4.bias: 0.0003815483651123941\n",
      "Gradient for decoder.decoder.6.weight: 0.0007063655066303909\n",
      "Gradient for decoder.decoder.6.bias: 4.4418622564990073e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.0055342852137982845\n",
      "Gradient for encoder.encoder.0.bias: 8.960718451966887e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.00039588293293491006\n",
      "Gradient for encoder.encoder.1.bias: 0.0004342530737631023\n",
      "Gradient for encoder.encoder.3.weight: 0.008373919874429703\n",
      "Gradient for encoder.encoder.3.bias: 1.0939728289915962e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0020923574920743704\n",
      "Gradient for encoder.encoder.4.bias: 0.0018668819684535265\n",
      "Gradient for encoder.mean.weight: 0.03253363072872162\n",
      "Gradient for encoder.mean.bias: 0.0014632914680987597\n",
      "Gradient for encoder.log_var.weight: 0.01923571154475212\n",
      "Gradient for encoder.log_var.bias: 0.00091878033708781\n",
      "Gradient for decoder.decoder.0.weight: 0.013285157270729542\n",
      "Gradient for decoder.decoder.0.bias: 1.15052987970099e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0006706150015816092\n",
      "Gradient for decoder.decoder.1.bias: 0.0005539424018934369\n",
      "Gradient for decoder.decoder.3.weight: 0.012838371098041534\n",
      "Gradient for decoder.decoder.3.bias: 1.0658272875385677e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0005012094043195248\n",
      "Gradient for decoder.decoder.4.bias: 0.0004709593195002526\n",
      "Gradient for decoder.decoder.6.weight: 0.0006935552810318768\n",
      "Gradient for decoder.decoder.6.bias: 3.930147067876533e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.011344167403876781\n",
      "Gradient for encoder.encoder.0.bias: 1.7164977772488044e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.000545259565114975\n",
      "Gradient for encoder.encoder.1.bias: 0.0005063727730885148\n",
      "Gradient for encoder.encoder.3.weight: 0.011860066093504429\n",
      "Gradient for encoder.encoder.3.bias: 1.451545411645938e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.002933905925601721\n",
      "Gradient for encoder.encoder.4.bias: 0.0027786761056631804\n",
      "Gradient for encoder.mean.weight: 0.04237458482384682\n",
      "Gradient for encoder.mean.bias: 0.001971501624211669\n",
      "Gradient for encoder.log_var.weight: 0.02179301343858242\n",
      "Gradient for encoder.log_var.bias: 0.0011373012093827128\n",
      "Gradient for decoder.decoder.0.weight: 0.010141260921955109\n",
      "Gradient for decoder.decoder.0.bias: 8.186928218689715e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.000521763926371932\n",
      "Gradient for decoder.decoder.1.bias: 0.0004330708470661193\n",
      "Gradient for decoder.decoder.3.weight: 0.009716114960610867\n",
      "Gradient for decoder.decoder.3.bias: 8.763707121106634e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0004565586568787694\n",
      "Gradient for decoder.decoder.4.bias: 0.0005215001292526722\n",
      "Gradient for decoder.decoder.6.weight: 0.0006689002038910985\n",
      "Gradient for decoder.decoder.6.bias: 4.170638931100257e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.008389614522457123\n",
      "Gradient for encoder.encoder.0.bias: 1.350511282666167e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.00047861188068054616\n",
      "Gradient for encoder.encoder.1.bias: 0.00045383378164842725\n",
      "Gradient for encoder.encoder.3.weight: 0.010976092889904976\n",
      "Gradient for encoder.encoder.3.bias: 1.2584815134442096e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0024402569979429245\n",
      "Gradient for encoder.encoder.4.bias: 0.002094932598993182\n",
      "Gradient for encoder.mean.weight: 0.036091387271881104\n",
      "Gradient for encoder.mean.bias: 0.0016377228312194347\n",
      "Gradient for encoder.log_var.weight: 0.020129697397351265\n",
      "Gradient for encoder.log_var.bias: 0.0010214844951406121\n",
      "Gradient for decoder.decoder.0.weight: 0.011156946420669556\n",
      "Gradient for decoder.decoder.0.bias: 9.797695293967124e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005311818677000701\n",
      "Gradient for decoder.decoder.1.bias: 0.0004585097194649279\n",
      "Gradient for decoder.decoder.3.weight: 0.010484335944056511\n",
      "Gradient for decoder.decoder.3.bias: 8.979398474773248e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0003872419474646449\n",
      "Gradient for decoder.decoder.4.bias: 0.00038168331957422197\n",
      "Gradient for decoder.decoder.6.weight: 0.0006877530831843615\n",
      "Gradient for decoder.decoder.6.bias: 4.238349720253609e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training VAE Epoch:  52%|█████▏    | 41/79 [00:00<00:00, 68.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient for encoder.encoder.0.weight: 0.010938364081084728\n",
      "Gradient for encoder.encoder.0.bias: 2.2358295770352754e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0005838663200847805\n",
      "Gradient for encoder.encoder.1.bias: 0.0005570460925810039\n",
      "Gradient for encoder.encoder.3.weight: 0.012496923096477985\n",
      "Gradient for encoder.encoder.3.bias: 1.384950210070457e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0028876871801912785\n",
      "Gradient for encoder.encoder.4.bias: 0.0022880651522427797\n",
      "Gradient for encoder.mean.weight: 0.03806379809975624\n",
      "Gradient for encoder.mean.bias: 0.00149090017657727\n",
      "Gradient for encoder.log_var.weight: 0.019849708303809166\n",
      "Gradient for encoder.log_var.bias: 0.0009920202428475022\n",
      "Gradient for decoder.decoder.0.weight: 0.009268734604120255\n",
      "Gradient for decoder.decoder.0.bias: 7.965116066710465e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.000451411004178226\n",
      "Gradient for decoder.decoder.1.bias: 0.0003885025216732174\n",
      "Gradient for decoder.decoder.3.weight: 0.008781182579696178\n",
      "Gradient for decoder.decoder.3.bias: 8.898426440140383e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0005444433772936463\n",
      "Gradient for decoder.decoder.4.bias: 0.0006269161822274327\n",
      "Gradient for decoder.decoder.6.weight: 0.0006594466394744813\n",
      "Gradient for decoder.decoder.6.bias: 4.485643148655072e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.007357265334576368\n",
      "Gradient for encoder.encoder.0.bias: 1.2521271346155327e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0004999771481379867\n",
      "Gradient for encoder.encoder.1.bias: 0.0006450308719649911\n",
      "Gradient for encoder.encoder.3.weight: 0.010618714615702629\n",
      "Gradient for encoder.encoder.3.bias: 1.3047504743290972e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.002812844468280673\n",
      "Gradient for encoder.encoder.4.bias: 0.0024073601234704256\n",
      "Gradient for encoder.mean.weight: 0.04172792658209801\n",
      "Gradient for encoder.mean.bias: 0.0016781678423285484\n",
      "Gradient for encoder.log_var.weight: 0.01974477805197239\n",
      "Gradient for encoder.log_var.bias: 0.0010763319442048669\n",
      "Gradient for decoder.decoder.0.weight: 0.012047057040035725\n",
      "Gradient for decoder.decoder.0.bias: 9.952969698412417e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005744464579038322\n",
      "Gradient for decoder.decoder.1.bias: 0.0005443620611913502\n",
      "Gradient for decoder.decoder.3.weight: 0.011538290418684483\n",
      "Gradient for decoder.decoder.3.bias: 1.0635159419791762e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0005172062083147466\n",
      "Gradient for decoder.decoder.4.bias: 0.000534613209310919\n",
      "Gradient for decoder.decoder.6.weight: 0.0006522872135974467\n",
      "Gradient for decoder.decoder.6.bias: 3.946643118979409e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.004736151546239853\n",
      "Gradient for encoder.encoder.0.bias: 8.098008374979315e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.0004911220748908818\n",
      "Gradient for encoder.encoder.1.bias: 0.0006201820797286928\n",
      "Gradient for encoder.encoder.3.weight: 0.009981351904571056\n",
      "Gradient for encoder.encoder.3.bias: 1.3598072667875272e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.003127085044980049\n",
      "Gradient for encoder.encoder.4.bias: 0.0031297418754547834\n",
      "Gradient for encoder.mean.weight: 0.04455145448446274\n",
      "Gradient for encoder.mean.bias: 0.0021774473134428263\n",
      "Gradient for encoder.log_var.weight: 0.02497544325888157\n",
      "Gradient for encoder.log_var.bias: 0.0013416369911283255\n",
      "Gradient for decoder.decoder.0.weight: 0.014598648995161057\n",
      "Gradient for decoder.decoder.0.bias: 1.2921738679061434e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0007131085731089115\n",
      "Gradient for decoder.decoder.1.bias: 0.0005844231927767396\n",
      "Gradient for decoder.decoder.3.weight: 0.013474498875439167\n",
      "Gradient for decoder.decoder.3.bias: 1.21941207131826e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0006303119007498026\n",
      "Gradient for decoder.decoder.4.bias: 0.0006915237754583359\n",
      "Gradient for decoder.decoder.6.weight: 0.0007456308812834322\n",
      "Gradient for decoder.decoder.6.bias: 4.7422934585483745e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.006989655550569296\n",
      "Gradient for encoder.encoder.0.bias: 1.1794495935468774e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0005077607347629964\n",
      "Gradient for encoder.encoder.1.bias: 0.00052074488485232\n",
      "Gradient for encoder.encoder.3.weight: 0.011234177276492119\n",
      "Gradient for encoder.encoder.3.bias: 1.1464944271732946e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0028448961675167084\n",
      "Gradient for encoder.encoder.4.bias: 0.002166489837691188\n",
      "Gradient for encoder.mean.weight: 0.039637304842472076\n",
      "Gradient for encoder.mean.bias: 0.001413433812558651\n",
      "Gradient for encoder.log_var.weight: 0.02237444557249546\n",
      "Gradient for encoder.log_var.bias: 0.0009459006832912564\n",
      "Gradient for decoder.decoder.0.weight: 0.013032502494752407\n",
      "Gradient for decoder.decoder.0.bias: 1.1281309220123603e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0006626002723351121\n",
      "Gradient for decoder.decoder.1.bias: 0.0005446194554679096\n",
      "Gradient for decoder.decoder.3.weight: 0.012495754286646843\n",
      "Gradient for decoder.decoder.3.bias: 9.636393072387506e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0005015340284444392\n",
      "Gradient for decoder.decoder.4.bias: 0.0004638125828932971\n",
      "Gradient for decoder.decoder.6.weight: 0.0006681102677248418\n",
      "Gradient for decoder.decoder.6.bias: 3.4577522455947474e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.006361640058457851\n",
      "Gradient for encoder.encoder.0.bias: 1.0212484503890895e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0004704338207375258\n",
      "Gradient for encoder.encoder.1.bias: 0.0005636353162117302\n",
      "Gradient for encoder.encoder.3.weight: 0.010013647377490997\n",
      "Gradient for encoder.encoder.3.bias: 1.2165793372709288e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0035485110711306334\n",
      "Gradient for encoder.encoder.4.bias: 0.0024387361481785774\n",
      "Gradient for encoder.mean.weight: 0.04810946807265282\n",
      "Gradient for encoder.mean.bias: 0.0016863051569089293\n",
      "Gradient for encoder.log_var.weight: 0.027653485536575317\n",
      "Gradient for encoder.log_var.bias: 0.0011674378765746951\n",
      "Gradient for decoder.decoder.0.weight: 0.012775599956512451\n",
      "Gradient for decoder.decoder.0.bias: 1.0845706277518019e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0005898561794310808\n",
      "Gradient for decoder.decoder.1.bias: 0.0005361609510146081\n",
      "Gradient for decoder.decoder.3.weight: 0.011352967470884323\n",
      "Gradient for decoder.decoder.3.bias: 1.0245392034757828e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.00039790794835425913\n",
      "Gradient for decoder.decoder.4.bias: 0.00037868396611884236\n",
      "Gradient for decoder.decoder.6.weight: 0.0006547938100993633\n",
      "Gradient for decoder.decoder.6.bias: 4.221112612867728e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.00708036171272397\n",
      "Gradient for encoder.encoder.0.bias: 1.137290175229344e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0004654747317545116\n",
      "Gradient for encoder.encoder.1.bias: 0.0005924369324930012\n",
      "Gradient for encoder.encoder.3.weight: 0.010423981584608555\n",
      "Gradient for encoder.encoder.3.bias: 1.0892783203209078e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.002970417495816946\n",
      "Gradient for encoder.encoder.4.bias: 0.0017757222522050142\n",
      "Gradient for encoder.mean.weight: 0.0412217415869236\n",
      "Gradient for encoder.mean.bias: 0.0012725985143333673\n",
      "Gradient for encoder.log_var.weight: 0.026997365057468414\n",
      "Gradient for encoder.log_var.bias: 0.0009857964469119906\n",
      "Gradient for decoder.decoder.0.weight: 0.012007770128548145\n",
      "Gradient for decoder.decoder.0.bias: 1.0519744797488073e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0005461539840325713\n",
      "Gradient for decoder.decoder.1.bias: 0.000489310419652611\n",
      "Gradient for decoder.decoder.3.weight: 0.010922751389443874\n",
      "Gradient for decoder.decoder.3.bias: 9.335814760147443e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0003990478871855885\n",
      "Gradient for decoder.decoder.4.bias: 0.0003865578328259289\n",
      "Gradient for decoder.decoder.6.weight: 0.0007286173640750349\n",
      "Gradient for decoder.decoder.6.bias: 5.144488750374876e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.007086286786943674\n",
      "Gradient for encoder.encoder.0.bias: 1.1363601899738729e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0005583618767559528\n",
      "Gradient for encoder.encoder.1.bias: 0.0006562123307958245\n",
      "Gradient for encoder.encoder.3.weight: 0.012159186415374279\n",
      "Gradient for encoder.encoder.3.bias: 1.4515778856694084e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0033850970212370157\n",
      "Gradient for encoder.encoder.4.bias: 0.003279915079474449\n",
      "Gradient for encoder.mean.weight: 0.04724601283669472\n",
      "Gradient for encoder.mean.bias: 0.002991817193105817\n",
      "Gradient for encoder.log_var.weight: 0.02712669037282467\n",
      "Gradient for encoder.log_var.bias: 0.0017786894459277391\n",
      "Gradient for decoder.decoder.0.weight: 0.012694277800619602\n",
      "Gradient for decoder.decoder.0.bias: 1.0199033978475214e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.000613574287854135\n",
      "Gradient for decoder.decoder.1.bias: 0.0004918192862533033\n",
      "Gradient for decoder.decoder.3.weight: 0.012009751982986927\n",
      "Gradient for decoder.decoder.3.bias: 9.419322960502186e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0004575842758640647\n",
      "Gradient for decoder.decoder.4.bias: 0.000392294954508543\n",
      "Gradient for decoder.decoder.6.weight: 0.0006761229014955461\n",
      "Gradient for decoder.decoder.6.bias: 3.877402559737675e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.0073654199950397015\n",
      "Gradient for encoder.encoder.0.bias: 1.3187858791119389e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.00045738433254882693\n",
      "Gradient for encoder.encoder.1.bias: 0.0005395770422182977\n",
      "Gradient for encoder.encoder.3.weight: 0.009647867642343044\n",
      "Gradient for encoder.encoder.3.bias: 1.7494725113031961e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.003212664043530822\n",
      "Gradient for encoder.encoder.4.bias: 0.0037294465582817793\n",
      "Gradient for encoder.mean.weight: 0.044035688042640686\n",
      "Gradient for encoder.mean.bias: 0.0027799534145742655\n",
      "Gradient for encoder.log_var.weight: 0.028882239013910294\n",
      "Gradient for encoder.log_var.bias: 0.0019823983311653137\n",
      "Gradient for decoder.decoder.0.weight: 0.01121462881565094\n",
      "Gradient for decoder.decoder.0.bias: 9.480963930608155e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005558276898227632\n",
      "Gradient for decoder.decoder.1.bias: 0.00043723295675590634\n",
      "Gradient for decoder.decoder.3.weight: 0.010420366190373898\n",
      "Gradient for decoder.decoder.3.bias: 8.047389837839702e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00040290073957294226\n",
      "Gradient for decoder.decoder.4.bias: 0.00037864467594772577\n",
      "Gradient for decoder.decoder.6.weight: 0.0006472558598034084\n",
      "Gradient for decoder.decoder.6.bias: 3.877569906762801e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.00882679596543312\n",
      "Gradient for encoder.encoder.0.bias: 1.5866774907835612e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0005496824160218239\n",
      "Gradient for encoder.encoder.1.bias: 0.0005208840593695641\n",
      "Gradient for encoder.encoder.3.weight: 0.012359926477074623\n",
      "Gradient for encoder.encoder.3.bias: 1.3596405945559553e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0030156734865158796\n",
      "Gradient for encoder.encoder.4.bias: 0.002391442423686385\n",
      "Gradient for encoder.mean.weight: 0.04155479371547699\n",
      "Gradient for encoder.mean.bias: 0.0016960935899987817\n",
      "Gradient for encoder.log_var.weight: 0.022718120366334915\n",
      "Gradient for encoder.log_var.bias: 0.0010808117222040892\n",
      "Gradient for decoder.decoder.0.weight: 0.009656882844865322\n",
      "Gradient for decoder.decoder.0.bias: 8.294489400872962e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.00043794128578156233\n",
      "Gradient for decoder.decoder.1.bias: 0.0003798721299972385\n",
      "Gradient for decoder.decoder.3.weight: 0.009029023349285126\n",
      "Gradient for decoder.decoder.3.bias: 7.449177386043004e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0003464656474534422\n",
      "Gradient for decoder.decoder.4.bias: 0.0002865989808924496\n",
      "Gradient for decoder.decoder.6.weight: 0.0006351335323415697\n",
      "Gradient for decoder.decoder.6.bias: 3.49602269125171e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.010261628776788712\n",
      "Gradient for encoder.encoder.0.bias: 1.9386653740682824e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0007133018225431442\n",
      "Gradient for encoder.encoder.1.bias: 0.0006170709966681898\n",
      "Gradient for encoder.encoder.3.weight: 0.014643142931163311\n",
      "Gradient for encoder.encoder.3.bias: 1.5552774346172527e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.00356334843672812\n",
      "Gradient for encoder.encoder.4.bias: 0.003299769014120102\n",
      "Gradient for encoder.mean.weight: 0.04970817640423775\n",
      "Gradient for encoder.mean.bias: 0.002144410740584135\n",
      "Gradient for encoder.log_var.weight: 0.030589783564209938\n",
      "Gradient for encoder.log_var.bias: 0.0012093853438273072\n",
      "Gradient for decoder.decoder.0.weight: 0.00917065516114235\n",
      "Gradient for decoder.decoder.0.bias: 7.997560252936964e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.00046297788503579795\n",
      "Gradient for decoder.decoder.1.bias: 0.0003559226170182228\n",
      "Gradient for decoder.decoder.3.weight: 0.008750888518989086\n",
      "Gradient for decoder.decoder.3.bias: 7.385524136704902e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00031876840512268245\n",
      "Gradient for decoder.decoder.4.bias: 0.00030218579922802746\n",
      "Gradient for decoder.decoder.6.weight: 0.000644773303065449\n",
      "Gradient for decoder.decoder.6.bias: 3.566980012692511e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.005098024848848581\n",
      "Gradient for encoder.encoder.0.bias: 8.487099044385271e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.0004428190004546195\n",
      "Gradient for encoder.encoder.1.bias: 0.00048497412353754044\n",
      "Gradient for encoder.encoder.3.weight: 0.009802188724279404\n",
      "Gradient for encoder.encoder.3.bias: 1.1019087725605559e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.003290467197075486\n",
      "Gradient for encoder.encoder.4.bias: 0.00238051381893456\n",
      "Gradient for encoder.mean.weight: 0.0481785386800766\n",
      "Gradient for encoder.mean.bias: 0.0014931896002963185\n",
      "Gradient for encoder.log_var.weight: 0.029045863077044487\n",
      "Gradient for encoder.log_var.bias: 0.001115610939450562\n",
      "Gradient for decoder.decoder.0.weight: 0.014593929052352905\n",
      "Gradient for decoder.decoder.0.bias: 1.2375260538544097e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0007176745566539466\n",
      "Gradient for decoder.decoder.1.bias: 0.0005837997887283564\n",
      "Gradient for decoder.decoder.3.weight: 0.013193873688578606\n",
      "Gradient for decoder.decoder.3.bias: 1.1029082508384747e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0005507948808372021\n",
      "Gradient for decoder.decoder.4.bias: 0.000545106828212738\n",
      "Gradient for decoder.decoder.6.weight: 0.0006903488538227975\n",
      "Gradient for decoder.decoder.6.bias: 3.7000791053287685e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.008525952696800232\n",
      "Gradient for encoder.encoder.0.bias: 1.2866341672634896e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0005065691075287759\n",
      "Gradient for encoder.encoder.1.bias: 0.00047643305151723325\n",
      "Gradient for encoder.encoder.3.weight: 0.010944204404950142\n",
      "Gradient for encoder.encoder.3.bias: 1.2027712159579096e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0024383494164794683\n",
      "Gradient for encoder.encoder.4.bias: 0.0021124728955328465\n",
      "Gradient for encoder.mean.weight: 0.03349748253822327\n",
      "Gradient for encoder.mean.bias: 0.0016468842513859272\n",
      "Gradient for encoder.log_var.weight: 0.019574318081140518\n",
      "Gradient for encoder.log_var.bias: 0.0010024902876466513\n",
      "Gradient for decoder.decoder.0.weight: 0.011150218546390533\n",
      "Gradient for decoder.decoder.0.bias: 1.0057848304212413e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.000573905068449676\n",
      "Gradient for decoder.decoder.1.bias: 0.0004568788572214544\n",
      "Gradient for decoder.decoder.3.weight: 0.010759192518889904\n",
      "Gradient for decoder.decoder.3.bias: 9.603828149407079e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0005162098677828908\n",
      "Gradient for decoder.decoder.4.bias: 0.0005181293818168342\n",
      "Gradient for decoder.decoder.6.weight: 0.0007298763957805932\n",
      "Gradient for decoder.decoder.6.bias: 4.5814427721779794e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.005838857498019934\n",
      "Gradient for encoder.encoder.0.bias: 1.1724557956449555e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0006583206704817712\n",
      "Gradient for encoder.encoder.1.bias: 0.00066476094070822\n",
      "Gradient for encoder.encoder.3.weight: 0.01417973730713129\n",
      "Gradient for encoder.encoder.3.bias: 1.4686601934599253e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0037533307913690805\n",
      "Gradient for encoder.encoder.4.bias: 0.003279920667409897\n",
      "Gradient for encoder.mean.weight: 0.054835475981235504\n",
      "Gradient for encoder.mean.bias: 0.0025370896328240633\n",
      "Gradient for encoder.log_var.weight: 0.028795843943953514\n",
      "Gradient for encoder.log_var.bias: 0.0013902724022045732\n",
      "Gradient for decoder.decoder.0.weight: 0.012401925399899483\n",
      "Gradient for decoder.decoder.0.bias: 1.0695937885385476e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0006380726699717343\n",
      "Gradient for decoder.decoder.1.bias: 0.000478583067888394\n",
      "Gradient for decoder.decoder.3.weight: 0.0115980738773942\n",
      "Gradient for decoder.decoder.3.bias: 8.602676210278659e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00048546382458880544\n",
      "Gradient for decoder.decoder.4.bias: 0.00043771014316007495\n",
      "Gradient for decoder.decoder.6.weight: 0.0006964097265154123\n",
      "Gradient for decoder.decoder.6.bias: 3.801369166467339e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.004871921148151159\n",
      "Gradient for encoder.encoder.0.bias: 8.725319945723786e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.0005133149679750204\n",
      "Gradient for encoder.encoder.1.bias: 0.0005345591343939304\n",
      "Gradient for encoder.encoder.3.weight: 0.010977122001349926\n",
      "Gradient for encoder.encoder.3.bias: 1.2084327982719856e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.003021800657734275\n",
      "Gradient for encoder.encoder.4.bias: 0.002403202233836055\n",
      "Gradient for encoder.mean.weight: 0.042877089232206345\n",
      "Gradient for encoder.mean.bias: 0.0018222290091216564\n",
      "Gradient for encoder.log_var.weight: 0.028324872255325317\n",
      "Gradient for encoder.log_var.bias: 0.001089888857677579\n",
      "Gradient for decoder.decoder.0.weight: 0.015099071897566319\n",
      "Gradient for decoder.decoder.0.bias: 1.3345381744134244e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0007665827870368958\n",
      "Gradient for decoder.decoder.1.bias: 0.0006015757098793983\n",
      "Gradient for decoder.decoder.3.weight: 0.014343639835715294\n",
      "Gradient for decoder.decoder.3.bias: 1.0989748694401058e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0006430702633224428\n",
      "Gradient for decoder.decoder.4.bias: 0.0006551235564984381\n",
      "Gradient for decoder.decoder.6.weight: 0.0008208034560084343\n",
      "Gradient for decoder.decoder.6.bias: 5.853994298377074e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.005147565621882677\n",
      "Gradient for encoder.encoder.0.bias: 9.934701498959253e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.0004918508348055184\n",
      "Gradient for encoder.encoder.1.bias: 0.0006389113259501755\n",
      "Gradient for encoder.encoder.3.weight: 0.010630999691784382\n",
      "Gradient for encoder.encoder.3.bias: 1.2782956637646947e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0033908118493855\n",
      "Gradient for encoder.encoder.4.bias: 0.0026084785349667072\n",
      "Gradient for encoder.mean.weight: 0.048461638391017914\n",
      "Gradient for encoder.mean.bias: 0.002073861425742507\n",
      "Gradient for encoder.log_var.weight: 0.029143691062927246\n",
      "Gradient for encoder.log_var.bias: 0.001265080412849784\n",
      "Gradient for decoder.decoder.0.weight: 0.012820648960769176\n",
      "Gradient for decoder.decoder.0.bias: 1.0881629625147937e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.000619349128101021\n",
      "Gradient for decoder.decoder.1.bias: 0.0005251873517408967\n",
      "Gradient for decoder.decoder.3.weight: 0.012356319464743137\n",
      "Gradient for decoder.decoder.3.bias: 9.021672298104022e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0004325375775806606\n",
      "Gradient for decoder.decoder.4.bias: 0.0003946615324821323\n",
      "Gradient for decoder.decoder.6.weight: 0.0007072330336086452\n",
      "Gradient for decoder.decoder.6.bias: 4.779845767188817e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.0058812228962779045\n",
      "Gradient for encoder.encoder.0.bias: 9.514260039533706e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.0004064648528583348\n",
      "Gradient for encoder.encoder.1.bias: 0.000465427030576393\n",
      "Gradient for encoder.encoder.3.weight: 0.00884831789880991\n",
      "Gradient for encoder.encoder.3.bias: 1.0369809871901836e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0023564465809613466\n",
      "Gradient for encoder.encoder.4.bias: 0.002082401653751731\n",
      "Gradient for encoder.mean.weight: 0.036988724023103714\n",
      "Gradient for encoder.mean.bias: 0.0016876420704647899\n",
      "Gradient for encoder.log_var.weight: 0.022148344665765762\n",
      "Gradient for encoder.log_var.bias: 0.0011414717882871628\n",
      "Gradient for decoder.decoder.0.weight: 0.013886955566704273\n",
      "Gradient for decoder.decoder.0.bias: 1.0252088067375098e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0006592563004232943\n",
      "Gradient for decoder.decoder.1.bias: 0.0005815252079628408\n",
      "Gradient for decoder.decoder.3.weight: 0.012769640423357487\n",
      "Gradient for decoder.decoder.3.bias: 9.211608559267503e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0004951428854838014\n",
      "Gradient for decoder.decoder.4.bias: 0.0004679405246861279\n",
      "Gradient for decoder.decoder.6.weight: 0.0007548462599515915\n",
      "Gradient for decoder.decoder.6.bias: 5.156608312972821e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training VAE Epoch:  72%|███████▏  | 57/79 [00:00<00:00, 72.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient for encoder.encoder.0.weight: 0.005360462237149477\n",
      "Gradient for encoder.encoder.0.bias: 9.066594697237917e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.000454923661891371\n",
      "Gradient for encoder.encoder.1.bias: 0.00046944545465521514\n",
      "Gradient for encoder.encoder.3.weight: 0.009951905347406864\n",
      "Gradient for encoder.encoder.3.bias: 1.0554394858086624e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0032409238629043102\n",
      "Gradient for encoder.encoder.4.bias: 0.0019374426919966936\n",
      "Gradient for encoder.mean.weight: 0.046070586889982224\n",
      "Gradient for encoder.mean.bias: 0.0015671716537326574\n",
      "Gradient for encoder.log_var.weight: 0.028380390256643295\n",
      "Gradient for encoder.log_var.bias: 0.000979285454377532\n",
      "Gradient for decoder.decoder.0.weight: 0.013549640774726868\n",
      "Gradient for decoder.decoder.0.bias: 1.1191799570431371e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.000657865428365767\n",
      "Gradient for decoder.decoder.1.bias: 0.0005526607274077833\n",
      "Gradient for decoder.decoder.3.weight: 0.012864787131547928\n",
      "Gradient for decoder.decoder.3.bias: 9.198608541538533e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0004336970450822264\n",
      "Gradient for decoder.decoder.4.bias: 0.00038842431968078017\n",
      "Gradient for decoder.decoder.6.weight: 0.0007085817633196712\n",
      "Gradient for decoder.decoder.6.bias: 4.678134428104386e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.005860996898263693\n",
      "Gradient for encoder.encoder.0.bias: 1.0014138823732921e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0004021812346763909\n",
      "Gradient for encoder.encoder.1.bias: 0.00040683153201825917\n",
      "Gradient for encoder.encoder.3.weight: 0.008977583609521389\n",
      "Gradient for encoder.encoder.3.bias: 1.1026017598947391e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0030059251002967358\n",
      "Gradient for encoder.encoder.4.bias: 0.002177601680159569\n",
      "Gradient for encoder.mean.weight: 0.04414208605885506\n",
      "Gradient for encoder.mean.bias: 0.0018487735651433468\n",
      "Gradient for encoder.log_var.weight: 0.023944998160004616\n",
      "Gradient for encoder.log_var.bias: 0.001074714818969369\n",
      "Gradient for decoder.decoder.0.weight: 0.012725076638162136\n",
      "Gradient for decoder.decoder.0.bias: 1.0487671148196043e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0006117078592069447\n",
      "Gradient for decoder.decoder.1.bias: 0.0005369972786866128\n",
      "Gradient for decoder.decoder.3.weight: 0.011483369395136833\n",
      "Gradient for decoder.decoder.3.bias: 9.713640308772753e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0004442530917003751\n",
      "Gradient for decoder.decoder.4.bias: 0.00045249846880324185\n",
      "Gradient for decoder.decoder.6.weight: 0.000629509100690484\n",
      "Gradient for decoder.decoder.6.bias: 3.2837953767739236e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.011525369249284267\n",
      "Gradient for encoder.encoder.0.bias: 2.2565052257284002e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0008719076868146658\n",
      "Gradient for encoder.encoder.1.bias: 0.0005313438014127314\n",
      "Gradient for encoder.encoder.3.weight: 0.01932738721370697\n",
      "Gradient for encoder.encoder.3.bias: 2.026102341456948e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.005188106093555689\n",
      "Gradient for encoder.encoder.4.bias: 0.004401049111038446\n",
      "Gradient for encoder.mean.weight: 0.07431203871965408\n",
      "Gradient for encoder.mean.bias: 0.002826569601893425\n",
      "Gradient for encoder.log_var.weight: 0.043620817363262177\n",
      "Gradient for encoder.log_var.bias: 0.001699924934655428\n",
      "Gradient for decoder.decoder.0.weight: 0.009489309042692184\n",
      "Gradient for decoder.decoder.0.bias: 7.02580979505818e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0004618512175511569\n",
      "Gradient for decoder.decoder.1.bias: 0.0003960363392252475\n",
      "Gradient for decoder.decoder.3.weight: 0.008809794671833515\n",
      "Gradient for decoder.decoder.3.bias: 7.096884191426511e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00031460748868994415\n",
      "Gradient for decoder.decoder.4.bias: 0.00027896877145394683\n",
      "Gradient for decoder.decoder.6.weight: 0.0006369129987433553\n",
      "Gradient for decoder.decoder.6.bias: 3.489935988909565e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.006067526061087847\n",
      "Gradient for encoder.encoder.0.bias: 1.016037861484298e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.00042045596637763083\n",
      "Gradient for encoder.encoder.1.bias: 0.00047299833386205137\n",
      "Gradient for encoder.encoder.3.weight: 0.009072680957615376\n",
      "Gradient for encoder.encoder.3.bias: 1.102216165560499e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0027041276916861534\n",
      "Gradient for encoder.encoder.4.bias: 0.0024207851383835077\n",
      "Gradient for encoder.mean.weight: 0.03972259536385536\n",
      "Gradient for encoder.mean.bias: 0.001995338825508952\n",
      "Gradient for encoder.log_var.weight: 0.024913998320698738\n",
      "Gradient for encoder.log_var.bias: 0.0011748045217245817\n",
      "Gradient for decoder.decoder.0.weight: 0.012045376002788544\n",
      "Gradient for decoder.decoder.0.bias: 1.1150853157504415e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0006139336037449539\n",
      "Gradient for decoder.decoder.1.bias: 0.0005032418412156403\n",
      "Gradient for decoder.decoder.3.weight: 0.011496171355247498\n",
      "Gradient for decoder.decoder.3.bias: 9.300639425280366e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0004113128816243261\n",
      "Gradient for decoder.decoder.4.bias: 0.0003498669248074293\n",
      "Gradient for decoder.decoder.6.weight: 0.0007196830702014267\n",
      "Gradient for decoder.decoder.6.bias: 4.758853538078256e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.004468939732760191\n",
      "Gradient for encoder.encoder.0.bias: 7.656607986517017e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.0003813710354734212\n",
      "Gradient for encoder.encoder.1.bias: 0.000429683830589056\n",
      "Gradient for encoder.encoder.3.weight: 0.007907404564321041\n",
      "Gradient for encoder.encoder.3.bias: 1.1014805734177457e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0024390683975070715\n",
      "Gradient for encoder.encoder.4.bias: 0.002009832765907049\n",
      "Gradient for encoder.mean.weight: 0.03377506509423256\n",
      "Gradient for encoder.mean.bias: 0.0014413055032491684\n",
      "Gradient for encoder.log_var.weight: 0.021295325830578804\n",
      "Gradient for encoder.log_var.bias: 0.000937954057008028\n",
      "Gradient for decoder.decoder.0.weight: 0.014282653108239174\n",
      "Gradient for decoder.decoder.0.bias: 1.1661221988035209e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0007148286676965654\n",
      "Gradient for decoder.decoder.1.bias: 0.000582653097808361\n",
      "Gradient for decoder.decoder.3.weight: 0.013213218189775944\n",
      "Gradient for decoder.decoder.3.bias: 1.2705149432523655e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0007228824542835355\n",
      "Gradient for decoder.decoder.4.bias: 0.0007615671493113041\n",
      "Gradient for decoder.decoder.6.weight: 0.0008341677603311837\n",
      "Gradient for decoder.decoder.6.bias: 5.742510256823152e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.004297541454434395\n",
      "Gradient for encoder.encoder.0.bias: 6.665030940350425e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.0003777607053052634\n",
      "Gradient for encoder.encoder.1.bias: 0.0003877469280268997\n",
      "Gradient for encoder.encoder.3.weight: 0.008358541876077652\n",
      "Gradient for encoder.encoder.3.bias: 1.0938475819566307e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0031906208023428917\n",
      "Gradient for encoder.encoder.4.bias: 0.002312124939635396\n",
      "Gradient for encoder.mean.weight: 0.048506464809179306\n",
      "Gradient for encoder.mean.bias: 0.0012582774506881833\n",
      "Gradient for encoder.log_var.weight: 0.025642860680818558\n",
      "Gradient for encoder.log_var.bias: 0.0009037783602252603\n",
      "Gradient for decoder.decoder.0.weight: 0.015583486296236515\n",
      "Gradient for decoder.decoder.0.bias: 1.1793840903884245e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0008048656163737178\n",
      "Gradient for decoder.decoder.1.bias: 0.0006661340012215078\n",
      "Gradient for decoder.decoder.3.weight: 0.014807356521487236\n",
      "Gradient for decoder.decoder.3.bias: 1.1426810886394634e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0005573370144702494\n",
      "Gradient for decoder.decoder.4.bias: 0.0004656960954889655\n",
      "Gradient for decoder.decoder.6.weight: 0.0007288937922567129\n",
      "Gradient for decoder.decoder.6.bias: 4.157695366302505e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.0059675732627511024\n",
      "Gradient for encoder.encoder.0.bias: 1.052112997418364e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.000589904491789639\n",
      "Gradient for encoder.encoder.1.bias: 0.0007064035744406283\n",
      "Gradient for encoder.encoder.3.weight: 0.012878109700977802\n",
      "Gradient for encoder.encoder.3.bias: 1.1336802330230711e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.003830929519608617\n",
      "Gradient for encoder.encoder.4.bias: 0.0023676909040659666\n",
      "Gradient for encoder.mean.weight: 0.058396466076374054\n",
      "Gradient for encoder.mean.bias: 0.0016168334987014532\n",
      "Gradient for encoder.log_var.weight: 0.029926691204309464\n",
      "Gradient for encoder.log_var.bias: 0.0009623386431485415\n",
      "Gradient for decoder.decoder.0.weight: 0.01242643129080534\n",
      "Gradient for decoder.decoder.0.bias: 9.652326854459048e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005614531110040843\n",
      "Gradient for decoder.decoder.1.bias: 0.0004978097858838737\n",
      "Gradient for decoder.decoder.3.weight: 0.010609732009470463\n",
      "Gradient for decoder.decoder.3.bias: 8.067865819860742e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0004083499079570174\n",
      "Gradient for decoder.decoder.4.bias: 0.00037623883690685034\n",
      "Gradient for decoder.decoder.6.weight: 0.0006507244543172419\n",
      "Gradient for decoder.decoder.6.bias: 3.975912477471866e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.0057022105902433395\n",
      "Gradient for encoder.encoder.0.bias: 9.190315175544583e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.00048729704576544464\n",
      "Gradient for encoder.encoder.1.bias: 0.0005198530852794647\n",
      "Gradient for encoder.encoder.3.weight: 0.010539931245148182\n",
      "Gradient for encoder.encoder.3.bias: 1.0412733869591406e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.002654024865478277\n",
      "Gradient for encoder.encoder.4.bias: 0.0019495143787935376\n",
      "Gradient for encoder.mean.weight: 0.03870893642306328\n",
      "Gradient for encoder.mean.bias: 0.0015056191477924585\n",
      "Gradient for encoder.log_var.weight: 0.023045668378472328\n",
      "Gradient for encoder.log_var.bias: 0.0009209804702550173\n",
      "Gradient for decoder.decoder.0.weight: 0.01337882038205862\n",
      "Gradient for decoder.decoder.0.bias: 1.0994904292571661e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0007017833995632827\n",
      "Gradient for decoder.decoder.1.bias: 0.0005293592112138867\n",
      "Gradient for decoder.decoder.3.weight: 0.012909842655062675\n",
      "Gradient for decoder.decoder.3.bias: 9.023885111369978e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0005653314292430878\n",
      "Gradient for decoder.decoder.4.bias: 0.0005239841411821544\n",
      "Gradient for decoder.decoder.6.weight: 0.0006945579661987722\n",
      "Gradient for decoder.decoder.6.bias: 4.0417162381345406e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.005709639750421047\n",
      "Gradient for encoder.encoder.0.bias: 1.0530013493104118e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.00041447774856351316\n",
      "Gradient for encoder.encoder.1.bias: 0.00046018583816476166\n",
      "Gradient for encoder.encoder.3.weight: 0.009240956045687199\n",
      "Gradient for encoder.encoder.3.bias: 1.1146906314651872e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0028498596511781216\n",
      "Gradient for encoder.encoder.4.bias: 0.002182393567636609\n",
      "Gradient for encoder.mean.weight: 0.04137071967124939\n",
      "Gradient for encoder.mean.bias: 0.0016709835035726428\n",
      "Gradient for encoder.log_var.weight: 0.02439761348068714\n",
      "Gradient for encoder.log_var.bias: 0.0011266454821452498\n",
      "Gradient for decoder.decoder.0.weight: 0.012176474556326866\n",
      "Gradient for decoder.decoder.0.bias: 1.0116271709215141e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0006110304384492338\n",
      "Gradient for decoder.decoder.1.bias: 0.00047095329500734806\n",
      "Gradient for decoder.decoder.3.weight: 0.01129137258976698\n",
      "Gradient for decoder.decoder.3.bias: 9.042335630260467e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00039108184864744544\n",
      "Gradient for decoder.decoder.4.bias: 0.0003367273893672973\n",
      "Gradient for decoder.decoder.6.weight: 0.0006088110967539251\n",
      "Gradient for decoder.decoder.6.bias: 3.053819091292098e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.008741595782339573\n",
      "Gradient for encoder.encoder.0.bias: 1.4093930016112477e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0006481929449364543\n",
      "Gradient for encoder.encoder.1.bias: 0.0006622961373068392\n",
      "Gradient for encoder.encoder.3.weight: 0.013307612389326096\n",
      "Gradient for encoder.encoder.3.bias: 1.4457658681354957e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.00327675836160779\n",
      "Gradient for encoder.encoder.4.bias: 0.0029807917308062315\n",
      "Gradient for encoder.mean.weight: 0.0471012219786644\n",
      "Gradient for encoder.mean.bias: 0.002551192417740822\n",
      "Gradient for encoder.log_var.weight: 0.02582446299493313\n",
      "Gradient for encoder.log_var.bias: 0.0015232176519930363\n",
      "Gradient for decoder.decoder.0.weight: 0.010486054234206676\n",
      "Gradient for decoder.decoder.0.bias: 8.179844995792607e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0004835895961150527\n",
      "Gradient for decoder.decoder.1.bias: 0.0003706249117385596\n",
      "Gradient for decoder.decoder.3.weight: 0.00951662752777338\n",
      "Gradient for decoder.decoder.3.bias: 6.770709687353715e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00033520953729748726\n",
      "Gradient for decoder.decoder.4.bias: 0.0002993975067511201\n",
      "Gradient for decoder.decoder.6.weight: 0.0006666474509984255\n",
      "Gradient for decoder.decoder.6.bias: 3.915580236935057e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.0041840351186692715\n",
      "Gradient for encoder.encoder.0.bias: 7.86755296328101e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.0003899360017385334\n",
      "Gradient for encoder.encoder.1.bias: 0.0004743457830045372\n",
      "Gradient for encoder.encoder.3.weight: 0.008738057687878609\n",
      "Gradient for encoder.encoder.3.bias: 1.0410369094548955e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.00294125871732831\n",
      "Gradient for encoder.encoder.4.bias: 0.0018310993909835815\n",
      "Gradient for encoder.mean.weight: 0.04584992304444313\n",
      "Gradient for encoder.mean.bias: 0.0012940318556502461\n",
      "Gradient for encoder.log_var.weight: 0.026199793443083763\n",
      "Gradient for encoder.log_var.bias: 0.0008874117629602551\n",
      "Gradient for decoder.decoder.0.weight: 0.014028730802237988\n",
      "Gradient for decoder.decoder.0.bias: 1.1782455566766714e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0006447755731642246\n",
      "Gradient for decoder.decoder.1.bias: 0.0005735172890126705\n",
      "Gradient for decoder.decoder.3.weight: 0.013406834565103054\n",
      "Gradient for decoder.decoder.3.bias: 1.0964156665904667e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0004997138166800141\n",
      "Gradient for decoder.decoder.4.bias: 0.0004496386682149023\n",
      "Gradient for decoder.decoder.6.weight: 0.0006895555998198688\n",
      "Gradient for decoder.decoder.6.bias: 4.0168586565414444e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.004517401102930307\n",
      "Gradient for encoder.encoder.0.bias: 7.912170051083134e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.0002967157051898539\n",
      "Gradient for encoder.encoder.1.bias: 0.00036697398172691464\n",
      "Gradient for encoder.encoder.3.weight: 0.0065744053572416306\n",
      "Gradient for encoder.encoder.3.bias: 1.0294931573895383e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0022759821731597185\n",
      "Gradient for encoder.encoder.4.bias: 0.0016499222256243229\n",
      "Gradient for encoder.mean.weight: 0.035059262067079544\n",
      "Gradient for encoder.mean.bias: 0.0012257195776328444\n",
      "Gradient for encoder.log_var.weight: 0.023589592427015305\n",
      "Gradient for encoder.log_var.bias: 0.0008534488151781261\n",
      "Gradient for decoder.decoder.0.weight: 0.013332189060747623\n",
      "Gradient for decoder.decoder.0.bias: 1.0967863423028135e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.000679781602229923\n",
      "Gradient for decoder.decoder.1.bias: 0.0005380036309361458\n",
      "Gradient for decoder.decoder.3.weight: 0.012719814665615559\n",
      "Gradient for decoder.decoder.3.bias: 9.015230229003635e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0004607244045473635\n",
      "Gradient for decoder.decoder.4.bias: 0.0004113907052669674\n",
      "Gradient for decoder.decoder.6.weight: 0.0006608832045458257\n",
      "Gradient for decoder.decoder.6.bias: 3.456749618635513e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.007966848090291023\n",
      "Gradient for encoder.encoder.0.bias: 1.3917100111227043e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0005101801943965256\n",
      "Gradient for encoder.encoder.1.bias: 0.0004940415383316576\n",
      "Gradient for encoder.encoder.3.weight: 0.011268067173659801\n",
      "Gradient for encoder.encoder.3.bias: 1.3156160882932255e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.002932189265266061\n",
      "Gradient for encoder.encoder.4.bias: 0.002695084549486637\n",
      "Gradient for encoder.mean.weight: 0.04294409975409508\n",
      "Gradient for encoder.mean.bias: 0.0021391974296420813\n",
      "Gradient for encoder.log_var.weight: 0.024227704852819443\n",
      "Gradient for encoder.log_var.bias: 0.001453746110200882\n",
      "Gradient for decoder.decoder.0.weight: 0.01230690535157919\n",
      "Gradient for decoder.decoder.0.bias: 9.709548443037619e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005625475896522403\n",
      "Gradient for decoder.decoder.1.bias: 0.0005390052101574838\n",
      "Gradient for decoder.decoder.3.weight: 0.011315657757222652\n",
      "Gradient for decoder.decoder.3.bias: 9.109075993496418e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00043306220322847366\n",
      "Gradient for decoder.decoder.4.bias: 0.0004288012278266251\n",
      "Gradient for decoder.decoder.6.weight: 0.0006361019914038479\n",
      "Gradient for decoder.decoder.6.bias: 3.158263643854298e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.008308077231049538\n",
      "Gradient for encoder.encoder.0.bias: 1.3958025707472288e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0006507753278128803\n",
      "Gradient for encoder.encoder.1.bias: 0.0006813894724473357\n",
      "Gradient for encoder.encoder.3.weight: 0.013149444945156574\n",
      "Gradient for encoder.encoder.3.bias: 1.40832664974333e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.003084175055846572\n",
      "Gradient for encoder.encoder.4.bias: 0.002721874974668026\n",
      "Gradient for encoder.mean.weight: 0.04221034795045853\n",
      "Gradient for encoder.mean.bias: 0.0020859926007688046\n",
      "Gradient for encoder.log_var.weight: 0.02521989867091179\n",
      "Gradient for encoder.log_var.bias: 0.0013043549843132496\n",
      "Gradient for decoder.decoder.0.weight: 0.011530648916959763\n",
      "Gradient for decoder.decoder.0.bias: 9.529778355332752e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005574946408160031\n",
      "Gradient for decoder.decoder.1.bias: 0.0005172447999939322\n",
      "Gradient for decoder.decoder.3.weight: 0.010981844738125801\n",
      "Gradient for decoder.decoder.3.bias: 8.574799204019712e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0004263180890120566\n",
      "Gradient for decoder.decoder.4.bias: 0.0004086588160134852\n",
      "Gradient for decoder.decoder.6.weight: 0.0006701376987621188\n",
      "Gradient for decoder.decoder.6.bias: 4.110639201826416e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.00603936892002821\n",
      "Gradient for encoder.encoder.0.bias: 9.173987090826952e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.00046487082727253437\n",
      "Gradient for encoder.encoder.1.bias: 0.0004726434708572924\n",
      "Gradient for encoder.encoder.3.weight: 0.010382355190813541\n",
      "Gradient for encoder.encoder.3.bias: 1.1675391209386987e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0026716114953160286\n",
      "Gradient for encoder.encoder.4.bias: 0.0017227772623300552\n",
      "Gradient for encoder.mean.weight: 0.037926964461803436\n",
      "Gradient for encoder.mean.bias: 0.0011903259437531233\n",
      "Gradient for encoder.log_var.weight: 0.023073777556419373\n",
      "Gradient for encoder.log_var.bias: 0.0009426270262338221\n",
      "Gradient for decoder.decoder.0.weight: 0.012419979088008404\n",
      "Gradient for decoder.decoder.0.bias: 1.0332770056242779e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0006121769547462463\n",
      "Gradient for decoder.decoder.1.bias: 0.0005243507330305874\n",
      "Gradient for decoder.decoder.3.weight: 0.01158637460321188\n",
      "Gradient for decoder.decoder.3.bias: 8.582580479643553e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00040306910523213446\n",
      "Gradient for decoder.decoder.4.bias: 0.00036026319139637053\n",
      "Gradient for decoder.decoder.6.weight: 0.0007165907300077379\n",
      "Gradient for decoder.decoder.6.bias: 4.471445208764635e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.0055092028342187405\n",
      "Gradient for encoder.encoder.0.bias: 9.682525614618243e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.0005812740419059992\n",
      "Gradient for encoder.encoder.1.bias: 0.0007767825154587626\n",
      "Gradient for encoder.encoder.3.weight: 0.011913069523870945\n",
      "Gradient for encoder.encoder.3.bias: 1.203039889929869e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.004284200724214315\n",
      "Gradient for encoder.encoder.4.bias: 0.002896953606978059\n",
      "Gradient for encoder.mean.weight: 0.061212483793497086\n",
      "Gradient for encoder.mean.bias: 0.0022285371087491512\n",
      "Gradient for encoder.log_var.weight: 0.03514517471194267\n",
      "Gradient for encoder.log_var.bias: 0.0014625226613134146\n",
      "Gradient for decoder.decoder.0.weight: 0.013987584970891476\n",
      "Gradient for decoder.decoder.0.bias: 1.232033502995833e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0006264825933612883\n",
      "Gradient for decoder.decoder.1.bias: 0.0006357220117934048\n",
      "Gradient for decoder.decoder.3.weight: 0.01267801970243454\n",
      "Gradient for decoder.decoder.3.bias: 1.1840231572968207e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0005070454208180308\n",
      "Gradient for decoder.decoder.4.bias: 0.0005752015858888626\n",
      "Gradient for decoder.decoder.6.weight: 0.0007610946777276695\n",
      "Gradient for decoder.decoder.6.bias: 5.313465590006672e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training VAE Epoch:  92%|█████████▏| 73/79 [00:01<00:00, 75.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient for encoder.encoder.0.weight: 0.006736340466886759\n",
      "Gradient for encoder.encoder.0.bias: 1.3881560831374706e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.00041660876013338566\n",
      "Gradient for encoder.encoder.1.bias: 0.0004850237164646387\n",
      "Gradient for encoder.encoder.3.weight: 0.008779168128967285\n",
      "Gradient for encoder.encoder.3.bias: 1.1775157238158585e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.00231840624473989\n",
      "Gradient for encoder.encoder.4.bias: 0.0021129699889570475\n",
      "Gradient for encoder.mean.weight: 0.03420451283454895\n",
      "Gradient for encoder.mean.bias: 0.0016139388317242265\n",
      "Gradient for encoder.log_var.weight: 0.019155064597725868\n",
      "Gradient for encoder.log_var.bias: 0.0010231425985693932\n",
      "Gradient for decoder.decoder.0.weight: 0.009998629800975323\n",
      "Gradient for decoder.decoder.0.bias: 8.81978379219106e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.00048607130884192884\n",
      "Gradient for decoder.decoder.1.bias: 0.0004331546660978347\n",
      "Gradient for decoder.decoder.3.weight: 0.009290916845202446\n",
      "Gradient for decoder.decoder.3.bias: 9.527343497461871e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0006882966845296323\n",
      "Gradient for decoder.decoder.4.bias: 0.0008400908554904163\n",
      "Gradient for decoder.decoder.6.weight: 0.0007493537850677967\n",
      "Gradient for decoder.decoder.6.bias: 6.130949623184279e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.006999528966844082\n",
      "Gradient for encoder.encoder.0.bias: 1.1868880010756921e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0004509256104938686\n",
      "Gradient for encoder.encoder.1.bias: 0.0004701276193372905\n",
      "Gradient for encoder.encoder.3.weight: 0.009369131177663803\n",
      "Gradient for encoder.encoder.3.bias: 1.0855313176127979e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.002500711940228939\n",
      "Gradient for encoder.encoder.4.bias: 0.002038222271949053\n",
      "Gradient for encoder.mean.weight: 0.03711964935064316\n",
      "Gradient for encoder.mean.bias: 0.0015485943295061588\n",
      "Gradient for encoder.log_var.weight: 0.020291533321142197\n",
      "Gradient for encoder.log_var.bias: 0.001024399301968515\n",
      "Gradient for decoder.decoder.0.weight: 0.010932480916380882\n",
      "Gradient for decoder.decoder.0.bias: 9.715270254950781e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005343149532563984\n",
      "Gradient for decoder.decoder.1.bias: 0.0004316438571549952\n",
      "Gradient for decoder.decoder.3.weight: 0.009910361841320992\n",
      "Gradient for decoder.decoder.3.bias: 8.863214329135616e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0004923965898342431\n",
      "Gradient for decoder.decoder.4.bias: 0.0005459896638058126\n",
      "Gradient for decoder.decoder.6.weight: 0.0006744703277945518\n",
      "Gradient for decoder.decoder.6.bias: 4.2393949115648866e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.008635043166577816\n",
      "Gradient for encoder.encoder.0.bias: 1.4394971326048278e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0005097364773973823\n",
      "Gradient for encoder.encoder.1.bias: 0.00041676900582388043\n",
      "Gradient for encoder.encoder.3.weight: 0.011183081194758415\n",
      "Gradient for encoder.encoder.3.bias: 1.6179582673636617e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.003703912254422903\n",
      "Gradient for encoder.encoder.4.bias: 0.003359014866873622\n",
      "Gradient for encoder.mean.weight: 0.051110055297613144\n",
      "Gradient for encoder.mean.bias: 0.0025235286448150873\n",
      "Gradient for encoder.log_var.weight: 0.024506544694304466\n",
      "Gradient for encoder.log_var.bias: 0.0013264128938317299\n",
      "Gradient for decoder.decoder.0.weight: 0.010519707575440407\n",
      "Gradient for decoder.decoder.0.bias: 8.499343590040453e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005247291410341859\n",
      "Gradient for decoder.decoder.1.bias: 0.0004482678195927292\n",
      "Gradient for decoder.decoder.3.weight: 0.010317720472812653\n",
      "Gradient for decoder.decoder.3.bias: 7.587827588473317e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0003937438887078315\n",
      "Gradient for decoder.decoder.4.bias: 0.00035146146547049284\n",
      "Gradient for decoder.decoder.6.weight: 0.0006134223658591509\n",
      "Gradient for decoder.decoder.6.bias: 2.786653749353718e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.00499303312972188\n",
      "Gradient for encoder.encoder.0.bias: 7.79922827709445e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.00037801527651026845\n",
      "Gradient for encoder.encoder.1.bias: 0.0004287798365112394\n",
      "Gradient for encoder.encoder.3.weight: 0.008544934913516045\n",
      "Gradient for encoder.encoder.3.bias: 1.0554304652465873e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0028553754091262817\n",
      "Gradient for encoder.encoder.4.bias: 0.0019069911213591695\n",
      "Gradient for encoder.mean.weight: 0.04054265469312668\n",
      "Gradient for encoder.mean.bias: 0.001318162539973855\n",
      "Gradient for encoder.log_var.weight: 0.025813013315200806\n",
      "Gradient for encoder.log_var.bias: 0.0010487986728549004\n",
      "Gradient for decoder.decoder.0.weight: 0.014330063946545124\n",
      "Gradient for decoder.decoder.0.bias: 1.1580939679456392e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0007713395752944052\n",
      "Gradient for decoder.decoder.1.bias: 0.0006103587220422924\n",
      "Gradient for decoder.decoder.3.weight: 0.013737821951508522\n",
      "Gradient for decoder.decoder.3.bias: 1.0161263497288076e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0005272378330118954\n",
      "Gradient for decoder.decoder.4.bias: 0.0004524002142716199\n",
      "Gradient for decoder.decoder.6.weight: 0.0007194618810899556\n",
      "Gradient for decoder.decoder.6.bias: 4.138119038543664e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.008415409363806248\n",
      "Gradient for encoder.encoder.0.bias: 1.2986637806799983e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0006755033391527832\n",
      "Gradient for encoder.encoder.1.bias: 0.0005952504579909146\n",
      "Gradient for encoder.encoder.3.weight: 0.01396471168845892\n",
      "Gradient for encoder.encoder.3.bias: 1.1839555724701967e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0029417066834867\n",
      "Gradient for encoder.encoder.4.bias: 0.0019192314939573407\n",
      "Gradient for encoder.mean.weight: 0.036075133830308914\n",
      "Gradient for encoder.mean.bias: 0.0013711986830458045\n",
      "Gradient for encoder.log_var.weight: 0.021900290623307228\n",
      "Gradient for encoder.log_var.bias: 0.0009386347373947501\n",
      "Gradient for decoder.decoder.0.weight: 0.011111312545835972\n",
      "Gradient for decoder.decoder.0.bias: 9.54932868890701e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005255613941699266\n",
      "Gradient for decoder.decoder.1.bias: 0.0004348814254626632\n",
      "Gradient for decoder.decoder.3.weight: 0.01041056402027607\n",
      "Gradient for decoder.decoder.3.bias: 8.000290707688151e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00037502439226955175\n",
      "Gradient for decoder.decoder.4.bias: 0.00032872785232029855\n",
      "Gradient for decoder.decoder.6.weight: 0.0006511110113933682\n",
      "Gradient for decoder.decoder.6.bias: 3.164868030580692e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.0058980840258300304\n",
      "Gradient for encoder.encoder.0.bias: 9.891979596554634e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.0004889941774308681\n",
      "Gradient for encoder.encoder.1.bias: 0.0005315832095220685\n",
      "Gradient for encoder.encoder.3.weight: 0.010475996881723404\n",
      "Gradient for encoder.encoder.3.bias: 1.4049922336667464e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.003089068690314889\n",
      "Gradient for encoder.encoder.4.bias: 0.003374359803274274\n",
      "Gradient for encoder.mean.weight: 0.04362694174051285\n",
      "Gradient for encoder.mean.bias: 0.0027730255387723446\n",
      "Gradient for encoder.log_var.weight: 0.02892190031707287\n",
      "Gradient for encoder.log_var.bias: 0.001841745455749333\n",
      "Gradient for decoder.decoder.0.weight: 0.012006674893200397\n",
      "Gradient for decoder.decoder.0.bias: 1.0744898026882055e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0006052284152247012\n",
      "Gradient for decoder.decoder.1.bias: 0.0005229596863500774\n",
      "Gradient for decoder.decoder.3.weight: 0.0111493906006217\n",
      "Gradient for decoder.decoder.3.bias: 9.48717146509459e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0003998061001766473\n",
      "Gradient for decoder.decoder.4.bias: 0.0003960855829063803\n",
      "Gradient for decoder.decoder.6.weight: 0.0006616170285269618\n",
      "Gradient for decoder.decoder.6.bias: 4.005496157333255e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.005360323935747147\n",
      "Gradient for encoder.encoder.0.bias: 1.0763840339877984e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.000531644094735384\n",
      "Gradient for encoder.encoder.1.bias: 0.0005851287278346717\n",
      "Gradient for encoder.encoder.3.weight: 0.011449022218585014\n",
      "Gradient for encoder.encoder.3.bias: 1.2816052386011023e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.003354601329192519\n",
      "Gradient for encoder.encoder.4.bias: 0.0031426039058715105\n",
      "Gradient for encoder.mean.weight: 0.04492055997252464\n",
      "Gradient for encoder.mean.bias: 0.002396757248789072\n",
      "Gradient for encoder.log_var.weight: 0.02997661381959915\n",
      "Gradient for encoder.log_var.bias: 0.0017358011100441217\n",
      "Gradient for decoder.decoder.0.weight: 0.012436866760253906\n",
      "Gradient for decoder.decoder.0.bias: 1.115610243074272e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0006473007379099727\n",
      "Gradient for decoder.decoder.1.bias: 0.000523150316439569\n",
      "Gradient for decoder.decoder.3.weight: 0.011762707494199276\n",
      "Gradient for decoder.decoder.3.bias: 9.154085128804113e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00044569256715476513\n",
      "Gradient for decoder.decoder.4.bias: 0.0004005036607850343\n",
      "Gradient for decoder.decoder.6.weight: 0.0006630932330153883\n",
      "Gradient for decoder.decoder.6.bias: 3.867653867928311e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.005995980463922024\n",
      "Gradient for encoder.encoder.0.bias: 9.97892480453233e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.00046910910168662667\n",
      "Gradient for encoder.encoder.1.bias: 0.0005280181067064404\n",
      "Gradient for encoder.encoder.3.weight: 0.010062707588076591\n",
      "Gradient for encoder.encoder.3.bias: 1.1063330113136871e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.003016997594386339\n",
      "Gradient for encoder.encoder.4.bias: 0.002068523783236742\n",
      "Gradient for encoder.mean.weight: 0.04685729369521141\n",
      "Gradient for encoder.mean.bias: 0.0015846858732402325\n",
      "Gradient for encoder.log_var.weight: 0.026013212278485298\n",
      "Gradient for encoder.log_var.bias: 0.001000066171400249\n",
      "Gradient for decoder.decoder.0.weight: 0.012633799575269222\n",
      "Gradient for decoder.decoder.0.bias: 1.1532362564903309e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0006136322044767439\n",
      "Gradient for decoder.decoder.1.bias: 0.0005358463968150318\n",
      "Gradient for decoder.decoder.3.weight: 0.011929718777537346\n",
      "Gradient for decoder.decoder.3.bias: 9.163781539145432e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00043899708543904126\n",
      "Gradient for decoder.decoder.4.bias: 0.000370902445865795\n",
      "Gradient for decoder.decoder.6.weight: 0.0007019779295660555\n",
      "Gradient for decoder.decoder.6.bias: 3.9530976209789515e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.006816460285335779\n",
      "Gradient for encoder.encoder.0.bias: 1.1277498032646882e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0006104864878579974\n",
      "Gradient for encoder.encoder.1.bias: 0.0005639599403366446\n",
      "Gradient for encoder.encoder.3.weight: 0.013590444810688496\n",
      "Gradient for encoder.encoder.3.bias: 1.3839512869040504e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0032427841797471046\n",
      "Gradient for encoder.encoder.4.bias: 0.0027471035718917847\n",
      "Gradient for encoder.mean.weight: 0.04779877886176109\n",
      "Gradient for encoder.mean.bias: 0.002118660369887948\n",
      "Gradient for encoder.log_var.weight: 0.026092519983649254\n",
      "Gradient for encoder.log_var.bias: 0.0012242080410942435\n",
      "Gradient for decoder.decoder.0.weight: 0.012911222875118256\n",
      "Gradient for decoder.decoder.0.bias: 1.0429074270845717e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0006253863102756441\n",
      "Gradient for decoder.decoder.1.bias: 0.0005049687460996211\n",
      "Gradient for decoder.decoder.3.weight: 0.01177870575338602\n",
      "Gradient for decoder.decoder.3.bias: 1.0248299431303565e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.000513033417519182\n",
      "Gradient for decoder.decoder.4.bias: 0.00048012216575443745\n",
      "Gradient for decoder.decoder.6.weight: 0.0006988489185459912\n",
      "Gradient for decoder.decoder.6.bias: 3.7593243177980185e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.007149944547563791\n",
      "Gradient for encoder.encoder.0.bias: 1.427758172106719e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0005475543439388275\n",
      "Gradient for encoder.encoder.1.bias: 0.0005198467406444252\n",
      "Gradient for encoder.encoder.3.weight: 0.011789867654442787\n",
      "Gradient for encoder.encoder.3.bias: 9.94954674204962e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.0024760437663644552\n",
      "Gradient for encoder.encoder.4.bias: 0.0020219474099576473\n",
      "Gradient for encoder.mean.weight: 0.03855486214160919\n",
      "Gradient for encoder.mean.bias: 0.0014883382245898247\n",
      "Gradient for encoder.log_var.weight: 0.020912257954478264\n",
      "Gradient for encoder.log_var.bias: 0.000947703723795712\n",
      "Gradient for decoder.decoder.0.weight: 0.009196887724101543\n",
      "Gradient for decoder.decoder.0.bias: 7.456298772856584e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0004430111439432949\n",
      "Gradient for decoder.decoder.1.bias: 0.00036883295979350805\n",
      "Gradient for decoder.decoder.3.weight: 0.008139137178659439\n",
      "Gradient for decoder.decoder.3.bias: 1.1779201225525782e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0008308813557960093\n",
      "Gradient for decoder.decoder.4.bias: 0.0010405685752630234\n",
      "Gradient for decoder.decoder.6.weight: 0.000805194431450218\n",
      "Gradient for decoder.decoder.6.bias: 6.905572081450373e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.007254188880324364\n",
      "Gradient for encoder.encoder.0.bias: 1.2257708736918005e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0004990975139662623\n",
      "Gradient for encoder.encoder.1.bias: 0.0004888221155852079\n",
      "Gradient for encoder.encoder.3.weight: 0.010602966882288456\n",
      "Gradient for encoder.encoder.3.bias: 1.2595757770128557e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0028458316810429096\n",
      "Gradient for encoder.encoder.4.bias: 0.0024902699515223503\n",
      "Gradient for encoder.mean.weight: 0.03951893001794815\n",
      "Gradient for encoder.mean.bias: 0.001881851116195321\n",
      "Gradient for encoder.log_var.weight: 0.024013414978981018\n",
      "Gradient for encoder.log_var.bias: 0.0011867554858326912\n",
      "Gradient for decoder.decoder.0.weight: 0.011367583647370338\n",
      "Gradient for decoder.decoder.0.bias: 9.535215672595854e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0006172153516672552\n",
      "Gradient for decoder.decoder.1.bias: 0.0004682599101215601\n",
      "Gradient for decoder.decoder.3.weight: 0.010829687118530273\n",
      "Gradient for decoder.decoder.3.bias: 1.0680604317636622e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0006333593046292663\n",
      "Gradient for decoder.decoder.4.bias: 0.0007698889239691198\n",
      "Gradient for decoder.decoder.6.weight: 0.0006864472525194287\n",
      "Gradient for decoder.decoder.6.bias: 4.671993156080134e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.005663497373461723\n",
      "Gradient for encoder.encoder.0.bias: 9.881368293052084e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.0004655748198274523\n",
      "Gradient for encoder.encoder.1.bias: 0.000590956537052989\n",
      "Gradient for encoder.encoder.3.weight: 0.010369833558797836\n",
      "Gradient for encoder.encoder.3.bias: 1.1123785226274663e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0029333685524761677\n",
      "Gradient for encoder.encoder.4.bias: 0.002041930565610528\n",
      "Gradient for encoder.mean.weight: 0.041746851056814194\n",
      "Gradient for encoder.mean.bias: 0.001354615786112845\n",
      "Gradient for encoder.log_var.weight: 0.024639291688799858\n",
      "Gradient for encoder.log_var.bias: 0.0010193451307713985\n",
      "Gradient for decoder.decoder.0.weight: 0.011677267029881477\n",
      "Gradient for decoder.decoder.0.bias: 9.852924032216492e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005575671093538404\n",
      "Gradient for decoder.decoder.1.bias: 0.0005109927733428776\n",
      "Gradient for decoder.decoder.3.weight: 0.010622160509228706\n",
      "Gradient for decoder.decoder.3.bias: 8.28358215354541e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0003871425869874656\n",
      "Gradient for decoder.decoder.4.bias: 0.00033266982063651085\n",
      "Gradient for decoder.decoder.6.weight: 0.0006382015999406576\n",
      "Gradient for decoder.decoder.6.bias: 3.3355190680595115e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.006278740242123604\n",
      "Gradient for encoder.encoder.0.bias: 1.0842956740808596e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0005704353097826242\n",
      "Gradient for encoder.encoder.1.bias: 0.0005746239912696183\n",
      "Gradient for encoder.encoder.3.weight: 0.012416522018611431\n",
      "Gradient for encoder.encoder.3.bias: 1.326260212763941e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0030500509310513735\n",
      "Gradient for encoder.encoder.4.bias: 0.002957868156954646\n",
      "Gradient for encoder.mean.weight: 0.04392543062567711\n",
      "Gradient for encoder.mean.bias: 0.002367275534197688\n",
      "Gradient for encoder.log_var.weight: 0.02709873765707016\n",
      "Gradient for encoder.log_var.bias: 0.0015745627461001277\n",
      "Gradient for decoder.decoder.0.weight: 0.011316266842186451\n",
      "Gradient for decoder.decoder.0.bias: 9.49418529905266e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005899404641240835\n",
      "Gradient for decoder.decoder.1.bias: 0.0004526706470642239\n",
      "Gradient for decoder.decoder.3.weight: 0.010638308711349964\n",
      "Gradient for decoder.decoder.3.bias: 8.587390520897742e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00047402619384229183\n",
      "Gradient for decoder.decoder.4.bias: 0.0005086450837552547\n",
      "Gradient for decoder.decoder.6.weight: 0.0006741510005667806\n",
      "Gradient for decoder.decoder.6.bias: 4.2432464397279546e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient for encoder.encoder.0.weight: 0.022213181480765343\n",
      "Gradient for encoder.encoder.0.bias: 3.8782695804817635e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0010632291669026017\n",
      "Gradient for encoder.encoder.1.bias: 0.0008783306693658233\n",
      "Gradient for encoder.encoder.3.weight: 0.023053577169775963\n",
      "Gradient for encoder.encoder.3.bias: 2.552751343642967e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.00687714759260416\n",
      "Gradient for encoder.encoder.4.bias: 0.005074429791420698\n",
      "Gradient for encoder.mean.weight: 0.08742661029100418\n",
      "Gradient for encoder.mean.bias: 0.004310476593673229\n",
      "Gradient for encoder.log_var.weight: 0.05656950920820236\n",
      "Gradient for encoder.log_var.bias: 0.0026908288709819317\n",
      "Gradient for decoder.decoder.0.weight: 0.019265329465270042\n",
      "Gradient for decoder.decoder.0.bias: 1.2894975365274064e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0008602453744970262\n",
      "Gradient for decoder.decoder.1.bias: 0.0007716716499999166\n",
      "Gradient for decoder.decoder.3.weight: 0.018783895298838615\n",
      "Gradient for decoder.decoder.3.bias: 1.4669999937044764e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0007590521709062159\n",
      "Gradient for decoder.decoder.4.bias: 0.0007323049940168858\n",
      "Gradient for decoder.decoder.6.weight: 0.0015683926176279783\n",
      "Gradient for decoder.decoder.6.bias: 8.133574010571465e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/3, Train Loss: 0.0683, Val Loss: 0.2942\n",
      "Training VAE for class 6...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training VAE Epoch:  11%|█▏        | 9/79 [00:00<00:01, 37.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient for encoder.encoder.0.weight: 0.003293389454483986\n",
      "Gradient for encoder.encoder.0.bias: 6.533818191351015e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.000363607716280967\n",
      "Gradient for encoder.encoder.1.bias: 0.0003527677326928824\n",
      "Gradient for encoder.encoder.3.weight: 0.007955875247716904\n",
      "Gradient for encoder.encoder.3.bias: 1.1588933285233693e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.004134349059313536\n",
      "Gradient for encoder.encoder.4.bias: 0.002815112005919218\n",
      "Gradient for encoder.mean.weight: 0.05838186293840408\n",
      "Gradient for encoder.mean.bias: 0.0018185595981776714\n",
      "Gradient for encoder.log_var.weight: 0.031613241881132126\n",
      "Gradient for encoder.log_var.bias: 0.001048133592121303\n",
      "Gradient for decoder.decoder.0.weight: 0.014411181211471558\n",
      "Gradient for decoder.decoder.0.bias: 1.2455808606759433e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0006948003428988159\n",
      "Gradient for decoder.decoder.1.bias: 0.000564069370739162\n",
      "Gradient for decoder.decoder.3.weight: 0.01330389454960823\n",
      "Gradient for decoder.decoder.3.bias: 1.3804053733412758e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0007956665358506143\n",
      "Gradient for decoder.decoder.4.bias: 0.0009436517138965428\n",
      "Gradient for decoder.decoder.6.weight: 0.0010095599573105574\n",
      "Gradient for decoder.decoder.6.bias: 9.44090643315576e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.004970616661012173\n",
      "Gradient for encoder.encoder.0.bias: 1.14553436181275e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0003351136401761323\n",
      "Gradient for encoder.encoder.1.bias: 0.0004570407036226243\n",
      "Gradient for encoder.encoder.3.weight: 0.006900557316839695\n",
      "Gradient for encoder.encoder.3.bias: 1.232536434025988e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.00409741373732686\n",
      "Gradient for encoder.encoder.4.bias: 0.0027399049140512943\n",
      "Gradient for encoder.mean.weight: 0.05782299116253853\n",
      "Gradient for encoder.mean.bias: 0.0019512275466695428\n",
      "Gradient for encoder.log_var.weight: 0.03137829154729843\n",
      "Gradient for encoder.log_var.bias: 0.0013489661505445838\n",
      "Gradient for decoder.decoder.0.weight: 0.00955281127244234\n",
      "Gradient for decoder.decoder.0.bias: 8.380517113604213e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.00048009862075559795\n",
      "Gradient for decoder.decoder.1.bias: 0.0004065592947881669\n",
      "Gradient for decoder.decoder.3.weight: 0.009366581216454506\n",
      "Gradient for decoder.decoder.3.bias: 1.955925421626148e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0016659650718793273\n",
      "Gradient for decoder.decoder.4.bias: 0.002120109274983406\n",
      "Gradient for decoder.decoder.6.weight: 0.0012384209549054503\n",
      "Gradient for decoder.decoder.6.bias: 0.00012616979074664414\n",
      "Gradient for encoder.encoder.0.weight: 0.005659386981278658\n",
      "Gradient for encoder.encoder.0.bias: 1.2011240960174696e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.00042708349064923823\n",
      "Gradient for encoder.encoder.1.bias: 0.0004571541794575751\n",
      "Gradient for encoder.encoder.3.weight: 0.009718487039208412\n",
      "Gradient for encoder.encoder.3.bias: 1.247798531167632e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0038443550001829863\n",
      "Gradient for encoder.encoder.4.bias: 0.0026623422745615244\n",
      "Gradient for encoder.mean.weight: 0.05151587352156639\n",
      "Gradient for encoder.mean.bias: 0.0020394427701830864\n",
      "Gradient for encoder.log_var.weight: 0.028691984713077545\n",
      "Gradient for encoder.log_var.bias: 0.0011039309902116656\n",
      "Gradient for decoder.decoder.0.weight: 0.010014139115810394\n",
      "Gradient for decoder.decoder.0.bias: 8.958856573260121e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0004771000239998102\n",
      "Gradient for decoder.decoder.1.bias: 0.00041494154720567167\n",
      "Gradient for decoder.decoder.3.weight: 0.009580912999808788\n",
      "Gradient for decoder.decoder.3.bias: 1.482383937823073e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.001186145469546318\n",
      "Gradient for decoder.decoder.4.bias: 0.0014715510187670588\n",
      "Gradient for decoder.decoder.6.weight: 0.0009850688511505723\n",
      "Gradient for decoder.decoder.6.bias: 9.383584256283939e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.0034985975362360477\n",
      "Gradient for encoder.encoder.0.bias: 7.548559000092325e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.00045051833149045706\n",
      "Gradient for encoder.encoder.1.bias: 0.0005058978567831218\n",
      "Gradient for encoder.encoder.3.weight: 0.010145297273993492\n",
      "Gradient for encoder.encoder.3.bias: 1.5012056875374213e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.004152150824666023\n",
      "Gradient for encoder.encoder.4.bias: 0.0038974399212747812\n",
      "Gradient for encoder.mean.weight: 0.05893276259303093\n",
      "Gradient for encoder.mean.bias: 0.0032102020923048258\n",
      "Gradient for encoder.log_var.weight: 0.03188236430287361\n",
      "Gradient for encoder.log_var.bias: 0.0017573374789208174\n",
      "Gradient for decoder.decoder.0.weight: 0.01185585092753172\n",
      "Gradient for decoder.decoder.0.bias: 1.022742515677244e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.00060671241953969\n",
      "Gradient for decoder.decoder.1.bias: 0.0005082599236629903\n",
      "Gradient for decoder.decoder.3.weight: 0.011370942927896976\n",
      "Gradient for decoder.decoder.3.bias: 1.2757872536184323e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.000917848024982959\n",
      "Gradient for decoder.decoder.4.bias: 0.0011306155938655138\n",
      "Gradient for decoder.decoder.6.weight: 0.0009493453544564545\n",
      "Gradient for decoder.decoder.6.bias: 8.834266191115603e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.004512798506766558\n",
      "Gradient for encoder.encoder.0.bias: 8.656732448930615e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.0004628601891454309\n",
      "Gradient for encoder.encoder.1.bias: 0.000504419906064868\n",
      "Gradient for encoder.encoder.3.weight: 0.010408071801066399\n",
      "Gradient for encoder.encoder.3.bias: 1.1118776038765432e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0031550584826618433\n",
      "Gradient for encoder.encoder.4.bias: 0.0027194838039577007\n",
      "Gradient for encoder.mean.weight: 0.04563293233513832\n",
      "Gradient for encoder.mean.bias: 0.0025867053773254156\n",
      "Gradient for encoder.log_var.weight: 0.02510758675634861\n",
      "Gradient for encoder.log_var.bias: 0.001441302476450801\n",
      "Gradient for decoder.decoder.0.weight: 0.012083223089575768\n",
      "Gradient for decoder.decoder.0.bias: 1.0033306130363684e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0005433479673229158\n",
      "Gradient for decoder.decoder.1.bias: 0.00047265621833503246\n",
      "Gradient for decoder.decoder.3.weight: 0.010913102887570858\n",
      "Gradient for decoder.decoder.3.bias: 1.3160737777351272e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0010054517770186067\n",
      "Gradient for decoder.decoder.4.bias: 0.0012640670174732804\n",
      "Gradient for decoder.decoder.6.weight: 0.001006791484542191\n",
      "Gradient for decoder.decoder.6.bias: 9.635251626605168e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.0038441538345068693\n",
      "Gradient for encoder.encoder.0.bias: 8.51173298510588e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.0003759973624255508\n",
      "Gradient for encoder.encoder.1.bias: 0.00044202920980751514\n",
      "Gradient for encoder.encoder.3.weight: 0.008068514987826347\n",
      "Gradient for encoder.encoder.3.bias: 9.849999982325386e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.0028077811002731323\n",
      "Gradient for encoder.encoder.4.bias: 0.0018350513419136405\n",
      "Gradient for encoder.mean.weight: 0.04406200721859932\n",
      "Gradient for encoder.mean.bias: 0.0016516521573066711\n",
      "Gradient for encoder.log_var.weight: 0.023010360077023506\n",
      "Gradient for encoder.log_var.bias: 0.000995693844743073\n",
      "Gradient for decoder.decoder.0.weight: 0.012783646583557129\n",
      "Gradient for decoder.decoder.0.bias: 1.0179112414077096e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0006065122433938086\n",
      "Gradient for decoder.decoder.1.bias: 0.0004917416372336447\n",
      "Gradient for decoder.decoder.3.weight: 0.01174901332706213\n",
      "Gradient for decoder.decoder.3.bias: 1.3455556113761702e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0009912477107718587\n",
      "Gradient for decoder.decoder.4.bias: 0.00124748342204839\n",
      "Gradient for decoder.decoder.6.weight: 0.0008754137088544667\n",
      "Gradient for decoder.decoder.6.bias: 8.09846751508303e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.003592998255044222\n",
      "Gradient for encoder.encoder.0.bias: 7.966261331149305e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.00030501981382258236\n",
      "Gradient for encoder.encoder.1.bias: 0.00038836643216200173\n",
      "Gradient for encoder.encoder.3.weight: 0.006599432788789272\n",
      "Gradient for encoder.encoder.3.bias: 1.0525762206281541e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0026129886973649263\n",
      "Gradient for encoder.encoder.4.bias: 0.0020836908370256424\n",
      "Gradient for encoder.mean.weight: 0.038468409329652786\n",
      "Gradient for encoder.mean.bias: 0.001703600399196148\n",
      "Gradient for encoder.log_var.weight: 0.019785940647125244\n",
      "Gradient for encoder.log_var.bias: 0.001020859694108367\n",
      "Gradient for decoder.decoder.0.weight: 0.013172860257327557\n",
      "Gradient for decoder.decoder.0.bias: 1.2172356178563604e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0006224469398148358\n",
      "Gradient for decoder.decoder.1.bias: 0.0005710484692826867\n",
      "Gradient for decoder.decoder.3.weight: 0.012242021039128304\n",
      "Gradient for decoder.decoder.3.bias: 1.5139570153088755e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0008585064788348973\n",
      "Gradient for decoder.decoder.4.bias: 0.0010509917046874762\n",
      "Gradient for decoder.decoder.6.weight: 0.0009894585236907005\n",
      "Gradient for decoder.decoder.6.bias: 9.447191405342892e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.004346063360571861\n",
      "Gradient for encoder.encoder.0.bias: 9.333773337560913e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.00027186976512894034\n",
      "Gradient for encoder.encoder.1.bias: 0.00036723437369801104\n",
      "Gradient for encoder.encoder.3.weight: 0.006003475282341242\n",
      "Gradient for encoder.encoder.3.bias: 9.817146401358556e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.002955065108835697\n",
      "Gradient for encoder.encoder.4.bias: 0.0017918716184794903\n",
      "Gradient for encoder.mean.weight: 0.04284372180700302\n",
      "Gradient for encoder.mean.bias: 0.0015179195906966925\n",
      "Gradient for encoder.log_var.weight: 0.022215593606233597\n",
      "Gradient for encoder.log_var.bias: 0.0008335001766681671\n",
      "Gradient for decoder.decoder.0.weight: 0.010642487555742264\n",
      "Gradient for decoder.decoder.0.bias: 9.521210209140207e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.000519280438311398\n",
      "Gradient for decoder.decoder.1.bias: 0.0003972424892708659\n",
      "Gradient for decoder.decoder.3.weight: 0.010238696821033955\n",
      "Gradient for decoder.decoder.3.bias: 1.6407590563982666e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0012028119526803493\n",
      "Gradient for decoder.decoder.4.bias: 0.001535397837869823\n",
      "Gradient for decoder.decoder.6.weight: 0.0009477829444222152\n",
      "Gradient for decoder.decoder.6.bias: 9.225367830367759e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.006229103542864323\n",
      "Gradient for encoder.encoder.0.bias: 1.3631706007044553e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0003208515408914536\n",
      "Gradient for encoder.encoder.1.bias: 0.00040992911090143025\n",
      "Gradient for encoder.encoder.3.weight: 0.006991397123783827\n",
      "Gradient for encoder.encoder.3.bias: 1.1415817596782674e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0030406618025153875\n",
      "Gradient for encoder.encoder.4.bias: 0.0020231714006513357\n",
      "Gradient for encoder.mean.weight: 0.0434829480946064\n",
      "Gradient for encoder.mean.bias: 0.001474961289204657\n",
      "Gradient for encoder.log_var.weight: 0.022610552608966827\n",
      "Gradient for encoder.log_var.bias: 0.001088859629817307\n",
      "Gradient for decoder.decoder.0.weight: 0.009467480704188347\n",
      "Gradient for decoder.decoder.0.bias: 7.919485900398371e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0004475853347685188\n",
      "Gradient for decoder.decoder.1.bias: 0.0003942937182728201\n",
      "Gradient for decoder.decoder.3.weight: 0.009054740890860558\n",
      "Gradient for decoder.decoder.3.bias: 1.8213205943418131e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0014947575982660055\n",
      "Gradient for decoder.decoder.4.bias: 0.001908642123453319\n",
      "Gradient for decoder.decoder.6.weight: 0.0010358234867453575\n",
      "Gradient for decoder.decoder.6.bias: 0.00010456011659698561\n",
      "Gradient for encoder.encoder.0.weight: 0.0028385017067193985\n",
      "Gradient for encoder.encoder.0.bias: 5.312356023828846e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.00026276090648025274\n",
      "Gradient for encoder.encoder.1.bias: 0.00033088677446357906\n",
      "Gradient for encoder.encoder.3.weight: 0.005879440810531378\n",
      "Gradient for encoder.encoder.3.bias: 1.0091236180009844e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0034123079385608435\n",
      "Gradient for encoder.encoder.4.bias: 0.0024600003380328417\n",
      "Gradient for encoder.mean.weight: 0.049729399383068085\n",
      "Gradient for encoder.mean.bias: 0.001848157960921526\n",
      "Gradient for encoder.log_var.weight: 0.023650987073779106\n",
      "Gradient for encoder.log_var.bias: 0.0009769308380782604\n",
      "Gradient for decoder.decoder.0.weight: 0.01468025054782629\n",
      "Gradient for decoder.decoder.0.bias: 1.2164805274217372e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0007295375689864159\n",
      "Gradient for decoder.decoder.1.bias: 0.0006029233918525279\n",
      "Gradient for decoder.decoder.3.weight: 0.014311200007796288\n",
      "Gradient for decoder.decoder.3.bias: 1.3685742816793578e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0007904783124104142\n",
      "Gradient for decoder.decoder.4.bias: 0.0008911497425287962\n",
      "Gradient for decoder.decoder.6.weight: 0.0008212833781726658\n",
      "Gradient for decoder.decoder.6.bias: 7.028604886727408e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.0048362622037529945\n",
      "Gradient for encoder.encoder.0.bias: 9.405170219023429e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.000368007953511551\n",
      "Gradient for encoder.encoder.1.bias: 0.00045121461153030396\n",
      "Gradient for encoder.encoder.3.weight: 0.0077658286318182945\n",
      "Gradient for encoder.encoder.3.bias: 1.1537130278904684e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0026601452846080065\n",
      "Gradient for encoder.encoder.4.bias: 0.0023823960218578577\n",
      "Gradient for encoder.mean.weight: 0.03916477411985397\n",
      "Gradient for encoder.mean.bias: 0.0019900852348655462\n",
      "Gradient for encoder.log_var.weight: 0.021005671471357346\n",
      "Gradient for encoder.log_var.bias: 0.0009911543456837535\n",
      "Gradient for decoder.decoder.0.weight: 0.012435175478458405\n",
      "Gradient for decoder.decoder.0.bias: 1.0781314729868541e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0006326964939944446\n",
      "Gradient for decoder.decoder.1.bias: 0.0005116152460686862\n",
      "Gradient for decoder.decoder.3.weight: 0.011525888927280903\n",
      "Gradient for decoder.decoder.3.bias: 1.3262300979643982e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0008465454448014498\n",
      "Gradient for decoder.decoder.4.bias: 0.000994421192444861\n",
      "Gradient for decoder.decoder.6.weight: 0.0007822160259820521\n",
      "Gradient for decoder.decoder.6.bias: 6.850600038887933e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.0038987072184681892\n",
      "Gradient for encoder.encoder.0.bias: 8.196204999422196e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.0003791339695453644\n",
      "Gradient for encoder.encoder.1.bias: 0.00040881888708099723\n",
      "Gradient for encoder.encoder.3.weight: 0.00837927870452404\n",
      "Gradient for encoder.encoder.3.bias: 1.2886131051104144e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0026904537808150053\n",
      "Gradient for encoder.encoder.4.bias: 0.002490559360012412\n",
      "Gradient for encoder.mean.weight: 0.04027996212244034\n",
      "Gradient for encoder.mean.bias: 0.0020940310787409544\n",
      "Gradient for encoder.log_var.weight: 0.024091776460409164\n",
      "Gradient for encoder.log_var.bias: 0.0012236456386744976\n",
      "Gradient for decoder.decoder.0.weight: 0.013390934094786644\n",
      "Gradient for decoder.decoder.0.bias: 1.1242484720952461e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0006888110656291246\n",
      "Gradient for decoder.decoder.1.bias: 0.000544730166438967\n",
      "Gradient for decoder.decoder.3.weight: 0.01248456072062254\n",
      "Gradient for decoder.decoder.3.bias: 1.1121246284995223e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0006199030904099345\n",
      "Gradient for decoder.decoder.4.bias: 0.0007088873535394669\n",
      "Gradient for decoder.decoder.6.weight: 0.0007166994037106633\n",
      "Gradient for decoder.decoder.6.bias: 5.8834302762988955e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.00416162796318531\n",
      "Gradient for encoder.encoder.0.bias: 7.236472272104111e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.00033780813100747764\n",
      "Gradient for encoder.encoder.1.bias: 0.00042524581658653915\n",
      "Gradient for encoder.encoder.3.weight: 0.0075449892319738865\n",
      "Gradient for encoder.encoder.3.bias: 1.1278988854002137e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0027723549865186214\n",
      "Gradient for encoder.encoder.4.bias: 0.002227621851488948\n",
      "Gradient for encoder.mean.weight: 0.03978722169995308\n",
      "Gradient for encoder.mean.bias: 0.0018798542441800237\n",
      "Gradient for encoder.log_var.weight: 0.024211496114730835\n",
      "Gradient for encoder.log_var.bias: 0.0011843222891911864\n",
      "Gradient for decoder.decoder.0.weight: 0.012541001662611961\n",
      "Gradient for decoder.decoder.0.bias: 1.0198273475703346e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0006162450881674886\n",
      "Gradient for decoder.decoder.1.bias: 0.0004897945909760892\n",
      "Gradient for decoder.decoder.3.weight: 0.011696579866111279\n",
      "Gradient for decoder.decoder.3.bias: 1.1220044338067225e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0006837931578047574\n",
      "Gradient for decoder.decoder.4.bias: 0.0008453686605207622\n",
      "Gradient for decoder.decoder.6.weight: 0.0006813196232542396\n",
      "Gradient for decoder.decoder.6.bias: 5.6482171203242615e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.003575156908482313\n",
      "Gradient for encoder.encoder.0.bias: 7.16808730427676e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.00027598548331297934\n",
      "Gradient for encoder.encoder.1.bias: 0.00037884467747062445\n",
      "Gradient for encoder.encoder.3.weight: 0.006331323646008968\n",
      "Gradient for encoder.encoder.3.bias: 1.0238307424081938e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.002970098052173853\n",
      "Gradient for encoder.encoder.4.bias: 0.0018658008193597198\n",
      "Gradient for encoder.mean.weight: 0.044975005090236664\n",
      "Gradient for encoder.mean.bias: 0.0014842420350760221\n",
      "Gradient for encoder.log_var.weight: 0.021507060155272484\n",
      "Gradient for encoder.log_var.bias: 0.000915796379558742\n",
      "Gradient for decoder.decoder.0.weight: 0.01399063691496849\n",
      "Gradient for decoder.decoder.0.bias: 1.1300019947535489e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.000694512389600277\n",
      "Gradient for decoder.decoder.1.bias: 0.0005659707239829004\n",
      "Gradient for decoder.decoder.3.weight: 0.013680705800652504\n",
      "Gradient for decoder.decoder.3.bias: 1.1396662086271547e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0005964902229607105\n",
      "Gradient for decoder.decoder.4.bias: 0.0005752958822995424\n",
      "Gradient for decoder.decoder.6.weight: 0.0007064202218316495\n",
      "Gradient for decoder.decoder.6.bias: 5.5111107940319926e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.0031783869490027428\n",
      "Gradient for encoder.encoder.0.bias: 6.954634784728242e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.00024529857910238206\n",
      "Gradient for encoder.encoder.1.bias: 0.00042086184839718044\n",
      "Gradient for encoder.encoder.3.weight: 0.005411113612353802\n",
      "Gradient for encoder.encoder.3.bias: 9.569352948934906e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.002696497831493616\n",
      "Gradient for encoder.encoder.4.bias: 0.0021173590794205666\n",
      "Gradient for encoder.mean.weight: 0.04508601129055023\n",
      "Gradient for encoder.mean.bias: 0.001747150789014995\n",
      "Gradient for encoder.log_var.weight: 0.02245800942182541\n",
      "Gradient for encoder.log_var.bias: 0.00097686389926821\n",
      "Gradient for decoder.decoder.0.weight: 0.011658038012683392\n",
      "Gradient for decoder.decoder.0.bias: 1.0618206314205736e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0005956808454357088\n",
      "Gradient for decoder.decoder.1.bias: 0.0004799531598109752\n",
      "Gradient for decoder.decoder.3.weight: 0.011048845946788788\n",
      "Gradient for decoder.decoder.3.bias: 1.336214056069096e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.000976060051470995\n",
      "Gradient for decoder.decoder.4.bias: 0.0012034573592245579\n",
      "Gradient for decoder.decoder.6.weight: 0.0007245881715789437\n",
      "Gradient for decoder.decoder.6.bias: 6.392295472323895e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.00423935754224658\n",
      "Gradient for encoder.encoder.0.bias: 8.52364619857715e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.0002651312679518014\n",
      "Gradient for encoder.encoder.1.bias: 0.0003704761911649257\n",
      "Gradient for encoder.encoder.3.weight: 0.005824395455420017\n",
      "Gradient for encoder.encoder.3.bias: 8.343901264362685e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.0025628553703427315\n",
      "Gradient for encoder.encoder.4.bias: 0.0018024495802819729\n",
      "Gradient for encoder.mean.weight: 0.039992328733205795\n",
      "Gradient for encoder.mean.bias: 0.0013979881769046187\n",
      "Gradient for encoder.log_var.weight: 0.021998867392539978\n",
      "Gradient for encoder.log_var.bias: 0.001044185017235577\n",
      "Gradient for decoder.decoder.0.weight: 0.011347418650984764\n",
      "Gradient for decoder.decoder.0.bias: 9.180654153562173e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.000609008886385709\n",
      "Gradient for decoder.decoder.1.bias: 0.0004893837030977011\n",
      "Gradient for decoder.decoder.3.weight: 0.01096240896731615\n",
      "Gradient for decoder.decoder.3.bias: 1.273732092021973e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0008657874423079193\n",
      "Gradient for decoder.decoder.4.bias: 0.0011048333253711462\n",
      "Gradient for decoder.decoder.6.weight: 0.0006875357939861715\n",
      "Gradient for decoder.decoder.6.bias: 5.787744885310531e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training VAE Epoch:  33%|███▎      | 26/79 [00:00<00:00, 63.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient for encoder.encoder.0.weight: 0.003849673317745328\n",
      "Gradient for encoder.encoder.0.bias: 8.379043119066676e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.0003553666756488383\n",
      "Gradient for encoder.encoder.1.bias: 0.0005350465071387589\n",
      "Gradient for encoder.encoder.3.weight: 0.007888075895607471\n",
      "Gradient for encoder.encoder.3.bias: 9.417649299292563e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.002929107751697302\n",
      "Gradient for encoder.encoder.4.bias: 0.002020450308918953\n",
      "Gradient for encoder.mean.weight: 0.0434504896402359\n",
      "Gradient for encoder.mean.bias: 0.0017251204699277878\n",
      "Gradient for encoder.log_var.weight: 0.02463586814701557\n",
      "Gradient for encoder.log_var.bias: 0.0010804228950291872\n",
      "Gradient for decoder.decoder.0.weight: 0.010952564887702465\n",
      "Gradient for decoder.decoder.0.bias: 1.0195656124922792e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0006110434187576175\n",
      "Gradient for decoder.decoder.1.bias: 0.0004821451148018241\n",
      "Gradient for decoder.decoder.3.weight: 0.010607210919260979\n",
      "Gradient for decoder.decoder.3.bias: 1.1902435981259174e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0007453412981703877\n",
      "Gradient for decoder.decoder.4.bias: 0.000922597770113498\n",
      "Gradient for decoder.decoder.6.weight: 0.0006329534808173776\n",
      "Gradient for decoder.decoder.6.bias: 5.291278284857981e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.003890963038429618\n",
      "Gradient for encoder.encoder.0.bias: 9.496257079300019e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.0003174481389578432\n",
      "Gradient for encoder.encoder.1.bias: 0.0003820940910372883\n",
      "Gradient for encoder.encoder.3.weight: 0.006719011813402176\n",
      "Gradient for encoder.encoder.3.bias: 1.0520369991828815e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0026735705323517323\n",
      "Gradient for encoder.encoder.4.bias: 0.0022275010123848915\n",
      "Gradient for encoder.mean.weight: 0.03934776410460472\n",
      "Gradient for encoder.mean.bias: 0.001837757881730795\n",
      "Gradient for encoder.log_var.weight: 0.021481642499566078\n",
      "Gradient for encoder.log_var.bias: 0.0009108901140280068\n",
      "Gradient for decoder.decoder.0.weight: 0.010169008746743202\n",
      "Gradient for decoder.decoder.0.bias: 8.378796961805435e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005138309788890183\n",
      "Gradient for decoder.decoder.1.bias: 0.0003899818693753332\n",
      "Gradient for decoder.decoder.3.weight: 0.009658152237534523\n",
      "Gradient for decoder.decoder.3.bias: 1.2101103452621942e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0008913245983421803\n",
      "Gradient for decoder.decoder.4.bias: 0.001097235712222755\n",
      "Gradient for decoder.decoder.6.weight: 0.0006511906976811588\n",
      "Gradient for decoder.decoder.6.bias: 5.732092176913284e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.004020539112389088\n",
      "Gradient for encoder.encoder.0.bias: 9.502887192425202e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.00035016759647987783\n",
      "Gradient for encoder.encoder.1.bias: 0.0005764212110079825\n",
      "Gradient for encoder.encoder.3.weight: 0.008020387031137943\n",
      "Gradient for encoder.encoder.3.bias: 1.1256099524681318e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0033745497930794954\n",
      "Gradient for encoder.encoder.4.bias: 0.002420191653072834\n",
      "Gradient for encoder.mean.weight: 0.050217028707265854\n",
      "Gradient for encoder.mean.bias: 0.002052364405244589\n",
      "Gradient for encoder.log_var.weight: 0.022022590041160583\n",
      "Gradient for encoder.log_var.bias: 0.0011834697797894478\n",
      "Gradient for decoder.decoder.0.weight: 0.009773281402885914\n",
      "Gradient for decoder.decoder.0.bias: 8.046187327526155e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0004904048983007669\n",
      "Gradient for decoder.decoder.1.bias: 0.00041954973130486906\n",
      "Gradient for decoder.decoder.3.weight: 0.009658150374889374\n",
      "Gradient for decoder.decoder.3.bias: 1.5703688349688605e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0011293153511360288\n",
      "Gradient for decoder.decoder.4.bias: 0.0014515738002955914\n",
      "Gradient for decoder.decoder.6.weight: 0.0007315785624086857\n",
      "Gradient for decoder.decoder.6.bias: 6.964931526454166e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.0041056848131120205\n",
      "Gradient for encoder.encoder.0.bias: 8.27162123517855e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.0002855217317119241\n",
      "Gradient for encoder.encoder.1.bias: 0.0003862817247863859\n",
      "Gradient for encoder.encoder.3.weight: 0.0066277747973799706\n",
      "Gradient for encoder.encoder.3.bias: 9.206663209582189e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.0028117182664573193\n",
      "Gradient for encoder.encoder.4.bias: 0.0018498891731724143\n",
      "Gradient for encoder.mean.weight: 0.041461970657110214\n",
      "Gradient for encoder.mean.bias: 0.0015368522144854069\n",
      "Gradient for encoder.log_var.weight: 0.021445345133543015\n",
      "Gradient for encoder.log_var.bias: 0.0008993252995423973\n",
      "Gradient for decoder.decoder.0.weight: 0.012007834389805794\n",
      "Gradient for decoder.decoder.0.bias: 9.474664108832798e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0006061476888135076\n",
      "Gradient for decoder.decoder.1.bias: 0.0005049134488217533\n",
      "Gradient for decoder.decoder.3.weight: 0.011316334828734398\n",
      "Gradient for decoder.decoder.3.bias: 1.0572508840622774e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0006560453330166638\n",
      "Gradient for decoder.decoder.4.bias: 0.0007775948033668101\n",
      "Gradient for decoder.decoder.6.weight: 0.0005827859858982265\n",
      "Gradient for decoder.decoder.6.bias: 4.44922516180668e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.00326047302223742\n",
      "Gradient for encoder.encoder.0.bias: 7.215126933413085e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.0002501741982996464\n",
      "Gradient for encoder.encoder.1.bias: 0.00037156190956011415\n",
      "Gradient for encoder.encoder.3.weight: 0.005780666600912809\n",
      "Gradient for encoder.encoder.3.bias: 9.339117673645703e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.0026749693788588047\n",
      "Gradient for encoder.encoder.4.bias: 0.00171660294290632\n",
      "Gradient for encoder.mean.weight: 0.042756762355566025\n",
      "Gradient for encoder.mean.bias: 0.0012743156403303146\n",
      "Gradient for encoder.log_var.weight: 0.02246413566172123\n",
      "Gradient for encoder.log_var.bias: 0.0008474868955090642\n",
      "Gradient for decoder.decoder.0.weight: 0.01318062748759985\n",
      "Gradient for decoder.decoder.0.bias: 1.1234606994703356e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0006739411037415266\n",
      "Gradient for decoder.decoder.1.bias: 0.0005266392254270613\n",
      "Gradient for decoder.decoder.3.weight: 0.01218665111809969\n",
      "Gradient for decoder.decoder.3.bias: 9.971579811862696e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0005129472119733691\n",
      "Gradient for decoder.decoder.4.bias: 0.0005005701677873731\n",
      "Gradient for decoder.decoder.6.weight: 0.0005749809206463397\n",
      "Gradient for decoder.decoder.6.bias: 3.9604339690413326e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.004686448257416487\n",
      "Gradient for encoder.encoder.0.bias: 9.09663403630967e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.00034866531495936215\n",
      "Gradient for encoder.encoder.1.bias: 0.00046160226338543\n",
      "Gradient for encoder.encoder.3.weight: 0.00764786871150136\n",
      "Gradient for encoder.encoder.3.bias: 9.834377756590129e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.002832700964063406\n",
      "Gradient for encoder.encoder.4.bias: 0.0015741464449092746\n",
      "Gradient for encoder.mean.weight: 0.040527310222387314\n",
      "Gradient for encoder.mean.bias: 0.0012762401020154357\n",
      "Gradient for encoder.log_var.weight: 0.02235015109181404\n",
      "Gradient for encoder.log_var.bias: 0.0008120586280710995\n",
      "Gradient for decoder.decoder.0.weight: 0.010124384425580502\n",
      "Gradient for decoder.decoder.0.bias: 8.568055293034504e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005090381600894034\n",
      "Gradient for decoder.decoder.1.bias: 0.0004101245431229472\n",
      "Gradient for decoder.decoder.3.weight: 0.009679427370429039\n",
      "Gradient for decoder.decoder.3.bias: 9.381156962362525e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0006065393681637943\n",
      "Gradient for decoder.decoder.4.bias: 0.0007220134721137583\n",
      "Gradient for decoder.decoder.6.weight: 0.0006091310642659664\n",
      "Gradient for decoder.decoder.6.bias: 4.8812311433721334e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.008257593959569931\n",
      "Gradient for encoder.encoder.0.bias: 1.9283411673010065e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0005682276678271592\n",
      "Gradient for encoder.encoder.1.bias: 0.0005449275486171246\n",
      "Gradient for encoder.encoder.3.weight: 0.012170783244073391\n",
      "Gradient for encoder.encoder.3.bias: 1.5532372610316258e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.003626372665166855\n",
      "Gradient for encoder.encoder.4.bias: 0.0035400940105319023\n",
      "Gradient for encoder.mean.weight: 0.052189815789461136\n",
      "Gradient for encoder.mean.bias: 0.0026361627969890833\n",
      "Gradient for encoder.log_var.weight: 0.026762038469314575\n",
      "Gradient for encoder.log_var.bias: 0.0014764419756829739\n",
      "Gradient for decoder.decoder.0.weight: 0.007995706051588058\n",
      "Gradient for decoder.decoder.0.bias: 6.597011131814767e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.00038763703196309507\n",
      "Gradient for decoder.decoder.1.bias: 0.0003086943179368973\n",
      "Gradient for decoder.decoder.3.weight: 0.007426421623677015\n",
      "Gradient for decoder.decoder.3.bias: 1.0339880340826113e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.000733136897906661\n",
      "Gradient for decoder.decoder.4.bias: 0.00092991505516693\n",
      "Gradient for decoder.decoder.6.weight: 0.0005514818476513028\n",
      "Gradient for decoder.decoder.6.bias: 4.7097062633838505e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.0031057754531502724\n",
      "Gradient for encoder.encoder.0.bias: 7.508049737481315e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.00034344758023507893\n",
      "Gradient for encoder.encoder.1.bias: 0.00045180419692769647\n",
      "Gradient for encoder.encoder.3.weight: 0.007557697128504515\n",
      "Gradient for encoder.encoder.3.bias: 9.778343412758517e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.002513186540454626\n",
      "Gradient for encoder.encoder.4.bias: 0.0019629921298474073\n",
      "Gradient for encoder.mean.weight: 0.04041585698723793\n",
      "Gradient for encoder.mean.bias: 0.0015209452249109745\n",
      "Gradient for encoder.log_var.weight: 0.021479133516550064\n",
      "Gradient for encoder.log_var.bias: 0.0010037043830379844\n",
      "Gradient for decoder.decoder.0.weight: 0.01275881752371788\n",
      "Gradient for decoder.decoder.0.bias: 9.690400565309787e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0006161179626360536\n",
      "Gradient for decoder.decoder.1.bias: 0.000489068275783211\n",
      "Gradient for decoder.decoder.3.weight: 0.011938375420868397\n",
      "Gradient for decoder.decoder.3.bias: 9.048852639415017e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00044278442510403693\n",
      "Gradient for decoder.decoder.4.bias: 0.0003860151919070631\n",
      "Gradient for decoder.decoder.6.weight: 0.0005813222960568964\n",
      "Gradient for decoder.decoder.6.bias: 3.9577709685545415e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.0048953453078866005\n",
      "Gradient for encoder.encoder.0.bias: 8.344470947552196e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.0003324120189063251\n",
      "Gradient for encoder.encoder.1.bias: 0.00038225544267334044\n",
      "Gradient for encoder.encoder.3.weight: 0.006980446167290211\n",
      "Gradient for encoder.encoder.3.bias: 8.898464604056855e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.0027455969247967005\n",
      "Gradient for encoder.encoder.4.bias: 0.00159875035751611\n",
      "Gradient for encoder.mean.weight: 0.04000929743051529\n",
      "Gradient for encoder.mean.bias: 0.0013193634804338217\n",
      "Gradient for encoder.log_var.weight: 0.020443100482225418\n",
      "Gradient for encoder.log_var.bias: 0.0007354757399298251\n",
      "Gradient for decoder.decoder.0.weight: 0.011889190413057804\n",
      "Gradient for decoder.decoder.0.bias: 1.0856261029035252e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0006371592171490192\n",
      "Gradient for decoder.decoder.1.bias: 0.0005093979416415095\n",
      "Gradient for decoder.decoder.3.weight: 0.011593888513743877\n",
      "Gradient for decoder.decoder.3.bias: 9.352026097975141e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0006008666823618114\n",
      "Gradient for decoder.decoder.4.bias: 0.0006822394789196551\n",
      "Gradient for decoder.decoder.6.weight: 0.0005195866106078029\n",
      "Gradient for decoder.decoder.6.bias: 3.478084909147583e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.004101332277059555\n",
      "Gradient for encoder.encoder.0.bias: 8.339822755998316e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.0003015359689015895\n",
      "Gradient for encoder.encoder.1.bias: 0.00034846688504330814\n",
      "Gradient for encoder.encoder.3.weight: 0.0065267132595181465\n",
      "Gradient for encoder.encoder.3.bias: 9.97391266799319e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.00274340040050447\n",
      "Gradient for encoder.encoder.4.bias: 0.001982978545129299\n",
      "Gradient for encoder.mean.weight: 0.03888111934065819\n",
      "Gradient for encoder.mean.bias: 0.0015788215678185225\n",
      "Gradient for encoder.log_var.weight: 0.021183446049690247\n",
      "Gradient for encoder.log_var.bias: 0.0009785122238099575\n",
      "Gradient for decoder.decoder.0.weight: 0.011305397376418114\n",
      "Gradient for decoder.decoder.0.bias: 9.55470771946132e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005672311526723206\n",
      "Gradient for decoder.decoder.1.bias: 0.0004660318954847753\n",
      "Gradient for decoder.decoder.3.weight: 0.010729065164923668\n",
      "Gradient for decoder.decoder.3.bias: 8.128680367702756e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00041749398224055767\n",
      "Gradient for decoder.decoder.4.bias: 0.00042809481965377927\n",
      "Gradient for decoder.decoder.6.weight: 0.0005340261268429458\n",
      "Gradient for decoder.decoder.6.bias: 3.59560435754247e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.0037608572747558355\n",
      "Gradient for encoder.encoder.0.bias: 7.885078874558804e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.00036475667729973793\n",
      "Gradient for encoder.encoder.1.bias: 0.0003943330666515976\n",
      "Gradient for encoder.encoder.3.weight: 0.007120716851204634\n",
      "Gradient for encoder.encoder.3.bias: 1.1720065196119123e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.002959350822493434\n",
      "Gradient for encoder.encoder.4.bias: 0.0025653294287621975\n",
      "Gradient for encoder.mean.weight: 0.04269661381840706\n",
      "Gradient for encoder.mean.bias: 0.0018661272479221225\n",
      "Gradient for encoder.log_var.weight: 0.02427571639418602\n",
      "Gradient for encoder.log_var.bias: 0.0013540927320718765\n",
      "Gradient for decoder.decoder.0.weight: 0.01202136930078268\n",
      "Gradient for decoder.decoder.0.bias: 9.253060817560055e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.000554228259716183\n",
      "Gradient for decoder.decoder.1.bias: 0.0004603759734891355\n",
      "Gradient for decoder.decoder.3.weight: 0.010863818228244781\n",
      "Gradient for decoder.decoder.3.bias: 9.901608005735696e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0005629822262562811\n",
      "Gradient for decoder.decoder.4.bias: 0.0006089264643378556\n",
      "Gradient for decoder.decoder.6.weight: 0.0005560168065130711\n",
      "Gradient for decoder.decoder.6.bias: 4.1103270632447675e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.004130409564822912\n",
      "Gradient for encoder.encoder.0.bias: 9.810909896990072e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.00031870516249909997\n",
      "Gradient for encoder.encoder.1.bias: 0.000377713207853958\n",
      "Gradient for encoder.encoder.3.weight: 0.00689062662422657\n",
      "Gradient for encoder.encoder.3.bias: 9.629328584503938e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.002570015611127019\n",
      "Gradient for encoder.encoder.4.bias: 0.001993873156607151\n",
      "Gradient for encoder.mean.weight: 0.0373881533741951\n",
      "Gradient for encoder.mean.bias: 0.0015359612880274653\n",
      "Gradient for encoder.log_var.weight: 0.018044758588075638\n",
      "Gradient for encoder.log_var.bias: 0.0008852910250425339\n",
      "Gradient for decoder.decoder.0.weight: 0.00966487918049097\n",
      "Gradient for decoder.decoder.0.bias: 8.944996132687066e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0004689772904384881\n",
      "Gradient for decoder.decoder.1.bias: 0.0003949831298086792\n",
      "Gradient for decoder.decoder.3.weight: 0.009219897910952568\n",
      "Gradient for decoder.decoder.3.bias: 9.689787167088681e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0005986164906062186\n",
      "Gradient for decoder.decoder.4.bias: 0.0007140316301956773\n",
      "Gradient for decoder.decoder.6.weight: 0.0005211170064285398\n",
      "Gradient for decoder.decoder.6.bias: 3.789553738897666e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.003948258236050606\n",
      "Gradient for encoder.encoder.0.bias: 8.128152664821364e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.00033599650487303734\n",
      "Gradient for encoder.encoder.1.bias: 0.0004515435721259564\n",
      "Gradient for encoder.encoder.3.weight: 0.007061062380671501\n",
      "Gradient for encoder.encoder.3.bias: 9.956293428592389e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.0022778669372200966\n",
      "Gradient for encoder.encoder.4.bias: 0.001864080666564405\n",
      "Gradient for encoder.mean.weight: 0.03723284974694252\n",
      "Gradient for encoder.mean.bias: 0.0015361483674496412\n",
      "Gradient for encoder.log_var.weight: 0.019713761284947395\n",
      "Gradient for encoder.log_var.bias: 0.0009930639062076807\n",
      "Gradient for decoder.decoder.0.weight: 0.012219076976180077\n",
      "Gradient for decoder.decoder.0.bias: 9.830388586484773e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0006026682676747441\n",
      "Gradient for decoder.decoder.1.bias: 0.0005091523635201156\n",
      "Gradient for decoder.decoder.3.weight: 0.011670434847474098\n",
      "Gradient for decoder.decoder.3.bias: 9.811928353142818e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0004475655441638082\n",
      "Gradient for decoder.decoder.4.bias: 0.00041383676580153406\n",
      "Gradient for decoder.decoder.6.weight: 0.0005636205314658582\n",
      "Gradient for decoder.decoder.6.bias: 3.9405560528393835e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.0029073809273540974\n",
      "Gradient for encoder.encoder.0.bias: 5.399708891823396e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.00024065801699180156\n",
      "Gradient for encoder.encoder.1.bias: 0.0004078119236510247\n",
      "Gradient for encoder.encoder.3.weight: 0.005264464765787125\n",
      "Gradient for encoder.encoder.3.bias: 8.787896799145045e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.002841199981048703\n",
      "Gradient for encoder.encoder.4.bias: 0.0018120685126632452\n",
      "Gradient for encoder.mean.weight: 0.041507937014102936\n",
      "Gradient for encoder.mean.bias: 0.0015255417674779892\n",
      "Gradient for encoder.log_var.weight: 0.026851190254092216\n",
      "Gradient for encoder.log_var.bias: 0.0010301541769877076\n",
      "Gradient for decoder.decoder.0.weight: 0.01499100960791111\n",
      "Gradient for decoder.decoder.0.bias: 1.2613547706319395e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0007160821696743369\n",
      "Gradient for decoder.decoder.1.bias: 0.0006693191244266927\n",
      "Gradient for decoder.decoder.3.weight: 0.013834579847753048\n",
      "Gradient for decoder.decoder.3.bias: 1.1726174198312123e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.00046708458103239536\n",
      "Gradient for decoder.decoder.4.bias: 0.0004276256950106472\n",
      "Gradient for decoder.decoder.6.weight: 0.0004743463941849768\n",
      "Gradient for decoder.decoder.6.bias: 2.4299884898937307e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.0032112773042172194\n",
      "Gradient for encoder.encoder.0.bias: 7.319073298817091e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.00027435130323283374\n",
      "Gradient for encoder.encoder.1.bias: 0.00044274976244196296\n",
      "Gradient for encoder.encoder.3.weight: 0.005811741109937429\n",
      "Gradient for encoder.encoder.3.bias: 9.53840686990226e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.0024309754371643066\n",
      "Gradient for encoder.encoder.4.bias: 0.0018702892120927572\n",
      "Gradient for encoder.mean.weight: 0.03958849981427193\n",
      "Gradient for encoder.mean.bias: 0.001733266981318593\n",
      "Gradient for encoder.log_var.weight: 0.02130097523331642\n",
      "Gradient for encoder.log_var.bias: 0.0010386729845777154\n",
      "Gradient for decoder.decoder.0.weight: 0.010761374607682228\n",
      "Gradient for decoder.decoder.0.bias: 8.84720283145235e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005254520801827312\n",
      "Gradient for decoder.decoder.1.bias: 0.0004289525677450001\n",
      "Gradient for decoder.decoder.3.weight: 0.010465500876307487\n",
      "Gradient for decoder.decoder.3.bias: 1.2074077848645004e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.000703775673173368\n",
      "Gradient for decoder.decoder.4.bias: 0.0008621428860351443\n",
      "Gradient for decoder.decoder.6.weight: 0.0005296634626574814\n",
      "Gradient for decoder.decoder.6.bias: 3.988821117673069e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.002959620673209429\n",
      "Gradient for encoder.encoder.0.bias: 5.59059092422598e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.00026366792735643685\n",
      "Gradient for encoder.encoder.1.bias: 0.0004058309714309871\n",
      "Gradient for encoder.encoder.3.weight: 0.005683184135705233\n",
      "Gradient for encoder.encoder.3.bias: 9.712457921251527e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.002854549791663885\n",
      "Gradient for encoder.encoder.4.bias: 0.0019900351762771606\n",
      "Gradient for encoder.mean.weight: 0.0453253872692585\n",
      "Gradient for encoder.mean.bias: 0.0016715449746698141\n",
      "Gradient for encoder.log_var.weight: 0.02455097995698452\n",
      "Gradient for encoder.log_var.bias: 0.0011366145918145776\n",
      "Gradient for decoder.decoder.0.weight: 0.013785588555037975\n",
      "Gradient for decoder.decoder.0.bias: 1.1143282130365861e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.000642515835352242\n",
      "Gradient for decoder.decoder.1.bias: 0.00056742929155007\n",
      "Gradient for decoder.decoder.3.weight: 0.012789161875844002\n",
      "Gradient for decoder.decoder.3.bias: 1.0249169568599115e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.00043424617615528405\n",
      "Gradient for decoder.decoder.4.bias: 0.00039854308124631643\n",
      "Gradient for decoder.decoder.6.weight: 0.0005047573358751833\n",
      "Gradient for decoder.decoder.6.bias: 3.098224988207221e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training VAE Epoch:  54%|█████▍    | 43/79 [00:00<00:00, 72.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient for encoder.encoder.0.weight: 0.004043573047965765\n",
      "Gradient for encoder.encoder.0.bias: 8.876279919411978e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.00035765269421972334\n",
      "Gradient for encoder.encoder.1.bias: 0.000476849265396595\n",
      "Gradient for encoder.encoder.3.weight: 0.007311690598726273\n",
      "Gradient for encoder.encoder.3.bias: 9.888787705358837e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.0028869006782770157\n",
      "Gradient for encoder.encoder.4.bias: 0.0019681251142174006\n",
      "Gradient for encoder.mean.weight: 0.04293932393193245\n",
      "Gradient for encoder.mean.bias: 0.0016306309262290597\n",
      "Gradient for encoder.log_var.weight: 0.021017609164118767\n",
      "Gradient for encoder.log_var.bias: 0.0009412601939402521\n",
      "Gradient for decoder.decoder.0.weight: 0.010471132583916187\n",
      "Gradient for decoder.decoder.0.bias: 8.467876400075625e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005012975307181478\n",
      "Gradient for decoder.decoder.1.bias: 0.00041730806697160006\n",
      "Gradient for decoder.decoder.3.weight: 0.009907548315823078\n",
      "Gradient for decoder.decoder.3.bias: 8.469814433142986e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0004526098782662302\n",
      "Gradient for decoder.decoder.4.bias: 0.0005104841548018157\n",
      "Gradient for decoder.decoder.6.weight: 0.000484699645312503\n",
      "Gradient for decoder.decoder.6.bias: 3.394943632883951e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.0030272172298282385\n",
      "Gradient for encoder.encoder.0.bias: 6.251193139517053e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.0002811795275192708\n",
      "Gradient for encoder.encoder.1.bias: 0.00034190918086096644\n",
      "Gradient for encoder.encoder.3.weight: 0.006236935965716839\n",
      "Gradient for encoder.encoder.3.bias: 8.531013395707276e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.002560326596722007\n",
      "Gradient for encoder.encoder.4.bias: 0.0017278996529057622\n",
      "Gradient for encoder.mean.weight: 0.0385393425822258\n",
      "Gradient for encoder.mean.bias: 0.0014494198840111494\n",
      "Gradient for encoder.log_var.weight: 0.022289829328656197\n",
      "Gradient for encoder.log_var.bias: 0.0007541688974015415\n",
      "Gradient for decoder.decoder.0.weight: 0.012305992655456066\n",
      "Gradient for decoder.decoder.0.bias: 1.0208294626279368e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0005695730214938521\n",
      "Gradient for decoder.decoder.1.bias: 0.0005018538213334978\n",
      "Gradient for decoder.decoder.3.weight: 0.011632571928203106\n",
      "Gradient for decoder.decoder.3.bias: 9.102839315655586e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0004780453455168754\n",
      "Gradient for decoder.decoder.4.bias: 0.0004466077371034771\n",
      "Gradient for decoder.decoder.6.weight: 0.0004999136435799301\n",
      "Gradient for decoder.decoder.6.bias: 2.9654649551957846e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.0028077363967895508\n",
      "Gradient for encoder.encoder.0.bias: 5.188995934324314e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.00024035410024225712\n",
      "Gradient for encoder.encoder.1.bias: 0.0003114428836852312\n",
      "Gradient for encoder.encoder.3.weight: 0.005243783351033926\n",
      "Gradient for encoder.encoder.3.bias: 8.577474147619668e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.0026496737264096737\n",
      "Gradient for encoder.encoder.4.bias: 0.0016719899140298367\n",
      "Gradient for encoder.mean.weight: 0.04306436702609062\n",
      "Gradient for encoder.mean.bias: 0.0012211061548441648\n",
      "Gradient for encoder.log_var.weight: 0.021863112226128578\n",
      "Gradient for encoder.log_var.bias: 0.0006934222183190286\n",
      "Gradient for decoder.decoder.0.weight: 0.015230578370392323\n",
      "Gradient for decoder.decoder.0.bias: 1.3701094425666582e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0007712655351497233\n",
      "Gradient for decoder.decoder.1.bias: 0.0006379986880347133\n",
      "Gradient for decoder.decoder.3.weight: 0.014649986289441586\n",
      "Gradient for decoder.decoder.3.bias: 1.1487142487220936e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.000511820544488728\n",
      "Gradient for decoder.decoder.4.bias: 0.0004515275068115443\n",
      "Gradient for decoder.decoder.6.weight: 0.0005057368543930352\n",
      "Gradient for decoder.decoder.6.bias: 2.7552923711482435e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.0036544876638799906\n",
      "Gradient for encoder.encoder.0.bias: 6.882331943930398e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.0003190416900906712\n",
      "Gradient for encoder.encoder.1.bias: 0.0004568127915263176\n",
      "Gradient for encoder.encoder.3.weight: 0.007153136655688286\n",
      "Gradient for encoder.encoder.3.bias: 8.838543091860274e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.0026349821127951145\n",
      "Gradient for encoder.encoder.4.bias: 0.0014101028209552169\n",
      "Gradient for encoder.mean.weight: 0.03900523856282234\n",
      "Gradient for encoder.mean.bias: 0.0013103567762300372\n",
      "Gradient for encoder.log_var.weight: 0.022485941648483276\n",
      "Gradient for encoder.log_var.bias: 0.0007830000249668956\n",
      "Gradient for decoder.decoder.0.weight: 0.013113473542034626\n",
      "Gradient for decoder.decoder.0.bias: 1.0880519402123312e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0006205986137501895\n",
      "Gradient for decoder.decoder.1.bias: 0.0005310826818458736\n",
      "Gradient for decoder.decoder.3.weight: 0.012353801168501377\n",
      "Gradient for decoder.decoder.3.bias: 9.680099083420046e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0004526976845227182\n",
      "Gradient for decoder.decoder.4.bias: 0.0004180758842267096\n",
      "Gradient for decoder.decoder.6.weight: 0.0004984650877304375\n",
      "Gradient for decoder.decoder.6.bias: 2.8978087357245386e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.003892436157912016\n",
      "Gradient for encoder.encoder.0.bias: 9.20419209599066e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.00036153863766230643\n",
      "Gradient for encoder.encoder.1.bias: 0.00041128191514872015\n",
      "Gradient for encoder.encoder.3.weight: 0.007754747290164232\n",
      "Gradient for encoder.encoder.3.bias: 1.2390416470609011e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0027897211257368326\n",
      "Gradient for encoder.encoder.4.bias: 0.003157983999699354\n",
      "Gradient for encoder.mean.weight: 0.042097363620996475\n",
      "Gradient for encoder.mean.bias: 0.002747987862676382\n",
      "Gradient for encoder.log_var.weight: 0.02306869626045227\n",
      "Gradient for encoder.log_var.bias: 0.0015139024471864104\n",
      "Gradient for decoder.decoder.0.weight: 0.010621127672493458\n",
      "Gradient for decoder.decoder.0.bias: 9.28924437371137e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005141591536812484\n",
      "Gradient for decoder.decoder.1.bias: 0.0004376405559014529\n",
      "Gradient for decoder.decoder.3.weight: 0.00948300026357174\n",
      "Gradient for decoder.decoder.3.bias: 7.465971590958631e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0003522963379509747\n",
      "Gradient for decoder.decoder.4.bias: 0.0003142181667499244\n",
      "Gradient for decoder.decoder.6.weight: 0.00046834704698994756\n",
      "Gradient for decoder.decoder.6.bias: 3.0386829166673124e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.003594693960621953\n",
      "Gradient for encoder.encoder.0.bias: 7.898078024926036e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.0003247372806072235\n",
      "Gradient for encoder.encoder.1.bias: 0.00046209892025217414\n",
      "Gradient for encoder.encoder.3.weight: 0.0071295625530183315\n",
      "Gradient for encoder.encoder.3.bias: 9.556256480580672e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.0028223723638802767\n",
      "Gradient for encoder.encoder.4.bias: 0.0016313564265146852\n",
      "Gradient for encoder.mean.weight: 0.0424911268055439\n",
      "Gradient for encoder.mean.bias: 0.001473478158004582\n",
      "Gradient for encoder.log_var.weight: 0.023129049688577652\n",
      "Gradient for encoder.log_var.bias: 0.0009046350605785847\n",
      "Gradient for decoder.decoder.0.weight: 0.01091742143034935\n",
      "Gradient for decoder.decoder.0.bias: 8.825951081092853e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005214377888478339\n",
      "Gradient for decoder.decoder.1.bias: 0.00047845987137407064\n",
      "Gradient for decoder.decoder.3.weight: 0.010179928503930569\n",
      "Gradient for decoder.decoder.3.bias: 8.594486233803877e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0004229334299452603\n",
      "Gradient for decoder.decoder.4.bias: 0.0004365977074485272\n",
      "Gradient for decoder.decoder.6.weight: 0.0004922714433632791\n",
      "Gradient for decoder.decoder.6.bias: 3.216930781491101e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.002876296639442444\n",
      "Gradient for encoder.encoder.0.bias: 7.798872658781875e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.00034816289553418756\n",
      "Gradient for encoder.encoder.1.bias: 0.0006216408801265061\n",
      "Gradient for encoder.encoder.3.weight: 0.0075262137688696384\n",
      "Gradient for encoder.encoder.3.bias: 1.0622355772760272e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.004216880537569523\n",
      "Gradient for encoder.encoder.4.bias: 0.002188615035265684\n",
      "Gradient for encoder.mean.weight: 0.060855116695165634\n",
      "Gradient for encoder.mean.bias: 0.001587684964761138\n",
      "Gradient for encoder.log_var.weight: 0.0343182198703289\n",
      "Gradient for encoder.log_var.bias: 0.0009059446165338159\n",
      "Gradient for decoder.decoder.0.weight: 0.012238631956279278\n",
      "Gradient for decoder.decoder.0.bias: 1.0248683846025841e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0006611562566831708\n",
      "Gradient for decoder.decoder.1.bias: 0.0005093683721497655\n",
      "Gradient for decoder.decoder.3.weight: 0.01173136942088604\n",
      "Gradient for decoder.decoder.3.bias: 1.0289182006406605e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.000632464827504009\n",
      "Gradient for decoder.decoder.4.bias: 0.0007261536666192114\n",
      "Gradient for decoder.decoder.6.weight: 0.0005087018362246454\n",
      "Gradient for decoder.decoder.6.bias: 3.7902365875197574e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.004282848909497261\n",
      "Gradient for encoder.encoder.0.bias: 8.998433942419837e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.0004260613932274282\n",
      "Gradient for encoder.encoder.1.bias: 0.0005220298771746457\n",
      "Gradient for encoder.encoder.3.weight: 0.008794255554676056\n",
      "Gradient for encoder.encoder.3.bias: 1.0691961205289147e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.002811396261677146\n",
      "Gradient for encoder.encoder.4.bias: 0.0026088671293109655\n",
      "Gradient for encoder.mean.weight: 0.04046010598540306\n",
      "Gradient for encoder.mean.bias: 0.0021253651939332485\n",
      "Gradient for encoder.log_var.weight: 0.02165302075445652\n",
      "Gradient for encoder.log_var.bias: 0.0012566872173920274\n",
      "Gradient for decoder.decoder.0.weight: 0.010732310824096203\n",
      "Gradient for decoder.decoder.0.bias: 8.518927230305451e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005362184019759297\n",
      "Gradient for decoder.decoder.1.bias: 0.00041730739758349955\n",
      "Gradient for decoder.decoder.3.weight: 0.01007903553545475\n",
      "Gradient for decoder.decoder.3.bias: 7.598729978575136e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0003504649212118238\n",
      "Gradient for decoder.decoder.4.bias: 0.00032180093694478273\n",
      "Gradient for decoder.decoder.6.weight: 0.0004457580216694623\n",
      "Gradient for decoder.decoder.6.bias: 2.547712210798636e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.0021180822513997555\n",
      "Gradient for encoder.encoder.0.bias: 5.0567384481114974e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.00023746669467072934\n",
      "Gradient for encoder.encoder.1.bias: 0.00035293636028654873\n",
      "Gradient for encoder.encoder.3.weight: 0.005366831552237272\n",
      "Gradient for encoder.encoder.3.bias: 8.607261431370361e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.0028619763907045126\n",
      "Gradient for encoder.encoder.4.bias: 0.0019989716820418835\n",
      "Gradient for encoder.mean.weight: 0.044022854417562485\n",
      "Gradient for encoder.mean.bias: 0.0016143983229994774\n",
      "Gradient for encoder.log_var.weight: 0.022687414661049843\n",
      "Gradient for encoder.log_var.bias: 0.0008387003908865154\n",
      "Gradient for decoder.decoder.0.weight: 0.013206125237047672\n",
      "Gradient for decoder.decoder.0.bias: 1.0873740102779195e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.000661320926155895\n",
      "Gradient for decoder.decoder.1.bias: 0.0005300678894855082\n",
      "Gradient for decoder.decoder.3.weight: 0.012759304605424404\n",
      "Gradient for decoder.decoder.3.bias: 9.070109940889637e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0005114664090797305\n",
      "Gradient for decoder.decoder.4.bias: 0.0004881121567450464\n",
      "Gradient for decoder.decoder.6.weight: 0.0004838857857976109\n",
      "Gradient for decoder.decoder.6.bias: 2.5876539439195767e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.0028402728494256735\n",
      "Gradient for encoder.encoder.0.bias: 6.676069853189803e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.00024212250718846917\n",
      "Gradient for encoder.encoder.1.bias: 0.00044050475116819143\n",
      "Gradient for encoder.encoder.3.weight: 0.005405643489211798\n",
      "Gradient for encoder.encoder.3.bias: 9.329886169195944e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.003133367979899049\n",
      "Gradient for encoder.encoder.4.bias: 0.00199344870634377\n",
      "Gradient for encoder.mean.weight: 0.049279797822237015\n",
      "Gradient for encoder.mean.bias: 0.0016499857883900404\n",
      "Gradient for encoder.log_var.weight: 0.02553384192287922\n",
      "Gradient for encoder.log_var.bias: 0.000891772098839283\n",
      "Gradient for decoder.decoder.0.weight: 0.013400253839790821\n",
      "Gradient for decoder.decoder.0.bias: 1.0428163194076134e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0006185143138282001\n",
      "Gradient for decoder.decoder.1.bias: 0.0005446663708426058\n",
      "Gradient for decoder.decoder.3.weight: 0.012220769189298153\n",
      "Gradient for decoder.decoder.3.bias: 1.0396641186849465e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0005193008109927177\n",
      "Gradient for decoder.decoder.4.bias: 0.0005028737941756845\n",
      "Gradient for decoder.decoder.6.weight: 0.0004754039691761136\n",
      "Gradient for decoder.decoder.6.bias: 2.8156593543826602e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.00304031721316278\n",
      "Gradient for encoder.encoder.0.bias: 5.916471739614293e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.00021779086091555655\n",
      "Gradient for encoder.encoder.1.bias: 0.0002582502784207463\n",
      "Gradient for encoder.encoder.3.weight: 0.0046242582611739635\n",
      "Gradient for encoder.encoder.3.bias: 8.797253203685074e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.0024814007338136435\n",
      "Gradient for encoder.encoder.4.bias: 0.0015059581492096186\n",
      "Gradient for encoder.mean.weight: 0.04159585013985634\n",
      "Gradient for encoder.mean.bias: 0.0015182561473920941\n",
      "Gradient for encoder.log_var.weight: 0.023378536105155945\n",
      "Gradient for encoder.log_var.bias: 0.0008234464330598712\n",
      "Gradient for decoder.decoder.0.weight: 0.012534300796687603\n",
      "Gradient for decoder.decoder.0.bias: 1.2653983416655024e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0006096889264881611\n",
      "Gradient for decoder.decoder.1.bias: 0.0005166820483282208\n",
      "Gradient for decoder.decoder.3.weight: 0.011803701519966125\n",
      "Gradient for decoder.decoder.3.bias: 1.1226458651591997e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0004377781297080219\n",
      "Gradient for decoder.decoder.4.bias: 0.0003964721690863371\n",
      "Gradient for decoder.decoder.6.weight: 0.0004705585306510329\n",
      "Gradient for decoder.decoder.6.bias: 2.4366130674025044e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.0032963473349809647\n",
      "Gradient for encoder.encoder.0.bias: 6.086614719180705e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.0002568922645878047\n",
      "Gradient for encoder.encoder.1.bias: 0.000349836511304602\n",
      "Gradient for encoder.encoder.3.weight: 0.005652429070323706\n",
      "Gradient for encoder.encoder.3.bias: 8.69802563308042e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.00287033012136817\n",
      "Gradient for encoder.encoder.4.bias: 0.0017318307654932141\n",
      "Gradient for encoder.mean.weight: 0.047314487397670746\n",
      "Gradient for encoder.mean.bias: 0.0014451874885708094\n",
      "Gradient for encoder.log_var.weight: 0.02185712568461895\n",
      "Gradient for encoder.log_var.bias: 0.0008802814991213381\n",
      "Gradient for decoder.decoder.0.weight: 0.013511598110198975\n",
      "Gradient for decoder.decoder.0.bias: 1.1978962266567805e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0006219924543984234\n",
      "Gradient for decoder.decoder.1.bias: 0.0005817060591652989\n",
      "Gradient for decoder.decoder.3.weight: 0.013294978067278862\n",
      "Gradient for decoder.decoder.3.bias: 1.0521494092641248e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0006221475778147578\n",
      "Gradient for decoder.decoder.4.bias: 0.0007132806931622326\n",
      "Gradient for decoder.decoder.6.weight: 0.000553252175450325\n",
      "Gradient for decoder.decoder.6.bias: 3.5594879591371864e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.003450196934863925\n",
      "Gradient for encoder.encoder.0.bias: 7.444178953819325e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.0003076119173783809\n",
      "Gradient for encoder.encoder.1.bias: 0.00044310453813523054\n",
      "Gradient for encoder.encoder.3.weight: 0.00665931636467576\n",
      "Gradient for encoder.encoder.3.bias: 9.027414926698896e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.0027689351700246334\n",
      "Gradient for encoder.encoder.4.bias: 0.0015448896447196603\n",
      "Gradient for encoder.mean.weight: 0.046611543744802475\n",
      "Gradient for encoder.mean.bias: 0.0013858812162652612\n",
      "Gradient for encoder.log_var.weight: 0.021394595503807068\n",
      "Gradient for encoder.log_var.bias: 0.0007414810243062675\n",
      "Gradient for decoder.decoder.0.weight: 0.011436330154538155\n",
      "Gradient for decoder.decoder.0.bias: 1.0202474975962161e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0005449160235002637\n",
      "Gradient for decoder.decoder.1.bias: 0.0004872336285188794\n",
      "Gradient for decoder.decoder.3.weight: 0.01078733243048191\n",
      "Gradient for decoder.decoder.3.bias: 8.387692623790244e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00037309975596144795\n",
      "Gradient for decoder.decoder.4.bias: 0.000365046551451087\n",
      "Gradient for decoder.decoder.6.weight: 0.00044815760338678956\n",
      "Gradient for decoder.decoder.6.bias: 2.480071816535201e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.0037507563829421997\n",
      "Gradient for encoder.encoder.0.bias: 9.131809024232052e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.0002662028418853879\n",
      "Gradient for encoder.encoder.1.bias: 0.00042348599527031183\n",
      "Gradient for encoder.encoder.3.weight: 0.005858602933585644\n",
      "Gradient for encoder.encoder.3.bias: 8.359479775066347e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.0026306493673473597\n",
      "Gradient for encoder.encoder.4.bias: 0.0016529036220163107\n",
      "Gradient for encoder.mean.weight: 0.039437949657440186\n",
      "Gradient for encoder.mean.bias: 0.00138218910433352\n",
      "Gradient for encoder.log_var.weight: 0.01952705718576908\n",
      "Gradient for encoder.log_var.bias: 0.000726929574739188\n",
      "Gradient for decoder.decoder.0.weight: 0.01035038661211729\n",
      "Gradient for decoder.decoder.0.bias: 8.987395549997501e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.000501812610309571\n",
      "Gradient for decoder.decoder.1.bias: 0.0004196235677227378\n",
      "Gradient for decoder.decoder.3.weight: 0.009429169818758965\n",
      "Gradient for decoder.decoder.3.bias: 9.054990784962413e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0005137434345670044\n",
      "Gradient for decoder.decoder.4.bias: 0.0006073078839108348\n",
      "Gradient for decoder.decoder.6.weight: 0.00045421242248266935\n",
      "Gradient for decoder.decoder.6.bias: 3.2892243325477466e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.0032227099873125553\n",
      "Gradient for encoder.encoder.0.bias: 5.771712101310111e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.00018519567674957216\n",
      "Gradient for encoder.encoder.1.bias: 0.0002831671736203134\n",
      "Gradient for encoder.encoder.3.weight: 0.004087098408490419\n",
      "Gradient for encoder.encoder.3.bias: 7.785000422089183e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.002192096086218953\n",
      "Gradient for encoder.encoder.4.bias: 0.0013878497993573546\n",
      "Gradient for encoder.mean.weight: 0.03792910650372505\n",
      "Gradient for encoder.mean.bias: 0.0012242899974808097\n",
      "Gradient for encoder.log_var.weight: 0.01991134136915207\n",
      "Gradient for encoder.log_var.bias: 0.0007010787376202643\n",
      "Gradient for decoder.decoder.0.weight: 0.011864262633025646\n",
      "Gradient for decoder.decoder.0.bias: 9.261591493725518e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005574336973950267\n",
      "Gradient for decoder.decoder.1.bias: 0.00048358197091147304\n",
      "Gradient for decoder.decoder.3.weight: 0.011233936063945293\n",
      "Gradient for decoder.decoder.3.bias: 8.587022065631444e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0004475989262573421\n",
      "Gradient for decoder.decoder.4.bias: 0.00043324040598236024\n",
      "Gradient for decoder.decoder.6.weight: 0.0004898422048427165\n",
      "Gradient for decoder.decoder.6.bias: 2.9881035516154952e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.0028236990328878164\n",
      "Gradient for encoder.encoder.0.bias: 5.2424440656617666e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.00024162705813068897\n",
      "Gradient for encoder.encoder.1.bias: 0.00036226114025339484\n",
      "Gradient for encoder.encoder.3.weight: 0.005721897818148136\n",
      "Gradient for encoder.encoder.3.bias: 1.0426206425995233e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0025387629866600037\n",
      "Gradient for encoder.encoder.4.bias: 0.002405275823548436\n",
      "Gradient for encoder.mean.weight: 0.04047689586877823\n",
      "Gradient for encoder.mean.bias: 0.0020740891341120005\n",
      "Gradient for encoder.log_var.weight: 0.021946074441075325\n",
      "Gradient for encoder.log_var.bias: 0.0010236524976789951\n",
      "Gradient for decoder.decoder.0.weight: 0.016278179362416267\n",
      "Gradient for decoder.decoder.0.bias: 1.4408316206804272e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0007969795842655003\n",
      "Gradient for decoder.decoder.1.bias: 0.0006748168962076306\n",
      "Gradient for decoder.decoder.3.weight: 0.015413905493915081\n",
      "Gradient for decoder.decoder.3.bias: 1.4610948562143733e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0008422784740105271\n",
      "Gradient for decoder.decoder.4.bias: 0.0009352178894914687\n",
      "Gradient for decoder.decoder.6.weight: 0.0007063918164931238\n",
      "Gradient for decoder.decoder.6.bias: 5.5321936088148504e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.003975204192101955\n",
      "Gradient for encoder.encoder.0.bias: 7.104596858736878e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.0003485623456072062\n",
      "Gradient for encoder.encoder.1.bias: 0.0004562793474178761\n",
      "Gradient for encoder.encoder.3.weight: 0.0075781457126140594\n",
      "Gradient for encoder.encoder.3.bias: 1.0066306815881276e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0027433570940047503\n",
      "Gradient for encoder.encoder.4.bias: 0.0018680316861718893\n",
      "Gradient for encoder.mean.weight: 0.043097320944070816\n",
      "Gradient for encoder.mean.bias: 0.0014905368443578482\n",
      "Gradient for encoder.log_var.weight: 0.023551080375909805\n",
      "Gradient for encoder.log_var.bias: 0.0008248718804679811\n",
      "Gradient for decoder.decoder.0.weight: 0.011528928764164448\n",
      "Gradient for decoder.decoder.0.bias: 9.34595040247288e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005281902267597616\n",
      "Gradient for decoder.decoder.1.bias: 0.0004541422822512686\n",
      "Gradient for decoder.decoder.3.weight: 0.011188152246177197\n",
      "Gradient for decoder.decoder.3.bias: 8.294278458498283e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0003952924453187734\n",
      "Gradient for decoder.decoder.4.bias: 0.0003622541553340852\n",
      "Gradient for decoder.decoder.6.weight: 0.00047981846728362143\n",
      "Gradient for decoder.decoder.6.bias: 2.6770519980345853e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training VAE Epoch:  77%|███████▋  | 61/79 [00:00<00:00, 76.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient for encoder.encoder.0.weight: 0.002911162097007036\n",
      "Gradient for encoder.encoder.0.bias: 7.18013886194524e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.00034637528005987406\n",
      "Gradient for encoder.encoder.1.bias: 0.00046793880756013095\n",
      "Gradient for encoder.encoder.3.weight: 0.007663351483643055\n",
      "Gradient for encoder.encoder.3.bias: 1.019517387179647e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.003386625088751316\n",
      "Gradient for encoder.encoder.4.bias: 0.0020869767758995295\n",
      "Gradient for encoder.mean.weight: 0.046775344759225845\n",
      "Gradient for encoder.mean.bias: 0.0016532199224457145\n",
      "Gradient for encoder.log_var.weight: 0.02423941344022751\n",
      "Gradient for encoder.log_var.bias: 0.0009791229385882616\n",
      "Gradient for decoder.decoder.0.weight: 0.012047626078128815\n",
      "Gradient for decoder.decoder.0.bias: 1.1185542769798218e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0005998926935717463\n",
      "Gradient for decoder.decoder.1.bias: 0.0005458656814880669\n",
      "Gradient for decoder.decoder.3.weight: 0.012001479975879192\n",
      "Gradient for decoder.decoder.3.bias: 1.0138890421673707e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0004625389992725104\n",
      "Gradient for decoder.decoder.4.bias: 0.00042472820496186614\n",
      "Gradient for decoder.decoder.6.weight: 0.00046774273505434394\n",
      "Gradient for decoder.decoder.6.bias: 2.6058352887048386e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.0022662649862468243\n",
      "Gradient for encoder.encoder.0.bias: 5.524898247233345e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.0002811959129758179\n",
      "Gradient for encoder.encoder.1.bias: 0.000446492776973173\n",
      "Gradient for encoder.encoder.3.weight: 0.005956305656582117\n",
      "Gradient for encoder.encoder.3.bias: 9.184165927766941e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.0035056734923273325\n",
      "Gradient for encoder.encoder.4.bias: 0.0020930408500134945\n",
      "Gradient for encoder.mean.weight: 0.0536554791033268\n",
      "Gradient for encoder.mean.bias: 0.0015978560550138354\n",
      "Gradient for encoder.log_var.weight: 0.023955734446644783\n",
      "Gradient for encoder.log_var.bias: 0.0008905950235202909\n",
      "Gradient for decoder.decoder.0.weight: 0.013729816302657127\n",
      "Gradient for decoder.decoder.0.bias: 1.1376894565318096e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0006922743050381541\n",
      "Gradient for decoder.decoder.1.bias: 0.0005861007375642657\n",
      "Gradient for decoder.decoder.3.weight: 0.013275908306241035\n",
      "Gradient for decoder.decoder.3.bias: 1.0133560657266116e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.00048695330042392015\n",
      "Gradient for decoder.decoder.4.bias: 0.00041772215627133846\n",
      "Gradient for decoder.decoder.6.weight: 0.0005239538149908185\n",
      "Gradient for decoder.decoder.6.bias: 3.484241460682824e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.003601583419367671\n",
      "Gradient for encoder.encoder.0.bias: 8.553270071376406e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.0002786985714919865\n",
      "Gradient for encoder.encoder.1.bias: 0.00041972569306381047\n",
      "Gradient for encoder.encoder.3.weight: 0.0058973110280931\n",
      "Gradient for encoder.encoder.3.bias: 9.856511440364812e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.002592360367998481\n",
      "Gradient for encoder.encoder.4.bias: 0.0020121654961258173\n",
      "Gradient for encoder.mean.weight: 0.03815625607967377\n",
      "Gradient for encoder.mean.bias: 0.0015446910401806235\n",
      "Gradient for encoder.log_var.weight: 0.024814577773213387\n",
      "Gradient for encoder.log_var.bias: 0.0009223080123774707\n",
      "Gradient for decoder.decoder.0.weight: 0.010784545913338661\n",
      "Gradient for decoder.decoder.0.bias: 9.146500223877752e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005033841007389128\n",
      "Gradient for decoder.decoder.1.bias: 0.000399641488911584\n",
      "Gradient for decoder.decoder.3.weight: 0.009958270937204361\n",
      "Gradient for decoder.decoder.3.bias: 8.086499525550295e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0004041634383611381\n",
      "Gradient for decoder.decoder.4.bias: 0.00044519201037473977\n",
      "Gradient for decoder.decoder.6.weight: 0.00043359000119380653\n",
      "Gradient for decoder.decoder.6.bias: 2.356055483687669e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.0027600370813161135\n",
      "Gradient for encoder.encoder.0.bias: 5.849740396940417e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.00020208505156915635\n",
      "Gradient for encoder.encoder.1.bias: 0.00032253770041279495\n",
      "Gradient for encoder.encoder.3.weight: 0.004483472555875778\n",
      "Gradient for encoder.encoder.3.bias: 9.541841622384695e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.003417951287701726\n",
      "Gradient for encoder.encoder.4.bias: 0.0024685582611709833\n",
      "Gradient for encoder.mean.weight: 0.050415731966495514\n",
      "Gradient for encoder.mean.bias: 0.001767464680597186\n",
      "Gradient for encoder.log_var.weight: 0.024499768391251564\n",
      "Gradient for encoder.log_var.bias: 0.0010555264307186007\n",
      "Gradient for decoder.decoder.0.weight: 0.013824974186718464\n",
      "Gradient for decoder.decoder.0.bias: 1.2022935425015646e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0006510990206152201\n",
      "Gradient for decoder.decoder.1.bias: 0.000587478163652122\n",
      "Gradient for decoder.decoder.3.weight: 0.012572717852890491\n",
      "Gradient for decoder.decoder.3.bias: 1.011136868678264e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.00044518717913888395\n",
      "Gradient for decoder.decoder.4.bias: 0.0003949561796616763\n",
      "Gradient for decoder.decoder.6.weight: 0.0004686058091465384\n",
      "Gradient for decoder.decoder.6.bias: 2.5965782697312534e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.0030930694192647934\n",
      "Gradient for encoder.encoder.0.bias: 5.9084265258135815e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.00030792804318480194\n",
      "Gradient for encoder.encoder.1.bias: 0.0003599000920075923\n",
      "Gradient for encoder.encoder.3.weight: 0.006460648030042648\n",
      "Gradient for encoder.encoder.3.bias: 9.298938702384518e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.0028231448959559202\n",
      "Gradient for encoder.encoder.4.bias: 0.0016259548719972372\n",
      "Gradient for encoder.mean.weight: 0.04301440715789795\n",
      "Gradient for encoder.mean.bias: 0.0012598972534760833\n",
      "Gradient for encoder.log_var.weight: 0.019173018634319305\n",
      "Gradient for encoder.log_var.bias: 0.0007590634049847722\n",
      "Gradient for decoder.decoder.0.weight: 0.01388917863368988\n",
      "Gradient for decoder.decoder.0.bias: 1.1345582112687325e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0006933718686923385\n",
      "Gradient for decoder.decoder.1.bias: 0.0005521820276044309\n",
      "Gradient for decoder.decoder.3.weight: 0.013040757738053799\n",
      "Gradient for decoder.decoder.3.bias: 9.495131070291762e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0005024518468417227\n",
      "Gradient for decoder.decoder.4.bias: 0.00044201783020980656\n",
      "Gradient for decoder.decoder.6.weight: 0.0004922057269141078\n",
      "Gradient for decoder.decoder.6.bias: 2.6232404707116075e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.0031943321228027344\n",
      "Gradient for encoder.encoder.0.bias: 7.321749109778786e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.00022082206851337105\n",
      "Gradient for encoder.encoder.1.bias: 0.00032740485039539635\n",
      "Gradient for encoder.encoder.3.weight: 0.005040256306529045\n",
      "Gradient for encoder.encoder.3.bias: 7.733488155414747e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.002656354336068034\n",
      "Gradient for encoder.encoder.4.bias: 0.0015054894611239433\n",
      "Gradient for encoder.mean.weight: 0.040823642164468765\n",
      "Gradient for encoder.mean.bias: 0.0013028002576902509\n",
      "Gradient for encoder.log_var.weight: 0.02142632007598877\n",
      "Gradient for encoder.log_var.bias: 0.0007194632198661566\n",
      "Gradient for decoder.decoder.0.weight: 0.01089722290635109\n",
      "Gradient for decoder.decoder.0.bias: 9.457535449231003e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005660821334458888\n",
      "Gradient for decoder.decoder.1.bias: 0.000469623802928254\n",
      "Gradient for decoder.decoder.3.weight: 0.010577969253063202\n",
      "Gradient for decoder.decoder.3.bias: 7.859741329996339e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00040018517756834626\n",
      "Gradient for decoder.decoder.4.bias: 0.0003805462038144469\n",
      "Gradient for decoder.decoder.6.weight: 0.0004356003482826054\n",
      "Gradient for decoder.decoder.6.bias: 2.1778640075353906e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.004525544587522745\n",
      "Gradient for encoder.encoder.0.bias: 8.711836807506756e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.00036665491643361747\n",
      "Gradient for encoder.encoder.1.bias: 0.0003533286799211055\n",
      "Gradient for encoder.encoder.3.weight: 0.007680252660065889\n",
      "Gradient for encoder.encoder.3.bias: 1.0264027822115551e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0030690617859363556\n",
      "Gradient for encoder.encoder.4.bias: 0.002203775104135275\n",
      "Gradient for encoder.mean.weight: 0.04705449193716049\n",
      "Gradient for encoder.mean.bias: 0.0016412794357165694\n",
      "Gradient for encoder.log_var.weight: 0.022220920771360397\n",
      "Gradient for encoder.log_var.bias: 0.0008908684831112623\n",
      "Gradient for decoder.decoder.0.weight: 0.010373945347964764\n",
      "Gradient for decoder.decoder.0.bias: 9.508320519824309e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005093262880109251\n",
      "Gradient for decoder.decoder.1.bias: 0.0004290930519346148\n",
      "Gradient for decoder.decoder.3.weight: 0.009928866289556026\n",
      "Gradient for decoder.decoder.3.bias: 8.206748475236836e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0003528419474605471\n",
      "Gradient for decoder.decoder.4.bias: 0.00035721086896955967\n",
      "Gradient for decoder.decoder.6.weight: 0.0004512838495429605\n",
      "Gradient for decoder.decoder.6.bias: 2.6184436137555167e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.0027671302668750286\n",
      "Gradient for encoder.encoder.0.bias: 6.040336199969465e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.00025642060791142285\n",
      "Gradient for encoder.encoder.1.bias: 0.0003201380604878068\n",
      "Gradient for encoder.encoder.3.weight: 0.005683876108378172\n",
      "Gradient for encoder.encoder.3.bias: 9.19906373297863e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.00254753977060318\n",
      "Gradient for encoder.encoder.4.bias: 0.0017735714791342616\n",
      "Gradient for encoder.mean.weight: 0.03941269591450691\n",
      "Gradient for encoder.mean.bias: 0.0013764423783868551\n",
      "Gradient for encoder.log_var.weight: 0.01962435059249401\n",
      "Gradient for encoder.log_var.bias: 0.0007752510136924684\n",
      "Gradient for decoder.decoder.0.weight: 0.013004827313125134\n",
      "Gradient for decoder.decoder.0.bias: 1.0920932907998449e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0006196554168127477\n",
      "Gradient for decoder.decoder.1.bias: 0.0005190697847865522\n",
      "Gradient for decoder.decoder.3.weight: 0.012277691625058651\n",
      "Gradient for decoder.decoder.3.bias: 1.032259555611148e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0005675707361660898\n",
      "Gradient for decoder.decoder.4.bias: 0.0005701861809939146\n",
      "Gradient for decoder.decoder.6.weight: 0.0005459370440803468\n",
      "Gradient for decoder.decoder.6.bias: 3.551095869624987e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.005294258706271648\n",
      "Gradient for encoder.encoder.0.bias: 1.078532749221317e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.00040117037133313715\n",
      "Gradient for encoder.encoder.1.bias: 0.000483739742776379\n",
      "Gradient for encoder.encoder.3.weight: 0.008444373495876789\n",
      "Gradient for encoder.encoder.3.bias: 1.0069312050831059e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0028591230511665344\n",
      "Gradient for encoder.encoder.4.bias: 0.002337656682357192\n",
      "Gradient for encoder.mean.weight: 0.042223114520311356\n",
      "Gradient for encoder.mean.bias: 0.0018493121024221182\n",
      "Gradient for encoder.log_var.weight: 0.023327643051743507\n",
      "Gradient for encoder.log_var.bias: 0.0009408856276422739\n",
      "Gradient for decoder.decoder.0.weight: 0.009514731355011463\n",
      "Gradient for decoder.decoder.0.bias: 8.377632615408359e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0004908928531222045\n",
      "Gradient for decoder.decoder.1.bias: 0.000382122554583475\n",
      "Gradient for decoder.decoder.3.weight: 0.008981702849268913\n",
      "Gradient for decoder.decoder.3.bias: 7.178241334671043e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00033141011954285204\n",
      "Gradient for decoder.decoder.4.bias: 0.0003146486706100404\n",
      "Gradient for decoder.decoder.6.weight: 0.0004450192500371486\n",
      "Gradient for decoder.decoder.6.bias: 2.620403938635718e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.0026799836196005344\n",
      "Gradient for encoder.encoder.0.bias: 5.761818105964878e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.0002423853293294087\n",
      "Gradient for encoder.encoder.1.bias: 0.0004239461268298328\n",
      "Gradient for encoder.encoder.3.weight: 0.00515563040971756\n",
      "Gradient for encoder.encoder.3.bias: 1.0215431278659537e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.003407555865123868\n",
      "Gradient for encoder.encoder.4.bias: 0.002203574636951089\n",
      "Gradient for encoder.mean.weight: 0.05025148391723633\n",
      "Gradient for encoder.mean.bias: 0.0014612353406846523\n",
      "Gradient for encoder.log_var.weight: 0.025257965549826622\n",
      "Gradient for encoder.log_var.bias: 0.0009434489184059203\n",
      "Gradient for decoder.decoder.0.weight: 0.012992095202207565\n",
      "Gradient for decoder.decoder.0.bias: 1.085171119630246e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0006597432657144964\n",
      "Gradient for decoder.decoder.1.bias: 0.0005255951546132565\n",
      "Gradient for decoder.decoder.3.weight: 0.012704439461231232\n",
      "Gradient for decoder.decoder.3.bias: 1.0524969784597715e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0005068804020993412\n",
      "Gradient for decoder.decoder.4.bias: 0.0004889758420176804\n",
      "Gradient for decoder.decoder.6.weight: 0.00046276432112790644\n",
      "Gradient for decoder.decoder.6.bias: 2.0585639504133724e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.0034287741873413324\n",
      "Gradient for encoder.encoder.0.bias: 7.192110622333825e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.00025078910402953625\n",
      "Gradient for encoder.encoder.1.bias: 0.000279675965430215\n",
      "Gradient for encoder.encoder.3.weight: 0.005258417222648859\n",
      "Gradient for encoder.encoder.3.bias: 1.0810614209377789e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.002611639443784952\n",
      "Gradient for encoder.encoder.4.bias: 0.002273790305480361\n",
      "Gradient for encoder.mean.weight: 0.03828486427664757\n",
      "Gradient for encoder.mean.bias: 0.0014985828893259168\n",
      "Gradient for encoder.log_var.weight: 0.020282955840229988\n",
      "Gradient for encoder.log_var.bias: 0.0010355849517509341\n",
      "Gradient for decoder.decoder.0.weight: 0.01075837668031454\n",
      "Gradient for decoder.decoder.0.bias: 9.120738886370106e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005646406789310277\n",
      "Gradient for decoder.decoder.1.bias: 0.00045761265209876\n",
      "Gradient for decoder.decoder.3.weight: 0.010675335302948952\n",
      "Gradient for decoder.decoder.3.bias: 7.663546880420924e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00037947462988086045\n",
      "Gradient for decoder.decoder.4.bias: 0.0003367204044479877\n",
      "Gradient for decoder.decoder.6.weight: 0.00047254623495973647\n",
      "Gradient for decoder.decoder.6.bias: 2.8888238375657238e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.002394082024693489\n",
      "Gradient for encoder.encoder.0.bias: 5.118487664962368e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.00020270094682928175\n",
      "Gradient for encoder.encoder.1.bias: 0.0003301218675915152\n",
      "Gradient for encoder.encoder.3.weight: 0.004332652315497398\n",
      "Gradient for encoder.encoder.3.bias: 9.288934899043255e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.003260386874899268\n",
      "Gradient for encoder.encoder.4.bias: 0.002406385960057378\n",
      "Gradient for encoder.mean.weight: 0.04815497249364853\n",
      "Gradient for encoder.mean.bias: 0.001633810461498797\n",
      "Gradient for encoder.log_var.weight: 0.027424022555351257\n",
      "Gradient for encoder.log_var.bias: 0.000980945653282106\n",
      "Gradient for decoder.decoder.0.weight: 0.013010740280151367\n",
      "Gradient for decoder.decoder.0.bias: 1.0448964610221267e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0006525290664285421\n",
      "Gradient for decoder.decoder.1.bias: 0.0005314960144460201\n",
      "Gradient for decoder.decoder.3.weight: 0.011926122941076756\n",
      "Gradient for decoder.decoder.3.bias: 9.865292610600207e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0004801393370144069\n",
      "Gradient for decoder.decoder.4.bias: 0.0004982245154678822\n",
      "Gradient for decoder.decoder.6.weight: 0.0004766553465742618\n",
      "Gradient for decoder.decoder.6.bias: 3.0680712370667607e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.0034849175717681646\n",
      "Gradient for encoder.encoder.0.bias: 7.69524027832702e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.0002754269808065146\n",
      "Gradient for encoder.encoder.1.bias: 0.00034834520192816854\n",
      "Gradient for encoder.encoder.3.weight: 0.006124947685748339\n",
      "Gradient for encoder.encoder.3.bias: 7.99870725209928e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.0023725107312202454\n",
      "Gradient for encoder.encoder.4.bias: 0.001489859540015459\n",
      "Gradient for encoder.mean.weight: 0.036155782639980316\n",
      "Gradient for encoder.mean.bias: 0.0011195414699614048\n",
      "Gradient for encoder.log_var.weight: 0.019664686173200607\n",
      "Gradient for encoder.log_var.bias: 0.0006981195765547454\n",
      "Gradient for decoder.decoder.0.weight: 0.0105189960449934\n",
      "Gradient for decoder.decoder.0.bias: 9.25312396149458e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0004830863908864558\n",
      "Gradient for decoder.decoder.1.bias: 0.0004088166751898825\n",
      "Gradient for decoder.decoder.3.weight: 0.00969373993575573\n",
      "Gradient for decoder.decoder.3.bias: 7.493661940971563e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00042785974801518023\n",
      "Gradient for decoder.decoder.4.bias: 0.00045259250327944756\n",
      "Gradient for decoder.decoder.6.weight: 0.00045115139801055193\n",
      "Gradient for decoder.decoder.6.bias: 2.6295683710486628e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.003053811378777027\n",
      "Gradient for encoder.encoder.0.bias: 5.981778006952654e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.0002552975493017584\n",
      "Gradient for encoder.encoder.1.bias: 0.0003313739434815943\n",
      "Gradient for encoder.encoder.3.weight: 0.005492059513926506\n",
      "Gradient for encoder.encoder.3.bias: 8.558959790905263e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.002262079156935215\n",
      "Gradient for encoder.encoder.4.bias: 0.0014840454095974565\n",
      "Gradient for encoder.mean.weight: 0.034707631915807724\n",
      "Gradient for encoder.mean.bias: 0.001080392044968903\n",
      "Gradient for encoder.log_var.weight: 0.01923578791320324\n",
      "Gradient for encoder.log_var.bias: 0.0007070566061884165\n",
      "Gradient for decoder.decoder.0.weight: 0.01335644070059061\n",
      "Gradient for decoder.decoder.0.bias: 1.2284850914312528e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0006771495100110769\n",
      "Gradient for decoder.decoder.1.bias: 0.0005412468453869224\n",
      "Gradient for decoder.decoder.3.weight: 0.013112001121044159\n",
      "Gradient for decoder.decoder.3.bias: 1.059798568348036e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0005661091418005526\n",
      "Gradient for decoder.decoder.4.bias: 0.0006050224183127284\n",
      "Gradient for decoder.decoder.6.weight: 0.0005416003987193108\n",
      "Gradient for decoder.decoder.6.bias: 3.2554500648984686e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.0029968335293233395\n",
      "Gradient for encoder.encoder.0.bias: 6.887699612045939e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.0002248844684800133\n",
      "Gradient for encoder.encoder.1.bias: 0.0003344392462167889\n",
      "Gradient for encoder.encoder.3.weight: 0.004763589706271887\n",
      "Gradient for encoder.encoder.3.bias: 8.564472048222527e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.0027447554748505354\n",
      "Gradient for encoder.encoder.4.bias: 0.0017459007212892175\n",
      "Gradient for encoder.mean.weight: 0.03827853873372078\n",
      "Gradient for encoder.mean.bias: 0.0013729821657761931\n",
      "Gradient for encoder.log_var.weight: 0.02098652347922325\n",
      "Gradient for encoder.log_var.bias: 0.0008477873634546995\n",
      "Gradient for decoder.decoder.0.weight: 0.010865154676139355\n",
      "Gradient for decoder.decoder.0.bias: 9.23838297528512e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005763702793046832\n",
      "Gradient for decoder.decoder.1.bias: 0.0004466660029720515\n",
      "Gradient for decoder.decoder.3.weight: 0.010452301241457462\n",
      "Gradient for decoder.decoder.3.bias: 9.351473068131e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0005089177866466343\n",
      "Gradient for decoder.decoder.4.bias: 0.0005567356129176915\n",
      "Gradient for decoder.decoder.6.weight: 0.00047868865658529103\n",
      "Gradient for decoder.decoder.6.bias: 3.436650149524212e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.00308454898186028\n",
      "Gradient for encoder.encoder.0.bias: 5.910170790268676e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.0002902803826145828\n",
      "Gradient for encoder.encoder.1.bias: 0.0004562883113976568\n",
      "Gradient for encoder.encoder.3.weight: 0.006607492454349995\n",
      "Gradient for encoder.encoder.3.bias: 9.505354836569779e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.003206584369763732\n",
      "Gradient for encoder.encoder.4.bias: 0.002333290409296751\n",
      "Gradient for encoder.mean.weight: 0.04935844987630844\n",
      "Gradient for encoder.mean.bias: 0.0016345708863809705\n",
      "Gradient for encoder.log_var.weight: 0.025436999276280403\n",
      "Gradient for encoder.log_var.bias: 0.0011580270947888494\n",
      "Gradient for decoder.decoder.0.weight: 0.014799948781728745\n",
      "Gradient for decoder.decoder.0.bias: 1.1586501896809764e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.000667152984533459\n",
      "Gradient for decoder.decoder.1.bias: 0.0005766268004663289\n",
      "Gradient for decoder.decoder.3.weight: 0.013638446107506752\n",
      "Gradient for decoder.decoder.3.bias: 1.0643225190065664e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0005233696429058909\n",
      "Gradient for decoder.decoder.4.bias: 0.0004926640540361404\n",
      "Gradient for decoder.decoder.6.weight: 0.0004993347101844847\n",
      "Gradient for decoder.decoder.6.bias: 2.812298589560669e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient for encoder.encoder.0.weight: 0.0030324358958750963\n",
      "Gradient for encoder.encoder.0.bias: 6.112340234648572e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.00017659460718277842\n",
      "Gradient for encoder.encoder.1.bias: 0.0002811839513015002\n",
      "Gradient for encoder.encoder.3.weight: 0.0036290250718593597\n",
      "Gradient for encoder.encoder.3.bias: 7.847721084086601e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.002500839764252305\n",
      "Gradient for encoder.encoder.4.bias: 0.0018269458087161183\n",
      "Gradient for encoder.mean.weight: 0.034927722066640854\n",
      "Gradient for encoder.mean.bias: 0.0013733647065237164\n",
      "Gradient for encoder.log_var.weight: 0.022737722843885422\n",
      "Gradient for encoder.log_var.bias: 0.000991466804407537\n",
      "Gradient for decoder.decoder.0.weight: 0.01176096498966217\n",
      "Gradient for decoder.decoder.0.bias: 1.046028264006793e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0005500848055817187\n",
      "Gradient for decoder.decoder.1.bias: 0.000488218356622383\n",
      "Gradient for decoder.decoder.3.weight: 0.01115370076149702\n",
      "Gradient for decoder.decoder.3.bias: 9.621018565164619e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0006053641554899514\n",
      "Gradient for decoder.decoder.4.bias: 0.0006538110901601613\n",
      "Gradient for decoder.decoder.6.weight: 0.0005009313463233411\n",
      "Gradient for decoder.decoder.6.bias: 3.527106309775263e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.004639544989913702\n",
      "Gradient for encoder.encoder.0.bias: 9.347945160997906e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.00026923874975182116\n",
      "Gradient for encoder.encoder.1.bias: 0.0003697925712913275\n",
      "Gradient for encoder.encoder.3.weight: 0.0061252000741660595\n",
      "Gradient for encoder.encoder.3.bias: 8.950728352941084e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.002606330905109644\n",
      "Gradient for encoder.encoder.4.bias: 0.0017741398187354207\n",
      "Gradient for encoder.mean.weight: 0.04055360332131386\n",
      "Gradient for encoder.mean.bias: 0.0011303446954116225\n",
      "Gradient for encoder.log_var.weight: 0.01988239213824272\n",
      "Gradient for encoder.log_var.bias: 0.0007510494324378669\n",
      "Gradient for decoder.decoder.0.weight: 0.009095338173210621\n",
      "Gradient for decoder.decoder.0.bias: 7.120082301526054e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.00042573665268719196\n",
      "Gradient for decoder.decoder.1.bias: 0.00034568930277600884\n",
      "Gradient for decoder.decoder.3.weight: 0.008604568429291248\n",
      "Gradient for decoder.decoder.3.bias: 7.546267083435865e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.000477341644000262\n",
      "Gradient for decoder.decoder.4.bias: 0.0005496939411386847\n",
      "Gradient for decoder.decoder.6.weight: 0.0004536546766757965\n",
      "Gradient for decoder.decoder.6.bias: 3.0001405320945196e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.0027828181628137827\n",
      "Gradient for encoder.encoder.0.bias: 5.23837223598278e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.00021270971046760678\n",
      "Gradient for encoder.encoder.1.bias: 0.0003544487408362329\n",
      "Gradient for encoder.encoder.3.weight: 0.004848370794206858\n",
      "Gradient for encoder.encoder.3.bias: 8.331012268936178e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.002977062715217471\n",
      "Gradient for encoder.encoder.4.bias: 0.0016551431035622954\n",
      "Gradient for encoder.mean.weight: 0.04412529617547989\n",
      "Gradient for encoder.mean.bias: 0.0011636639246717095\n",
      "Gradient for encoder.log_var.weight: 0.02414095029234886\n",
      "Gradient for encoder.log_var.bias: 0.0008688299567438662\n",
      "Gradient for decoder.decoder.0.weight: 0.013721315190196037\n",
      "Gradient for decoder.decoder.0.bias: 1.1061209587159837e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0006883093155920506\n",
      "Gradient for decoder.decoder.1.bias: 0.000557960825972259\n",
      "Gradient for decoder.decoder.3.weight: 0.01267713401466608\n",
      "Gradient for decoder.decoder.3.bias: 9.57330256734501e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0004425235092639923\n",
      "Gradient for decoder.decoder.4.bias: 0.0003828394110314548\n",
      "Gradient for decoder.decoder.6.weight: 0.00046386165195144713\n",
      "Gradient for decoder.decoder.6.bias: 2.301400490978267e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.0024345198180526495\n",
      "Gradient for encoder.encoder.0.bias: 4.8390727189207006e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.00020218858844600618\n",
      "Gradient for encoder.encoder.1.bias: 0.0003160304040648043\n",
      "Gradient for encoder.encoder.3.weight: 0.004506845958530903\n",
      "Gradient for encoder.encoder.3.bias: 7.778701294203216e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.0026921883691102266\n",
      "Gradient for encoder.encoder.4.bias: 0.0013428323436528444\n",
      "Gradient for encoder.mean.weight: 0.042130615562200546\n",
      "Gradient for encoder.mean.bias: 0.0009966237703338265\n",
      "Gradient for encoder.log_var.weight: 0.01947733759880066\n",
      "Gradient for encoder.log_var.bias: 0.0006914879777468741\n",
      "Gradient for decoder.decoder.0.weight: 0.01259762141853571\n",
      "Gradient for decoder.decoder.0.bias: 1.027618962146093e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0006424224120564759\n",
      "Gradient for decoder.decoder.1.bias: 0.0005443083355203271\n",
      "Gradient for decoder.decoder.3.weight: 0.012558783404529095\n",
      "Gradient for decoder.decoder.3.bias: 8.652838168199395e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00045911825145594776\n",
      "Gradient for decoder.decoder.4.bias: 0.00042328948620706797\n",
      "Gradient for decoder.decoder.6.weight: 0.0004677340039052069\n",
      "Gradient for decoder.decoder.6.bias: 2.3775264708092436e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.0039619868621230125\n",
      "Gradient for encoder.encoder.0.bias: 8.009994577340418e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.00031570706050843\n",
      "Gradient for encoder.encoder.1.bias: 0.0004006116068921983\n",
      "Gradient for encoder.encoder.3.weight: 0.007114300038665533\n",
      "Gradient for encoder.encoder.3.bias: 9.642466686221596e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.002422972582280636\n",
      "Gradient for encoder.encoder.4.bias: 0.0016940353671088815\n",
      "Gradient for encoder.mean.weight: 0.0356353297829628\n",
      "Gradient for encoder.mean.bias: 0.0013155612396076322\n",
      "Gradient for encoder.log_var.weight: 0.02105420082807541\n",
      "Gradient for encoder.log_var.bias: 0.000770090555306524\n",
      "Gradient for decoder.decoder.0.weight: 0.010635015554726124\n",
      "Gradient for decoder.decoder.0.bias: 8.749891783343955e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005189344519749284\n",
      "Gradient for decoder.decoder.1.bias: 0.00040281645487993956\n",
      "Gradient for decoder.decoder.3.weight: 0.009661993943154812\n",
      "Gradient for decoder.decoder.3.bias: 8.366756593103375e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0003706019779201597\n",
      "Gradient for decoder.decoder.4.bias: 0.00037649981095455587\n",
      "Gradient for decoder.decoder.6.weight: 0.0004505723190959543\n",
      "Gradient for decoder.decoder.6.bias: 2.5887849915307015e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.0026312917470932007\n",
      "Gradient for encoder.encoder.0.bias: 6.096055951698709e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.00020298929302953184\n",
      "Gradient for encoder.encoder.1.bias: 0.0003246906853746623\n",
      "Gradient for encoder.encoder.3.weight: 0.004541470669209957\n",
      "Gradient for encoder.encoder.3.bias: 7.532891671546693e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.002510520862415433\n",
      "Gradient for encoder.encoder.4.bias: 0.0013051002752035856\n",
      "Gradient for encoder.mean.weight: 0.03615584596991539\n",
      "Gradient for encoder.mean.bias: 0.0009552144329063594\n",
      "Gradient for encoder.log_var.weight: 0.02295517362654209\n",
      "Gradient for encoder.log_var.bias: 0.000715473317541182\n",
      "Gradient for decoder.decoder.0.weight: 0.012286806479096413\n",
      "Gradient for decoder.decoder.0.bias: 1.0895322144488517e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0005717851454392076\n",
      "Gradient for decoder.decoder.1.bias: 0.0005146205658093095\n",
      "Gradient for decoder.decoder.3.weight: 0.011644016019999981\n",
      "Gradient for decoder.decoder.3.bias: 9.82381259673204e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0004940593498758972\n",
      "Gradient for decoder.decoder.4.bias: 0.00048665658687241375\n",
      "Gradient for decoder.decoder.6.weight: 0.000446946156444028\n",
      "Gradient for decoder.decoder.6.bias: 2.8227685106685385e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.0027857632376253605\n",
      "Gradient for encoder.encoder.0.bias: 6.205723435126487e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.00022370187798514962\n",
      "Gradient for encoder.encoder.1.bias: 0.00035753578413277864\n",
      "Gradient for encoder.encoder.3.weight: 0.005113569553941488\n",
      "Gradient for encoder.encoder.3.bias: 8.90728185654055e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.0025595182087272406\n",
      "Gradient for encoder.encoder.4.bias: 0.001902156975120306\n",
      "Gradient for encoder.mean.weight: 0.03870396316051483\n",
      "Gradient for encoder.mean.bias: 0.001577382325194776\n",
      "Gradient for encoder.log_var.weight: 0.02440531551837921\n",
      "Gradient for encoder.log_var.bias: 0.0009237730409950018\n",
      "Gradient for decoder.decoder.0.weight: 0.011285597458481789\n",
      "Gradient for decoder.decoder.0.bias: 9.412892687521435e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005291059496812522\n",
      "Gradient for decoder.decoder.1.bias: 0.00047166700824163854\n",
      "Gradient for decoder.decoder.3.weight: 0.010511831380426884\n",
      "Gradient for decoder.decoder.3.bias: 8.537381912532283e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00039747782284393907\n",
      "Gradient for decoder.decoder.4.bias: 0.0003733695484697819\n",
      "Gradient for decoder.decoder.6.weight: 0.0005120932473801076\n",
      "Gradient for decoder.decoder.6.bias: 3.803829167736694e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.0033250644337385893\n",
      "Gradient for encoder.encoder.0.bias: 6.90366991004665e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.00024464374291710556\n",
      "Gradient for encoder.encoder.1.bias: 0.00037851391243748367\n",
      "Gradient for encoder.encoder.3.weight: 0.005355373956263065\n",
      "Gradient for encoder.encoder.3.bias: 8.25696178097246e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.002245537005364895\n",
      "Gradient for encoder.encoder.4.bias: 0.0016234685899689794\n",
      "Gradient for encoder.mean.weight: 0.03730862960219383\n",
      "Gradient for encoder.mean.bias: 0.0012287863064557314\n",
      "Gradient for encoder.log_var.weight: 0.020351575687527657\n",
      "Gradient for encoder.log_var.bias: 0.0008558358531445265\n",
      "Gradient for decoder.decoder.0.weight: 0.009714472107589245\n",
      "Gradient for decoder.decoder.0.bias: 7.798137829917451e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.000496275257319212\n",
      "Gradient for decoder.decoder.1.bias: 0.00042981503065675497\n",
      "Gradient for decoder.decoder.3.weight: 0.009296433068811893\n",
      "Gradient for decoder.decoder.3.bias: 7.282955488685516e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0003391818900126964\n",
      "Gradient for decoder.decoder.4.bias: 0.0003153477155137807\n",
      "Gradient for decoder.decoder.6.weight: 0.00042963348096236587\n",
      "Gradient for decoder.decoder.6.bias: 2.2137384803500026e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.0030265911482274532\n",
      "Gradient for encoder.encoder.0.bias: 7.03486097500261e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.0002384660765528679\n",
      "Gradient for encoder.encoder.1.bias: 0.0003299200616311282\n",
      "Gradient for encoder.encoder.3.weight: 0.005140597000718117\n",
      "Gradient for encoder.encoder.3.bias: 8.30865862222474e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.002447806065902114\n",
      "Gradient for encoder.encoder.4.bias: 0.0016000160248950124\n",
      "Gradient for encoder.mean.weight: 0.03813783451914787\n",
      "Gradient for encoder.mean.bias: 0.0011163518065586686\n",
      "Gradient for encoder.log_var.weight: 0.01955728605389595\n",
      "Gradient for encoder.log_var.bias: 0.0007760652806609869\n",
      "Gradient for decoder.decoder.0.weight: 0.01075761392712593\n",
      "Gradient for decoder.decoder.0.bias: 9.069573564390865e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005428172298707068\n",
      "Gradient for decoder.decoder.1.bias: 0.00045184532064013183\n",
      "Gradient for decoder.decoder.3.weight: 0.010386104695498943\n",
      "Gradient for decoder.decoder.3.bias: 8.012714797223097e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00043385993922129273\n",
      "Gradient for decoder.decoder.4.bias: 0.000446921942057088\n",
      "Gradient for decoder.decoder.6.weight: 0.00043267791625112295\n",
      "Gradient for decoder.decoder.6.bias: 2.287552888446953e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.0048022945411503315\n",
      "Gradient for encoder.encoder.0.bias: 1.2538275105666852e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.00032858288614079356\n",
      "Gradient for encoder.encoder.1.bias: 0.0004027287650387734\n",
      "Gradient for encoder.encoder.3.weight: 0.0068634613417088985\n",
      "Gradient for encoder.encoder.3.bias: 9.613781992712234e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.002346758032217622\n",
      "Gradient for encoder.encoder.4.bias: 0.0013891783310100436\n",
      "Gradient for encoder.mean.weight: 0.034515660256147385\n",
      "Gradient for encoder.mean.bias: 0.0012094142148271203\n",
      "Gradient for encoder.log_var.weight: 0.018783684819936752\n",
      "Gradient for encoder.log_var.bias: 0.0006966717191971838\n",
      "Gradient for decoder.decoder.0.weight: 0.00813523679971695\n",
      "Gradient for decoder.decoder.0.bias: 7.411701807846782e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0004093731986358762\n",
      "Gradient for decoder.decoder.1.bias: 0.00035899714566767216\n",
      "Gradient for decoder.decoder.3.weight: 0.0077035091817379\n",
      "Gradient for decoder.decoder.3.bias: 7.415754815776054e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00044263535528443754\n",
      "Gradient for decoder.decoder.4.bias: 0.0004974519251845777\n",
      "Gradient for decoder.decoder.6.weight: 0.000480332673760131\n",
      "Gradient for decoder.decoder.6.bias: 3.66842323273886e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.003363918513059616\n",
      "Gradient for encoder.encoder.0.bias: 6.7610968906839375e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.00022152748715598136\n",
      "Gradient for encoder.encoder.1.bias: 0.0003329256142023951\n",
      "Gradient for encoder.encoder.3.weight: 0.005200456827878952\n",
      "Gradient for encoder.encoder.3.bias: 8.452530342317743e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.0021643335931003094\n",
      "Gradient for encoder.encoder.4.bias: 0.0014637779677286744\n",
      "Gradient for encoder.mean.weight: 0.033723507076501846\n",
      "Gradient for encoder.mean.bias: 0.001223334576934576\n",
      "Gradient for encoder.log_var.weight: 0.020966483280062675\n",
      "Gradient for encoder.log_var.bias: 0.000944133847951889\n",
      "Gradient for decoder.decoder.0.weight: 0.011391760781407356\n",
      "Gradient for decoder.decoder.0.bias: 1.0089840074556378e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.000533920363523066\n",
      "Gradient for decoder.decoder.1.bias: 0.00048563876771368086\n",
      "Gradient for decoder.decoder.3.weight: 0.010622117668390274\n",
      "Gradient for decoder.decoder.3.bias: 8.327832173860017e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0003958549350500107\n",
      "Gradient for decoder.decoder.4.bias: 0.0003341191040817648\n",
      "Gradient for decoder.decoder.6.weight: 0.0004526928532868624\n",
      "Gradient for decoder.decoder.6.bias: 2.453138404234778e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.0027708089910447598\n",
      "Gradient for encoder.encoder.0.bias: 5.687915850122183e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.00023589679040014744\n",
      "Gradient for encoder.encoder.1.bias: 0.00029522101976908743\n",
      "Gradient for encoder.encoder.3.weight: 0.0052601671777665615\n",
      "Gradient for encoder.encoder.3.bias: 8.219692287925184e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.0023430194705724716\n",
      "Gradient for encoder.encoder.4.bias: 0.0014947191812098026\n",
      "Gradient for encoder.mean.weight: 0.033381056040525436\n",
      "Gradient for encoder.mean.bias: 0.0010853754356503487\n",
      "Gradient for encoder.log_var.weight: 0.020849639549851418\n",
      "Gradient for encoder.log_var.bias: 0.0007244093576446176\n",
      "Gradient for decoder.decoder.0.weight: 0.013217576779425144\n",
      "Gradient for decoder.decoder.0.bias: 1.076044600645254e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0006644800305366516\n",
      "Gradient for decoder.decoder.1.bias: 0.0005775218014605343\n",
      "Gradient for decoder.decoder.3.weight: 0.012400983832776546\n",
      "Gradient for decoder.decoder.3.bias: 9.698453151685271e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0005424481933005154\n",
      "Gradient for decoder.decoder.4.bias: 0.0005948760081082582\n",
      "Gradient for decoder.decoder.6.weight: 0.0005330159328877926\n",
      "Gradient for decoder.decoder.6.bias: 3.561917765182443e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.005108214449137449\n",
      "Gradient for encoder.encoder.0.bias: 9.934800378197384e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.00029222280136309564\n",
      "Gradient for encoder.encoder.1.bias: 0.0003905264602508396\n",
      "Gradient for encoder.encoder.3.weight: 0.006590419914573431\n",
      "Gradient for encoder.encoder.3.bias: 9.060819455841695e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.002344459295272827\n",
      "Gradient for encoder.encoder.4.bias: 0.001591473468579352\n",
      "Gradient for encoder.mean.weight: 0.03578468784689903\n",
      "Gradient for encoder.mean.bias: 0.0012190209235996008\n",
      "Gradient for encoder.log_var.weight: 0.018970388919115067\n",
      "Gradient for encoder.log_var.bias: 0.0008844115654937923\n",
      "Gradient for decoder.decoder.0.weight: 0.009658078663051128\n",
      "Gradient for decoder.decoder.0.bias: 8.03387148473611e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0004925655666738749\n",
      "Gradient for decoder.decoder.1.bias: 0.00038545840652659535\n",
      "Gradient for decoder.decoder.3.weight: 0.009468530304729939\n",
      "Gradient for decoder.decoder.3.bias: 9.088635399834288e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0004977017524652183\n",
      "Gradient for decoder.decoder.4.bias: 0.0005753480945713818\n",
      "Gradient for decoder.decoder.6.weight: 0.0004752386885229498\n",
      "Gradient for decoder.decoder.6.bias: 3.422790905460715e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.03705635294318199\n",
      "Gradient for encoder.encoder.0.bias: 6.383118339448046e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0017747250385582447\n",
      "Gradient for encoder.encoder.1.bias: 0.001705668866634369\n",
      "Gradient for encoder.encoder.3.weight: 0.04066053032875061\n",
      "Gradient for encoder.encoder.3.bias: 3.4465563736318927e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.006400015205144882\n",
      "Gradient for encoder.encoder.4.bias: 0.005352228879928589\n",
      "Gradient for encoder.mean.weight: 0.07895783334970474\n",
      "Gradient for encoder.mean.bias: 0.00400489941239357\n",
      "Gradient for encoder.log_var.weight: 0.04686291515827179\n",
      "Gradient for encoder.log_var.bias: 0.0022483444772660732\n",
      "Gradient for decoder.decoder.0.weight: 0.014891818165779114\n",
      "Gradient for decoder.decoder.0.bias: 9.350489132975426e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0006256065098568797\n",
      "Gradient for decoder.decoder.1.bias: 0.0005459910025820136\n",
      "Gradient for decoder.decoder.3.weight: 0.013557467609643936\n",
      "Gradient for decoder.decoder.3.bias: 8.48351389137747e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00047423382056877017\n",
      "Gradient for decoder.decoder.4.bias: 0.0004336722195148468\n",
      "Gradient for decoder.decoder.6.weight: 0.0011207085335627198\n",
      "Gradient for decoder.decoder.6.bias: 6.876249244669452e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3, Train Loss: 0.0504, Val Loss: 0.2736\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training VAE Epoch:   1%|▏         | 1/79 [00:00<00:14,  5.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient for encoder.encoder.0.weight: 0.0028710737824440002\n",
      "Gradient for encoder.encoder.0.bias: 5.77709798402215e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.00042062604916282\n",
      "Gradient for encoder.encoder.1.bias: 0.000525351264514029\n",
      "Gradient for encoder.encoder.3.weight: 0.009004679508507252\n",
      "Gradient for encoder.encoder.3.bias: 1.2738354815411412e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0029068475123494864\n",
      "Gradient for encoder.encoder.4.bias: 0.002940179081633687\n",
      "Gradient for encoder.mean.weight: 0.0448787696659565\n",
      "Gradient for encoder.mean.bias: 0.0021285347174853086\n",
      "Gradient for encoder.log_var.weight: 0.025428496301174164\n",
      "Gradient for encoder.log_var.bias: 0.0015608490211889148\n",
      "Gradient for decoder.decoder.0.weight: 0.015109996311366558\n",
      "Gradient for decoder.decoder.0.bias: 1.294503254589685e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0007791557582095265\n",
      "Gradient for decoder.decoder.1.bias: 0.0006194080924615264\n",
      "Gradient for decoder.decoder.3.weight: 0.015148267149925232\n",
      "Gradient for decoder.decoder.3.bias: 1.4322014407763817e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.000667461717966944\n",
      "Gradient for decoder.decoder.4.bias: 0.0006403657025657594\n",
      "Gradient for decoder.decoder.6.weight: 0.000576256774365902\n",
      "Gradient for decoder.decoder.6.bias: 3.7774974771309644e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.003365333192050457\n",
      "Gradient for encoder.encoder.0.bias: 7.3437506076246e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.0004936204641126096\n",
      "Gradient for encoder.encoder.1.bias: 0.00047735171392560005\n",
      "Gradient for encoder.encoder.3.weight: 0.011161858215928078\n",
      "Gradient for encoder.encoder.3.bias: 1.0735830280328429e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0033288265112787485\n",
      "Gradient for encoder.encoder.4.bias: 0.0024714272003620863\n",
      "Gradient for encoder.mean.weight: 0.046798136085271835\n",
      "Gradient for encoder.mean.bias: 0.001732468488626182\n",
      "Gradient for encoder.log_var.weight: 0.02542022243142128\n",
      "Gradient for encoder.log_var.bias: 0.000979571952484548\n",
      "Gradient for decoder.decoder.0.weight: 0.013014296069741249\n",
      "Gradient for decoder.decoder.0.bias: 1.1359222590323625e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0006752401823177934\n",
      "Gradient for decoder.decoder.1.bias: 0.0005435326602309942\n",
      "Gradient for decoder.decoder.3.weight: 0.01204304676502943\n",
      "Gradient for decoder.decoder.3.bias: 1.0221540280852537e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.00043389498023316264\n",
      "Gradient for decoder.decoder.4.bias: 0.00040063756750896573\n",
      "Gradient for decoder.decoder.6.weight: 0.00044258416164666414\n",
      "Gradient for decoder.decoder.6.bias: 2.050634975603316e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training VAE Epoch:  11%|█▏        | 9/79 [00:00<00:01, 37.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient for encoder.encoder.0.weight: 0.004514506086707115\n",
      "Gradient for encoder.encoder.0.bias: 9.420488694678042e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.0004919323837384582\n",
      "Gradient for encoder.encoder.1.bias: 0.0005108949262648821\n",
      "Gradient for encoder.encoder.3.weight: 0.01166042871773243\n",
      "Gradient for encoder.encoder.3.bias: 1.0404054007207009e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0028484719805419445\n",
      "Gradient for encoder.encoder.4.bias: 0.002360493643209338\n",
      "Gradient for encoder.mean.weight: 0.03993634134531021\n",
      "Gradient for encoder.mean.bias: 0.0018252081936225295\n",
      "Gradient for encoder.log_var.weight: 0.022622155025601387\n",
      "Gradient for encoder.log_var.bias: 0.00113095308188349\n",
      "Gradient for decoder.decoder.0.weight: 0.011570146307349205\n",
      "Gradient for decoder.decoder.0.bias: 9.398486155998143e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005614764522761106\n",
      "Gradient for decoder.decoder.1.bias: 0.0004816986620426178\n",
      "Gradient for decoder.decoder.3.weight: 0.01079249382019043\n",
      "Gradient for decoder.decoder.3.bias: 8.831155251520784e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0004291869990993291\n",
      "Gradient for decoder.decoder.4.bias: 0.00040694812196306884\n",
      "Gradient for decoder.decoder.6.weight: 0.0004896440077573061\n",
      "Gradient for decoder.decoder.6.bias: 2.9343227652134374e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.0038462867960333824\n",
      "Gradient for encoder.encoder.0.bias: 6.763254453007184e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.000428099388955161\n",
      "Gradient for encoder.encoder.1.bias: 0.0004917477490380406\n",
      "Gradient for encoder.encoder.3.weight: 0.00961717963218689\n",
      "Gradient for encoder.encoder.3.bias: 1.0762230689964625e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0032371263951063156\n",
      "Gradient for encoder.encoder.4.bias: 0.002373678609728813\n",
      "Gradient for encoder.mean.weight: 0.043965235352516174\n",
      "Gradient for encoder.mean.bias: 0.0016863492783159018\n",
      "Gradient for encoder.log_var.weight: 0.028157168999314308\n",
      "Gradient for encoder.log_var.bias: 0.0011463224655017257\n",
      "Gradient for decoder.decoder.0.weight: 0.014097951352596283\n",
      "Gradient for decoder.decoder.0.bias: 1.1992797033233416e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0006686679553240538\n",
      "Gradient for decoder.decoder.1.bias: 0.0006024707690812647\n",
      "Gradient for decoder.decoder.3.weight: 0.012955697253346443\n",
      "Gradient for decoder.decoder.3.bias: 1.0887044737950546e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.000544585520401597\n",
      "Gradient for decoder.decoder.4.bias: 0.0005539393750950694\n",
      "Gradient for decoder.decoder.6.weight: 0.0005044329445809126\n",
      "Gradient for decoder.decoder.6.bias: 3.1084655347513035e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.005671339575201273\n",
      "Gradient for encoder.encoder.0.bias: 1.1588192211364756e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0004323868779465556\n",
      "Gradient for encoder.encoder.1.bias: 0.0005460789543576539\n",
      "Gradient for encoder.encoder.3.weight: 0.009677319787442684\n",
      "Gradient for encoder.encoder.3.bias: 1.2561748863326727e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0031974271405488253\n",
      "Gradient for encoder.encoder.4.bias: 0.0023773033171892166\n",
      "Gradient for encoder.mean.weight: 0.04199984669685364\n",
      "Gradient for encoder.mean.bias: 0.0017598778940737247\n",
      "Gradient for encoder.log_var.weight: 0.023826640099287033\n",
      "Gradient for encoder.log_var.bias: 0.0011068976018577814\n",
      "Gradient for decoder.decoder.0.weight: 0.010011271573603153\n",
      "Gradient for decoder.decoder.0.bias: 9.009881035693112e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.00048701424384489655\n",
      "Gradient for decoder.decoder.1.bias: 0.00043940896284766495\n",
      "Gradient for decoder.decoder.3.weight: 0.009627657011151314\n",
      "Gradient for decoder.decoder.3.bias: 8.368108289635856e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00044748466461896896\n",
      "Gradient for decoder.decoder.4.bias: 0.0004881876229774207\n",
      "Gradient for decoder.decoder.6.weight: 0.00044264007010497153\n",
      "Gradient for decoder.decoder.6.bias: 2.7881340429303236e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.004262064583599567\n",
      "Gradient for encoder.encoder.0.bias: 8.272185020308243e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.00042103027226403356\n",
      "Gradient for encoder.encoder.1.bias: 0.0006648536073043942\n",
      "Gradient for encoder.encoder.3.weight: 0.009001722559332848\n",
      "Gradient for encoder.encoder.3.bias: 1.099680277394377e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0028016252908855677\n",
      "Gradient for encoder.encoder.4.bias: 0.0025398400612175465\n",
      "Gradient for encoder.mean.weight: 0.0401381216943264\n",
      "Gradient for encoder.mean.bias: 0.002145827515050769\n",
      "Gradient for encoder.log_var.weight: 0.023900602012872696\n",
      "Gradient for encoder.log_var.bias: 0.0014619854046031833\n",
      "Gradient for decoder.decoder.0.weight: 0.011633488349616528\n",
      "Gradient for decoder.decoder.0.bias: 8.952288216290682e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.000568950257729739\n",
      "Gradient for decoder.decoder.1.bias: 0.0004922080552205443\n",
      "Gradient for decoder.decoder.3.weight: 0.010952935554087162\n",
      "Gradient for decoder.decoder.3.bias: 8.039816035143588e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00040655743214301765\n",
      "Gradient for decoder.decoder.4.bias: 0.00042115437099710107\n",
      "Gradient for decoder.decoder.6.weight: 0.0004567583673633635\n",
      "Gradient for decoder.decoder.6.bias: 2.4775144993327558e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.004154965281486511\n",
      "Gradient for encoder.encoder.0.bias: 7.127735467821195e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.00036906590685248375\n",
      "Gradient for encoder.encoder.1.bias: 0.0003744589339476079\n",
      "Gradient for encoder.encoder.3.weight: 0.007429144345223904\n",
      "Gradient for encoder.encoder.3.bias: 1.0112827936170632e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0026049776934087276\n",
      "Gradient for encoder.encoder.4.bias: 0.0020190218929201365\n",
      "Gradient for encoder.mean.weight: 0.03891458362340927\n",
      "Gradient for encoder.mean.bias: 0.0016441065818071365\n",
      "Gradient for encoder.log_var.weight: 0.022074051201343536\n",
      "Gradient for encoder.log_var.bias: 0.000937288103159517\n",
      "Gradient for decoder.decoder.0.weight: 0.01352271530777216\n",
      "Gradient for decoder.decoder.0.bias: 1.1880404993114269e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0006367269670590758\n",
      "Gradient for decoder.decoder.1.bias: 0.0005603435565717518\n",
      "Gradient for decoder.decoder.3.weight: 0.012402692809700966\n",
      "Gradient for decoder.decoder.3.bias: 9.561171299132809e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00047950155567377806\n",
      "Gradient for decoder.decoder.4.bias: 0.00043398491106927395\n",
      "Gradient for decoder.decoder.6.weight: 0.0004730330838356167\n",
      "Gradient for decoder.decoder.6.bias: 2.5683366402518004e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.004232437815517187\n",
      "Gradient for encoder.encoder.0.bias: 7.162538791238848e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.0003381296119187027\n",
      "Gradient for encoder.encoder.1.bias: 0.00035278304130770266\n",
      "Gradient for encoder.encoder.3.weight: 0.007190226577222347\n",
      "Gradient for encoder.encoder.3.bias: 9.529262795515692e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.0027839175891131163\n",
      "Gradient for encoder.encoder.4.bias: 0.002051795134320855\n",
      "Gradient for encoder.mean.weight: 0.04065919667482376\n",
      "Gradient for encoder.mean.bias: 0.001618515932932496\n",
      "Gradient for encoder.log_var.weight: 0.022769901901483536\n",
      "Gradient for encoder.log_var.bias: 0.0009241989464499056\n",
      "Gradient for decoder.decoder.0.weight: 0.013054057024419308\n",
      "Gradient for decoder.decoder.0.bias: 9.956286489698485e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0006669647991657257\n",
      "Gradient for decoder.decoder.1.bias: 0.0005699327448382974\n",
      "Gradient for decoder.decoder.3.weight: 0.012849659658968449\n",
      "Gradient for decoder.decoder.3.bias: 8.851869237602727e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0004993514157831669\n",
      "Gradient for decoder.decoder.4.bias: 0.00046205634134821594\n",
      "Gradient for decoder.decoder.6.weight: 0.0005277350428514183\n",
      "Gradient for decoder.decoder.6.bias: 3.0235283702495508e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.0038090215530246496\n",
      "Gradient for encoder.encoder.0.bias: 8.793459016498417e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.00028781118453480303\n",
      "Gradient for encoder.encoder.1.bias: 0.00045172913814894855\n",
      "Gradient for encoder.encoder.3.weight: 0.006677581928670406\n",
      "Gradient for encoder.encoder.3.bias: 1.0751579487822127e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0033423686400055885\n",
      "Gradient for encoder.encoder.4.bias: 0.002511866856366396\n",
      "Gradient for encoder.mean.weight: 0.05052802339196205\n",
      "Gradient for encoder.mean.bias: 0.0020468763541430235\n",
      "Gradient for encoder.log_var.weight: 0.023698626086115837\n",
      "Gradient for encoder.log_var.bias: 0.0011772793950513005\n",
      "Gradient for decoder.decoder.0.weight: 0.011070242151618004\n",
      "Gradient for decoder.decoder.0.bias: 8.855146477193543e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005239099264144897\n",
      "Gradient for decoder.decoder.1.bias: 0.00047510990407317877\n",
      "Gradient for decoder.decoder.3.weight: 0.010471520945429802\n",
      "Gradient for decoder.decoder.3.bias: 8.849987409575988e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.000516196305397898\n",
      "Gradient for decoder.decoder.4.bias: 0.0005731206038035452\n",
      "Gradient for decoder.decoder.6.weight: 0.0004716250696219504\n",
      "Gradient for decoder.decoder.6.bias: 3.163226574542932e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.0034386306069791317\n",
      "Gradient for encoder.encoder.0.bias: 6.518524001825066e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.00030829658498987556\n",
      "Gradient for encoder.encoder.1.bias: 0.00039178162114694715\n",
      "Gradient for encoder.encoder.3.weight: 0.006886251270771027\n",
      "Gradient for encoder.encoder.3.bias: 1.0649987142175021e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0031455382704734802\n",
      "Gradient for encoder.encoder.4.bias: 0.0022791477385908365\n",
      "Gradient for encoder.mean.weight: 0.0463482104241848\n",
      "Gradient for encoder.mean.bias: 0.0017535333754494786\n",
      "Gradient for encoder.log_var.weight: 0.023929757997393608\n",
      "Gradient for encoder.log_var.bias: 0.0009653595625422895\n",
      "Gradient for decoder.decoder.0.weight: 0.013447282835841179\n",
      "Gradient for decoder.decoder.0.bias: 1.0589518845138812e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0006906128255650401\n",
      "Gradient for decoder.decoder.1.bias: 0.0005521905841305852\n",
      "Gradient for decoder.decoder.3.weight: 0.012745298445224762\n",
      "Gradient for decoder.decoder.3.bias: 8.868433071240744e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0004844576760660857\n",
      "Gradient for decoder.decoder.4.bias: 0.00040025939233601093\n",
      "Gradient for decoder.decoder.6.weight: 0.00046153267612680793\n",
      "Gradient for decoder.decoder.6.bias: 1.9306467947899364e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.0035352285485714674\n",
      "Gradient for encoder.encoder.0.bias: 6.749183677212667e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.000302464934065938\n",
      "Gradient for encoder.encoder.1.bias: 0.00042436880175955594\n",
      "Gradient for encoder.encoder.3.weight: 0.006847937125712633\n",
      "Gradient for encoder.encoder.3.bias: 8.666039413851578e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.0030052715446799994\n",
      "Gradient for encoder.encoder.4.bias: 0.0018699361244216561\n",
      "Gradient for encoder.mean.weight: 0.046019040048122406\n",
      "Gradient for encoder.mean.bias: 0.0013921157224103808\n",
      "Gradient for encoder.log_var.weight: 0.02545817755162716\n",
      "Gradient for encoder.log_var.bias: 0.0009179270709864795\n",
      "Gradient for decoder.decoder.0.weight: 0.012445616535842419\n",
      "Gradient for decoder.decoder.0.bias: 1.031783686267218e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.000596849771682173\n",
      "Gradient for decoder.decoder.1.bias: 0.0004935375181958079\n",
      "Gradient for decoder.decoder.3.weight: 0.011647895909845829\n",
      "Gradient for decoder.decoder.3.bias: 8.357660397084743e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00046914632548578084\n",
      "Gradient for decoder.decoder.4.bias: 0.00044924861867912114\n",
      "Gradient for decoder.decoder.6.weight: 0.000457674526842311\n",
      "Gradient for decoder.decoder.6.bias: 2.531636164349038e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.006863913964480162\n",
      "Gradient for encoder.encoder.0.bias: 1.4166768452783529e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.00037452467950060964\n",
      "Gradient for encoder.encoder.1.bias: 0.0006248538848012686\n",
      "Gradient for encoder.encoder.3.weight: 0.008200435899198055\n",
      "Gradient for encoder.encoder.3.bias: 1.4557119398794782e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0029315545689314604\n",
      "Gradient for encoder.encoder.4.bias: 0.0031037284061312675\n",
      "Gradient for encoder.mean.weight: 0.04397246986627579\n",
      "Gradient for encoder.mean.bias: 0.002370369853451848\n",
      "Gradient for encoder.log_var.weight: 0.022890012711286545\n",
      "Gradient for encoder.log_var.bias: 0.0014441891107708216\n",
      "Gradient for decoder.decoder.0.weight: 0.008512548170983791\n",
      "Gradient for decoder.decoder.0.bias: 7.592119294352884e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0004374765558168292\n",
      "Gradient for decoder.decoder.1.bias: 0.00035247800406068563\n",
      "Gradient for decoder.decoder.3.weight: 0.008145085535943508\n",
      "Gradient for decoder.decoder.3.bias: 7.416088576572832e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0004965291591361165\n",
      "Gradient for decoder.decoder.4.bias: 0.0005967296892777085\n",
      "Gradient for decoder.decoder.6.weight: 0.0005026881117373705\n",
      "Gradient for decoder.decoder.6.bias: 3.999985710834153e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.004074335563927889\n",
      "Gradient for encoder.encoder.0.bias: 1.0135558191348704e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0003093457780778408\n",
      "Gradient for encoder.encoder.1.bias: 0.0004973539034835994\n",
      "Gradient for encoder.encoder.3.weight: 0.0068033551797270775\n",
      "Gradient for encoder.encoder.3.bias: 9.63821175647972e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.0026122487615793943\n",
      "Gradient for encoder.encoder.4.bias: 0.0016907593235373497\n",
      "Gradient for encoder.mean.weight: 0.043480176478624344\n",
      "Gradient for encoder.mean.bias: 0.0014401315711438656\n",
      "Gradient for encoder.log_var.weight: 0.022074690088629723\n",
      "Gradient for encoder.log_var.bias: 0.0009549648384563625\n",
      "Gradient for decoder.decoder.0.weight: 0.009831544011831284\n",
      "Gradient for decoder.decoder.0.bias: 8.592222766612423e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005179076106287539\n",
      "Gradient for decoder.decoder.1.bias: 0.00042351821321062744\n",
      "Gradient for decoder.decoder.3.weight: 0.009540821425616741\n",
      "Gradient for decoder.decoder.3.bias: 8.943520229953705e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0005223667831160128\n",
      "Gradient for decoder.decoder.4.bias: 0.000615556666161865\n",
      "Gradient for decoder.decoder.6.weight: 0.0004634624347090721\n",
      "Gradient for decoder.decoder.6.bias: 3.5516557545633987e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.0034906165674328804\n",
      "Gradient for encoder.encoder.0.bias: 6.924209036002216e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.00038596102967858315\n",
      "Gradient for encoder.encoder.1.bias: 0.00046913119149394333\n",
      "Gradient for encoder.encoder.3.weight: 0.008140294812619686\n",
      "Gradient for encoder.encoder.3.bias: 9.018483876355177e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.0027456413954496384\n",
      "Gradient for encoder.encoder.4.bias: 0.0019764809403568506\n",
      "Gradient for encoder.mean.weight: 0.045236747711896896\n",
      "Gradient for encoder.mean.bias: 0.0015662494115531445\n",
      "Gradient for encoder.log_var.weight: 0.02247721701860428\n",
      "Gradient for encoder.log_var.bias: 0.0009739089291542768\n",
      "Gradient for decoder.decoder.0.weight: 0.013311580754816532\n",
      "Gradient for decoder.decoder.0.bias: 1.019027293103214e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0006566329393535852\n",
      "Gradient for decoder.decoder.1.bias: 0.0005192140815779567\n",
      "Gradient for decoder.decoder.3.weight: 0.012419314123690128\n",
      "Gradient for decoder.decoder.3.bias: 9.685039575879628e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0005685583455488086\n",
      "Gradient for decoder.decoder.4.bias: 0.0006121810874901712\n",
      "Gradient for decoder.decoder.6.weight: 0.0005754789453931153\n",
      "Gradient for decoder.decoder.6.bias: 4.164912388660014e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.004095273558050394\n",
      "Gradient for encoder.encoder.0.bias: 8.110016998241765e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.0003343140706419945\n",
      "Gradient for encoder.encoder.1.bias: 0.0003404485760256648\n",
      "Gradient for encoder.encoder.3.weight: 0.007029135245829821\n",
      "Gradient for encoder.encoder.3.bias: 1.0033603808912162e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.002560113789513707\n",
      "Gradient for encoder.encoder.4.bias: 0.0018506941851228476\n",
      "Gradient for encoder.mean.weight: 0.03994495049118996\n",
      "Gradient for encoder.mean.bias: 0.0016043747309595346\n",
      "Gradient for encoder.log_var.weight: 0.021028365939855576\n",
      "Gradient for encoder.log_var.bias: 0.0009633391164243221\n",
      "Gradient for decoder.decoder.0.weight: 0.011239290237426758\n",
      "Gradient for decoder.decoder.0.bias: 9.473394985137773e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005431271274574101\n",
      "Gradient for decoder.decoder.1.bias: 0.00045518201659433544\n",
      "Gradient for decoder.decoder.3.weight: 0.01083005964756012\n",
      "Gradient for decoder.decoder.3.bias: 9.243795312530168e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0004017571045551449\n",
      "Gradient for decoder.decoder.4.bias: 0.00034792235237546265\n",
      "Gradient for decoder.decoder.6.weight: 0.0004711691290140152\n",
      "Gradient for decoder.decoder.6.bias: 2.36593623412773e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.006595333106815815\n",
      "Gradient for encoder.encoder.0.bias: 1.4211941519459703e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.00044470836292020977\n",
      "Gradient for encoder.encoder.1.bias: 0.0005520203849300742\n",
      "Gradient for encoder.encoder.3.weight: 0.010029726661741734\n",
      "Gradient for encoder.encoder.3.bias: 1.1560123691634061e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0032597053796052933\n",
      "Gradient for encoder.encoder.4.bias: 0.0023085104767233133\n",
      "Gradient for encoder.mean.weight: 0.04546597972512245\n",
      "Gradient for encoder.mean.bias: 0.001700830296613276\n",
      "Gradient for encoder.log_var.weight: 0.02355032041668892\n",
      "Gradient for encoder.log_var.bias: 0.0010234108194708824\n",
      "Gradient for decoder.decoder.0.weight: 0.00849447213113308\n",
      "Gradient for decoder.decoder.0.bias: 6.737192054240282e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0004226216406095773\n",
      "Gradient for decoder.decoder.1.bias: 0.00034325532033108175\n",
      "Gradient for decoder.decoder.3.weight: 0.008493971079587936\n",
      "Gradient for decoder.decoder.3.bias: 8.809506596429983e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0005944574368186295\n",
      "Gradient for decoder.decoder.4.bias: 0.0007259699050337076\n",
      "Gradient for decoder.decoder.6.weight: 0.0005133227678015828\n",
      "Gradient for decoder.decoder.6.bias: 4.1983705159509555e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training VAE Epoch:  22%|██▏       | 17/79 [00:00<00:01, 52.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient for encoder.encoder.0.weight: 0.005788994021713734\n",
      "Gradient for encoder.encoder.0.bias: 1.3975109264263708e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.00034732450149022043\n",
      "Gradient for encoder.encoder.1.bias: 0.0005812426679767668\n",
      "Gradient for encoder.encoder.3.weight: 0.007866566069424152\n",
      "Gradient for encoder.encoder.3.bias: 1.0885768675361618e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0032195704989135265\n",
      "Gradient for encoder.encoder.4.bias: 0.0019636088982224464\n",
      "Gradient for encoder.mean.weight: 0.04462515935301781\n",
      "Gradient for encoder.mean.bias: 0.0015869314083829522\n",
      "Gradient for encoder.log_var.weight: 0.023429516702890396\n",
      "Gradient for encoder.log_var.bias: 0.0007511039730161428\n",
      "Gradient for decoder.decoder.0.weight: 0.008527528494596481\n",
      "Gradient for decoder.decoder.0.bias: 7.301854954011588e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.00045834542834199965\n",
      "Gradient for decoder.decoder.1.bias: 0.00035328915691934526\n",
      "Gradient for decoder.decoder.3.weight: 0.008000025525689125\n",
      "Gradient for decoder.decoder.3.bias: 1.0639753661445539e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0007756012491881847\n",
      "Gradient for decoder.decoder.4.bias: 0.0009759219246916473\n",
      "Gradient for decoder.decoder.6.weight: 0.0006051603122614324\n",
      "Gradient for decoder.decoder.6.bias: 5.5771357438061386e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.004007336683571339\n",
      "Gradient for encoder.encoder.0.bias: 9.178595383740884e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.00030991851235739887\n",
      "Gradient for encoder.encoder.1.bias: 0.0004988778382539749\n",
      "Gradient for encoder.encoder.3.weight: 0.006908888928592205\n",
      "Gradient for encoder.encoder.3.bias: 1.0489235868771374e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0033159011509269476\n",
      "Gradient for encoder.encoder.4.bias: 0.0023689696099609137\n",
      "Gradient for encoder.mean.weight: 0.04605906829237938\n",
      "Gradient for encoder.mean.bias: 0.0019583366811275482\n",
      "Gradient for encoder.log_var.weight: 0.02861207351088524\n",
      "Gradient for encoder.log_var.bias: 0.0011133634252473712\n",
      "Gradient for decoder.decoder.0.weight: 0.009367190301418304\n",
      "Gradient for decoder.decoder.0.bias: 7.577046629014816e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.00045431737089529634\n",
      "Gradient for decoder.decoder.1.bias: 0.00039312339504249394\n",
      "Gradient for decoder.decoder.3.weight: 0.008795029483735561\n",
      "Gradient for decoder.decoder.3.bias: 8.634088582981647e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0005720661720260978\n",
      "Gradient for decoder.decoder.4.bias: 0.0007015446317382157\n",
      "Gradient for decoder.decoder.6.weight: 0.0005059976829215884\n",
      "Gradient for decoder.decoder.6.bias: 4.106271080672741e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training VAE Epoch:  32%|███▏      | 25/79 [00:00<00:00, 61.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient for encoder.encoder.0.weight: 0.003475598990917206\n",
      "Gradient for encoder.encoder.0.bias: 7.736243937128684e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.00026565627194941044\n",
      "Gradient for encoder.encoder.1.bias: 0.00045356785994954407\n",
      "Gradient for encoder.encoder.3.weight: 0.005977342836558819\n",
      "Gradient for encoder.encoder.3.bias: 1.0737438715935355e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.002678114455193281\n",
      "Gradient for encoder.encoder.4.bias: 0.0026614288799464703\n",
      "Gradient for encoder.mean.weight: 0.04405508190393448\n",
      "Gradient for encoder.mean.bias: 0.002184094162657857\n",
      "Gradient for encoder.log_var.weight: 0.022705089300870895\n",
      "Gradient for encoder.log_var.bias: 0.0012279063230380416\n",
      "Gradient for decoder.decoder.0.weight: 0.01060109306126833\n",
      "Gradient for decoder.decoder.0.bias: 8.32977228859555e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005178484716452658\n",
      "Gradient for decoder.decoder.1.bias: 0.0004387276421766728\n",
      "Gradient for decoder.decoder.3.weight: 0.010053981095552444\n",
      "Gradient for decoder.decoder.3.bias: 8.958758040966686e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0005577320116572082\n",
      "Gradient for decoder.decoder.4.bias: 0.0006738660740666091\n",
      "Gradient for decoder.decoder.6.weight: 0.0004818972374778241\n",
      "Gradient for decoder.decoder.6.bias: 3.4738124668365344e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.006297425366938114\n",
      "Gradient for encoder.encoder.0.bias: 1.3825314157389634e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.00044986934517510235\n",
      "Gradient for encoder.encoder.1.bias: 0.0004827952943742275\n",
      "Gradient for encoder.encoder.3.weight: 0.00949707068502903\n",
      "Gradient for encoder.encoder.3.bias: 1.272751903869107e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0030900875572115183\n",
      "Gradient for encoder.encoder.4.bias: 0.002868706826120615\n",
      "Gradient for encoder.mean.weight: 0.04523776099085808\n",
      "Gradient for encoder.mean.bias: 0.0024191243574023247\n",
      "Gradient for encoder.log_var.weight: 0.025912463665008545\n",
      "Gradient for encoder.log_var.bias: 0.0013980979565531015\n",
      "Gradient for decoder.decoder.0.weight: 0.007846246473491192\n",
      "Gradient for decoder.decoder.0.bias: 6.78087655470172e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.00041198523831553757\n",
      "Gradient for decoder.decoder.1.bias: 0.0003436921106185764\n",
      "Gradient for decoder.decoder.3.weight: 0.007404362317174673\n",
      "Gradient for decoder.decoder.3.bias: 7.547841518462661e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0005031221080571413\n",
      "Gradient for decoder.decoder.4.bias: 0.0006325225112959743\n",
      "Gradient for decoder.decoder.6.weight: 0.00044596492080017924\n",
      "Gradient for decoder.decoder.6.bias: 3.238278077333234e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.004157773684710264\n",
      "Gradient for encoder.encoder.0.bias: 7.852648219175418e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.0002762074873317033\n",
      "Gradient for encoder.encoder.1.bias: 0.00036424785503186285\n",
      "Gradient for encoder.encoder.3.weight: 0.005772273987531662\n",
      "Gradient for encoder.encoder.3.bias: 9.07924291304596e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.002664589323103428\n",
      "Gradient for encoder.encoder.4.bias: 0.0020341668277978897\n",
      "Gradient for encoder.mean.weight: 0.037002481520175934\n",
      "Gradient for encoder.mean.bias: 0.001569105195812881\n",
      "Gradient for encoder.log_var.weight: 0.023512069135904312\n",
      "Gradient for encoder.log_var.bias: 0.0009398153051733971\n",
      "Gradient for decoder.decoder.0.weight: 0.010328620672225952\n",
      "Gradient for decoder.decoder.0.bias: 8.399165390970964e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005211937823332846\n",
      "Gradient for decoder.decoder.1.bias: 0.00041326909558847547\n",
      "Gradient for decoder.decoder.3.weight: 0.009541146457195282\n",
      "Gradient for decoder.decoder.3.bias: 8.496400805135806e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00048171731759794056\n",
      "Gradient for decoder.decoder.4.bias: 0.0005415010382421315\n",
      "Gradient for decoder.decoder.6.weight: 0.0004644446598831564\n",
      "Gradient for decoder.decoder.6.bias: 2.9574555810540915e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.0034811797086149454\n",
      "Gradient for encoder.encoder.0.bias: 5.936426263758454e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.0002963765000458807\n",
      "Gradient for encoder.encoder.1.bias: 0.0003050641098525375\n",
      "Gradient for encoder.encoder.3.weight: 0.006591340992599726\n",
      "Gradient for encoder.encoder.3.bias: 9.247479171303752e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.0028427974320948124\n",
      "Gradient for encoder.encoder.4.bias: 0.0018541603349149227\n",
      "Gradient for encoder.mean.weight: 0.04183651879429817\n",
      "Gradient for encoder.mean.bias: 0.0014463140396401286\n",
      "Gradient for encoder.log_var.weight: 0.022799717262387276\n",
      "Gradient for encoder.log_var.bias: 0.0008425448904745281\n",
      "Gradient for decoder.decoder.0.weight: 0.014861484058201313\n",
      "Gradient for decoder.decoder.0.bias: 1.2476093769198116e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0007620399119332433\n",
      "Gradient for decoder.decoder.1.bias: 0.0005694082356058061\n",
      "Gradient for decoder.decoder.3.weight: 0.014329224824905396\n",
      "Gradient for decoder.decoder.3.bias: 1.1708739533489165e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0008138546254485846\n",
      "Gradient for decoder.decoder.4.bias: 0.0009021756122820079\n",
      "Gradient for decoder.decoder.6.weight: 0.0006839560810476542\n",
      "Gradient for decoder.decoder.6.bias: 5.2792925998801365e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.004874257370829582\n",
      "Gradient for encoder.encoder.0.bias: 1.0725994745164336e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0002844332775566727\n",
      "Gradient for encoder.encoder.1.bias: 0.0003779383550863713\n",
      "Gradient for encoder.encoder.3.weight: 0.0061942096799612045\n",
      "Gradient for encoder.encoder.3.bias: 9.787236993075155e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.002935674972832203\n",
      "Gradient for encoder.encoder.4.bias: 0.001733783632516861\n",
      "Gradient for encoder.mean.weight: 0.04101710394024849\n",
      "Gradient for encoder.mean.bias: 0.001395763480104506\n",
      "Gradient for encoder.log_var.weight: 0.019808948040008545\n",
      "Gradient for encoder.log_var.bias: 0.0008120445418171585\n",
      "Gradient for decoder.decoder.0.weight: 0.009286460466682911\n",
      "Gradient for decoder.decoder.0.bias: 8.088952424545326e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.00044362872722558677\n",
      "Gradient for decoder.decoder.1.bias: 0.0003868587373290211\n",
      "Gradient for decoder.decoder.3.weight: 0.008388260379433632\n",
      "Gradient for decoder.decoder.3.bias: 9.475436407724303e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0006442914018407464\n",
      "Gradient for decoder.decoder.4.bias: 0.0007940944633446634\n",
      "Gradient for decoder.decoder.6.weight: 0.0005165949696674943\n",
      "Gradient for decoder.decoder.6.bias: 4.343432010500692e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.0032887051347643137\n",
      "Gradient for encoder.encoder.0.bias: 6.805133713483347e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.0002516130043659359\n",
      "Gradient for encoder.encoder.1.bias: 0.00038269133074209094\n",
      "Gradient for encoder.encoder.3.weight: 0.005399175453931093\n",
      "Gradient for encoder.encoder.3.bias: 8.743546858758222e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.0025382807943969965\n",
      "Gradient for encoder.encoder.4.bias: 0.0017588033806532621\n",
      "Gradient for encoder.mean.weight: 0.038089852780103683\n",
      "Gradient for encoder.mean.bias: 0.001418692758306861\n",
      "Gradient for encoder.log_var.weight: 0.021211382001638412\n",
      "Gradient for encoder.log_var.bias: 0.0008903303532861173\n",
      "Gradient for decoder.decoder.0.weight: 0.011029630899429321\n",
      "Gradient for decoder.decoder.0.bias: 9.495518954460991e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.00058392045320943\n",
      "Gradient for decoder.decoder.1.bias: 0.00046150333946570754\n",
      "Gradient for decoder.decoder.3.weight: 0.011000080034136772\n",
      "Gradient for decoder.decoder.3.bias: 9.286175994827062e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00038927490822970867\n",
      "Gradient for decoder.decoder.4.bias: 0.00032761026523076\n",
      "Gradient for decoder.decoder.6.weight: 0.00047084360267035663\n",
      "Gradient for decoder.decoder.6.bias: 2.711285742407199e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.004672129638493061\n",
      "Gradient for encoder.encoder.0.bias: 9.659231747782826e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.0003146287053823471\n",
      "Gradient for encoder.encoder.1.bias: 0.000412717810831964\n",
      "Gradient for encoder.encoder.3.weight: 0.006898914463818073\n",
      "Gradient for encoder.encoder.3.bias: 9.686705604305956e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.0022593364119529724\n",
      "Gradient for encoder.encoder.4.bias: 0.0014939630636945367\n",
      "Gradient for encoder.mean.weight: 0.03678004443645477\n",
      "Gradient for encoder.mean.bias: 0.0013414984568953514\n",
      "Gradient for encoder.log_var.weight: 0.018749015405774117\n",
      "Gradient for encoder.log_var.bias: 0.0007539602811448276\n",
      "Gradient for decoder.decoder.0.weight: 0.010574079118669033\n",
      "Gradient for decoder.decoder.0.bias: 8.108384103033828e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0004763681790791452\n",
      "Gradient for decoder.decoder.1.bias: 0.0004022076609544456\n",
      "Gradient for decoder.decoder.3.weight: 0.009922710247337818\n",
      "Gradient for decoder.decoder.3.bias: 7.165770754546941e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00033017105306498706\n",
      "Gradient for decoder.decoder.4.bias: 0.0002914166543632746\n",
      "Gradient for decoder.decoder.6.weight: 0.00045867584412917495\n",
      "Gradient for decoder.decoder.6.bias: 2.6808471375261433e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.0029781616758555174\n",
      "Gradient for encoder.encoder.0.bias: 5.357006938738751e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.0002256545121781528\n",
      "Gradient for encoder.encoder.1.bias: 0.0003753732016775757\n",
      "Gradient for encoder.encoder.3.weight: 0.004997754469513893\n",
      "Gradient for encoder.encoder.3.bias: 8.300674730898905e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.0028462286572903395\n",
      "Gradient for encoder.encoder.4.bias: 0.0016852437984198332\n",
      "Gradient for encoder.mean.weight: 0.04431706294417381\n",
      "Gradient for encoder.mean.bias: 0.001409789314493537\n",
      "Gradient for encoder.log_var.weight: 0.023814300075173378\n",
      "Gradient for encoder.log_var.bias: 0.0008172890520654619\n",
      "Gradient for decoder.decoder.0.weight: 0.014094647951424122\n",
      "Gradient for decoder.decoder.0.bias: 1.151052170245137e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0007353216060437262\n",
      "Gradient for decoder.decoder.1.bias: 0.0005920228431932628\n",
      "Gradient for decoder.decoder.3.weight: 0.013641821220517159\n",
      "Gradient for decoder.decoder.3.bias: 1.0192513499873712e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0005264620995149016\n",
      "Gradient for decoder.decoder.4.bias: 0.0004900847561657429\n",
      "Gradient for decoder.decoder.6.weight: 0.00046514609130099416\n",
      "Gradient for decoder.decoder.6.bias: 2.069731090159621e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.00478967884555459\n",
      "Gradient for encoder.encoder.0.bias: 1.0909355883936822e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.00033085502218455076\n",
      "Gradient for encoder.encoder.1.bias: 0.000485865370137617\n",
      "Gradient for encoder.encoder.3.weight: 0.007177740801125765\n",
      "Gradient for encoder.encoder.3.bias: 1.1007246503158541e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0024962082970887423\n",
      "Gradient for encoder.encoder.4.bias: 0.002787096193060279\n",
      "Gradient for encoder.mean.weight: 0.03786590322852135\n",
      "Gradient for encoder.mean.bias: 0.002246089046820998\n",
      "Gradient for encoder.log_var.weight: 0.022316928952932358\n",
      "Gradient for encoder.log_var.bias: 0.001407421543262899\n",
      "Gradient for decoder.decoder.0.weight: 0.008945821784436703\n",
      "Gradient for decoder.decoder.0.bias: 6.535648411354344e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0004405564395710826\n",
      "Gradient for decoder.decoder.1.bias: 0.00035545078571885824\n",
      "Gradient for decoder.decoder.3.weight: 0.008643267676234245\n",
      "Gradient for decoder.decoder.3.bias: 6.075925873538779e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.000332556024659425\n",
      "Gradient for decoder.decoder.4.bias: 0.0003109026001766324\n",
      "Gradient for decoder.decoder.6.weight: 0.0004216236702632159\n",
      "Gradient for decoder.decoder.6.bias: 2.518136716389563e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.003187529044225812\n",
      "Gradient for encoder.encoder.0.bias: 6.535803582369271e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.0003246692649554461\n",
      "Gradient for encoder.encoder.1.bias: 0.0003716221544891596\n",
      "Gradient for encoder.encoder.3.weight: 0.00680282898247242\n",
      "Gradient for encoder.encoder.3.bias: 8.549582569683523e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.0028766237664967775\n",
      "Gradient for encoder.encoder.4.bias: 0.0015532819088548422\n",
      "Gradient for encoder.mean.weight: 0.039580877870321274\n",
      "Gradient for encoder.mean.bias: 0.001333690481260419\n",
      "Gradient for encoder.log_var.weight: 0.021639719605445862\n",
      "Gradient for encoder.log_var.bias: 0.0008224733755923808\n",
      "Gradient for decoder.decoder.0.weight: 0.012732204049825668\n",
      "Gradient for decoder.decoder.0.bias: 1.0637230679622078e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0007107119308784604\n",
      "Gradient for decoder.decoder.1.bias: 0.0005382970557548106\n",
      "Gradient for decoder.decoder.3.weight: 0.013096476905047894\n",
      "Gradient for decoder.decoder.3.bias: 1.0286529267267142e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.000639000500086695\n",
      "Gradient for decoder.decoder.4.bias: 0.0006401481805369258\n",
      "Gradient for decoder.decoder.6.weight: 0.000587862974498421\n",
      "Gradient for decoder.decoder.6.bias: 3.947710865759291e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.004936973564326763\n",
      "Gradient for encoder.encoder.0.bias: 9.512954660118034e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.00030631860136054456\n",
      "Gradient for encoder.encoder.1.bias: 0.00035795156145468354\n",
      "Gradient for encoder.encoder.3.weight: 0.006564952898770571\n",
      "Gradient for encoder.encoder.3.bias: 1.0062083111161968e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0027057076804339886\n",
      "Gradient for encoder.encoder.4.bias: 0.001707415678538382\n",
      "Gradient for encoder.mean.weight: 0.037866588681936264\n",
      "Gradient for encoder.mean.bias: 0.0012870050268247724\n",
      "Gradient for encoder.log_var.weight: 0.020017003640532494\n",
      "Gradient for encoder.log_var.bias: 0.0008434703922830522\n",
      "Gradient for decoder.decoder.0.weight: 0.008851781487464905\n",
      "Gradient for decoder.decoder.0.bias: 7.426328996196219e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.000458871218143031\n",
      "Gradient for decoder.decoder.1.bias: 0.0004030436684843153\n",
      "Gradient for decoder.decoder.3.weight: 0.008844169788062572\n",
      "Gradient for decoder.decoder.3.bias: 6.377021133374683e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0003755794605240226\n",
      "Gradient for decoder.decoder.4.bias: 0.0003638124035205692\n",
      "Gradient for decoder.decoder.6.weight: 0.00041278538992628455\n",
      "Gradient for decoder.decoder.6.bias: 2.0313013010309078e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.00316185737028718\n",
      "Gradient for encoder.encoder.0.bias: 5.902647294553365e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.00024969212245196104\n",
      "Gradient for encoder.encoder.1.bias: 0.0003274620685260743\n",
      "Gradient for encoder.encoder.3.weight: 0.005665889475494623\n",
      "Gradient for encoder.encoder.3.bias: 8.517814925612655e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.0024176391307264566\n",
      "Gradient for encoder.encoder.4.bias: 0.0014922288246452808\n",
      "Gradient for encoder.mean.weight: 0.03759157657623291\n",
      "Gradient for encoder.mean.bias: 0.0012216779869049788\n",
      "Gradient for encoder.log_var.weight: 0.01909377984702587\n",
      "Gradient for encoder.log_var.bias: 0.0007352661923505366\n",
      "Gradient for decoder.decoder.0.weight: 0.012311466038227081\n",
      "Gradient for decoder.decoder.0.bias: 1.0383947174341657e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0005912508349865675\n",
      "Gradient for decoder.decoder.1.bias: 0.0004785171477124095\n",
      "Gradient for decoder.decoder.3.weight: 0.011450676247477531\n",
      "Gradient for decoder.decoder.3.bias: 9.508719506223784e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0005394360632635653\n",
      "Gradient for decoder.decoder.4.bias: 0.0005291217239573598\n",
      "Gradient for decoder.decoder.6.weight: 0.0005351798026822507\n",
      "Gradient for decoder.decoder.6.bias: 3.335206565679982e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.003475021803751588\n",
      "Gradient for encoder.encoder.0.bias: 7.24145266320364e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.0002519377740100026\n",
      "Gradient for encoder.encoder.1.bias: 0.000365586020052433\n",
      "Gradient for encoder.encoder.3.weight: 0.005490624345839024\n",
      "Gradient for encoder.encoder.3.bias: 8.810913110224305e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.0022770122159272432\n",
      "Gradient for encoder.encoder.4.bias: 0.0014014446642249823\n",
      "Gradient for encoder.mean.weight: 0.036115046590566635\n",
      "Gradient for encoder.mean.bias: 0.0010958650382235646\n",
      "Gradient for encoder.log_var.weight: 0.02066885307431221\n",
      "Gradient for encoder.log_var.bias: 0.0008297105669043958\n",
      "Gradient for decoder.decoder.0.weight: 0.011707103811204433\n",
      "Gradient for decoder.decoder.0.bias: 1.0247044185396348e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0005465474096126854\n",
      "Gradient for decoder.decoder.1.bias: 0.0004789081576745957\n",
      "Gradient for decoder.decoder.3.weight: 0.010588133707642555\n",
      "Gradient for decoder.decoder.3.bias: 8.902835413326926e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0004779379232786596\n",
      "Gradient for decoder.decoder.4.bias: 0.0005149440839886665\n",
      "Gradient for decoder.decoder.6.weight: 0.0004752173845190555\n",
      "Gradient for decoder.decoder.6.bias: 3.119461689493619e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training VAE Epoch:  41%|████      | 32/79 [00:00<00:00, 63.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient for encoder.encoder.0.weight: 0.0038572922348976135\n",
      "Gradient for encoder.encoder.0.bias: 7.53559974836504e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.0002434091584291309\n",
      "Gradient for encoder.encoder.1.bias: 0.0003593701112549752\n",
      "Gradient for encoder.encoder.3.weight: 0.0054678102023899555\n",
      "Gradient for encoder.encoder.3.bias: 8.362762565772286e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.002021795604377985\n",
      "Gradient for encoder.encoder.4.bias: 0.0015704288380220532\n",
      "Gradient for encoder.mean.weight: 0.03402889519929886\n",
      "Gradient for encoder.mean.bias: 0.001298076007515192\n",
      "Gradient for encoder.log_var.weight: 0.019136937335133553\n",
      "Gradient for encoder.log_var.bias: 0.0008995421812869608\n",
      "Gradient for decoder.decoder.0.weight: 0.010620363056659698\n",
      "Gradient for decoder.decoder.0.bias: 9.5159755075791e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0004863412759732455\n",
      "Gradient for decoder.decoder.1.bias: 0.00040535282460041344\n",
      "Gradient for decoder.decoder.3.weight: 0.010070046409964561\n",
      "Gradient for decoder.decoder.3.bias: 9.000494100019907e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00042261838098056614\n",
      "Gradient for decoder.decoder.4.bias: 0.0004563426482491195\n",
      "Gradient for decoder.decoder.6.weight: 0.00045049836626276374\n",
      "Gradient for decoder.decoder.6.bias: 2.9088159863022156e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.004513121210038662\n",
      "Gradient for encoder.encoder.0.bias: 9.398965980511598e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.00028952735010534525\n",
      "Gradient for encoder.encoder.1.bias: 0.00042393917101435363\n",
      "Gradient for encoder.encoder.3.weight: 0.006329728756099939\n",
      "Gradient for encoder.encoder.3.bias: 9.149756646786855e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.0023091628681868315\n",
      "Gradient for encoder.encoder.4.bias: 0.0017984346486628056\n",
      "Gradient for encoder.mean.weight: 0.03507749363780022\n",
      "Gradient for encoder.mean.bias: 0.0015872834483161569\n",
      "Gradient for encoder.log_var.weight: 0.018399829044938087\n",
      "Gradient for encoder.log_var.bias: 0.000985827879048884\n",
      "Gradient for decoder.decoder.0.weight: 0.009168708696961403\n",
      "Gradient for decoder.decoder.0.bias: 7.856426620378443e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0004600599058903754\n",
      "Gradient for decoder.decoder.1.bias: 0.0003422433219384402\n",
      "Gradient for decoder.decoder.3.weight: 0.008466450497508049\n",
      "Gradient for decoder.decoder.3.bias: 6.450372874722277e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0003506233624648303\n",
      "Gradient for decoder.decoder.4.bias: 0.00037837662966921926\n",
      "Gradient for decoder.decoder.6.weight: 0.000404093210818246\n",
      "Gradient for decoder.decoder.6.bias: 2.2513502699439414e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training VAE Epoch:  51%|█████     | 40/79 [00:00<00:00, 67.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient for encoder.encoder.0.weight: 0.004989140667021275\n",
      "Gradient for encoder.encoder.0.bias: 9.904009903860533e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.0003558766038622707\n",
      "Gradient for encoder.encoder.1.bias: 0.0004278901615180075\n",
      "Gradient for encoder.encoder.3.weight: 0.007356962654739618\n",
      "Gradient for encoder.encoder.3.bias: 1.0877353184834959e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0026537799276411533\n",
      "Gradient for encoder.encoder.4.bias: 0.002046345267444849\n",
      "Gradient for encoder.mean.weight: 0.03665107116103172\n",
      "Gradient for encoder.mean.bias: 0.0015597337624058127\n",
      "Gradient for encoder.log_var.weight: 0.01948174647986889\n",
      "Gradient for encoder.log_var.bias: 0.0010631369659677148\n",
      "Gradient for decoder.decoder.0.weight: 0.009409722872078419\n",
      "Gradient for decoder.decoder.0.bias: 9.111594118094146e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.000465601246105507\n",
      "Gradient for decoder.decoder.1.bias: 0.00038932004827074707\n",
      "Gradient for decoder.decoder.3.weight: 0.008688624948263168\n",
      "Gradient for decoder.decoder.3.bias: 8.175878030147743e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00028871215181425214\n",
      "Gradient for decoder.decoder.4.bias: 0.00026484119007363915\n",
      "Gradient for decoder.decoder.6.weight: 0.0004261658468749374\n",
      "Gradient for decoder.decoder.6.bias: 2.2888600142323412e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.0025443381164222956\n",
      "Gradient for encoder.encoder.0.bias: 4.980944909999119e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.00026417471235617995\n",
      "Gradient for encoder.encoder.1.bias: 0.00039731792639940977\n",
      "Gradient for encoder.encoder.3.weight: 0.005877221934497356\n",
      "Gradient for encoder.encoder.3.bias: 9.097256281620503e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.0029982051346451044\n",
      "Gradient for encoder.encoder.4.bias: 0.0018775257049128413\n",
      "Gradient for encoder.mean.weight: 0.04129980131983757\n",
      "Gradient for encoder.mean.bias: 0.0013475329615175724\n",
      "Gradient for encoder.log_var.weight: 0.025413312017917633\n",
      "Gradient for encoder.log_var.bias: 0.0009632254368625581\n",
      "Gradient for decoder.decoder.0.weight: 0.01549591775983572\n",
      "Gradient for decoder.decoder.0.bias: 1.1704003044510358e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0007986023556441069\n",
      "Gradient for decoder.decoder.1.bias: 0.0006607966497540474\n",
      "Gradient for decoder.decoder.3.weight: 0.014671945944428444\n",
      "Gradient for decoder.decoder.3.bias: 1.1996617588216907e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.000726771482732147\n",
      "Gradient for decoder.decoder.4.bias: 0.0007979145739227533\n",
      "Gradient for decoder.decoder.6.weight: 0.0006486751371994615\n",
      "Gradient for decoder.decoder.6.bias: 4.7952427848940715e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.0030052040237933397\n",
      "Gradient for encoder.encoder.0.bias: 6.000094952135493e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.0002140619035344571\n",
      "Gradient for encoder.encoder.1.bias: 0.0003376043459866196\n",
      "Gradient for encoder.encoder.3.weight: 0.004912949167191982\n",
      "Gradient for encoder.encoder.3.bias: 7.474803415119524e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.002437307732179761\n",
      "Gradient for encoder.encoder.4.bias: 0.0015053321840241551\n",
      "Gradient for encoder.mean.weight: 0.03792241960763931\n",
      "Gradient for encoder.mean.bias: 0.0011576596880331635\n",
      "Gradient for encoder.log_var.weight: 0.021667135879397392\n",
      "Gradient for encoder.log_var.bias: 0.0008228804217651486\n",
      "Gradient for decoder.decoder.0.weight: 0.011582087725400925\n",
      "Gradient for decoder.decoder.0.bias: 9.517693577709707e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005550861242227256\n",
      "Gradient for decoder.decoder.1.bias: 0.00047306084888987243\n",
      "Gradient for decoder.decoder.3.weight: 0.010641669854521751\n",
      "Gradient for decoder.decoder.3.bias: 7.759391046358033e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0003818545665126294\n",
      "Gradient for decoder.decoder.4.bias: 0.0003285279672127217\n",
      "Gradient for decoder.decoder.6.weight: 0.00042282018694095314\n",
      "Gradient for decoder.decoder.6.bias: 2.254202809126582e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.0031475492287427187\n",
      "Gradient for encoder.encoder.0.bias: 6.761141559813444e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.00025774314417503774\n",
      "Gradient for encoder.encoder.1.bias: 0.00037919130409136415\n",
      "Gradient for encoder.encoder.3.weight: 0.005542771425098181\n",
      "Gradient for encoder.encoder.3.bias: 9.427460201383298e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.002694559982046485\n",
      "Gradient for encoder.encoder.4.bias: 0.0020362171344459057\n",
      "Gradient for encoder.mean.weight: 0.03831201046705246\n",
      "Gradient for encoder.mean.bias: 0.001636193715967238\n",
      "Gradient for encoder.log_var.weight: 0.022466881200671196\n",
      "Gradient for encoder.log_var.bias: 0.0011918303789570928\n",
      "Gradient for decoder.decoder.0.weight: 0.010355325415730476\n",
      "Gradient for decoder.decoder.0.bias: 9.039950038536304e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005538876284845173\n",
      "Gradient for decoder.decoder.1.bias: 0.000447852915385738\n",
      "Gradient for decoder.decoder.3.weight: 0.009837950579822063\n",
      "Gradient for decoder.decoder.3.bias: 8.01692948138033e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0004049011622555554\n",
      "Gradient for decoder.decoder.4.bias: 0.0004123569233343005\n",
      "Gradient for decoder.decoder.6.weight: 0.0004224600561428815\n",
      "Gradient for decoder.decoder.6.bias: 2.555639366619289e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.0028129450511187315\n",
      "Gradient for encoder.encoder.0.bias: 4.979875452976179e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.00023484595294576138\n",
      "Gradient for encoder.encoder.1.bias: 0.00035409306292422116\n",
      "Gradient for encoder.encoder.3.weight: 0.004886517766863108\n",
      "Gradient for encoder.encoder.3.bias: 7.770821486285939e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.0024002939462661743\n",
      "Gradient for encoder.encoder.4.bias: 0.0014412540476769209\n",
      "Gradient for encoder.mean.weight: 0.037988513708114624\n",
      "Gradient for encoder.mean.bias: 0.0010372439865022898\n",
      "Gradient for encoder.log_var.weight: 0.021260226145386696\n",
      "Gradient for encoder.log_var.bias: 0.0008541268180124462\n",
      "Gradient for decoder.decoder.0.weight: 0.01276389416307211\n",
      "Gradient for decoder.decoder.0.bias: 1.0680005491092714e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0006287215510383248\n",
      "Gradient for decoder.decoder.1.bias: 0.0005249701789580286\n",
      "Gradient for decoder.decoder.3.weight: 0.012845687568187714\n",
      "Gradient for decoder.decoder.3.bias: 9.154191293880842e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00046441482845693827\n",
      "Gradient for decoder.decoder.4.bias: 0.0003898876311723143\n",
      "Gradient for decoder.decoder.6.weight: 0.0004461604403331876\n",
      "Gradient for decoder.decoder.6.bias: 1.853639514592942e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.003344625234603882\n",
      "Gradient for encoder.encoder.0.bias: 7.73485702570964e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.00029896688647568226\n",
      "Gradient for encoder.encoder.1.bias: 0.0004440158954821527\n",
      "Gradient for encoder.encoder.3.weight: 0.0063652340322732925\n",
      "Gradient for encoder.encoder.3.bias: 8.814955709812722e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.0025303761940449476\n",
      "Gradient for encoder.encoder.4.bias: 0.0019747542683035135\n",
      "Gradient for encoder.mean.weight: 0.038087647408246994\n",
      "Gradient for encoder.mean.bias: 0.0015558118466287851\n",
      "Gradient for encoder.log_var.weight: 0.02148248255252838\n",
      "Gradient for encoder.log_var.bias: 0.0011202240129932761\n",
      "Gradient for decoder.decoder.0.weight: 0.009869653731584549\n",
      "Gradient for decoder.decoder.0.bias: 7.742904234442349e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005000969977118075\n",
      "Gradient for decoder.decoder.1.bias: 0.00040321520646102726\n",
      "Gradient for decoder.decoder.3.weight: 0.009375087916851044\n",
      "Gradient for decoder.decoder.3.bias: 8.312506238894457e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.000435888854553923\n",
      "Gradient for decoder.decoder.4.bias: 0.00048255559522658587\n",
      "Gradient for decoder.decoder.6.weight: 0.0004263493465259671\n",
      "Gradient for decoder.decoder.6.bias: 2.6180983695667237e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.0032528864685446024\n",
      "Gradient for encoder.encoder.0.bias: 6.8733577857083006e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.0002401809033472091\n",
      "Gradient for encoder.encoder.1.bias: 0.00037222381797619164\n",
      "Gradient for encoder.encoder.3.weight: 0.005147537682205439\n",
      "Gradient for encoder.encoder.3.bias: 8.625582192944847e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.0028368362691253424\n",
      "Gradient for encoder.encoder.4.bias: 0.0013354484690353274\n",
      "Gradient for encoder.mean.weight: 0.04059017822146416\n",
      "Gradient for encoder.mean.bias: 0.0010228302562609315\n",
      "Gradient for encoder.log_var.weight: 0.025099948048591614\n",
      "Gradient for encoder.log_var.bias: 0.0007037448231130838\n",
      "Gradient for decoder.decoder.0.weight: 0.012372476048767567\n",
      "Gradient for decoder.decoder.0.bias: 1.0582333620501316e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0006145950756035745\n",
      "Gradient for decoder.decoder.1.bias: 0.0005216053687036037\n",
      "Gradient for decoder.decoder.3.weight: 0.011817452497780323\n",
      "Gradient for decoder.decoder.3.bias: 9.59937268563138e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00041804282227531075\n",
      "Gradient for decoder.decoder.4.bias: 0.000374316587112844\n",
      "Gradient for decoder.decoder.6.weight: 0.00043483925401233137\n",
      "Gradient for decoder.decoder.6.bias: 2.0364244846859947e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.003484148532152176\n",
      "Gradient for encoder.encoder.0.bias: 6.935086185877459e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.0003232568851672113\n",
      "Gradient for encoder.encoder.1.bias: 0.00044245884055271745\n",
      "Gradient for encoder.encoder.3.weight: 0.007301054894924164\n",
      "Gradient for encoder.encoder.3.bias: 9.379737958559176e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.0026472804602235556\n",
      "Gradient for encoder.encoder.4.bias: 0.0016540688229724765\n",
      "Gradient for encoder.mean.weight: 0.039731696248054504\n",
      "Gradient for encoder.mean.bias: 0.0012415272649377584\n",
      "Gradient for encoder.log_var.weight: 0.02129238285124302\n",
      "Gradient for encoder.log_var.bias: 0.0008304262300953269\n",
      "Gradient for decoder.decoder.0.weight: 0.012109719216823578\n",
      "Gradient for decoder.decoder.0.bias: 1.0331557137588376e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0005867324071004987\n",
      "Gradient for decoder.decoder.1.bias: 0.000486342963995412\n",
      "Gradient for decoder.decoder.3.weight: 0.011308932676911354\n",
      "Gradient for decoder.decoder.3.bias: 8.71470257068907e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00043463727342896163\n",
      "Gradient for decoder.decoder.4.bias: 0.000418033916503191\n",
      "Gradient for decoder.decoder.6.weight: 0.00046879416913725436\n",
      "Gradient for decoder.decoder.6.bias: 2.582434353826102e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.0062562585808336735\n",
      "Gradient for encoder.encoder.0.bias: 1.477415065287424e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.00045286648673936725\n",
      "Gradient for encoder.encoder.1.bias: 0.0004841197223868221\n",
      "Gradient for encoder.encoder.3.weight: 0.009239504113793373\n",
      "Gradient for encoder.encoder.3.bias: 1.1356666301809426e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0031505085062235594\n",
      "Gradient for encoder.encoder.4.bias: 0.002091513480991125\n",
      "Gradient for encoder.mean.weight: 0.04343236982822418\n",
      "Gradient for encoder.mean.bias: 0.0013669286854565144\n",
      "Gradient for encoder.log_var.weight: 0.027086634188890457\n",
      "Gradient for encoder.log_var.bias: 0.0009049674845300615\n",
      "Gradient for decoder.decoder.0.weight: 0.00800755713135004\n",
      "Gradient for decoder.decoder.0.bias: 7.19377474256433e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0004090844886377454\n",
      "Gradient for decoder.decoder.1.bias: 0.00033784942934289575\n",
      "Gradient for decoder.decoder.3.weight: 0.007789167109876871\n",
      "Gradient for decoder.decoder.3.bias: 6.481017111870102e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0004498698399402201\n",
      "Gradient for decoder.decoder.4.bias: 0.0005505880690179765\n",
      "Gradient for decoder.decoder.6.weight: 0.000465366174466908\n",
      "Gradient for decoder.decoder.6.bias: 3.6540048313327134e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.0024610417895019054\n",
      "Gradient for encoder.encoder.0.bias: 4.6340678690193204e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.0002060638798866421\n",
      "Gradient for encoder.encoder.1.bias: 0.00027146030333824456\n",
      "Gradient for encoder.encoder.3.weight: 0.004523812793195248\n",
      "Gradient for encoder.encoder.3.bias: 9.444632576016687e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.002721924101933837\n",
      "Gradient for encoder.encoder.4.bias: 0.0023299020249396563\n",
      "Gradient for encoder.mean.weight: 0.03907923772931099\n",
      "Gradient for encoder.mean.bias: 0.0017310836119577289\n",
      "Gradient for encoder.log_var.weight: 0.024318236857652664\n",
      "Gradient for encoder.log_var.bias: 0.0012010174104943871\n",
      "Gradient for decoder.decoder.0.weight: 0.012946280650794506\n",
      "Gradient for decoder.decoder.0.bias: 1.1698193802534007e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0006707637221552432\n",
      "Gradient for decoder.decoder.1.bias: 0.0005322423530742526\n",
      "Gradient for decoder.decoder.3.weight: 0.012671977281570435\n",
      "Gradient for decoder.decoder.3.bias: 9.281924534532138e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0004354709235485643\n",
      "Gradient for decoder.decoder.4.bias: 0.0003872268716804683\n",
      "Gradient for decoder.decoder.6.weight: 0.00045522674918174744\n",
      "Gradient for decoder.decoder.6.bias: 2.2748428818886168e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.0024635514710098505\n",
      "Gradient for encoder.encoder.0.bias: 4.669574189125614e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.0002019010717049241\n",
      "Gradient for encoder.encoder.1.bias: 0.0002925566222984344\n",
      "Gradient for encoder.encoder.3.weight: 0.00474716629832983\n",
      "Gradient for encoder.encoder.3.bias: 9.745999146604234e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.003043676260858774\n",
      "Gradient for encoder.encoder.4.bias: 0.0018643117509782314\n",
      "Gradient for encoder.mean.weight: 0.04542483389377594\n",
      "Gradient for encoder.mean.bias: 0.0012103392509743571\n",
      "Gradient for encoder.log_var.weight: 0.025382427498698235\n",
      "Gradient for encoder.log_var.bias: 0.0008690921240486205\n",
      "Gradient for decoder.decoder.0.weight: 0.015473095700144768\n",
      "Gradient for decoder.decoder.0.bias: 1.2524642434286193e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0007598267984576523\n",
      "Gradient for decoder.decoder.1.bias: 0.0006325615686364472\n",
      "Gradient for decoder.decoder.3.weight: 0.014294808730483055\n",
      "Gradient for decoder.decoder.3.bias: 1.0919690152100259e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0006844181916676462\n",
      "Gradient for decoder.decoder.4.bias: 0.0006807721219956875\n",
      "Gradient for decoder.decoder.6.weight: 0.0005924450815655291\n",
      "Gradient for decoder.decoder.6.bias: 4.0217008063336834e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.004034731071442366\n",
      "Gradient for encoder.encoder.0.bias: 8.657277152102072e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.0002992102818097919\n",
      "Gradient for encoder.encoder.1.bias: 0.00034915172727778554\n",
      "Gradient for encoder.encoder.3.weight: 0.0065431660041213036\n",
      "Gradient for encoder.encoder.3.bias: 9.458478444912544e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.0023540419060736895\n",
      "Gradient for encoder.encoder.4.bias: 0.0017566400347277522\n",
      "Gradient for encoder.mean.weight: 0.03326727822422981\n",
      "Gradient for encoder.mean.bias: 0.0012245116522535682\n",
      "Gradient for encoder.log_var.weight: 0.017960984259843826\n",
      "Gradient for encoder.log_var.bias: 0.0008975050877779722\n",
      "Gradient for decoder.decoder.0.weight: 0.010328621603548527\n",
      "Gradient for decoder.decoder.0.bias: 9.215887081248653e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005102978902868927\n",
      "Gradient for decoder.decoder.1.bias: 0.00040608944254927337\n",
      "Gradient for decoder.decoder.3.weight: 0.00970667228102684\n",
      "Gradient for decoder.decoder.3.bias: 6.986498185534984e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00034411827800795436\n",
      "Gradient for decoder.decoder.4.bias: 0.00031237301300279796\n",
      "Gradient for decoder.decoder.6.weight: 0.0004188867751508951\n",
      "Gradient for decoder.decoder.6.bias: 2.1064844986540265e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.002913195174187422\n",
      "Gradient for encoder.encoder.0.bias: 5.243892126083338e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.00021460269636008888\n",
      "Gradient for encoder.encoder.1.bias: 0.0003586166421882808\n",
      "Gradient for encoder.encoder.3.weight: 0.0049073765985667706\n",
      "Gradient for encoder.encoder.3.bias: 8.29780757993781e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.0028625281993299723\n",
      "Gradient for encoder.encoder.4.bias: 0.0017132231732830405\n",
      "Gradient for encoder.mean.weight: 0.040550172328948975\n",
      "Gradient for encoder.mean.bias: 0.0010875248117372394\n",
      "Gradient for encoder.log_var.weight: 0.026333795860409737\n",
      "Gradient for encoder.log_var.bias: 0.0006893054815009236\n",
      "Gradient for decoder.decoder.0.weight: 0.012962124310433865\n",
      "Gradient for decoder.decoder.0.bias: 1.0499716374123835e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0006237388588488102\n",
      "Gradient for decoder.decoder.1.bias: 0.0005175936385057867\n",
      "Gradient for decoder.decoder.3.weight: 0.012461043894290924\n",
      "Gradient for decoder.decoder.3.bias: 9.79527431388405e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00044303780305199325\n",
      "Gradient for decoder.decoder.4.bias: 0.0004069320857524872\n",
      "Gradient for decoder.decoder.6.weight: 0.0004459548508748412\n",
      "Gradient for decoder.decoder.6.bias: 2.434705493215006e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.0035057058557868004\n",
      "Gradient for encoder.encoder.0.bias: 8.145212802845858e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.00026352982968091965\n",
      "Gradient for encoder.encoder.1.bias: 0.00037805127794854343\n",
      "Gradient for encoder.encoder.3.weight: 0.005732834339141846\n",
      "Gradient for encoder.encoder.3.bias: 8.563373621317538e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.0026889205910265446\n",
      "Gradient for encoder.encoder.4.bias: 0.0018013067310675979\n",
      "Gradient for encoder.mean.weight: 0.040913619101047516\n",
      "Gradient for encoder.mean.bias: 0.0014587148325517774\n",
      "Gradient for encoder.log_var.weight: 0.021116510033607483\n",
      "Gradient for encoder.log_var.bias: 0.000935206247959286\n",
      "Gradient for decoder.decoder.0.weight: 0.010259771719574928\n",
      "Gradient for decoder.decoder.0.bias: 8.574580628861739e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005094014341011643\n",
      "Gradient for decoder.decoder.1.bias: 0.0004460425698198378\n",
      "Gradient for decoder.decoder.3.weight: 0.009558457881212234\n",
      "Gradient for decoder.decoder.3.bias: 7.901872906002083e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00046895991545170546\n",
      "Gradient for decoder.decoder.4.bias: 0.0005710662226192653\n",
      "Gradient for decoder.decoder.6.weight: 0.00045520527055487037\n",
      "Gradient for decoder.decoder.6.bias: 3.3011605410138145e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training VAE Epoch:  61%|██████    | 48/79 [00:00<00:00, 71.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient for encoder.encoder.0.weight: 0.0030995956622064114\n",
      "Gradient for encoder.encoder.0.bias: 7.205141431404494e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.00028387087513692677\n",
      "Gradient for encoder.encoder.1.bias: 0.00041823205538094044\n",
      "Gradient for encoder.encoder.3.weight: 0.006068048067390919\n",
      "Gradient for encoder.encoder.3.bias: 1.0625131330321835e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.002735102316364646\n",
      "Gradient for encoder.encoder.4.bias: 0.0021320292726159096\n",
      "Gradient for encoder.mean.weight: 0.04270413890480995\n",
      "Gradient for encoder.mean.bias: 0.0018333490006625652\n",
      "Gradient for encoder.log_var.weight: 0.022817833349108696\n",
      "Gradient for encoder.log_var.bias: 0.0011520240223035216\n",
      "Gradient for decoder.decoder.0.weight: 0.011137984693050385\n",
      "Gradient for decoder.decoder.0.bias: 9.64986285323377e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.000581402680836618\n",
      "Gradient for decoder.decoder.1.bias: 0.00046108028618618846\n",
      "Gradient for decoder.decoder.3.weight: 0.010863831266760826\n",
      "Gradient for decoder.decoder.3.bias: 9.237148546059615e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0003723196277860552\n",
      "Gradient for decoder.decoder.4.bias: 0.0003339851973578334\n",
      "Gradient for decoder.decoder.6.weight: 0.0004252110666129738\n",
      "Gradient for decoder.decoder.6.bias: 1.894455635920167e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.0025963280349969864\n",
      "Gradient for encoder.encoder.0.bias: 4.618529083483258e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.00017917358491104096\n",
      "Gradient for encoder.encoder.1.bias: 0.00025960413040593266\n",
      "Gradient for encoder.encoder.3.weight: 0.0043004355393350124\n",
      "Gradient for encoder.encoder.3.bias: 9.012778023897994e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.0026640535797923803\n",
      "Gradient for encoder.encoder.4.bias: 0.0017388461856171489\n",
      "Gradient for encoder.mean.weight: 0.03678370267152786\n",
      "Gradient for encoder.mean.bias: 0.001163590350188315\n",
      "Gradient for encoder.log_var.weight: 0.023908985778689384\n",
      "Gradient for encoder.log_var.bias: 0.0009005868923850358\n",
      "Gradient for decoder.decoder.0.weight: 0.015323838219046593\n",
      "Gradient for decoder.decoder.0.bias: 1.215430811551954e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.000769364065490663\n",
      "Gradient for decoder.decoder.1.bias: 0.000637382676359266\n",
      "Gradient for decoder.decoder.3.weight: 0.014467195607721806\n",
      "Gradient for decoder.decoder.3.bias: 1.2940774840597413e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0007839755853638053\n",
      "Gradient for decoder.decoder.4.bias: 0.0008958411053754389\n",
      "Gradient for decoder.decoder.6.weight: 0.0006807325407862663\n",
      "Gradient for decoder.decoder.6.bias: 5.237486038822681e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training VAE Epoch:  71%|███████   | 56/79 [00:00<00:00, 73.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient for encoder.encoder.0.weight: 0.003676567692309618\n",
      "Gradient for encoder.encoder.0.bias: 7.556781589368455e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.00026493973564356565\n",
      "Gradient for encoder.encoder.1.bias: 0.00029213636298663914\n",
      "Gradient for encoder.encoder.3.weight: 0.0059719691053032875\n",
      "Gradient for encoder.encoder.3.bias: 7.857471617800371e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.0026125696022063494\n",
      "Gradient for encoder.encoder.4.bias: 0.0015609777765348554\n",
      "Gradient for encoder.mean.weight: 0.03744960576295853\n",
      "Gradient for encoder.mean.bias: 0.0012177926255390048\n",
      "Gradient for encoder.log_var.weight: 0.020073309540748596\n",
      "Gradient for encoder.log_var.bias: 0.0008363283704966307\n",
      "Gradient for decoder.decoder.0.weight: 0.010970041155815125\n",
      "Gradient for decoder.decoder.0.bias: 9.980299225942346e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005541668506339192\n",
      "Gradient for decoder.decoder.1.bias: 0.00044863243238069117\n",
      "Gradient for decoder.decoder.3.weight: 0.0104672284796834\n",
      "Gradient for decoder.decoder.3.bias: 8.751553648433941e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00046441590529866517\n",
      "Gradient for decoder.decoder.4.bias: 0.00044990680180490017\n",
      "Gradient for decoder.decoder.6.weight: 0.00047161037218756974\n",
      "Gradient for decoder.decoder.6.bias: 2.6799976694746874e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.0025058314204216003\n",
      "Gradient for encoder.encoder.0.bias: 4.666059205682416e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.0001853612338891253\n",
      "Gradient for encoder.encoder.1.bias: 0.0003068785590585321\n",
      "Gradient for encoder.encoder.3.weight: 0.00395311089232564\n",
      "Gradient for encoder.encoder.3.bias: 7.992782824484124e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.0027229024562984705\n",
      "Gradient for encoder.encoder.4.bias: 0.0016254130750894547\n",
      "Gradient for encoder.mean.weight: 0.038522422313690186\n",
      "Gradient for encoder.mean.bias: 0.0012001863215118647\n",
      "Gradient for encoder.log_var.weight: 0.023144284263253212\n",
      "Gradient for encoder.log_var.bias: 0.0008189902873709798\n",
      "Gradient for decoder.decoder.0.weight: 0.014455582946538925\n",
      "Gradient for decoder.decoder.0.bias: 1.2380944880430178e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0006616279715672135\n",
      "Gradient for decoder.decoder.1.bias: 0.0005947005120106041\n",
      "Gradient for decoder.decoder.3.weight: 0.013627078384160995\n",
      "Gradient for decoder.decoder.3.bias: 1.0288187662910175e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0004977493081241846\n",
      "Gradient for decoder.decoder.4.bias: 0.00042658488382585347\n",
      "Gradient for decoder.decoder.6.weight: 0.0004600821412168443\n",
      "Gradient for decoder.decoder.6.bias: 2.11736169148935e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.0036264159716665745\n",
      "Gradient for encoder.encoder.0.bias: 7.2572854843688805e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.00025363301392644644\n",
      "Gradient for encoder.encoder.1.bias: 0.0003405090537853539\n",
      "Gradient for encoder.encoder.3.weight: 0.005291998852044344\n",
      "Gradient for encoder.encoder.3.bias: 1.0101144226615233e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0024227150715887547\n",
      "Gradient for encoder.encoder.4.bias: 0.0018683535745367408\n",
      "Gradient for encoder.mean.weight: 0.03552009165287018\n",
      "Gradient for encoder.mean.bias: 0.0014445156557485461\n",
      "Gradient for encoder.log_var.weight: 0.023275626823306084\n",
      "Gradient for encoder.log_var.bias: 0.0009432747028768063\n",
      "Gradient for decoder.decoder.0.weight: 0.01115809939801693\n",
      "Gradient for decoder.decoder.0.bias: 9.11396236258355e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005486656446009874\n",
      "Gradient for decoder.decoder.1.bias: 0.0004677415417972952\n",
      "Gradient for decoder.decoder.3.weight: 0.01034806203097105\n",
      "Gradient for decoder.decoder.3.bias: 7.74377645340607e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0004071589792147279\n",
      "Gradient for decoder.decoder.4.bias: 0.00036455949884839356\n",
      "Gradient for decoder.decoder.6.weight: 0.00044510432053357363\n",
      "Gradient for decoder.decoder.6.bias: 2.3529399186372757e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.003749109571799636\n",
      "Gradient for encoder.encoder.0.bias: 8.058660509735471e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.0003018037823494524\n",
      "Gradient for encoder.encoder.1.bias: 0.0003891998785547912\n",
      "Gradient for encoder.encoder.3.weight: 0.006988828536123037\n",
      "Gradient for encoder.encoder.3.bias: 1.1022564805340807e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.002545948838815093\n",
      "Gradient for encoder.encoder.4.bias: 0.0020863066893070936\n",
      "Gradient for encoder.mean.weight: 0.03477221727371216\n",
      "Gradient for encoder.mean.bias: 0.0013605162966996431\n",
      "Gradient for encoder.log_var.weight: 0.02032065950334072\n",
      "Gradient for encoder.log_var.bias: 0.0010214229114353657\n",
      "Gradient for decoder.decoder.0.weight: 0.010778768919408321\n",
      "Gradient for decoder.decoder.0.bias: 9.300284847801876e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0004948842688463628\n",
      "Gradient for decoder.decoder.1.bias: 0.00041646044701337814\n",
      "Gradient for decoder.decoder.3.weight: 0.010497397743165493\n",
      "Gradient for decoder.decoder.3.bias: 8.204354556839988e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0003929325903300196\n",
      "Gradient for decoder.decoder.4.bias: 0.00033106133923865855\n",
      "Gradient for decoder.decoder.6.weight: 0.0004332850512582809\n",
      "Gradient for decoder.decoder.6.bias: 2.1145096980035305e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.0031178914941847324\n",
      "Gradient for encoder.encoder.0.bias: 6.687592753878979e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.0002683523634914309\n",
      "Gradient for encoder.encoder.1.bias: 0.00041072070598602295\n",
      "Gradient for encoder.encoder.3.weight: 0.005884274840354919\n",
      "Gradient for encoder.encoder.3.bias: 9.672271317207048e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.0025970106944441795\n",
      "Gradient for encoder.encoder.4.bias: 0.002360715065151453\n",
      "Gradient for encoder.mean.weight: 0.03805328533053398\n",
      "Gradient for encoder.mean.bias: 0.001903983298689127\n",
      "Gradient for encoder.log_var.weight: 0.024026036262512207\n",
      "Gradient for encoder.log_var.bias: 0.0012846244499087334\n",
      "Gradient for decoder.decoder.0.weight: 0.011310256086289883\n",
      "Gradient for decoder.decoder.0.bias: 8.930425149378252e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005659129819832742\n",
      "Gradient for decoder.decoder.1.bias: 0.00046363231376744807\n",
      "Gradient for decoder.decoder.3.weight: 0.010265424847602844\n",
      "Gradient for decoder.decoder.3.bias: 7.892569237055724e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0003314248751848936\n",
      "Gradient for decoder.decoder.4.bias: 0.0003022986638825387\n",
      "Gradient for decoder.decoder.6.weight: 0.00040349375922232866\n",
      "Gradient for decoder.decoder.6.bias: 1.7543208741699345e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.003294590627774596\n",
      "Gradient for encoder.encoder.0.bias: 7.687340347617422e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.00026721725589595735\n",
      "Gradient for encoder.encoder.1.bias: 0.00033056188840419054\n",
      "Gradient for encoder.encoder.3.weight: 0.006011336576193571\n",
      "Gradient for encoder.encoder.3.bias: 8.88117634989527e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.0022575182374566793\n",
      "Gradient for encoder.encoder.4.bias: 0.0016633238410577178\n",
      "Gradient for encoder.mean.weight: 0.033445000648498535\n",
      "Gradient for encoder.mean.bias: 0.0012378029059618711\n",
      "Gradient for encoder.log_var.weight: 0.019289584830403328\n",
      "Gradient for encoder.log_var.bias: 0.0008355661411769688\n",
      "Gradient for decoder.decoder.0.weight: 0.010129989124834538\n",
      "Gradient for decoder.decoder.0.bias: 9.153823532503935e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.00048798698117025197\n",
      "Gradient for decoder.decoder.1.bias: 0.0004217424138914794\n",
      "Gradient for decoder.decoder.3.weight: 0.009295276366174221\n",
      "Gradient for decoder.decoder.3.bias: 7.565540555143357e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00033021881245076656\n",
      "Gradient for decoder.decoder.4.bias: 0.0002853532787412405\n",
      "Gradient for decoder.decoder.6.weight: 0.0004014164151158184\n",
      "Gradient for decoder.decoder.6.bias: 2.1461955839185975e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.002819279907271266\n",
      "Gradient for encoder.encoder.0.bias: 5.535310491217027e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.0002110009954776615\n",
      "Gradient for encoder.encoder.1.bias: 0.0003087254299316555\n",
      "Gradient for encoder.encoder.3.weight: 0.004701132886111736\n",
      "Gradient for encoder.encoder.3.bias: 8.45945050120811e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.0023478905204683542\n",
      "Gradient for encoder.encoder.4.bias: 0.0018302351236343384\n",
      "Gradient for encoder.mean.weight: 0.03323446586728096\n",
      "Gradient for encoder.mean.bias: 0.001358849462121725\n",
      "Gradient for encoder.log_var.weight: 0.019350063055753708\n",
      "Gradient for encoder.log_var.bias: 0.0008936815429478884\n",
      "Gradient for decoder.decoder.0.weight: 0.01142683532088995\n",
      "Gradient for decoder.decoder.0.bias: 1.0311101278359658e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0005493081407621503\n",
      "Gradient for decoder.decoder.1.bias: 0.00045995847904123366\n",
      "Gradient for decoder.decoder.3.weight: 0.010894300416111946\n",
      "Gradient for decoder.decoder.3.bias: 7.6614978250511e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.000394920032704249\n",
      "Gradient for decoder.decoder.4.bias: 0.0003515163261909038\n",
      "Gradient for decoder.decoder.6.weight: 0.00048504871665500104\n",
      "Gradient for decoder.decoder.6.bias: 3.1089344702195376e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.0032655459363013506\n",
      "Gradient for encoder.encoder.0.bias: 6.480184878282502e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.00022139784414321184\n",
      "Gradient for encoder.encoder.1.bias: 0.00034533257712610066\n",
      "Gradient for encoder.encoder.3.weight: 0.004924257751554251\n",
      "Gradient for encoder.encoder.3.bias: 9.10124753339403e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.0023050005547702312\n",
      "Gradient for encoder.encoder.4.bias: 0.0019389836816117167\n",
      "Gradient for encoder.mean.weight: 0.03326471522450447\n",
      "Gradient for encoder.mean.bias: 0.0013632921036332846\n",
      "Gradient for encoder.log_var.weight: 0.02014126256108284\n",
      "Gradient for encoder.log_var.bias: 0.001042273361235857\n",
      "Gradient for decoder.decoder.0.weight: 0.01148139126598835\n",
      "Gradient for decoder.decoder.0.bias: 1.0893679014412072e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0005377377383410931\n",
      "Gradient for decoder.decoder.1.bias: 0.00045326555846259\n",
      "Gradient for decoder.decoder.3.weight: 0.010825627483427525\n",
      "Gradient for decoder.decoder.3.bias: 1.0254729010394925e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0003856477269437164\n",
      "Gradient for decoder.decoder.4.bias: 0.00036876750527881086\n",
      "Gradient for decoder.decoder.6.weight: 0.00042840850073844194\n",
      "Gradient for decoder.decoder.6.bias: 2.1675812604371458e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.002468843711540103\n",
      "Gradient for encoder.encoder.0.bias: 5.291087012970763e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.0002520341658964753\n",
      "Gradient for encoder.encoder.1.bias: 0.0003424411406740546\n",
      "Gradient for encoder.encoder.3.weight: 0.005584226921200752\n",
      "Gradient for encoder.encoder.3.bias: 8.302591947284554e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.0026766033843159676\n",
      "Gradient for encoder.encoder.4.bias: 0.0014608040219172835\n",
      "Gradient for encoder.mean.weight: 0.037288811057806015\n",
      "Gradient for encoder.mean.bias: 0.001016866764985025\n",
      "Gradient for encoder.log_var.weight: 0.022041676566004753\n",
      "Gradient for encoder.log_var.bias: 0.000718092720489949\n",
      "Gradient for decoder.decoder.0.weight: 0.01402541808784008\n",
      "Gradient for decoder.decoder.0.bias: 1.116514172783134e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0006941358442418277\n",
      "Gradient for decoder.decoder.1.bias: 0.0005532963550649583\n",
      "Gradient for decoder.decoder.3.weight: 0.013563447631895542\n",
      "Gradient for decoder.decoder.3.bias: 9.724345634287701e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0006239206995815039\n",
      "Gradient for decoder.decoder.4.bias: 0.0006469761719927192\n",
      "Gradient for decoder.decoder.6.weight: 0.0005090427002869546\n",
      "Gradient for decoder.decoder.6.bias: 2.8963668228243478e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.002945082727819681\n",
      "Gradient for encoder.encoder.0.bias: 6.596213592696687e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.00024906525504775345\n",
      "Gradient for encoder.encoder.1.bias: 0.00037672914913855493\n",
      "Gradient for encoder.encoder.3.weight: 0.005346803460270166\n",
      "Gradient for encoder.encoder.3.bias: 9.578181997538238e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.0027904065791517496\n",
      "Gradient for encoder.encoder.4.bias: 0.0019137033959850669\n",
      "Gradient for encoder.mean.weight: 0.04250868037343025\n",
      "Gradient for encoder.mean.bias: 0.0013713911175727844\n",
      "Gradient for encoder.log_var.weight: 0.025955552235245705\n",
      "Gradient for encoder.log_var.bias: 0.0008137841941788793\n",
      "Gradient for decoder.decoder.0.weight: 0.012181858532130718\n",
      "Gradient for decoder.decoder.0.bias: 9.979774645563211e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0006019122665748\n",
      "Gradient for decoder.decoder.1.bias: 0.0004906152025796473\n",
      "Gradient for decoder.decoder.3.weight: 0.011600842699408531\n",
      "Gradient for decoder.decoder.3.bias: 8.313120331004953e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00040958577301353216\n",
      "Gradient for decoder.decoder.4.bias: 0.0003637991612777114\n",
      "Gradient for decoder.decoder.6.weight: 0.0004443129582796246\n",
      "Gradient for decoder.decoder.6.bias: 2.2725600501871668e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.0034768206533044577\n",
      "Gradient for encoder.encoder.0.bias: 8.072340539067024e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.0003251149319112301\n",
      "Gradient for encoder.encoder.1.bias: 0.0005139554268680513\n",
      "Gradient for encoder.encoder.3.weight: 0.007200282998383045\n",
      "Gradient for encoder.encoder.3.bias: 8.865357753462533e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.0030325863044708967\n",
      "Gradient for encoder.encoder.4.bias: 0.0020217818673700094\n",
      "Gradient for encoder.mean.weight: 0.04293380305171013\n",
      "Gradient for encoder.mean.bias: 0.0013384894700720906\n",
      "Gradient for encoder.log_var.weight: 0.023733027279376984\n",
      "Gradient for encoder.log_var.bias: 0.0008974935044534504\n",
      "Gradient for decoder.decoder.0.weight: 0.010616502724587917\n",
      "Gradient for decoder.decoder.0.bias: 9.226630570680072e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005533902440220118\n",
      "Gradient for decoder.decoder.1.bias: 0.00043281129910610616\n",
      "Gradient for decoder.decoder.3.weight: 0.010095366276800632\n",
      "Gradient for decoder.decoder.3.bias: 7.612129676592971e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00037853719550184906\n",
      "Gradient for decoder.decoder.4.bias: 0.0003395075036678463\n",
      "Gradient for decoder.decoder.6.weight: 0.0004442424396984279\n",
      "Gradient for decoder.decoder.6.bias: 2.256037259940058e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.00572853721678257\n",
      "Gradient for encoder.encoder.0.bias: 1.2099839359624998e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.000343282736139372\n",
      "Gradient for encoder.encoder.1.bias: 0.0003763756831176579\n",
      "Gradient for encoder.encoder.3.weight: 0.007626343984156847\n",
      "Gradient for encoder.encoder.3.bias: 1.0400195982196436e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0029107911977916956\n",
      "Gradient for encoder.encoder.4.bias: 0.0024327090941369534\n",
      "Gradient for encoder.mean.weight: 0.03887929394841194\n",
      "Gradient for encoder.mean.bias: 0.001873337896540761\n",
      "Gradient for encoder.log_var.weight: 0.022669367492198944\n",
      "Gradient for encoder.log_var.bias: 0.001004352467134595\n",
      "Gradient for decoder.decoder.0.weight: 0.008419027552008629\n",
      "Gradient for decoder.decoder.0.bias: 7.070151408772318e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.00041753871482796967\n",
      "Gradient for decoder.decoder.1.bias: 0.0003583145735319704\n",
      "Gradient for decoder.decoder.3.weight: 0.008025930263102055\n",
      "Gradient for decoder.decoder.3.bias: 5.779371425873592e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0003039156727027148\n",
      "Gradient for decoder.decoder.4.bias: 0.0002874219499062747\n",
      "Gradient for decoder.decoder.6.weight: 0.00040639983490109444\n",
      "Gradient for decoder.decoder.6.bias: 2.0788011170225218e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.003028815845027566\n",
      "Gradient for encoder.encoder.0.bias: 6.119535433946055e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.0002478274400345981\n",
      "Gradient for encoder.encoder.1.bias: 0.0002843413094524294\n",
      "Gradient for encoder.encoder.3.weight: 0.005730185192078352\n",
      "Gradient for encoder.encoder.3.bias: 8.789258904018382e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.002408116590231657\n",
      "Gradient for encoder.encoder.4.bias: 0.0016251718625426292\n",
      "Gradient for encoder.mean.weight: 0.033580482006073\n",
      "Gradient for encoder.mean.bias: 0.0011149568017572165\n",
      "Gradient for encoder.log_var.weight: 0.0212614256888628\n",
      "Gradient for encoder.log_var.bias: 0.0007408490055240691\n",
      "Gradient for decoder.decoder.0.weight: 0.013921128585934639\n",
      "Gradient for decoder.decoder.0.bias: 1.120717685321182e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0006548933451995254\n",
      "Gradient for decoder.decoder.1.bias: 0.0005585710750892758\n",
      "Gradient for decoder.decoder.3.weight: 0.013185190968215466\n",
      "Gradient for decoder.decoder.3.bias: 1.1045873937742812e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0006540110916830599\n",
      "Gradient for decoder.decoder.4.bias: 0.0007070299470797181\n",
      "Gradient for decoder.decoder.6.weight: 0.000572972116060555\n",
      "Gradient for decoder.decoder.6.bias: 3.959410241805017e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.0031250216998159885\n",
      "Gradient for encoder.encoder.0.bias: 6.513906167932015e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.00022696898668073118\n",
      "Gradient for encoder.encoder.1.bias: 0.0003439239808358252\n",
      "Gradient for encoder.encoder.3.weight: 0.004747454077005386\n",
      "Gradient for encoder.encoder.3.bias: 8.573521753652003e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.0024110395461320877\n",
      "Gradient for encoder.encoder.4.bias: 0.0017865255940705538\n",
      "Gradient for encoder.mean.weight: 0.0373336523771286\n",
      "Gradient for encoder.mean.bias: 0.0013750059297308326\n",
      "Gradient for encoder.log_var.weight: 0.02062224969267845\n",
      "Gradient for encoder.log_var.bias: 0.0008712208364158869\n",
      "Gradient for decoder.decoder.0.weight: 0.011382541619241238\n",
      "Gradient for decoder.decoder.0.bias: 9.384454324745661e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.000475234177429229\n",
      "Gradient for decoder.decoder.1.bias: 0.0004514982283581048\n",
      "Gradient for decoder.decoder.3.weight: 0.010618409141898155\n",
      "Gradient for decoder.decoder.3.bias: 9.172154008529887e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0003662766539491713\n",
      "Gradient for decoder.decoder.4.bias: 0.00034360014251433313\n",
      "Gradient for decoder.decoder.6.weight: 0.0004318124265410006\n",
      "Gradient for decoder.decoder.6.bias: 2.3155862436397e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training VAE Epoch:  81%|████████  | 64/79 [00:01<00:00, 74.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient for encoder.encoder.0.weight: 0.005236049182713032\n",
      "Gradient for encoder.encoder.0.bias: 1.1439793556888844e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.00030678347684442997\n",
      "Gradient for encoder.encoder.1.bias: 0.00039323451346717775\n",
      "Gradient for encoder.encoder.3.weight: 0.006638405844569206\n",
      "Gradient for encoder.encoder.3.bias: 1.249201575515002e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0026364705990999937\n",
      "Gradient for encoder.encoder.4.bias: 0.0029111437033861876\n",
      "Gradient for encoder.mean.weight: 0.03812381997704506\n",
      "Gradient for encoder.mean.bias: 0.0021659419871866703\n",
      "Gradient for encoder.log_var.weight: 0.02209022268652916\n",
      "Gradient for encoder.log_var.bias: 0.0015914402902126312\n",
      "Gradient for decoder.decoder.0.weight: 0.00832965038716793\n",
      "Gradient for decoder.decoder.0.bias: 7.025048598396921e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.00037314597284421325\n",
      "Gradient for decoder.decoder.1.bias: 0.0003463032189756632\n",
      "Gradient for decoder.decoder.3.weight: 0.007472081109881401\n",
      "Gradient for decoder.decoder.3.bias: 7.337135760066005e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0003357499372214079\n",
      "Gradient for decoder.decoder.4.bias: 0.00036565150367096066\n",
      "Gradient for decoder.decoder.6.weight: 0.0004284574824851006\n",
      "Gradient for decoder.decoder.6.bias: 2.951620081148576e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.003390772035345435\n",
      "Gradient for encoder.encoder.0.bias: 8.449335849036732e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.0002899879473261535\n",
      "Gradient for encoder.encoder.1.bias: 0.0004471355932764709\n",
      "Gradient for encoder.encoder.3.weight: 0.006207591388374567\n",
      "Gradient for encoder.encoder.3.bias: 9.184109722726319e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.00237483368255198\n",
      "Gradient for encoder.encoder.4.bias: 0.0019657211378216743\n",
      "Gradient for encoder.mean.weight: 0.037457648664712906\n",
      "Gradient for encoder.mean.bias: 0.0016239613760262728\n",
      "Gradient for encoder.log_var.weight: 0.021767355501651764\n",
      "Gradient for encoder.log_var.bias: 0.0009194834856316447\n",
      "Gradient for decoder.decoder.0.weight: 0.009806676767766476\n",
      "Gradient for decoder.decoder.0.bias: 8.344528540371599e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0004163406847510487\n",
      "Gradient for decoder.decoder.1.bias: 0.0003900389710906893\n",
      "Gradient for decoder.decoder.3.weight: 0.008800409734249115\n",
      "Gradient for decoder.decoder.3.bias: 8.578784904678116e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0004802478651981801\n",
      "Gradient for decoder.decoder.4.bias: 0.0005378221976570785\n",
      "Gradient for decoder.decoder.6.weight: 0.00043987907702103257\n",
      "Gradient for decoder.decoder.6.bias: 3.011233638972044e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training VAE Epoch:  92%|█████████▏| 73/79 [00:01<00:00, 77.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient for encoder.encoder.0.weight: 0.0034695854410529137\n",
      "Gradient for encoder.encoder.0.bias: 8.242091037446997e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.0002761474170256406\n",
      "Gradient for encoder.encoder.1.bias: 0.0003796072560362518\n",
      "Gradient for encoder.encoder.3.weight: 0.005967334844172001\n",
      "Gradient for encoder.encoder.3.bias: 8.941634238590623e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.0022436489816755056\n",
      "Gradient for encoder.encoder.4.bias: 0.0016584094846621156\n",
      "Gradient for encoder.mean.weight: 0.03172283247113228\n",
      "Gradient for encoder.mean.bias: 0.0013517324114218354\n",
      "Gradient for encoder.log_var.weight: 0.019921187311410904\n",
      "Gradient for encoder.log_var.bias: 0.0008150830981321633\n",
      "Gradient for decoder.decoder.0.weight: 0.009459016844630241\n",
      "Gradient for decoder.decoder.0.bias: 8.815190244426674e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.00045771122677251697\n",
      "Gradient for decoder.decoder.1.bias: 0.0003903770702891052\n",
      "Gradient for decoder.decoder.3.weight: 0.008655543439090252\n",
      "Gradient for decoder.decoder.3.bias: 7.563723258829924e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0004542790702544153\n",
      "Gradient for decoder.decoder.4.bias: 0.0004988735308870673\n",
      "Gradient for decoder.decoder.6.weight: 0.0004445633094292134\n",
      "Gradient for decoder.decoder.6.bias: 2.8183834729134105e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.002766281832009554\n",
      "Gradient for encoder.encoder.0.bias: 5.138201929905106e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.00029046303825452924\n",
      "Gradient for encoder.encoder.1.bias: 0.00036548523348756135\n",
      "Gradient for encoder.encoder.3.weight: 0.006308459211140871\n",
      "Gradient for encoder.encoder.3.bias: 8.577048793423359e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.002672941191121936\n",
      "Gradient for encoder.encoder.4.bias: 0.0015835571102797985\n",
      "Gradient for encoder.mean.weight: 0.0400538444519043\n",
      "Gradient for encoder.mean.bias: 0.001037444919347763\n",
      "Gradient for encoder.log_var.weight: 0.024846764281392097\n",
      "Gradient for encoder.log_var.bias: 0.0008719068136997521\n",
      "Gradient for decoder.decoder.0.weight: 0.015291480347514153\n",
      "Gradient for decoder.decoder.0.bias: 1.3129874965045474e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0007658941322006285\n",
      "Gradient for decoder.decoder.1.bias: 0.000622266554273665\n",
      "Gradient for decoder.decoder.3.weight: 0.014401864260435104\n",
      "Gradient for decoder.decoder.3.bias: 1.198628696297277e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0006972283590584993\n",
      "Gradient for decoder.decoder.4.bias: 0.0007742088637314737\n",
      "Gradient for decoder.decoder.6.weight: 0.0005637136637233198\n",
      "Gradient for decoder.decoder.6.bias: 4.0804192394716665e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.003203624626621604\n",
      "Gradient for encoder.encoder.0.bias: 7.355308202783295e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.00021390012989286333\n",
      "Gradient for encoder.encoder.1.bias: 0.00033480869024060667\n",
      "Gradient for encoder.encoder.3.weight: 0.004936038516461849\n",
      "Gradient for encoder.encoder.3.bias: 9.261696271023467e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.002302533481270075\n",
      "Gradient for encoder.encoder.4.bias: 0.001974156592041254\n",
      "Gradient for encoder.mean.weight: 0.035541608929634094\n",
      "Gradient for encoder.mean.bias: 0.001598835689947009\n",
      "Gradient for encoder.log_var.weight: 0.019841808825731277\n",
      "Gradient for encoder.log_var.bias: 0.0009954948909580708\n",
      "Gradient for decoder.decoder.0.weight: 0.010849440470337868\n",
      "Gradient for decoder.decoder.0.bias: 9.072017442823821e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.000552400597371161\n",
      "Gradient for decoder.decoder.1.bias: 0.00045473274076357484\n",
      "Gradient for decoder.decoder.3.weight: 0.009881376288831234\n",
      "Gradient for decoder.decoder.3.bias: 7.954610581339949e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.000346346729202196\n",
      "Gradient for decoder.decoder.4.bias: 0.0003099859750363976\n",
      "Gradient for decoder.decoder.6.weight: 0.0004236952809151262\n",
      "Gradient for decoder.decoder.6.bias: 2.1610600015264936e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.003679172368720174\n",
      "Gradient for encoder.encoder.0.bias: 7.936902003680135e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.00032969668973237276\n",
      "Gradient for encoder.encoder.1.bias: 0.00046606038813479245\n",
      "Gradient for encoder.encoder.3.weight: 0.007353328634053469\n",
      "Gradient for encoder.encoder.3.bias: 9.012304791333747e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.0022145358379930258\n",
      "Gradient for encoder.encoder.4.bias: 0.0017609026981517673\n",
      "Gradient for encoder.mean.weight: 0.03269147127866745\n",
      "Gradient for encoder.mean.bias: 0.0013296299148350954\n",
      "Gradient for encoder.log_var.weight: 0.017871377989649773\n",
      "Gradient for encoder.log_var.bias: 0.0008569387719035149\n",
      "Gradient for decoder.decoder.0.weight: 0.008934393525123596\n",
      "Gradient for decoder.decoder.0.bias: 7.765102449930339e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0004392472037579864\n",
      "Gradient for decoder.decoder.1.bias: 0.0003861824225168675\n",
      "Gradient for decoder.decoder.3.weight: 0.00841935258358717\n",
      "Gradient for decoder.decoder.3.bias: 7.84178832979876e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0004283701709937304\n",
      "Gradient for decoder.decoder.4.bias: 0.00046392803778871894\n",
      "Gradient for decoder.decoder.6.weight: 0.00044331882963888347\n",
      "Gradient for decoder.decoder.6.bias: 3.108044620603323e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.0031888361554592848\n",
      "Gradient for encoder.encoder.0.bias: 6.527846405784965e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.0002706128580030054\n",
      "Gradient for encoder.encoder.1.bias: 0.00035297012072987854\n",
      "Gradient for encoder.encoder.3.weight: 0.005916695576161146\n",
      "Gradient for encoder.encoder.3.bias: 9.982138032826882e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.0023159016855061054\n",
      "Gradient for encoder.encoder.4.bias: 0.002191998530179262\n",
      "Gradient for encoder.mean.weight: 0.03706526756286621\n",
      "Gradient for encoder.mean.bias: 0.0017434045439586043\n",
      "Gradient for encoder.log_var.weight: 0.0219536442309618\n",
      "Gradient for encoder.log_var.bias: 0.0011509006144478917\n",
      "Gradient for decoder.decoder.0.weight: 0.011546134017407894\n",
      "Gradient for decoder.decoder.0.bias: 9.626865277168051e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005658582085743546\n",
      "Gradient for decoder.decoder.1.bias: 0.0004962472594343126\n",
      "Gradient for decoder.decoder.3.weight: 0.010711842216551304\n",
      "Gradient for decoder.decoder.3.bias: 8.740588114397596e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00038119309465400875\n",
      "Gradient for decoder.decoder.4.bias: 0.0003298644442111254\n",
      "Gradient for decoder.decoder.6.weight: 0.00041595340007916093\n",
      "Gradient for decoder.decoder.6.bias: 1.5567346054012887e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.0040054055862128735\n",
      "Gradient for encoder.encoder.0.bias: 8.072441153028631e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.00023707585933152586\n",
      "Gradient for encoder.encoder.1.bias: 0.00032477022614330053\n",
      "Gradient for encoder.encoder.3.weight: 0.0051684132777154446\n",
      "Gradient for encoder.encoder.3.bias: 8.838301618352418e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.0020293749403208494\n",
      "Gradient for encoder.encoder.4.bias: 0.0017694265116006136\n",
      "Gradient for encoder.mean.weight: 0.030181828886270523\n",
      "Gradient for encoder.mean.bias: 0.0012853550724685192\n",
      "Gradient for encoder.log_var.weight: 0.017872119322419167\n",
      "Gradient for encoder.log_var.bias: 0.0008821586379781365\n",
      "Gradient for decoder.decoder.0.weight: 0.009216166101396084\n",
      "Gradient for decoder.decoder.0.bias: 7.221937631252118e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.00046913744881749153\n",
      "Gradient for decoder.decoder.1.bias: 0.00038359759491868317\n",
      "Gradient for decoder.decoder.3.weight: 0.008786083199083805\n",
      "Gradient for decoder.decoder.3.bias: 7.385500544465629e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00042626584763638675\n",
      "Gradient for decoder.decoder.4.bias: 0.0004627029993571341\n",
      "Gradient for decoder.decoder.6.weight: 0.0004684371524490416\n",
      "Gradient for decoder.decoder.6.bias: 3.251261296099983e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.004015711601823568\n",
      "Gradient for encoder.encoder.0.bias: 7.821136099872561e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.0003378831606823951\n",
      "Gradient for encoder.encoder.1.bias: 0.0004917217302136123\n",
      "Gradient for encoder.encoder.3.weight: 0.006997353862971067\n",
      "Gradient for encoder.encoder.3.bias: 9.832445968527281e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.0023812183644622564\n",
      "Gradient for encoder.encoder.4.bias: 0.0019712536595761776\n",
      "Gradient for encoder.mean.weight: 0.0341949537396431\n",
      "Gradient for encoder.mean.bias: 0.0017194696702063084\n",
      "Gradient for encoder.log_var.weight: 0.021597951650619507\n",
      "Gradient for encoder.log_var.bias: 0.001144489157013595\n",
      "Gradient for decoder.decoder.0.weight: 0.010436560958623886\n",
      "Gradient for decoder.decoder.0.bias: 8.578621146781984e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.00045922663412056863\n",
      "Gradient for decoder.decoder.1.bias: 0.0004391755792312324\n",
      "Gradient for decoder.decoder.3.weight: 0.00987420603632927\n",
      "Gradient for decoder.decoder.3.bias: 6.41171837845178e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0003568553947843611\n",
      "Gradient for decoder.decoder.4.bias: 0.00031105297966860235\n",
      "Gradient for decoder.decoder.6.weight: 0.00043940747855231166\n",
      "Gradient for decoder.decoder.6.bias: 2.400705125182867e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.002670175628736615\n",
      "Gradient for encoder.encoder.0.bias: 5.44151442655183e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.00022840504243504256\n",
      "Gradient for encoder.encoder.1.bias: 0.000303135922877118\n",
      "Gradient for encoder.encoder.3.weight: 0.004925629589706659\n",
      "Gradient for encoder.encoder.3.bias: 7.679190616727283e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.0023194104433059692\n",
      "Gradient for encoder.encoder.4.bias: 0.0013073536101728678\n",
      "Gradient for encoder.mean.weight: 0.03406769037246704\n",
      "Gradient for encoder.mean.bias: 0.0010615014471113682\n",
      "Gradient for encoder.log_var.weight: 0.020924538373947144\n",
      "Gradient for encoder.log_var.bias: 0.0007267074543051422\n",
      "Gradient for decoder.decoder.0.weight: 0.012868993915617466\n",
      "Gradient for decoder.decoder.0.bias: 1.1390168669356271e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0006463647587224841\n",
      "Gradient for decoder.decoder.1.bias: 0.0005569853237830102\n",
      "Gradient for decoder.decoder.3.weight: 0.012316359207034111\n",
      "Gradient for decoder.decoder.3.bias: 9.524230015767188e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00043518442544154823\n",
      "Gradient for decoder.decoder.4.bias: 0.0003770494367927313\n",
      "Gradient for decoder.decoder.6.weight: 0.00047335680574178696\n",
      "Gradient for decoder.decoder.6.bias: 2.7143056286149658e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.0033496804535388947\n",
      "Gradient for encoder.encoder.0.bias: 7.384190481296571e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.0002761353680398315\n",
      "Gradient for encoder.encoder.1.bias: 0.00035125642898492515\n",
      "Gradient for encoder.encoder.3.weight: 0.005963990930467844\n",
      "Gradient for encoder.encoder.3.bias: 8.275566343307617e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.001872985390946269\n",
      "Gradient for encoder.encoder.4.bias: 0.0013836766593158245\n",
      "Gradient for encoder.mean.weight: 0.02611425705254078\n",
      "Gradient for encoder.mean.bias: 0.0010379579616710544\n",
      "Gradient for encoder.log_var.weight: 0.017009852454066277\n",
      "Gradient for encoder.log_var.bias: 0.000742751348298043\n",
      "Gradient for decoder.decoder.0.weight: 0.01072818785905838\n",
      "Gradient for decoder.decoder.0.bias: 9.017803170863203e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005358939524739981\n",
      "Gradient for decoder.decoder.1.bias: 0.0004237954271957278\n",
      "Gradient for decoder.decoder.3.weight: 0.010110564529895782\n",
      "Gradient for decoder.decoder.3.bias: 7.627073278504426e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00034483542549423873\n",
      "Gradient for decoder.decoder.4.bias: 0.0003050991508644074\n",
      "Gradient for decoder.decoder.6.weight: 0.00042648176895454526\n",
      "Gradient for decoder.decoder.6.bias: 2.124083948729094e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.00220286613330245\n",
      "Gradient for encoder.encoder.0.bias: 5.071493572317287e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.00022388533398043364\n",
      "Gradient for encoder.encoder.1.bias: 0.0003689840668812394\n",
      "Gradient for encoder.encoder.3.weight: 0.004902821034193039\n",
      "Gradient for encoder.encoder.3.bias: 7.894644660222383e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.002736660884693265\n",
      "Gradient for encoder.encoder.4.bias: 0.0018953600665554404\n",
      "Gradient for encoder.mean.weight: 0.04128531739115715\n",
      "Gradient for encoder.mean.bias: 0.00125727744307369\n",
      "Gradient for encoder.log_var.weight: 0.025791632011532784\n",
      "Gradient for encoder.log_var.bias: 0.000885280838701874\n",
      "Gradient for decoder.decoder.0.weight: 0.013286057859659195\n",
      "Gradient for decoder.decoder.0.bias: 1.0476988721030978e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0006871315999887884\n",
      "Gradient for decoder.decoder.1.bias: 0.0005765819805674255\n",
      "Gradient for decoder.decoder.3.weight: 0.012352341786026955\n",
      "Gradient for decoder.decoder.3.bias: 9.410393297937247e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0005209355731494725\n",
      "Gradient for decoder.decoder.4.bias: 0.0005272056441754103\n",
      "Gradient for decoder.decoder.6.weight: 0.0004450363921932876\n",
      "Gradient for decoder.decoder.6.bias: 2.5532079234835692e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.003426498034968972\n",
      "Gradient for encoder.encoder.0.bias: 7.945942515075188e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.0002533363294787705\n",
      "Gradient for encoder.encoder.1.bias: 0.0003271500172559172\n",
      "Gradient for encoder.encoder.3.weight: 0.005441450979560614\n",
      "Gradient for encoder.encoder.3.bias: 8.031015436005262e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.0021442153956741095\n",
      "Gradient for encoder.encoder.4.bias: 0.0014375433092936873\n",
      "Gradient for encoder.mean.weight: 0.03410547971725464\n",
      "Gradient for encoder.mean.bias: 0.0012283155228942633\n",
      "Gradient for encoder.log_var.weight: 0.018005602061748505\n",
      "Gradient for encoder.log_var.bias: 0.000766555720474571\n",
      "Gradient for decoder.decoder.0.weight: 0.010473925620317459\n",
      "Gradient for decoder.decoder.0.bias: 8.934369910562623e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0004901174106635153\n",
      "Gradient for decoder.decoder.1.bias: 0.00043180782813578844\n",
      "Gradient for decoder.decoder.3.weight: 0.010031027719378471\n",
      "Gradient for decoder.decoder.3.bias: 7.794192374843689e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0004588449955917895\n",
      "Gradient for decoder.decoder.4.bias: 0.0005231261602602899\n",
      "Gradient for decoder.decoder.6.weight: 0.000432919361628592\n",
      "Gradient for decoder.decoder.6.bias: 2.7233361834078096e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.0041389791294932365\n",
      "Gradient for encoder.encoder.0.bias: 1.1384269395231517e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.00037680950481444597\n",
      "Gradient for encoder.encoder.1.bias: 0.0005786201218143106\n",
      "Gradient for encoder.encoder.3.weight: 0.008075308986008167\n",
      "Gradient for encoder.encoder.3.bias: 9.073270607062867e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.0029594190418720245\n",
      "Gradient for encoder.encoder.4.bias: 0.001755783916451037\n",
      "Gradient for encoder.mean.weight: 0.04344823956489563\n",
      "Gradient for encoder.mean.bias: 0.0014502843841910362\n",
      "Gradient for encoder.log_var.weight: 0.023668821901082993\n",
      "Gradient for encoder.log_var.bias: 0.0009729431476444006\n",
      "Gradient for decoder.decoder.0.weight: 0.008144787512719631\n",
      "Gradient for decoder.decoder.0.bias: 6.976283439819042e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0003817079705186188\n",
      "Gradient for decoder.decoder.1.bias: 0.0003226371482014656\n",
      "Gradient for decoder.decoder.3.weight: 0.007854900322854519\n",
      "Gradient for decoder.decoder.3.bias: 8.317940086710607e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.000534858088940382\n",
      "Gradient for decoder.decoder.4.bias: 0.0006402662256732583\n",
      "Gradient for decoder.decoder.6.weight: 0.00046375044621527195\n",
      "Gradient for decoder.decoder.6.bias: 3.5669094359036535e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.0027694005984812975\n",
      "Gradient for encoder.encoder.0.bias: 5.374958724629897e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.00020148891780991107\n",
      "Gradient for encoder.encoder.1.bias: 0.00030510660144500434\n",
      "Gradient for encoder.encoder.3.weight: 0.004677257034927607\n",
      "Gradient for encoder.encoder.3.bias: 8.378908677997288e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.0022733609657734632\n",
      "Gradient for encoder.encoder.4.bias: 0.0015529213706031442\n",
      "Gradient for encoder.mean.weight: 0.0334332138299942\n",
      "Gradient for encoder.mean.bias: 0.0011445253621786833\n",
      "Gradient for encoder.log_var.weight: 0.02167901210486889\n",
      "Gradient for encoder.log_var.bias: 0.0008537691319361329\n",
      "Gradient for decoder.decoder.0.weight: 0.014393244870007038\n",
      "Gradient for decoder.decoder.0.bias: 1.2091454226759168e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0006862461450509727\n",
      "Gradient for decoder.decoder.1.bias: 0.0005499761900864542\n",
      "Gradient for decoder.decoder.3.weight: 0.013435009866952896\n",
      "Gradient for decoder.decoder.3.bias: 1.037146757365548e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0005461530527099967\n",
      "Gradient for decoder.decoder.4.bias: 0.0005653167609125376\n",
      "Gradient for decoder.decoder.6.weight: 0.0005259992904029787\n",
      "Gradient for decoder.decoder.6.bias: 3.4070781111950055e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.003839059267193079\n",
      "Gradient for encoder.encoder.0.bias: 7.738761888254064e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.0004190871841274202\n",
      "Gradient for encoder.encoder.1.bias: 0.0005270293331705034\n",
      "Gradient for encoder.encoder.3.weight: 0.00943530723452568\n",
      "Gradient for encoder.encoder.3.bias: 1.612496108860384e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0052482266910374165\n",
      "Gradient for encoder.encoder.4.bias: 0.003355365013703704\n",
      "Gradient for encoder.mean.weight: 0.08196237683296204\n",
      "Gradient for encoder.mean.bias: 0.0019461624324321747\n",
      "Gradient for encoder.log_var.weight: 0.04898970574140549\n",
      "Gradient for encoder.log_var.bias: 0.0020715564023703337\n",
      "Gradient for decoder.decoder.0.weight: 0.04966253787279129\n",
      "Gradient for decoder.decoder.0.bias: 3.148130922614456e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0020293905399739742\n",
      "Gradient for decoder.decoder.1.bias: 0.0018965094350278378\n",
      "Gradient for decoder.decoder.3.weight: 0.0462232381105423\n",
      "Gradient for decoder.decoder.3.bias: 3.388152258754218e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.001365200150758028\n",
      "Gradient for decoder.decoder.4.bias: 0.0012607277603819966\n",
      "Gradient for decoder.decoder.6.weight: 0.0011273499112576246\n",
      "Gradient for decoder.decoder.6.bias: 3.904475306626409e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/3, Train Loss: 0.0495, Val Loss: 0.2702\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training VAE Epoch:   1%|▏         | 1/79 [00:00<00:15,  5.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient for encoder.encoder.0.weight: 0.004382426850497723\n",
      "Gradient for encoder.encoder.0.bias: 7.981425416414556e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.000351951748598367\n",
      "Gradient for encoder.encoder.1.bias: 0.0004608249291777611\n",
      "Gradient for encoder.encoder.3.weight: 0.007767864037305117\n",
      "Gradient for encoder.encoder.3.bias: 1.2078026079276327e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.003309744643047452\n",
      "Gradient for encoder.encoder.4.bias: 0.0032247332856059074\n",
      "Gradient for encoder.mean.weight: 0.04874124005436897\n",
      "Gradient for encoder.mean.bias: 0.0024345959536731243\n",
      "Gradient for encoder.log_var.weight: 0.027269775047898293\n",
      "Gradient for encoder.log_var.bias: 0.0014966899761930108\n",
      "Gradient for decoder.decoder.0.weight: 0.009339941665530205\n",
      "Gradient for decoder.decoder.0.bias: 7.630292925275839e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.00047939372598193586\n",
      "Gradient for decoder.decoder.1.bias: 0.0003729972813744098\n",
      "Gradient for decoder.decoder.3.weight: 0.008741666562855244\n",
      "Gradient for decoder.decoder.3.bias: 6.29853807998515e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0003126180381514132\n",
      "Gradient for decoder.decoder.4.bias: 0.0002766696852631867\n",
      "Gradient for decoder.decoder.6.weight: 0.00042597585706971586\n",
      "Gradient for decoder.decoder.6.bias: 2.3791681087459438e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training VAE Epoch:  11%|█▏        | 9/79 [00:00<00:01, 35.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient for encoder.encoder.0.weight: 0.0031008312944322824\n",
      "Gradient for encoder.encoder.0.bias: 5.383194758012966e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.00023617033730261028\n",
      "Gradient for encoder.encoder.1.bias: 0.00030296528711915016\n",
      "Gradient for encoder.encoder.3.weight: 0.004998173099011183\n",
      "Gradient for encoder.encoder.3.bias: 8.600799933367043e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.0033001259434968233\n",
      "Gradient for encoder.encoder.4.bias: 0.0017626684857532382\n",
      "Gradient for encoder.mean.weight: 0.04921668767929077\n",
      "Gradient for encoder.mean.bias: 0.001185081317089498\n",
      "Gradient for encoder.log_var.weight: 0.029563330113887787\n",
      "Gradient for encoder.log_var.bias: 0.0010157565120607615\n",
      "Gradient for decoder.decoder.0.weight: 0.013664599508047104\n",
      "Gradient for decoder.decoder.0.bias: 1.1404869409981089e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0007038600742816925\n",
      "Gradient for decoder.decoder.1.bias: 0.0005241285543888807\n",
      "Gradient for decoder.decoder.3.weight: 0.012837274000048637\n",
      "Gradient for decoder.decoder.3.bias: 9.074659773622429e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0005076230154372752\n",
      "Gradient for decoder.decoder.4.bias: 0.00042993525858037174\n",
      "Gradient for decoder.decoder.6.weight: 0.0005304061342030764\n",
      "Gradient for decoder.decoder.6.bias: 3.1759067496750504e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.007077760528773069\n",
      "Gradient for encoder.encoder.0.bias: 1.576514266354856e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0004344504268374294\n",
      "Gradient for encoder.encoder.1.bias: 0.0005359476781450212\n",
      "Gradient for encoder.encoder.3.weight: 0.009499787352979183\n",
      "Gradient for encoder.encoder.3.bias: 1.0729002408726984e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0034349029883742332\n",
      "Gradient for encoder.encoder.4.bias: 0.002029075985774398\n",
      "Gradient for encoder.mean.weight: 0.04844439774751663\n",
      "Gradient for encoder.mean.bias: 0.001421427703462541\n",
      "Gradient for encoder.log_var.weight: 0.02797042205929756\n",
      "Gradient for encoder.log_var.bias: 0.0010492118308320642\n",
      "Gradient for decoder.decoder.0.weight: 0.006933302618563175\n",
      "Gradient for decoder.decoder.0.bias: 5.898084798339198e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.00033985884510912\n",
      "Gradient for decoder.decoder.1.bias: 0.0003113805432803929\n",
      "Gradient for decoder.decoder.3.weight: 0.006486524362117052\n",
      "Gradient for decoder.decoder.3.bias: 8.022662395523739e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0005560973659157753\n",
      "Gradient for decoder.decoder.4.bias: 0.000693518843036145\n",
      "Gradient for decoder.decoder.6.weight: 0.0004968768334947526\n",
      "Gradient for decoder.decoder.6.bias: 4.202996569802053e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.002835571300238371\n",
      "Gradient for encoder.encoder.0.bias: 5.237834038024358e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.00024676142493262887\n",
      "Gradient for encoder.encoder.1.bias: 0.000399478041799739\n",
      "Gradient for encoder.encoder.3.weight: 0.0052049956284463406\n",
      "Gradient for encoder.encoder.3.bias: 8.772513965249473e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.0030419309623539448\n",
      "Gradient for encoder.encoder.4.bias: 0.0018851392669603229\n",
      "Gradient for encoder.mean.weight: 0.045844051986932755\n",
      "Gradient for encoder.mean.bias: 0.0013278961414471269\n",
      "Gradient for encoder.log_var.weight: 0.028017019852995872\n",
      "Gradient for encoder.log_var.bias: 0.0010131181916221976\n",
      "Gradient for decoder.decoder.0.weight: 0.012459118850529194\n",
      "Gradient for decoder.decoder.0.bias: 9.52409123788911e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005955954547971487\n",
      "Gradient for decoder.decoder.1.bias: 0.0005127204349264503\n",
      "Gradient for decoder.decoder.3.weight: 0.01261003129184246\n",
      "Gradient for decoder.decoder.3.bias: 8.777779891833148e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0004554795450530946\n",
      "Gradient for decoder.decoder.4.bias: 0.0003930654493160546\n",
      "Gradient for decoder.decoder.6.weight: 0.00045719966874457896\n",
      "Gradient for decoder.decoder.6.bias: 2.0094661522307433e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.003978588152676821\n",
      "Gradient for encoder.encoder.0.bias: 1.0044272705234114e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.000305227906210348\n",
      "Gradient for encoder.encoder.1.bias: 0.00046533203567378223\n",
      "Gradient for encoder.encoder.3.weight: 0.006240122951567173\n",
      "Gradient for encoder.encoder.3.bias: 8.988301769541351e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.002501115668565035\n",
      "Gradient for encoder.encoder.4.bias: 0.0016280094860121608\n",
      "Gradient for encoder.mean.weight: 0.039548419415950775\n",
      "Gradient for encoder.mean.bias: 0.0012209480628371239\n",
      "Gradient for encoder.log_var.weight: 0.02296217530965805\n",
      "Gradient for encoder.log_var.bias: 0.0008323144284076989\n",
      "Gradient for decoder.decoder.0.weight: 0.008387879468500614\n",
      "Gradient for decoder.decoder.0.bias: 7.262564855059495e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0004193468193989247\n",
      "Gradient for decoder.decoder.1.bias: 0.00033959370921365917\n",
      "Gradient for decoder.decoder.3.weight: 0.007705156225711107\n",
      "Gradient for decoder.decoder.3.bias: 9.659361505098829e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0006066763307899237\n",
      "Gradient for decoder.decoder.4.bias: 0.0007498090271838009\n",
      "Gradient for decoder.decoder.6.weight: 0.000503104121889919\n",
      "Gradient for decoder.decoder.6.bias: 4.1984018025686964e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.0033447497989982367\n",
      "Gradient for encoder.encoder.0.bias: 7.188613853487125e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.0002927084278780967\n",
      "Gradient for encoder.encoder.1.bias: 0.000443286873633042\n",
      "Gradient for encoder.encoder.3.weight: 0.006233299151062965\n",
      "Gradient for encoder.encoder.3.bias: 1.0769648367547902e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0026191622018814087\n",
      "Gradient for encoder.encoder.4.bias: 0.0025744044687598944\n",
      "Gradient for encoder.mean.weight: 0.040954165160655975\n",
      "Gradient for encoder.mean.bias: 0.0020576096139848232\n",
      "Gradient for encoder.log_var.weight: 0.0207245834171772\n",
      "Gradient for encoder.log_var.bias: 0.0012774565257132053\n",
      "Gradient for decoder.decoder.0.weight: 0.00997298862785101\n",
      "Gradient for decoder.decoder.0.bias: 8.391538158791789e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.00047221488784998655\n",
      "Gradient for decoder.decoder.1.bias: 0.00040566566167399287\n",
      "Gradient for decoder.decoder.3.weight: 0.009361441247165203\n",
      "Gradient for decoder.decoder.3.bias: 9.102624903833956e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0004791035607922822\n",
      "Gradient for decoder.decoder.4.bias: 0.0005275400471873581\n",
      "Gradient for decoder.decoder.6.weight: 0.0004315958358347416\n",
      "Gradient for decoder.decoder.6.bias: 2.9106755391694605e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.005157555919140577\n",
      "Gradient for encoder.encoder.0.bias: 1.1543501397814904e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.00032391431159339845\n",
      "Gradient for encoder.encoder.1.bias: 0.0003648791171144694\n",
      "Gradient for encoder.encoder.3.weight: 0.006971983704715967\n",
      "Gradient for encoder.encoder.3.bias: 9.044872489871736e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.0024565865751355886\n",
      "Gradient for encoder.encoder.4.bias: 0.0018229817505925894\n",
      "Gradient for encoder.mean.weight: 0.03529033064842224\n",
      "Gradient for encoder.mean.bias: 0.0013825674541294575\n",
      "Gradient for encoder.log_var.weight: 0.021881679072976112\n",
      "Gradient for encoder.log_var.bias: 0.0009320336976088583\n",
      "Gradient for decoder.decoder.0.weight: 0.008085670880973339\n",
      "Gradient for decoder.decoder.0.bias: 6.923867035268927e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.00039222583291120827\n",
      "Gradient for decoder.decoder.1.bias: 0.0003300789394415915\n",
      "Gradient for decoder.decoder.3.weight: 0.007729589473456144\n",
      "Gradient for decoder.decoder.3.bias: 6.159128068672359e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0003659069770947099\n",
      "Gradient for decoder.decoder.4.bias: 0.0003763831336982548\n",
      "Gradient for decoder.decoder.6.weight: 0.0004109673900529742\n",
      "Gradient for decoder.decoder.6.bias: 2.5736106181284413e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.002550129545852542\n",
      "Gradient for encoder.encoder.0.bias: 5.4360235930694945e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.0001894827582873404\n",
      "Gradient for encoder.encoder.1.bias: 0.00030930867069400847\n",
      "Gradient for encoder.encoder.3.weight: 0.004349253140389919\n",
      "Gradient for encoder.encoder.3.bias: 9.135756040556942e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.002935329219326377\n",
      "Gradient for encoder.encoder.4.bias: 0.0021914353128522635\n",
      "Gradient for encoder.mean.weight: 0.042884837836027145\n",
      "Gradient for encoder.mean.bias: 0.0018290982116013765\n",
      "Gradient for encoder.log_var.weight: 0.02694687433540821\n",
      "Gradient for encoder.log_var.bias: 0.001271862187422812\n",
      "Gradient for decoder.decoder.0.weight: 0.01144061703234911\n",
      "Gradient for decoder.decoder.0.bias: 9.338202433539777e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005544601008296013\n",
      "Gradient for decoder.decoder.1.bias: 0.00047590062604285777\n",
      "Gradient for decoder.decoder.3.weight: 0.011044546030461788\n",
      "Gradient for decoder.decoder.3.bias: 8.386811384264448e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0004018207546323538\n",
      "Gradient for decoder.decoder.4.bias: 0.00035801721969619393\n",
      "Gradient for decoder.decoder.6.weight: 0.0004487234400585294\n",
      "Gradient for decoder.decoder.6.bias: 2.147621489712037e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.002351602539420128\n",
      "Gradient for encoder.encoder.0.bias: 4.395624489395011e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.0002437163348076865\n",
      "Gradient for encoder.encoder.1.bias: 0.00038950960151851177\n",
      "Gradient for encoder.encoder.3.weight: 0.005365137942135334\n",
      "Gradient for encoder.encoder.3.bias: 8.818435565105531e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.0034714590292423964\n",
      "Gradient for encoder.encoder.4.bias: 0.0022583240643143654\n",
      "Gradient for encoder.mean.weight: 0.0490957647562027\n",
      "Gradient for encoder.mean.bias: 0.0016622556140646338\n",
      "Gradient for encoder.log_var.weight: 0.033556725829839706\n",
      "Gradient for encoder.log_var.bias: 0.0011222392786294222\n",
      "Gradient for decoder.decoder.0.weight: 0.014672160148620605\n",
      "Gradient for decoder.decoder.0.bias: 1.229469026586827e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0007939682109281421\n",
      "Gradient for decoder.decoder.1.bias: 0.0005981375579722226\n",
      "Gradient for decoder.decoder.3.weight: 0.01492297649383545\n",
      "Gradient for decoder.decoder.3.bias: 1.0969530839233244e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0005841695237904787\n",
      "Gradient for decoder.decoder.4.bias: 0.0005508489557541907\n",
      "Gradient for decoder.decoder.6.weight: 0.0005289062391966581\n",
      "Gradient for decoder.decoder.6.bias: 3.130217737634666e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.004317653365433216\n",
      "Gradient for encoder.encoder.0.bias: 8.691959478557276e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.00031137149198912084\n",
      "Gradient for encoder.encoder.1.bias: 0.0003805502492468804\n",
      "Gradient for encoder.encoder.3.weight: 0.007010211236774921\n",
      "Gradient for encoder.encoder.3.bias: 9.355302643676566e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.0023048236034810543\n",
      "Gradient for encoder.encoder.4.bias: 0.0017067899461835623\n",
      "Gradient for encoder.mean.weight: 0.035893622785806656\n",
      "Gradient for encoder.mean.bias: 0.0013466067612171173\n",
      "Gradient for encoder.log_var.weight: 0.019880376756191254\n",
      "Gradient for encoder.log_var.bias: 0.0008814773173071444\n",
      "Gradient for decoder.decoder.0.weight: 0.00957814697176218\n",
      "Gradient for decoder.decoder.0.bias: 7.382734701355531e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.00048500107368454337\n",
      "Gradient for decoder.decoder.1.bias: 0.000402874662540853\n",
      "Gradient for decoder.decoder.3.weight: 0.00934592541307211\n",
      "Gradient for decoder.decoder.3.bias: 7.389959477688279e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0003902086173184216\n",
      "Gradient for decoder.decoder.4.bias: 0.00033618698944337666\n",
      "Gradient for decoder.decoder.6.weight: 0.0004796395660378039\n",
      "Gradient for decoder.decoder.6.bias: 2.916504854511004e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.0028590087313205004\n",
      "Gradient for encoder.encoder.0.bias: 5.5090159864490396e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.0002557842235546559\n",
      "Gradient for encoder.encoder.1.bias: 0.00033193480339832604\n",
      "Gradient for encoder.encoder.3.weight: 0.005752833094447851\n",
      "Gradient for encoder.encoder.3.bias: 8.43164010833064e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.002678387798368931\n",
      "Gradient for encoder.encoder.4.bias: 0.001613922300748527\n",
      "Gradient for encoder.mean.weight: 0.03955559805035591\n",
      "Gradient for encoder.mean.bias: 0.0011292491108179092\n",
      "Gradient for encoder.log_var.weight: 0.023068809881806374\n",
      "Gradient for encoder.log_var.bias: 0.0008353583980351686\n",
      "Gradient for decoder.decoder.0.weight: 0.01368071511387825\n",
      "Gradient for decoder.decoder.0.bias: 1.017119860557969e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0007181031978689134\n",
      "Gradient for decoder.decoder.1.bias: 0.0005151151563040912\n",
      "Gradient for decoder.decoder.3.weight: 0.01322480570524931\n",
      "Gradient for decoder.decoder.3.bias: 9.171970821730824e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0005581515142694116\n",
      "Gradient for decoder.decoder.4.bias: 0.0005227724905125797\n",
      "Gradient for decoder.decoder.6.weight: 0.0004958814824931324\n",
      "Gradient for decoder.decoder.6.bias: 2.8818158170906827e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.0026694354601204395\n",
      "Gradient for encoder.encoder.0.bias: 5.2722223288503844e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.00023252774553839117\n",
      "Gradient for encoder.encoder.1.bias: 0.00045941531425341964\n",
      "Gradient for encoder.encoder.3.weight: 0.005239284597337246\n",
      "Gradient for encoder.encoder.3.bias: 1.0253468907261976e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.003212522715330124\n",
      "Gradient for encoder.encoder.4.bias: 0.002472963649779558\n",
      "Gradient for encoder.mean.weight: 0.046459879726171494\n",
      "Gradient for encoder.mean.bias: 0.0018037131521850824\n",
      "Gradient for encoder.log_var.weight: 0.02707454189658165\n",
      "Gradient for encoder.log_var.bias: 0.0012514609843492508\n",
      "Gradient for decoder.decoder.0.weight: 0.013485361821949482\n",
      "Gradient for decoder.decoder.0.bias: 1.065875790406956e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0006495484849438071\n",
      "Gradient for decoder.decoder.1.bias: 0.0005499626859091222\n",
      "Gradient for decoder.decoder.3.weight: 0.01319166924804449\n",
      "Gradient for decoder.decoder.3.bias: 8.373498422420411e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0004715317627415061\n",
      "Gradient for decoder.decoder.4.bias: 0.0004105267580598593\n",
      "Gradient for decoder.decoder.6.weight: 0.0004313139943405986\n",
      "Gradient for decoder.decoder.6.bias: 1.8905850083683617e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.003558301366865635\n",
      "Gradient for encoder.encoder.0.bias: 8.485941983826795e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.00032537771039642394\n",
      "Gradient for encoder.encoder.1.bias: 0.0004732091911137104\n",
      "Gradient for encoder.encoder.3.weight: 0.006975346244871616\n",
      "Gradient for encoder.encoder.3.bias: 9.081216334472231e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.002924097701907158\n",
      "Gradient for encoder.encoder.4.bias: 0.001728324918076396\n",
      "Gradient for encoder.mean.weight: 0.04338345304131508\n",
      "Gradient for encoder.mean.bias: 0.0013088942505419254\n",
      "Gradient for encoder.log_var.weight: 0.02631095051765442\n",
      "Gradient for encoder.log_var.bias: 0.0010025184601545334\n",
      "Gradient for decoder.decoder.0.weight: 0.009202671237289906\n",
      "Gradient for decoder.decoder.0.bias: 7.634934351408162e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.00046191210276447237\n",
      "Gradient for decoder.decoder.1.bias: 0.00039251442649401724\n",
      "Gradient for decoder.decoder.3.weight: 0.008800038136541843\n",
      "Gradient for decoder.decoder.3.bias: 7.270751362087324e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00040350898052565753\n",
      "Gradient for decoder.decoder.4.bias: 0.0004254367377143353\n",
      "Gradient for decoder.decoder.6.weight: 0.0004402852791827172\n",
      "Gradient for decoder.decoder.6.bias: 3.085018033743836e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.0029489113949239254\n",
      "Gradient for encoder.encoder.0.bias: 7.03160576639994e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.00025227811420336366\n",
      "Gradient for encoder.encoder.1.bias: 0.000419026444433257\n",
      "Gradient for encoder.encoder.3.weight: 0.005505590233951807\n",
      "Gradient for encoder.encoder.3.bias: 8.893900893536255e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.0028038611635565758\n",
      "Gradient for encoder.encoder.4.bias: 0.002160929376259446\n",
      "Gradient for encoder.mean.weight: 0.039891891181468964\n",
      "Gradient for encoder.mean.bias: 0.0018528996733948588\n",
      "Gradient for encoder.log_var.weight: 0.025351790711283684\n",
      "Gradient for encoder.log_var.bias: 0.0012330515310168266\n",
      "Gradient for decoder.decoder.0.weight: 0.010367273353040218\n",
      "Gradient for decoder.decoder.0.bias: 8.744951290884373e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0004642614512704313\n",
      "Gradient for decoder.decoder.1.bias: 0.00043599915807135403\n",
      "Gradient for decoder.decoder.3.weight: 0.00961554516106844\n",
      "Gradient for decoder.decoder.3.bias: 8.11803055333904e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00047937288763932884\n",
      "Gradient for decoder.decoder.4.bias: 0.00050823186757043\n",
      "Gradient for decoder.decoder.6.weight: 0.0004537111090030521\n",
      "Gradient for decoder.decoder.6.bias: 3.0282339139375836e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.0038803524803370237\n",
      "Gradient for encoder.encoder.0.bias: 6.825883608341243e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.00024816024233587086\n",
      "Gradient for encoder.encoder.1.bias: 0.00028631967143155634\n",
      "Gradient for encoder.encoder.3.weight: 0.005487652495503426\n",
      "Gradient for encoder.encoder.3.bias: 9.21733869785335e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.002788705751299858\n",
      "Gradient for encoder.encoder.4.bias: 0.0020820938516408205\n",
      "Gradient for encoder.mean.weight: 0.03823225572705269\n",
      "Gradient for encoder.mean.bias: 0.001572730834595859\n",
      "Gradient for encoder.log_var.weight: 0.023640790954232216\n",
      "Gradient for encoder.log_var.bias: 0.0009876617696136236\n",
      "Gradient for decoder.decoder.0.weight: 0.010030200704932213\n",
      "Gradient for decoder.decoder.0.bias: 7.372670529637304e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0004627806774806231\n",
      "Gradient for decoder.decoder.1.bias: 0.0004046816029585898\n",
      "Gradient for decoder.decoder.3.weight: 0.009067068807780743\n",
      "Gradient for decoder.decoder.3.bias: 6.899088939027465e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0003165941743645817\n",
      "Gradient for decoder.decoder.4.bias: 0.0002679872268345207\n",
      "Gradient for decoder.decoder.6.weight: 0.00043166943942196667\n",
      "Gradient for decoder.decoder.6.bias: 2.3823522496968508e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.002542097121477127\n",
      "Gradient for encoder.encoder.0.bias: 5.299915454420878e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.00017836049664765596\n",
      "Gradient for encoder.encoder.1.bias: 0.00025490837288089097\n",
      "Gradient for encoder.encoder.3.weight: 0.004064282868057489\n",
      "Gradient for encoder.encoder.3.bias: 8.61088284009881e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.00267933146096766\n",
      "Gradient for encoder.encoder.4.bias: 0.001995069906115532\n",
      "Gradient for encoder.mean.weight: 0.03881705924868584\n",
      "Gradient for encoder.mean.bias: 0.0015200518537312746\n",
      "Gradient for encoder.log_var.weight: 0.024981563910841942\n",
      "Gradient for encoder.log_var.bias: 0.0011240635067224503\n",
      "Gradient for decoder.decoder.0.weight: 0.014158387668430805\n",
      "Gradient for decoder.decoder.0.bias: 1.2646693414719579e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0006658173515461385\n",
      "Gradient for decoder.decoder.1.bias: 0.0005272876005619764\n",
      "Gradient for decoder.decoder.3.weight: 0.012233905494213104\n",
      "Gradient for decoder.decoder.3.bias: 8.855934735541027e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.000415968825109303\n",
      "Gradient for decoder.decoder.4.bias: 0.00035817656316794455\n",
      "Gradient for decoder.decoder.6.weight: 0.00043153809383511543\n",
      "Gradient for decoder.decoder.6.bias: 2.2400303350877948e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.002567863557487726\n",
      "Gradient for encoder.encoder.0.bias: 5.680365899873863e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.00020933078485541046\n",
      "Gradient for encoder.encoder.1.bias: 0.00032260623993352056\n",
      "Gradient for encoder.encoder.3.weight: 0.004749591462314129\n",
      "Gradient for encoder.encoder.3.bias: 7.452664180229718e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.002777589252218604\n",
      "Gradient for encoder.encoder.4.bias: 0.0014195803087204695\n",
      "Gradient for encoder.mean.weight: 0.039345115423202515\n",
      "Gradient for encoder.mean.bias: 0.0010971250012516975\n",
      "Gradient for encoder.log_var.weight: 0.023189673200249672\n",
      "Gradient for encoder.log_var.bias: 0.0007280693389475346\n",
      "Gradient for decoder.decoder.0.weight: 0.011999404989182949\n",
      "Gradient for decoder.decoder.0.bias: 9.552651031308201e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005595803377218544\n",
      "Gradient for decoder.decoder.1.bias: 0.0004968378343619406\n",
      "Gradient for decoder.decoder.3.weight: 0.011217431165277958\n",
      "Gradient for decoder.decoder.3.bias: 8.057918915449491e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.000434964953456074\n",
      "Gradient for decoder.decoder.4.bias: 0.00040303150308318436\n",
      "Gradient for decoder.decoder.6.weight: 0.00041971408063545823\n",
      "Gradient for decoder.decoder.6.bias: 2.3398719349643216e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training VAE Epoch:  32%|███▏      | 25/79 [00:00<00:00, 60.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient for encoder.encoder.0.weight: 0.003978434484452009\n",
      "Gradient for encoder.encoder.0.bias: 8.966812535537994e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.0003643568488769233\n",
      "Gradient for encoder.encoder.1.bias: 0.0003971965052187443\n",
      "Gradient for encoder.encoder.3.weight: 0.007597909774631262\n",
      "Gradient for encoder.encoder.3.bias: 1.1256093279676804e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.002753926906734705\n",
      "Gradient for encoder.encoder.4.bias: 0.0026340868789702654\n",
      "Gradient for encoder.mean.weight: 0.038327235728502274\n",
      "Gradient for encoder.mean.bias: 0.0018995304126292467\n",
      "Gradient for encoder.log_var.weight: 0.02355838380753994\n",
      "Gradient for encoder.log_var.bias: 0.0012145941145718098\n",
      "Gradient for decoder.decoder.0.weight: 0.008995231240987778\n",
      "Gradient for decoder.decoder.0.bias: 7.739195395650711e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0004281432484276593\n",
      "Gradient for decoder.decoder.1.bias: 0.0003686714044306427\n",
      "Gradient for decoder.decoder.3.weight: 0.008126073516905308\n",
      "Gradient for decoder.decoder.3.bias: 6.562764220952033e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0002805641561280936\n",
      "Gradient for decoder.decoder.4.bias: 0.00025337981060147285\n",
      "Gradient for decoder.decoder.6.weight: 0.0003887919883709401\n",
      "Gradient for decoder.decoder.6.bias: 2.1817371816723607e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.0028219008818268776\n",
      "Gradient for encoder.encoder.0.bias: 7.080218789728976e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.0002417856885585934\n",
      "Gradient for encoder.encoder.1.bias: 0.0003904015466105193\n",
      "Gradient for encoder.encoder.3.weight: 0.005231047514826059\n",
      "Gradient for encoder.encoder.3.bias: 7.279465225051851e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.002918542828410864\n",
      "Gradient for encoder.encoder.4.bias: 0.0014926688745617867\n",
      "Gradient for encoder.mean.weight: 0.04407230764627457\n",
      "Gradient for encoder.mean.bias: 0.001202483312226832\n",
      "Gradient for encoder.log_var.weight: 0.02636866830289364\n",
      "Gradient for encoder.log_var.bias: 0.0007911912980489433\n",
      "Gradient for decoder.decoder.0.weight: 0.009726202115416527\n",
      "Gradient for decoder.decoder.0.bias: 8.0051902606737e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.000488406396470964\n",
      "Gradient for decoder.decoder.1.bias: 0.000421652541263029\n",
      "Gradient for decoder.decoder.3.weight: 0.009551315568387508\n",
      "Gradient for decoder.decoder.3.bias: 6.982741468375409e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00041512810275889933\n",
      "Gradient for decoder.decoder.4.bias: 0.0004196398367639631\n",
      "Gradient for decoder.decoder.6.weight: 0.00042037441744469106\n",
      "Gradient for decoder.decoder.6.bias: 2.6307981897844e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.0028488803654909134\n",
      "Gradient for encoder.encoder.0.bias: 4.542480107339042e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.0002345939283259213\n",
      "Gradient for encoder.encoder.1.bias: 0.0002977365511469543\n",
      "Gradient for encoder.encoder.3.weight: 0.005419807508587837\n",
      "Gradient for encoder.encoder.3.bias: 1.0335710759479255e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0026226453483104706\n",
      "Gradient for encoder.encoder.4.bias: 0.0019963677041232586\n",
      "Gradient for encoder.mean.weight: 0.041293103247880936\n",
      "Gradient for encoder.mean.bias: 0.001390857039950788\n",
      "Gradient for encoder.log_var.weight: 0.025019101798534393\n",
      "Gradient for encoder.log_var.bias: 0.001061821822077036\n",
      "Gradient for decoder.decoder.0.weight: 0.017538350075483322\n",
      "Gradient for decoder.decoder.0.bias: 1.5047173229643107e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0008649995434097946\n",
      "Gradient for decoder.decoder.1.bias: 0.0007201110129244626\n",
      "Gradient for decoder.decoder.3.weight: 0.016395507380366325\n",
      "Gradient for decoder.decoder.3.bias: 1.9066784262555814e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0012525931233540177\n",
      "Gradient for decoder.decoder.4.bias: 0.0015267719281837344\n",
      "Gradient for decoder.decoder.6.weight: 0.000887933885678649\n",
      "Gradient for decoder.decoder.6.bias: 7.817860023351386e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.00495166564360261\n",
      "Gradient for encoder.encoder.0.bias: 1.2662341661306975e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0002741619246080518\n",
      "Gradient for encoder.encoder.1.bias: 0.0003837279218714684\n",
      "Gradient for encoder.encoder.3.weight: 0.006138526368886232\n",
      "Gradient for encoder.encoder.3.bias: 8.991019040394121e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.0021417096722871065\n",
      "Gradient for encoder.encoder.4.bias: 0.0016482473583891988\n",
      "Gradient for encoder.mean.weight: 0.033510155975818634\n",
      "Gradient for encoder.mean.bias: 0.001266004634089768\n",
      "Gradient for encoder.log_var.weight: 0.020987501367926598\n",
      "Gradient for encoder.log_var.bias: 0.0008743835496716201\n",
      "Gradient for decoder.decoder.0.weight: 0.007813818752765656\n",
      "Gradient for decoder.decoder.0.bias: 6.889661757769616e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0003898215654771775\n",
      "Gradient for decoder.decoder.1.bias: 0.00031623023096472025\n",
      "Gradient for decoder.decoder.3.weight: 0.007202689070254564\n",
      "Gradient for decoder.decoder.3.bias: 8.315420574334098e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0005489799077622592\n",
      "Gradient for decoder.decoder.4.bias: 0.0006771753542125225\n",
      "Gradient for decoder.decoder.6.weight: 0.0004516936605796218\n",
      "Gradient for decoder.decoder.6.bias: 3.587172250263393e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.0027648131363093853\n",
      "Gradient for encoder.encoder.0.bias: 5.87392417691901e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.0002695653820410371\n",
      "Gradient for encoder.encoder.1.bias: 0.0003666906850412488\n",
      "Gradient for encoder.encoder.3.weight: 0.005975665524601936\n",
      "Gradient for encoder.encoder.3.bias: 9.600843731139008e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.002533076796680689\n",
      "Gradient for encoder.encoder.4.bias: 0.0022236111108213663\n",
      "Gradient for encoder.mean.weight: 0.038805559277534485\n",
      "Gradient for encoder.mean.bias: 0.0017263928893953562\n",
      "Gradient for encoder.log_var.weight: 0.024779973551630974\n",
      "Gradient for encoder.log_var.bias: 0.0011712467530742288\n",
      "Gradient for decoder.decoder.0.weight: 0.011778652667999268\n",
      "Gradient for decoder.decoder.0.bias: 1.0105558057027508e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0005527465254999697\n",
      "Gradient for decoder.decoder.1.bias: 0.0004687838663812727\n",
      "Gradient for decoder.decoder.3.weight: 0.010632423684000969\n",
      "Gradient for decoder.decoder.3.bias: 8.432400611102508e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00041409843834117055\n",
      "Gradient for decoder.decoder.4.bias: 0.0003558637108653784\n",
      "Gradient for decoder.decoder.6.weight: 0.0004790791717823595\n",
      "Gradient for decoder.decoder.6.bias: 3.018824827449862e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.0030816998332738876\n",
      "Gradient for encoder.encoder.0.bias: 6.044313487219011e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.00026847352273762226\n",
      "Gradient for encoder.encoder.1.bias: 0.0003801989369094372\n",
      "Gradient for encoder.encoder.3.weight: 0.00600867485627532\n",
      "Gradient for encoder.encoder.3.bias: 8.570275739083755e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.0026250514201819897\n",
      "Gradient for encoder.encoder.4.bias: 0.001968181226402521\n",
      "Gradient for encoder.mean.weight: 0.03967994451522827\n",
      "Gradient for encoder.mean.bias: 0.0015229849377647042\n",
      "Gradient for encoder.log_var.weight: 0.022041181102395058\n",
      "Gradient for encoder.log_var.bias: 0.0010680389823392034\n",
      "Gradient for decoder.decoder.0.weight: 0.01234885398298502\n",
      "Gradient for decoder.decoder.0.bias: 9.433212544429637e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0006439590360969305\n",
      "Gradient for decoder.decoder.1.bias: 0.0004741639131680131\n",
      "Gradient for decoder.decoder.3.weight: 0.012139366008341312\n",
      "Gradient for decoder.decoder.3.bias: 8.614890051328317e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00047389522660523653\n",
      "Gradient for decoder.decoder.4.bias: 0.0004588523006532341\n",
      "Gradient for decoder.decoder.6.weight: 0.0004660765116568655\n",
      "Gradient for decoder.decoder.6.bias: 2.3213759050122462e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.0031378662679344416\n",
      "Gradient for encoder.encoder.0.bias: 5.9257772300203015e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.00025161891244351864\n",
      "Gradient for encoder.encoder.1.bias: 0.0003497390716802329\n",
      "Gradient for encoder.encoder.3.weight: 0.005496262572705746\n",
      "Gradient for encoder.encoder.3.bias: 9.104719062014155e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.0026290316600352526\n",
      "Gradient for encoder.encoder.4.bias: 0.0018506731139495969\n",
      "Gradient for encoder.mean.weight: 0.03789970278739929\n",
      "Gradient for encoder.mean.bias: 0.0014593435917049646\n",
      "Gradient for encoder.log_var.weight: 0.02280893176794052\n",
      "Gradient for encoder.log_var.bias: 0.0009483425528742373\n",
      "Gradient for decoder.decoder.0.weight: 0.012355788610875607\n",
      "Gradient for decoder.decoder.0.bias: 9.64986285323377e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0006283713737502694\n",
      "Gradient for decoder.decoder.1.bias: 0.0004904255620203912\n",
      "Gradient for decoder.decoder.3.weight: 0.011950635351240635\n",
      "Gradient for decoder.decoder.3.bias: 9.118033411636972e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0004665013402700424\n",
      "Gradient for decoder.decoder.4.bias: 0.0004314432153478265\n",
      "Gradient for decoder.decoder.6.weight: 0.00046286385622806847\n",
      "Gradient for decoder.decoder.6.bias: 2.157911512767896e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.0027498609852045774\n",
      "Gradient for encoder.encoder.0.bias: 6.410092075193052e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.0002649835078045726\n",
      "Gradient for encoder.encoder.1.bias: 0.00039691824349574745\n",
      "Gradient for encoder.encoder.3.weight: 0.005599815398454666\n",
      "Gradient for encoder.encoder.3.bias: 9.147729101988133e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.0026216451078653336\n",
      "Gradient for encoder.encoder.4.bias: 0.0019575997721403837\n",
      "Gradient for encoder.mean.weight: 0.03864109888672829\n",
      "Gradient for encoder.mean.bias: 0.0014614075189456344\n",
      "Gradient for encoder.log_var.weight: 0.024294354021549225\n",
      "Gradient for encoder.log_var.bias: 0.0009704222320578992\n",
      "Gradient for decoder.decoder.0.weight: 0.011805465444922447\n",
      "Gradient for decoder.decoder.0.bias: 1.0858676458003202e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0005696906591765583\n",
      "Gradient for decoder.decoder.1.bias: 0.00048331471043638885\n",
      "Gradient for decoder.decoder.3.weight: 0.010954929515719414\n",
      "Gradient for decoder.decoder.3.bias: 8.02165209257133e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00039471505442634225\n",
      "Gradient for decoder.decoder.4.bias: 0.00032128565362654626\n",
      "Gradient for decoder.decoder.6.weight: 0.000437887676525861\n",
      "Gradient for decoder.decoder.6.bias: 2.1660889615304768e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.002428758190944791\n",
      "Gradient for encoder.encoder.0.bias: 4.901735701362542e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.0001692427322268486\n",
      "Gradient for encoder.encoder.1.bias: 0.00026461726520210505\n",
      "Gradient for encoder.encoder.3.weight: 0.0036130910739302635\n",
      "Gradient for encoder.encoder.3.bias: 8.141035068298663e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.00239489134401083\n",
      "Gradient for encoder.encoder.4.bias: 0.0016138040227815509\n",
      "Gradient for encoder.mean.weight: 0.035569947212934494\n",
      "Gradient for encoder.mean.bias: 0.001093090744689107\n",
      "Gradient for encoder.log_var.weight: 0.023183992132544518\n",
      "Gradient for encoder.log_var.bias: 0.0008937458624131978\n",
      "Gradient for decoder.decoder.0.weight: 0.014091567136347294\n",
      "Gradient for decoder.decoder.0.bias: 1.126922721805812e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0006901900051161647\n",
      "Gradient for decoder.decoder.1.bias: 0.0005627346690744162\n",
      "Gradient for decoder.decoder.3.weight: 0.01322358101606369\n",
      "Gradient for decoder.decoder.3.bias: 9.100134534811843e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0005074412329122424\n",
      "Gradient for decoder.decoder.4.bias: 0.00042113650124520063\n",
      "Gradient for decoder.decoder.6.weight: 0.0004809750826098025\n",
      "Gradient for decoder.decoder.6.bias: 2.295863305334933e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.0036041783168911934\n",
      "Gradient for encoder.encoder.0.bias: 7.557476346120584e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.0003141628985758871\n",
      "Gradient for encoder.encoder.1.bias: 0.0004334612167440355\n",
      "Gradient for encoder.encoder.3.weight: 0.0071107372641563416\n",
      "Gradient for encoder.encoder.3.bias: 9.464531935954312e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.002837178763002157\n",
      "Gradient for encoder.encoder.4.bias: 0.0019304302986711264\n",
      "Gradient for encoder.mean.weight: 0.040644142776727676\n",
      "Gradient for encoder.mean.bias: 0.001420504180714488\n",
      "Gradient for encoder.log_var.weight: 0.02472902275621891\n",
      "Gradient for encoder.log_var.bias: 0.001033288543112576\n",
      "Gradient for decoder.decoder.0.weight: 0.00990140251815319\n",
      "Gradient for decoder.decoder.0.bias: 8.890063685207394e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0004813138803001493\n",
      "Gradient for decoder.decoder.1.bias: 0.0003909946826752275\n",
      "Gradient for decoder.decoder.3.weight: 0.009573077782988548\n",
      "Gradient for decoder.decoder.3.bias: 7.690777875657417e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0003309299936518073\n",
      "Gradient for decoder.decoder.4.bias: 0.0002878329833038151\n",
      "Gradient for decoder.decoder.6.weight: 0.0004051606811117381\n",
      "Gradient for decoder.decoder.6.bias: 1.9862673070747405e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.0029431444127112627\n",
      "Gradient for encoder.encoder.0.bias: 5.73033244119503e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.00024408164608757943\n",
      "Gradient for encoder.encoder.1.bias: 0.0003158199251629412\n",
      "Gradient for encoder.encoder.3.weight: 0.005481701344251633\n",
      "Gradient for encoder.encoder.3.bias: 8.579086052673546e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.002392952563241124\n",
      "Gradient for encoder.encoder.4.bias: 0.0015723670367151499\n",
      "Gradient for encoder.mean.weight: 0.034240156412124634\n",
      "Gradient for encoder.mean.bias: 0.0011570332571864128\n",
      "Gradient for encoder.log_var.weight: 0.023218976333737373\n",
      "Gradient for encoder.log_var.bias: 0.0008649870287626982\n",
      "Gradient for decoder.decoder.0.weight: 0.013042423874139786\n",
      "Gradient for decoder.decoder.0.bias: 1.1345473865942424e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0006894311518408358\n",
      "Gradient for decoder.decoder.1.bias: 0.0005281164776533842\n",
      "Gradient for decoder.decoder.3.weight: 0.01249503344297409\n",
      "Gradient for decoder.decoder.3.bias: 1.0961297841616258e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0006079076556488872\n",
      "Gradient for decoder.decoder.4.bias: 0.0006041852757334709\n",
      "Gradient for decoder.decoder.6.weight: 0.0005612469976767898\n",
      "Gradient for decoder.decoder.6.bias: 3.7432138924486935e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.0029617168474942446\n",
      "Gradient for encoder.encoder.0.bias: 6.591175522041581e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.00023774463625159115\n",
      "Gradient for encoder.encoder.1.bias: 0.0003363069845363498\n",
      "Gradient for encoder.encoder.3.weight: 0.005204968620091677\n",
      "Gradient for encoder.encoder.3.bias: 8.146346097692714e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.002511395839974284\n",
      "Gradient for encoder.encoder.4.bias: 0.0012993613490834832\n",
      "Gradient for encoder.mean.weight: 0.03562894091010094\n",
      "Gradient for encoder.mean.bias: 0.0010699935955926776\n",
      "Gradient for encoder.log_var.weight: 0.022121865302324295\n",
      "Gradient for encoder.log_var.bias: 0.0007913679582998157\n",
      "Gradient for decoder.decoder.0.weight: 0.010278604924678802\n",
      "Gradient for decoder.decoder.0.bias: 8.167368864553382e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005395791376940906\n",
      "Gradient for decoder.decoder.1.bias: 0.00042472631321288645\n",
      "Gradient for decoder.decoder.3.weight: 0.009660347364842892\n",
      "Gradient for decoder.decoder.3.bias: 7.945136215603554e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0003952943079639226\n",
      "Gradient for decoder.decoder.4.bias: 0.0004074914613738656\n",
      "Gradient for decoder.decoder.6.weight: 0.0004338393628131598\n",
      "Gradient for decoder.decoder.6.bias: 2.4783155822660774e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.0023985099978744984\n",
      "Gradient for encoder.encoder.0.bias: 5.308015745691952e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.0001802381593734026\n",
      "Gradient for encoder.encoder.1.bias: 0.0003596610331442207\n",
      "Gradient for encoder.encoder.3.weight: 0.003929415252059698\n",
      "Gradient for encoder.encoder.3.bias: 7.242835498022515e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.002938213525339961\n",
      "Gradient for encoder.encoder.4.bias: 0.001924490905366838\n",
      "Gradient for encoder.mean.weight: 0.04364334046840668\n",
      "Gradient for encoder.mean.bias: 0.0015588075621053576\n",
      "Gradient for encoder.log_var.weight: 0.0288611501455307\n",
      "Gradient for encoder.log_var.bias: 0.00101767061278224\n",
      "Gradient for decoder.decoder.0.weight: 0.01062542200088501\n",
      "Gradient for decoder.decoder.0.bias: 8.11314695980947e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005154434475116432\n",
      "Gradient for decoder.decoder.1.bias: 0.00044304478797130287\n",
      "Gradient for decoder.decoder.3.weight: 0.010683066211640835\n",
      "Gradient for decoder.decoder.3.bias: 8.030766329714112e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.000559298787266016\n",
      "Gradient for decoder.decoder.4.bias: 0.0006229803548194468\n",
      "Gradient for decoder.decoder.6.weight: 0.0004622522974386811\n",
      "Gradient for decoder.decoder.6.bias: 3.342972559039481e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.0036835770588368177\n",
      "Gradient for encoder.encoder.0.bias: 8.322712310993019e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.00042669230606406927\n",
      "Gradient for encoder.encoder.1.bias: 0.0006517771980725229\n",
      "Gradient for encoder.encoder.3.weight: 0.009390454739332199\n",
      "Gradient for encoder.encoder.3.bias: 1.1127514187858623e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0027891837526112795\n",
      "Gradient for encoder.encoder.4.bias: 0.0030233822762966156\n",
      "Gradient for encoder.mean.weight: 0.0397525280714035\n",
      "Gradient for encoder.mean.bias: 0.0022918374743312597\n",
      "Gradient for encoder.log_var.weight: 0.027073871344327927\n",
      "Gradient for encoder.log_var.bias: 0.0017672120593488216\n",
      "Gradient for decoder.decoder.0.weight: 0.009803887456655502\n",
      "Gradient for decoder.decoder.0.bias: 7.55515511263738e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0004294599639251828\n",
      "Gradient for decoder.decoder.1.bias: 0.00039323195233009756\n",
      "Gradient for decoder.decoder.3.weight: 0.008785884827375412\n",
      "Gradient for decoder.decoder.3.bias: 6.83189824157715e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00034956916351802647\n",
      "Gradient for decoder.decoder.4.bias: 0.0003484949702396989\n",
      "Gradient for decoder.decoder.6.weight: 0.0004178059461992234\n",
      "Gradient for decoder.decoder.6.bias: 2.6039622753160074e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.0029784790240228176\n",
      "Gradient for encoder.encoder.0.bias: 6.6702255697992374e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.00023010063159745187\n",
      "Gradient for encoder.encoder.1.bias: 0.00037139130290597677\n",
      "Gradient for encoder.encoder.3.weight: 0.005120927933603525\n",
      "Gradient for encoder.encoder.3.bias: 7.76862046913962e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.0024936862755566835\n",
      "Gradient for encoder.encoder.4.bias: 0.0012966590002179146\n",
      "Gradient for encoder.mean.weight: 0.035771746188402176\n",
      "Gradient for encoder.mean.bias: 0.0009997490560635924\n",
      "Gradient for encoder.log_var.weight: 0.023580562323331833\n",
      "Gradient for encoder.log_var.bias: 0.0007920490461401641\n",
      "Gradient for decoder.decoder.0.weight: 0.010074117220938206\n",
      "Gradient for decoder.decoder.0.bias: 1.1057761650778986e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0005325855454429984\n",
      "Gradient for decoder.decoder.1.bias: 0.0003990672412328422\n",
      "Gradient for decoder.decoder.3.weight: 0.009649588726460934\n",
      "Gradient for decoder.decoder.3.bias: 9.851095633672813e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0005096050444990396\n",
      "Gradient for decoder.decoder.4.bias: 0.0005905399448238313\n",
      "Gradient for decoder.decoder.6.weight: 0.0004354502016212791\n",
      "Gradient for decoder.decoder.6.bias: 2.9073135010548867e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.0030861729755997658\n",
      "Gradient for encoder.encoder.0.bias: 6.924609757125166e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.0003106995136477053\n",
      "Gradient for encoder.encoder.1.bias: 0.00040964497020468116\n",
      "Gradient for encoder.encoder.3.weight: 0.006557374261319637\n",
      "Gradient for encoder.encoder.3.bias: 1.0539610156845569e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0025631459429860115\n",
      "Gradient for encoder.encoder.4.bias: 0.0026038067881017923\n",
      "Gradient for encoder.mean.weight: 0.03585764765739441\n",
      "Gradient for encoder.mean.bias: 0.0019060529302805662\n",
      "Gradient for encoder.log_var.weight: 0.024991806596517563\n",
      "Gradient for encoder.log_var.bias: 0.0012065100017935038\n",
      "Gradient for decoder.decoder.0.weight: 0.009229851886630058\n",
      "Gradient for decoder.decoder.0.bias: 7.330044210496212e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0004562492831610143\n",
      "Gradient for decoder.decoder.1.bias: 0.00037198924110271037\n",
      "Gradient for decoder.decoder.3.weight: 0.008985732682049274\n",
      "Gradient for decoder.decoder.3.bias: 6.987739553654393e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0003420001012273133\n",
      "Gradient for decoder.decoder.4.bias: 0.00029743771301582456\n",
      "Gradient for decoder.decoder.6.weight: 0.00043657736387103796\n",
      "Gradient for decoder.decoder.6.bias: 2.419889460725244e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training VAE Epoch:  52%|█████▏    | 41/79 [00:00<00:00, 69.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient for encoder.encoder.0.weight: 0.002280548680573702\n",
      "Gradient for encoder.encoder.0.bias: 4.6674222646536645e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.0002160931908292696\n",
      "Gradient for encoder.encoder.1.bias: 0.00027524519828148186\n",
      "Gradient for encoder.encoder.3.weight: 0.005111290607601404\n",
      "Gradient for encoder.encoder.3.bias: 8.657842498482893e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.0029104130808264017\n",
      "Gradient for encoder.encoder.4.bias: 0.0019619741942733526\n",
      "Gradient for encoder.mean.weight: 0.04721233993768692\n",
      "Gradient for encoder.mean.bias: 0.001508102985098958\n",
      "Gradient for encoder.log_var.weight: 0.024418024346232414\n",
      "Gradient for encoder.log_var.bias: 0.0009117827867157757\n",
      "Gradient for decoder.decoder.0.weight: 0.014158462174236774\n",
      "Gradient for decoder.decoder.0.bias: 1.132747715071325e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0007540378137491643\n",
      "Gradient for decoder.decoder.1.bias: 0.0005877144867554307\n",
      "Gradient for decoder.decoder.3.weight: 0.013285907916724682\n",
      "Gradient for decoder.decoder.3.bias: 9.465683792342361e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0004951170994900167\n",
      "Gradient for decoder.decoder.4.bias: 0.0004836389562115073\n",
      "Gradient for decoder.decoder.6.weight: 0.00045258417958393693\n",
      "Gradient for decoder.decoder.6.bias: 2.374950418015942e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.00263477535918355\n",
      "Gradient for encoder.encoder.0.bias: 5.625389910834944e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.0001899871858768165\n",
      "Gradient for encoder.encoder.1.bias: 0.00025322652072645724\n",
      "Gradient for encoder.encoder.3.weight: 0.004395537544041872\n",
      "Gradient for encoder.encoder.3.bias: 7.539961710545384e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.002199767855927348\n",
      "Gradient for encoder.encoder.4.bias: 0.001553210662677884\n",
      "Gradient for encoder.mean.weight: 0.036565132439136505\n",
      "Gradient for encoder.mean.bias: 0.0012897889828309417\n",
      "Gradient for encoder.log_var.weight: 0.02097802795469761\n",
      "Gradient for encoder.log_var.bias: 0.0007992542814463377\n",
      "Gradient for decoder.decoder.0.weight: 0.010467439889907837\n",
      "Gradient for decoder.decoder.0.bias: 8.805028928193792e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.00048172063543461263\n",
      "Gradient for decoder.decoder.1.bias: 0.0004580026725307107\n",
      "Gradient for decoder.decoder.3.weight: 0.009415636770427227\n",
      "Gradient for decoder.decoder.3.bias: 7.164879800569679e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00038395985029637814\n",
      "Gradient for decoder.decoder.4.bias: 0.00037277379306033254\n",
      "Gradient for decoder.decoder.6.weight: 0.0004063406668137759\n",
      "Gradient for decoder.decoder.6.bias: 2.1090556401759386e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.00321167497895658\n",
      "Gradient for encoder.encoder.0.bias: 6.3123954847921215e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.0002332593285245821\n",
      "Gradient for encoder.encoder.1.bias: 0.0002996535913553089\n",
      "Gradient for encoder.encoder.3.weight: 0.0052931588143110275\n",
      "Gradient for encoder.encoder.3.bias: 8.255600369988514e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.002253327053040266\n",
      "Gradient for encoder.encoder.4.bias: 0.0017584291053935885\n",
      "Gradient for encoder.mean.weight: 0.036094553768634796\n",
      "Gradient for encoder.mean.bias: 0.001396179897710681\n",
      "Gradient for encoder.log_var.weight: 0.01923101209104061\n",
      "Gradient for encoder.log_var.bias: 0.0008890948374755681\n",
      "Gradient for decoder.decoder.0.weight: 0.01126557681709528\n",
      "Gradient for decoder.decoder.0.bias: 9.081571605840111e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.000564065296202898\n",
      "Gradient for decoder.decoder.1.bias: 0.0004881264176219702\n",
      "Gradient for decoder.decoder.3.weight: 0.010636248625814915\n",
      "Gradient for decoder.decoder.3.bias: 7.662028650434749e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00038857405888848007\n",
      "Gradient for decoder.decoder.4.bias: 0.0003466199850663543\n",
      "Gradient for decoder.decoder.6.weight: 0.0004314631223678589\n",
      "Gradient for decoder.decoder.6.bias: 2.2546733816852793e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.004438062198460102\n",
      "Gradient for encoder.encoder.0.bias: 1.0766870034428777e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.00034348611370660365\n",
      "Gradient for encoder.encoder.1.bias: 0.0004068873531650752\n",
      "Gradient for encoder.encoder.3.weight: 0.007584564853459597\n",
      "Gradient for encoder.encoder.3.bias: 9.634797126789607e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.0024164707865566015\n",
      "Gradient for encoder.encoder.4.bias: 0.0019264277070760727\n",
      "Gradient for encoder.mean.weight: 0.034421406686306\n",
      "Gradient for encoder.mean.bias: 0.0015098489820957184\n",
      "Gradient for encoder.log_var.weight: 0.021140705794095993\n",
      "Gradient for encoder.log_var.bias: 0.0010056723840534687\n",
      "Gradient for decoder.decoder.0.weight: 0.008004708215594292\n",
      "Gradient for decoder.decoder.0.bias: 6.509512373575888e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0003787252935580909\n",
      "Gradient for decoder.decoder.1.bias: 0.0003196762700099498\n",
      "Gradient for decoder.decoder.3.weight: 0.007584817241877317\n",
      "Gradient for decoder.decoder.3.bias: 8.005678758804535e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00047390564577654004\n",
      "Gradient for decoder.decoder.4.bias: 0.0005721573252230883\n",
      "Gradient for decoder.decoder.6.weight: 0.000434731860877946\n",
      "Gradient for decoder.decoder.6.bias: 3.234234463889152e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.003122724127024412\n",
      "Gradient for encoder.encoder.0.bias: 8.75312496095848e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.0002859040105249733\n",
      "Gradient for encoder.encoder.1.bias: 0.0004426412924658507\n",
      "Gradient for encoder.encoder.3.weight: 0.0063154431991279125\n",
      "Gradient for encoder.encoder.3.bias: 1.071947530739692e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0024262843653559685\n",
      "Gradient for encoder.encoder.4.bias: 0.002430451801046729\n",
      "Gradient for encoder.mean.weight: 0.037737734615802765\n",
      "Gradient for encoder.mean.bias: 0.0019485426601022482\n",
      "Gradient for encoder.log_var.weight: 0.022078463807702065\n",
      "Gradient for encoder.log_var.bias: 0.0013106227852404118\n",
      "Gradient for decoder.decoder.0.weight: 0.009136714972555637\n",
      "Gradient for decoder.decoder.0.bias: 7.535255058810364e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0004532434977591038\n",
      "Gradient for decoder.decoder.1.bias: 0.0003845058963634074\n",
      "Gradient for decoder.decoder.3.weight: 0.008479305543005466\n",
      "Gradient for decoder.decoder.3.bias: 8.660355765854888e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0005539519479498267\n",
      "Gradient for decoder.decoder.4.bias: 0.0006741747492924333\n",
      "Gradient for decoder.decoder.6.weight: 0.0004601047548931092\n",
      "Gradient for decoder.decoder.6.bias: 3.566207305993885e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.003681686706840992\n",
      "Gradient for encoder.encoder.0.bias: 7.893231207534157e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.00026987679302692413\n",
      "Gradient for encoder.encoder.1.bias: 0.0003594021836761385\n",
      "Gradient for encoder.encoder.3.weight: 0.005784683860838413\n",
      "Gradient for encoder.encoder.3.bias: 8.279617963458108e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.00197808095254004\n",
      "Gradient for encoder.encoder.4.bias: 0.001379106193780899\n",
      "Gradient for encoder.mean.weight: 0.03291922062635422\n",
      "Gradient for encoder.mean.bias: 0.0012128916569054127\n",
      "Gradient for encoder.log_var.weight: 0.01959206908941269\n",
      "Gradient for encoder.log_var.bias: 0.0006890653166919947\n",
      "Gradient for decoder.decoder.0.weight: 0.01010739617049694\n",
      "Gradient for decoder.decoder.0.bias: 8.032409459790557e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0004545152187347412\n",
      "Gradient for decoder.decoder.1.bias: 0.0004158116353210062\n",
      "Gradient for decoder.decoder.3.weight: 0.009345581755042076\n",
      "Gradient for decoder.decoder.3.bias: 6.934505747402397e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00034665060229599476\n",
      "Gradient for decoder.decoder.4.bias: 0.00032861094223335385\n",
      "Gradient for decoder.decoder.6.weight: 0.00042097223922610283\n",
      "Gradient for decoder.decoder.6.bias: 2.324723573110532e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.0029904975090175867\n",
      "Gradient for encoder.encoder.0.bias: 6.0488931571955895e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.0002422699617454782\n",
      "Gradient for encoder.encoder.1.bias: 0.0003028283244930208\n",
      "Gradient for encoder.encoder.3.weight: 0.00533512094989419\n",
      "Gradient for encoder.encoder.3.bias: 7.15243142490607e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.001985788345336914\n",
      "Gradient for encoder.encoder.4.bias: 0.0012471516383811831\n",
      "Gradient for encoder.mean.weight: 0.03219064697623253\n",
      "Gradient for encoder.mean.bias: 0.0010479772463440895\n",
      "Gradient for encoder.log_var.weight: 0.017037929967045784\n",
      "Gradient for encoder.log_var.bias: 0.0008132249349728227\n",
      "Gradient for decoder.decoder.0.weight: 0.0109039805829525\n",
      "Gradient for decoder.decoder.0.bias: 8.297688924852054e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005306301172822714\n",
      "Gradient for decoder.decoder.1.bias: 0.0004472032014746219\n",
      "Gradient for decoder.decoder.3.weight: 0.009897790849208832\n",
      "Gradient for decoder.decoder.3.bias: 7.702365134587552e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0003923909680452198\n",
      "Gradient for decoder.decoder.4.bias: 0.00032760435715317726\n",
      "Gradient for decoder.decoder.6.weight: 0.0004451533604878932\n",
      "Gradient for decoder.decoder.6.bias: 2.3820477508706972e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.004012521356344223\n",
      "Gradient for encoder.encoder.0.bias: 9.872704216651318e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.00026748405070975423\n",
      "Gradient for encoder.encoder.1.bias: 0.0003780894912779331\n",
      "Gradient for encoder.encoder.3.weight: 0.005736932624131441\n",
      "Gradient for encoder.encoder.3.bias: 9.822608698639712e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.002083844505250454\n",
      "Gradient for encoder.encoder.4.bias: 0.002114639151841402\n",
      "Gradient for encoder.mean.weight: 0.03214172646403313\n",
      "Gradient for encoder.mean.bias: 0.001808503526262939\n",
      "Gradient for encoder.log_var.weight: 0.01934690959751606\n",
      "Gradient for encoder.log_var.bias: 0.0014020402450114489\n",
      "Gradient for decoder.decoder.0.weight: 0.008860648609697819\n",
      "Gradient for decoder.decoder.0.bias: 7.747313901518282e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.00043442443711683154\n",
      "Gradient for decoder.decoder.1.bias: 0.0003527021035552025\n",
      "Gradient for decoder.decoder.3.weight: 0.007966195233166218\n",
      "Gradient for decoder.decoder.3.bias: 7.015629743811758e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00032979276147671044\n",
      "Gradient for decoder.decoder.4.bias: 0.0003356069209985435\n",
      "Gradient for decoder.decoder.6.weight: 0.0004015403683297336\n",
      "Gradient for decoder.decoder.6.bias: 2.5437233489356004e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.0023913404438644648\n",
      "Gradient for encoder.encoder.0.bias: 5.012652619373892e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.00019034923752769828\n",
      "Gradient for encoder.encoder.1.bias: 0.0001947088894667104\n",
      "Gradient for encoder.encoder.3.weight: 0.004227444529533386\n",
      "Gradient for encoder.encoder.3.bias: 9.313507604025162e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.002754734829068184\n",
      "Gradient for encoder.encoder.4.bias: 0.0019887504167854786\n",
      "Gradient for encoder.mean.weight: 0.03966028615832329\n",
      "Gradient for encoder.mean.bias: 0.0012719001388177276\n",
      "Gradient for encoder.log_var.weight: 0.022916056215763092\n",
      "Gradient for encoder.log_var.bias: 0.0009559957543388009\n",
      "Gradient for decoder.decoder.0.weight: 0.013697164133191109\n",
      "Gradient for decoder.decoder.0.bias: 1.1846713887653237e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.000662760401610285\n",
      "Gradient for decoder.decoder.1.bias: 0.0005659024463966489\n",
      "Gradient for decoder.decoder.3.weight: 0.012476816773414612\n",
      "Gradient for decoder.decoder.3.bias: 1.1249489534348456e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0004486198886297643\n",
      "Gradient for decoder.decoder.4.bias: 0.0004213466017972678\n",
      "Gradient for decoder.decoder.6.weight: 0.00046022291644476354\n",
      "Gradient for decoder.decoder.6.bias: 2.2865619030199014e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.0029002060182392597\n",
      "Gradient for encoder.encoder.0.bias: 5.385653728540163e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.0002698573807720095\n",
      "Gradient for encoder.encoder.1.bias: 0.00037517069722525775\n",
      "Gradient for encoder.encoder.3.weight: 0.0059198178350925446\n",
      "Gradient for encoder.encoder.3.bias: 8.885337604569443e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.0023424180690199137\n",
      "Gradient for encoder.encoder.4.bias: 0.0018070489168167114\n",
      "Gradient for encoder.mean.weight: 0.03760037198662758\n",
      "Gradient for encoder.mean.bias: 0.00126601941883564\n",
      "Gradient for encoder.log_var.weight: 0.02298508584499359\n",
      "Gradient for encoder.log_var.bias: 0.0008173399837687612\n",
      "Gradient for decoder.decoder.0.weight: 0.012651276774704456\n",
      "Gradient for decoder.decoder.0.bias: 1.0754978851945651e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0005872861365787685\n",
      "Gradient for decoder.decoder.1.bias: 0.0005193639080971479\n",
      "Gradient for decoder.decoder.3.weight: 0.012242886237800121\n",
      "Gradient for decoder.decoder.3.bias: 9.211605089820551e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.000526507617905736\n",
      "Gradient for decoder.decoder.4.bias: 0.0005607340135611594\n",
      "Gradient for decoder.decoder.6.weight: 0.0004994060145691037\n",
      "Gradient for decoder.decoder.6.bias: 3.276356073911302e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.0040096864104270935\n",
      "Gradient for encoder.encoder.0.bias: 8.358921194107083e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.0003892456879839301\n",
      "Gradient for encoder.encoder.1.bias: 0.0006107412627898157\n",
      "Gradient for encoder.encoder.3.weight: 0.00845525786280632\n",
      "Gradient for encoder.encoder.3.bias: 1.284856387950839e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0029310956597328186\n",
      "Gradient for encoder.encoder.4.bias: 0.00321819051168859\n",
      "Gradient for encoder.mean.weight: 0.044534724205732346\n",
      "Gradient for encoder.mean.bias: 0.0027806328143924475\n",
      "Gradient for encoder.log_var.weight: 0.024761518463492393\n",
      "Gradient for encoder.log_var.bias: 0.0016802807804197073\n",
      "Gradient for decoder.decoder.0.weight: 0.009858628734946251\n",
      "Gradient for decoder.decoder.0.bias: 8.758936631547698e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0004616350634023547\n",
      "Gradient for decoder.decoder.1.bias: 0.00042640947503969073\n",
      "Gradient for decoder.decoder.3.weight: 0.00933673046529293\n",
      "Gradient for decoder.decoder.3.bias: 8.548652757900399e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0004428992688190192\n",
      "Gradient for decoder.decoder.4.bias: 0.0004570304008666426\n",
      "Gradient for decoder.decoder.6.weight: 0.0004551670572254807\n",
      "Gradient for decoder.decoder.6.bias: 2.898706770793069e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.0027988909278064966\n",
      "Gradient for encoder.encoder.0.bias: 6.417644627526586e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.00024240622587967664\n",
      "Gradient for encoder.encoder.1.bias: 0.00031500982004217803\n",
      "Gradient for encoder.encoder.3.weight: 0.005277595482766628\n",
      "Gradient for encoder.encoder.3.bias: 7.145848496259433e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.0021180950570851564\n",
      "Gradient for encoder.encoder.4.bias: 0.001246298779733479\n",
      "Gradient for encoder.mean.weight: 0.03091757372021675\n",
      "Gradient for encoder.mean.bias: 0.0009948115330189466\n",
      "Gradient for encoder.log_var.weight: 0.020195690914988518\n",
      "Gradient for encoder.log_var.bias: 0.0007633769419044256\n",
      "Gradient for decoder.decoder.0.weight: 0.01042663212865591\n",
      "Gradient for decoder.decoder.0.bias: 9.284310820145691e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005123348091728985\n",
      "Gradient for decoder.decoder.1.bias: 0.0004597935185302049\n",
      "Gradient for decoder.decoder.3.weight: 0.009709112346172333\n",
      "Gradient for decoder.decoder.3.bias: 8.420711350431986e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0003480245650280267\n",
      "Gradient for decoder.decoder.4.bias: 0.00030996082932688296\n",
      "Gradient for decoder.decoder.6.weight: 0.00040522063500247896\n",
      "Gradient for decoder.decoder.6.bias: 2.0326888261479326e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.0026412862353026867\n",
      "Gradient for encoder.encoder.0.bias: 5.1408053161616785e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.00022137982887215912\n",
      "Gradient for encoder.encoder.1.bias: 0.0003001921286340803\n",
      "Gradient for encoder.encoder.3.weight: 0.005194181110709906\n",
      "Gradient for encoder.encoder.3.bias: 8.746796342773422e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.0023066115099936724\n",
      "Gradient for encoder.encoder.4.bias: 0.0018149380339309573\n",
      "Gradient for encoder.mean.weight: 0.034861788153648376\n",
      "Gradient for encoder.mean.bias: 0.001636364497244358\n",
      "Gradient for encoder.log_var.weight: 0.025388004258275032\n",
      "Gradient for encoder.log_var.bias: 0.0011424943804740906\n",
      "Gradient for decoder.decoder.0.weight: 0.01309110876172781\n",
      "Gradient for decoder.decoder.0.bias: 1.0594113086792589e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0006230685394257307\n",
      "Gradient for decoder.decoder.1.bias: 0.0005265881773084402\n",
      "Gradient for decoder.decoder.3.weight: 0.012107428163290024\n",
      "Gradient for decoder.decoder.3.bias: 9.315642701679394e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00043429521610960364\n",
      "Gradient for decoder.decoder.4.bias: 0.00041982601396739483\n",
      "Gradient for decoder.decoder.6.weight: 0.0004546838463284075\n",
      "Gradient for decoder.decoder.6.bias: 2.6328096282668412e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.0028048765379935503\n",
      "Gradient for encoder.encoder.0.bias: 5.542256324014838e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.0002026658330578357\n",
      "Gradient for encoder.encoder.1.bias: 0.00024302597739733756\n",
      "Gradient for encoder.encoder.3.weight: 0.004550240933895111\n",
      "Gradient for encoder.encoder.3.bias: 8.147492402965639e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.0021475825924426317\n",
      "Gradient for encoder.encoder.4.bias: 0.0015715875197201967\n",
      "Gradient for encoder.mean.weight: 0.034268882125616074\n",
      "Gradient for encoder.mean.bias: 0.001340996939688921\n",
      "Gradient for encoder.log_var.weight: 0.021051855757832527\n",
      "Gradient for encoder.log_var.bias: 0.0009042787714861333\n",
      "Gradient for decoder.decoder.0.weight: 0.012570567429065704\n",
      "Gradient for decoder.decoder.0.bias: 1.1137817751416534e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.000668120221234858\n",
      "Gradient for decoder.decoder.1.bias: 0.0005443763802759349\n",
      "Gradient for decoder.decoder.3.weight: 0.011666320264339447\n",
      "Gradient for decoder.decoder.3.bias: 9.915102072710624e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.000502381066326052\n",
      "Gradient for decoder.decoder.4.bias: 0.00052790337940678\n",
      "Gradient for decoder.decoder.6.weight: 0.000514195126015693\n",
      "Gradient for decoder.decoder.6.bias: 3.385539457667619e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.0032433662563562393\n",
      "Gradient for encoder.encoder.0.bias: 6.066458099751593e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.0002826059644576162\n",
      "Gradient for encoder.encoder.1.bias: 0.00034330409835092723\n",
      "Gradient for encoder.encoder.3.weight: 0.00624758331105113\n",
      "Gradient for encoder.encoder.3.bias: 8.252810934639143e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.002362092025578022\n",
      "Gradient for encoder.encoder.4.bias: 0.0017129986081272364\n",
      "Gradient for encoder.mean.weight: 0.03376919403672218\n",
      "Gradient for encoder.mean.bias: 0.0011784285306930542\n",
      "Gradient for encoder.log_var.weight: 0.021023044362664223\n",
      "Gradient for encoder.log_var.bias: 0.0008300210465677083\n",
      "Gradient for decoder.decoder.0.weight: 0.011162853799760342\n",
      "Gradient for decoder.decoder.0.bias: 9.685938162640184e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005494114593602717\n",
      "Gradient for decoder.decoder.1.bias: 0.00045388779835775495\n",
      "Gradient for decoder.decoder.3.weight: 0.010210159234702587\n",
      "Gradient for decoder.decoder.3.bias: 7.799679652142899e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00036931896465830505\n",
      "Gradient for decoder.decoder.4.bias: 0.00037779961712658405\n",
      "Gradient for decoder.decoder.6.weight: 0.0004367862129583955\n",
      "Gradient for decoder.decoder.6.bias: 2.627743197081145e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training VAE Epoch:  62%|██████▏   | 49/79 [00:00<00:00, 72.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient for encoder.encoder.0.weight: 0.0030776613857597113\n",
      "Gradient for encoder.encoder.0.bias: 6.626956795818817e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.00029021649970673025\n",
      "Gradient for encoder.encoder.1.bias: 0.0003433659439906478\n",
      "Gradient for encoder.encoder.3.weight: 0.006239501293748617\n",
      "Gradient for encoder.encoder.3.bias: 8.274793350526721e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.0024420723784714937\n",
      "Gradient for encoder.encoder.4.bias: 0.002120805671438575\n",
      "Gradient for encoder.mean.weight: 0.03517348691821098\n",
      "Gradient for encoder.mean.bias: 0.0014943474670872092\n",
      "Gradient for encoder.log_var.weight: 0.021100640296936035\n",
      "Gradient for encoder.log_var.bias: 0.0008684498025104403\n",
      "Gradient for decoder.decoder.0.weight: 0.011063856072723866\n",
      "Gradient for decoder.decoder.0.bias: 8.988883942739889e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005497967358678579\n",
      "Gradient for decoder.decoder.1.bias: 0.00044686332694254816\n",
      "Gradient for decoder.decoder.3.weight: 0.01037893258035183\n",
      "Gradient for decoder.decoder.3.bias: 7.879024516155297e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00040100771002471447\n",
      "Gradient for decoder.decoder.4.bias: 0.0003569714317563921\n",
      "Gradient for decoder.decoder.6.weight: 0.00048373802565038204\n",
      "Gradient for decoder.decoder.6.bias: 3.070478487643413e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.00372658995911479\n",
      "Gradient for encoder.encoder.0.bias: 9.091871353006376e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.00030907843029126525\n",
      "Gradient for encoder.encoder.1.bias: 0.00036032183561474085\n",
      "Gradient for encoder.encoder.3.weight: 0.006788887549191713\n",
      "Gradient for encoder.encoder.3.bias: 9.33888244514236e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.0024398500099778175\n",
      "Gradient for encoder.encoder.4.bias: 0.0020565830636769533\n",
      "Gradient for encoder.mean.weight: 0.03630533441901207\n",
      "Gradient for encoder.mean.bias: 0.0016819137381389737\n",
      "Gradient for encoder.log_var.weight: 0.022064099088311195\n",
      "Gradient for encoder.log_var.bias: 0.0010422656778246164\n",
      "Gradient for decoder.decoder.0.weight: 0.008619640953838825\n",
      "Gradient for decoder.decoder.0.bias: 7.179114247524154e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0004397875745780766\n",
      "Gradient for decoder.decoder.1.bias: 0.0003775647492147982\n",
      "Gradient for decoder.decoder.3.weight: 0.008205347694456577\n",
      "Gradient for decoder.decoder.3.bias: 6.594012835758889e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0003064834454562515\n",
      "Gradient for decoder.decoder.4.bias: 0.00027746151317842305\n",
      "Gradient for decoder.decoder.6.weight: 0.0004156150680501014\n",
      "Gradient for decoder.decoder.6.bias: 2.6246336346957833e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training VAE Epoch:  72%|███████▏  | 57/79 [00:00<00:00, 74.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient for encoder.encoder.0.weight: 0.0024553893599659204\n",
      "Gradient for encoder.encoder.0.bias: 4.790545564403725e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.00018012762302532792\n",
      "Gradient for encoder.encoder.1.bias: 0.0002738332550507039\n",
      "Gradient for encoder.encoder.3.weight: 0.0040082791820168495\n",
      "Gradient for encoder.encoder.3.bias: 7.938535245832767e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.0025826350320130587\n",
      "Gradient for encoder.encoder.4.bias: 0.0017136831302195787\n",
      "Gradient for encoder.mean.weight: 0.038799915462732315\n",
      "Gradient for encoder.mean.bias: 0.001188935013487935\n",
      "Gradient for encoder.log_var.weight: 0.023476168513298035\n",
      "Gradient for encoder.log_var.bias: 0.0008465283899568021\n",
      "Gradient for decoder.decoder.0.weight: 0.012917879968881607\n",
      "Gradient for decoder.decoder.0.bias: 1.05577616094088e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0006424857419915497\n",
      "Gradient for decoder.decoder.1.bias: 0.0005368785350583494\n",
      "Gradient for decoder.decoder.3.weight: 0.011883025988936424\n",
      "Gradient for decoder.decoder.3.bias: 9.566272773930962e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00040878221625462174\n",
      "Gradient for decoder.decoder.4.bias: 0.0003686989366542548\n",
      "Gradient for decoder.decoder.6.weight: 0.0004407949454616755\n",
      "Gradient for decoder.decoder.6.bias: 2.3813377993064933e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.002439532894641161\n",
      "Gradient for encoder.encoder.0.bias: 5.014186982288393e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.00025128378183580935\n",
      "Gradient for encoder.encoder.1.bias: 0.0003614942543208599\n",
      "Gradient for encoder.encoder.3.weight: 0.0056809489615261555\n",
      "Gradient for encoder.encoder.3.bias: 7.597037582351973e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.002707179868593812\n",
      "Gradient for encoder.encoder.4.bias: 0.0016396354185417295\n",
      "Gradient for encoder.mean.weight: 0.03738175332546234\n",
      "Gradient for encoder.mean.bias: 0.001097642700187862\n",
      "Gradient for encoder.log_var.weight: 0.026114555075764656\n",
      "Gradient for encoder.log_var.bias: 0.0008433981565758586\n",
      "Gradient for decoder.decoder.0.weight: 0.013901103287935257\n",
      "Gradient for decoder.decoder.0.bias: 1.0396181138183636e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0006861380534246564\n",
      "Gradient for decoder.decoder.1.bias: 0.0005404948024079204\n",
      "Gradient for decoder.decoder.3.weight: 0.013046705164015293\n",
      "Gradient for decoder.decoder.3.bias: 9.065981992906202e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0005088028265163302\n",
      "Gradient for decoder.decoder.4.bias: 0.000480391550809145\n",
      "Gradient for decoder.decoder.6.weight: 0.0004834290884900838\n",
      "Gradient for decoder.decoder.6.bias: 2.7041545763495378e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.003358482616022229\n",
      "Gradient for encoder.encoder.0.bias: 7.049464744585121e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.00033095336402766407\n",
      "Gradient for encoder.encoder.1.bias: 0.00045326765393838286\n",
      "Gradient for encoder.encoder.3.weight: 0.007150227669626474\n",
      "Gradient for encoder.encoder.3.bias: 8.147573588024315e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.002379416720941663\n",
      "Gradient for encoder.encoder.4.bias: 0.0017009526491165161\n",
      "Gradient for encoder.mean.weight: 0.03470287099480629\n",
      "Gradient for encoder.mean.bias: 0.0012871387880295515\n",
      "Gradient for encoder.log_var.weight: 0.02017560601234436\n",
      "Gradient for encoder.log_var.bias: 0.0007349162478931248\n",
      "Gradient for decoder.decoder.0.weight: 0.010182804428040981\n",
      "Gradient for decoder.decoder.0.bias: 9.121819272150944e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0004748408682644367\n",
      "Gradient for decoder.decoder.1.bias: 0.0004006510425824672\n",
      "Gradient for decoder.decoder.3.weight: 0.009643176570534706\n",
      "Gradient for decoder.decoder.3.bias: 7.950222424835118e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00034311501076444983\n",
      "Gradient for decoder.decoder.4.bias: 0.00031612187740392983\n",
      "Gradient for decoder.decoder.6.weight: 0.0004245756717864424\n",
      "Gradient for decoder.decoder.6.bias: 2.178125942009501e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.002714600181207061\n",
      "Gradient for encoder.encoder.0.bias: 4.90913559803019e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.0002425002312520519\n",
      "Gradient for encoder.encoder.1.bias: 0.00040588757838122547\n",
      "Gradient for encoder.encoder.3.weight: 0.005522741470485926\n",
      "Gradient for encoder.encoder.3.bias: 8.545681523530746e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.002736970316618681\n",
      "Gradient for encoder.encoder.4.bias: 0.0020353817380964756\n",
      "Gradient for encoder.mean.weight: 0.04558851569890976\n",
      "Gradient for encoder.mean.bias: 0.0016489296685904264\n",
      "Gradient for encoder.log_var.weight: 0.024437181651592255\n",
      "Gradient for encoder.log_var.bias: 0.0010818671435117722\n",
      "Gradient for decoder.decoder.0.weight: 0.014190644025802612\n",
      "Gradient for decoder.decoder.0.bias: 1.3438480883642967e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0007364919874817133\n",
      "Gradient for decoder.decoder.1.bias: 0.0006161781493574381\n",
      "Gradient for decoder.decoder.3.weight: 0.013466553762555122\n",
      "Gradient for decoder.decoder.3.bias: 1.0655407806092754e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0005331180873326957\n",
      "Gradient for decoder.decoder.4.bias: 0.0005320424679666758\n",
      "Gradient for decoder.decoder.6.weight: 0.0004989317967556417\n",
      "Gradient for decoder.decoder.6.bias: 3.091801409027539e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.0046117533929646015\n",
      "Gradient for encoder.encoder.0.bias: 9.516457066816031e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.0003825002640951425\n",
      "Gradient for encoder.encoder.1.bias: 0.0005749707925133407\n",
      "Gradient for encoder.encoder.3.weight: 0.008344212546944618\n",
      "Gradient for encoder.encoder.3.bias: 1.0188117016696197e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0028270375914871693\n",
      "Gradient for encoder.encoder.4.bias: 0.0023281739559024572\n",
      "Gradient for encoder.mean.weight: 0.045590613037347794\n",
      "Gradient for encoder.mean.bias: 0.0018923116149380803\n",
      "Gradient for encoder.log_var.weight: 0.02478516288101673\n",
      "Gradient for encoder.log_var.bias: 0.0011058468371629715\n",
      "Gradient for decoder.decoder.0.weight: 0.009377948008477688\n",
      "Gradient for decoder.decoder.0.bias: 8.852854560537082e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.00047215260565280914\n",
      "Gradient for decoder.decoder.1.bias: 0.00039023891440592706\n",
      "Gradient for decoder.decoder.3.weight: 0.008891718462109566\n",
      "Gradient for decoder.decoder.3.bias: 7.250827716021035e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0003628428094089031\n",
      "Gradient for decoder.decoder.4.bias: 0.00034532361314632\n",
      "Gradient for decoder.decoder.6.weight: 0.0004359089070931077\n",
      "Gradient for decoder.decoder.6.bias: 2.8278553145355545e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.002370221773162484\n",
      "Gradient for encoder.encoder.0.bias: 4.881971563119869e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.00019348837668076158\n",
      "Gradient for encoder.encoder.1.bias: 0.00024825980653986335\n",
      "Gradient for encoder.encoder.3.weight: 0.004380814265459776\n",
      "Gradient for encoder.encoder.3.bias: 7.564551762762051e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.002484419383108616\n",
      "Gradient for encoder.encoder.4.bias: 0.0014356441097334027\n",
      "Gradient for encoder.mean.weight: 0.03834613785147667\n",
      "Gradient for encoder.mean.bias: 0.0011979843256995082\n",
      "Gradient for encoder.log_var.weight: 0.024820497259497643\n",
      "Gradient for encoder.log_var.bias: 0.0008963157306425273\n",
      "Gradient for decoder.decoder.0.weight: 0.012881999835371971\n",
      "Gradient for decoder.decoder.0.bias: 1.1539736527454991e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0006432142108678818\n",
      "Gradient for decoder.decoder.1.bias: 0.0005167362978681922\n",
      "Gradient for decoder.decoder.3.weight: 0.011830003000795841\n",
      "Gradient for decoder.decoder.3.bias: 1.2001906413150465e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0005435505299828947\n",
      "Gradient for decoder.decoder.4.bias: 0.0005674323765560985\n",
      "Gradient for decoder.decoder.6.weight: 0.000523294904269278\n",
      "Gradient for decoder.decoder.6.bias: 3.5992663470096886e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.0034805634059011936\n",
      "Gradient for encoder.encoder.0.bias: 6.41757393754494e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.0002164078177884221\n",
      "Gradient for encoder.encoder.1.bias: 0.0003224745159968734\n",
      "Gradient for encoder.encoder.3.weight: 0.004897641483694315\n",
      "Gradient for encoder.encoder.3.bias: 7.566582777007724e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.0025434105191379786\n",
      "Gradient for encoder.encoder.4.bias: 0.0014384532114490867\n",
      "Gradient for encoder.mean.weight: 0.03861718997359276\n",
      "Gradient for encoder.mean.bias: 0.0012555749854072928\n",
      "Gradient for encoder.log_var.weight: 0.0234061386436224\n",
      "Gradient for encoder.log_var.bias: 0.0008422962855547667\n",
      "Gradient for decoder.decoder.0.weight: 0.01211986318230629\n",
      "Gradient for decoder.decoder.0.bias: 1.0159151297983726e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.000523736176546663\n",
      "Gradient for decoder.decoder.1.bias: 0.0004987005959264934\n",
      "Gradient for decoder.decoder.3.weight: 0.011091909371316433\n",
      "Gradient for decoder.decoder.3.bias: 8.680062918431375e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00038369285175576806\n",
      "Gradient for decoder.decoder.4.bias: 0.0003454066172707826\n",
      "Gradient for decoder.decoder.6.weight: 0.00041517612407915294\n",
      "Gradient for decoder.decoder.6.bias: 1.936998887686059e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.002928447676822543\n",
      "Gradient for encoder.encoder.0.bias: 6.001652300136051e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.00023527351731900126\n",
      "Gradient for encoder.encoder.1.bias: 0.0003290015156380832\n",
      "Gradient for encoder.encoder.3.weight: 0.005307959858328104\n",
      "Gradient for encoder.encoder.3.bias: 8.283800728703383e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.0025687329471111298\n",
      "Gradient for encoder.encoder.4.bias: 0.0015824405709281564\n",
      "Gradient for encoder.mean.weight: 0.03728976100683212\n",
      "Gradient for encoder.mean.bias: 0.0012720649829134345\n",
      "Gradient for encoder.log_var.weight: 0.02189980447292328\n",
      "Gradient for encoder.log_var.bias: 0.0008116879616864026\n",
      "Gradient for decoder.decoder.0.weight: 0.011852250434458256\n",
      "Gradient for decoder.decoder.0.bias: 9.505737169623885e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0006058811559341848\n",
      "Gradient for decoder.decoder.1.bias: 0.0004949739086441696\n",
      "Gradient for decoder.decoder.3.weight: 0.01089164987206459\n",
      "Gradient for decoder.decoder.3.bias: 7.817505670582037e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00037886970676481724\n",
      "Gradient for decoder.decoder.4.bias: 0.0003306881117168814\n",
      "Gradient for decoder.decoder.6.weight: 0.00040942843770608306\n",
      "Gradient for decoder.decoder.6.bias: 2.0691679310402833e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.004161247983574867\n",
      "Gradient for encoder.encoder.0.bias: 8.308225635245137e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.0003217553021386266\n",
      "Gradient for encoder.encoder.1.bias: 0.00040142404031939805\n",
      "Gradient for encoder.encoder.3.weight: 0.006622977089136839\n",
      "Gradient for encoder.encoder.3.bias: 9.894667724053008e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.0024539045989513397\n",
      "Gradient for encoder.encoder.4.bias: 0.002153280656784773\n",
      "Gradient for encoder.mean.weight: 0.03690163418650627\n",
      "Gradient for encoder.mean.bias: 0.0016172804171219468\n",
      "Gradient for encoder.log_var.weight: 0.01994457095861435\n",
      "Gradient for encoder.log_var.bias: 0.0011185755720362067\n",
      "Gradient for decoder.decoder.0.weight: 0.008836330845952034\n",
      "Gradient for decoder.decoder.0.bias: 7.15792078387345e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0004797048750333488\n",
      "Gradient for decoder.decoder.1.bias: 0.0003908343496732414\n",
      "Gradient for decoder.decoder.3.weight: 0.008287841454148293\n",
      "Gradient for decoder.decoder.3.bias: 7.67799504530764e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0003089479578193277\n",
      "Gradient for decoder.decoder.4.bias: 0.0002803043171297759\n",
      "Gradient for decoder.decoder.6.weight: 0.0004145053680986166\n",
      "Gradient for decoder.decoder.6.bias: 2.178846079914365e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.002488301368430257\n",
      "Gradient for encoder.encoder.0.bias: 4.429662799759759e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.00021745786943938583\n",
      "Gradient for encoder.encoder.1.bias: 0.00028850455419160426\n",
      "Gradient for encoder.encoder.3.weight: 0.0049852486699819565\n",
      "Gradient for encoder.encoder.3.bias: 8.880310375936062e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.002579277381300926\n",
      "Gradient for encoder.encoder.4.bias: 0.001673873863182962\n",
      "Gradient for encoder.mean.weight: 0.03993013873696327\n",
      "Gradient for encoder.mean.bias: 0.0011785250389948487\n",
      "Gradient for encoder.log_var.weight: 0.023693464696407318\n",
      "Gradient for encoder.log_var.bias: 0.0006844840827398002\n",
      "Gradient for decoder.decoder.0.weight: 0.014977474696934223\n",
      "Gradient for decoder.decoder.0.bias: 1.2375564462097088e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0006668171263299882\n",
      "Gradient for decoder.decoder.1.bias: 0.0006129399407655001\n",
      "Gradient for decoder.decoder.3.weight: 0.014054087921977043\n",
      "Gradient for decoder.decoder.3.bias: 9.950839457983918e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0006562080816365778\n",
      "Gradient for decoder.decoder.4.bias: 0.0007003420032560825\n",
      "Gradient for decoder.decoder.6.weight: 0.0005664924974553287\n",
      "Gradient for decoder.decoder.6.bias: 3.683059549075551e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.0031733298674225807\n",
      "Gradient for encoder.encoder.0.bias: 7.045445823972152e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.0003264723054599017\n",
      "Gradient for encoder.encoder.1.bias: 0.00044701615115627646\n",
      "Gradient for encoder.encoder.3.weight: 0.007230086252093315\n",
      "Gradient for encoder.encoder.3.bias: 8.277865892747371e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.0023630952928215265\n",
      "Gradient for encoder.encoder.4.bias: 0.0018936231499537826\n",
      "Gradient for encoder.mean.weight: 0.039211027324199677\n",
      "Gradient for encoder.mean.bias: 0.00155009631998837\n",
      "Gradient for encoder.log_var.weight: 0.0214228518307209\n",
      "Gradient for encoder.log_var.bias: 0.0008517962414771318\n",
      "Gradient for decoder.decoder.0.weight: 0.010545645840466022\n",
      "Gradient for decoder.decoder.0.bias: 9.05322761202143e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005168993375264108\n",
      "Gradient for decoder.decoder.1.bias: 0.00042768713319674134\n",
      "Gradient for decoder.decoder.3.weight: 0.009872280061244965\n",
      "Gradient for decoder.decoder.3.bias: 8.22616766371631e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0003507607616484165\n",
      "Gradient for decoder.decoder.4.bias: 0.00029663468012586236\n",
      "Gradient for decoder.decoder.6.weight: 0.00040738171082921326\n",
      "Gradient for decoder.decoder.6.bias: 2.042012056335807e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.0031696504447609186\n",
      "Gradient for encoder.encoder.0.bias: 8.288794130228982e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.0002371265145484358\n",
      "Gradient for encoder.encoder.1.bias: 0.0003780774713959545\n",
      "Gradient for encoder.encoder.3.weight: 0.0052690026350319386\n",
      "Gradient for encoder.encoder.3.bias: 7.67163832460227e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.002673105103895068\n",
      "Gradient for encoder.encoder.4.bias: 0.0016321188304573298\n",
      "Gradient for encoder.mean.weight: 0.03748241066932678\n",
      "Gradient for encoder.mean.bias: 0.001243867096491158\n",
      "Gradient for encoder.log_var.weight: 0.02421858161687851\n",
      "Gradient for encoder.log_var.bias: 0.0008667281945236027\n",
      "Gradient for decoder.decoder.0.weight: 0.009799085557460785\n",
      "Gradient for decoder.decoder.0.bias: 8.12968234398248e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0004971966845914721\n",
      "Gradient for decoder.decoder.1.bias: 0.00039285249658860266\n",
      "Gradient for decoder.decoder.3.weight: 0.00896607805043459\n",
      "Gradient for decoder.decoder.3.bias: 7.637674520610815e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0003723014669958502\n",
      "Gradient for decoder.decoder.4.bias: 0.00036547327181324363\n",
      "Gradient for decoder.decoder.6.weight: 0.00042207216029055417\n",
      "Gradient for decoder.decoder.6.bias: 2.5608340365579352e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.0026990429032593966\n",
      "Gradient for encoder.encoder.0.bias: 6.051004749346722e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.00029478970100171864\n",
      "Gradient for encoder.encoder.1.bias: 0.000521707406733185\n",
      "Gradient for encoder.encoder.3.weight: 0.006484965328127146\n",
      "Gradient for encoder.encoder.3.bias: 9.388309574198672e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.00390672730281949\n",
      "Gradient for encoder.encoder.4.bias: 0.002144130179658532\n",
      "Gradient for encoder.mean.weight: 0.05506940558552742\n",
      "Gradient for encoder.mean.bias: 0.0015570188406854868\n",
      "Gradient for encoder.log_var.weight: 0.03568658232688904\n",
      "Gradient for encoder.log_var.bias: 0.0009931365493685007\n",
      "Gradient for decoder.decoder.0.weight: 0.012967780232429504\n",
      "Gradient for decoder.decoder.0.bias: 1.0790641991054173e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0006238184287212789\n",
      "Gradient for decoder.decoder.1.bias: 0.0005497880047187209\n",
      "Gradient for decoder.decoder.3.weight: 0.011795362457633018\n",
      "Gradient for decoder.decoder.3.bias: 8.818325236692459e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00045759405475109816\n",
      "Gradient for decoder.decoder.4.bias: 0.000459989532828331\n",
      "Gradient for decoder.decoder.6.weight: 0.00042722304351627827\n",
      "Gradient for decoder.decoder.6.bias: 2.2315884052659385e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.003855728544294834\n",
      "Gradient for encoder.encoder.0.bias: 7.053037841264764e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.0002913742500822991\n",
      "Gradient for encoder.encoder.1.bias: 0.00040247669676318765\n",
      "Gradient for encoder.encoder.3.weight: 0.006297651212662458\n",
      "Gradient for encoder.encoder.3.bias: 8.702719794806413e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.002476423280313611\n",
      "Gradient for encoder.encoder.4.bias: 0.0016103072557598352\n",
      "Gradient for encoder.mean.weight: 0.039562929421663284\n",
      "Gradient for encoder.mean.bias: 0.0013529306743294\n",
      "Gradient for encoder.log_var.weight: 0.017583344131708145\n",
      "Gradient for encoder.log_var.bias: 0.0007446325034834445\n",
      "Gradient for decoder.decoder.0.weight: 0.010084565728902817\n",
      "Gradient for decoder.decoder.0.bias: 8.778164306555425e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.000498790992423892\n",
      "Gradient for decoder.decoder.1.bias: 0.00041228788904845715\n",
      "Gradient for decoder.decoder.3.weight: 0.009398241527378559\n",
      "Gradient for decoder.decoder.3.bias: 6.458613505122557e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00033843968412838876\n",
      "Gradient for decoder.decoder.4.bias: 0.00029853155137971044\n",
      "Gradient for decoder.decoder.6.weight: 0.00046860400470905006\n",
      "Gradient for decoder.decoder.6.bias: 2.6022949896287173e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training VAE Epoch:  82%|████████▏ | 65/79 [00:01<00:00, 76.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient for encoder.encoder.0.weight: 0.0025000476744025946\n",
      "Gradient for encoder.encoder.0.bias: 5.142724354006978e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.00020018902432639152\n",
      "Gradient for encoder.encoder.1.bias: 0.00029179718694649637\n",
      "Gradient for encoder.encoder.3.weight: 0.004573476035147905\n",
      "Gradient for encoder.encoder.3.bias: 8.33826133139759e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.002591797150671482\n",
      "Gradient for encoder.encoder.4.bias: 0.001712682656943798\n",
      "Gradient for encoder.mean.weight: 0.04281611368060112\n",
      "Gradient for encoder.mean.bias: 0.0012983388733118773\n",
      "Gradient for encoder.log_var.weight: 0.02242286317050457\n",
      "Gradient for encoder.log_var.bias: 0.0008761543431319296\n",
      "Gradient for decoder.decoder.0.weight: 0.013701357878744602\n",
      "Gradient for decoder.decoder.0.bias: 1.0993189691888006e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.00066292256815359\n",
      "Gradient for decoder.decoder.1.bias: 0.0005327535327523947\n",
      "Gradient for decoder.decoder.3.weight: 0.012724516913294792\n",
      "Gradient for decoder.decoder.3.bias: 9.634153197435325e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0005651641986332834\n",
      "Gradient for decoder.decoder.4.bias: 0.0005639890441671014\n",
      "Gradient for decoder.decoder.6.weight: 0.0005038634408265352\n",
      "Gradient for decoder.decoder.6.bias: 2.7242285796091892e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.002642944687977433\n",
      "Gradient for encoder.encoder.0.bias: 4.82462854389798e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.00018679544155020267\n",
      "Gradient for encoder.encoder.1.bias: 0.00031298704561777413\n",
      "Gradient for encoder.encoder.3.weight: 0.004180981777608395\n",
      "Gradient for encoder.encoder.3.bias: 7.655288902785884e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.0026234881952404976\n",
      "Gradient for encoder.encoder.4.bias: 0.0015024588210508227\n",
      "Gradient for encoder.mean.weight: 0.04118292033672333\n",
      "Gradient for encoder.mean.bias: 0.0013391621178016067\n",
      "Gradient for encoder.log_var.weight: 0.022878795862197876\n",
      "Gradient for encoder.log_var.bias: 0.0007785335183143616\n",
      "Gradient for decoder.decoder.0.weight: 0.01259430032223463\n",
      "Gradient for decoder.decoder.0.bias: 1.0443276104998844e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0006061907624825835\n",
      "Gradient for decoder.decoder.1.bias: 0.0005099440459161997\n",
      "Gradient for decoder.decoder.3.weight: 0.011949772946536541\n",
      "Gradient for decoder.decoder.3.bias: 8.821871705366746e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00042273206054233015\n",
      "Gradient for decoder.decoder.4.bias: 0.00037553985021077096\n",
      "Gradient for decoder.decoder.6.weight: 0.0004570110177155584\n",
      "Gradient for decoder.decoder.6.bias: 2.2001448087394238e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training VAE Epoch:  92%|█████████▏| 73/79 [00:01<00:00, 76.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient for encoder.encoder.0.weight: 0.0022897161543369293\n",
      "Gradient for encoder.encoder.0.bias: 4.950168313450076e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.00020768921240232885\n",
      "Gradient for encoder.encoder.1.bias: 0.0003921372990589589\n",
      "Gradient for encoder.encoder.3.weight: 0.00439554825425148\n",
      "Gradient for encoder.encoder.3.bias: 8.471799650688894e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.0028398700524121523\n",
      "Gradient for encoder.encoder.4.bias: 0.002085059182718396\n",
      "Gradient for encoder.mean.weight: 0.04346656799316406\n",
      "Gradient for encoder.mean.bias: 0.0016690939664840698\n",
      "Gradient for encoder.log_var.weight: 0.025297662243247032\n",
      "Gradient for encoder.log_var.bias: 0.0011307902168482542\n",
      "Gradient for decoder.decoder.0.weight: 0.012364795431494713\n",
      "Gradient for decoder.decoder.0.bias: 1.0696330626780437e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.00060565973399207\n",
      "Gradient for decoder.decoder.1.bias: 0.0005558637203648686\n",
      "Gradient for decoder.decoder.3.weight: 0.011605310253798962\n",
      "Gradient for decoder.decoder.3.bias: 1.036878777282979e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0005038111703470349\n",
      "Gradient for decoder.decoder.4.bias: 0.0005159024731256068\n",
      "Gradient for decoder.decoder.6.weight: 0.00044049372081644833\n",
      "Gradient for decoder.decoder.6.bias: 2.662554834387265e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.002620053943246603\n",
      "Gradient for encoder.encoder.0.bias: 5.1915199569818604e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.00020970597688574344\n",
      "Gradient for encoder.encoder.1.bias: 0.0002685007930267602\n",
      "Gradient for encoder.encoder.3.weight: 0.004681626334786415\n",
      "Gradient for encoder.encoder.3.bias: 7.91037374492376e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.0024055498652160168\n",
      "Gradient for encoder.encoder.4.bias: 0.0016691783675923944\n",
      "Gradient for encoder.mean.weight: 0.038462091237306595\n",
      "Gradient for encoder.mean.bias: 0.0012456417316570878\n",
      "Gradient for encoder.log_var.weight: 0.020012514665722847\n",
      "Gradient for encoder.log_var.bias: 0.0008109344635158777\n",
      "Gradient for decoder.decoder.0.weight: 0.013435724191367626\n",
      "Gradient for decoder.decoder.0.bias: 1.1766494723008947e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0006376929813995957\n",
      "Gradient for decoder.decoder.1.bias: 0.0005685677169822156\n",
      "Gradient for decoder.decoder.3.weight: 0.01342834159731865\n",
      "Gradient for decoder.decoder.3.bias: 1.188936032958665e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0006133678834885359\n",
      "Gradient for decoder.decoder.4.bias: 0.0006907423376105726\n",
      "Gradient for decoder.decoder.6.weight: 0.0005525045562535524\n",
      "Gradient for decoder.decoder.6.bias: 3.7638586945831776e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.0029979082755744457\n",
      "Gradient for encoder.encoder.0.bias: 6.2726759550435496e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.00022757436090614647\n",
      "Gradient for encoder.encoder.1.bias: 0.00033610936952754855\n",
      "Gradient for encoder.encoder.3.weight: 0.0049713714979588985\n",
      "Gradient for encoder.encoder.3.bias: 8.827816255774223e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.0025243053678423166\n",
      "Gradient for encoder.encoder.4.bias: 0.0018149702809751034\n",
      "Gradient for encoder.mean.weight: 0.0429769903421402\n",
      "Gradient for encoder.mean.bias: 0.001487737288698554\n",
      "Gradient for encoder.log_var.weight: 0.022686485201120377\n",
      "Gradient for encoder.log_var.bias: 0.0010262976866215467\n",
      "Gradient for decoder.decoder.0.weight: 0.011036020703613758\n",
      "Gradient for decoder.decoder.0.bias: 8.401210976893836e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.000519795052241534\n",
      "Gradient for decoder.decoder.1.bias: 0.00044867760152556\n",
      "Gradient for decoder.decoder.3.weight: 0.010231588035821915\n",
      "Gradient for decoder.decoder.3.bias: 7.820844666328597e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00038474626489914954\n",
      "Gradient for decoder.decoder.4.bias: 0.00035130756441503763\n",
      "Gradient for decoder.decoder.6.weight: 0.00044936666381545365\n",
      "Gradient for decoder.decoder.6.bias: 2.653475348779466e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.0025377196725457907\n",
      "Gradient for encoder.encoder.0.bias: 5.014760742078073e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.00018847423780243844\n",
      "Gradient for encoder.encoder.1.bias: 0.0002746232785284519\n",
      "Gradient for encoder.encoder.3.weight: 0.004228179808706045\n",
      "Gradient for encoder.encoder.3.bias: 8.295877873543134e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.0028309114277362823\n",
      "Gradient for encoder.encoder.4.bias: 0.00189229438547045\n",
      "Gradient for encoder.mean.weight: 0.04162801802158356\n",
      "Gradient for encoder.mean.bias: 0.0016022828640416265\n",
      "Gradient for encoder.log_var.weight: 0.02293648011982441\n",
      "Gradient for encoder.log_var.bias: 0.0010459157638251781\n",
      "Gradient for decoder.decoder.0.weight: 0.012173440307378769\n",
      "Gradient for decoder.decoder.0.bias: 9.73226430001084e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005883962148800492\n",
      "Gradient for decoder.decoder.1.bias: 0.00048220151802524924\n",
      "Gradient for decoder.decoder.3.weight: 0.011361440643668175\n",
      "Gradient for decoder.decoder.3.bias: 8.460638439844459e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00041374689317308366\n",
      "Gradient for decoder.decoder.4.bias: 0.0003931402461603284\n",
      "Gradient for decoder.decoder.6.weight: 0.0004356930439826101\n",
      "Gradient for decoder.decoder.6.bias: 2.22469461732544e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.003437844105064869\n",
      "Gradient for encoder.encoder.0.bias: 6.6753070085412425e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.0002625421911943704\n",
      "Gradient for encoder.encoder.1.bias: 0.0003348140453454107\n",
      "Gradient for encoder.encoder.3.weight: 0.005893487483263016\n",
      "Gradient for encoder.encoder.3.bias: 8.034861664896198e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.0024757308419793844\n",
      "Gradient for encoder.encoder.4.bias: 0.00147919449955225\n",
      "Gradient for encoder.mean.weight: 0.0383102148771286\n",
      "Gradient for encoder.mean.bias: 0.0012785241706296802\n",
      "Gradient for encoder.log_var.weight: 0.024133805185556412\n",
      "Gradient for encoder.log_var.bias: 0.0008337217150256038\n",
      "Gradient for decoder.decoder.0.weight: 0.009818720631301403\n",
      "Gradient for decoder.decoder.0.bias: 8.580675753266931e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.000504360010381788\n",
      "Gradient for decoder.decoder.1.bias: 0.0004232439096085727\n",
      "Gradient for decoder.decoder.3.weight: 0.009159045293927193\n",
      "Gradient for decoder.decoder.3.bias: 7.729451106941454e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00035541554098017514\n",
      "Gradient for decoder.decoder.4.bias: 0.0003533741692081094\n",
      "Gradient for decoder.decoder.6.weight: 0.0004175124631728977\n",
      "Gradient for decoder.decoder.6.bias: 2.2148024072521366e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.0035350576508790255\n",
      "Gradient for encoder.encoder.0.bias: 7.159732876016456e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.0002814640465658158\n",
      "Gradient for encoder.encoder.1.bias: 0.00039035006193444133\n",
      "Gradient for encoder.encoder.3.weight: 0.0062349410727620125\n",
      "Gradient for encoder.encoder.3.bias: 9.706479370263921e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.002464834600687027\n",
      "Gradient for encoder.encoder.4.bias: 0.0023719980381429195\n",
      "Gradient for encoder.mean.weight: 0.03710193186998367\n",
      "Gradient for encoder.mean.bias: 0.0020095733925700188\n",
      "Gradient for encoder.log_var.weight: 0.020378854125738144\n",
      "Gradient for encoder.log_var.bias: 0.0011574026430025697\n",
      "Gradient for decoder.decoder.0.weight: 0.011273965239524841\n",
      "Gradient for decoder.decoder.0.bias: 9.641756837375226e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005723052308894694\n",
      "Gradient for decoder.decoder.1.bias: 0.0004449398547876626\n",
      "Gradient for decoder.decoder.3.weight: 0.010692231357097626\n",
      "Gradient for decoder.decoder.3.bias: 8.271418966421251e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00047183799324557185\n",
      "Gradient for decoder.decoder.4.bias: 0.00044407814857549965\n",
      "Gradient for decoder.decoder.6.weight: 0.000494025181978941\n",
      "Gradient for decoder.decoder.6.bias: 2.7125515771331266e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.0033434447832405567\n",
      "Gradient for encoder.encoder.0.bias: 6.0757510134124004e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.0002632001705933362\n",
      "Gradient for encoder.encoder.1.bias: 0.00038042350206524134\n",
      "Gradient for encoder.encoder.3.weight: 0.005623780190944672\n",
      "Gradient for encoder.encoder.3.bias: 8.889614738771812e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.0021283533424139023\n",
      "Gradient for encoder.encoder.4.bias: 0.0015695923939347267\n",
      "Gradient for encoder.mean.weight: 0.031754270195961\n",
      "Gradient for encoder.mean.bias: 0.0012559570604935288\n",
      "Gradient for encoder.log_var.weight: 0.0209183469414711\n",
      "Gradient for encoder.log_var.bias: 0.0008957262034527957\n",
      "Gradient for decoder.decoder.0.weight: 0.012256113812327385\n",
      "Gradient for decoder.decoder.0.bias: 1.1179198539101876e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0006185178062878549\n",
      "Gradient for decoder.decoder.1.bias: 0.0004948709974996746\n",
      "Gradient for decoder.decoder.3.weight: 0.01140380185097456\n",
      "Gradient for decoder.decoder.3.bias: 1.0592575427903483e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0007298788405023515\n",
      "Gradient for decoder.decoder.4.bias: 0.0008302065543830395\n",
      "Gradient for decoder.decoder.6.weight: 0.0006263602408580482\n",
      "Gradient for decoder.decoder.6.bias: 4.659186379285529e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.002494753571227193\n",
      "Gradient for encoder.encoder.0.bias: 4.896685921323973e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.0001777670404408127\n",
      "Gradient for encoder.encoder.1.bias: 0.000244479306275025\n",
      "Gradient for encoder.encoder.3.weight: 0.004013494122773409\n",
      "Gradient for encoder.encoder.3.bias: 7.348772285142857e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.0023399468045681715\n",
      "Gradient for encoder.encoder.4.bias: 0.0015069283545017242\n",
      "Gradient for encoder.mean.weight: 0.03791625797748566\n",
      "Gradient for encoder.mean.bias: 0.0013047597603872418\n",
      "Gradient for encoder.log_var.weight: 0.018323732540011406\n",
      "Gradient for encoder.log_var.bias: 0.0007252827053889632\n",
      "Gradient for decoder.decoder.0.weight: 0.011801576241850853\n",
      "Gradient for decoder.decoder.0.bias: 9.908758535903672e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005556197720579803\n",
      "Gradient for decoder.decoder.1.bias: 0.00047282339073717594\n",
      "Gradient for decoder.decoder.3.weight: 0.010710877366364002\n",
      "Gradient for decoder.decoder.3.bias: 7.945953617305435e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00037247303407639265\n",
      "Gradient for decoder.decoder.4.bias: 0.0003414504462853074\n",
      "Gradient for decoder.decoder.6.weight: 0.0004313042445573956\n",
      "Gradient for decoder.decoder.6.bias: 2.214561027358286e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.003098501591011882\n",
      "Gradient for encoder.encoder.0.bias: 5.721642777622993e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.00022072675346862525\n",
      "Gradient for encoder.encoder.1.bias: 0.0002937794488389045\n",
      "Gradient for encoder.encoder.3.weight: 0.0050748963840305805\n",
      "Gradient for encoder.encoder.3.bias: 7.912850930047455e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.0023879241198301315\n",
      "Gradient for encoder.encoder.4.bias: 0.001486727618612349\n",
      "Gradient for encoder.mean.weight: 0.036519329994916916\n",
      "Gradient for encoder.mean.bias: 0.0011013939511030912\n",
      "Gradient for encoder.log_var.weight: 0.02038932591676712\n",
      "Gradient for encoder.log_var.bias: 0.0006978008896112442\n",
      "Gradient for decoder.decoder.0.weight: 0.012113076634705067\n",
      "Gradient for decoder.decoder.0.bias: 9.84187453756391e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005932878120802343\n",
      "Gradient for decoder.decoder.1.bias: 0.0005301680066622794\n",
      "Gradient for decoder.decoder.3.weight: 0.011447547934949398\n",
      "Gradient for decoder.decoder.3.bias: 9.064691358640076e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0004620484833139926\n",
      "Gradient for decoder.decoder.4.bias: 0.0004287826595827937\n",
      "Gradient for decoder.decoder.6.weight: 0.00046624091919511557\n",
      "Gradient for decoder.decoder.6.bias: 2.3282875190488994e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.0022235913202166557\n",
      "Gradient for encoder.encoder.0.bias: 4.084519181213331e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.0001621054543647915\n",
      "Gradient for encoder.encoder.1.bias: 0.00023462423996534199\n",
      "Gradient for encoder.encoder.3.weight: 0.0038136171642690897\n",
      "Gradient for encoder.encoder.3.bias: 8.676333956847415e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.0027173683047294617\n",
      "Gradient for encoder.encoder.4.bias: 0.0017135224770754576\n",
      "Gradient for encoder.mean.weight: 0.04340485483407974\n",
      "Gradient for encoder.mean.bias: 0.0011374508030712605\n",
      "Gradient for encoder.log_var.weight: 0.024742066860198975\n",
      "Gradient for encoder.log_var.bias: 0.0008350170101039112\n",
      "Gradient for decoder.decoder.0.weight: 0.01501865778118372\n",
      "Gradient for decoder.decoder.0.bias: 1.27277841044382e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0007047694525681436\n",
      "Gradient for decoder.decoder.1.bias: 0.0006343229906633496\n",
      "Gradient for decoder.decoder.3.weight: 0.013753058388829231\n",
      "Gradient for decoder.decoder.3.bias: 1.3009966715049615e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0005762966466136277\n",
      "Gradient for decoder.decoder.4.bias: 0.0006086516077630222\n",
      "Gradient for decoder.decoder.6.weight: 0.0005621466552838683\n",
      "Gradient for decoder.decoder.6.bias: 3.9765756810083985e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.0028635808266699314\n",
      "Gradient for encoder.encoder.0.bias: 5.532596082657992e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.00023855311155784875\n",
      "Gradient for encoder.encoder.1.bias: 0.00033689741394482553\n",
      "Gradient for encoder.encoder.3.weight: 0.005124527495354414\n",
      "Gradient for encoder.encoder.3.bias: 8.640962251282858e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.0022168848663568497\n",
      "Gradient for encoder.encoder.4.bias: 0.0016609306912869215\n",
      "Gradient for encoder.mean.weight: 0.03173317387700081\n",
      "Gradient for encoder.mean.bias: 0.0013250225456431508\n",
      "Gradient for encoder.log_var.weight: 0.022993598133325577\n",
      "Gradient for encoder.log_var.bias: 0.0009116143337450922\n",
      "Gradient for decoder.decoder.0.weight: 0.0131740877404809\n",
      "Gradient for decoder.decoder.0.bias: 1.1398543914298287e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0006099622696638107\n",
      "Gradient for decoder.decoder.1.bias: 0.0005131426732987165\n",
      "Gradient for decoder.decoder.3.weight: 0.012075970880687237\n",
      "Gradient for decoder.decoder.3.bias: 1.1023215673588993e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.00048765106475912035\n",
      "Gradient for decoder.decoder.4.bias: 0.00044215971138328314\n",
      "Gradient for decoder.decoder.6.weight: 0.00047393710701726377\n",
      "Gradient for decoder.decoder.6.bias: 2.3599339328939095e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.0023907411377876997\n",
      "Gradient for encoder.encoder.0.bias: 5.836186135060872e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.00023702476755715907\n",
      "Gradient for encoder.encoder.1.bias: 0.00036417553201317787\n",
      "Gradient for encoder.encoder.3.weight: 0.005094442516565323\n",
      "Gradient for encoder.encoder.3.bias: 8.984664401356923e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.0027851974591612816\n",
      "Gradient for encoder.encoder.4.bias: 0.002317562699317932\n",
      "Gradient for encoder.mean.weight: 0.0429338701069355\n",
      "Gradient for encoder.mean.bias: 0.0020550230983644724\n",
      "Gradient for encoder.log_var.weight: 0.024779368191957474\n",
      "Gradient for encoder.log_var.bias: 0.0012622118229046464\n",
      "Gradient for decoder.decoder.0.weight: 0.012549752369523048\n",
      "Gradient for decoder.decoder.0.bias: 1.0078952256131757e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0006026052869856358\n",
      "Gradient for decoder.decoder.1.bias: 0.0005006142891943455\n",
      "Gradient for decoder.decoder.3.weight: 0.011796812526881695\n",
      "Gradient for decoder.decoder.3.bias: 9.065812683894947e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00042650289833545685\n",
      "Gradient for decoder.decoder.4.bias: 0.0004219180846121162\n",
      "Gradient for decoder.decoder.6.weight: 0.0004195638175588101\n",
      "Gradient for decoder.decoder.6.bias: 2.0142155335634016e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.024790113791823387\n",
      "Gradient for encoder.encoder.0.bias: 5.8172602152017916e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.000903372943866998\n",
      "Gradient for encoder.encoder.1.bias: 0.0010803930927067995\n",
      "Gradient for encoder.encoder.3.weight: 0.019631998613476753\n",
      "Gradient for encoder.encoder.3.bias: 2.0702946301742742e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.00392790837213397\n",
      "Gradient for encoder.encoder.4.bias: 0.00409781513735652\n",
      "Gradient for encoder.mean.weight: 0.05459916219115257\n",
      "Gradient for encoder.mean.bias: 0.0025111690629273653\n",
      "Gradient for encoder.log_var.weight: 0.027194876223802567\n",
      "Gradient for encoder.log_var.bias: 0.0015108779771253467\n",
      "Gradient for decoder.decoder.0.weight: 0.01638876460492611\n",
      "Gradient for decoder.decoder.0.bias: 1.1669971933248036e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0006768129533156753\n",
      "Gradient for decoder.decoder.1.bias: 0.0006356554804369807\n",
      "Gradient for decoder.decoder.3.weight: 0.01562042161822319\n",
      "Gradient for decoder.decoder.3.bias: 1.5469603376061514e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.000891994044650346\n",
      "Gradient for decoder.decoder.4.bias: 0.0010444637155160308\n",
      "Gradient for decoder.decoder.6.weight: 0.0008932976634241641\n",
      "Gradient for decoder.decoder.6.bias: 6.344638677546754e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/3, Train Loss: 0.0491, Val Loss: 0.2696\n",
      "Training VAE for class 7...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training VAE Epoch:  10%|█         | 8/79 [00:00<00:02, 33.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient for encoder.encoder.0.weight: 0.010679042898118496\n",
      "Gradient for encoder.encoder.0.bias: 1.8218477074172235e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0010375817073509097\n",
      "Gradient for encoder.encoder.1.bias: 0.0009873067028820515\n",
      "Gradient for encoder.encoder.3.weight: 0.02309095673263073\n",
      "Gradient for encoder.encoder.3.bias: 2.1267441974170964e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0062186759896576405\n",
      "Gradient for encoder.encoder.4.bias: 0.005263828672468662\n",
      "Gradient for encoder.mean.weight: 0.08413201570510864\n",
      "Gradient for encoder.mean.bias: 0.0030086031183600426\n",
      "Gradient for encoder.log_var.weight: 0.053101446479558945\n",
      "Gradient for encoder.log_var.bias: 0.001955172745510936\n",
      "Gradient for decoder.decoder.0.weight: 0.00945900660008192\n",
      "Gradient for decoder.decoder.0.bias: 7.79902462055837e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0004762828757520765\n",
      "Gradient for decoder.decoder.1.bias: 0.0003807374741882086\n",
      "Gradient for decoder.decoder.3.weight: 0.008947811089456081\n",
      "Gradient for decoder.decoder.3.bias: 1.1798619026226476e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0008945793379098177\n",
      "Gradient for decoder.decoder.4.bias: 0.0010912296129390597\n",
      "Gradient for decoder.decoder.6.weight: 0.0009020044235512614\n",
      "Gradient for decoder.decoder.6.bias: 8.25907991384156e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.008259667083621025\n",
      "Gradient for encoder.encoder.0.bias: 1.579569634813094e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0008443424012511969\n",
      "Gradient for encoder.encoder.1.bias: 0.0007018759497441351\n",
      "Gradient for encoder.encoder.3.weight: 0.01899907737970352\n",
      "Gradient for encoder.encoder.3.bias: 1.4826319338911986e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.004693411756306887\n",
      "Gradient for encoder.encoder.4.bias: 0.0032906276173889637\n",
      "Gradient for encoder.mean.weight: 0.060876619070768356\n",
      "Gradient for encoder.mean.bias: 0.0021591270342469215\n",
      "Gradient for encoder.log_var.weight: 0.03823326528072357\n",
      "Gradient for encoder.log_var.bias: 0.0013746214099228382\n",
      "Gradient for decoder.decoder.0.weight: 0.008706393651664257\n",
      "Gradient for decoder.decoder.0.bias: 7.094104470528606e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0004125572449993342\n",
      "Gradient for decoder.decoder.1.bias: 0.0003419227432459593\n",
      "Gradient for decoder.decoder.3.weight: 0.00814193207770586\n",
      "Gradient for decoder.decoder.3.bias: 8.288717628923692e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0005363966338336468\n",
      "Gradient for decoder.decoder.4.bias: 0.0006202519289217889\n",
      "Gradient for decoder.decoder.6.weight: 0.000605264212936163\n",
      "Gradient for decoder.decoder.6.bias: 4.774448098032735e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.004786134231835604\n",
      "Gradient for encoder.encoder.0.bias: 7.901273385568786e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.0004692852671723813\n",
      "Gradient for encoder.encoder.1.bias: 0.0006978207384236157\n",
      "Gradient for encoder.encoder.3.weight: 0.010105387307703495\n",
      "Gradient for encoder.encoder.3.bias: 1.1374667874264333e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.004206337966024876\n",
      "Gradient for encoder.encoder.4.bias: 0.0029615748208016157\n",
      "Gradient for encoder.mean.weight: 0.062301523983478546\n",
      "Gradient for encoder.mean.bias: 0.0021264213137328625\n",
      "Gradient for encoder.log_var.weight: 0.030971592292189598\n",
      "Gradient for encoder.log_var.bias: 0.0013638646341860294\n",
      "Gradient for decoder.decoder.0.weight: 0.013838260434567928\n",
      "Gradient for decoder.decoder.0.bias: 1.1005615169201732e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0007607713923789561\n",
      "Gradient for decoder.decoder.1.bias: 0.0005518211401067674\n",
      "Gradient for decoder.decoder.3.weight: 0.013420363888144493\n",
      "Gradient for decoder.decoder.3.bias: 1.318467418576219e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.001010565203614533\n",
      "Gradient for decoder.decoder.4.bias: 0.001181656145490706\n",
      "Gradient for decoder.decoder.6.weight: 0.0007224904256872833\n",
      "Gradient for decoder.decoder.6.bias: 5.83640176046174e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.008255994878709316\n",
      "Gradient for encoder.encoder.0.bias: 1.3329819886775951e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0005916532245464623\n",
      "Gradient for encoder.encoder.1.bias: 0.0005546440952457488\n",
      "Gradient for encoder.encoder.3.weight: 0.012602186761796474\n",
      "Gradient for encoder.encoder.3.bias: 1.1598572102755611e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0024278515484184027\n",
      "Gradient for encoder.encoder.4.bias: 0.0020599847193807364\n",
      "Gradient for encoder.mean.weight: 0.03221452608704567\n",
      "Gradient for encoder.mean.bias: 0.001540826284326613\n",
      "Gradient for encoder.log_var.weight: 0.01846473477780819\n",
      "Gradient for encoder.log_var.bias: 0.0009954574052244425\n",
      "Gradient for decoder.decoder.0.weight: 0.00960884615778923\n",
      "Gradient for decoder.decoder.0.bias: 8.06340480496992e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0004774741246365011\n",
      "Gradient for decoder.decoder.1.bias: 0.0003712901961989701\n",
      "Gradient for decoder.decoder.3.weight: 0.009482184424996376\n",
      "Gradient for decoder.decoder.3.bias: 9.640216402928559e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0006803821888752282\n",
      "Gradient for decoder.decoder.4.bias: 0.0007789434166625142\n",
      "Gradient for decoder.decoder.6.weight: 0.0007108991267159581\n",
      "Gradient for decoder.decoder.6.bias: 5.8834277297137305e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.007236761040985584\n",
      "Gradient for encoder.encoder.0.bias: 1.2113618268194681e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0007084433455020189\n",
      "Gradient for encoder.encoder.1.bias: 0.0007743049063719809\n",
      "Gradient for encoder.encoder.3.weight: 0.015036145225167274\n",
      "Gradient for encoder.encoder.3.bias: 1.2896944623363993e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0033394251950085163\n",
      "Gradient for encoder.encoder.4.bias: 0.002973560243844986\n",
      "Gradient for encoder.mean.weight: 0.048048608005046844\n",
      "Gradient for encoder.mean.bias: 0.0022258830722421408\n",
      "Gradient for encoder.log_var.weight: 0.02777874283492565\n",
      "Gradient for encoder.log_var.bias: 0.0014755346346646547\n",
      "Gradient for decoder.decoder.0.weight: 0.010460426099598408\n",
      "Gradient for decoder.decoder.0.bias: 8.420453917468151e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005242093466222286\n",
      "Gradient for decoder.decoder.1.bias: 0.0004138341755606234\n",
      "Gradient for decoder.decoder.3.weight: 0.009702467359602451\n",
      "Gradient for decoder.decoder.3.bias: 1.1873849126153857e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0008657333091832697\n",
      "Gradient for decoder.decoder.4.bias: 0.0010762113379314542\n",
      "Gradient for decoder.decoder.6.weight: 0.000812477373983711\n",
      "Gradient for decoder.decoder.6.bias: 7.368437945842743e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.007231981959193945\n",
      "Gradient for encoder.encoder.0.bias: 1.1876406975919185e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0006781871197745204\n",
      "Gradient for encoder.encoder.1.bias: 0.000600281055085361\n",
      "Gradient for encoder.encoder.3.weight: 0.01562519185245037\n",
      "Gradient for encoder.encoder.3.bias: 1.216011319415955e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.002845123643055558\n",
      "Gradient for encoder.encoder.4.bias: 0.002199005801230669\n",
      "Gradient for encoder.mean.weight: 0.03997471183538437\n",
      "Gradient for encoder.mean.bias: 0.0016688271425664425\n",
      "Gradient for encoder.log_var.weight: 0.021069275215268135\n",
      "Gradient for encoder.log_var.bias: 0.0011328469263389707\n",
      "Gradient for decoder.decoder.0.weight: 0.011512392200529575\n",
      "Gradient for decoder.decoder.0.bias: 8.875272738961826e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005733792204409838\n",
      "Gradient for decoder.decoder.1.bias: 0.00045369972940534353\n",
      "Gradient for decoder.decoder.3.weight: 0.01080629788339138\n",
      "Gradient for decoder.decoder.3.bias: 1.6340925834690267e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0012835499364882708\n",
      "Gradient for decoder.decoder.4.bias: 0.0015773159684613347\n",
      "Gradient for decoder.decoder.6.weight: 0.0009893336100503802\n",
      "Gradient for decoder.decoder.6.bias: 9.012711234390736e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.007368492893874645\n",
      "Gradient for encoder.encoder.0.bias: 1.3304441749684148e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0006743145058862865\n",
      "Gradient for encoder.encoder.1.bias: 0.0005046924925409257\n",
      "Gradient for encoder.encoder.3.weight: 0.014969267882406712\n",
      "Gradient for encoder.encoder.3.bias: 1.3299197854088618e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.00358111341483891\n",
      "Gradient for encoder.encoder.4.bias: 0.002762335352599621\n",
      "Gradient for encoder.mean.weight: 0.049197133630514145\n",
      "Gradient for encoder.mean.bias: 0.002015192061662674\n",
      "Gradient for encoder.log_var.weight: 0.030256230384111404\n",
      "Gradient for encoder.log_var.bias: 0.001323855365626514\n",
      "Gradient for decoder.decoder.0.weight: 0.011446534655988216\n",
      "Gradient for decoder.decoder.0.bias: 9.599323419484662e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005778881604783237\n",
      "Gradient for decoder.decoder.1.bias: 0.0004760906158480793\n",
      "Gradient for decoder.decoder.3.weight: 0.011014388874173164\n",
      "Gradient for decoder.decoder.3.bias: 1.854149750402101e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.00141864363104105\n",
      "Gradient for decoder.decoder.4.bias: 0.001823038561269641\n",
      "Gradient for decoder.decoder.6.weight: 0.0010849111713469028\n",
      "Gradient for decoder.decoder.6.bias: 0.0001067460179910995\n",
      "Gradient for encoder.encoder.0.weight: 0.006848135031759739\n",
      "Gradient for encoder.encoder.0.bias: 1.1310236601447254e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.000615077733527869\n",
      "Gradient for encoder.encoder.1.bias: 0.0005370863946154714\n",
      "Gradient for encoder.encoder.3.weight: 0.013399249874055386\n",
      "Gradient for encoder.encoder.3.bias: 1.2981747621321205e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.003682701149955392\n",
      "Gradient for encoder.encoder.4.bias: 0.0027843667194247246\n",
      "Gradient for encoder.mean.weight: 0.05022347718477249\n",
      "Gradient for encoder.mean.bias: 0.0017293106066063046\n",
      "Gradient for encoder.log_var.weight: 0.03341074660420418\n",
      "Gradient for encoder.log_var.bias: 0.0013075569877400994\n",
      "Gradient for decoder.decoder.0.weight: 0.01116167288273573\n",
      "Gradient for decoder.decoder.0.bias: 9.351993485173793e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005406237905845046\n",
      "Gradient for decoder.decoder.1.bias: 0.00045067048631608486\n",
      "Gradient for decoder.decoder.3.weight: 0.010459134355187416\n",
      "Gradient for decoder.decoder.3.bias: 1.571545255041329e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0011947982711717486\n",
      "Gradient for decoder.decoder.4.bias: 0.0015075657283887267\n",
      "Gradient for decoder.decoder.6.weight: 0.0008737627067603171\n",
      "Gradient for decoder.decoder.6.bias: 7.843637285986915e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.007945136167109013\n",
      "Gradient for encoder.encoder.0.bias: 1.3033130130679638e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0005174815305508673\n",
      "Gradient for encoder.encoder.1.bias: 0.0004753063840325922\n",
      "Gradient for encoder.encoder.3.weight: 0.011379027739167213\n",
      "Gradient for encoder.encoder.3.bias: 1.5743624459663152e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.004440794233232737\n",
      "Gradient for encoder.encoder.4.bias: 0.003913735505193472\n",
      "Gradient for encoder.mean.weight: 0.06043519824743271\n",
      "Gradient for encoder.mean.bias: 0.003031707601621747\n",
      "Gradient for encoder.log_var.weight: 0.03921569138765335\n",
      "Gradient for encoder.log_var.bias: 0.0018263759557157755\n",
      "Gradient for decoder.decoder.0.weight: 0.009132947772741318\n",
      "Gradient for decoder.decoder.0.bias: 7.795908363306125e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0004461561038624495\n",
      "Gradient for decoder.decoder.1.bias: 0.00038381596095860004\n",
      "Gradient for decoder.decoder.3.weight: 0.00862857699394226\n",
      "Gradient for decoder.decoder.3.bias: 8.415646651771524e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0006115525029599667\n",
      "Gradient for decoder.decoder.4.bias: 0.0006996370502747595\n",
      "Gradient for decoder.decoder.6.weight: 0.000636969693005085\n",
      "Gradient for decoder.decoder.6.bias: 4.9683287215884775e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.009619222022593021\n",
      "Gradient for encoder.encoder.0.bias: 1.5155088989304843e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.000633828982245177\n",
      "Gradient for encoder.encoder.1.bias: 0.0006013031816110015\n",
      "Gradient for encoder.encoder.3.weight: 0.013705948367714882\n",
      "Gradient for encoder.encoder.3.bias: 1.2682280225995157e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.002790623577311635\n",
      "Gradient for encoder.encoder.4.bias: 0.002662606770172715\n",
      "Gradient for encoder.mean.weight: 0.03808228299021721\n",
      "Gradient for encoder.mean.bias: 0.0018249743152409792\n",
      "Gradient for encoder.log_var.weight: 0.021142609417438507\n",
      "Gradient for encoder.log_var.bias: 0.0011636012932285666\n",
      "Gradient for decoder.decoder.0.weight: 0.009030977264046669\n",
      "Gradient for decoder.decoder.0.bias: 7.795620399209113e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0004490300198085606\n",
      "Gradient for decoder.decoder.1.bias: 0.0003743570705410093\n",
      "Gradient for decoder.decoder.3.weight: 0.00820885319262743\n",
      "Gradient for decoder.decoder.3.bias: 7.819010022780404e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0005199956940487027\n",
      "Gradient for decoder.decoder.4.bias: 0.0006117680459283292\n",
      "Gradient for decoder.decoder.6.weight: 0.0006843972951173782\n",
      "Gradient for decoder.decoder.6.bias: 5.510265691555105e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.008053114637732506\n",
      "Gradient for encoder.encoder.0.bias: 1.4692773039892693e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0005528005422092974\n",
      "Gradient for encoder.encoder.1.bias: 0.0005846578278578818\n",
      "Gradient for encoder.encoder.3.weight: 0.012212813831865788\n",
      "Gradient for encoder.encoder.3.bias: 1.2109752089983772e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.002530548954382539\n",
      "Gradient for encoder.encoder.4.bias: 0.00227795890532434\n",
      "Gradient for encoder.mean.weight: 0.0350479818880558\n",
      "Gradient for encoder.mean.bias: 0.0016023716889321804\n",
      "Gradient for encoder.log_var.weight: 0.020358335226774216\n",
      "Gradient for encoder.log_var.bias: 0.000929197994992137\n",
      "Gradient for decoder.decoder.0.weight: 0.009772171266376972\n",
      "Gradient for decoder.decoder.0.bias: 7.72743813381993e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.00046100476174615324\n",
      "Gradient for decoder.decoder.1.bias: 0.00040105340303853154\n",
      "Gradient for decoder.decoder.3.weight: 0.009361600503325462\n",
      "Gradient for decoder.decoder.3.bias: 9.15365422349268e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0006490660016424954\n",
      "Gradient for decoder.decoder.4.bias: 0.0007319246069528162\n",
      "Gradient for decoder.decoder.6.weight: 0.0006562915514223278\n",
      "Gradient for decoder.decoder.6.bias: 4.9312082410324365e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.007983583956956863\n",
      "Gradient for encoder.encoder.0.bias: 1.2294631458742433e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0005726013914681971\n",
      "Gradient for encoder.encoder.1.bias: 0.0006421640864573419\n",
      "Gradient for encoder.encoder.3.weight: 0.012450074777007103\n",
      "Gradient for encoder.encoder.3.bias: 1.2210500666132162e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0025736268144100904\n",
      "Gradient for encoder.encoder.4.bias: 0.0024871539790183306\n",
      "Gradient for encoder.mean.weight: 0.03583041578531265\n",
      "Gradient for encoder.mean.bias: 0.0020568915642797947\n",
      "Gradient for encoder.log_var.weight: 0.022149989381432533\n",
      "Gradient for encoder.log_var.bias: 0.0012020154390484095\n",
      "Gradient for decoder.decoder.0.weight: 0.010877157561480999\n",
      "Gradient for decoder.decoder.0.bias: 8.87654186265685e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005466715665534139\n",
      "Gradient for decoder.decoder.1.bias: 0.0004498425987549126\n",
      "Gradient for decoder.decoder.3.weight: 0.01022521872073412\n",
      "Gradient for decoder.decoder.3.bias: 9.999830130613674e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.000713805144187063\n",
      "Gradient for decoder.decoder.4.bias: 0.0008397484198212624\n",
      "Gradient for decoder.decoder.6.weight: 0.0006816431414335966\n",
      "Gradient for decoder.decoder.6.bias: 5.190809315536171e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.011576511897146702\n",
      "Gradient for encoder.encoder.0.bias: 2.0383781468291673e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0010028944816440344\n",
      "Gradient for encoder.encoder.1.bias: 0.0008036992512643337\n",
      "Gradient for encoder.encoder.3.weight: 0.02116708643734455\n",
      "Gradient for encoder.encoder.3.bias: 1.6035132943681418e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.004105006344616413\n",
      "Gradient for encoder.encoder.4.bias: 0.003113499144092202\n",
      "Gradient for encoder.mean.weight: 0.0585172213613987\n",
      "Gradient for encoder.mean.bias: 0.0021529013756662607\n",
      "Gradient for encoder.log_var.weight: 0.030711224302649498\n",
      "Gradient for encoder.log_var.bias: 0.0013461520429700613\n",
      "Gradient for decoder.decoder.0.weight: 0.009169182740151882\n",
      "Gradient for decoder.decoder.0.bias: 7.956754699556257e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.00047641381388530135\n",
      "Gradient for decoder.decoder.1.bias: 0.0003680078370962292\n",
      "Gradient for decoder.decoder.3.weight: 0.008761411532759666\n",
      "Gradient for decoder.decoder.3.bias: 8.777750054589362e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0006324085406959057\n",
      "Gradient for decoder.decoder.4.bias: 0.0007186959264799953\n",
      "Gradient for decoder.decoder.6.weight: 0.0008262758492492139\n",
      "Gradient for decoder.decoder.6.bias: 7.359009032370523e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.008481158874928951\n",
      "Gradient for encoder.encoder.0.bias: 1.2684435966858754e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0005389962461777031\n",
      "Gradient for encoder.encoder.1.bias: 0.0005453787161968648\n",
      "Gradient for encoder.encoder.3.weight: 0.011581526137888432\n",
      "Gradient for encoder.encoder.3.bias: 1.1839974833893763e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.002406979212537408\n",
      "Gradient for encoder.encoder.4.bias: 0.0025405215565115213\n",
      "Gradient for encoder.mean.weight: 0.036338552832603455\n",
      "Gradient for encoder.mean.bias: 0.0019315340323373675\n",
      "Gradient for encoder.log_var.weight: 0.019837651401758194\n",
      "Gradient for encoder.log_var.bias: 0.0012885266914963722\n",
      "Gradient for decoder.decoder.0.weight: 0.009587029926478863\n",
      "Gradient for decoder.decoder.0.bias: 8.33355537355196e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.00046733819181099534\n",
      "Gradient for decoder.decoder.1.bias: 0.00040971412090584636\n",
      "Gradient for decoder.decoder.3.weight: 0.008941327221691608\n",
      "Gradient for decoder.decoder.3.bias: 8.315485106047404e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0005091513739898801\n",
      "Gradient for decoder.decoder.4.bias: 0.0005507243913598359\n",
      "Gradient for decoder.decoder.6.weight: 0.0005912975175306201\n",
      "Gradient for decoder.decoder.6.bias: 4.112301394343376e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.004917777143418789\n",
      "Gradient for encoder.encoder.0.bias: 8.630880732329871e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.00060881651006639\n",
      "Gradient for encoder.encoder.1.bias: 0.0007947834674268961\n",
      "Gradient for encoder.encoder.3.weight: 0.013201845809817314\n",
      "Gradient for encoder.encoder.3.bias: 1.2038486874033083e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0038200602866709232\n",
      "Gradient for encoder.encoder.4.bias: 0.0031133315060287714\n",
      "Gradient for encoder.mean.weight: 0.05327834188938141\n",
      "Gradient for encoder.mean.bias: 0.002500939881429076\n",
      "Gradient for encoder.log_var.weight: 0.03459316864609718\n",
      "Gradient for encoder.log_var.bias: 0.001617930131033063\n",
      "Gradient for decoder.decoder.0.weight: 0.013210592791438103\n",
      "Gradient for decoder.decoder.0.bias: 9.889650903760483e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0006479560397565365\n",
      "Gradient for decoder.decoder.1.bias: 0.0005168065545149148\n",
      "Gradient for decoder.decoder.3.weight: 0.012225588783621788\n",
      "Gradient for decoder.decoder.3.bias: 1.0836551794790594e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0008120168349705637\n",
      "Gradient for decoder.decoder.4.bias: 0.0009131964179687202\n",
      "Gradient for decoder.decoder.6.weight: 0.0007172049954533577\n",
      "Gradient for decoder.decoder.6.bias: 5.590181172010489e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training VAE Epoch:  30%|███       | 24/79 [00:00<00:00, 59.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient for encoder.encoder.0.weight: 0.009124181233346462\n",
      "Gradient for encoder.encoder.0.bias: 1.3313819664795279e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0007052061846479774\n",
      "Gradient for encoder.encoder.1.bias: 0.0006077772122807801\n",
      "Gradient for encoder.encoder.3.weight: 0.0156452264636755\n",
      "Gradient for encoder.encoder.3.bias: 1.3286163835779519e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.003347659483551979\n",
      "Gradient for encoder.encoder.4.bias: 0.002607800764963031\n",
      "Gradient for encoder.mean.weight: 0.04689131677150726\n",
      "Gradient for encoder.mean.bias: 0.001892481348477304\n",
      "Gradient for encoder.log_var.weight: 0.02794731967151165\n",
      "Gradient for encoder.log_var.bias: 0.0012157587334513664\n",
      "Gradient for decoder.decoder.0.weight: 0.010495665483176708\n",
      "Gradient for decoder.decoder.0.bias: 8.543223767309982e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005552626680582762\n",
      "Gradient for decoder.decoder.1.bias: 0.0004387788358144462\n",
      "Gradient for decoder.decoder.3.weight: 0.009682067669928074\n",
      "Gradient for decoder.decoder.3.bias: 9.844748627418909e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0007069513667374849\n",
      "Gradient for decoder.decoder.4.bias: 0.0008448955486528575\n",
      "Gradient for decoder.decoder.6.weight: 0.0007616443908773363\n",
      "Gradient for decoder.decoder.6.bias: 6.15473254583776e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.008622491732239723\n",
      "Gradient for encoder.encoder.0.bias: 1.375126922054104e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0005278150783851743\n",
      "Gradient for encoder.encoder.1.bias: 0.0005540464771911502\n",
      "Gradient for encoder.encoder.3.weight: 0.012406435795128345\n",
      "Gradient for encoder.encoder.3.bias: 1.2067916110858334e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0027843064162880182\n",
      "Gradient for encoder.encoder.4.bias: 0.0024032876826822758\n",
      "Gradient for encoder.mean.weight: 0.03806811571121216\n",
      "Gradient for encoder.mean.bias: 0.0017776824533939362\n",
      "Gradient for encoder.log_var.weight: 0.023532312363386154\n",
      "Gradient for encoder.log_var.bias: 0.0010269115446135402\n",
      "Gradient for decoder.decoder.0.weight: 0.009754075668752193\n",
      "Gradient for decoder.decoder.0.bias: 7.764361376061402e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0004821220354642719\n",
      "Gradient for decoder.decoder.1.bias: 0.00038426718674600124\n",
      "Gradient for decoder.decoder.3.weight: 0.009866106323897839\n",
      "Gradient for decoder.decoder.3.bias: 9.37892888352998e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0006351732299663126\n",
      "Gradient for decoder.decoder.4.bias: 0.0007233795477077365\n",
      "Gradient for decoder.decoder.6.weight: 0.0006790844490751624\n",
      "Gradient for decoder.decoder.6.bias: 5.167809649719857e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.006555550266057253\n",
      "Gradient for encoder.encoder.0.bias: 1.0090937634099628e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0005730275297537446\n",
      "Gradient for encoder.encoder.1.bias: 0.0006402370636351407\n",
      "Gradient for encoder.encoder.3.weight: 0.012600824236869812\n",
      "Gradient for encoder.encoder.3.bias: 1.2859940889953236e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.003132158424705267\n",
      "Gradient for encoder.encoder.4.bias: 0.0025502354837954044\n",
      "Gradient for encoder.mean.weight: 0.04464340955018997\n",
      "Gradient for encoder.mean.bias: 0.001748975133523345\n",
      "Gradient for encoder.log_var.weight: 0.02348901890218258\n",
      "Gradient for encoder.log_var.bias: 0.001136171049438417\n",
      "Gradient for decoder.decoder.0.weight: 0.011945946142077446\n",
      "Gradient for decoder.decoder.0.bias: 1.019444528793656e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.000578124076128006\n",
      "Gradient for decoder.decoder.1.bias: 0.0005000660312362015\n",
      "Gradient for decoder.decoder.3.weight: 0.01134015154093504\n",
      "Gradient for decoder.decoder.3.bias: 1.6191356588812766e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.00122038833796978\n",
      "Gradient for decoder.decoder.4.bias: 0.0015039851423352957\n",
      "Gradient for decoder.decoder.6.weight: 0.0010687783360481262\n",
      "Gradient for decoder.decoder.6.bias: 0.00010013324208557606\n",
      "Gradient for encoder.encoder.0.weight: 0.01762087270617485\n",
      "Gradient for encoder.encoder.0.bias: 2.6516464371462156e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.001359598129056394\n",
      "Gradient for encoder.encoder.1.bias: 0.0011603081366047263\n",
      "Gradient for encoder.encoder.3.weight: 0.03004414215683937\n",
      "Gradient for encoder.encoder.3.bias: 2.113189762065204e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.004998920019716024\n",
      "Gradient for encoder.encoder.4.bias: 0.004386843182146549\n",
      "Gradient for encoder.mean.weight: 0.06637834012508392\n",
      "Gradient for encoder.mean.bias: 0.0032236240804195404\n",
      "Gradient for encoder.log_var.weight: 0.041661519557237625\n",
      "Gradient for encoder.log_var.bias: 0.001869036233983934\n",
      "Gradient for decoder.decoder.0.weight: 0.0093800388276577\n",
      "Gradient for decoder.decoder.0.bias: 8.600512663159421e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.00045199907617643476\n",
      "Gradient for decoder.decoder.1.bias: 0.00037580946809612215\n",
      "Gradient for decoder.decoder.3.weight: 0.008457192219793797\n",
      "Gradient for decoder.decoder.3.bias: 1.3330828108060189e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0009020467405207455\n",
      "Gradient for decoder.decoder.4.bias: 0.0011217313585802913\n",
      "Gradient for decoder.decoder.6.weight: 0.0009660748764872551\n",
      "Gradient for decoder.decoder.6.bias: 9.055502596311271e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.0077055045403540134\n",
      "Gradient for encoder.encoder.0.bias: 1.2171959620776995e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0006807355093769729\n",
      "Gradient for encoder.encoder.1.bias: 0.0007327895727939904\n",
      "Gradient for encoder.encoder.3.weight: 0.01503838412463665\n",
      "Gradient for encoder.encoder.3.bias: 1.2027290274829738e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0030176914297044277\n",
      "Gradient for encoder.encoder.4.bias: 0.002290216274559498\n",
      "Gradient for encoder.mean.weight: 0.04068461433053017\n",
      "Gradient for encoder.mean.bias: 0.0016081114299595356\n",
      "Gradient for encoder.log_var.weight: 0.024274490773677826\n",
      "Gradient for encoder.log_var.bias: 0.001060943934135139\n",
      "Gradient for decoder.decoder.0.weight: 0.011933240108191967\n",
      "Gradient for decoder.decoder.0.bias: 9.91031701147449e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0006205157260410488\n",
      "Gradient for decoder.decoder.1.bias: 0.0004845645453315228\n",
      "Gradient for decoder.decoder.3.weight: 0.01148943416774273\n",
      "Gradient for decoder.decoder.3.bias: 1.0798274774348471e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.000762895040679723\n",
      "Gradient for decoder.decoder.4.bias: 0.0008416412747465074\n",
      "Gradient for decoder.decoder.6.weight: 0.0008417567005380988\n",
      "Gradient for decoder.decoder.6.bias: 7.254230877151713e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.013296878896653652\n",
      "Gradient for encoder.encoder.0.bias: 1.7809717242633916e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0007828015950508416\n",
      "Gradient for encoder.encoder.1.bias: 0.0006409153575077653\n",
      "Gradient for encoder.encoder.3.weight: 0.01791476272046566\n",
      "Gradient for encoder.encoder.3.bias: 1.5688651766598838e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0031042310874909163\n",
      "Gradient for encoder.encoder.4.bias: 0.003217515302821994\n",
      "Gradient for encoder.mean.weight: 0.04350234195590019\n",
      "Gradient for encoder.mean.bias: 0.0026060619857162237\n",
      "Gradient for encoder.log_var.weight: 0.02748144045472145\n",
      "Gradient for encoder.log_var.bias: 0.001891288673505187\n",
      "Gradient for decoder.decoder.0.weight: 0.009718052111566067\n",
      "Gradient for decoder.decoder.0.bias: 8.84130615941281e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0004776760470122099\n",
      "Gradient for decoder.decoder.1.bias: 0.00038496433990076184\n",
      "Gradient for decoder.decoder.3.weight: 0.009155900217592716\n",
      "Gradient for decoder.decoder.3.bias: 1.1372508490481437e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0007596049690619111\n",
      "Gradient for decoder.decoder.4.bias: 0.0009344301070086658\n",
      "Gradient for decoder.decoder.6.weight: 0.0007983940886333585\n",
      "Gradient for decoder.decoder.6.bias: 6.792359636165202e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.015384475700557232\n",
      "Gradient for encoder.encoder.0.bias: 1.6505161820612457e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0009189068805426359\n",
      "Gradient for encoder.encoder.1.bias: 0.000823489623144269\n",
      "Gradient for encoder.encoder.3.weight: 0.01920335367321968\n",
      "Gradient for encoder.encoder.3.bias: 1.5253706631135344e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0032966851722449064\n",
      "Gradient for encoder.encoder.4.bias: 0.0032477513886988163\n",
      "Gradient for encoder.mean.weight: 0.044003043323755264\n",
      "Gradient for encoder.mean.bias: 0.0024907710030674934\n",
      "Gradient for encoder.log_var.weight: 0.025156980380415916\n",
      "Gradient for encoder.log_var.bias: 0.001571229542605579\n",
      "Gradient for decoder.decoder.0.weight: 0.009127559140324593\n",
      "Gradient for decoder.decoder.0.bias: 7.945254176799921e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0004666016320697963\n",
      "Gradient for decoder.decoder.1.bias: 0.0003818501136265695\n",
      "Gradient for decoder.decoder.3.weight: 0.008552897721529007\n",
      "Gradient for decoder.decoder.3.bias: 8.585524652326981e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0004690556088462472\n",
      "Gradient for decoder.decoder.4.bias: 0.0005275330622680485\n",
      "Gradient for decoder.decoder.6.weight: 0.0005838747601956129\n",
      "Gradient for decoder.decoder.6.bias: 3.620578354457393e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.007133780978620052\n",
      "Gradient for encoder.encoder.0.bias: 1.1505659272548208e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0005698824534192681\n",
      "Gradient for encoder.encoder.1.bias: 0.00053952302550897\n",
      "Gradient for encoder.encoder.3.weight: 0.012450718320906162\n",
      "Gradient for encoder.encoder.3.bias: 1.2707933316757902e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0027135764248669147\n",
      "Gradient for encoder.encoder.4.bias: 0.0025885533541440964\n",
      "Gradient for encoder.mean.weight: 0.041348058730363846\n",
      "Gradient for encoder.mean.bias: 0.002153086941689253\n",
      "Gradient for encoder.log_var.weight: 0.026012936607003212\n",
      "Gradient for encoder.log_var.bias: 0.0013272063806653023\n",
      "Gradient for decoder.decoder.0.weight: 0.011675108224153519\n",
      "Gradient for decoder.decoder.0.bias: 9.653512017537835e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005668062367476523\n",
      "Gradient for decoder.decoder.1.bias: 0.000475394626846537\n",
      "Gradient for decoder.decoder.3.weight: 0.011218640953302383\n",
      "Gradient for decoder.decoder.3.bias: 1.087383724729385e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0008454230264760554\n",
      "Gradient for decoder.decoder.4.bias: 0.0009562587947584689\n",
      "Gradient for decoder.decoder.6.weight: 0.0008251426625065506\n",
      "Gradient for decoder.decoder.6.bias: 6.706393469357863e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.009941047988831997\n",
      "Gradient for encoder.encoder.0.bias: 1.46834645137206e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.000748319667764008\n",
      "Gradient for encoder.encoder.1.bias: 0.0007419644971378148\n",
      "Gradient for encoder.encoder.3.weight: 0.016219887882471085\n",
      "Gradient for encoder.encoder.3.bias: 1.3350925920363466e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0031252983026206493\n",
      "Gradient for encoder.encoder.4.bias: 0.0030027462635189295\n",
      "Gradient for encoder.mean.weight: 0.044337689876556396\n",
      "Gradient for encoder.mean.bias: 0.0025553416926413774\n",
      "Gradient for encoder.log_var.weight: 0.026104655116796494\n",
      "Gradient for encoder.log_var.bias: 0.0014806324616074562\n",
      "Gradient for decoder.decoder.0.weight: 0.010017406195402145\n",
      "Gradient for decoder.decoder.0.bias: 8.976344667566138e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0004494644526857883\n",
      "Gradient for decoder.decoder.1.bias: 0.0003906738420482725\n",
      "Gradient for decoder.decoder.3.weight: 0.008986792527139187\n",
      "Gradient for decoder.decoder.3.bias: 1.164193741409747e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0009265760309062898\n",
      "Gradient for decoder.decoder.4.bias: 0.0011468398151919246\n",
      "Gradient for decoder.decoder.6.weight: 0.000872377713676542\n",
      "Gradient for decoder.decoder.6.bias: 7.31257678125985e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.011624429374933243\n",
      "Gradient for encoder.encoder.0.bias: 1.523546740156423e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0006755469948984683\n",
      "Gradient for encoder.encoder.1.bias: 0.0006173294968903065\n",
      "Gradient for encoder.encoder.3.weight: 0.014410662464797497\n",
      "Gradient for encoder.encoder.3.bias: 1.4317109997552535e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.003069672267884016\n",
      "Gradient for encoder.encoder.4.bias: 0.0031177173368632793\n",
      "Gradient for encoder.mean.weight: 0.04047110304236412\n",
      "Gradient for encoder.mean.bias: 0.002381326397880912\n",
      "Gradient for encoder.log_var.weight: 0.02872966043651104\n",
      "Gradient for encoder.log_var.bias: 0.0015909981448203325\n",
      "Gradient for decoder.decoder.0.weight: 0.010193374939262867\n",
      "Gradient for decoder.decoder.0.bias: 9.502601483468709e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.00047655581147409976\n",
      "Gradient for decoder.decoder.1.bias: 0.00040474915294907987\n",
      "Gradient for decoder.decoder.3.weight: 0.009543064050376415\n",
      "Gradient for decoder.decoder.3.bias: 1.274405164730652e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0007425591466017067\n",
      "Gradient for decoder.decoder.4.bias: 0.0008968045003712177\n",
      "Gradient for decoder.decoder.6.weight: 0.0008053065976127982\n",
      "Gradient for decoder.decoder.6.bias: 6.439245044020936e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.01081540621817112\n",
      "Gradient for encoder.encoder.0.bias: 1.546057379342436e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0005868618609383702\n",
      "Gradient for encoder.encoder.1.bias: 0.0005611956003122032\n",
      "Gradient for encoder.encoder.3.weight: 0.013409813866019249\n",
      "Gradient for encoder.encoder.3.bias: 1.3067544268885456e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0026342803612351418\n",
      "Gradient for encoder.encoder.4.bias: 0.0023567371536046267\n",
      "Gradient for encoder.mean.weight: 0.036789581179618835\n",
      "Gradient for encoder.mean.bias: 0.0019087836844846606\n",
      "Gradient for encoder.log_var.weight: 0.025131918489933014\n",
      "Gradient for encoder.log_var.bias: 0.0012471138034015894\n",
      "Gradient for decoder.decoder.0.weight: 0.008521431125700474\n",
      "Gradient for decoder.decoder.0.bias: 7.686817155017067e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0004166454600635916\n",
      "Gradient for decoder.decoder.1.bias: 0.0003512325929477811\n",
      "Gradient for decoder.decoder.3.weight: 0.007835691794753075\n",
      "Gradient for decoder.decoder.3.bias: 6.156544024582544e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0003601697681006044\n",
      "Gradient for decoder.decoder.4.bias: 0.00036424002610147\n",
      "Gradient for decoder.decoder.6.weight: 0.000615968310739845\n",
      "Gradient for decoder.decoder.6.bias: 4.172378976363689e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.005909185856580734\n",
      "Gradient for encoder.encoder.0.bias: 9.104556518424456e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.0005073892534710467\n",
      "Gradient for encoder.encoder.1.bias: 0.0004969414439983666\n",
      "Gradient for encoder.encoder.3.weight: 0.011303371749818325\n",
      "Gradient for encoder.encoder.3.bias: 1.2020021089576005e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.003358169924467802\n",
      "Gradient for encoder.encoder.4.bias: 0.002570507815107703\n",
      "Gradient for encoder.mean.weight: 0.04328629747033119\n",
      "Gradient for encoder.mean.bias: 0.0019095804309472442\n",
      "Gradient for encoder.log_var.weight: 0.03267442062497139\n",
      "Gradient for encoder.log_var.bias: 0.001323631964623928\n",
      "Gradient for decoder.decoder.0.weight: 0.012973238714039326\n",
      "Gradient for decoder.decoder.0.bias: 1.1328984278469179e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0006596864550374448\n",
      "Gradient for decoder.decoder.1.bias: 0.0005493235657922924\n",
      "Gradient for decoder.decoder.3.weight: 0.012354760430753231\n",
      "Gradient for decoder.decoder.3.bias: 1.2563028395362608e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0008877972140908241\n",
      "Gradient for decoder.decoder.4.bias: 0.001056792214512825\n",
      "Gradient for decoder.decoder.6.weight: 0.000785786600317806\n",
      "Gradient for decoder.decoder.6.bias: 5.949986007180996e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.006159427110105753\n",
      "Gradient for encoder.encoder.0.bias: 1.0253976487351046e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.000565960188396275\n",
      "Gradient for encoder.encoder.1.bias: 0.0005839627701789141\n",
      "Gradient for encoder.encoder.3.weight: 0.012796266004443169\n",
      "Gradient for encoder.encoder.3.bias: 1.3257606124028598e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.003476650919765234\n",
      "Gradient for encoder.encoder.4.bias: 0.0032148819882422686\n",
      "Gradient for encoder.mean.weight: 0.048354048281908035\n",
      "Gradient for encoder.mean.bias: 0.002410282613709569\n",
      "Gradient for encoder.log_var.weight: 0.028496643528342247\n",
      "Gradient for encoder.log_var.bias: 0.0015689617721363902\n",
      "Gradient for decoder.decoder.0.weight: 0.011122696101665497\n",
      "Gradient for decoder.decoder.0.bias: 9.183821064739917e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005506867310032248\n",
      "Gradient for decoder.decoder.1.bias: 0.00043662296957336366\n",
      "Gradient for decoder.decoder.3.weight: 0.010755532421171665\n",
      "Gradient for decoder.decoder.3.bias: 8.450604105370019e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0005121552967466414\n",
      "Gradient for decoder.decoder.4.bias: 0.0005024766433052719\n",
      "Gradient for decoder.decoder.6.weight: 0.000671696150675416\n",
      "Gradient for decoder.decoder.6.bias: 4.480852294364013e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.013979844748973846\n",
      "Gradient for encoder.encoder.0.bias: 1.895973482379798e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.000966952124144882\n",
      "Gradient for encoder.encoder.1.bias: 0.0006937531288713217\n",
      "Gradient for encoder.encoder.3.weight: 0.02041010744869709\n",
      "Gradient for encoder.encoder.3.bias: 1.7994242207386435e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.004597218241542578\n",
      "Gradient for encoder.encoder.4.bias: 0.004088195506483316\n",
      "Gradient for encoder.mean.weight: 0.06555372476577759\n",
      "Gradient for encoder.mean.bias: 0.0022277566604316235\n",
      "Gradient for encoder.log_var.weight: 0.03723911568522453\n",
      "Gradient for encoder.log_var.bias: 0.001313060405664146\n",
      "Gradient for decoder.decoder.0.weight: 0.00954621471464634\n",
      "Gradient for decoder.decoder.0.bias: 9.26841312032245e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0004648511821869761\n",
      "Gradient for decoder.decoder.1.bias: 0.0003935991844628006\n",
      "Gradient for decoder.decoder.3.weight: 0.00879210326820612\n",
      "Gradient for decoder.decoder.3.bias: 7.887310943255343e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0003258395299781114\n",
      "Gradient for decoder.decoder.4.bias: 0.00028071895940229297\n",
      "Gradient for decoder.decoder.6.weight: 0.0006194679299369454\n",
      "Gradient for decoder.decoder.6.bias: 3.529953755787574e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.013411716558039188\n",
      "Gradient for encoder.encoder.0.bias: 1.8309631588664388e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0011083607096225023\n",
      "Gradient for encoder.encoder.1.bias: 0.0009196221944876015\n",
      "Gradient for encoder.encoder.3.weight: 0.023885546252131462\n",
      "Gradient for encoder.encoder.3.bias: 1.6498608035320217e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0045268177054822445\n",
      "Gradient for encoder.encoder.4.bias: 0.003600267693400383\n",
      "Gradient for encoder.mean.weight: 0.06134923920035362\n",
      "Gradient for encoder.mean.bias: 0.0023909553419798613\n",
      "Gradient for encoder.log_var.weight: 0.03937734290957451\n",
      "Gradient for encoder.log_var.bias: 0.00138740218244493\n",
      "Gradient for decoder.decoder.0.weight: 0.009393543004989624\n",
      "Gradient for decoder.decoder.0.bias: 7.71612565508839e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0004602361877914518\n",
      "Gradient for decoder.decoder.1.bias: 0.0003932796244043857\n",
      "Gradient for decoder.decoder.3.weight: 0.008866259828209877\n",
      "Gradient for decoder.decoder.3.bias: 9.642500686801725e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0006759508396498859\n",
      "Gradient for decoder.decoder.4.bias: 0.0007853361894376576\n",
      "Gradient for decoder.decoder.6.weight: 0.0007243379950523376\n",
      "Gradient for decoder.decoder.6.bias: 5.105384479975328e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training VAE Epoch:  51%|█████     | 40/79 [00:00<00:00, 68.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient for encoder.encoder.0.weight: 0.008817480877041817\n",
      "Gradient for encoder.encoder.0.bias: 1.262499046278398e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0007182681001722813\n",
      "Gradient for encoder.encoder.1.bias: 0.0006691091111861169\n",
      "Gradient for encoder.encoder.3.weight: 0.015344550833106041\n",
      "Gradient for encoder.encoder.3.bias: 1.3358353312398208e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.003651487408205867\n",
      "Gradient for encoder.encoder.4.bias: 0.002821878995746374\n",
      "Gradient for encoder.mean.weight: 0.05048061162233353\n",
      "Gradient for encoder.mean.bias: 0.0019849399104714394\n",
      "Gradient for encoder.log_var.weight: 0.03358765318989754\n",
      "Gradient for encoder.log_var.bias: 0.0013842895859852433\n",
      "Gradient for decoder.decoder.0.weight: 0.01109497994184494\n",
      "Gradient for decoder.decoder.0.bias: 9.080731999677738e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005411622114479542\n",
      "Gradient for decoder.decoder.1.bias: 0.00043215363984927535\n",
      "Gradient for decoder.decoder.3.weight: 0.010097471065819263\n",
      "Gradient for decoder.decoder.3.bias: 1.0546401252309323e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0008353732991963625\n",
      "Gradient for decoder.decoder.4.bias: 0.000963518163189292\n",
      "Gradient for decoder.decoder.6.weight: 0.0008816597401164472\n",
      "Gradient for decoder.decoder.6.bias: 7.277127588167787e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.009044789709150791\n",
      "Gradient for encoder.encoder.0.bias: 1.181957916956966e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0006614509620703757\n",
      "Gradient for encoder.encoder.1.bias: 0.0006090864189900458\n",
      "Gradient for encoder.encoder.3.weight: 0.013805028051137924\n",
      "Gradient for encoder.encoder.3.bias: 1.5824591637070284e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0035944466944783926\n",
      "Gradient for encoder.encoder.4.bias: 0.0033494881354272366\n",
      "Gradient for encoder.mean.weight: 0.04750463739037514\n",
      "Gradient for encoder.mean.bias: 0.002636669436469674\n",
      "Gradient for encoder.log_var.weight: 0.026291584596037865\n",
      "Gradient for encoder.log_var.bias: 0.0015602355124428868\n",
      "Gradient for decoder.decoder.0.weight: 0.011602654121816158\n",
      "Gradient for decoder.decoder.0.bias: 1.0465157213035425e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0005711709382012486\n",
      "Gradient for decoder.decoder.1.bias: 0.00046648381976410747\n",
      "Gradient for decoder.decoder.3.weight: 0.01052064448595047\n",
      "Gradient for decoder.decoder.3.bias: 1.0820147555712367e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0007673967047594488\n",
      "Gradient for decoder.decoder.4.bias: 0.0009315168135799468\n",
      "Gradient for decoder.decoder.6.weight: 0.0008125035674311221\n",
      "Gradient for decoder.decoder.6.bias: 6.218867201823741e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.0077689881436526775\n",
      "Gradient for encoder.encoder.0.bias: 1.0924062869566153e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0006426990730687976\n",
      "Gradient for encoder.encoder.1.bias: 0.0005238070734776556\n",
      "Gradient for encoder.encoder.3.weight: 0.013584291562438011\n",
      "Gradient for encoder.encoder.3.bias: 1.2122451653606703e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.003064926713705063\n",
      "Gradient for encoder.encoder.4.bias: 0.0023285828065127134\n",
      "Gradient for encoder.mean.weight: 0.04463193565607071\n",
      "Gradient for encoder.mean.bias: 0.001475648838095367\n",
      "Gradient for encoder.log_var.weight: 0.022636739537119865\n",
      "Gradient for encoder.log_var.bias: 0.0010128639405593276\n",
      "Gradient for decoder.decoder.0.weight: 0.011347976513206959\n",
      "Gradient for decoder.decoder.0.bias: 1.0205635642135391e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0005852118483744562\n",
      "Gradient for decoder.decoder.1.bias: 0.0004529903526417911\n",
      "Gradient for decoder.decoder.3.weight: 0.010577863082289696\n",
      "Gradient for decoder.decoder.3.bias: 1.0978852549303753e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0006530446698889136\n",
      "Gradient for decoder.decoder.4.bias: 0.0007431236444972456\n",
      "Gradient for decoder.decoder.6.weight: 0.0007523842505179346\n",
      "Gradient for decoder.decoder.6.bias: 5.465133654070087e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.01268771942704916\n",
      "Gradient for encoder.encoder.0.bias: 2.0511601098172072e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0008967636385932565\n",
      "Gradient for encoder.encoder.1.bias: 0.0008882016991265118\n",
      "Gradient for encoder.encoder.3.weight: 0.020152701064944267\n",
      "Gradient for encoder.encoder.3.bias: 1.5382867202262673e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0029999513644725084\n",
      "Gradient for encoder.encoder.4.bias: 0.00285119260661304\n",
      "Gradient for encoder.mean.weight: 0.042773544788360596\n",
      "Gradient for encoder.mean.bias: 0.0024903700686991215\n",
      "Gradient for encoder.log_var.weight: 0.026592601090669632\n",
      "Gradient for encoder.log_var.bias: 0.001381623325869441\n",
      "Gradient for decoder.decoder.0.weight: 0.009043414145708084\n",
      "Gradient for decoder.decoder.0.bias: 7.441808974606445e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005078822141513228\n",
      "Gradient for decoder.decoder.1.bias: 0.00036018912214785814\n",
      "Gradient for decoder.decoder.3.weight: 0.008774988353252411\n",
      "Gradient for decoder.decoder.3.bias: 6.451219419778553e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00035145398578606546\n",
      "Gradient for decoder.decoder.4.bias: 0.00028551911236718297\n",
      "Gradient for decoder.decoder.6.weight: 0.000635560427326709\n",
      "Gradient for decoder.decoder.6.bias: 3.746544098248705e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.007753236219286919\n",
      "Gradient for encoder.encoder.0.bias: 1.3192771528003355e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0006647157715633512\n",
      "Gradient for encoder.encoder.1.bias: 0.0005840678350068629\n",
      "Gradient for encoder.encoder.3.weight: 0.014862935990095139\n",
      "Gradient for encoder.encoder.3.bias: 1.3598989989649368e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0028590168803930283\n",
      "Gradient for encoder.encoder.4.bias: 0.002764100907370448\n",
      "Gradient for encoder.mean.weight: 0.0427619032561779\n",
      "Gradient for encoder.mean.bias: 0.0021346970461308956\n",
      "Gradient for encoder.log_var.weight: 0.02469465509057045\n",
      "Gradient for encoder.log_var.bias: 0.001425264636054635\n",
      "Gradient for decoder.decoder.0.weight: 0.010003604926168919\n",
      "Gradient for decoder.decoder.0.bias: 8.440220050642822e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0004973134491592646\n",
      "Gradient for decoder.decoder.1.bias: 0.00040636566700413823\n",
      "Gradient for decoder.decoder.3.weight: 0.009218377061188221\n",
      "Gradient for decoder.decoder.3.bias: 8.511159138580027e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0005521926796063781\n",
      "Gradient for decoder.decoder.4.bias: 0.0005656075081788003\n",
      "Gradient for decoder.decoder.6.weight: 0.0006875449907965958\n",
      "Gradient for decoder.decoder.6.bias: 4.4227934267837554e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.00990414246916771\n",
      "Gradient for encoder.encoder.0.bias: 1.3849373037277957e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0006073132972232997\n",
      "Gradient for encoder.encoder.1.bias: 0.0005287163075990975\n",
      "Gradient for encoder.encoder.3.weight: 0.013546868227422237\n",
      "Gradient for encoder.encoder.3.bias: 1.5389775565033403e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.004602579865604639\n",
      "Gradient for encoder.encoder.4.bias: 0.003600731026381254\n",
      "Gradient for encoder.mean.weight: 0.06476383656263351\n",
      "Gradient for encoder.mean.bias: 0.0023097305092960596\n",
      "Gradient for encoder.log_var.weight: 0.0366254486143589\n",
      "Gradient for encoder.log_var.bias: 0.001427309587597847\n",
      "Gradient for decoder.decoder.0.weight: 0.009676455520093441\n",
      "Gradient for decoder.decoder.0.bias: 8.512595489618136e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0004713101079687476\n",
      "Gradient for decoder.decoder.1.bias: 0.00038746491190977395\n",
      "Gradient for decoder.decoder.3.weight: 0.009071601554751396\n",
      "Gradient for decoder.decoder.3.bias: 8.045349803031954e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0003421073779463768\n",
      "Gradient for decoder.decoder.4.bias: 0.00031241236138157547\n",
      "Gradient for decoder.decoder.6.weight: 0.0007194393547251821\n",
      "Gradient for decoder.decoder.6.bias: 5.195490302867256e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.008656363002955914\n",
      "Gradient for encoder.encoder.0.bias: 1.307241814796356e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0006635200115852058\n",
      "Gradient for encoder.encoder.1.bias: 0.000627417815849185\n",
      "Gradient for encoder.encoder.3.weight: 0.014271292835474014\n",
      "Gradient for encoder.encoder.3.bias: 1.2636694468604048e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0031801837030798197\n",
      "Gradient for encoder.encoder.4.bias: 0.0022592544555664062\n",
      "Gradient for encoder.mean.weight: 0.04700838774442673\n",
      "Gradient for encoder.mean.bias: 0.0018179940525442362\n",
      "Gradient for encoder.log_var.weight: 0.02780322916805744\n",
      "Gradient for encoder.log_var.bias: 0.00093181396368891\n",
      "Gradient for decoder.decoder.0.weight: 0.009843340143561363\n",
      "Gradient for decoder.decoder.0.bias: 9.036725534539158e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0004919658531434834\n",
      "Gradient for decoder.decoder.1.bias: 0.0004075758042745292\n",
      "Gradient for decoder.decoder.3.weight: 0.00946512259542942\n",
      "Gradient for decoder.decoder.3.bias: 8.93266086099409e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00045096169924363494\n",
      "Gradient for decoder.decoder.4.bias: 0.0004588431620504707\n",
      "Gradient for decoder.decoder.6.weight: 0.0008092116331681609\n",
      "Gradient for decoder.decoder.6.bias: 6.414747622329742e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.0056418851017951965\n",
      "Gradient for encoder.encoder.0.bias: 7.846698985014555e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.0005583749152719975\n",
      "Gradient for encoder.encoder.1.bias: 0.0006298863445408642\n",
      "Gradient for encoder.encoder.3.weight: 0.012178124859929085\n",
      "Gradient for encoder.encoder.3.bias: 1.2618329991997967e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0032485220581293106\n",
      "Gradient for encoder.encoder.4.bias: 0.0031062886118888855\n",
      "Gradient for encoder.mean.weight: 0.04885459691286087\n",
      "Gradient for encoder.mean.bias: 0.002699100412428379\n",
      "Gradient for encoder.log_var.weight: 0.03192751482129097\n",
      "Gradient for encoder.log_var.bias: 0.0014925786526873708\n",
      "Gradient for decoder.decoder.0.weight: 0.013618388213217258\n",
      "Gradient for decoder.decoder.0.bias: 1.2415539429877498e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.000692005967721343\n",
      "Gradient for decoder.decoder.1.bias: 0.0005500604165717959\n",
      "Gradient for decoder.decoder.3.weight: 0.01285480335354805\n",
      "Gradient for decoder.decoder.3.bias: 1.2829252937773816e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0007871860289014876\n",
      "Gradient for decoder.decoder.4.bias: 0.0008954589138738811\n",
      "Gradient for decoder.decoder.6.weight: 0.0008837085333652794\n",
      "Gradient for decoder.decoder.6.bias: 6.934170960448682e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.010044025257229805\n",
      "Gradient for encoder.encoder.0.bias: 1.514273775815589e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0007791222888045013\n",
      "Gradient for encoder.encoder.1.bias: 0.0007352016982622445\n",
      "Gradient for encoder.encoder.3.weight: 0.016772570088505745\n",
      "Gradient for encoder.encoder.3.bias: 1.4535332659715294e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.003152081510052085\n",
      "Gradient for encoder.encoder.4.bias: 0.0029912979807704687\n",
      "Gradient for encoder.mean.weight: 0.045613594353199005\n",
      "Gradient for encoder.mean.bias: 0.0020729920361191034\n",
      "Gradient for encoder.log_var.weight: 0.02661670185625553\n",
      "Gradient for encoder.log_var.bias: 0.0014056324725970626\n",
      "Gradient for decoder.decoder.0.weight: 0.0107836639508605\n",
      "Gradient for decoder.decoder.0.bias: 8.97465990412627e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005216514691710472\n",
      "Gradient for decoder.decoder.1.bias: 0.00044128383160568774\n",
      "Gradient for decoder.decoder.3.weight: 0.010226679034531116\n",
      "Gradient for decoder.decoder.3.bias: 7.600356455306212e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.000433422508649528\n",
      "Gradient for decoder.decoder.4.bias: 0.0004203359130769968\n",
      "Gradient for decoder.decoder.6.weight: 0.0007594564813189209\n",
      "Gradient for decoder.decoder.6.bias: 5.3765503253089264e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.007550844457000494\n",
      "Gradient for encoder.encoder.0.bias: 1.2602256044269566e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0007790480158291757\n",
      "Gradient for encoder.encoder.1.bias: 0.000691253982950002\n",
      "Gradient for encoder.encoder.3.weight: 0.016739143058657646\n",
      "Gradient for encoder.encoder.3.bias: 1.4724020613865463e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.00398163590580225\n",
      "Gradient for encoder.encoder.4.bias: 0.002809936413541436\n",
      "Gradient for encoder.mean.weight: 0.05503258481621742\n",
      "Gradient for encoder.mean.bias: 0.0018638047622516751\n",
      "Gradient for encoder.log_var.weight: 0.027289019897580147\n",
      "Gradient for encoder.log_var.bias: 0.0012472164817154408\n",
      "Gradient for decoder.decoder.0.weight: 0.011759734712541103\n",
      "Gradient for decoder.decoder.0.bias: 9.850883997408744e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005176200065761805\n",
      "Gradient for decoder.decoder.1.bias: 0.0005002132384106517\n",
      "Gradient for decoder.decoder.3.weight: 0.010964836925268173\n",
      "Gradient for decoder.decoder.3.bias: 1.189894988096185e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0006766321021132171\n",
      "Gradient for decoder.decoder.4.bias: 0.0007725336472503841\n",
      "Gradient for decoder.decoder.6.weight: 0.0008768771076574922\n",
      "Gradient for decoder.decoder.6.bias: 6.676607154076919e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.009814146906137466\n",
      "Gradient for encoder.encoder.0.bias: 1.5358048166547178e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0010721792932599783\n",
      "Gradient for encoder.encoder.1.bias: 0.0011147632030770183\n",
      "Gradient for encoder.encoder.3.weight: 0.023053353652358055\n",
      "Gradient for encoder.encoder.3.bias: 1.5287113241946315e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.004627353511750698\n",
      "Gradient for encoder.encoder.4.bias: 0.003766051260754466\n",
      "Gradient for encoder.mean.weight: 0.06577752530574799\n",
      "Gradient for encoder.mean.bias: 0.0027561704628169537\n",
      "Gradient for encoder.log_var.weight: 0.036013226956129074\n",
      "Gradient for encoder.log_var.bias: 0.00184976018499583\n",
      "Gradient for decoder.decoder.0.weight: 0.0104522705078125\n",
      "Gradient for decoder.decoder.0.bias: 9.948773749268724e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005100785056129098\n",
      "Gradient for decoder.decoder.1.bias: 0.0004430943517945707\n",
      "Gradient for decoder.decoder.3.weight: 0.009922401048243046\n",
      "Gradient for decoder.decoder.3.bias: 7.995169803987068e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0004910272546112537\n",
      "Gradient for decoder.decoder.4.bias: 0.0004848735698033124\n",
      "Gradient for decoder.decoder.6.weight: 0.000774966727476567\n",
      "Gradient for decoder.decoder.6.bias: 5.111722930450924e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.0059199645183980465\n",
      "Gradient for encoder.encoder.0.bias: 8.66328449949938e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.0004745458427350968\n",
      "Gradient for encoder.encoder.1.bias: 0.00047630633343942463\n",
      "Gradient for encoder.encoder.3.weight: 0.010466005653142929\n",
      "Gradient for encoder.encoder.3.bias: 1.1120182552559754e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.00252808490768075\n",
      "Gradient for encoder.encoder.4.bias: 0.002221958013251424\n",
      "Gradient for encoder.mean.weight: 0.0372718907892704\n",
      "Gradient for encoder.mean.bias: 0.0016532898880541325\n",
      "Gradient for encoder.log_var.weight: 0.023053297773003578\n",
      "Gradient for encoder.log_var.bias: 0.0009497539722360671\n",
      "Gradient for decoder.decoder.0.weight: 0.012993733398616314\n",
      "Gradient for decoder.decoder.0.bias: 1.0652693310797545e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0006662410451099277\n",
      "Gradient for decoder.decoder.1.bias: 0.0005859268130734563\n",
      "Gradient for decoder.decoder.3.weight: 0.012708231806755066\n",
      "Gradient for decoder.decoder.3.bias: 1.0708485487231911e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0006029657670296729\n",
      "Gradient for decoder.decoder.4.bias: 0.0005803679232485592\n",
      "Gradient for decoder.decoder.6.weight: 0.0007627978338859975\n",
      "Gradient for decoder.decoder.6.bias: 4.222612187732011e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.008824357762932777\n",
      "Gradient for encoder.encoder.0.bias: 1.4008500956452785e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0005786921828985214\n",
      "Gradient for encoder.encoder.1.bias: 0.0005217049620114267\n",
      "Gradient for encoder.encoder.3.weight: 0.012911359779536724\n",
      "Gradient for encoder.encoder.3.bias: 1.306453140115238e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0029599855188280344\n",
      "Gradient for encoder.encoder.4.bias: 0.002656902652233839\n",
      "Gradient for encoder.mean.weight: 0.0435459241271019\n",
      "Gradient for encoder.mean.bias: 0.002287474228069186\n",
      "Gradient for encoder.log_var.weight: 0.023508403450250626\n",
      "Gradient for encoder.log_var.bias: 0.0011769830016419291\n",
      "Gradient for decoder.decoder.0.weight: 0.010158311575651169\n",
      "Gradient for decoder.decoder.0.bias: 8.435304538201294e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0004925404209643602\n",
      "Gradient for decoder.decoder.1.bias: 0.0004042703367304057\n",
      "Gradient for decoder.decoder.3.weight: 0.00936805922538042\n",
      "Gradient for decoder.decoder.3.bias: 7.320940381694285e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0003602338256314397\n",
      "Gradient for decoder.decoder.4.bias: 0.00030158553272485733\n",
      "Gradient for decoder.decoder.6.weight: 0.0006656477926298976\n",
      "Gradient for decoder.decoder.6.bias: 3.1970444979378954e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.007680781185626984\n",
      "Gradient for encoder.encoder.0.bias: 1.2388695971865538e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0006367058958858252\n",
      "Gradient for encoder.encoder.1.bias: 0.0005700444453395903\n",
      "Gradient for encoder.encoder.3.weight: 0.013131505809724331\n",
      "Gradient for encoder.encoder.3.bias: 1.1350980572144564e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0024142710026353598\n",
      "Gradient for encoder.encoder.4.bias: 0.0021869901102036238\n",
      "Gradient for encoder.mean.weight: 0.0371483713388443\n",
      "Gradient for encoder.mean.bias: 0.0016367179341614246\n",
      "Gradient for encoder.log_var.weight: 0.02108433097600937\n",
      "Gradient for encoder.log_var.bias: 0.0009778583189472556\n",
      "Gradient for decoder.decoder.0.weight: 0.010923677124083042\n",
      "Gradient for decoder.decoder.0.bias: 8.416660424170885e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.000557631952688098\n",
      "Gradient for decoder.decoder.1.bias: 0.0004565757408272475\n",
      "Gradient for decoder.decoder.3.weight: 0.010381855070590973\n",
      "Gradient for decoder.decoder.3.bias: 7.296595966321817e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0004286732291802764\n",
      "Gradient for decoder.decoder.4.bias: 0.0003967504599131644\n",
      "Gradient for decoder.decoder.6.weight: 0.0006679698708467185\n",
      "Gradient for decoder.decoder.6.bias: 3.7358022382250056e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.010010248981416225\n",
      "Gradient for encoder.encoder.0.bias: 1.3240825970373127e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.000650069850962609\n",
      "Gradient for encoder.encoder.1.bias: 0.0005339235067367554\n",
      "Gradient for encoder.encoder.3.weight: 0.014094984158873558\n",
      "Gradient for encoder.encoder.3.bias: 1.2571969854047182e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.002961967373266816\n",
      "Gradient for encoder.encoder.4.bias: 0.0023702532052993774\n",
      "Gradient for encoder.mean.weight: 0.041218116879463196\n",
      "Gradient for encoder.mean.bias: 0.0017929601017385721\n",
      "Gradient for encoder.log_var.weight: 0.02836679294705391\n",
      "Gradient for encoder.log_var.bias: 0.001228434732183814\n",
      "Gradient for decoder.decoder.0.weight: 0.010099958628416061\n",
      "Gradient for decoder.decoder.0.bias: 8.466474049617645e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.00047794097918085754\n",
      "Gradient for decoder.decoder.1.bias: 0.0004225540906190872\n",
      "Gradient for decoder.decoder.3.weight: 0.009514695033431053\n",
      "Gradient for decoder.decoder.3.bias: 7.505294996601464e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00035837088944390416\n",
      "Gradient for decoder.decoder.4.bias: 0.0003110943653155118\n",
      "Gradient for decoder.decoder.6.weight: 0.0007852321723476052\n",
      "Gradient for decoder.decoder.6.bias: 5.480583422468044e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.007391622290015221\n",
      "Gradient for encoder.encoder.0.bias: 1.008750461634067e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0005994386738166213\n",
      "Gradient for encoder.encoder.1.bias: 0.0004815874563064426\n",
      "Gradient for encoder.encoder.3.weight: 0.012781261466443539\n",
      "Gradient for encoder.encoder.3.bias: 1.362335938503989e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0036507572513073683\n",
      "Gradient for encoder.encoder.4.bias: 0.0029902299866080284\n",
      "Gradient for encoder.mean.weight: 0.04909820109605789\n",
      "Gradient for encoder.mean.bias: 0.0018968534423038363\n",
      "Gradient for encoder.log_var.weight: 0.02762596867978573\n",
      "Gradient for encoder.log_var.bias: 0.0012873625382781029\n",
      "Gradient for decoder.decoder.0.weight: 0.011505182832479477\n",
      "Gradient for decoder.decoder.0.bias: 9.73576289031719e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.000536785984877497\n",
      "Gradient for decoder.decoder.1.bias: 0.0004681780992541462\n",
      "Gradient for decoder.decoder.3.weight: 0.010555445216596127\n",
      "Gradient for decoder.decoder.3.bias: 9.587804855604176e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0005289714899845421\n",
      "Gradient for decoder.decoder.4.bias: 0.0005572130321525037\n",
      "Gradient for decoder.decoder.6.weight: 0.0007132894825190306\n",
      "Gradient for decoder.decoder.6.bias: 3.9498001569882035e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training VAE Epoch:  71%|███████   | 56/79 [00:00<00:00, 71.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient for encoder.encoder.0.weight: 0.006811354774981737\n",
      "Gradient for encoder.encoder.0.bias: 1.03424664665841e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0006166149978525937\n",
      "Gradient for encoder.encoder.1.bias: 0.0005645787459798157\n",
      "Gradient for encoder.encoder.3.weight: 0.013713502325117588\n",
      "Gradient for encoder.encoder.3.bias: 1.1264845306557802e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.002875442150980234\n",
      "Gradient for encoder.encoder.4.bias: 0.002090382855385542\n",
      "Gradient for encoder.mean.weight: 0.04193507134914398\n",
      "Gradient for encoder.mean.bias: 0.001721111824735999\n",
      "Gradient for encoder.log_var.weight: 0.021921003237366676\n",
      "Gradient for encoder.log_var.bias: 0.0009818114340305328\n",
      "Gradient for decoder.decoder.0.weight: 0.010518920607864857\n",
      "Gradient for decoder.decoder.0.bias: 9.296073633091595e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005105952150188386\n",
      "Gradient for decoder.decoder.1.bias: 0.0004368017544038594\n",
      "Gradient for decoder.decoder.3.weight: 0.010363521054387093\n",
      "Gradient for decoder.decoder.3.bias: 8.103511611734504e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00042035029036924243\n",
      "Gradient for decoder.decoder.4.bias: 0.0004135068447794765\n",
      "Gradient for decoder.decoder.6.weight: 0.0006814179359935224\n",
      "Gradient for decoder.decoder.6.bias: 3.568263855413534e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.007360583636909723\n",
      "Gradient for encoder.encoder.0.bias: 1.1572087038613788e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0005915584624744952\n",
      "Gradient for encoder.encoder.1.bias: 0.0005648828810080886\n",
      "Gradient for encoder.encoder.3.weight: 0.01224404014647007\n",
      "Gradient for encoder.encoder.3.bias: 1.0939462530279442e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.002571405377238989\n",
      "Gradient for encoder.encoder.4.bias: 0.002115175360813737\n",
      "Gradient for encoder.mean.weight: 0.038014642894268036\n",
      "Gradient for encoder.mean.bias: 0.0018820844125002623\n",
      "Gradient for encoder.log_var.weight: 0.019765734672546387\n",
      "Gradient for encoder.log_var.bias: 0.0008775771711952984\n",
      "Gradient for decoder.decoder.0.weight: 0.01068695168942213\n",
      "Gradient for decoder.decoder.0.bias: 9.301875936174042e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0004997910582460463\n",
      "Gradient for decoder.decoder.1.bias: 0.0004517768684308976\n",
      "Gradient for decoder.decoder.3.weight: 0.010330592282116413\n",
      "Gradient for decoder.decoder.3.bias: 8.622245278866458e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0004711397923529148\n",
      "Gradient for decoder.decoder.4.bias: 0.0004923990345560014\n",
      "Gradient for decoder.decoder.6.weight: 0.000737861089874059\n",
      "Gradient for decoder.decoder.6.bias: 4.346650530351326e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.008440259844064713\n",
      "Gradient for encoder.encoder.0.bias: 1.2534142994347075e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.000570778560359031\n",
      "Gradient for encoder.encoder.1.bias: 0.0004961303202435374\n",
      "Gradient for encoder.encoder.3.weight: 0.012282137759029865\n",
      "Gradient for encoder.encoder.3.bias: 1.278752520539328e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0025221887044608593\n",
      "Gradient for encoder.encoder.4.bias: 0.0023602137807756662\n",
      "Gradient for encoder.mean.weight: 0.0383845716714859\n",
      "Gradient for encoder.mean.bias: 0.0019170216983184218\n",
      "Gradient for encoder.log_var.weight: 0.019859693944454193\n",
      "Gradient for encoder.log_var.bias: 0.0010000645415857434\n",
      "Gradient for decoder.decoder.0.weight: 0.00941908173263073\n",
      "Gradient for decoder.decoder.0.bias: 7.791488981778727e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.00045248738024383783\n",
      "Gradient for decoder.decoder.1.bias: 0.00041697343112900853\n",
      "Gradient for decoder.decoder.3.weight: 0.008647441864013672\n",
      "Gradient for decoder.decoder.3.bias: 6.815753517130929e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00037207070272415876\n",
      "Gradient for decoder.decoder.4.bias: 0.0003796237870119512\n",
      "Gradient for decoder.decoder.6.weight: 0.0006797234527766705\n",
      "Gradient for decoder.decoder.6.bias: 4.1492661694064736e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.007894056849181652\n",
      "Gradient for encoder.encoder.0.bias: 1.108215255674061e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0006482193130068481\n",
      "Gradient for encoder.encoder.1.bias: 0.0006828068289905787\n",
      "Gradient for encoder.encoder.3.weight: 0.014396578073501587\n",
      "Gradient for encoder.encoder.3.bias: 1.5126486174743548e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0033599366433918476\n",
      "Gradient for encoder.encoder.4.bias: 0.0034764467272907495\n",
      "Gradient for encoder.mean.weight: 0.04967016354203224\n",
      "Gradient for encoder.mean.bias: 0.0032419338822364807\n",
      "Gradient for encoder.log_var.weight: 0.030608417466282845\n",
      "Gradient for encoder.log_var.bias: 0.0020908245351165533\n",
      "Gradient for decoder.decoder.0.weight: 0.012366357259452343\n",
      "Gradient for decoder.decoder.0.bias: 9.734069800204637e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.000596244353801012\n",
      "Gradient for decoder.decoder.1.bias: 0.0005149756325408816\n",
      "Gradient for decoder.decoder.3.weight: 0.011338993906974792\n",
      "Gradient for decoder.decoder.3.bias: 7.992485839825036e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0004143859550822526\n",
      "Gradient for decoder.decoder.4.bias: 0.00038802644121460617\n",
      "Gradient for decoder.decoder.6.weight: 0.0006746375584043562\n",
      "Gradient for decoder.decoder.6.bias: 3.541938713169657e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.0075611830689013\n",
      "Gradient for encoder.encoder.0.bias: 9.789845149821286e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.00047645080485381186\n",
      "Gradient for encoder.encoder.1.bias: 0.0004330401716288179\n",
      "Gradient for encoder.encoder.3.weight: 0.01021805964410305\n",
      "Gradient for encoder.encoder.3.bias: 1.5779484663358545e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0038938168436288834\n",
      "Gradient for encoder.encoder.4.bias: 0.004430891014635563\n",
      "Gradient for encoder.mean.weight: 0.053161583840847015\n",
      "Gradient for encoder.mean.bias: 0.003548197913914919\n",
      "Gradient for encoder.log_var.weight: 0.03534597530961037\n",
      "Gradient for encoder.log_var.bias: 0.002397378673776984\n",
      "Gradient for decoder.decoder.0.weight: 0.010330040007829666\n",
      "Gradient for decoder.decoder.0.bias: 9.391188521279403e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005162166198715568\n",
      "Gradient for decoder.decoder.1.bias: 0.00045723715447820723\n",
      "Gradient for decoder.decoder.3.weight: 0.009723401628434658\n",
      "Gradient for decoder.decoder.3.bias: 7.873129925783928e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00038351412513293326\n",
      "Gradient for decoder.decoder.4.bias: 0.00036422384437173605\n",
      "Gradient for decoder.decoder.6.weight: 0.0008374715107493103\n",
      "Gradient for decoder.decoder.6.bias: 6.629995186813176e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.006813011597841978\n",
      "Gradient for encoder.encoder.0.bias: 8.816950641810095e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.0004070488503202796\n",
      "Gradient for encoder.encoder.1.bias: 0.000381516816560179\n",
      "Gradient for encoder.encoder.3.weight: 0.00927562266588211\n",
      "Gradient for encoder.encoder.3.bias: 1.1317416448441975e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0024174749851226807\n",
      "Gradient for encoder.encoder.4.bias: 0.0021583917550742626\n",
      "Gradient for encoder.mean.weight: 0.033441212028265\n",
      "Gradient for encoder.mean.bias: 0.001680587767623365\n",
      "Gradient for encoder.log_var.weight: 0.01806732825934887\n",
      "Gradient for encoder.log_var.bias: 0.0009600315825082362\n",
      "Gradient for decoder.decoder.0.weight: 0.012149416841566563\n",
      "Gradient for decoder.decoder.0.bias: 9.957727697962326e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0006206364487297833\n",
      "Gradient for decoder.decoder.1.bias: 0.0005121747381053865\n",
      "Gradient for decoder.decoder.3.weight: 0.011387220583856106\n",
      "Gradient for decoder.decoder.3.bias: 8.012900065690332e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00048386864364147186\n",
      "Gradient for decoder.decoder.4.bias: 0.0004718193376902491\n",
      "Gradient for decoder.decoder.6.weight: 0.0007019241456873715\n",
      "Gradient for decoder.decoder.6.bias: 3.62516802852042e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.007169765420258045\n",
      "Gradient for encoder.encoder.0.bias: 1.0537451987369106e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0005691066617146134\n",
      "Gradient for encoder.encoder.1.bias: 0.0005061131669208407\n",
      "Gradient for encoder.encoder.3.weight: 0.01224436517804861\n",
      "Gradient for encoder.encoder.3.bias: 1.283101958016175e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0032508859876543283\n",
      "Gradient for encoder.encoder.4.bias: 0.0024064574390649796\n",
      "Gradient for encoder.mean.weight: 0.04337330907583237\n",
      "Gradient for encoder.mean.bias: 0.0017502100672572851\n",
      "Gradient for encoder.log_var.weight: 0.023549001663923264\n",
      "Gradient for encoder.log_var.bias: 0.0011010621674358845\n",
      "Gradient for decoder.decoder.0.weight: 0.011104310862720013\n",
      "Gradient for decoder.decoder.0.bias: 9.718677251857599e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005310668493621051\n",
      "Gradient for decoder.decoder.1.bias: 0.00044443723163567483\n",
      "Gradient for decoder.decoder.3.weight: 0.01054470706731081\n",
      "Gradient for decoder.decoder.3.bias: 9.461936789634251e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0005393872852437198\n",
      "Gradient for decoder.decoder.4.bias: 0.000597032776568085\n",
      "Gradient for decoder.decoder.6.weight: 0.0009487661882303655\n",
      "Gradient for decoder.decoder.6.bias: 7.517891936004162e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.007192322053015232\n",
      "Gradient for encoder.encoder.0.bias: 9.765194729227655e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.0004945973632857203\n",
      "Gradient for encoder.encoder.1.bias: 0.0004182218690402806\n",
      "Gradient for encoder.encoder.3.weight: 0.01031265314668417\n",
      "Gradient for encoder.encoder.3.bias: 1.13078178765047e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.002578454092144966\n",
      "Gradient for encoder.encoder.4.bias: 0.0021089946385473013\n",
      "Gradient for encoder.mean.weight: 0.03592785820364952\n",
      "Gradient for encoder.mean.bias: 0.0017686516512185335\n",
      "Gradient for encoder.log_var.weight: 0.0199145320802927\n",
      "Gradient for encoder.log_var.bias: 0.0010413001291453838\n",
      "Gradient for decoder.decoder.0.weight: 0.011725104413926601\n",
      "Gradient for decoder.decoder.0.bias: 1.0644494313760688e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0005360053037293255\n",
      "Gradient for decoder.decoder.1.bias: 0.00045342749217525125\n",
      "Gradient for decoder.decoder.3.weight: 0.010738842189311981\n",
      "Gradient for decoder.decoder.3.bias: 8.806880225087355e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0004303444584365934\n",
      "Gradient for decoder.decoder.4.bias: 0.00040597713086754084\n",
      "Gradient for decoder.decoder.6.weight: 0.0007427511154673994\n",
      "Gradient for decoder.decoder.6.bias: 4.764251207234338e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.0061927009373903275\n",
      "Gradient for encoder.encoder.0.bias: 9.496939692987816e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.0005746274837292731\n",
      "Gradient for encoder.encoder.1.bias: 0.000601855106651783\n",
      "Gradient for encoder.encoder.3.weight: 0.01209783274680376\n",
      "Gradient for encoder.encoder.3.bias: 1.3335102466704996e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0031886491924524307\n",
      "Gradient for encoder.encoder.4.bias: 0.0032438028138130903\n",
      "Gradient for encoder.mean.weight: 0.04755702614784241\n",
      "Gradient for encoder.mean.bias: 0.002602608175948262\n",
      "Gradient for encoder.log_var.weight: 0.026833800598978996\n",
      "Gradient for encoder.log_var.bias: 0.0017178297275677323\n",
      "Gradient for decoder.decoder.0.weight: 0.01166785228997469\n",
      "Gradient for decoder.decoder.0.bias: 1.0085746127153072e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.000584449153393507\n",
      "Gradient for decoder.decoder.1.bias: 0.0004908479750156403\n",
      "Gradient for decoder.decoder.3.weight: 0.011036116629838943\n",
      "Gradient for decoder.decoder.3.bias: 8.895564840294412e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00040842159069143236\n",
      "Gradient for decoder.decoder.4.bias: 0.0003835974493995309\n",
      "Gradient for decoder.decoder.6.weight: 0.0007262934814207256\n",
      "Gradient for decoder.decoder.6.bias: 4.0153950976673514e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.009299361146986485\n",
      "Gradient for encoder.encoder.0.bias: 1.5758883781247235e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.000819589477032423\n",
      "Gradient for encoder.encoder.1.bias: 0.0008259108872152865\n",
      "Gradient for encoder.encoder.3.weight: 0.017852766439318657\n",
      "Gradient for encoder.encoder.3.bias: 1.7752774250645587e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0046460265293717384\n",
      "Gradient for encoder.encoder.4.bias: 0.004269538447260857\n",
      "Gradient for encoder.mean.weight: 0.0671376883983612\n",
      "Gradient for encoder.mean.bias: 0.0030806988943368196\n",
      "Gradient for encoder.log_var.weight: 0.03986622393131256\n",
      "Gradient for encoder.log_var.bias: 0.0020194139797240496\n",
      "Gradient for decoder.decoder.0.weight: 0.009687868878245354\n",
      "Gradient for decoder.decoder.0.bias: 8.66490629247707e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0004643652937375009\n",
      "Gradient for decoder.decoder.1.bias: 0.000404121121391654\n",
      "Gradient for decoder.decoder.3.weight: 0.009144374169409275\n",
      "Gradient for decoder.decoder.3.bias: 7.4175061925974e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00044425070518627763\n",
      "Gradient for decoder.decoder.4.bias: 0.000452163367299363\n",
      "Gradient for decoder.decoder.6.weight: 0.0007392842089757323\n",
      "Gradient for decoder.decoder.6.bias: 4.5429434976540506e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.005058319307863712\n",
      "Gradient for encoder.encoder.0.bias: 8.841584582530704e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.00041469329153187573\n",
      "Gradient for encoder.encoder.1.bias: 0.0004503464442677796\n",
      "Gradient for encoder.encoder.3.weight: 0.009479667991399765\n",
      "Gradient for encoder.encoder.3.bias: 1.1761165652490746e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0029576001688838005\n",
      "Gradient for encoder.encoder.4.bias: 0.002366828266531229\n",
      "Gradient for encoder.mean.weight: 0.04225463420152664\n",
      "Gradient for encoder.mean.bias: 0.0016976475017145276\n",
      "Gradient for encoder.log_var.weight: 0.020510496571660042\n",
      "Gradient for encoder.log_var.bias: 0.0009708958095870912\n",
      "Gradient for decoder.decoder.0.weight: 0.012161120772361755\n",
      "Gradient for decoder.decoder.0.bias: 1.1210006534145833e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0006094247219152749\n",
      "Gradient for decoder.decoder.1.bias: 0.0005432103644125164\n",
      "Gradient for decoder.decoder.3.weight: 0.011499624699354172\n",
      "Gradient for decoder.decoder.3.bias: 9.605024414716112e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0004979287623427808\n",
      "Gradient for decoder.decoder.4.bias: 0.0004921072395518422\n",
      "Gradient for decoder.decoder.6.weight: 0.000716381473466754\n",
      "Gradient for decoder.decoder.6.bias: 3.5701992601389065e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.007375508546829224\n",
      "Gradient for encoder.encoder.0.bias: 1.1239833716536474e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0005818299832753837\n",
      "Gradient for encoder.encoder.1.bias: 0.0005531274364329875\n",
      "Gradient for encoder.encoder.3.weight: 0.01247358974069357\n",
      "Gradient for encoder.encoder.3.bias: 1.3242808238889126e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0030311327427625656\n",
      "Gradient for encoder.encoder.4.bias: 0.0023308023810386658\n",
      "Gradient for encoder.mean.weight: 0.04058759659528732\n",
      "Gradient for encoder.mean.bias: 0.0017157200491055846\n",
      "Gradient for encoder.log_var.weight: 0.023600930348038673\n",
      "Gradient for encoder.log_var.bias: 0.0010990053415298462\n",
      "Gradient for decoder.decoder.0.weight: 0.011061456985771656\n",
      "Gradient for decoder.decoder.0.bias: 8.728854444806089e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005016487557440996\n",
      "Gradient for decoder.decoder.1.bias: 0.0004454956215340644\n",
      "Gradient for decoder.decoder.3.weight: 0.010202981531620026\n",
      "Gradient for decoder.decoder.3.bias: 7.630233250788265e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0003625483950600028\n",
      "Gradient for decoder.decoder.4.bias: 0.0003478351281955838\n",
      "Gradient for decoder.decoder.6.weight: 0.0006920587038621306\n",
      "Gradient for decoder.decoder.6.bias: 3.631861909525469e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.009008258581161499\n",
      "Gradient for encoder.encoder.0.bias: 1.53319787421502e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0007255916716530919\n",
      "Gradient for encoder.encoder.1.bias: 0.0006194492452777922\n",
      "Gradient for encoder.encoder.3.weight: 0.014898020774126053\n",
      "Gradient for encoder.encoder.3.bias: 1.4778195334130828e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0033425434958189726\n",
      "Gradient for encoder.encoder.4.bias: 0.003106992691755295\n",
      "Gradient for encoder.mean.weight: 0.04503735899925232\n",
      "Gradient for encoder.mean.bias: 0.0025460519827902317\n",
      "Gradient for encoder.log_var.weight: 0.026394914835691452\n",
      "Gradient for encoder.log_var.bias: 0.0017387234838679433\n",
      "Gradient for decoder.decoder.0.weight: 0.008637209422886372\n",
      "Gradient for decoder.decoder.0.bias: 8.03269950555574e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.00041678891284391284\n",
      "Gradient for decoder.decoder.1.bias: 0.00035665943869389594\n",
      "Gradient for decoder.decoder.3.weight: 0.007934952154755592\n",
      "Gradient for decoder.decoder.3.bias: 7.222514947224923e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00032094569178298116\n",
      "Gradient for decoder.decoder.4.bias: 0.00033477068063803017\n",
      "Gradient for decoder.decoder.6.weight: 0.000726047030184418\n",
      "Gradient for decoder.decoder.6.bias: 4.674721640185453e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.005904146004468203\n",
      "Gradient for encoder.encoder.0.bias: 8.705316849322298e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.00039774866309016943\n",
      "Gradient for encoder.encoder.1.bias: 0.0005382949020713568\n",
      "Gradient for encoder.encoder.3.weight: 0.009049603715538979\n",
      "Gradient for encoder.encoder.3.bias: 1.1395799581759292e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.003694765968248248\n",
      "Gradient for encoder.encoder.4.bias: 0.002426853170618415\n",
      "Gradient for encoder.mean.weight: 0.05237426981329918\n",
      "Gradient for encoder.mean.bias: 0.0019390129018574953\n",
      "Gradient for encoder.log_var.weight: 0.0300089530646801\n",
      "Gradient for encoder.log_var.bias: 0.001417389721609652\n",
      "Gradient for decoder.decoder.0.weight: 0.01121179573237896\n",
      "Gradient for decoder.decoder.0.bias: 9.29665025517501e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005504463333636522\n",
      "Gradient for decoder.decoder.1.bias: 0.00046821244177408516\n",
      "Gradient for decoder.decoder.3.weight: 0.010551794432103634\n",
      "Gradient for decoder.decoder.3.bias: 8.213801167000767e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00044038984924554825\n",
      "Gradient for decoder.decoder.4.bias: 0.00043945611105300486\n",
      "Gradient for decoder.decoder.6.weight: 0.0007193430210463703\n",
      "Gradient for decoder.decoder.6.bias: 4.0637849451741204e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.0076737115159630775\n",
      "Gradient for encoder.encoder.0.bias: 1.252839759019464e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0005008212174288929\n",
      "Gradient for encoder.encoder.1.bias: 0.0004787483485415578\n",
      "Gradient for encoder.encoder.3.weight: 0.011335330083966255\n",
      "Gradient for encoder.encoder.3.bias: 1.1494346446871972e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0022881333716213703\n",
      "Gradient for encoder.encoder.4.bias: 0.0019015113357454538\n",
      "Gradient for encoder.mean.weight: 0.03508885204792023\n",
      "Gradient for encoder.mean.bias: 0.001486875698901713\n",
      "Gradient for encoder.log_var.weight: 0.02007262594997883\n",
      "Gradient for encoder.log_var.bias: 0.0009882361628115177\n",
      "Gradient for decoder.decoder.0.weight: 0.009386551566421986\n",
      "Gradient for decoder.decoder.0.bias: 8.528652090111777e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.00044837285531684756\n",
      "Gradient for decoder.decoder.1.bias: 0.0003782407147809863\n",
      "Gradient for decoder.decoder.3.weight: 0.00880206935107708\n",
      "Gradient for decoder.decoder.3.bias: 6.836099047946576e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00036119192373007536\n",
      "Gradient for decoder.decoder.4.bias: 0.00036144329351373017\n",
      "Gradient for decoder.decoder.6.weight: 0.0006998269818723202\n",
      "Gradient for decoder.decoder.6.bias: 3.555024159140885e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training VAE Epoch:  92%|█████████▏| 73/79 [00:01<00:00, 75.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient for encoder.encoder.0.weight: 0.009620193392038345\n",
      "Gradient for encoder.encoder.0.bias: 1.7750530212357063e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0007188425515778363\n",
      "Gradient for encoder.encoder.1.bias: 0.0006404373561963439\n",
      "Gradient for encoder.encoder.3.weight: 0.016009461134672165\n",
      "Gradient for encoder.encoder.3.bias: 1.3803731768735616e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.003103182651102543\n",
      "Gradient for encoder.encoder.4.bias: 0.0029446473345160484\n",
      "Gradient for encoder.mean.weight: 0.04422903433442116\n",
      "Gradient for encoder.mean.bias: 0.0023531790357083082\n",
      "Gradient for encoder.log_var.weight: 0.02667228691279888\n",
      "Gradient for encoder.log_var.bias: 0.001557928160764277\n",
      "Gradient for decoder.decoder.0.weight: 0.007883974350988865\n",
      "Gradient for decoder.decoder.0.bias: 6.557936138573695e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.00040921897743828595\n",
      "Gradient for decoder.decoder.1.bias: 0.0003327075392007828\n",
      "Gradient for decoder.decoder.3.weight: 0.0076441168785095215\n",
      "Gradient for decoder.decoder.3.bias: 8.468709761233484e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0005393729661591351\n",
      "Gradient for decoder.decoder.4.bias: 0.0006615834427066147\n",
      "Gradient for decoder.decoder.6.weight: 0.0007776847342029214\n",
      "Gradient for decoder.decoder.6.bias: 5.878275987925008e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.005965462885797024\n",
      "Gradient for encoder.encoder.0.bias: 9.634720972429012e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.000627561763394624\n",
      "Gradient for encoder.encoder.1.bias: 0.0006672960007563233\n",
      "Gradient for encoder.encoder.3.weight: 0.013943425379693508\n",
      "Gradient for encoder.encoder.3.bias: 1.1933744270553603e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.004200716502964497\n",
      "Gradient for encoder.encoder.4.bias: 0.002430480672046542\n",
      "Gradient for encoder.mean.weight: 0.06081992760300636\n",
      "Gradient for encoder.mean.bias: 0.0018790160538628697\n",
      "Gradient for encoder.log_var.weight: 0.029796870425343513\n",
      "Gradient for encoder.log_var.bias: 0.0010836111614480615\n",
      "Gradient for decoder.decoder.0.weight: 0.012159674428403378\n",
      "Gradient for decoder.decoder.0.bias: 1.0445481979370896e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0005815693293698132\n",
      "Gradient for decoder.decoder.1.bias: 0.0005335757159627974\n",
      "Gradient for decoder.decoder.3.weight: 0.011334256269037724\n",
      "Gradient for decoder.decoder.3.bias: 1.184622261396484e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.000731205043848604\n",
      "Gradient for decoder.decoder.4.bias: 0.0008815499022603035\n",
      "Gradient for decoder.decoder.6.weight: 0.0009445587638765574\n",
      "Gradient for decoder.decoder.6.bias: 7.555217598564923e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.004576197825372219\n",
      "Gradient for encoder.encoder.0.bias: 6.165076261999136e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.000357725570211187\n",
      "Gradient for encoder.encoder.1.bias: 0.0003872268716804683\n",
      "Gradient for encoder.encoder.3.weight: 0.008269966579973698\n",
      "Gradient for encoder.encoder.3.bias: 1.0475426082123818e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0029487828724086285\n",
      "Gradient for encoder.encoder.4.bias: 0.002249140990898013\n",
      "Gradient for encoder.mean.weight: 0.0425683930516243\n",
      "Gradient for encoder.mean.bias: 0.0015267141861841083\n",
      "Gradient for encoder.log_var.weight: 0.02700984477996826\n",
      "Gradient for encoder.log_var.bias: 0.0010464497609063983\n",
      "Gradient for decoder.decoder.0.weight: 0.013614772818982601\n",
      "Gradient for decoder.decoder.0.bias: 1.1814180189695378e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.000717714661732316\n",
      "Gradient for decoder.decoder.1.bias: 0.0005618997965939343\n",
      "Gradient for decoder.decoder.3.weight: 0.013655111193656921\n",
      "Gradient for decoder.decoder.3.bias: 1.0799507815795195e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0006583701469935477\n",
      "Gradient for decoder.decoder.4.bias: 0.0006226329132914543\n",
      "Gradient for decoder.decoder.6.weight: 0.0007851138361729681\n",
      "Gradient for decoder.decoder.6.bias: 3.937721703550778e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.006340144667774439\n",
      "Gradient for encoder.encoder.0.bias: 9.156268625243325e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.0004966718843206763\n",
      "Gradient for encoder.encoder.1.bias: 0.0006098152371123433\n",
      "Gradient for encoder.encoder.3.weight: 0.011201315559446812\n",
      "Gradient for encoder.encoder.3.bias: 1.0811846556935123e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.002661149948835373\n",
      "Gradient for encoder.encoder.4.bias: 0.002232094295322895\n",
      "Gradient for encoder.mean.weight: 0.038090795278549194\n",
      "Gradient for encoder.mean.bias: 0.001872400171123445\n",
      "Gradient for encoder.log_var.weight: 0.02368703857064247\n",
      "Gradient for encoder.log_var.bias: 0.0011025401763617992\n",
      "Gradient for decoder.decoder.0.weight: 0.012207563035190105\n",
      "Gradient for decoder.decoder.0.bias: 1.0662831728680544e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0006323638372123241\n",
      "Gradient for decoder.decoder.1.bias: 0.0005181505694054067\n",
      "Gradient for decoder.decoder.3.weight: 0.011740604415535927\n",
      "Gradient for decoder.decoder.3.bias: 8.970383463813292e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00040833555976860225\n",
      "Gradient for decoder.decoder.4.bias: 0.0003802673891186714\n",
      "Gradient for decoder.decoder.6.weight: 0.0007779602892696857\n",
      "Gradient for decoder.decoder.6.bias: 4.413503484101966e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.010008295066654682\n",
      "Gradient for encoder.encoder.0.bias: 1.4941738818441408e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0006266687996685505\n",
      "Gradient for encoder.encoder.1.bias: 0.0005963331204839051\n",
      "Gradient for encoder.encoder.3.weight: 0.01484560128301382\n",
      "Gradient for encoder.encoder.3.bias: 1.3739974435988955e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.003180245403200388\n",
      "Gradient for encoder.encoder.4.bias: 0.002373318886384368\n",
      "Gradient for encoder.mean.weight: 0.046517737209796906\n",
      "Gradient for encoder.mean.bias: 0.0015489459037780762\n",
      "Gradient for encoder.log_var.weight: 0.027167804539203644\n",
      "Gradient for encoder.log_var.bias: 0.0010394597193226218\n",
      "Gradient for decoder.decoder.0.weight: 0.009708630852401257\n",
      "Gradient for decoder.decoder.0.bias: 8.507231030741025e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0004838684690184891\n",
      "Gradient for decoder.decoder.1.bias: 0.00041142606642097235\n",
      "Gradient for decoder.decoder.3.weight: 0.009260972961783409\n",
      "Gradient for decoder.decoder.3.bias: 8.381372679222565e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0004665349842980504\n",
      "Gradient for decoder.decoder.4.bias: 0.0004832761187572032\n",
      "Gradient for decoder.decoder.6.weight: 0.0007283047307282686\n",
      "Gradient for decoder.decoder.6.bias: 4.354395787231624e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.010430458001792431\n",
      "Gradient for encoder.encoder.0.bias: 1.895176723887282e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0006979155004955828\n",
      "Gradient for encoder.encoder.1.bias: 0.0006012938683852553\n",
      "Gradient for encoder.encoder.3.weight: 0.015512580052018166\n",
      "Gradient for encoder.encoder.3.bias: 1.3803889975516626e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0034755573142319918\n",
      "Gradient for encoder.encoder.4.bias: 0.002990873297676444\n",
      "Gradient for encoder.mean.weight: 0.050841499119997025\n",
      "Gradient for encoder.mean.bias: 0.001898072543554008\n",
      "Gradient for encoder.log_var.weight: 0.027599461376667023\n",
      "Gradient for encoder.log_var.bias: 0.0012011697981506586\n",
      "Gradient for decoder.decoder.0.weight: 0.007974384352564812\n",
      "Gradient for decoder.decoder.0.bias: 6.652040029919704e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.00039373591425828636\n",
      "Gradient for decoder.decoder.1.bias: 0.00032892197486944497\n",
      "Gradient for decoder.decoder.3.weight: 0.007509416434913874\n",
      "Gradient for decoder.decoder.3.bias: 6.809514063732536e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00040236287168227136\n",
      "Gradient for decoder.decoder.4.bias: 0.0004794434644281864\n",
      "Gradient for decoder.decoder.6.weight: 0.0007377013098448515\n",
      "Gradient for decoder.decoder.6.bias: 5.3190473408903927e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.006882815156131983\n",
      "Gradient for encoder.encoder.0.bias: 1.031994975586592e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.000509978795889765\n",
      "Gradient for encoder.encoder.1.bias: 0.0005449547898024321\n",
      "Gradient for encoder.encoder.3.weight: 0.010843843221664429\n",
      "Gradient for encoder.encoder.3.bias: 1.368592600359264e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.00314251147210598\n",
      "Gradient for encoder.encoder.4.bias: 0.002816265681758523\n",
      "Gradient for encoder.mean.weight: 0.04783117398619652\n",
      "Gradient for encoder.mean.bias: 0.002155163325369358\n",
      "Gradient for encoder.log_var.weight: 0.02676539681851864\n",
      "Gradient for encoder.log_var.bias: 0.0015221841167658567\n",
      "Gradient for decoder.decoder.0.weight: 0.010894332081079483\n",
      "Gradient for decoder.decoder.0.bias: 9.954664176303751e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.000534733640961349\n",
      "Gradient for decoder.decoder.1.bias: 0.0004683065926656127\n",
      "Gradient for decoder.decoder.3.weight: 0.010278540663421154\n",
      "Gradient for decoder.decoder.3.bias: 1.2820211559017025e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0008441517711617053\n",
      "Gradient for decoder.decoder.4.bias: 0.0010298709385097027\n",
      "Gradient for decoder.decoder.6.weight: 0.0009958420414477587\n",
      "Gradient for decoder.decoder.6.bias: 8.077803067862988e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.008653723634779453\n",
      "Gradient for encoder.encoder.0.bias: 1.2709653642029028e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0004979569930583239\n",
      "Gradient for encoder.encoder.1.bias: 0.0004596100770868361\n",
      "Gradient for encoder.encoder.3.weight: 0.010746781714260578\n",
      "Gradient for encoder.encoder.3.bias: 1.0875803729826217e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.002573614940047264\n",
      "Gradient for encoder.encoder.4.bias: 0.0019351831870153546\n",
      "Gradient for encoder.mean.weight: 0.03874252364039421\n",
      "Gradient for encoder.mean.bias: 0.0016269651241600513\n",
      "Gradient for encoder.log_var.weight: 0.01806282065808773\n",
      "Gradient for encoder.log_var.bias: 0.0008815916371531785\n",
      "Gradient for decoder.decoder.0.weight: 0.009579705074429512\n",
      "Gradient for decoder.decoder.0.bias: 8.603374956894783e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.00044803033233620226\n",
      "Gradient for decoder.decoder.1.bias: 0.000409641390433535\n",
      "Gradient for decoder.decoder.3.weight: 0.0086751040071249\n",
      "Gradient for decoder.decoder.3.bias: 7.712202404475121e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0003621908836066723\n",
      "Gradient for decoder.decoder.4.bias: 0.00037668648292310536\n",
      "Gradient for decoder.decoder.6.weight: 0.0007409124518744648\n",
      "Gradient for decoder.decoder.6.bias: 4.94069536216557e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.008184813894331455\n",
      "Gradient for encoder.encoder.0.bias: 1.3524799336028792e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0005776629550382495\n",
      "Gradient for encoder.encoder.1.bias: 0.0005201477324590087\n",
      "Gradient for encoder.encoder.3.weight: 0.012670517899096012\n",
      "Gradient for encoder.encoder.3.bias: 1.350081990647567e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.002774583175778389\n",
      "Gradient for encoder.encoder.4.bias: 0.003047031117603183\n",
      "Gradient for encoder.mean.weight: 0.03849209100008011\n",
      "Gradient for encoder.mean.bias: 0.0025731821078807116\n",
      "Gradient for encoder.log_var.weight: 0.02091950923204422\n",
      "Gradient for encoder.log_var.bias: 0.0015534351114183664\n",
      "Gradient for decoder.decoder.0.weight: 0.008622542023658752\n",
      "Gradient for decoder.decoder.0.bias: 7.658933209864216e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.00042834182386286557\n",
      "Gradient for decoder.decoder.1.bias: 0.0003559394972398877\n",
      "Gradient for decoder.decoder.3.weight: 0.007784405257552862\n",
      "Gradient for decoder.decoder.3.bias: 6.980337141637705e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0002993707312270999\n",
      "Gradient for decoder.decoder.4.bias: 0.00031230945023708045\n",
      "Gradient for decoder.decoder.6.weight: 0.0007161063840612769\n",
      "Gradient for decoder.decoder.6.bias: 4.44010402134154e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.007016632240265608\n",
      "Gradient for encoder.encoder.0.bias: 1.1027303202515437e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0006618017214350402\n",
      "Gradient for encoder.encoder.1.bias: 0.0006170084234327078\n",
      "Gradient for encoder.encoder.3.weight: 0.013770823366940022\n",
      "Gradient for encoder.encoder.3.bias: 1.2714422570336836e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0027701829094439745\n",
      "Gradient for encoder.encoder.4.bias: 0.0028059864416718483\n",
      "Gradient for encoder.mean.weight: 0.04153137281537056\n",
      "Gradient for encoder.mean.bias: 0.0023310098331421614\n",
      "Gradient for encoder.log_var.weight: 0.024197274819016457\n",
      "Gradient for encoder.log_var.bias: 0.0014261140022426844\n",
      "Gradient for decoder.decoder.0.weight: 0.010928796604275703\n",
      "Gradient for decoder.decoder.0.bias: 9.407371409642096e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005664777127094567\n",
      "Gradient for decoder.decoder.1.bias: 0.00046209164429455996\n",
      "Gradient for decoder.decoder.3.weight: 0.009938771836459637\n",
      "Gradient for decoder.decoder.3.bias: 9.679104046034226e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0005143219605088234\n",
      "Gradient for decoder.decoder.4.bias: 0.0005665230564773083\n",
      "Gradient for decoder.decoder.6.weight: 0.0007564168772660196\n",
      "Gradient for decoder.decoder.6.bias: 4.431606794241816e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.007247872184962034\n",
      "Gradient for encoder.encoder.0.bias: 1.1502358961135162e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0005292159039527178\n",
      "Gradient for encoder.encoder.1.bias: 0.0005339276976883411\n",
      "Gradient for encoder.encoder.3.weight: 0.011831655167043209\n",
      "Gradient for encoder.encoder.3.bias: 1.3229553563753882e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.002645080676302314\n",
      "Gradient for encoder.encoder.4.bias: 0.0024171380791813135\n",
      "Gradient for encoder.mean.weight: 0.03794674575328827\n",
      "Gradient for encoder.mean.bias: 0.0018813353963196278\n",
      "Gradient for encoder.log_var.weight: 0.021374937146902084\n",
      "Gradient for encoder.log_var.bias: 0.0011475789360702038\n",
      "Gradient for decoder.decoder.0.weight: 0.010761338286101818\n",
      "Gradient for decoder.decoder.0.bias: 1.0304326142351883e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0005058746901340783\n",
      "Gradient for decoder.decoder.1.bias: 0.00043062606710009277\n",
      "Gradient for decoder.decoder.3.weight: 0.010054245591163635\n",
      "Gradient for decoder.decoder.3.bias: 1.0196872513024147e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0005665923235937953\n",
      "Gradient for decoder.decoder.4.bias: 0.0006208994309417903\n",
      "Gradient for decoder.decoder.6.weight: 0.0009638770134188235\n",
      "Gradient for decoder.decoder.6.bias: 7.834517600713298e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.005406608805060387\n",
      "Gradient for encoder.encoder.0.bias: 7.1115105991503835e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.0005207874346524477\n",
      "Gradient for encoder.encoder.1.bias: 0.0005166085320524871\n",
      "Gradient for encoder.encoder.3.weight: 0.011305826716125011\n",
      "Gradient for encoder.encoder.3.bias: 1.2450229736060692e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0036239938344806433\n",
      "Gradient for encoder.encoder.4.bias: 0.0028459448367357254\n",
      "Gradient for encoder.mean.weight: 0.05443181097507477\n",
      "Gradient for encoder.mean.bias: 0.0018911188235506415\n",
      "Gradient for encoder.log_var.weight: 0.0320102721452713\n",
      "Gradient for encoder.log_var.bias: 0.0013485023519024253\n",
      "Gradient for decoder.decoder.0.weight: 0.014867005869746208\n",
      "Gradient for decoder.decoder.0.bias: 1.3388332109620649e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0007104001706466079\n",
      "Gradient for decoder.decoder.1.bias: 0.000616316800005734\n",
      "Gradient for decoder.decoder.3.weight: 0.014254851266741753\n",
      "Gradient for decoder.decoder.3.bias: 1.5955443910531386e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0009860896971076727\n",
      "Gradient for decoder.decoder.4.bias: 0.0012002418516203761\n",
      "Gradient for decoder.decoder.6.weight: 0.000981602119281888\n",
      "Gradient for decoder.decoder.6.bias: 7.410488615278155e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.006301118992269039\n",
      "Gradient for encoder.encoder.0.bias: 9.994264964230393e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.0005243556224741042\n",
      "Gradient for encoder.encoder.1.bias: 0.0005889182793907821\n",
      "Gradient for encoder.encoder.3.weight: 0.011191113851964474\n",
      "Gradient for encoder.encoder.3.bias: 1.1781475794947482e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0035014019813388586\n",
      "Gradient for encoder.encoder.4.bias: 0.0022955136373639107\n",
      "Gradient for encoder.mean.weight: 0.050493158400058746\n",
      "Gradient for encoder.mean.bias: 0.0016802528407424688\n",
      "Gradient for encoder.log_var.weight: 0.027800150215625763\n",
      "Gradient for encoder.log_var.bias: 0.0009749209857545793\n",
      "Gradient for decoder.decoder.0.weight: 0.011623421683907509\n",
      "Gradient for decoder.decoder.0.bias: 9.289786995214655e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.000632121751550585\n",
      "Gradient for decoder.decoder.1.bias: 0.00046631114673800766\n",
      "Gradient for decoder.decoder.3.weight: 0.011135732755064964\n",
      "Gradient for decoder.decoder.3.bias: 8.043743449093199e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.000391740701161325\n",
      "Gradient for decoder.decoder.4.bias: 0.00033477795659564435\n",
      "Gradient for decoder.decoder.6.weight: 0.0007319420110434294\n",
      "Gradient for decoder.decoder.6.bias: 4.337084465078078e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.00717260641977191\n",
      "Gradient for encoder.encoder.0.bias: 1.2702638420292178e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0006527650402858853\n",
      "Gradient for encoder.encoder.1.bias: 0.0006106375949457288\n",
      "Gradient for encoder.encoder.3.weight: 0.014351604506373405\n",
      "Gradient for encoder.encoder.3.bias: 1.1915296527220676e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0029237798880785704\n",
      "Gradient for encoder.encoder.4.bias: 0.0022869741078466177\n",
      "Gradient for encoder.mean.weight: 0.044317785650491714\n",
      "Gradient for encoder.mean.bias: 0.0017293081618845463\n",
      "Gradient for encoder.log_var.weight: 0.023101119324564934\n",
      "Gradient for encoder.log_var.bias: 0.0009630700806155801\n",
      "Gradient for decoder.decoder.0.weight: 0.010005934163928032\n",
      "Gradient for decoder.decoder.0.bias: 9.05159280861767e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005125569296069443\n",
      "Gradient for decoder.decoder.1.bias: 0.0004249060293659568\n",
      "Gradient for decoder.decoder.3.weight: 0.009717613458633423\n",
      "Gradient for decoder.decoder.3.bias: 7.997675438575769e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00042481982382014394\n",
      "Gradient for decoder.decoder.4.bias: 0.0003808719920925796\n",
      "Gradient for decoder.decoder.6.weight: 0.0007638516835868359\n",
      "Gradient for decoder.decoder.6.bias: 4.930793511448428e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.005857508163899183\n",
      "Gradient for encoder.encoder.0.bias: 1.059790623314516e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0005721672205254436\n",
      "Gradient for encoder.encoder.1.bias: 0.0006555356667377055\n",
      "Gradient for encoder.encoder.3.weight: 0.012472221627831459\n",
      "Gradient for encoder.encoder.3.bias: 1.2294096296550094e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.003046920523047447\n",
      "Gradient for encoder.encoder.4.bias: 0.0026923674158751965\n",
      "Gradient for encoder.mean.weight: 0.044891174882650375\n",
      "Gradient for encoder.mean.bias: 0.002373482333496213\n",
      "Gradient for encoder.log_var.weight: 0.024355392903089523\n",
      "Gradient for encoder.log_var.bias: 0.001366135780699551\n",
      "Gradient for decoder.decoder.0.weight: 0.011620686389505863\n",
      "Gradient for decoder.decoder.0.bias: 9.656097449406431e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005613724351860583\n",
      "Gradient for decoder.decoder.1.bias: 0.00048402350512333214\n",
      "Gradient for decoder.decoder.3.weight: 0.010907832533121109\n",
      "Gradient for decoder.decoder.3.bias: 8.583258409577965e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0003844194579869509\n",
      "Gradient for decoder.decoder.4.bias: 0.0003564356593415141\n",
      "Gradient for decoder.decoder.6.weight: 0.0006774973007850349\n",
      "Gradient for decoder.decoder.6.bias: 3.118940367130563e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.007522204425185919\n",
      "Gradient for encoder.encoder.0.bias: 1.30894930311376e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0006034787511453032\n",
      "Gradient for encoder.encoder.1.bias: 0.0005329845589585602\n",
      "Gradient for encoder.encoder.3.weight: 0.01365001779049635\n",
      "Gradient for encoder.encoder.3.bias: 1.362094464996133e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.003396686166524887\n",
      "Gradient for encoder.encoder.4.bias: 0.002825693693011999\n",
      "Gradient for encoder.mean.weight: 0.04889044538140297\n",
      "Gradient for encoder.mean.bias: 0.0020564666483551264\n",
      "Gradient for encoder.log_var.weight: 0.02394496463239193\n",
      "Gradient for encoder.log_var.bias: 0.00142007227987051\n",
      "Gradient for decoder.decoder.0.weight: 0.01103224791586399\n",
      "Gradient for decoder.decoder.0.bias: 8.972390885819692e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005494391079992056\n",
      "Gradient for decoder.decoder.1.bias: 0.00045350988511927426\n",
      "Gradient for decoder.decoder.3.weight: 0.010706097818911076\n",
      "Gradient for decoder.decoder.3.bias: 8.148708097177604e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00043384599848650396\n",
      "Gradient for decoder.decoder.4.bias: 0.0003948639496229589\n",
      "Gradient for decoder.decoder.6.weight: 0.000711500586476177\n",
      "Gradient for decoder.decoder.6.bias: 3.393825318198651e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient for encoder.encoder.0.weight: 0.00561238219961524\n",
      "Gradient for encoder.encoder.0.bias: 8.415994463828458e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.0004325488116592169\n",
      "Gradient for encoder.encoder.1.bias: 0.000485272757941857\n",
      "Gradient for encoder.encoder.3.weight: 0.009900951758027077\n",
      "Gradient for encoder.encoder.3.bias: 9.995633487580591e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.0029465050902217627\n",
      "Gradient for encoder.encoder.4.bias: 0.0018568040104582906\n",
      "Gradient for encoder.mean.weight: 0.04495014622807503\n",
      "Gradient for encoder.mean.bias: 0.0014729814138263464\n",
      "Gradient for encoder.log_var.weight: 0.021608488634228706\n",
      "Gradient for encoder.log_var.bias: 0.001057244255207479\n",
      "Gradient for decoder.decoder.0.weight: 0.01193071436136961\n",
      "Gradient for decoder.decoder.0.bias: 1.0133432981618284e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0005833573522977531\n",
      "Gradient for decoder.decoder.1.bias: 0.000551412464119494\n",
      "Gradient for decoder.decoder.3.weight: 0.011092474684119225\n",
      "Gradient for decoder.decoder.3.bias: 9.338368273104081e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0004062119987793267\n",
      "Gradient for decoder.decoder.4.bias: 0.00038934528129175305\n",
      "Gradient for decoder.decoder.6.weight: 0.0007038248586468399\n",
      "Gradient for decoder.decoder.6.bias: 3.5259610740467906e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.013991167768836021\n",
      "Gradient for encoder.encoder.0.bias: 1.64160005033942e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.00060852593742311\n",
      "Gradient for encoder.encoder.1.bias: 0.00038575183134526014\n",
      "Gradient for encoder.encoder.3.weight: 0.013429992832243443\n",
      "Gradient for encoder.encoder.3.bias: 1.7864813794954415e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0032469769939780235\n",
      "Gradient for encoder.encoder.4.bias: 0.0035572387278079987\n",
      "Gradient for encoder.mean.weight: 0.04624976962804794\n",
      "Gradient for encoder.mean.bias: 0.002704156097024679\n",
      "Gradient for encoder.log_var.weight: 0.026796773076057434\n",
      "Gradient for encoder.log_var.bias: 0.0016696937382221222\n",
      "Gradient for decoder.decoder.0.weight: 0.029664089903235435\n",
      "Gradient for decoder.decoder.0.bias: 2.258915832165087e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0012270676670596004\n",
      "Gradient for decoder.decoder.1.bias: 0.001107791904360056\n",
      "Gradient for decoder.decoder.3.weight: 0.02668881230056286\n",
      "Gradient for decoder.decoder.3.bias: 2.143691057998609e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0011075474321842194\n",
      "Gradient for decoder.decoder.4.bias: 0.0011655555572360754\n",
      "Gradient for decoder.decoder.6.weight: 0.001831062021665275\n",
      "Gradient for decoder.decoder.6.bias: 0.00010322395246475935\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3, Train Loss: 0.0728, Val Loss: 0.2806\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training VAE Epoch:   1%|▏         | 1/79 [00:00<00:14,  5.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient for encoder.encoder.0.weight: 0.011813156306743622\n",
      "Gradient for encoder.encoder.0.bias: 1.7739722885101727e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0008768641855567694\n",
      "Gradient for encoder.encoder.1.bias: 0.0007591051398776472\n",
      "Gradient for encoder.encoder.3.weight: 0.019535280764102936\n",
      "Gradient for encoder.encoder.3.bias: 1.8678096569413327e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.005138181149959564\n",
      "Gradient for encoder.encoder.4.bias: 0.004276815801858902\n",
      "Gradient for encoder.mean.weight: 0.07081170380115509\n",
      "Gradient for encoder.mean.bias: 0.0025529193226248026\n",
      "Gradient for encoder.log_var.weight: 0.042896099388599396\n",
      "Gradient for encoder.log_var.bias: 0.0015048731584101915\n",
      "Gradient for decoder.decoder.0.weight: 0.009671761654317379\n",
      "Gradient for decoder.decoder.0.bias: 7.668166795982145e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.00046699217637069523\n",
      "Gradient for decoder.decoder.1.bias: 0.0003860970900859684\n",
      "Gradient for decoder.decoder.3.weight: 0.008864294737577438\n",
      "Gradient for decoder.decoder.3.bias: 6.643558619900958e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00033525482285767794\n",
      "Gradient for decoder.decoder.4.bias: 0.0002817930653691292\n",
      "Gradient for decoder.decoder.6.weight: 0.0007699456764385104\n",
      "Gradient for decoder.decoder.6.bias: 4.479627750697546e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.003580150194466114\n",
      "Gradient for encoder.encoder.0.bias: 5.749691521506062e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.00045253385906107724\n",
      "Gradient for encoder.encoder.1.bias: 0.0004545904812403023\n",
      "Gradient for encoder.encoder.3.weight: 0.010274969972670078\n",
      "Gradient for encoder.encoder.3.bias: 1.0097592900715213e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0033531791996210814\n",
      "Gradient for encoder.encoder.4.bias: 0.002377044642344117\n",
      "Gradient for encoder.mean.weight: 0.04647452011704445\n",
      "Gradient for encoder.mean.bias: 0.0018045795150101185\n",
      "Gradient for encoder.log_var.weight: 0.024196892976760864\n",
      "Gradient for encoder.log_var.bias: 0.0012389441253617406\n",
      "Gradient for decoder.decoder.0.weight: 0.016104919835925102\n",
      "Gradient for decoder.decoder.0.bias: 1.4512034629543535e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0008433907059952617\n",
      "Gradient for decoder.decoder.1.bias: 0.0006844906019978225\n",
      "Gradient for decoder.decoder.3.weight: 0.015194240026175976\n",
      "Gradient for decoder.decoder.3.bias: 1.3341687477019804e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0007614392670802772\n",
      "Gradient for decoder.decoder.4.bias: 0.0008281290647573769\n",
      "Gradient for decoder.decoder.6.weight: 0.0008685338543727994\n",
      "Gradient for decoder.decoder.6.bias: 5.907541708438657e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training VAE Epoch:  10%|█         | 8/79 [00:00<00:02, 32.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient for encoder.encoder.0.weight: 0.006616851780563593\n",
      "Gradient for encoder.encoder.0.bias: 8.904526421771308e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.0004642657295335084\n",
      "Gradient for encoder.encoder.1.bias: 0.0004674274241551757\n",
      "Gradient for encoder.encoder.3.weight: 0.010305608622729778\n",
      "Gradient for encoder.encoder.3.bias: 1.1543687533643876e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0028260883409529924\n",
      "Gradient for encoder.encoder.4.bias: 0.002102016704156995\n",
      "Gradient for encoder.mean.weight: 0.03823057562112808\n",
      "Gradient for encoder.mean.bias: 0.0014612097293138504\n",
      "Gradient for encoder.log_var.weight: 0.02275833673775196\n",
      "Gradient for encoder.log_var.bias: 0.0011080886470153928\n",
      "Gradient for decoder.decoder.0.weight: 0.011340580880641937\n",
      "Gradient for decoder.decoder.0.bias: 1.0618691342889619e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0005868569714948535\n",
      "Gradient for decoder.decoder.1.bias: 0.0004588755255099386\n",
      "Gradient for decoder.decoder.3.weight: 0.010541805066168308\n",
      "Gradient for decoder.decoder.3.bias: 8.794571321191214e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0003712962206918746\n",
      "Gradient for decoder.decoder.4.bias: 0.00034350078203715384\n",
      "Gradient for decoder.decoder.6.weight: 0.0007249792106449604\n",
      "Gradient for decoder.decoder.6.bias: 3.632043444667943e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.010271912440657616\n",
      "Gradient for encoder.encoder.0.bias: 1.7852714098709477e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.000813629012554884\n",
      "Gradient for encoder.encoder.1.bias: 0.0008438448421657085\n",
      "Gradient for encoder.encoder.3.weight: 0.017106173560023308\n",
      "Gradient for encoder.encoder.3.bias: 1.4795327463179575e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0037812921218574047\n",
      "Gradient for encoder.encoder.4.bias: 0.0033714603632688522\n",
      "Gradient for encoder.mean.weight: 0.051014311611652374\n",
      "Gradient for encoder.mean.bias: 0.0023196800611913204\n",
      "Gradient for encoder.log_var.weight: 0.034668929874897\n",
      "Gradient for encoder.log_var.bias: 0.0014397527556866407\n",
      "Gradient for decoder.decoder.0.weight: 0.00908011756837368\n",
      "Gradient for decoder.decoder.0.bias: 6.82783135586007e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0004553690378088504\n",
      "Gradient for decoder.decoder.1.bias: 0.00035422423388808966\n",
      "Gradient for decoder.decoder.3.weight: 0.008348374627530575\n",
      "Gradient for decoder.decoder.3.bias: 6.166156474307627e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0003017401322722435\n",
      "Gradient for decoder.decoder.4.bias: 0.00026111083570867777\n",
      "Gradient for decoder.decoder.6.weight: 0.0007179954554885626\n",
      "Gradient for decoder.decoder.6.bias: 4.105192419956438e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.012117789126932621\n",
      "Gradient for encoder.encoder.0.bias: 1.6509319952784374e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0006525477510876954\n",
      "Gradient for encoder.encoder.1.bias: 0.0005824922118335962\n",
      "Gradient for encoder.encoder.3.weight: 0.01456429623067379\n",
      "Gradient for encoder.encoder.3.bias: 1.3262109466172234e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0023925816640257835\n",
      "Gradient for encoder.encoder.4.bias: 0.002282483270391822\n",
      "Gradient for encoder.mean.weight: 0.03484247624874115\n",
      "Gradient for encoder.mean.bias: 0.0016591675812378526\n",
      "Gradient for encoder.log_var.weight: 0.02150081843137741\n",
      "Gradient for encoder.log_var.bias: 0.001208960311487317\n",
      "Gradient for decoder.decoder.0.weight: 0.009453745558857918\n",
      "Gradient for decoder.decoder.0.bias: 7.585144318200676e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.00046188486157916486\n",
      "Gradient for decoder.decoder.1.bias: 0.00040538652683608234\n",
      "Gradient for decoder.decoder.3.weight: 0.00897408090531826\n",
      "Gradient for decoder.decoder.3.bias: 8.348972901917051e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00033833979978226125\n",
      "Gradient for decoder.decoder.4.bias: 0.00029389007249847054\n",
      "Gradient for decoder.decoder.6.weight: 0.0007020080229267478\n",
      "Gradient for decoder.decoder.6.bias: 3.7841971789021045e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.010615727864205837\n",
      "Gradient for encoder.encoder.0.bias: 1.918480305174164e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0006741938996128738\n",
      "Gradient for encoder.encoder.1.bias: 0.0005722787464037538\n",
      "Gradient for encoder.encoder.3.weight: 0.015193329192698002\n",
      "Gradient for encoder.encoder.3.bias: 1.417334305475748e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0027896729297935963\n",
      "Gradient for encoder.encoder.4.bias: 0.0026067050639539957\n",
      "Gradient for encoder.mean.weight: 0.039393071085214615\n",
      "Gradient for encoder.mean.bias: 0.0022538243792951107\n",
      "Gradient for encoder.log_var.weight: 0.022950394079089165\n",
      "Gradient for encoder.log_var.bias: 0.0014885002747178078\n",
      "Gradient for decoder.decoder.0.weight: 0.008716581389307976\n",
      "Gradient for decoder.decoder.0.bias: 7.357704029375967e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.00044555653585121036\n",
      "Gradient for decoder.decoder.1.bias: 0.0003641084476839751\n",
      "Gradient for decoder.decoder.3.weight: 0.00877276249229908\n",
      "Gradient for decoder.decoder.3.bias: 6.70422745097099e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00038604592555202544\n",
      "Gradient for decoder.decoder.4.bias: 0.0004100081278011203\n",
      "Gradient for decoder.decoder.6.weight: 0.0007502497173845768\n",
      "Gradient for decoder.decoder.6.bias: 4.696406904258765e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.006494974251836538\n",
      "Gradient for encoder.encoder.0.bias: 9.746421551770634e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.00048190465895459056\n",
      "Gradient for encoder.encoder.1.bias: 0.0005507466848939657\n",
      "Gradient for encoder.encoder.3.weight: 0.01087393518537283\n",
      "Gradient for encoder.encoder.3.bias: 1.1870131266800144e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.004208358936011791\n",
      "Gradient for encoder.encoder.4.bias: 0.0028524112422019243\n",
      "Gradient for encoder.mean.weight: 0.05921211093664169\n",
      "Gradient for encoder.mean.bias: 0.0017840899527072906\n",
      "Gradient for encoder.log_var.weight: 0.037032101303339005\n",
      "Gradient for encoder.log_var.bias: 0.0011902737896889448\n",
      "Gradient for decoder.decoder.0.weight: 0.011072047054767609\n",
      "Gradient for decoder.decoder.0.bias: 9.757205460259044e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.000521104724612087\n",
      "Gradient for decoder.decoder.1.bias: 0.00048052272177301347\n",
      "Gradient for decoder.decoder.3.weight: 0.010491149500012398\n",
      "Gradient for decoder.decoder.3.bias: 8.203480256208096e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00039432328776456416\n",
      "Gradient for decoder.decoder.4.bias: 0.0003839789133053273\n",
      "Gradient for decoder.decoder.6.weight: 0.0007701001013629138\n",
      "Gradient for decoder.decoder.6.bias: 4.9972059059655294e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.007347002625465393\n",
      "Gradient for encoder.encoder.0.bias: 1.077214619588096e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0005348701379261911\n",
      "Gradient for encoder.encoder.1.bias: 0.0005066327867098153\n",
      "Gradient for encoder.encoder.3.weight: 0.012488862499594688\n",
      "Gradient for encoder.encoder.3.bias: 1.4613256438256172e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0048202709294855595\n",
      "Gradient for encoder.encoder.4.bias: 0.0033606262877583504\n",
      "Gradient for encoder.mean.weight: 0.06288236379623413\n",
      "Gradient for encoder.mean.bias: 0.0022566858679056168\n",
      "Gradient for encoder.log_var.weight: 0.03699953481554985\n",
      "Gradient for encoder.log_var.bias: 0.0014297807356342673\n",
      "Gradient for decoder.decoder.0.weight: 0.011602513492107391\n",
      "Gradient for decoder.decoder.0.bias: 9.110275034363013e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005421449313871562\n",
      "Gradient for decoder.decoder.1.bias: 0.0004431365814525634\n",
      "Gradient for decoder.decoder.3.weight: 0.010314268991351128\n",
      "Gradient for decoder.decoder.3.bias: 9.284862462211052e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0003842788573820144\n",
      "Gradient for decoder.decoder.4.bias: 0.0003794645599555224\n",
      "Gradient for decoder.decoder.6.weight: 0.0006825741729699075\n",
      "Gradient for decoder.decoder.6.bias: 3.448388451943174e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.008833516389131546\n",
      "Gradient for encoder.encoder.0.bias: 1.3540438735526461e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0005427590222097933\n",
      "Gradient for encoder.encoder.1.bias: 0.0006203046068549156\n",
      "Gradient for encoder.encoder.3.weight: 0.011757390573620796\n",
      "Gradient for encoder.encoder.3.bias: 1.3838126478038504e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.002816202584654093\n",
      "Gradient for encoder.encoder.4.bias: 0.003179510124027729\n",
      "Gradient for encoder.mean.weight: 0.039117809385061264\n",
      "Gradient for encoder.mean.bias: 0.0028241975232958794\n",
      "Gradient for encoder.log_var.weight: 0.02374252863228321\n",
      "Gradient for encoder.log_var.bias: 0.0016771750524640083\n",
      "Gradient for decoder.decoder.0.weight: 0.00937629770487547\n",
      "Gradient for decoder.decoder.0.bias: 8.3242156223573e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0004355148412287235\n",
      "Gradient for decoder.decoder.1.bias: 0.00038019343628548086\n",
      "Gradient for decoder.decoder.3.weight: 0.008845705538988113\n",
      "Gradient for decoder.decoder.3.bias: 8.085254687983934e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0004733512760140002\n",
      "Gradient for decoder.decoder.4.bias: 0.0005472209304571152\n",
      "Gradient for decoder.decoder.6.weight: 0.0007411509868688881\n",
      "Gradient for decoder.decoder.6.bias: 5.133923696121201e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.004889909643679857\n",
      "Gradient for encoder.encoder.0.bias: 7.129644097325638e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.0005175378173589706\n",
      "Gradient for encoder.encoder.1.bias: 0.0004612520569935441\n",
      "Gradient for encoder.encoder.3.weight: 0.011288669891655445\n",
      "Gradient for encoder.encoder.3.bias: 1.3761429495939836e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.003856172552332282\n",
      "Gradient for encoder.encoder.4.bias: 0.0031357735861092806\n",
      "Gradient for encoder.mean.weight: 0.05122893676161766\n",
      "Gradient for encoder.mean.bias: 0.0019813391845673323\n",
      "Gradient for encoder.log_var.weight: 0.03706134110689163\n",
      "Gradient for encoder.log_var.bias: 0.0014706029323861003\n",
      "Gradient for decoder.decoder.0.weight: 0.013510881923139095\n",
      "Gradient for decoder.decoder.0.bias: 1.2187313658262866e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0006276948843151331\n",
      "Gradient for decoder.decoder.1.bias: 0.0005260733305476606\n",
      "Gradient for decoder.decoder.3.weight: 0.012446504086256027\n",
      "Gradient for decoder.decoder.3.bias: 1.2633595558586563e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0007266734028235078\n",
      "Gradient for decoder.decoder.4.bias: 0.0007743032183498144\n",
      "Gradient for decoder.decoder.6.weight: 0.0008587643387727439\n",
      "Gradient for decoder.decoder.6.bias: 5.44844260730315e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.005729017313569784\n",
      "Gradient for encoder.encoder.0.bias: 8.242274050773712e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.0005710080149583519\n",
      "Gradient for encoder.encoder.1.bias: 0.0006192956934683025\n",
      "Gradient for encoder.encoder.3.weight: 0.011544025503098965\n",
      "Gradient for encoder.encoder.3.bias: 1.3420127509267132e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.003540672594681382\n",
      "Gradient for encoder.encoder.4.bias: 0.003457707352936268\n",
      "Gradient for encoder.mean.weight: 0.04744773730635643\n",
      "Gradient for encoder.mean.bias: 0.0028541877400130033\n",
      "Gradient for encoder.log_var.weight: 0.03195298835635185\n",
      "Gradient for encoder.log_var.bias: 0.0019753603264689445\n",
      "Gradient for decoder.decoder.0.weight: 0.01271961908787489\n",
      "Gradient for decoder.decoder.0.bias: 1.0579713494163201e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0006277118227444589\n",
      "Gradient for decoder.decoder.1.bias: 0.0005015709903091192\n",
      "Gradient for decoder.decoder.3.weight: 0.01194821484386921\n",
      "Gradient for decoder.decoder.3.bias: 9.25799020778939e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0004748989886138588\n",
      "Gradient for decoder.decoder.4.bias: 0.0004747462226077914\n",
      "Gradient for decoder.decoder.6.weight: 0.0007643436547368765\n",
      "Gradient for decoder.decoder.6.bias: 4.361335595604032e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.004916615784168243\n",
      "Gradient for encoder.encoder.0.bias: 8.048087370149393e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.0004662613500840962\n",
      "Gradient for encoder.encoder.1.bias: 0.0005805324763059616\n",
      "Gradient for encoder.encoder.3.weight: 0.010535228066146374\n",
      "Gradient for encoder.encoder.3.bias: 1.0094272639982194e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0033132696989923716\n",
      "Gradient for encoder.encoder.4.bias: 0.0020060790702700615\n",
      "Gradient for encoder.mean.weight: 0.04659393057227135\n",
      "Gradient for encoder.mean.bias: 0.001508971443399787\n",
      "Gradient for encoder.log_var.weight: 0.02618451975286007\n",
      "Gradient for encoder.log_var.bias: 0.0009975378634408116\n",
      "Gradient for decoder.decoder.0.weight: 0.012570971623063087\n",
      "Gradient for decoder.decoder.0.bias: 1.0304393449622751e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0006299786036834121\n",
      "Gradient for decoder.decoder.1.bias: 0.0005273056449368596\n",
      "Gradient for decoder.decoder.3.weight: 0.011706751771271229\n",
      "Gradient for decoder.decoder.3.bias: 9.89742385271164e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00045805046102032065\n",
      "Gradient for decoder.decoder.4.bias: 0.00043447240022942424\n",
      "Gradient for decoder.decoder.6.weight: 0.0007407050579786301\n",
      "Gradient for decoder.decoder.6.bias: 3.9719074266031384e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.008538970723748207\n",
      "Gradient for encoder.encoder.0.bias: 1.153973010897813e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0006929488154128194\n",
      "Gradient for encoder.encoder.1.bias: 0.0006343068671412766\n",
      "Gradient for encoder.encoder.3.weight: 0.015588494017720222\n",
      "Gradient for encoder.encoder.3.bias: 1.4209644572105162e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.004400909878313541\n",
      "Gradient for encoder.encoder.4.bias: 0.0033847212325781584\n",
      "Gradient for encoder.mean.weight: 0.059006549417972565\n",
      "Gradient for encoder.mean.bias: 0.002053204458206892\n",
      "Gradient for encoder.log_var.weight: 0.03537649288773537\n",
      "Gradient for encoder.log_var.bias: 0.0013545771362259984\n",
      "Gradient for decoder.decoder.0.weight: 0.011440057307481766\n",
      "Gradient for decoder.decoder.0.bias: 9.825175395494767e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.000560026615858078\n",
      "Gradient for decoder.decoder.1.bias: 0.00047651436761952937\n",
      "Gradient for decoder.decoder.3.weight: 0.010655833408236504\n",
      "Gradient for decoder.decoder.3.bias: 9.347894680544755e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00038538500666618347\n",
      "Gradient for decoder.decoder.4.bias: 0.0003371537022758275\n",
      "Gradient for decoder.decoder.6.weight: 0.0007660932606086135\n",
      "Gradient for decoder.decoder.6.bias: 4.351367897470482e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.0074219778180122375\n",
      "Gradient for encoder.encoder.0.bias: 1.046735354642836e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.000620090460870415\n",
      "Gradient for encoder.encoder.1.bias: 0.0006076008430682123\n",
      "Gradient for encoder.encoder.3.weight: 0.014026958495378494\n",
      "Gradient for encoder.encoder.3.bias: 1.259792964392048e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.003922074101865292\n",
      "Gradient for encoder.encoder.4.bias: 0.002831121673807502\n",
      "Gradient for encoder.mean.weight: 0.05490538477897644\n",
      "Gradient for encoder.mean.bias: 0.0019112717127427459\n",
      "Gradient for encoder.log_var.weight: 0.03413567692041397\n",
      "Gradient for encoder.log_var.bias: 0.0012004332384094596\n",
      "Gradient for decoder.decoder.0.weight: 0.011693568900227547\n",
      "Gradient for decoder.decoder.0.bias: 9.422362196032097e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005517093231901526\n",
      "Gradient for decoder.decoder.1.bias: 0.0004591506440192461\n",
      "Gradient for decoder.decoder.3.weight: 0.01114040520042181\n",
      "Gradient for decoder.decoder.3.bias: 8.248988991876871e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0004191050829831511\n",
      "Gradient for decoder.decoder.4.bias: 0.0003688074357341975\n",
      "Gradient for decoder.decoder.6.weight: 0.0007800954044796526\n",
      "Gradient for decoder.decoder.6.bias: 4.649553375202231e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.006925137713551521\n",
      "Gradient for encoder.encoder.0.bias: 1.2703486700071931e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0006518125301226974\n",
      "Gradient for encoder.encoder.1.bias: 0.000507770455442369\n",
      "Gradient for encoder.encoder.3.weight: 0.014507154934108257\n",
      "Gradient for encoder.encoder.3.bias: 1.475800592842802e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.003905294230207801\n",
      "Gradient for encoder.encoder.4.bias: 0.0032690181396901608\n",
      "Gradient for encoder.mean.weight: 0.05448991805315018\n",
      "Gradient for encoder.mean.bias: 0.002238516928628087\n",
      "Gradient for encoder.log_var.weight: 0.03495725989341736\n",
      "Gradient for encoder.log_var.bias: 0.0014129242626950145\n",
      "Gradient for decoder.decoder.0.weight: 0.010374230332672596\n",
      "Gradient for decoder.decoder.0.bias: 8.6719735559182e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0004970005247741938\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training VAE Epoch:  20%|██        | 16/79 [00:00<00:01, 49.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient for decoder.decoder.1.bias: 0.00041075190529227257\n",
      "Gradient for decoder.decoder.3.weight: 0.00988991092890501\n",
      "Gradient for decoder.decoder.3.bias: 7.873086904641724e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00037449097726494074\n",
      "Gradient for decoder.decoder.4.bias: 0.00028542475774884224\n",
      "Gradient for decoder.decoder.6.weight: 0.0007098622154444456\n",
      "Gradient for decoder.decoder.6.bias: 3.5292185202706605e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.005808365065604448\n",
      "Gradient for encoder.encoder.0.bias: 8.517913804850785e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.0004450820561032742\n",
      "Gradient for encoder.encoder.1.bias: 0.0004126277635805309\n",
      "Gradient for encoder.encoder.3.weight: 0.009877693839371204\n",
      "Gradient for encoder.encoder.3.bias: 1.0926913540654226e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0027827725280076265\n",
      "Gradient for encoder.encoder.4.bias: 0.0017978404648602009\n",
      "Gradient for encoder.mean.weight: 0.042020268738269806\n",
      "Gradient for encoder.mean.bias: 0.0014222110621631145\n",
      "Gradient for encoder.log_var.weight: 0.02426435425877571\n",
      "Gradient for encoder.log_var.bias: 0.0008986633620224893\n",
      "Gradient for decoder.decoder.0.weight: 0.011764406226575375\n",
      "Gradient for decoder.decoder.0.bias: 1.02007319258135e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0005781588843092322\n",
      "Gradient for decoder.decoder.1.bias: 0.0004942458472214639\n",
      "Gradient for decoder.decoder.3.weight: 0.011564280837774277\n",
      "Gradient for decoder.decoder.3.bias: 8.661260597619957e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0004274604725651443\n",
      "Gradient for decoder.decoder.4.bias: 0.00038843255606479943\n",
      "Gradient for decoder.decoder.6.weight: 0.0007187487208284438\n",
      "Gradient for decoder.decoder.6.bias: 3.581239434424788e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.006934387609362602\n",
      "Gradient for encoder.encoder.0.bias: 1.0017806029161136e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0005127154872752726\n",
      "Gradient for encoder.encoder.1.bias: 0.0005152064259164035\n",
      "Gradient for encoder.encoder.3.weight: 0.011315437965095043\n",
      "Gradient for encoder.encoder.3.bias: 1.0641130337996074e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0032204652670770884\n",
      "Gradient for encoder.encoder.4.bias: 0.0020579847041517496\n",
      "Gradient for encoder.mean.weight: 0.048012442886829376\n",
      "Gradient for encoder.mean.bias: 0.0016300121787935495\n",
      "Gradient for encoder.log_var.weight: 0.029633639380335808\n",
      "Gradient for encoder.log_var.bias: 0.0012083299225196242\n",
      "Gradient for decoder.decoder.0.weight: 0.010645410977303982\n",
      "Gradient for decoder.decoder.0.bias: 8.744890228618019e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005448925658129156\n",
      "Gradient for decoder.decoder.1.bias: 0.00043240885133855045\n",
      "Gradient for decoder.decoder.3.weight: 0.010235410183668137\n",
      "Gradient for decoder.decoder.3.bias: 7.412730845812732e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00042086877510882914\n",
      "Gradient for decoder.decoder.4.bias: 0.00037504223291762173\n",
      "Gradient for decoder.decoder.6.weight: 0.0007259026169776917\n",
      "Gradient for decoder.decoder.6.bias: 3.4275617508683354e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training VAE Epoch:  30%|███       | 24/79 [00:00<00:00, 58.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient for encoder.encoder.0.weight: 0.007177600637078285\n",
      "Gradient for encoder.encoder.0.bias: 1.0123970238529179e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0004679114499595016\n",
      "Gradient for encoder.encoder.1.bias: 0.00046313239727169275\n",
      "Gradient for encoder.encoder.3.weight: 0.011003971099853516\n",
      "Gradient for encoder.encoder.3.bias: 1.1859903337185784e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0034615148324519396\n",
      "Gradient for encoder.encoder.4.bias: 0.002761546755209565\n",
      "Gradient for encoder.mean.weight: 0.047994207590818405\n",
      "Gradient for encoder.mean.bias: 0.0016886625671759248\n",
      "Gradient for encoder.log_var.weight: 0.025573594495654106\n",
      "Gradient for encoder.log_var.bias: 0.001117661246098578\n",
      "Gradient for decoder.decoder.0.weight: 0.010508444160223007\n",
      "Gradient for decoder.decoder.0.bias: 9.23960907783794e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005239320453256369\n",
      "Gradient for decoder.decoder.1.bias: 0.000445701414719224\n",
      "Gradient for decoder.decoder.3.weight: 0.009970197454094887\n",
      "Gradient for decoder.decoder.3.bias: 8.796202655148022e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0003712914476636797\n",
      "Gradient for decoder.decoder.4.bias: 0.00035360289621166885\n",
      "Gradient for decoder.decoder.6.weight: 0.000735125970095396\n",
      "Gradient for decoder.decoder.6.bias: 4.4550513848662376e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.006353881675750017\n",
      "Gradient for encoder.encoder.0.bias: 9.33996196356146e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.0005647194338962436\n",
      "Gradient for encoder.encoder.1.bias: 0.0005331606371328235\n",
      "Gradient for encoder.encoder.3.weight: 0.01219707727432251\n",
      "Gradient for encoder.encoder.3.bias: 1.210701261467051e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0030198656022548676\n",
      "Gradient for encoder.encoder.4.bias: 0.002354355063289404\n",
      "Gradient for encoder.mean.weight: 0.0449715219438076\n",
      "Gradient for encoder.mean.bias: 0.0016108386917039752\n",
      "Gradient for encoder.log_var.weight: 0.022758040577173233\n",
      "Gradient for encoder.log_var.bias: 0.001002786448225379\n",
      "Gradient for decoder.decoder.0.weight: 0.012679592706263065\n",
      "Gradient for decoder.decoder.0.bias: 1.0555502999443078e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0006148532847873867\n",
      "Gradient for decoder.decoder.1.bias: 0.000530910911038518\n",
      "Gradient for decoder.decoder.3.weight: 0.01208565104752779\n",
      "Gradient for decoder.decoder.3.bias: 9.377524451403829e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0004923098022118211\n",
      "Gradient for decoder.decoder.4.bias: 0.0004369105736259371\n",
      "Gradient for decoder.decoder.6.weight: 0.0008348519913852215\n",
      "Gradient for decoder.decoder.6.bias: 5.152769881533459e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.006303527858108282\n",
      "Gradient for encoder.encoder.0.bias: 1.1342149441873062e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0004490653518587351\n",
      "Gradient for encoder.encoder.1.bias: 0.0005739749176427722\n",
      "Gradient for encoder.encoder.3.weight: 0.0100984713062644\n",
      "Gradient for encoder.encoder.3.bias: 1.1237039770906065e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0035846529062837362\n",
      "Gradient for encoder.encoder.4.bias: 0.002280866727232933\n",
      "Gradient for encoder.mean.weight: 0.05319688841700554\n",
      "Gradient for encoder.mean.bias: 0.001650145510211587\n",
      "Gradient for encoder.log_var.weight: 0.03221645951271057\n",
      "Gradient for encoder.log_var.bias: 0.001144760986790061\n",
      "Gradient for decoder.decoder.0.weight: 0.011356730945408344\n",
      "Gradient for decoder.decoder.0.bias: 8.454036082294891e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005485814763233066\n",
      "Gradient for decoder.decoder.1.bias: 0.0004295165417715907\n",
      "Gradient for decoder.decoder.3.weight: 0.010028505697846413\n",
      "Gradient for decoder.decoder.3.bias: 1.0161358560134559e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0006308580050244927\n",
      "Gradient for decoder.decoder.4.bias: 0.0007596070063300431\n",
      "Gradient for decoder.decoder.6.weight: 0.0008617903804406524\n",
      "Gradient for decoder.decoder.6.bias: 6.732623296556994e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.007133727427572012\n",
      "Gradient for encoder.encoder.0.bias: 9.464727612762402e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.0005523175350390375\n",
      "Gradient for encoder.encoder.1.bias: 0.0005659558228217065\n",
      "Gradient for encoder.encoder.3.weight: 0.012553870677947998\n",
      "Gradient for encoder.encoder.3.bias: 1.3620404804015607e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0031540384516119957\n",
      "Gradient for encoder.encoder.4.bias: 0.0028678434900939465\n",
      "Gradient for encoder.mean.weight: 0.04498777538537979\n",
      "Gradient for encoder.mean.bias: 0.0026445589028298855\n",
      "Gradient for encoder.log_var.weight: 0.025152573361992836\n",
      "Gradient for encoder.log_var.bias: 0.0014952777419239283\n",
      "Gradient for decoder.decoder.0.weight: 0.011454351246356964\n",
      "Gradient for decoder.decoder.0.bias: 1.0197005739787102e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0005217015277594328\n",
      "Gradient for decoder.decoder.1.bias: 0.0005163461319170892\n",
      "Gradient for decoder.decoder.3.weight: 0.010906058363616467\n",
      "Gradient for decoder.decoder.3.bias: 9.569244702190005e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0004682632570620626\n",
      "Gradient for decoder.decoder.4.bias: 0.0004701278230641037\n",
      "Gradient for decoder.decoder.6.weight: 0.0007585962302982807\n",
      "Gradient for decoder.decoder.6.bias: 4.228380203130655e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.008182939141988754\n",
      "Gradient for encoder.encoder.0.bias: 1.3038534661669043e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0005649427766911685\n",
      "Gradient for encoder.encoder.1.bias: 0.0006996635347604752\n",
      "Gradient for encoder.encoder.3.weight: 0.012574628926813602\n",
      "Gradient for encoder.encoder.3.bias: 1.2758195888640245e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0026390866842120886\n",
      "Gradient for encoder.encoder.4.bias: 0.002664984669536352\n",
      "Gradient for encoder.mean.weight: 0.039721857756376266\n",
      "Gradient for encoder.mean.bias: 0.002087915316224098\n",
      "Gradient for encoder.log_var.weight: 0.02311502769589424\n",
      "Gradient for encoder.log_var.bias: 0.0014154723612591624\n",
      "Gradient for decoder.decoder.0.weight: 0.010016798041760921\n",
      "Gradient for decoder.decoder.0.bias: 8.345653335073422e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005001217941753566\n",
      "Gradient for decoder.decoder.1.bias: 0.0003924011252820492\n",
      "Gradient for decoder.decoder.3.weight: 0.009718144312500954\n",
      "Gradient for decoder.decoder.3.bias: 9.023434083266224e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0005563343875110149\n",
      "Gradient for decoder.decoder.4.bias: 0.0006827272591181099\n",
      "Gradient for decoder.decoder.6.weight: 0.0007713024388067424\n",
      "Gradient for decoder.decoder.6.bias: 5.860315650352277e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.004964545834809542\n",
      "Gradient for encoder.encoder.0.bias: 7.642626115300644e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.0004149216692894697\n",
      "Gradient for encoder.encoder.1.bias: 0.00048820432857610285\n",
      "Gradient for encoder.encoder.3.weight: 0.008897651918232441\n",
      "Gradient for encoder.encoder.3.bias: 1.0724917481885754e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.002751236082985997\n",
      "Gradient for encoder.encoder.4.bias: 0.0020268410444259644\n",
      "Gradient for encoder.mean.weight: 0.042145438492298126\n",
      "Gradient for encoder.mean.bias: 0.001374014769680798\n",
      "Gradient for encoder.log_var.weight: 0.023383378982543945\n",
      "Gradient for encoder.log_var.bias: 0.0010506620164960623\n",
      "Gradient for decoder.decoder.0.weight: 0.012867964804172516\n",
      "Gradient for decoder.decoder.0.bias: 1.1422834900187695e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0006397186662070453\n",
      "Gradient for decoder.decoder.1.bias: 0.0005447338917292655\n",
      "Gradient for decoder.decoder.3.weight: 0.012349581345915794\n",
      "Gradient for decoder.decoder.3.bias: 1.0784220044746107e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0004503865202423185\n",
      "Gradient for decoder.decoder.4.bias: 0.0004144445701967925\n",
      "Gradient for decoder.decoder.6.weight: 0.0007049897103570402\n",
      "Gradient for decoder.decoder.6.bias: 3.339715476613492e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.006697257049381733\n",
      "Gradient for encoder.encoder.0.bias: 1.0699556692028711e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0005396395572461188\n",
      "Gradient for encoder.encoder.1.bias: 0.0004845054936595261\n",
      "Gradient for encoder.encoder.3.weight: 0.012052923440933228\n",
      "Gradient for encoder.encoder.3.bias: 1.273881139463029e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.003368858713656664\n",
      "Gradient for encoder.encoder.4.bias: 0.003137006191536784\n",
      "Gradient for encoder.mean.weight: 0.05026187375187874\n",
      "Gradient for encoder.mean.bias: 0.0026409828569740057\n",
      "Gradient for encoder.log_var.weight: 0.03136643394827843\n",
      "Gradient for encoder.log_var.bias: 0.001770224655047059\n",
      "Gradient for decoder.decoder.0.weight: 0.010509124957025051\n",
      "Gradient for decoder.decoder.0.bias: 8.600116452317508e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.00053780636517331\n",
      "Gradient for decoder.decoder.1.bias: 0.0004234685329720378\n",
      "Gradient for decoder.decoder.3.weight: 0.009810938499867916\n",
      "Gradient for decoder.decoder.3.bias: 7.915854083329066e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0003999663458671421\n",
      "Gradient for decoder.decoder.4.bias: 0.0003752410120796412\n",
      "Gradient for decoder.decoder.6.weight: 0.000744158576708287\n",
      "Gradient for decoder.decoder.6.bias: 4.392833943711594e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.008461089804768562\n",
      "Gradient for encoder.encoder.0.bias: 1.4224868678802682e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.000824081536848098\n",
      "Gradient for encoder.encoder.1.bias: 0.0006885133334435523\n",
      "Gradient for encoder.encoder.3.weight: 0.01828591153025627\n",
      "Gradient for encoder.encoder.3.bias: 1.485097461673135e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.00429572444409132\n",
      "Gradient for encoder.encoder.4.bias: 0.003413085825741291\n",
      "Gradient for encoder.mean.weight: 0.0592358224093914\n",
      "Gradient for encoder.mean.bias: 0.001941386959515512\n",
      "Gradient for encoder.log_var.weight: 0.03649359941482544\n",
      "Gradient for encoder.log_var.bias: 0.0012130840914323926\n",
      "Gradient for decoder.decoder.0.weight: 0.010862781666219234\n",
      "Gradient for decoder.decoder.0.bias: 9.427081337776144e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005140951252542436\n",
      "Gradient for decoder.decoder.1.bias: 0.0004631649935618043\n",
      "Gradient for decoder.decoder.3.weight: 0.010422272607684135\n",
      "Gradient for decoder.decoder.3.bias: 9.043807369657486e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0003477555583231151\n",
      "Gradient for decoder.decoder.4.bias: 0.00033063089358620346\n",
      "Gradient for decoder.decoder.6.weight: 0.0008647526265121996\n",
      "Gradient for decoder.decoder.6.bias: 6.188724364619702e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.006875069346278906\n",
      "Gradient for encoder.encoder.0.bias: 1.0555221627295275e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.00048607162898406386\n",
      "Gradient for encoder.encoder.1.bias: 0.0004646157321985811\n",
      "Gradient for encoder.encoder.3.weight: 0.010889235883951187\n",
      "Gradient for encoder.encoder.3.bias: 1.106650743265547e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0024511825758963823\n",
      "Gradient for encoder.encoder.4.bias: 0.0023487010039389133\n",
      "Gradient for encoder.mean.weight: 0.03779160976409912\n",
      "Gradient for encoder.mean.bias: 0.0019233131315559149\n",
      "Gradient for encoder.log_var.weight: 0.020349621772766113\n",
      "Gradient for encoder.log_var.bias: 0.0013317292323336005\n",
      "Gradient for decoder.decoder.0.weight: 0.009439255110919476\n",
      "Gradient for decoder.decoder.0.bias: 7.867351214940754e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0004624510183930397\n",
      "Gradient for decoder.decoder.1.bias: 0.00039546325569972396\n",
      "Gradient for decoder.decoder.3.weight: 0.008744553662836552\n",
      "Gradient for decoder.decoder.3.bias: 7.604122193027862e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00034201587550342083\n",
      "Gradient for decoder.decoder.4.bias: 0.0002927987079601735\n",
      "Gradient for decoder.decoder.6.weight: 0.0007612842018716037\n",
      "Gradient for decoder.decoder.6.bias: 5.153952952241525e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.0058978283777832985\n",
      "Gradient for encoder.encoder.0.bias: 8.02616740430695e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.0004257076943758875\n",
      "Gradient for encoder.encoder.1.bias: 0.00040630524745211005\n",
      "Gradient for encoder.encoder.3.weight: 0.009266847744584084\n",
      "Gradient for encoder.encoder.3.bias: 1.0284317841779966e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.002898314269259572\n",
      "Gradient for encoder.encoder.4.bias: 0.0019226595759391785\n",
      "Gradient for encoder.mean.weight: 0.04290091246366501\n",
      "Gradient for encoder.mean.bias: 0.0014676988357678056\n",
      "Gradient for encoder.log_var.weight: 0.02302294224500656\n",
      "Gradient for encoder.log_var.bias: 0.0009145091171376407\n",
      "Gradient for decoder.decoder.0.weight: 0.012725423090159893\n",
      "Gradient for decoder.decoder.0.bias: 1.075437239261845e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0006058909930288792\n",
      "Gradient for decoder.decoder.1.bias: 0.0005289711989462376\n",
      "Gradient for decoder.decoder.3.weight: 0.011880413629114628\n",
      "Gradient for decoder.decoder.3.bias: 9.757390728726278e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0005896286456845701\n",
      "Gradient for decoder.decoder.4.bias: 0.0006488548242487013\n",
      "Gradient for decoder.decoder.6.weight: 0.0008378753555007279\n",
      "Gradient for decoder.decoder.6.bias: 5.508787216967903e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.009411269798874855\n",
      "Gradient for encoder.encoder.0.bias: 1.4912191273475095e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0006043793400749564\n",
      "Gradient for encoder.encoder.1.bias: 0.0005703098140656948\n",
      "Gradient for encoder.encoder.3.weight: 0.012842454016208649\n",
      "Gradient for encoder.encoder.3.bias: 1.331658672221181e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0027561835013329983\n",
      "Gradient for encoder.encoder.4.bias: 0.002170892897993326\n",
      "Gradient for encoder.mean.weight: 0.03946448862552643\n",
      "Gradient for encoder.mean.bias: 0.0016986984992399812\n",
      "Gradient for encoder.log_var.weight: 0.021073587238788605\n",
      "Gradient for encoder.log_var.bias: 0.001058437628671527\n",
      "Gradient for decoder.decoder.0.weight: 0.009479508735239506\n",
      "Gradient for decoder.decoder.0.bias: 8.27266102843005e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.00044942970271222293\n",
      "Gradient for decoder.decoder.1.bias: 0.0003773192875087261\n",
      "Gradient for decoder.decoder.3.weight: 0.008573953062295914\n",
      "Gradient for decoder.decoder.3.bias: 7.9182778389697e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00034850023803301156\n",
      "Gradient for decoder.decoder.4.bias: 0.00035378927714191377\n",
      "Gradient for decoder.decoder.6.weight: 0.0007526410627178848\n",
      "Gradient for decoder.decoder.6.bias: 5.0445622036932036e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.0068503012880682945\n",
      "Gradient for encoder.encoder.0.bias: 1.2589574348298438e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0005572623922489583\n",
      "Gradient for encoder.encoder.1.bias: 0.000607981055509299\n",
      "Gradient for encoder.encoder.3.weight: 0.012572425417602062\n",
      "Gradient for encoder.encoder.3.bias: 1.1474316635728954e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0026535242795944214\n",
      "Gradient for encoder.encoder.4.bias: 0.002150586573407054\n",
      "Gradient for encoder.mean.weight: 0.04090489447116852\n",
      "Gradient for encoder.mean.bias: 0.0015923428582027555\n",
      "Gradient for encoder.log_var.weight: 0.022841284051537514\n",
      "Gradient for encoder.log_var.bias: 0.0011140004498884082\n",
      "Gradient for decoder.decoder.0.weight: 0.011620929464697838\n",
      "Gradient for decoder.decoder.0.bias: 1.0451364079733239e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0005795934121124446\n",
      "Gradient for decoder.decoder.1.bias: 0.0004963497631251812\n",
      "Gradient for decoder.decoder.3.weight: 0.010554203763604164\n",
      "Gradient for decoder.decoder.3.bias: 7.889579961561921e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0004009926924481988\n",
      "Gradient for decoder.decoder.4.bias: 0.00035536964423954487\n",
      "Gradient for decoder.decoder.6.weight: 0.0007580398814752698\n",
      "Gradient for decoder.decoder.6.bias: 4.229439946357161e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.00781695730984211\n",
      "Gradient for encoder.encoder.0.bias: 9.357143532229273e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.0005034233327023685\n",
      "Gradient for encoder.encoder.1.bias: 0.00044942324166186154\n",
      "Gradient for encoder.encoder.3.weight: 0.010730723850429058\n",
      "Gradient for encoder.encoder.3.bias: 1.0830692592778135e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0021798613015562296\n",
      "Gradient for encoder.encoder.4.bias: 0.0016515483148396015\n",
      "Gradient for encoder.mean.weight: 0.03330866992473602\n",
      "Gradient for encoder.mean.bias: 0.0012536486610770226\n",
      "Gradient for encoder.log_var.weight: 0.01960110291838646\n",
      "Gradient for encoder.log_var.bias: 0.0009041462908498943\n",
      "Gradient for decoder.decoder.0.weight: 0.011123293079435825\n",
      "Gradient for decoder.decoder.0.bias: 8.885773367106609e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005567999323830009\n",
      "Gradient for decoder.decoder.1.bias: 0.00047116808127611876\n",
      "Gradient for decoder.decoder.3.weight: 0.010542066767811775\n",
      "Gradient for decoder.decoder.3.bias: 7.643734950546488e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00044105006963945925\n",
      "Gradient for decoder.decoder.4.bias: 0.00038196684909053147\n",
      "Gradient for decoder.decoder.6.weight: 0.0007974770269356668\n",
      "Gradient for decoder.decoder.6.bias: 4.6899582230253145e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training VAE Epoch:  41%|████      | 32/79 [00:00<00:00, 64.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient for encoder.encoder.0.weight: 0.005009067244827747\n",
      "Gradient for encoder.encoder.0.bias: 7.942253625603524e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.0004756850248668343\n",
      "Gradient for encoder.encoder.1.bias: 0.0004259465786162764\n",
      "Gradient for encoder.encoder.3.weight: 0.010845083743333817\n",
      "Gradient for encoder.encoder.3.bias: 1.0900641500555253e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0030825892463326454\n",
      "Gradient for encoder.encoder.4.bias: 0.002194622065871954\n",
      "Gradient for encoder.mean.weight: 0.04663271829485893\n",
      "Gradient for encoder.mean.bias: 0.0014602396404370666\n",
      "Gradient for encoder.log_var.weight: 0.025493644177913666\n",
      "Gradient for encoder.log_var.bias: 0.0008999543497338891\n",
      "Gradient for decoder.decoder.0.weight: 0.013160591013729572\n",
      "Gradient for decoder.decoder.0.bias: 1.0704447744869228e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0006206032121554017\n",
      "Gradient for decoder.decoder.1.bias: 0.0005608135834336281\n",
      "Gradient for decoder.decoder.3.weight: 0.01194535568356514\n",
      "Gradient for decoder.decoder.3.bias: 1.1377002812062997e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0006335081998258829\n",
      "Gradient for decoder.decoder.4.bias: 0.0006948723457753658\n",
      "Gradient for decoder.decoder.6.weight: 0.0008184267207980156\n",
      "Gradient for decoder.decoder.6.bias: 5.1748862460954115e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.005006357096135616\n",
      "Gradient for encoder.encoder.0.bias: 8.574225530966206e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.0004033581062685698\n",
      "Gradient for encoder.encoder.1.bias: 0.00046584728988818824\n",
      "Gradient for encoder.encoder.3.weight: 0.009194974787533283\n",
      "Gradient for encoder.encoder.3.bias: 9.835168096605784e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.0029263726901263\n",
      "Gradient for encoder.encoder.4.bias: 0.002217501401901245\n",
      "Gradient for encoder.mean.weight: 0.042909033596515656\n",
      "Gradient for encoder.mean.bias: 0.0019339246209710836\n",
      "Gradient for encoder.log_var.weight: 0.026933889836072922\n",
      "Gradient for encoder.log_var.bias: 0.001023625023663044\n",
      "Gradient for decoder.decoder.0.weight: 0.011064505204558372\n",
      "Gradient for decoder.decoder.0.bias: 1.0223639296258469e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0005161241278983653\n",
      "Gradient for decoder.decoder.1.bias: 0.00042307100375182927\n",
      "Gradient for decoder.decoder.3.weight: 0.010077427141368389\n",
      "Gradient for decoder.decoder.3.bias: 9.567222014617016e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0006285755080170929\n",
      "Gradient for decoder.decoder.4.bias: 0.0007571576279588044\n",
      "Gradient for decoder.decoder.6.weight: 0.0008653730037622154\n",
      "Gradient for decoder.decoder.6.bias: 6.986528023844585e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.011277319863438606\n",
      "Gradient for encoder.encoder.0.bias: 2.0207660197946176e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.001029664184898138\n",
      "Gradient for encoder.encoder.1.bias: 0.0007782148313708603\n",
      "Gradient for encoder.encoder.3.weight: 0.02178112044930458\n",
      "Gradient for encoder.encoder.3.bias: 1.7841651767103173e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.004755964502692223\n",
      "Gradient for encoder.encoder.4.bias: 0.00402069091796875\n",
      "Gradient for encoder.mean.weight: 0.06755203753709793\n",
      "Gradient for encoder.mean.bias: 0.0021112579852342606\n",
      "Gradient for encoder.log_var.weight: 0.03607570752501488\n",
      "Gradient for encoder.log_var.bias: 0.0014420514926314354\n",
      "Gradient for decoder.decoder.0.weight: 0.008528103120625019\n",
      "Gradient for decoder.decoder.0.bias: 7.199844193062077e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.00038011811557225883\n",
      "Gradient for decoder.decoder.1.bias: 0.00035011174622923136\n",
      "Gradient for decoder.decoder.3.weight: 0.007942372933030128\n",
      "Gradient for decoder.decoder.3.bias: 6.544383784889973e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0003226358676329255\n",
      "Gradient for decoder.decoder.4.bias: 0.00030014029471203685\n",
      "Gradient for decoder.decoder.6.weight: 0.0007543748943135142\n",
      "Gradient for decoder.decoder.6.bias: 4.836216976400465e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training VAE Epoch:  51%|█████     | 40/79 [00:00<00:00, 68.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient for encoder.encoder.0.weight: 0.004326815716922283\n",
      "Gradient for encoder.encoder.0.bias: 7.0512337288497484e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.0004613596247509122\n",
      "Gradient for encoder.encoder.1.bias: 0.0005871165194548666\n",
      "Gradient for encoder.encoder.3.weight: 0.01074175350368023\n",
      "Gradient for encoder.encoder.3.bias: 1.0643953773925574e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0037998841144144535\n",
      "Gradient for encoder.encoder.4.bias: 0.0023357481695711613\n",
      "Gradient for encoder.mean.weight: 0.05046561732888222\n",
      "Gradient for encoder.mean.bias: 0.0016721105203032494\n",
      "Gradient for encoder.log_var.weight: 0.03376708924770355\n",
      "Gradient for encoder.log_var.bias: 0.001200461178086698\n",
      "Gradient for decoder.decoder.0.weight: 0.01375572569668293\n",
      "Gradient for decoder.decoder.0.bias: 1.23846044530751e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0006292167818173766\n",
      "Gradient for decoder.decoder.1.bias: 0.0005905146826989949\n",
      "Gradient for decoder.decoder.3.weight: 0.013176088221371174\n",
      "Gradient for decoder.decoder.3.bias: 1.1153235279781626e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0004840792389586568\n",
      "Gradient for decoder.decoder.4.bias: 0.00045327848056331277\n",
      "Gradient for decoder.decoder.6.weight: 0.0008195527479983866\n",
      "Gradient for decoder.decoder.6.bias: 5.751470598625019e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.005547177977859974\n",
      "Gradient for encoder.encoder.0.bias: 8.56347891903253e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.0004345215274952352\n",
      "Gradient for encoder.encoder.1.bias: 0.0004824283823836595\n",
      "Gradient for encoder.encoder.3.weight: 0.009465804323554039\n",
      "Gradient for encoder.encoder.3.bias: 9.167715891988948e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.002625287976115942\n",
      "Gradient for encoder.encoder.4.bias: 0.0017355285817757249\n",
      "Gradient for encoder.mean.weight: 0.04091649502515793\n",
      "Gradient for encoder.mean.bias: 0.0013264201115816832\n",
      "Gradient for encoder.log_var.weight: 0.022384487092494965\n",
      "Gradient for encoder.log_var.bias: 0.0010330460499972105\n",
      "Gradient for decoder.decoder.0.weight: 0.012456471100449562\n",
      "Gradient for decoder.decoder.0.bias: 1.0428875818480066e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0006314889178611338\n",
      "Gradient for decoder.decoder.1.bias: 0.0005341369542293251\n",
      "Gradient for decoder.decoder.3.weight: 0.011679543182253838\n",
      "Gradient for decoder.decoder.3.bias: 9.449784010850948e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0004519394424278289\n",
      "Gradient for decoder.decoder.4.bias: 0.0003569078689906746\n",
      "Gradient for decoder.decoder.6.weight: 0.0007306694169528782\n",
      "Gradient for decoder.decoder.6.bias: 3.336804729769938e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.007963649928569794\n",
      "Gradient for encoder.encoder.0.bias: 1.0781122522507403e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.00047651398926973343\n",
      "Gradient for encoder.encoder.1.bias: 0.000446688529336825\n",
      "Gradient for encoder.encoder.3.weight: 0.010399838909506798\n",
      "Gradient for encoder.encoder.3.bias: 1.303333135860285e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0026660310104489326\n",
      "Gradient for encoder.encoder.4.bias: 0.002606405410915613\n",
      "Gradient for encoder.mean.weight: 0.03990016132593155\n",
      "Gradient for encoder.mean.bias: 0.002070824848487973\n",
      "Gradient for encoder.log_var.weight: 0.021915731951594353\n",
      "Gradient for encoder.log_var.bias: 0.001155942678451538\n",
      "Gradient for decoder.decoder.0.weight: 0.009936889633536339\n",
      "Gradient for decoder.decoder.0.bias: 8.48976583478489e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0004799762973561883\n",
      "Gradient for decoder.decoder.1.bias: 0.0004061397921759635\n",
      "Gradient for decoder.decoder.3.weight: 0.009228800423443317\n",
      "Gradient for decoder.decoder.3.bias: 9.645705068006549e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0005412216996774077\n",
      "Gradient for decoder.decoder.4.bias: 0.0006362170679494739\n",
      "Gradient for decoder.decoder.6.weight: 0.0007327639614231884\n",
      "Gradient for decoder.decoder.6.bias: 4.955055192112923e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.006350548937916756\n",
      "Gradient for encoder.encoder.0.bias: 9.155949436123745e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.0005218383739702404\n",
      "Gradient for encoder.encoder.1.bias: 0.000528391101397574\n",
      "Gradient for encoder.encoder.3.weight: 0.011141299270093441\n",
      "Gradient for encoder.encoder.3.bias: 9.45236180993625e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.003013479756191373\n",
      "Gradient for encoder.encoder.4.bias: 0.0018557445146143436\n",
      "Gradient for encoder.mean.weight: 0.046204786747694016\n",
      "Gradient for encoder.mean.bias: 0.0015140565810725093\n",
      "Gradient for encoder.log_var.weight: 0.026221785694360733\n",
      "Gradient for encoder.log_var.bias: 0.0008774313027970493\n",
      "Gradient for decoder.decoder.0.weight: 0.011151446960866451\n",
      "Gradient for decoder.decoder.0.bias: 8.938207812780874e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005080124828964472\n",
      "Gradient for decoder.decoder.1.bias: 0.00043723502312786877\n",
      "Gradient for decoder.decoder.3.weight: 0.010680589824914932\n",
      "Gradient for decoder.decoder.3.bias: 7.391786488453178e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00046889419900253415\n",
      "Gradient for decoder.decoder.4.bias: 0.0004550358571577817\n",
      "Gradient for decoder.decoder.6.weight: 0.0007538975914940238\n",
      "Gradient for decoder.decoder.6.bias: 3.9599250158062205e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.009450509212911129\n",
      "Gradient for encoder.encoder.0.bias: 1.8458078815397627e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0007190323085524142\n",
      "Gradient for encoder.encoder.1.bias: 0.0007450653938576579\n",
      "Gradient for encoder.encoder.3.weight: 0.01612744852900505\n",
      "Gradient for encoder.encoder.3.bias: 1.5426449007094334e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0034327649045735598\n",
      "Gradient for encoder.encoder.4.bias: 0.003505078610032797\n",
      "Gradient for encoder.mean.weight: 0.04823951795697212\n",
      "Gradient for encoder.mean.bias: 0.0028210992459207773\n",
      "Gradient for encoder.log_var.weight: 0.030818723142147064\n",
      "Gradient for encoder.log_var.bias: 0.0020315018482506275\n",
      "Gradient for decoder.decoder.0.weight: 0.008790251798927784\n",
      "Gradient for decoder.decoder.0.bias: 7.526416295755567e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0004179474199190736\n",
      "Gradient for decoder.decoder.1.bias: 0.00035877697519026697\n",
      "Gradient for decoder.decoder.3.weight: 0.008237655274569988\n",
      "Gradient for decoder.decoder.3.bias: 7.693404247000046e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00044770148815587163\n",
      "Gradient for decoder.decoder.4.bias: 0.0005058196256868541\n",
      "Gradient for decoder.decoder.6.weight: 0.000764943310059607\n",
      "Gradient for decoder.decoder.6.bias: 5.290027183946222e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.007476327009499073\n",
      "Gradient for encoder.encoder.0.bias: 1.2493410819769402e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.00059371447423473\n",
      "Gradient for encoder.encoder.1.bias: 0.0005314373993314803\n",
      "Gradient for encoder.encoder.3.weight: 0.012741579674184322\n",
      "Gradient for encoder.encoder.3.bias: 1.256956899675643e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.003018977353349328\n",
      "Gradient for encoder.encoder.4.bias: 0.002999701537191868\n",
      "Gradient for encoder.mean.weight: 0.04121077060699463\n",
      "Gradient for encoder.mean.bias: 0.0022960430942475796\n",
      "Gradient for encoder.log_var.weight: 0.026188718155026436\n",
      "Gradient for encoder.log_var.bias: 0.0016920518828555942\n",
      "Gradient for decoder.decoder.0.weight: 0.010059795342385769\n",
      "Gradient for decoder.decoder.0.bias: 8.274753798831469e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0004964436520822346\n",
      "Gradient for decoder.decoder.1.bias: 0.00039969885256141424\n",
      "Gradient for decoder.decoder.3.weight: 0.009457050822675228\n",
      "Gradient for decoder.decoder.3.bias: 7.944603308551734e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0003761078987736255\n",
      "Gradient for decoder.decoder.4.bias: 0.00034631745074875653\n",
      "Gradient for decoder.decoder.6.weight: 0.0008352983859367669\n",
      "Gradient for decoder.decoder.6.bias: 6.271660822676495e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.006963478866964579\n",
      "Gradient for encoder.encoder.0.bias: 1.048006906950727e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0005267735105007887\n",
      "Gradient for encoder.encoder.1.bias: 0.0005223908228799701\n",
      "Gradient for encoder.encoder.3.weight: 0.011479825712740421\n",
      "Gradient for encoder.encoder.3.bias: 1.0686616869204357e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.002687948988750577\n",
      "Gradient for encoder.encoder.4.bias: 0.0019516820320859551\n",
      "Gradient for encoder.mean.weight: 0.036280322819948196\n",
      "Gradient for encoder.mean.bias: 0.0013362448662519455\n",
      "Gradient for encoder.log_var.weight: 0.023626098409295082\n",
      "Gradient for encoder.log_var.bias: 0.0010754429968073964\n",
      "Gradient for decoder.decoder.0.weight: 0.011908297426998615\n",
      "Gradient for decoder.decoder.0.bias: 9.990621524513799e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0006460441509261727\n",
      "Gradient for decoder.decoder.1.bias: 0.0005365963443182409\n",
      "Gradient for decoder.decoder.3.weight: 0.011348842643201351\n",
      "Gradient for decoder.decoder.3.bias: 8.65222546386768e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0004482024523895234\n",
      "Gradient for decoder.decoder.4.bias: 0.0003820928977802396\n",
      "Gradient for decoder.decoder.6.weight: 0.0007911029388196766\n",
      "Gradient for decoder.decoder.6.bias: 4.504165190155618e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.008917883038520813\n",
      "Gradient for encoder.encoder.0.bias: 1.3001301424342415e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0006238301284611225\n",
      "Gradient for encoder.encoder.1.bias: 0.0005665912758558989\n",
      "Gradient for encoder.encoder.3.weight: 0.013505078852176666\n",
      "Gradient for encoder.encoder.3.bias: 1.336286775677209e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.003265251172706485\n",
      "Gradient for encoder.encoder.4.bias: 0.0033314188476651907\n",
      "Gradient for encoder.mean.weight: 0.044650524854660034\n",
      "Gradient for encoder.mean.bias: 0.00264424504712224\n",
      "Gradient for encoder.log_var.weight: 0.024906305596232414\n",
      "Gradient for encoder.log_var.bias: 0.001526475534774363\n",
      "Gradient for decoder.decoder.0.weight: 0.010455888696014881\n",
      "Gradient for decoder.decoder.0.bias: 8.752727709282482e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005550483474507928\n",
      "Gradient for decoder.decoder.1.bias: 0.00041844561928883195\n",
      "Gradient for decoder.decoder.3.weight: 0.009647086262702942\n",
      "Gradient for decoder.decoder.3.bias: 9.018297220109162e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00036685183295048773\n",
      "Gradient for decoder.decoder.4.bias: 0.0003190467250533402\n",
      "Gradient for decoder.decoder.6.weight: 0.0007604161510244012\n",
      "Gradient for decoder.decoder.6.bias: 4.712511508841999e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.008475794456899166\n",
      "Gradient for encoder.encoder.0.bias: 1.4043237059335745e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0008244224009104073\n",
      "Gradient for encoder.encoder.1.bias: 0.0008172429515980184\n",
      "Gradient for encoder.encoder.3.weight: 0.017475202679634094\n",
      "Gradient for encoder.encoder.3.bias: 1.6971658800546408e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.004175896290689707\n",
      "Gradient for encoder.encoder.4.bias: 0.004394054412841797\n",
      "Gradient for encoder.mean.weight: 0.05640898272395134\n",
      "Gradient for encoder.mean.bias: 0.0035064718686044216\n",
      "Gradient for encoder.log_var.weight: 0.033965274691581726\n",
      "Gradient for encoder.log_var.bias: 0.002308094408363104\n",
      "Gradient for decoder.decoder.0.weight: 0.010450298897922039\n",
      "Gradient for decoder.decoder.0.bias: 9.017351448870059e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005092873470857739\n",
      "Gradient for decoder.decoder.1.bias: 0.00045871554175391793\n",
      "Gradient for decoder.decoder.3.weight: 0.009683066047728062\n",
      "Gradient for decoder.decoder.3.bias: 7.815124936083606e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00039326027035713196\n",
      "Gradient for decoder.decoder.4.bias: 0.00042213586857542396\n",
      "Gradient for decoder.decoder.6.weight: 0.0007116585620678961\n",
      "Gradient for decoder.decoder.6.bias: 3.850789289572276e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.008641871623694897\n",
      "Gradient for encoder.encoder.0.bias: 1.365964806543385e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0006680752849206328\n",
      "Gradient for encoder.encoder.1.bias: 0.0005811228766106069\n",
      "Gradient for encoder.encoder.3.weight: 0.014689682051539421\n",
      "Gradient for encoder.encoder.3.bias: 1.4559037309069822e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0034442164469510317\n",
      "Gradient for encoder.encoder.4.bias: 0.0028394334949553013\n",
      "Gradient for encoder.mean.weight: 0.04610152170062065\n",
      "Gradient for encoder.mean.bias: 0.0018903809832409024\n",
      "Gradient for encoder.log_var.weight: 0.025821682065725327\n",
      "Gradient for encoder.log_var.bias: 0.0012452721130102873\n",
      "Gradient for decoder.decoder.0.weight: 0.009644139558076859\n",
      "Gradient for decoder.decoder.0.bias: 9.357704194856709e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.00045916304225102067\n",
      "Gradient for decoder.decoder.1.bias: 0.00039646754157729447\n",
      "Gradient for decoder.decoder.3.weight: 0.008846969343721867\n",
      "Gradient for decoder.decoder.3.bias: 7.912195204573536e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0003118100867141038\n",
      "Gradient for decoder.decoder.4.bias: 0.0002874222118407488\n",
      "Gradient for decoder.decoder.6.weight: 0.0006851638318039477\n",
      "Gradient for decoder.decoder.6.bias: 3.586363891372457e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.005944030359387398\n",
      "Gradient for encoder.encoder.0.bias: 8.394901961084056e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.0004754072579089552\n",
      "Gradient for encoder.encoder.1.bias: 0.0004989932640455663\n",
      "Gradient for encoder.encoder.3.weight: 0.010199404321610928\n",
      "Gradient for encoder.encoder.3.bias: 1.0964493202259007e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.00281775020994246\n",
      "Gradient for encoder.encoder.4.bias: 0.00216804095543921\n",
      "Gradient for encoder.mean.weight: 0.037686627358198166\n",
      "Gradient for encoder.mean.bias: 0.0016865541692823172\n",
      "Gradient for encoder.log_var.weight: 0.025010887533426285\n",
      "Gradient for encoder.log_var.bias: 0.0011068625608459115\n",
      "Gradient for decoder.decoder.0.weight: 0.012840164825320244\n",
      "Gradient for decoder.decoder.0.bias: 1.0585068932478237e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0006579639157280326\n",
      "Gradient for decoder.decoder.1.bias: 0.0005205977940931916\n",
      "Gradient for decoder.decoder.3.weight: 0.011977802030742168\n",
      "Gradient for decoder.decoder.3.bias: 1.1299539776077339e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.000657202210277319\n",
      "Gradient for decoder.decoder.4.bias: 0.000753224128857255\n",
      "Gradient for decoder.decoder.6.weight: 0.0008130409405566752\n",
      "Gradient for decoder.decoder.6.bias: 5.1866409194190055e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.006987473927438259\n",
      "Gradient for encoder.encoder.0.bias: 9.59493682423096e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.00048699029139243066\n",
      "Gradient for encoder.encoder.1.bias: 0.0004929061979055405\n",
      "Gradient for encoder.encoder.3.weight: 0.010767228901386261\n",
      "Gradient for encoder.encoder.3.bias: 1.0668341904329637e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0033666668459773064\n",
      "Gradient for encoder.encoder.4.bias: 0.002311619697138667\n",
      "Gradient for encoder.mean.weight: 0.04576268419623375\n",
      "Gradient for encoder.mean.bias: 0.0017563368892297149\n",
      "Gradient for encoder.log_var.weight: 0.031047936528921127\n",
      "Gradient for encoder.log_var.bias: 0.001190554117783904\n",
      "Gradient for decoder.decoder.0.weight: 0.01156657375395298\n",
      "Gradient for decoder.decoder.0.bias: 9.53643553014416e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005193838151171803\n",
      "Gradient for decoder.decoder.1.bias: 0.00046245218254625797\n",
      "Gradient for decoder.decoder.3.weight: 0.010552949272096157\n",
      "Gradient for decoder.decoder.3.bias: 7.626226039558759e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0003675800689961761\n",
      "Gradient for decoder.decoder.4.bias: 0.00032595518860034645\n",
      "Gradient for decoder.decoder.6.weight: 0.000699844618793577\n",
      "Gradient for decoder.decoder.6.bias: 3.771538831642829e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.011920817196369171\n",
      "Gradient for encoder.encoder.0.bias: 1.8224572892466817e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0008139413548633456\n",
      "Gradient for encoder.encoder.1.bias: 0.0005593501264229417\n",
      "Gradient for encoder.encoder.3.weight: 0.017415372654795647\n",
      "Gradient for encoder.encoder.3.bias: 1.562870249882664e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0037176604382693768\n",
      "Gradient for encoder.encoder.4.bias: 0.003156971652060747\n",
      "Gradient for encoder.mean.weight: 0.04919329285621643\n",
      "Gradient for encoder.mean.bias: 0.0024551048409193754\n",
      "Gradient for encoder.log_var.weight: 0.02387760579586029\n",
      "Gradient for encoder.log_var.bias: 0.0011965050362050533\n",
      "Gradient for decoder.decoder.0.weight: 0.00901223998516798\n",
      "Gradient for decoder.decoder.0.bias: 7.592578649129322e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.00046023994218558073\n",
      "Gradient for decoder.decoder.1.bias: 0.0003850756329484284\n",
      "Gradient for decoder.decoder.3.weight: 0.008479577489197254\n",
      "Gradient for decoder.decoder.3.bias: 9.396401018380018e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0004061474755872041\n",
      "Gradient for decoder.decoder.4.bias: 0.00046654738252982497\n",
      "Gradient for decoder.decoder.6.weight: 0.0006698689539916813\n",
      "Gradient for decoder.decoder.6.bias: 3.817189281107858e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training VAE Epoch:  61%|██████    | 48/79 [00:00<00:00, 70.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient for encoder.encoder.0.weight: 0.005159784574061632\n",
      "Gradient for encoder.encoder.0.bias: 9.330724561051884e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.0005615950212813914\n",
      "Gradient for encoder.encoder.1.bias: 0.0004073121235705912\n",
      "Gradient for encoder.encoder.3.weight: 0.011903656646609306\n",
      "Gradient for encoder.encoder.3.bias: 1.4528261926827213e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.003914766013622284\n",
      "Gradient for encoder.encoder.4.bias: 0.0036148126237094402\n",
      "Gradient for encoder.mean.weight: 0.05359407141804695\n",
      "Gradient for encoder.mean.bias: 0.0026632705703377724\n",
      "Gradient for encoder.log_var.weight: 0.029770247638225555\n",
      "Gradient for encoder.log_var.bias: 0.001499454490840435\n",
      "Gradient for decoder.decoder.0.weight: 0.010694463737308979\n",
      "Gradient for decoder.decoder.0.bias: 9.056125294115702e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0004936882760375738\n",
      "Gradient for decoder.decoder.1.bias: 0.00042999323341064155\n",
      "Gradient for decoder.decoder.3.weight: 0.010009638033807278\n",
      "Gradient for decoder.decoder.3.bias: 7.814217328760975e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00039834383642300963\n",
      "Gradient for decoder.decoder.4.bias: 0.0003490190429147333\n",
      "Gradient for decoder.decoder.6.weight: 0.0007048464030958712\n",
      "Gradient for decoder.decoder.6.bias: 3.8688056520186365e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.0103443069383502\n",
      "Gradient for encoder.encoder.0.bias: 1.7342885808013797e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0006962274201214314\n",
      "Gradient for encoder.encoder.1.bias: 0.0007113548927009106\n",
      "Gradient for encoder.encoder.3.weight: 0.01470846589654684\n",
      "Gradient for encoder.encoder.3.bias: 1.3045464708483223e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.003416442545130849\n",
      "Gradient for encoder.encoder.4.bias: 0.002717520808801055\n",
      "Gradient for encoder.mean.weight: 0.0451381541788578\n",
      "Gradient for encoder.mean.bias: 0.0019983011297881603\n",
      "Gradient for encoder.log_var.weight: 0.024942703545093536\n",
      "Gradient for encoder.log_var.bias: 0.0010774406837299466\n",
      "Gradient for decoder.decoder.0.weight: 0.009402303956449032\n",
      "Gradient for decoder.decoder.0.bias: 8.30306309818063e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0004728579369839281\n",
      "Gradient for decoder.decoder.1.bias: 0.0003689782170113176\n",
      "Gradient for decoder.decoder.3.weight: 0.008807692676782608\n",
      "Gradient for decoder.decoder.3.bias: 8.735893952671603e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.000534404010977596\n",
      "Gradient for decoder.decoder.4.bias: 0.0006388045731000602\n",
      "Gradient for decoder.decoder.6.weight: 0.0007827128283679485\n",
      "Gradient for decoder.decoder.6.bias: 5.344711462385021e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.015561376698315144\n",
      "Gradient for encoder.encoder.0.bias: 2.0580934526059913e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.001006919308565557\n",
      "Gradient for encoder.encoder.1.bias: 0.0008276141597889364\n",
      "Gradient for encoder.encoder.3.weight: 0.019880875945091248\n",
      "Gradient for encoder.encoder.3.bias: 1.4321152597140951e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0032437965273857117\n",
      "Gradient for encoder.encoder.4.bias: 0.0028106984682381153\n",
      "Gradient for encoder.mean.weight: 0.046394746750593185\n",
      "Gradient for encoder.mean.bias: 0.0018412810750305653\n",
      "Gradient for encoder.log_var.weight: 0.0247943252325058\n",
      "Gradient for encoder.log_var.bias: 0.001024613156914711\n",
      "Gradient for decoder.decoder.0.weight: 0.00828128308057785\n",
      "Gradient for decoder.decoder.0.bias: 7.159283582636178e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0004024350200779736\n",
      "Gradient for decoder.decoder.1.bias: 0.0003333913628011942\n",
      "Gradient for decoder.decoder.3.weight: 0.00781702995300293\n",
      "Gradient for decoder.decoder.3.bias: 5.5108338031795157e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00030102499295026064\n",
      "Gradient for decoder.decoder.4.bias: 0.0002835804771166295\n",
      "Gradient for decoder.decoder.6.weight: 0.0007443758076988161\n",
      "Gradient for decoder.decoder.6.bias: 4.7270048526115716e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training VAE Epoch:  71%|███████   | 56/79 [00:00<00:00, 72.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient for encoder.encoder.0.weight: 0.0066619012504816055\n",
      "Gradient for encoder.encoder.0.bias: 9.966116473747455e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.0004526526026893407\n",
      "Gradient for encoder.encoder.1.bias: 0.00044299126602709293\n",
      "Gradient for encoder.encoder.3.weight: 0.01029767096042633\n",
      "Gradient for encoder.encoder.3.bias: 1.0849906389998054e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0024681449867784977\n",
      "Gradient for encoder.encoder.4.bias: 0.0020654951222240925\n",
      "Gradient for encoder.mean.weight: 0.033705953508615494\n",
      "Gradient for encoder.mean.bias: 0.0017063989071175456\n",
      "Gradient for encoder.log_var.weight: 0.01949252560734749\n",
      "Gradient for encoder.log_var.bias: 0.001098490203730762\n",
      "Gradient for decoder.decoder.0.weight: 0.01180067379027605\n",
      "Gradient for decoder.decoder.0.bias: 1.0101425945707732e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.000560167885851115\n",
      "Gradient for decoder.decoder.1.bias: 0.0004923180676996708\n",
      "Gradient for decoder.decoder.3.weight: 0.01081441156566143\n",
      "Gradient for decoder.decoder.3.bias: 8.8454805979854e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.000495398067869246\n",
      "Gradient for decoder.decoder.4.bias: 0.0005345652461983263\n",
      "Gradient for decoder.decoder.6.weight: 0.0007555032498203218\n",
      "Gradient for decoder.decoder.6.bias: 3.9474496588809416e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.00982376467436552\n",
      "Gradient for encoder.encoder.0.bias: 1.4324999519921278e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.000618311227299273\n",
      "Gradient for encoder.encoder.1.bias: 0.0005267725209705532\n",
      "Gradient for encoder.encoder.3.weight: 0.013777423650026321\n",
      "Gradient for encoder.encoder.3.bias: 1.2505035895671313e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0026877953205257654\n",
      "Gradient for encoder.encoder.4.bias: 0.0024350909516215324\n",
      "Gradient for encoder.mean.weight: 0.0362061932682991\n",
      "Gradient for encoder.mean.bias: 0.0019184163538739085\n",
      "Gradient for encoder.log_var.weight: 0.021356932818889618\n",
      "Gradient for encoder.log_var.bias: 0.0010441896738484502\n",
      "Gradient for decoder.decoder.0.weight: 0.009521863423287868\n",
      "Gradient for decoder.decoder.0.bias: 8.126994910373497e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0004889548872597516\n",
      "Gradient for decoder.decoder.1.bias: 0.0003741311084013432\n",
      "Gradient for decoder.decoder.3.weight: 0.009305163286626339\n",
      "Gradient for decoder.decoder.3.bias: 6.936182878058972e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00036715029273182154\n",
      "Gradient for decoder.decoder.4.bias: 0.0003535495779942721\n",
      "Gradient for decoder.decoder.6.weight: 0.0007064579986035824\n",
      "Gradient for decoder.decoder.6.bias: 3.9983489841688424e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.011001970618963242\n",
      "Gradient for encoder.encoder.0.bias: 1.3232564349818787e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0006230678991414607\n",
      "Gradient for encoder.encoder.1.bias: 0.00048405496636405587\n",
      "Gradient for encoder.encoder.3.weight: 0.013073756359517574\n",
      "Gradient for encoder.encoder.3.bias: 1.241309416366576e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0028585982508957386\n",
      "Gradient for encoder.encoder.4.bias: 0.002626673085615039\n",
      "Gradient for encoder.mean.weight: 0.0376792773604393\n",
      "Gradient for encoder.mean.bias: 0.0021229260601103306\n",
      "Gradient for encoder.log_var.weight: 0.021465232595801353\n",
      "Gradient for encoder.log_var.bias: 0.0011815123725682497\n",
      "Gradient for decoder.decoder.0.weight: 0.010300593450665474\n",
      "Gradient for decoder.decoder.0.bias: 8.571000159607323e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005106325261294842\n",
      "Gradient for decoder.decoder.1.bias: 0.0004031059506814927\n",
      "Gradient for decoder.decoder.3.weight: 0.009583750739693642\n",
      "Gradient for decoder.decoder.3.bias: 8.30387980599312e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00034709315514191985\n",
      "Gradient for decoder.decoder.4.bias: 0.0002975143725052476\n",
      "Gradient for decoder.decoder.6.weight: 0.0006935397977940738\n",
      "Gradient for decoder.decoder.6.bias: 3.3446893212385476e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.008067970164120197\n",
      "Gradient for encoder.encoder.0.bias: 1.386971440475726e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0008454505586996675\n",
      "Gradient for encoder.encoder.1.bias: 0.0008655732963234186\n",
      "Gradient for encoder.encoder.3.weight: 0.018302742391824722\n",
      "Gradient for encoder.encoder.3.bias: 1.8119741818090063e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.004267034120857716\n",
      "Gradient for encoder.encoder.4.bias: 0.004381536040455103\n",
      "Gradient for encoder.mean.weight: 0.057185154408216476\n",
      "Gradient for encoder.mean.bias: 0.003706393763422966\n",
      "Gradient for encoder.log_var.weight: 0.032814811915159225\n",
      "Gradient for encoder.log_var.bias: 0.0022432617843151093\n",
      "Gradient for decoder.decoder.0.weight: 0.010851440951228142\n",
      "Gradient for decoder.decoder.0.bias: 8.322458694420831e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005543187726289034\n",
      "Gradient for decoder.decoder.1.bias: 0.0004380272002890706\n",
      "Gradient for decoder.decoder.3.weight: 0.010379509069025517\n",
      "Gradient for decoder.decoder.3.bias: 7.428571646705961e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00036819372326135635\n",
      "Gradient for decoder.decoder.4.bias: 0.0003108962846454233\n",
      "Gradient for decoder.decoder.6.weight: 0.0007699948619119823\n",
      "Gradient for decoder.decoder.6.bias: 5.197619611863047e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.00826550368219614\n",
      "Gradient for encoder.encoder.0.bias: 1.3857914815673666e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0006147302337922156\n",
      "Gradient for encoder.encoder.1.bias: 0.00044525551493279636\n",
      "Gradient for encoder.encoder.3.weight: 0.012963571585714817\n",
      "Gradient for encoder.encoder.3.bias: 1.1429033414112055e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0026971898041665554\n",
      "Gradient for encoder.encoder.4.bias: 0.0022730091586709023\n",
      "Gradient for encoder.mean.weight: 0.0381493866443634\n",
      "Gradient for encoder.mean.bias: 0.0017447640420868993\n",
      "Gradient for encoder.log_var.weight: 0.020976301282644272\n",
      "Gradient for encoder.log_var.bias: 0.0010878413449972868\n",
      "Gradient for decoder.decoder.0.weight: 0.00922805443406105\n",
      "Gradient for decoder.decoder.0.bias: 7.19635184776024e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0004656131495721638\n",
      "Gradient for decoder.decoder.1.bias: 0.0003543504572007805\n",
      "Gradient for decoder.decoder.3.weight: 0.008822564035654068\n",
      "Gradient for decoder.decoder.3.bias: 7.399530987939329e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0003117039450444281\n",
      "Gradient for decoder.decoder.4.bias: 0.0002835291961673647\n",
      "Gradient for decoder.decoder.6.weight: 0.0006621757638640702\n",
      "Gradient for decoder.decoder.6.bias: 3.171043863403611e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.006254257168620825\n",
      "Gradient for encoder.encoder.0.bias: 8.837280733586805e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.00046469192602671683\n",
      "Gradient for encoder.encoder.1.bias: 0.0005578873679041862\n",
      "Gradient for encoder.encoder.3.weight: 0.010089925490319729\n",
      "Gradient for encoder.encoder.3.bias: 1.2076116495673972e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0030994685366749763\n",
      "Gradient for encoder.encoder.4.bias: 0.002889832481741905\n",
      "Gradient for encoder.mean.weight: 0.04364090412855148\n",
      "Gradient for encoder.mean.bias: 0.0024357896763831377\n",
      "Gradient for encoder.log_var.weight: 0.026637909933924675\n",
      "Gradient for encoder.log_var.bias: 0.0018563331104815006\n",
      "Gradient for decoder.decoder.0.weight: 0.012666099704802036\n",
      "Gradient for decoder.decoder.0.bias: 1.062894078307508e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0005987677723169327\n",
      "Gradient for decoder.decoder.1.bias: 0.0005168175557628274\n",
      "Gradient for decoder.decoder.3.weight: 0.011821878142654896\n",
      "Gradient for decoder.decoder.3.bias: 9.368050779556825e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00042819479131139815\n",
      "Gradient for decoder.decoder.4.bias: 0.0003905058838427067\n",
      "Gradient for decoder.decoder.6.weight: 0.0007872215355746448\n",
      "Gradient for decoder.decoder.6.bias: 4.677478500525467e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.0064204540103673935\n",
      "Gradient for encoder.encoder.0.bias: 1.0589864055110532e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.000665027997456491\n",
      "Gradient for encoder.encoder.1.bias: 0.0004808459198102355\n",
      "Gradient for encoder.encoder.3.weight: 0.014639858156442642\n",
      "Gradient for encoder.encoder.3.bias: 1.4724071961680352e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0037785687018185854\n",
      "Gradient for encoder.encoder.4.bias: 0.003224728163331747\n",
      "Gradient for encoder.mean.weight: 0.05103275552392006\n",
      "Gradient for encoder.mean.bias: 0.0022420205641537905\n",
      "Gradient for encoder.log_var.weight: 0.02622084505856037\n",
      "Gradient for encoder.log_var.bias: 0.0010062229121103883\n",
      "Gradient for decoder.decoder.0.weight: 0.011479456909000874\n",
      "Gradient for decoder.decoder.0.bias: 9.559218000498859e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005225496715866029\n",
      "Gradient for decoder.decoder.1.bias: 0.00045914281508885324\n",
      "Gradient for decoder.decoder.3.weight: 0.010662414133548737\n",
      "Gradient for decoder.decoder.3.bias: 9.084974439410587e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00038550872704945505\n",
      "Gradient for decoder.decoder.4.bias: 0.000355083349859342\n",
      "Gradient for decoder.decoder.6.weight: 0.000708575127646327\n",
      "Gradient for decoder.decoder.6.bias: 4.0783452277537435e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.008616414852440357\n",
      "Gradient for encoder.encoder.0.bias: 1.3542399840416053e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.000847304763738066\n",
      "Gradient for encoder.encoder.1.bias: 0.0006388924666680396\n",
      "Gradient for encoder.encoder.3.weight: 0.017760111019015312\n",
      "Gradient for encoder.encoder.3.bias: 1.5256909624561388e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.003753264434635639\n",
      "Gradient for encoder.encoder.4.bias: 0.0031268715392798185\n",
      "Gradient for encoder.mean.weight: 0.050625938922166824\n",
      "Gradient for encoder.mean.bias: 0.0024585167411714792\n",
      "Gradient for encoder.log_var.weight: 0.023236053064465523\n",
      "Gradient for encoder.log_var.bias: 0.00113581120967865\n",
      "Gradient for decoder.decoder.0.weight: 0.01032323483377695\n",
      "Gradient for decoder.decoder.0.bias: 8.041911581102568e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005088183679617941\n",
      "Gradient for decoder.decoder.1.bias: 0.000410737149650231\n",
      "Gradient for decoder.decoder.3.weight: 0.009742479771375656\n",
      "Gradient for decoder.decoder.3.bias: 9.743957030128314e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0007411738624796271\n",
      "Gradient for decoder.decoder.4.bias: 0.0008552587241865695\n",
      "Gradient for decoder.decoder.6.weight: 0.0009025563485920429\n",
      "Gradient for decoder.decoder.6.bias: 6.819925329182297e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.006384322885423899\n",
      "Gradient for encoder.encoder.0.bias: 8.71619009606972e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.00047012080904096365\n",
      "Gradient for encoder.encoder.1.bias: 0.0005085954908281565\n",
      "Gradient for encoder.encoder.3.weight: 0.010819594375789165\n",
      "Gradient for encoder.encoder.3.bias: 1.0681917850252631e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.002342056715860963\n",
      "Gradient for encoder.encoder.4.bias: 0.0020342194475233555\n",
      "Gradient for encoder.mean.weight: 0.03210920840501785\n",
      "Gradient for encoder.mean.bias: 0.001622000359930098\n",
      "Gradient for encoder.log_var.weight: 0.020472023636102676\n",
      "Gradient for encoder.log_var.bias: 0.000976886018179357\n",
      "Gradient for decoder.decoder.0.weight: 0.011314267292618752\n",
      "Gradient for decoder.decoder.0.bias: 9.504731030007818e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.000557457678951323\n",
      "Gradient for decoder.decoder.1.bias: 0.0004458138719201088\n",
      "Gradient for decoder.decoder.3.weight: 0.010213345289230347\n",
      "Gradient for decoder.decoder.3.bias: 9.553070834389388e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0006408154731616378\n",
      "Gradient for decoder.decoder.4.bias: 0.0007291180663742125\n",
      "Gradient for decoder.decoder.6.weight: 0.0008375264587812126\n",
      "Gradient for decoder.decoder.6.bias: 5.493000571732409e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.0079954219982028\n",
      "Gradient for encoder.encoder.0.bias: 1.4194830207092668e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0007485623937100172\n",
      "Gradient for encoder.encoder.1.bias: 0.0006548105156980455\n",
      "Gradient for encoder.encoder.3.weight: 0.016375325620174408\n",
      "Gradient for encoder.encoder.3.bias: 1.5172955947218014e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.003918281756341457\n",
      "Gradient for encoder.encoder.4.bias: 0.0029885799158364534\n",
      "Gradient for encoder.mean.weight: 0.05058197304606438\n",
      "Gradient for encoder.mean.bias: 0.002382952719926834\n",
      "Gradient for encoder.log_var.weight: 0.029229886829853058\n",
      "Gradient for encoder.log_var.bias: 0.0013276071986183524\n",
      "Gradient for decoder.decoder.0.weight: 0.01035973709076643\n",
      "Gradient for decoder.decoder.0.bias: 8.549840002647358e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005530875059776008\n",
      "Gradient for decoder.decoder.1.bias: 0.000420291384216398\n",
      "Gradient for decoder.decoder.3.weight: 0.010013608261942863\n",
      "Gradient for decoder.decoder.3.bias: 7.871062829289954e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0003946032375097275\n",
      "Gradient for decoder.decoder.4.bias: 0.00042208158993162215\n",
      "Gradient for decoder.decoder.6.weight: 0.000758012814912945\n",
      "Gradient for decoder.decoder.6.bias: 4.8208661610260606e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.007658896967768669\n",
      "Gradient for encoder.encoder.0.bias: 1.21512782474964e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0006235620239749551\n",
      "Gradient for encoder.encoder.1.bias: 0.00047691218787804246\n",
      "Gradient for encoder.encoder.3.weight: 0.013462211936712265\n",
      "Gradient for encoder.encoder.3.bias: 1.168179164512395e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.002817537635564804\n",
      "Gradient for encoder.encoder.4.bias: 0.002405924256891012\n",
      "Gradient for encoder.mean.weight: 0.03960268199443817\n",
      "Gradient for encoder.mean.bias: 0.0017706711078062654\n",
      "Gradient for encoder.log_var.weight: 0.023683426901698112\n",
      "Gradient for encoder.log_var.bias: 0.0010822976473718882\n",
      "Gradient for decoder.decoder.0.weight: 0.01050725020468235\n",
      "Gradient for decoder.decoder.0.bias: 8.963217668078727e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.000521133653819561\n",
      "Gradient for decoder.decoder.1.bias: 0.00042750430293381214\n",
      "Gradient for decoder.decoder.3.weight: 0.009854981675744057\n",
      "Gradient for decoder.decoder.3.bias: 8.039267168635789e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00038656670949421823\n",
      "Gradient for decoder.decoder.4.bias: 0.0003632022126112133\n",
      "Gradient for decoder.decoder.6.weight: 0.0007110515725798905\n",
      "Gradient for decoder.decoder.6.bias: 4.3077292502857745e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.009033801034092903\n",
      "Gradient for encoder.encoder.0.bias: 1.4450545794686409e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.000665251980535686\n",
      "Gradient for encoder.encoder.1.bias: 0.0004976741038262844\n",
      "Gradient for encoder.encoder.3.weight: 0.014021693728864193\n",
      "Gradient for encoder.encoder.3.bias: 1.30007393739362e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.002700584940612316\n",
      "Gradient for encoder.encoder.4.bias: 0.0023581553250551224\n",
      "Gradient for encoder.mean.weight: 0.03835403546690941\n",
      "Gradient for encoder.mean.bias: 0.0019247580785304308\n",
      "Gradient for encoder.log_var.weight: 0.020748719573020935\n",
      "Gradient for encoder.log_var.bias: 0.0012433248339220881\n",
      "Gradient for decoder.decoder.0.weight: 0.0089753782376647\n",
      "Gradient for decoder.decoder.0.bias: 7.75446720724382e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.00042648299131542444\n",
      "Gradient for decoder.decoder.1.bias: 0.0003270635788794607\n",
      "Gradient for decoder.decoder.3.weight: 0.008482682518661022\n",
      "Gradient for decoder.decoder.3.bias: 6.966881932468638e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00033638166496530175\n",
      "Gradient for decoder.decoder.4.bias: 0.00029523711418733\n",
      "Gradient for decoder.decoder.6.weight: 0.0007883448852226138\n",
      "Gradient for decoder.decoder.6.bias: 5.208771108300425e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.007466946728527546\n",
      "Gradient for encoder.encoder.0.bias: 1.2513147636117328e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0005192371900193393\n",
      "Gradient for encoder.encoder.1.bias: 0.0005094829248264432\n",
      "Gradient for encoder.encoder.3.weight: 0.011541521176695824\n",
      "Gradient for encoder.encoder.3.bias: 1.1451464776435216e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.00250059156678617\n",
      "Gradient for encoder.encoder.4.bias: 0.0018621442141011357\n",
      "Gradient for encoder.mean.weight: 0.03472702577710152\n",
      "Gradient for encoder.mean.bias: 0.0014994223602116108\n",
      "Gradient for encoder.log_var.weight: 0.019009007140994072\n",
      "Gradient for encoder.log_var.bias: 0.0008568128105252981\n",
      "Gradient for decoder.decoder.0.weight: 0.009639312513172626\n",
      "Gradient for decoder.decoder.0.bias: 7.854962513764718e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0004928598646074533\n",
      "Gradient for decoder.decoder.1.bias: 0.00038504385156556964\n",
      "Gradient for decoder.decoder.3.weight: 0.008870719000697136\n",
      "Gradient for decoder.decoder.3.bias: 7.843708321741971e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.000511778227519244\n",
      "Gradient for decoder.decoder.4.bias: 0.0005941997515037656\n",
      "Gradient for decoder.decoder.6.weight: 0.0008861302048899233\n",
      "Gradient for decoder.decoder.6.bias: 7.286678737727925e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training VAE Epoch:  81%|████████  | 64/79 [00:01<00:00, 74.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient for encoder.encoder.0.weight: 0.0091063492000103\n",
      "Gradient for encoder.encoder.0.bias: 1.329498924146355e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.000519291905220598\n",
      "Gradient for encoder.encoder.1.bias: 0.0004696609976235777\n",
      "Gradient for encoder.encoder.3.weight: 0.01135678868740797\n",
      "Gradient for encoder.encoder.3.bias: 1.1196150950798511e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0024295540060847998\n",
      "Gradient for encoder.encoder.4.bias: 0.001894385670311749\n",
      "Gradient for encoder.mean.weight: 0.031610310077667236\n",
      "Gradient for encoder.mean.bias: 0.001615035580471158\n",
      "Gradient for encoder.log_var.weight: 0.01930929720401764\n",
      "Gradient for encoder.log_var.bias: 0.0010573950130492449\n",
      "Gradient for decoder.decoder.0.weight: 0.009622606448829174\n",
      "Gradient for decoder.decoder.0.bias: 8.194384754078854e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.000492717488668859\n",
      "Gradient for decoder.decoder.1.bias: 0.00039202062180265784\n",
      "Gradient for decoder.decoder.3.weight: 0.009301351383328438\n",
      "Gradient for decoder.decoder.3.bias: 7.902388465819143e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0003476911224424839\n",
      "Gradient for decoder.decoder.4.bias: 0.0002901082916650921\n",
      "Gradient for decoder.decoder.6.weight: 0.0007164342096075416\n",
      "Gradient for decoder.decoder.6.bias: 3.7729652831330895e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.00816420093178749\n",
      "Gradient for encoder.encoder.0.bias: 1.2416677061533044e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0005626501515507698\n",
      "Gradient for encoder.encoder.1.bias: 0.0004265343304723501\n",
      "Gradient for encoder.encoder.3.weight: 0.0118845971301198\n",
      "Gradient for encoder.encoder.3.bias: 1.2732194465403524e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0024868969339877367\n",
      "Gradient for encoder.encoder.4.bias: 0.00267686671577394\n",
      "Gradient for encoder.mean.weight: 0.03366566449403763\n",
      "Gradient for encoder.mean.bias: 0.0021215248852968216\n",
      "Gradient for encoder.log_var.weight: 0.021262533962726593\n",
      "Gradient for encoder.log_var.bias: 0.0014713401906192303\n",
      "Gradient for decoder.decoder.0.weight: 0.010608123615384102\n",
      "Gradient for decoder.decoder.0.bias: 8.949688906634279e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005158409476280212\n",
      "Gradient for decoder.decoder.1.bias: 0.0004359688318800181\n",
      "Gradient for decoder.decoder.3.weight: 0.0096902996301651\n",
      "Gradient for decoder.decoder.3.bias: 7.418362452105143e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0003690243174787611\n",
      "Gradient for decoder.decoder.4.bias: 0.0003041499003302306\n",
      "Gradient for decoder.decoder.6.weight: 0.0007242225110530853\n",
      "Gradient for decoder.decoder.6.bias: 4.145805723965168e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.007309832144528627\n",
      "Gradient for encoder.encoder.0.bias: 1.0249487022995218e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.00048699654871597886\n",
      "Gradient for encoder.encoder.1.bias: 0.00036464218283072114\n",
      "Gradient for encoder.encoder.3.weight: 0.010244923643767834\n",
      "Gradient for encoder.encoder.3.bias: 1.0508821590704542e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.002882407745346427\n",
      "Gradient for encoder.encoder.4.bias: 0.0023697498254477978\n",
      "Gradient for encoder.mean.weight: 0.038360562175512314\n",
      "Gradient for encoder.mean.bias: 0.0019572121091187\n",
      "Gradient for encoder.log_var.weight: 0.021126220002770424\n",
      "Gradient for encoder.log_var.bias: 0.0011232777033001184\n",
      "Gradient for decoder.decoder.0.weight: 0.010869543068110943\n",
      "Gradient for decoder.decoder.0.bias: 8.882878460569898e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005381519440561533\n",
      "Gradient for decoder.decoder.1.bias: 0.00044568863813765347\n",
      "Gradient for decoder.decoder.3.weight: 0.01010387297719717\n",
      "Gradient for decoder.decoder.3.bias: 8.497678255503516e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0004646660527214408\n",
      "Gradient for decoder.decoder.4.bias: 0.0004592585319187492\n",
      "Gradient for decoder.decoder.6.weight: 0.0007580694509670138\n",
      "Gradient for decoder.decoder.6.bias: 4.0951559640234336e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training VAE Epoch:  91%|█████████ | 72/79 [00:01<00:00, 75.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient for encoder.encoder.0.weight: 0.0044095576740801334\n",
      "Gradient for encoder.encoder.0.bias: 7.755055278502176e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.0006237427587620914\n",
      "Gradient for encoder.encoder.1.bias: 0.0006587668904103339\n",
      "Gradient for encoder.encoder.3.weight: 0.013812507502734661\n",
      "Gradient for encoder.encoder.3.bias: 1.213638772812331e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.003870544256642461\n",
      "Gradient for encoder.encoder.4.bias: 0.0028356281109154224\n",
      "Gradient for encoder.mean.weight: 0.05216558277606964\n",
      "Gradient for encoder.mean.bias: 0.002216208027675748\n",
      "Gradient for encoder.log_var.weight: 0.03415791317820549\n",
      "Gradient for encoder.log_var.bias: 0.001465984620153904\n",
      "Gradient for decoder.decoder.0.weight: 0.014516293071210384\n",
      "Gradient for decoder.decoder.0.bias: 1.345557137932829e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0006977749872021377\n",
      "Gradient for decoder.decoder.1.bias: 0.0005676162545569241\n",
      "Gradient for decoder.decoder.3.weight: 0.013228699564933777\n",
      "Gradient for decoder.decoder.3.bias: 1.0219687596180194e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0005744336522184312\n",
      "Gradient for decoder.decoder.4.bias: 0.0005222635809332132\n",
      "Gradient for decoder.decoder.6.weight: 0.0007445528171956539\n",
      "Gradient for decoder.decoder.6.bias: 3.536816802807152e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.007352931424975395\n",
      "Gradient for encoder.encoder.0.bias: 1.129363356305868e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.00045888836029917\n",
      "Gradient for encoder.encoder.1.bias: 0.00042736457544378936\n",
      "Gradient for encoder.encoder.3.weight: 0.009845489636063576\n",
      "Gradient for encoder.encoder.3.bias: 1.1448744036135494e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0023398096673190594\n",
      "Gradient for encoder.encoder.4.bias: 0.0019591113086789846\n",
      "Gradient for encoder.mean.weight: 0.032452572137117386\n",
      "Gradient for encoder.mean.bias: 0.0015160671900957823\n",
      "Gradient for encoder.log_var.weight: 0.019060980528593063\n",
      "Gradient for encoder.log_var.bias: 0.0010936190374195576\n",
      "Gradient for decoder.decoder.0.weight: 0.010940560139715672\n",
      "Gradient for decoder.decoder.0.bias: 8.925900990552904e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005495364894159138\n",
      "Gradient for decoder.decoder.1.bias: 0.00048306630924344063\n",
      "Gradient for decoder.decoder.3.weight: 0.010409933514893055\n",
      "Gradient for decoder.decoder.3.bias: 9.007678630768012e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0003972790436819196\n",
      "Gradient for decoder.decoder.4.bias: 0.0003821880673058331\n",
      "Gradient for decoder.decoder.6.weight: 0.0006678829086013138\n",
      "Gradient for decoder.decoder.6.bias: 3.220617145416327e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.00939016044139862\n",
      "Gradient for encoder.encoder.0.bias: 1.3989098074373985e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0007009226828813553\n",
      "Gradient for encoder.encoder.1.bias: 0.0006723662372678518\n",
      "Gradient for encoder.encoder.3.weight: 0.01532641053199768\n",
      "Gradient for encoder.encoder.3.bias: 1.3954257194193076e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.003005857113748789\n",
      "Gradient for encoder.encoder.4.bias: 0.0027237567119300365\n",
      "Gradient for encoder.mean.weight: 0.04381522536277771\n",
      "Gradient for encoder.mean.bias: 0.002101405756548047\n",
      "Gradient for encoder.log_var.weight: 0.023180237039923668\n",
      "Gradient for encoder.log_var.bias: 0.0014059864915907383\n",
      "Gradient for decoder.decoder.0.weight: 0.010209106840193272\n",
      "Gradient for decoder.decoder.0.bias: 9.02601882124543e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0004925697576254606\n",
      "Gradient for decoder.decoder.1.bias: 0.0004330973606556654\n",
      "Gradient for decoder.decoder.3.weight: 0.009639355354011059\n",
      "Gradient for decoder.decoder.3.bias: 8.33392937993338e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00037673726910725236\n",
      "Gradient for decoder.decoder.4.bias: 0.00033507435000501573\n",
      "Gradient for decoder.decoder.6.weight: 0.0007060800562612712\n",
      "Gradient for decoder.decoder.6.bias: 3.658938658190891e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.004476369358599186\n",
      "Gradient for encoder.encoder.0.bias: 7.34749327352402e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.0004178421513643116\n",
      "Gradient for encoder.encoder.1.bias: 0.0004929304705001414\n",
      "Gradient for encoder.encoder.3.weight: 0.008835694752633572\n",
      "Gradient for encoder.encoder.3.bias: 1.0576720055333055e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0030827540904283524\n",
      "Gradient for encoder.encoder.4.bias: 0.0021294441539794207\n",
      "Gradient for encoder.mean.weight: 0.042953845113515854\n",
      "Gradient for encoder.mean.bias: 0.0016219409881159663\n",
      "Gradient for encoder.log_var.weight: 0.02418394759297371\n",
      "Gradient for encoder.log_var.bias: 0.0010285330936312675\n",
      "Gradient for decoder.decoder.0.weight: 0.013684984296560287\n",
      "Gradient for decoder.decoder.0.bias: 1.1471942840124427e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0007264782907441258\n",
      "Gradient for decoder.decoder.1.bias: 0.000597652920987457\n",
      "Gradient for decoder.decoder.3.weight: 0.012908929958939552\n",
      "Gradient for decoder.decoder.3.bias: 9.782697568683218e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0004899606574326754\n",
      "Gradient for decoder.decoder.4.bias: 0.00040533929131925106\n",
      "Gradient for decoder.decoder.6.weight: 0.000716749404091388\n",
      "Gradient for decoder.decoder.6.bias: 3.597716931835748e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.007897017523646355\n",
      "Gradient for encoder.encoder.0.bias: 1.0818297646597586e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0005184881738387048\n",
      "Gradient for encoder.encoder.1.bias: 0.000474405795102939\n",
      "Gradient for encoder.encoder.3.weight: 0.010192976333200932\n",
      "Gradient for encoder.encoder.3.bias: 1.0578980053077558e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0023397866170853376\n",
      "Gradient for encoder.encoder.4.bias: 0.0019241494592279196\n",
      "Gradient for encoder.mean.weight: 0.03437812253832817\n",
      "Gradient for encoder.mean.bias: 0.0015833786455914378\n",
      "Gradient for encoder.log_var.weight: 0.018243886530399323\n",
      "Gradient for encoder.log_var.bias: 0.0009296071948483586\n",
      "Gradient for decoder.decoder.0.weight: 0.01189588475972414\n",
      "Gradient for decoder.decoder.0.bias: 9.731520450584341e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005806312547065318\n",
      "Gradient for decoder.decoder.1.bias: 0.0005366717232391238\n",
      "Gradient for decoder.decoder.3.weight: 0.011104093864560127\n",
      "Gradient for decoder.decoder.3.bias: 8.224724373784298e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00040113209979608655\n",
      "Gradient for decoder.decoder.4.bias: 0.0003488507936708629\n",
      "Gradient for decoder.decoder.6.weight: 0.0007252288633026183\n",
      "Gradient for decoder.decoder.6.bias: 4.0009133954299614e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.009205852635204792\n",
      "Gradient for encoder.encoder.0.bias: 1.76872856638699e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0007512353477068245\n",
      "Gradient for encoder.encoder.1.bias: 0.0007856861921027303\n",
      "Gradient for encoder.encoder.3.weight: 0.01648731157183647\n",
      "Gradient for encoder.encoder.3.bias: 1.6027698612752772e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0036182389594614506\n",
      "Gradient for encoder.encoder.4.bias: 0.0034126576501876116\n",
      "Gradient for encoder.mean.weight: 0.0513630211353302\n",
      "Gradient for encoder.mean.bias: 0.0025120789650827646\n",
      "Gradient for encoder.log_var.weight: 0.02801356464624405\n",
      "Gradient for encoder.log_var.bias: 0.001600062707439065\n",
      "Gradient for decoder.decoder.0.weight: 0.009235787205398083\n",
      "Gradient for decoder.decoder.0.bias: 7.975747146060641e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.00046579769696108997\n",
      "Gradient for decoder.decoder.1.bias: 0.00038324526394717395\n",
      "Gradient for decoder.decoder.3.weight: 0.008737941272556782\n",
      "Gradient for decoder.decoder.3.bias: 7.561817838563911e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0004185549623798579\n",
      "Gradient for decoder.decoder.4.bias: 0.00044725139741785824\n",
      "Gradient for decoder.decoder.6.weight: 0.0007558931247331202\n",
      "Gradient for decoder.decoder.6.bias: 5.4009226005291566e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.008143567480146885\n",
      "Gradient for encoder.encoder.0.bias: 1.2190908872666828e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0006542647024616599\n",
      "Gradient for encoder.encoder.1.bias: 0.0006353987264446914\n",
      "Gradient for encoder.encoder.3.weight: 0.013976202346384525\n",
      "Gradient for encoder.encoder.3.bias: 1.3347140059849494e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.003390870988368988\n",
      "Gradient for encoder.encoder.4.bias: 0.002784128300845623\n",
      "Gradient for encoder.mean.weight: 0.04481562227010727\n",
      "Gradient for encoder.mean.bias: 0.002064243657514453\n",
      "Gradient for encoder.log_var.weight: 0.024789860472083092\n",
      "Gradient for encoder.log_var.bias: 0.0012467154301702976\n",
      "Gradient for decoder.decoder.0.weight: 0.010942469350993633\n",
      "Gradient for decoder.decoder.0.bias: 8.101574966445924e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005300823249854147\n",
      "Gradient for decoder.decoder.1.bias: 0.00041920572402887046\n",
      "Gradient for decoder.decoder.3.weight: 0.009903273545205593\n",
      "Gradient for decoder.decoder.3.bias: 7.320268002874997e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00035687454510480165\n",
      "Gradient for decoder.decoder.4.bias: 0.000333138246787712\n",
      "Gradient for decoder.decoder.6.weight: 0.0007788861403241754\n",
      "Gradient for decoder.decoder.6.bias: 5.0063325033988804e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.005431849975138903\n",
      "Gradient for encoder.encoder.0.bias: 8.27014672022397e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.0004972466849721968\n",
      "Gradient for encoder.encoder.1.bias: 0.0003978473541792482\n",
      "Gradient for encoder.encoder.3.weight: 0.010508664883673191\n",
      "Gradient for encoder.encoder.3.bias: 1.1164499186255838e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0031226195860654116\n",
      "Gradient for encoder.encoder.4.bias: 0.002239952562376857\n",
      "Gradient for encoder.mean.weight: 0.04443247616291046\n",
      "Gradient for encoder.mean.bias: 0.0015684333629906178\n",
      "Gradient for encoder.log_var.weight: 0.0263912845402956\n",
      "Gradient for encoder.log_var.bias: 0.0012557482114061713\n",
      "Gradient for decoder.decoder.0.weight: 0.011627530679106712\n",
      "Gradient for decoder.decoder.0.bias: 1.0622269036586474e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0005726534873247147\n",
      "Gradient for decoder.decoder.1.bias: 0.0004876604361925274\n",
      "Gradient for decoder.decoder.3.weight: 0.011135567910969257\n",
      "Gradient for decoder.decoder.3.bias: 1.0365490410446654e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0005179737927392125\n",
      "Gradient for decoder.decoder.4.bias: 0.0005276723532006145\n",
      "Gradient for decoder.decoder.6.weight: 0.0007973082829266787\n",
      "Gradient for decoder.decoder.6.bias: 4.8850826715352014e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.007470129057765007\n",
      "Gradient for encoder.encoder.0.bias: 1.3146092721350033e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0005045881844125688\n",
      "Gradient for encoder.encoder.1.bias: 0.0005262874765321612\n",
      "Gradient for encoder.encoder.3.weight: 0.010950109921395779\n",
      "Gradient for encoder.encoder.3.bias: 1.0286874824183556e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0025003175251185894\n",
      "Gradient for encoder.encoder.4.bias: 0.0016793074319139123\n",
      "Gradient for encoder.mean.weight: 0.03908915817737579\n",
      "Gradient for encoder.mean.bias: 0.001201279810629785\n",
      "Gradient for encoder.log_var.weight: 0.020952126011252403\n",
      "Gradient for encoder.log_var.bias: 0.0008955675875768065\n",
      "Gradient for decoder.decoder.0.weight: 0.009969674982130527\n",
      "Gradient for decoder.decoder.0.bias: 8.335377527091126e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.00047824220382608473\n",
      "Gradient for decoder.decoder.1.bias: 0.0004036673635710031\n",
      "Gradient for decoder.decoder.3.weight: 0.009160660207271576\n",
      "Gradient for decoder.decoder.3.bias: 7.806439522584085e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00046635017497465014\n",
      "Gradient for decoder.decoder.4.bias: 0.0005191111704334617\n",
      "Gradient for decoder.decoder.6.weight: 0.0008229865343309939\n",
      "Gradient for decoder.decoder.6.bias: 6.495345587609336e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.0074881636537611485\n",
      "Gradient for encoder.encoder.0.bias: 1.2165338181269192e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0006123167695477605\n",
      "Gradient for encoder.encoder.1.bias: 0.0005545429303310812\n",
      "Gradient for encoder.encoder.3.weight: 0.013354706577956676\n",
      "Gradient for encoder.encoder.3.bias: 1.169019187008402e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.002998223528265953\n",
      "Gradient for encoder.encoder.4.bias: 0.002266853116452694\n",
      "Gradient for encoder.mean.weight: 0.0442359521985054\n",
      "Gradient for encoder.mean.bias: 0.0015046776970848441\n",
      "Gradient for encoder.log_var.weight: 0.022849632427096367\n",
      "Gradient for encoder.log_var.bias: 0.000962157966569066\n",
      "Gradient for decoder.decoder.0.weight: 0.010325090028345585\n",
      "Gradient for decoder.decoder.0.bias: 8.350884567187578e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005246248911134899\n",
      "Gradient for decoder.decoder.1.bias: 0.00041215610690414906\n",
      "Gradient for decoder.decoder.3.weight: 0.009901195764541626\n",
      "Gradient for decoder.decoder.3.bias: 7.143243635487906e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00036500318674370646\n",
      "Gradient for decoder.decoder.4.bias: 0.00030080805299803615\n",
      "Gradient for decoder.decoder.6.weight: 0.0006775635993108153\n",
      "Gradient for decoder.decoder.6.bias: 3.415156606934033e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.006710789632052183\n",
      "Gradient for encoder.encoder.0.bias: 1.1589952088331135e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.00047360180178657174\n",
      "Gradient for encoder.encoder.1.bias: 0.0004647229507099837\n",
      "Gradient for encoder.encoder.3.weight: 0.010530310682952404\n",
      "Gradient for encoder.encoder.3.bias: 1.1058486765191944e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0024910145439207554\n",
      "Gradient for encoder.encoder.4.bias: 0.00208439608104527\n",
      "Gradient for encoder.mean.weight: 0.034139234572649\n",
      "Gradient for encoder.mean.bias: 0.0015032354276627302\n",
      "Gradient for encoder.log_var.weight: 0.019344599917531013\n",
      "Gradient for encoder.log_var.bias: 0.0010028226533904672\n",
      "Gradient for decoder.decoder.0.weight: 0.009307609871029854\n",
      "Gradient for decoder.decoder.0.bias: 8.356887404303848e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.00047487756819464266\n",
      "Gradient for decoder.decoder.1.bias: 0.00039589853258803487\n",
      "Gradient for decoder.decoder.3.weight: 0.008717707358300686\n",
      "Gradient for decoder.decoder.3.bias: 8.223292186082531e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0005508516333065927\n",
      "Gradient for decoder.decoder.4.bias: 0.0006298650405369699\n",
      "Gradient for decoder.decoder.6.weight: 0.0007275090320035815\n",
      "Gradient for decoder.decoder.6.bias: 4.925136818201281e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.006544189993292093\n",
      "Gradient for encoder.encoder.0.bias: 1.1201407856820111e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0005386227276176214\n",
      "Gradient for encoder.encoder.1.bias: 0.00048347064875997603\n",
      "Gradient for encoder.encoder.3.weight: 0.011276241391897202\n",
      "Gradient for encoder.encoder.3.bias: 1.2183941355825567e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.003266367595642805\n",
      "Gradient for encoder.encoder.4.bias: 0.0026638286653906107\n",
      "Gradient for encoder.mean.weight: 0.04326809570193291\n",
      "Gradient for encoder.mean.bias: 0.0018483558669686317\n",
      "Gradient for encoder.log_var.weight: 0.02467770129442215\n",
      "Gradient for encoder.log_var.bias: 0.001204628380946815\n",
      "Gradient for decoder.decoder.0.weight: 0.010343164205551147\n",
      "Gradient for decoder.decoder.0.bias: 8.824508485050231e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0004926153924316168\n",
      "Gradient for decoder.decoder.1.bias: 0.00044168339809402823\n",
      "Gradient for decoder.decoder.3.weight: 0.009579429402947426\n",
      "Gradient for decoder.decoder.3.bias: 8.043004456892433e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0003835097304545343\n",
      "Gradient for decoder.decoder.4.bias: 0.0003790980263147503\n",
      "Gradient for decoder.decoder.6.weight: 0.0007566678686998785\n",
      "Gradient for decoder.decoder.6.bias: 5.2460010920185596e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.004459561314433813\n",
      "Gradient for encoder.encoder.0.bias: 7.0075438507455345e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.00045879592653363943\n",
      "Gradient for encoder.encoder.1.bias: 0.00040861303568817675\n",
      "Gradient for encoder.encoder.3.weight: 0.010326897725462914\n",
      "Gradient for encoder.encoder.3.bias: 1.0849733611539847e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0032121865078806877\n",
      "Gradient for encoder.encoder.4.bias: 0.0020481515675783157\n",
      "Gradient for encoder.mean.weight: 0.04135940596461296\n",
      "Gradient for encoder.mean.bias: 0.0014363115187734365\n",
      "Gradient for encoder.log_var.weight: 0.026522090658545494\n",
      "Gradient for encoder.log_var.bias: 0.0010131902527064085\n",
      "Gradient for decoder.decoder.0.weight: 0.013216300867497921\n",
      "Gradient for decoder.decoder.0.bias: 1.184939785181527e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0006343208369798958\n",
      "Gradient for decoder.decoder.1.bias: 0.0005794618045911193\n",
      "Gradient for decoder.decoder.3.weight: 0.012965897098183632\n",
      "Gradient for decoder.decoder.3.bias: 1.081393724566837e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0006027870113030076\n",
      "Gradient for decoder.decoder.4.bias: 0.0005588140920735896\n",
      "Gradient for decoder.decoder.6.weight: 0.000844135764054954\n",
      "Gradient for decoder.decoder.6.bias: 4.972756505594589e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient for encoder.encoder.0.weight: 0.009795526042580605\n",
      "Gradient for encoder.encoder.0.bias: 1.3305875498637043e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0006617340841330588\n",
      "Gradient for encoder.encoder.1.bias: 0.000899746548384428\n",
      "Gradient for encoder.encoder.3.weight: 0.014098819345235825\n",
      "Gradient for encoder.encoder.3.bias: 1.7749596237237597e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.004431514069437981\n",
      "Gradient for encoder.encoder.4.bias: 0.0040744333527982235\n",
      "Gradient for encoder.mean.weight: 0.06462693959474564\n",
      "Gradient for encoder.mean.bias: 0.0030356955248862505\n",
      "Gradient for encoder.log_var.weight: 0.03464866429567337\n",
      "Gradient for encoder.log_var.bias: 0.0021954397670924664\n",
      "Gradient for decoder.decoder.0.weight: 0.03862630948424339\n",
      "Gradient for decoder.decoder.0.bias: 2.409992760910029e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0015318741789087653\n",
      "Gradient for decoder.decoder.1.bias: 0.0013939616037532687\n",
      "Gradient for decoder.decoder.3.weight: 0.03386459872126579\n",
      "Gradient for decoder.decoder.3.bias: 2.3136807747459187e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.001107880612835288\n",
      "Gradient for decoder.decoder.4.bias: 0.0009221232030540705\n",
      "Gradient for decoder.decoder.6.weight: 0.001871226355433464\n",
      "Gradient for decoder.decoder.6.bias: 8.986847387859598e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/3, Train Loss: 0.0713, Val Loss: 0.2813\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training VAE Epoch:   1%|▏         | 1/79 [00:00<00:14,  5.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient for encoder.encoder.0.weight: 0.007687240839004517\n",
      "Gradient for encoder.encoder.0.bias: 1.054216783313855e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0004976709606125951\n",
      "Gradient for encoder.encoder.1.bias: 0.0004577190848067403\n",
      "Gradient for encoder.encoder.3.weight: 0.010712161660194397\n",
      "Gradient for encoder.encoder.3.bias: 1.1585988418660875e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.002931870287284255\n",
      "Gradient for encoder.encoder.4.bias: 0.002405475126579404\n",
      "Gradient for encoder.mean.weight: 0.04234331101179123\n",
      "Gradient for encoder.mean.bias: 0.0017656338168308139\n",
      "Gradient for encoder.log_var.weight: 0.021700717508792877\n",
      "Gradient for encoder.log_var.bias: 0.0011488668387755752\n",
      "Gradient for decoder.decoder.0.weight: 0.011000758968293667\n",
      "Gradient for decoder.decoder.0.bias: 9.229159103618656e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005370262661017478\n",
      "Gradient for decoder.decoder.1.bias: 0.00045059609692543745\n",
      "Gradient for decoder.decoder.3.weight: 0.010313980281352997\n",
      "Gradient for decoder.decoder.3.bias: 7.854553119024388e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00042471082997508347\n",
      "Gradient for decoder.decoder.4.bias: 0.00041379962931387126\n",
      "Gradient for decoder.decoder.6.weight: 0.0006895815022289753\n",
      "Gradient for decoder.decoder.6.bias: 3.4076583688147366e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.010775060392916203\n",
      "Gradient for encoder.encoder.0.bias: 1.5125437360929972e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0007079920032992959\n",
      "Gradient for encoder.encoder.1.bias: 0.0007696294342167675\n",
      "Gradient for encoder.encoder.3.weight: 0.015905654057860374\n",
      "Gradient for encoder.encoder.3.bias: 1.5968400213228762e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.004074099939316511\n",
      "Gradient for encoder.encoder.4.bias: 0.0036415131762623787\n",
      "Gradient for encoder.mean.weight: 0.056312818080186844\n",
      "Gradient for encoder.mean.bias: 0.002659616293385625\n",
      "Gradient for encoder.log_var.weight: 0.030017642304301262\n",
      "Gradient for encoder.log_var.bias: 0.0015893079107627273\n",
      "Gradient for decoder.decoder.0.weight: 0.009540279395878315\n",
      "Gradient for decoder.decoder.0.bias: 7.682261077279762e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.00044011775753460824\n",
      "Gradient for decoder.decoder.1.bias: 0.0004022019566036761\n",
      "Gradient for decoder.decoder.3.weight: 0.008893552236258984\n",
      "Gradient for decoder.decoder.3.bias: 6.710894340233864e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.000319043843774125\n",
      "Gradient for decoder.decoder.4.bias: 0.0002935780503321439\n",
      "Gradient for decoder.decoder.6.weight: 0.0007425855146721005\n",
      "Gradient for decoder.decoder.6.bias: 4.55426488770172e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training VAE Epoch:  11%|█▏        | 9/79 [00:00<00:01, 36.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient for encoder.encoder.0.weight: 0.006408574525266886\n",
      "Gradient for encoder.encoder.0.bias: 1.070936655328536e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.00042545507312752306\n",
      "Gradient for encoder.encoder.1.bias: 0.0005097000976093113\n",
      "Gradient for encoder.encoder.3.weight: 0.009723115712404251\n",
      "Gradient for encoder.encoder.3.bias: 1.1233145663647193e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.00309140607714653\n",
      "Gradient for encoder.encoder.4.bias: 0.0023376375902444124\n",
      "Gradient for encoder.mean.weight: 0.04311252385377884\n",
      "Gradient for encoder.mean.bias: 0.0017205631593242288\n",
      "Gradient for encoder.log_var.weight: 0.024057716131210327\n",
      "Gradient for encoder.log_var.bias: 0.00112144963350147\n",
      "Gradient for decoder.decoder.0.weight: 0.011842183768749237\n",
      "Gradient for decoder.decoder.0.bias: 1.1196462507134797e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0005721525521948934\n",
      "Gradient for decoder.decoder.1.bias: 0.0005080616101622581\n",
      "Gradient for decoder.decoder.3.weight: 0.011372367851436138\n",
      "Gradient for decoder.decoder.3.bias: 9.732556427444194e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00042131953523494303\n",
      "Gradient for decoder.decoder.4.bias: 0.00044578700908459723\n",
      "Gradient for decoder.decoder.6.weight: 0.0006911659729667008\n",
      "Gradient for decoder.decoder.6.bias: 3.729990203282796e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.004835246130824089\n",
      "Gradient for encoder.encoder.0.bias: 7.180223429714694e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.0003694563638418913\n",
      "Gradient for encoder.encoder.1.bias: 0.00042033212957903743\n",
      "Gradient for encoder.encoder.3.weight: 0.008079029619693756\n",
      "Gradient for encoder.encoder.3.bias: 9.431294634154597e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.002672094851732254\n",
      "Gradient for encoder.encoder.4.bias: 0.0019300434505566955\n",
      "Gradient for encoder.mean.weight: 0.039469074457883835\n",
      "Gradient for encoder.mean.bias: 0.0014265293721109629\n",
      "Gradient for encoder.log_var.weight: 0.02356739155948162\n",
      "Gradient for encoder.log_var.bias: 0.0009304984705522656\n",
      "Gradient for decoder.decoder.0.weight: 0.012382040731608868\n",
      "Gradient for decoder.decoder.0.bias: 1.0309710030131924e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0006414579693228006\n",
      "Gradient for decoder.decoder.1.bias: 0.0005195452249608934\n",
      "Gradient for decoder.decoder.3.weight: 0.012184470891952515\n",
      "Gradient for decoder.decoder.3.bias: 9.529534106267334e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00045350388973020017\n",
      "Gradient for decoder.decoder.4.bias: 0.00041205508750863373\n",
      "Gradient for decoder.decoder.6.weight: 0.000771549588534981\n",
      "Gradient for decoder.decoder.6.bias: 4.5722958020633087e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.01210417877882719\n",
      "Gradient for encoder.encoder.0.bias: 1.640393203217183e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0007427914533764124\n",
      "Gradient for encoder.encoder.1.bias: 0.0005439688102342188\n",
      "Gradient for encoder.encoder.3.weight: 0.015805071219801903\n",
      "Gradient for encoder.encoder.3.bias: 1.546570649324508e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0037264099810272455\n",
      "Gradient for encoder.encoder.4.bias: 0.003386228810995817\n",
      "Gradient for encoder.mean.weight: 0.05253502354025841\n",
      "Gradient for encoder.mean.bias: 0.0025142021477222443\n",
      "Gradient for encoder.log_var.weight: 0.031129440292716026\n",
      "Gradient for encoder.log_var.bias: 0.0015159283066168427\n",
      "Gradient for decoder.decoder.0.weight: 0.008691328577697277\n",
      "Gradient for decoder.decoder.0.bias: 7.235754356793578e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.00043389713391661644\n",
      "Gradient for decoder.decoder.1.bias: 0.00034511127159930766\n",
      "Gradient for decoder.decoder.3.weight: 0.008473783731460571\n",
      "Gradient for decoder.decoder.3.bias: 7.718115729860031e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0004710514040198177\n",
      "Gradient for decoder.decoder.4.bias: 0.0005069163162261248\n",
      "Gradient for decoder.decoder.6.weight: 0.0007462443900294602\n",
      "Gradient for decoder.decoder.6.bias: 4.417602758621797e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.005640714429318905\n",
      "Gradient for encoder.encoder.0.bias: 9.470839043568269e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.00047611058107577264\n",
      "Gradient for encoder.encoder.1.bias: 0.00035944764385931194\n",
      "Gradient for encoder.encoder.3.weight: 0.010476011782884598\n",
      "Gradient for encoder.encoder.3.bias: 1.2519404957167524e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0033326924312859774\n",
      "Gradient for encoder.encoder.4.bias: 0.003220742102712393\n",
      "Gradient for encoder.mean.weight: 0.04743434488773346\n",
      "Gradient for encoder.mean.bias: 0.002533067250624299\n",
      "Gradient for encoder.log_var.weight: 0.023656707257032394\n",
      "Gradient for encoder.log_var.bias: 0.0015439881244674325\n",
      "Gradient for decoder.decoder.0.weight: 0.0105516342446208\n",
      "Gradient for decoder.decoder.0.bias: 9.192719502282287e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005043334676884115\n",
      "Gradient for decoder.decoder.1.bias: 0.000412677793065086\n",
      "Gradient for decoder.decoder.3.weight: 0.009997338056564331\n",
      "Gradient for decoder.decoder.3.bias: 7.773195975779856e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0003757813246920705\n",
      "Gradient for decoder.decoder.4.bias: 0.00033323062234558165\n",
      "Gradient for decoder.decoder.6.weight: 0.0006880652508698404\n",
      "Gradient for decoder.decoder.6.bias: 3.242789534851909e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.005663969554007053\n",
      "Gradient for encoder.encoder.0.bias: 9.505107638474453e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.00042934194789268076\n",
      "Gradient for encoder.encoder.1.bias: 0.00039436965016648173\n",
      "Gradient for encoder.encoder.3.weight: 0.009559604339301586\n",
      "Gradient for encoder.encoder.3.bias: 1.1512463898855074e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.003459919709712267\n",
      "Gradient for encoder.encoder.4.bias: 0.002628551097586751\n",
      "Gradient for encoder.mean.weight: 0.048229366540908813\n",
      "Gradient for encoder.mean.bias: 0.0016176310600712895\n",
      "Gradient for encoder.log_var.weight: 0.022801034152507782\n",
      "Gradient for encoder.log_var.bias: 0.0009649727726355195\n",
      "Gradient for decoder.decoder.0.weight: 0.011022665537893772\n",
      "Gradient for decoder.decoder.0.bias: 8.97838886571023e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005554293747991323\n",
      "Gradient for decoder.decoder.1.bias: 0.0004521851078607142\n",
      "Gradient for decoder.decoder.3.weight: 0.010501311160624027\n",
      "Gradient for decoder.decoder.3.bias: 7.957217523779647e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00037815733230672777\n",
      "Gradient for decoder.decoder.4.bias: 0.0003671980812214315\n",
      "Gradient for decoder.decoder.6.weight: 0.0007049182313494384\n",
      "Gradient for decoder.decoder.6.bias: 3.836975520243868e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.007760214153677225\n",
      "Gradient for encoder.encoder.0.bias: 1.2103686108932976e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0006192345754243433\n",
      "Gradient for encoder.encoder.1.bias: 0.0005497999372892082\n",
      "Gradient for encoder.encoder.3.weight: 0.013233357109129429\n",
      "Gradient for encoder.encoder.3.bias: 1.2240186642031858e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0032470999285578728\n",
      "Gradient for encoder.encoder.4.bias: 0.0025853035040199757\n",
      "Gradient for encoder.mean.weight: 0.04587223008275032\n",
      "Gradient for encoder.mean.bias: 0.0017128047766163945\n",
      "Gradient for encoder.log_var.weight: 0.02257589064538479\n",
      "Gradient for encoder.log_var.bias: 0.0009890926303341985\n",
      "Gradient for decoder.decoder.0.weight: 0.010226225480437279\n",
      "Gradient for decoder.decoder.0.bias: 9.704501785501307e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005161681910976768\n",
      "Gradient for decoder.decoder.1.bias: 0.00043361986172385514\n",
      "Gradient for decoder.decoder.3.weight: 0.00975885521620512\n",
      "Gradient for decoder.decoder.3.bias: 8.949111590661474e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0003844400926027447\n",
      "Gradient for decoder.decoder.4.bias: 0.0003358922840561718\n",
      "Gradient for decoder.decoder.6.weight: 0.0007152093457989395\n",
      "Gradient for decoder.decoder.6.bias: 4.0050748793873936e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.004874832928180695\n",
      "Gradient for encoder.encoder.0.bias: 8.07793068546836e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.0005080140545032918\n",
      "Gradient for encoder.encoder.1.bias: 0.0004745691257994622\n",
      "Gradient for encoder.encoder.3.weight: 0.010994779877364635\n",
      "Gradient for encoder.encoder.3.bias: 1.0510020631571138e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0027294389437884092\n",
      "Gradient for encoder.encoder.4.bias: 0.0022374249529093504\n",
      "Gradient for encoder.mean.weight: 0.041139207780361176\n",
      "Gradient for encoder.mean.bias: 0.0016615292988717556\n",
      "Gradient for encoder.log_var.weight: 0.02143995091319084\n",
      "Gradient for encoder.log_var.bias: 0.0009970542741939425\n",
      "Gradient for decoder.decoder.0.weight: 0.012199601158499718\n",
      "Gradient for decoder.decoder.0.bias: 9.845155246601678e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0006124301580712199\n",
      "Gradient for decoder.decoder.1.bias: 0.0004805955686606467\n",
      "Gradient for decoder.decoder.3.weight: 0.011524815112352371\n",
      "Gradient for decoder.decoder.3.bias: 9.044686527515111e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0005181350279599428\n",
      "Gradient for decoder.decoder.4.bias: 0.0004805969656445086\n",
      "Gradient for decoder.decoder.6.weight: 0.0008023589034564793\n",
      "Gradient for decoder.decoder.6.bias: 4.966596679878421e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.0065514626912772655\n",
      "Gradient for encoder.encoder.0.bias: 9.664112392282487e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.00044183715363033116\n",
      "Gradient for encoder.encoder.1.bias: 0.00042663406929932535\n",
      "Gradient for encoder.encoder.3.weight: 0.009746856056153774\n",
      "Gradient for encoder.encoder.3.bias: 1.0647893677884213e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0024990146048367023\n",
      "Gradient for encoder.encoder.4.bias: 0.0021400251425802708\n",
      "Gradient for encoder.mean.weight: 0.037444088608026505\n",
      "Gradient for encoder.mean.bias: 0.0018265499966219068\n",
      "Gradient for encoder.log_var.weight: 0.021356455981731415\n",
      "Gradient for encoder.log_var.bias: 0.0009734443738125265\n",
      "Gradient for decoder.decoder.0.weight: 0.010620271787047386\n",
      "Gradient for decoder.decoder.0.bias: 8.719232280629541e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005257581942714751\n",
      "Gradient for decoder.decoder.1.bias: 0.00043746482697315514\n",
      "Gradient for decoder.decoder.3.weight: 0.01063952874392271\n",
      "Gradient for decoder.decoder.3.bias: 7.730219936386007e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00041179280378855765\n",
      "Gradient for decoder.decoder.4.bias: 0.00040543990326114\n",
      "Gradient for decoder.decoder.6.weight: 0.0007205895963124931\n",
      "Gradient for decoder.decoder.6.bias: 4.4808213715441525e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.006552431266754866\n",
      "Gradient for encoder.encoder.0.bias: 1.0310983837580334e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.000458813039585948\n",
      "Gradient for encoder.encoder.1.bias: 0.00042121350998058915\n",
      "Gradient for encoder.encoder.3.weight: 0.0097691360861063\n",
      "Gradient for encoder.encoder.3.bias: 1.0267917072148691e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.002519826637580991\n",
      "Gradient for encoder.encoder.4.bias: 0.0019466988742351532\n",
      "Gradient for encoder.mean.weight: 0.03703199699521065\n",
      "Gradient for encoder.mean.bias: 0.0014701118925586343\n",
      "Gradient for encoder.log_var.weight: 0.018539562821388245\n",
      "Gradient for encoder.log_var.bias: 0.0009351514163427055\n",
      "Gradient for decoder.decoder.0.weight: 0.010873954743146896\n",
      "Gradient for decoder.decoder.0.bias: 8.996893507973169e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005338541814126074\n",
      "Gradient for decoder.decoder.1.bias: 0.00045179424341768026\n",
      "Gradient for decoder.decoder.3.weight: 0.009871901012957096\n",
      "Gradient for decoder.decoder.3.bias: 8.660997613541e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0004375045245978981\n",
      "Gradient for decoder.decoder.4.bias: 0.00044351123506203294\n",
      "Gradient for decoder.decoder.6.weight: 0.0007374997367151082\n",
      "Gradient for decoder.decoder.6.bias: 4.106248889002018e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.009932358749210835\n",
      "Gradient for encoder.encoder.0.bias: 1.8020866049406337e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0005275700823403895\n",
      "Gradient for encoder.encoder.1.bias: 0.00048209785018116236\n",
      "Gradient for encoder.encoder.3.weight: 0.01191988866776228\n",
      "Gradient for encoder.encoder.3.bias: 1.3452343405884193e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.002728384220972657\n",
      "Gradient for encoder.encoder.4.bias: 0.002560099819675088\n",
      "Gradient for encoder.mean.weight: 0.040120046585798264\n",
      "Gradient for encoder.mean.bias: 0.002091317670419812\n",
      "Gradient for encoder.log_var.weight: 0.021943992003798485\n",
      "Gradient for encoder.log_var.bias: 0.0014157769037410617\n",
      "Gradient for decoder.decoder.0.weight: 0.008973155170679092\n",
      "Gradient for decoder.decoder.0.bias: 7.842488464193664e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0004332062089815736\n",
      "Gradient for decoder.decoder.1.bias: 0.00035660690627992153\n",
      "Gradient for decoder.decoder.3.weight: 0.008138816803693771\n",
      "Gradient for decoder.decoder.3.bias: 8.318598587742088e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0004767088685184717\n",
      "Gradient for decoder.decoder.4.bias: 0.0005761694046668708\n",
      "Gradient for decoder.decoder.6.weight: 0.0008448599837720394\n",
      "Gradient for decoder.decoder.6.bias: 6.928871152922511e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.005198145750910044\n",
      "Gradient for encoder.encoder.0.bias: 8.21692193453405e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.0004956008633598685\n",
      "Gradient for encoder.encoder.1.bias: 0.0004821133625227958\n",
      "Gradient for encoder.encoder.3.weight: 0.010481420904397964\n",
      "Gradient for encoder.encoder.3.bias: 1.086513726211713e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.002841958310455084\n",
      "Gradient for encoder.encoder.4.bias: 0.0021461560390889645\n",
      "Gradient for encoder.mean.weight: 0.042496003210544586\n",
      "Gradient for encoder.mean.bias: 0.0016408732626587152\n",
      "Gradient for encoder.log_var.weight: 0.02021189033985138\n",
      "Gradient for encoder.log_var.bias: 0.001114464714191854\n",
      "Gradient for decoder.decoder.0.weight: 0.011991064064204693\n",
      "Gradient for decoder.decoder.0.bias: 9.708391729423838e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005964361480437219\n",
      "Gradient for decoder.decoder.1.bias: 0.0005023412522859871\n",
      "Gradient for decoder.decoder.3.weight: 0.011730975471436977\n",
      "Gradient for decoder.decoder.3.bias: 1.0450523085792085e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0006398119730874896\n",
      "Gradient for decoder.decoder.4.bias: 0.0007355949492193758\n",
      "Gradient for decoder.decoder.6.weight: 0.0007818767917342484\n",
      "Gradient for decoder.decoder.6.bias: 4.687964974436909e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.005367899779230356\n",
      "Gradient for encoder.encoder.0.bias: 7.676036022086219e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.0005045426078140736\n",
      "Gradient for encoder.encoder.1.bias: 0.0005422587273642421\n",
      "Gradient for encoder.encoder.3.weight: 0.011528611183166504\n",
      "Gradient for encoder.encoder.3.bias: 9.957124014192686e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.0029085499700158834\n",
      "Gradient for encoder.encoder.4.bias: 0.0020026492420583963\n",
      "Gradient for encoder.mean.weight: 0.04595271870493889\n",
      "Gradient for encoder.mean.bias: 0.0016057019820436835\n",
      "Gradient for encoder.log_var.weight: 0.02285158261656761\n",
      "Gradient for encoder.log_var.bias: 0.0010356634156778455\n",
      "Gradient for decoder.decoder.0.weight: 0.012602370232343674\n",
      "Gradient for decoder.decoder.0.bias: 1.0711671133423195e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0005966302705928683\n",
      "Gradient for decoder.decoder.1.bias: 0.0005066279554739594\n",
      "Gradient for decoder.decoder.3.weight: 0.011684132739901543\n",
      "Gradient for decoder.decoder.3.bias: 1.021625353758715e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0004314423131290823\n",
      "Gradient for decoder.decoder.4.bias: 0.00036647618981078267\n",
      "Gradient for decoder.decoder.6.weight: 0.0007563772960565984\n",
      "Gradient for decoder.decoder.6.bias: 4.897050530416891e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.0077828289940953255\n",
      "Gradient for encoder.encoder.0.bias: 1.089845661633726e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0005693223210982978\n",
      "Gradient for encoder.encoder.1.bias: 0.0005036052316427231\n",
      "Gradient for encoder.encoder.3.weight: 0.013617407530546188\n",
      "Gradient for encoder.encoder.3.bias: 1.3488291039642775e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.003237853990867734\n",
      "Gradient for encoder.encoder.4.bias: 0.002543067093938589\n",
      "Gradient for encoder.mean.weight: 0.04713733121752739\n",
      "Gradient for encoder.mean.bias: 0.001712247496470809\n",
      "Gradient for encoder.log_var.weight: 0.028615238144993782\n",
      "Gradient for encoder.log_var.bias: 0.0011284155771136284\n",
      "Gradient for decoder.decoder.0.weight: 0.011343150399625301\n",
      "Gradient for decoder.decoder.0.bias: 1.0042493225892457e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0005749193369410932\n",
      "Gradient for decoder.decoder.1.bias: 0.00042015413055196404\n",
      "Gradient for decoder.decoder.3.weight: 0.010732785798609257\n",
      "Gradient for decoder.decoder.3.bias: 1.0492970381470457e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.000600260857027024\n",
      "Gradient for decoder.decoder.4.bias: 0.0006571214180439711\n",
      "Gradient for decoder.decoder.6.weight: 0.0009130816906690598\n",
      "Gradient for decoder.decoder.6.bias: 6.749222666257992e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.007167644798755646\n",
      "Gradient for encoder.encoder.0.bias: 1.1529522996045483e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0005219979211688042\n",
      "Gradient for encoder.encoder.1.bias: 0.00042916147504001856\n",
      "Gradient for encoder.encoder.3.weight: 0.011532621458172798\n",
      "Gradient for encoder.encoder.3.bias: 1.0729701155343108e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0024574371054768562\n",
      "Gradient for encoder.encoder.4.bias: 0.001974058337509632\n",
      "Gradient for encoder.mean.weight: 0.03615580499172211\n",
      "Gradient for encoder.mean.bias: 0.0015920529840514064\n",
      "Gradient for encoder.log_var.weight: 0.02193077839910984\n",
      "Gradient for encoder.log_var.bias: 0.0009886714396998286\n",
      "Gradient for decoder.decoder.0.weight: 0.009469905868172646\n",
      "Gradient for decoder.decoder.0.bias: 8.624980590843379e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0004885243833996356\n",
      "Gradient for decoder.decoder.1.bias: 0.00042002307600341737\n",
      "Gradient for decoder.decoder.3.weight: 0.009554626420140266\n",
      "Gradient for decoder.decoder.3.bias: 8.512191645992928e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00045258234604261816\n",
      "Gradient for decoder.decoder.4.bias: 0.000498319452162832\n",
      "Gradient for decoder.decoder.6.weight: 0.0006949621019884944\n",
      "Gradient for decoder.decoder.6.bias: 3.9318598282989115e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training VAE Epoch:  22%|██▏       | 17/79 [00:00<00:01, 52.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient for encoder.encoder.0.weight: 0.008290586061775684\n",
      "Gradient for encoder.encoder.0.bias: 1.329890017554014e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0005319439223967493\n",
      "Gradient for encoder.encoder.1.bias: 0.0005938422400504351\n",
      "Gradient for encoder.encoder.3.weight: 0.0115473298355937\n",
      "Gradient for encoder.encoder.3.bias: 1.4845907836402716e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0029437376651912928\n",
      "Gradient for encoder.encoder.4.bias: 0.0033869293984025717\n",
      "Gradient for encoder.mean.weight: 0.04146189242601395\n",
      "Gradient for encoder.mean.bias: 0.002659400925040245\n",
      "Gradient for encoder.log_var.weight: 0.026764551177620888\n",
      "Gradient for encoder.log_var.bias: 0.001848224550485611\n",
      "Gradient for decoder.decoder.0.weight: 0.008903914131224155\n",
      "Gradient for decoder.decoder.0.bias: 7.932807882804482e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.000423570309067145\n",
      "Gradient for decoder.decoder.1.bias: 0.0003892519453074783\n",
      "Gradient for decoder.decoder.3.weight: 0.008082632906734943\n",
      "Gradient for decoder.decoder.3.bias: 7.482718611395711e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0003457202692516148\n",
      "Gradient for decoder.decoder.4.bias: 0.0003691423044074327\n",
      "Gradient for decoder.decoder.6.weight: 0.0007197392405942082\n",
      "Gradient for decoder.decoder.6.bias: 4.543026443570852e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.004102990962564945\n",
      "Gradient for encoder.encoder.0.bias: 6.306522144783333e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.0005224563064984977\n",
      "Gradient for encoder.encoder.1.bias: 0.0005018849042244256\n",
      "Gradient for encoder.encoder.3.weight: 0.01206214725971222\n",
      "Gradient for encoder.encoder.3.bias: 1.225942125593349e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.003960891626775265\n",
      "Gradient for encoder.encoder.4.bias: 0.0026585119776427746\n",
      "Gradient for encoder.mean.weight: 0.059943437576293945\n",
      "Gradient for encoder.mean.bias: 0.0014613928506150842\n",
      "Gradient for encoder.log_var.weight: 0.028217321261763573\n",
      "Gradient for encoder.log_var.bias: 0.000994412461295724\n",
      "Gradient for decoder.decoder.0.weight: 0.01518278755247593\n",
      "Gradient for decoder.decoder.0.bias: 1.3513176688739748e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0007163551053963602\n",
      "Gradient for decoder.decoder.1.bias: 0.0006389349582605064\n",
      "Gradient for decoder.decoder.3.weight: 0.01475411094725132\n",
      "Gradient for decoder.decoder.3.bias: 1.3751164096298396e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.000877287529874593\n",
      "Gradient for decoder.decoder.4.bias: 0.0009985461365431547\n",
      "Gradient for decoder.decoder.6.weight: 0.0009749927558004856\n",
      "Gradient for decoder.decoder.6.bias: 7.30111132725142e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training VAE Epoch:  32%|███▏      | 25/79 [00:00<00:00, 59.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient for encoder.encoder.0.weight: 0.006945307832211256\n",
      "Gradient for encoder.encoder.0.bias: 1.0285687232491902e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0005851836176589131\n",
      "Gradient for encoder.encoder.1.bias: 0.0004918915801681578\n",
      "Gradient for encoder.encoder.3.weight: 0.013230687007308006\n",
      "Gradient for encoder.encoder.3.bias: 1.0026193070222789e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.002754922490566969\n",
      "Gradient for encoder.encoder.4.bias: 0.0017346907407045364\n",
      "Gradient for encoder.mean.weight: 0.04157787188887596\n",
      "Gradient for encoder.mean.bias: 0.0012056719278916717\n",
      "Gradient for encoder.log_var.weight: 0.021962305530905724\n",
      "Gradient for encoder.log_var.bias: 0.0008057093946263194\n",
      "Gradient for decoder.decoder.0.weight: 0.01244738232344389\n",
      "Gradient for decoder.decoder.0.bias: 1.025759616135602e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0006370720802806318\n",
      "Gradient for decoder.decoder.1.bias: 0.0005323460791260004\n",
      "Gradient for decoder.decoder.3.weight: 0.011755171231925488\n",
      "Gradient for decoder.decoder.3.bias: 1.0099986125222671e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0004785466881003231\n",
      "Gradient for decoder.decoder.4.bias: 0.0004665456071961671\n",
      "Gradient for decoder.decoder.6.weight: 0.000836088031064719\n",
      "Gradient for decoder.decoder.6.bias: 5.979583875159733e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.007073770277202129\n",
      "Gradient for encoder.encoder.0.bias: 9.37828113778405e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.0004732132365461439\n",
      "Gradient for encoder.encoder.1.bias: 0.0005305011873133481\n",
      "Gradient for encoder.encoder.3.weight: 0.010438061319291592\n",
      "Gradient for encoder.encoder.3.bias: 1.1115026954389151e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.002324481727555394\n",
      "Gradient for encoder.encoder.4.bias: 0.0022507605608552694\n",
      "Gradient for encoder.mean.weight: 0.033623404800891876\n",
      "Gradient for encoder.mean.bias: 0.0017215162515640259\n",
      "Gradient for encoder.log_var.weight: 0.019443737342953682\n",
      "Gradient for encoder.log_var.bias: 0.0013188272714614868\n",
      "Gradient for decoder.decoder.0.weight: 0.011928994208574295\n",
      "Gradient for decoder.decoder.0.bias: 9.910323950368394e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005924465367570519\n",
      "Gradient for decoder.decoder.1.bias: 0.00046221475349739194\n",
      "Gradient for decoder.decoder.3.weight: 0.011385818012058735\n",
      "Gradient for decoder.decoder.3.bias: 9.573005582685923e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0004274430684745312\n",
      "Gradient for decoder.decoder.4.bias: 0.00037453757249750197\n",
      "Gradient for decoder.decoder.6.weight: 0.0007469058036804199\n",
      "Gradient for decoder.decoder.6.bias: 3.6328943679109216e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.005143312271684408\n",
      "Gradient for encoder.encoder.0.bias: 9.361114314265784e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.0004859916807617992\n",
      "Gradient for encoder.encoder.1.bias: 0.0005213698022998869\n",
      "Gradient for encoder.encoder.3.weight: 0.010769951157271862\n",
      "Gradient for encoder.encoder.3.bias: 1.1312485670433858e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.003270936431363225\n",
      "Gradient for encoder.encoder.4.bias: 0.0024367445148527622\n",
      "Gradient for encoder.mean.weight: 0.0465979278087616\n",
      "Gradient for encoder.mean.bias: 0.0017262117471545935\n",
      "Gradient for encoder.log_var.weight: 0.027960719540715218\n",
      "Gradient for encoder.log_var.bias: 0.0010914858430624008\n",
      "Gradient for decoder.decoder.0.weight: 0.012780374847352505\n",
      "Gradient for decoder.decoder.0.bias: 1.0580910453361625e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0005954193184152246\n",
      "Gradient for decoder.decoder.1.bias: 0.0004963946994394064\n",
      "Gradient for decoder.decoder.3.weight: 0.012269927188754082\n",
      "Gradient for decoder.decoder.3.bias: 9.09819372618692e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00043844827450811863\n",
      "Gradient for decoder.decoder.4.bias: 0.0003851975197903812\n",
      "Gradient for decoder.decoder.6.weight: 0.0007547197164967656\n",
      "Gradient for decoder.decoder.6.bias: 4.012493445770815e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.006029720418155193\n",
      "Gradient for encoder.encoder.0.bias: 1.0517079394867235e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0004877480387222022\n",
      "Gradient for encoder.encoder.1.bias: 0.0004378122976049781\n",
      "Gradient for encoder.encoder.3.weight: 0.010690155439078808\n",
      "Gradient for encoder.encoder.3.bias: 1.5143762632785496e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.003757592523470521\n",
      "Gradient for encoder.encoder.4.bias: 0.003464861074462533\n",
      "Gradient for encoder.mean.weight: 0.0512409433722496\n",
      "Gradient for encoder.mean.bias: 0.0024937556590884924\n",
      "Gradient for encoder.log_var.weight: 0.033275119960308075\n",
      "Gradient for encoder.log_var.bias: 0.0015984205529093742\n",
      "Gradient for decoder.decoder.0.weight: 0.010423261672258377\n",
      "Gradient for decoder.decoder.0.bias: 8.589136346603965e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005484886351041496\n",
      "Gradient for decoder.decoder.1.bias: 0.00041561017860658467\n",
      "Gradient for decoder.decoder.3.weight: 0.009837829507887363\n",
      "Gradient for decoder.decoder.3.bias: 8.540736173845431e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00044721580343320966\n",
      "Gradient for decoder.decoder.4.bias: 0.0004730921646114439\n",
      "Gradient for decoder.decoder.6.weight: 0.0007402434712275863\n",
      "Gradient for decoder.decoder.6.bias: 5.130088175064884e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.008192792534828186\n",
      "Gradient for encoder.encoder.0.bias: 1.4213172305765909e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0006292034522630274\n",
      "Gradient for encoder.encoder.1.bias: 0.0006398635450750589\n",
      "Gradient for encoder.encoder.3.weight: 0.013715404085814953\n",
      "Gradient for encoder.encoder.3.bias: 1.220895051723403e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0032449597492814064\n",
      "Gradient for encoder.encoder.4.bias: 0.0030310768634080887\n",
      "Gradient for encoder.mean.weight: 0.04559856653213501\n",
      "Gradient for encoder.mean.bias: 0.002276388229802251\n",
      "Gradient for encoder.log_var.weight: 0.024121476337313652\n",
      "Gradient for encoder.log_var.bias: 0.001558781135827303\n",
      "Gradient for decoder.decoder.0.weight: 0.010041777044534683\n",
      "Gradient for decoder.decoder.0.bias: 8.823043684547116e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.00048726002569310367\n",
      "Gradient for decoder.decoder.1.bias: 0.00039854025817476213\n",
      "Gradient for decoder.decoder.3.weight: 0.009592939168214798\n",
      "Gradient for decoder.decoder.3.bias: 8.612083962633577e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0004096386837773025\n",
      "Gradient for decoder.decoder.4.bias: 0.00041305788909085095\n",
      "Gradient for decoder.decoder.6.weight: 0.0007192292832769454\n",
      "Gradient for decoder.decoder.6.bias: 4.1474064346402884e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.006450751330703497\n",
      "Gradient for encoder.encoder.0.bias: 1.0390778515390053e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0005027119186706841\n",
      "Gradient for encoder.encoder.1.bias: 0.0003990895056631416\n",
      "Gradient for encoder.encoder.3.weight: 0.011097804643213749\n",
      "Gradient for encoder.encoder.3.bias: 1.1358453066989682e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0029148319736123085\n",
      "Gradient for encoder.encoder.4.bias: 0.002485588425770402\n",
      "Gradient for encoder.mean.weight: 0.039601027965545654\n",
      "Gradient for encoder.mean.bias: 0.0016914202133193612\n",
      "Gradient for encoder.log_var.weight: 0.022376038134098053\n",
      "Gradient for encoder.log_var.bias: 0.0011862035607919097\n",
      "Gradient for decoder.decoder.0.weight: 0.009257622994482517\n",
      "Gradient for decoder.decoder.0.bias: 8.472431090034149e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.000458438036730513\n",
      "Gradient for decoder.decoder.1.bias: 0.0004057131882291287\n",
      "Gradient for decoder.decoder.3.weight: 0.008870918303728104\n",
      "Gradient for decoder.decoder.3.bias: 8.907855009177013e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00042018209933303297\n",
      "Gradient for decoder.decoder.4.bias: 0.00046195933828130364\n",
      "Gradient for decoder.decoder.6.weight: 0.0008092126809060574\n",
      "Gradient for decoder.decoder.6.bias: 6.142177153378725e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.00914617907255888\n",
      "Gradient for encoder.encoder.0.bias: 1.7585736686309694e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0008043416310101748\n",
      "Gradient for encoder.encoder.1.bias: 0.0005318879266269505\n",
      "Gradient for encoder.encoder.3.weight: 0.0173003189265728\n",
      "Gradient for encoder.encoder.3.bias: 1.4086565247595217e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.003740401705726981\n",
      "Gradient for encoder.encoder.4.bias: 0.003096651518717408\n",
      "Gradient for encoder.mean.weight: 0.05417333170771599\n",
      "Gradient for encoder.mean.bias: 0.0021780075039714575\n",
      "Gradient for encoder.log_var.weight: 0.02951604314148426\n",
      "Gradient for encoder.log_var.bias: 0.0014528962783515453\n",
      "Gradient for decoder.decoder.0.weight: 0.009765979833900928\n",
      "Gradient for decoder.decoder.0.bias: 7.744620916794176e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0004743699391838163\n",
      "Gradient for decoder.decoder.1.bias: 0.00041744872578419745\n",
      "Gradient for decoder.decoder.3.weight: 0.009150839410722256\n",
      "Gradient for decoder.decoder.3.bias: 6.841711919225446e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00039671504055149853\n",
      "Gradient for decoder.decoder.4.bias: 0.00041682878509163857\n",
      "Gradient for decoder.decoder.6.weight: 0.0006996808806434274\n",
      "Gradient for decoder.decoder.6.bias: 4.1703904571477324e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.01019700150936842\n",
      "Gradient for encoder.encoder.0.bias: 2.0606915479559618e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0008203703910112381\n",
      "Gradient for encoder.encoder.1.bias: 0.0005898299277760088\n",
      "Gradient for encoder.encoder.3.weight: 0.017454449087381363\n",
      "Gradient for encoder.encoder.3.bias: 1.6096647625918337e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.004381816368550062\n",
      "Gradient for encoder.encoder.4.bias: 0.0038022876251488924\n",
      "Gradient for encoder.mean.weight: 0.06445871293544769\n",
      "Gradient for encoder.mean.bias: 0.0029163267463445663\n",
      "Gradient for encoder.log_var.weight: 0.037816185504198074\n",
      "Gradient for encoder.log_var.bias: 0.0017190478974953294\n",
      "Gradient for decoder.decoder.0.weight: 0.008622038178145885\n",
      "Gradient for decoder.decoder.0.bias: 7.745144803283921e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0004376586002763361\n",
      "Gradient for decoder.decoder.1.bias: 0.0003406876639928669\n",
      "Gradient for decoder.decoder.3.weight: 0.008151846937835217\n",
      "Gradient for decoder.decoder.3.bias: 7.334087503974018e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0003546954249031842\n",
      "Gradient for decoder.decoder.4.bias: 0.00039066802128218114\n",
      "Gradient for decoder.decoder.6.weight: 0.0006907468778081238\n",
      "Gradient for decoder.decoder.6.bias: 3.609900159062818e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.0044043464586138725\n",
      "Gradient for encoder.encoder.0.bias: 7.295775962534723e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.0004946112749166787\n",
      "Gradient for encoder.encoder.1.bias: 0.0004257646214682609\n",
      "Gradient for encoder.encoder.3.weight: 0.010692226700484753\n",
      "Gradient for encoder.encoder.3.bias: 9.493177771657813e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.003039911389350891\n",
      "Gradient for encoder.encoder.4.bias: 0.002031453885138035\n",
      "Gradient for encoder.mean.weight: 0.041511449962854385\n",
      "Gradient for encoder.mean.bias: 0.0013291130308061838\n",
      "Gradient for encoder.log_var.weight: 0.021291686221957207\n",
      "Gradient for encoder.log_var.bias: 0.0009054055553860962\n",
      "Gradient for decoder.decoder.0.weight: 0.013066312298178673\n",
      "Gradient for decoder.decoder.0.bias: 1.1103078179086623e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0006471298402175307\n",
      "Gradient for decoder.decoder.1.bias: 0.0005216156132519245\n",
      "Gradient for decoder.decoder.3.weight: 0.012113329023122787\n",
      "Gradient for decoder.decoder.3.bias: 1.0031431935120239e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0004625626024790108\n",
      "Gradient for decoder.decoder.4.bias: 0.0004044074157718569\n",
      "Gradient for decoder.decoder.6.weight: 0.0007715240935795009\n",
      "Gradient for decoder.decoder.6.bias: 4.57647220173385e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.004456866532564163\n",
      "Gradient for encoder.encoder.0.bias: 7.488274757216917e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.00048126227920874953\n",
      "Gradient for encoder.encoder.1.bias: 0.00043663327232934535\n",
      "Gradient for encoder.encoder.3.weight: 0.010395701974630356\n",
      "Gradient for encoder.encoder.3.bias: 1.0075072026660692e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.003208717331290245\n",
      "Gradient for encoder.encoder.4.bias: 0.002250944497063756\n",
      "Gradient for encoder.mean.weight: 0.046617019921541214\n",
      "Gradient for encoder.mean.bias: 0.0014728461392223835\n",
      "Gradient for encoder.log_var.weight: 0.022363770753145218\n",
      "Gradient for encoder.log_var.bias: 0.0009166234522126615\n",
      "Gradient for decoder.decoder.0.weight: 0.013864508830010891\n",
      "Gradient for decoder.decoder.0.bias: 1.1221749224299415e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.000642193655949086\n",
      "Gradient for decoder.decoder.1.bias: 0.0005532376817427576\n",
      "Gradient for decoder.decoder.3.weight: 0.012971891090273857\n",
      "Gradient for decoder.decoder.3.bias: 9.625972935412008e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0004542366659734398\n",
      "Gradient for decoder.decoder.4.bias: 0.0003983408387284726\n",
      "Gradient for decoder.decoder.6.weight: 0.0006946944631636143\n",
      "Gradient for decoder.decoder.6.bias: 3.592418215703219e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.007806364446878433\n",
      "Gradient for encoder.encoder.0.bias: 1.1646564788969638e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0006627434631809592\n",
      "Gradient for encoder.encoder.1.bias: 0.000597141042817384\n",
      "Gradient for encoder.encoder.3.weight: 0.014238755218684673\n",
      "Gradient for encoder.encoder.3.bias: 1.0601186595238232e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.002711502369493246\n",
      "Gradient for encoder.encoder.4.bias: 0.002106520114466548\n",
      "Gradient for encoder.mean.weight: 0.03860674798488617\n",
      "Gradient for encoder.mean.bias: 0.001620932249352336\n",
      "Gradient for encoder.log_var.weight: 0.02384147420525551\n",
      "Gradient for encoder.log_var.bias: 0.0011233376571908593\n",
      "Gradient for decoder.decoder.0.weight: 0.011651578359305859\n",
      "Gradient for decoder.decoder.0.bias: 1.0311778514404679e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.000541393703315407\n",
      "Gradient for decoder.decoder.1.bias: 0.0004909508861601353\n",
      "Gradient for decoder.decoder.3.weight: 0.010801531374454498\n",
      "Gradient for decoder.decoder.3.bias: 8.869883300066661e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00042879549437202513\n",
      "Gradient for decoder.decoder.4.bias: 0.00038454425521194935\n",
      "Gradient for decoder.decoder.6.weight: 0.0008184417383745313\n",
      "Gradient for decoder.decoder.6.bias: 5.6753990065772086e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.007706739008426666\n",
      "Gradient for encoder.encoder.0.bias: 1.2194586486435899e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0006936229183338583\n",
      "Gradient for encoder.encoder.1.bias: 0.0006551871192641556\n",
      "Gradient for encoder.encoder.3.weight: 0.014954437501728535\n",
      "Gradient for encoder.encoder.3.bias: 1.2588495523768728e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.003499265294522047\n",
      "Gradient for encoder.encoder.4.bias: 0.0029553340282291174\n",
      "Gradient for encoder.mean.weight: 0.048151593655347824\n",
      "Gradient for encoder.mean.bias: 0.002378014847636223\n",
      "Gradient for encoder.log_var.weight: 0.025618717074394226\n",
      "Gradient for encoder.log_var.bias: 0.0014508957974612713\n",
      "Gradient for decoder.decoder.0.weight: 0.01088157668709755\n",
      "Gradient for decoder.decoder.0.bias: 9.225446795380066e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005450479802675545\n",
      "Gradient for decoder.decoder.1.bias: 0.0004586741852108389\n",
      "Gradient for decoder.decoder.3.weight: 0.010519608855247498\n",
      "Gradient for decoder.decoder.3.bias: 8.463128114977181e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.000420936819864437\n",
      "Gradient for decoder.decoder.4.bias: 0.00040339978295378387\n",
      "Gradient for decoder.decoder.6.weight: 0.0007230575429275632\n",
      "Gradient for decoder.decoder.6.bias: 3.9963611925486475e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.007874581031501293\n",
      "Gradient for encoder.encoder.0.bias: 1.3980000317104224e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0005750354030169547\n",
      "Gradient for encoder.encoder.1.bias: 0.00042552792001515627\n",
      "Gradient for encoder.encoder.3.weight: 0.012443900108337402\n",
      "Gradient for encoder.encoder.3.bias: 1.2666524773496945e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.002932401606813073\n",
      "Gradient for encoder.encoder.4.bias: 0.0025134324096143246\n",
      "Gradient for encoder.mean.weight: 0.04180934652686119\n",
      "Gradient for encoder.mean.bias: 0.0020751722622662783\n",
      "Gradient for encoder.log_var.weight: 0.02071801759302616\n",
      "Gradient for encoder.log_var.bias: 0.0011789542622864246\n",
      "Gradient for decoder.decoder.0.weight: 0.008970502763986588\n",
      "Gradient for decoder.decoder.0.bias: 7.40503769414147e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.00044044156675226986\n",
      "Gradient for decoder.decoder.1.bias: 0.00035504813422448933\n",
      "Gradient for decoder.decoder.3.weight: 0.008417172357439995\n",
      "Gradient for decoder.decoder.3.bias: 7.290334308462931e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0003790685150306672\n",
      "Gradient for decoder.decoder.4.bias: 0.00039838257362134755\n",
      "Gradient for decoder.decoder.6.weight: 0.0006738931988365948\n",
      "Gradient for decoder.decoder.6.bias: 3.835752067971043e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.005065068602561951\n",
      "Gradient for encoder.encoder.0.bias: 7.89852905302979e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.0005900122923776507\n",
      "Gradient for encoder.encoder.1.bias: 0.0005683528142981231\n",
      "Gradient for encoder.encoder.3.weight: 0.012661759741604328\n",
      "Gradient for encoder.encoder.3.bias: 1.1200063793070925e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.003446925664320588\n",
      "Gradient for encoder.encoder.4.bias: 0.001956178806722164\n",
      "Gradient for encoder.mean.weight: 0.05060713365674019\n",
      "Gradient for encoder.mean.bias: 0.0014432475436478853\n",
      "Gradient for encoder.log_var.weight: 0.026419203728437424\n",
      "Gradient for encoder.log_var.bias: 0.000952962611336261\n",
      "Gradient for decoder.decoder.0.weight: 0.013139658607542515\n",
      "Gradient for decoder.decoder.0.bias: 1.1814944855803589e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0006034476682543755\n",
      "Gradient for decoder.decoder.1.bias: 0.000578501436393708\n",
      "Gradient for decoder.decoder.3.weight: 0.012739120982587337\n",
      "Gradient for decoder.decoder.3.bias: 1.1989299830705846e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0006778578390367329\n",
      "Gradient for decoder.decoder.4.bias: 0.0008296495070680976\n",
      "Gradient for decoder.decoder.6.weight: 0.0009327816078439355\n",
      "Gradient for decoder.decoder.6.bias: 7.566823478555307e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training VAE Epoch:  42%|████▏     | 33/79 [00:00<00:00, 65.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient for encoder.encoder.0.weight: 0.007878542877733707\n",
      "Gradient for encoder.encoder.0.bias: 1.1448316253326318e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0004954221076332033\n",
      "Gradient for encoder.encoder.1.bias: 0.00039576462586410344\n",
      "Gradient for encoder.encoder.3.weight: 0.010810041800141335\n",
      "Gradient for encoder.encoder.3.bias: 1.0878333650543581e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.002409718930721283\n",
      "Gradient for encoder.encoder.4.bias: 0.002132253022864461\n",
      "Gradient for encoder.mean.weight: 0.03355635702610016\n",
      "Gradient for encoder.mean.bias: 0.0016338983550667763\n",
      "Gradient for encoder.log_var.weight: 0.018238844349980354\n",
      "Gradient for encoder.log_var.bias: 0.0010301851434633136\n",
      "Gradient for decoder.decoder.0.weight: 0.009680160321295261\n",
      "Gradient for decoder.decoder.0.bias: 8.584711413961443e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.00047834610450081527\n",
      "Gradient for decoder.decoder.1.bias: 0.0004001080815214664\n",
      "Gradient for decoder.decoder.3.weight: 0.008833615109324455\n",
      "Gradient for decoder.decoder.3.bias: 8.130540685158394e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00046234685578383505\n",
      "Gradient for decoder.decoder.4.bias: 0.0004739521536976099\n",
      "Gradient for decoder.decoder.6.weight: 0.001005434081889689\n",
      "Gradient for decoder.decoder.6.bias: 7.919886411400512e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.0038208109326660633\n",
      "Gradient for encoder.encoder.0.bias: 6.657679182259235e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.00045694931759499013\n",
      "Gradient for encoder.encoder.1.bias: 0.0004588983138091862\n",
      "Gradient for encoder.encoder.3.weight: 0.010177313350141048\n",
      "Gradient for encoder.encoder.3.bias: 1.1098578306389939e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0033934805542230606\n",
      "Gradient for encoder.encoder.4.bias: 0.002452113665640354\n",
      "Gradient for encoder.mean.weight: 0.05285053327679634\n",
      "Gradient for encoder.mean.bias: 0.0017029962036758661\n",
      "Gradient for encoder.log_var.weight: 0.02776946686208248\n",
      "Gradient for encoder.log_var.bias: 0.0009965880308300257\n",
      "Gradient for decoder.decoder.0.weight: 0.014407065697014332\n",
      "Gradient for decoder.decoder.0.bias: 1.0936272026862426e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0006579709006473422\n",
      "Gradient for decoder.decoder.1.bias: 0.0005726731033064425\n",
      "Gradient for decoder.decoder.3.weight: 0.013147762045264244\n",
      "Gradient for decoder.decoder.3.bias: 9.757741836757816e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0005213393014855683\n",
      "Gradient for decoder.decoder.4.bias: 0.0005226494977250695\n",
      "Gradient for decoder.decoder.6.weight: 0.0007253653602674603\n",
      "Gradient for decoder.decoder.6.bias: 3.9393125916831195e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training VAE Epoch:  52%|█████▏    | 41/79 [00:00<00:00, 69.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient for encoder.encoder.0.weight: 0.006087797693908215\n",
      "Gradient for encoder.encoder.0.bias: 8.995695681413007e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.0005439994856715202\n",
      "Gradient for encoder.encoder.1.bias: 0.0004905425594188273\n",
      "Gradient for encoder.encoder.3.weight: 0.012290219776332378\n",
      "Gradient for encoder.encoder.3.bias: 1.2327702747505498e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.003685560543090105\n",
      "Gradient for encoder.encoder.4.bias: 0.002947088098153472\n",
      "Gradient for encoder.mean.weight: 0.0488639660179615\n",
      "Gradient for encoder.mean.bias: 0.002047412795946002\n",
      "Gradient for encoder.log_var.weight: 0.027304209768772125\n",
      "Gradient for encoder.log_var.bias: 0.0013642495032399893\n",
      "Gradient for decoder.decoder.0.weight: 0.011548752896487713\n",
      "Gradient for decoder.decoder.0.bias: 9.482416241102243e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005923518911004066\n",
      "Gradient for decoder.decoder.1.bias: 0.0004770325613208115\n",
      "Gradient for decoder.decoder.3.weight: 0.010835997760295868\n",
      "Gradient for decoder.decoder.3.bias: 8.94546381413619e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0005086354212835431\n",
      "Gradient for decoder.decoder.4.bias: 0.0005144090391695499\n",
      "Gradient for decoder.decoder.6.weight: 0.0008539425325579941\n",
      "Gradient for decoder.decoder.6.bias: 5.6718516134424135e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.01528885867446661\n",
      "Gradient for encoder.encoder.0.bias: 2.802925253009292e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.001305250683799386\n",
      "Gradient for encoder.encoder.1.bias: 0.0009280084050260484\n",
      "Gradient for encoder.encoder.3.weight: 0.028507260605692863\n",
      "Gradient for encoder.encoder.3.bias: 2.0264573352690718e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0060531445778906345\n",
      "Gradient for encoder.encoder.4.bias: 0.004955364391207695\n",
      "Gradient for encoder.mean.weight: 0.08547630161046982\n",
      "Gradient for encoder.mean.bias: 0.002942201914265752\n",
      "Gradient for encoder.log_var.weight: 0.04864565655589104\n",
      "Gradient for encoder.log_var.bias: 0.0015822021523490548\n",
      "Gradient for decoder.decoder.0.weight: 0.007895886898040771\n",
      "Gradient for decoder.decoder.0.bias: 7.30178695285133e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0003578867472242564\n",
      "Gradient for decoder.decoder.1.bias: 0.00030707777477800846\n",
      "Gradient for decoder.decoder.3.weight: 0.007205958012491465\n",
      "Gradient for decoder.decoder.3.bias: 7.10117867286364e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0003120946348644793\n",
      "Gradient for decoder.decoder.4.bias: 0.0003006003680638969\n",
      "Gradient for decoder.decoder.6.weight: 0.0006981128826737404\n",
      "Gradient for decoder.decoder.6.bias: 3.278529038652778e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.00642224820330739\n",
      "Gradient for encoder.encoder.0.bias: 1.1193553896282626e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0005317481700330973\n",
      "Gradient for encoder.encoder.1.bias: 0.0005016765207983553\n",
      "Gradient for encoder.encoder.3.weight: 0.011990709230303764\n",
      "Gradient for encoder.encoder.3.bias: 1.0392232907552312e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0026370876003056765\n",
      "Gradient for encoder.encoder.4.bias: 0.0020573667716234922\n",
      "Gradient for encoder.mean.weight: 0.03912844881415367\n",
      "Gradient for encoder.mean.bias: 0.0017555009108036757\n",
      "Gradient for encoder.log_var.weight: 0.01914255879819393\n",
      "Gradient for encoder.log_var.bias: 0.000953776587266475\n",
      "Gradient for decoder.decoder.0.weight: 0.010513673536479473\n",
      "Gradient for decoder.decoder.0.bias: 9.083350738237073e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005229254602454603\n",
      "Gradient for decoder.decoder.1.bias: 0.0004097996570635587\n",
      "Gradient for decoder.decoder.3.weight: 0.009760078974068165\n",
      "Gradient for decoder.decoder.3.bias: 8.451712246726473e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00037237818469293416\n",
      "Gradient for decoder.decoder.4.bias: 0.00030485462048090994\n",
      "Gradient for decoder.decoder.6.weight: 0.0006911720265634358\n",
      "Gradient for decoder.decoder.6.bias: 3.4389260690659285e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.005532956216484308\n",
      "Gradient for encoder.encoder.0.bias: 8.193839703962702e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.0005907203885726631\n",
      "Gradient for encoder.encoder.1.bias: 0.00042569221113808453\n",
      "Gradient for encoder.encoder.3.weight: 0.013193252496421337\n",
      "Gradient for encoder.encoder.3.bias: 1.2108640479180366e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0038421060889959335\n",
      "Gradient for encoder.encoder.4.bias: 0.0029721902683377266\n",
      "Gradient for encoder.mean.weight: 0.05286653712391853\n",
      "Gradient for encoder.mean.bias: 0.0016995781334117055\n",
      "Gradient for encoder.log_var.weight: 0.0263353418558836\n",
      "Gradient for encoder.log_var.bias: 0.0009918930009007454\n",
      "Gradient for decoder.decoder.0.weight: 0.01266486942768097\n",
      "Gradient for decoder.decoder.0.bias: 1.0794887206344583e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0006131157279014587\n",
      "Gradient for decoder.decoder.1.bias: 0.000531705969478935\n",
      "Gradient for decoder.decoder.3.weight: 0.01187131181359291\n",
      "Gradient for decoder.decoder.3.bias: 9.950527901647632e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.000534295744728297\n",
      "Gradient for decoder.decoder.4.bias: 0.0005137243424542248\n",
      "Gradient for decoder.decoder.6.weight: 0.0007608195883221924\n",
      "Gradient for decoder.decoder.6.bias: 3.814685624092817e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.00970672070980072\n",
      "Gradient for encoder.encoder.0.bias: 1.525340444230583e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0007503072265535593\n",
      "Gradient for encoder.encoder.1.bias: 0.000639562145806849\n",
      "Gradient for encoder.encoder.3.weight: 0.016726873815059662\n",
      "Gradient for encoder.encoder.3.bias: 1.3230593010060687e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.003276851959526539\n",
      "Gradient for encoder.encoder.4.bias: 0.002821831963956356\n",
      "Gradient for encoder.mean.weight: 0.04324968904256821\n",
      "Gradient for encoder.mean.bias: 0.0018142439657822251\n",
      "Gradient for encoder.log_var.weight: 0.0232535433024168\n",
      "Gradient for encoder.log_var.bias: 0.00107651820871979\n",
      "Gradient for decoder.decoder.0.weight: 0.009820538572967052\n",
      "Gradient for decoder.decoder.0.bias: 9.659775757064892e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.00046195159666240215\n",
      "Gradient for decoder.decoder.1.bias: 0.0003902204625774175\n",
      "Gradient for decoder.decoder.3.weight: 0.009206801652908325\n",
      "Gradient for decoder.decoder.3.bias: 8.067040785375568e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0003513045085128397\n",
      "Gradient for decoder.decoder.4.bias: 0.0003509101225063205\n",
      "Gradient for decoder.decoder.6.weight: 0.0007230471819639206\n",
      "Gradient for decoder.decoder.6.bias: 4.33465902460739e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.006364391651004553\n",
      "Gradient for encoder.encoder.0.bias: 9.257172285670467e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.0005660739843733609\n",
      "Gradient for encoder.encoder.1.bias: 0.0005186186754144728\n",
      "Gradient for encoder.encoder.3.weight: 0.012579234316945076\n",
      "Gradient for encoder.encoder.3.bias: 1.2261594517504193e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0036763022653758526\n",
      "Gradient for encoder.encoder.4.bias: 0.0026799573097378016\n",
      "Gradient for encoder.mean.weight: 0.047702692449092865\n",
      "Gradient for encoder.mean.bias: 0.0017442370299249887\n",
      "Gradient for encoder.log_var.weight: 0.026694875210523605\n",
      "Gradient for encoder.log_var.bias: 0.00125788152217865\n",
      "Gradient for decoder.decoder.0.weight: 0.012004004791378975\n",
      "Gradient for decoder.decoder.0.bias: 1.0033879283000147e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0006187712424434721\n",
      "Gradient for decoder.decoder.1.bias: 0.00047608898603357375\n",
      "Gradient for decoder.decoder.3.weight: 0.011975860223174095\n",
      "Gradient for decoder.decoder.3.bias: 9.030214076499732e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0004496346809901297\n",
      "Gradient for decoder.decoder.4.bias: 0.0004036117752548307\n",
      "Gradient for decoder.decoder.6.weight: 0.000755552900955081\n",
      "Gradient for decoder.decoder.6.bias: 4.2243340431014076e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.010375146754086018\n",
      "Gradient for encoder.encoder.0.bias: 1.2806282943811365e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.000718589115422219\n",
      "Gradient for encoder.encoder.1.bias: 0.0006312007317319512\n",
      "Gradient for encoder.encoder.3.weight: 0.015194532461464405\n",
      "Gradient for encoder.encoder.3.bias: 1.247246195212881e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.002779075875878334\n",
      "Gradient for encoder.encoder.4.bias: 0.0023229147773236036\n",
      "Gradient for encoder.mean.weight: 0.03531081601977348\n",
      "Gradient for encoder.mean.bias: 0.0017254955600947142\n",
      "Gradient for encoder.log_var.weight: 0.021521078422665596\n",
      "Gradient for encoder.log_var.bias: 0.0012286209966987371\n",
      "Gradient for decoder.decoder.0.weight: 0.010980745777487755\n",
      "Gradient for decoder.decoder.0.bias: 9.720804716728537e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005370421567931771\n",
      "Gradient for decoder.decoder.1.bias: 0.00044507617712952197\n",
      "Gradient for decoder.decoder.3.weight: 0.010177401825785637\n",
      "Gradient for decoder.decoder.3.bias: 7.251466788149585e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0003701747627928853\n",
      "Gradient for decoder.decoder.4.bias: 0.00032862182706594467\n",
      "Gradient for decoder.decoder.6.weight: 0.0008638399885967374\n",
      "Gradient for decoder.decoder.6.bias: 5.747180330217816e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.005129879806190729\n",
      "Gradient for encoder.encoder.0.bias: 8.180606365926213e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.0005224256310611963\n",
      "Gradient for encoder.encoder.1.bias: 0.0005147969350218773\n",
      "Gradient for encoder.encoder.3.weight: 0.011173338629305363\n",
      "Gradient for encoder.encoder.3.bias: 1.1421590062621334e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0032945345155894756\n",
      "Gradient for encoder.encoder.4.bias: 0.0027988723013550043\n",
      "Gradient for encoder.mean.weight: 0.04821242392063141\n",
      "Gradient for encoder.mean.bias: 0.0023685581982135773\n",
      "Gradient for encoder.log_var.weight: 0.031385745853185654\n",
      "Gradient for encoder.log_var.bias: 0.0013014255091547966\n",
      "Gradient for decoder.decoder.0.weight: 0.011786137707531452\n",
      "Gradient for decoder.decoder.0.bias: 1.0164359631747999e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0005586775951087475\n",
      "Gradient for decoder.decoder.1.bias: 0.0005101325223222375\n",
      "Gradient for decoder.decoder.3.weight: 0.010964103043079376\n",
      "Gradient for decoder.decoder.3.bias: 7.772347349055408e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0003805156738962978\n",
      "Gradient for decoder.decoder.4.bias: 0.0003282375691924244\n",
      "Gradient for decoder.decoder.6.weight: 0.0007084383396431804\n",
      "Gradient for decoder.decoder.6.bias: 3.822895814664662e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.005213320255279541\n",
      "Gradient for encoder.encoder.0.bias: 8.380805598118268e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.0006086102803237736\n",
      "Gradient for encoder.encoder.1.bias: 0.0005265647196210921\n",
      "Gradient for encoder.encoder.3.weight: 0.013260480016469955\n",
      "Gradient for encoder.encoder.3.bias: 1.0338885303440293e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.003049456747248769\n",
      "Gradient for encoder.encoder.4.bias: 0.002142920857295394\n",
      "Gradient for encoder.mean.weight: 0.04232623800635338\n",
      "Gradient for encoder.mean.bias: 0.0015580452745780349\n",
      "Gradient for encoder.log_var.weight: 0.024076979607343674\n",
      "Gradient for encoder.log_var.bias: 0.0008474664646200836\n",
      "Gradient for decoder.decoder.0.weight: 0.012734671123325825\n",
      "Gradient for decoder.decoder.0.bias: 1.0037891351455386e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0005945951561443508\n",
      "Gradient for decoder.decoder.1.bias: 0.0005200499435886741\n",
      "Gradient for decoder.decoder.3.weight: 0.012508251704275608\n",
      "Gradient for decoder.decoder.3.bias: 9.422341379350385e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0004559018125291914\n",
      "Gradient for decoder.decoder.4.bias: 0.0003949714300688356\n",
      "Gradient for decoder.decoder.6.weight: 0.0007578801014460623\n",
      "Gradient for decoder.decoder.6.bias: 4.138080112170428e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.0061469110660254955\n",
      "Gradient for encoder.encoder.0.bias: 8.377280640015083e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.0005295706214383245\n",
      "Gradient for encoder.encoder.1.bias: 0.0005183083121664822\n",
      "Gradient for encoder.encoder.3.weight: 0.011962780728936195\n",
      "Gradient for encoder.encoder.3.bias: 1.0478320988660528e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.003022917779162526\n",
      "Gradient for encoder.encoder.4.bias: 0.002162058837711811\n",
      "Gradient for encoder.mean.weight: 0.04163694754242897\n",
      "Gradient for encoder.mean.bias: 0.0014787915861234069\n",
      "Gradient for encoder.log_var.weight: 0.023921115323901176\n",
      "Gradient for encoder.log_var.bias: 0.001009455882012844\n",
      "Gradient for decoder.decoder.0.weight: 0.01155578438192606\n",
      "Gradient for decoder.decoder.0.bias: 1.0797947258556206e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0005214537959545851\n",
      "Gradient for decoder.decoder.1.bias: 0.0004539219371508807\n",
      "Gradient for decoder.decoder.3.weight: 0.010536261834204197\n",
      "Gradient for decoder.decoder.3.bias: 9.424508395916575e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00036793979234062135\n",
      "Gradient for decoder.decoder.4.bias: 0.0003245755797252059\n",
      "Gradient for decoder.decoder.6.weight: 0.0007421855116263032\n",
      "Gradient for decoder.decoder.6.bias: 4.184471254120581e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.0058966283686459064\n",
      "Gradient for encoder.encoder.0.bias: 7.656430177360729e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.00042339955689385533\n",
      "Gradient for encoder.encoder.1.bias: 0.000440513773355633\n",
      "Gradient for encoder.encoder.3.weight: 0.009349378757178783\n",
      "Gradient for encoder.encoder.3.bias: 9.511343102008851e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.0026957858353853226\n",
      "Gradient for encoder.encoder.4.bias: 0.001975851133465767\n",
      "Gradient for encoder.mean.weight: 0.04053372144699097\n",
      "Gradient for encoder.mean.bias: 0.0015000062994658947\n",
      "Gradient for encoder.log_var.weight: 0.021849164739251137\n",
      "Gradient for encoder.log_var.bias: 0.0009506067726761103\n",
      "Gradient for decoder.decoder.0.weight: 0.012139873579144478\n",
      "Gradient for decoder.decoder.0.bias: 1.0074193562692457e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0006239073700271547\n",
      "Gradient for decoder.decoder.1.bias: 0.0005187923670746386\n",
      "Gradient for decoder.decoder.3.weight: 0.01202482171356678\n",
      "Gradient for decoder.decoder.3.bias: 9.094991426650267e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00047214439837262034\n",
      "Gradient for decoder.decoder.4.bias: 0.0003863684833049774\n",
      "Gradient for decoder.decoder.6.weight: 0.0007747042691335082\n",
      "Gradient for decoder.decoder.6.bias: 4.542543683783151e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.008115067146718502\n",
      "Gradient for encoder.encoder.0.bias: 1.0454196536224813e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0005851347232237458\n",
      "Gradient for encoder.encoder.1.bias: 0.0005372076411731541\n",
      "Gradient for encoder.encoder.3.weight: 0.013263187371194363\n",
      "Gradient for encoder.encoder.3.bias: 1.3583521807358778e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0031349859200417995\n",
      "Gradient for encoder.encoder.4.bias: 0.0022546020336449146\n",
      "Gradient for encoder.mean.weight: 0.04347296059131622\n",
      "Gradient for encoder.mean.bias: 0.0016673292266204953\n",
      "Gradient for encoder.log_var.weight: 0.025433417409658432\n",
      "Gradient for encoder.log_var.bias: 0.0009884937899187207\n",
      "Gradient for decoder.decoder.0.weight: 0.010593355633318424\n",
      "Gradient for decoder.decoder.0.bias: 8.884500773964632e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005546435713768005\n",
      "Gradient for decoder.decoder.1.bias: 0.0004440080083440989\n",
      "Gradient for decoder.decoder.3.weight: 0.010105205699801445\n",
      "Gradient for decoder.decoder.3.bias: 8.114087179933449e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0003762473934330046\n",
      "Gradient for decoder.decoder.4.bias: 0.0003209653659723699\n",
      "Gradient for decoder.decoder.6.weight: 0.0007274253875948489\n",
      "Gradient for decoder.decoder.6.bias: 3.480950545053929e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.00512354914098978\n",
      "Gradient for encoder.encoder.0.bias: 8.543279798878256e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.0005526074091903865\n",
      "Gradient for encoder.encoder.1.bias: 0.0005903140990994871\n",
      "Gradient for encoder.encoder.3.weight: 0.011807304807007313\n",
      "Gradient for encoder.encoder.3.bias: 1.0408377631998533e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0036095832474529743\n",
      "Gradient for encoder.encoder.4.bias: 0.0023972976487129927\n",
      "Gradient for encoder.mean.weight: 0.05375935509800911\n",
      "Gradient for encoder.mean.bias: 0.0016380769666284323\n",
      "Gradient for encoder.log_var.weight: 0.027234112843871117\n",
      "Gradient for encoder.log_var.bias: 0.0009881634032353759\n",
      "Gradient for decoder.decoder.0.weight: 0.0121314013376832\n",
      "Gradient for decoder.decoder.0.bias: 1.0958103174862899e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.000635260425042361\n",
      "Gradient for decoder.decoder.1.bias: 0.0005194980767555535\n",
      "Gradient for decoder.decoder.3.weight: 0.011518692597746849\n",
      "Gradient for decoder.decoder.3.bias: 9.471341766431607e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0004565248382277787\n",
      "Gradient for decoder.decoder.4.bias: 0.0004474285233300179\n",
      "Gradient for decoder.decoder.6.weight: 0.0007260282291099429\n",
      "Gradient for decoder.decoder.6.bias: 3.762776032090187e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.007371570449322462\n",
      "Gradient for encoder.encoder.0.bias: 9.684293297840263e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.0005106371245346963\n",
      "Gradient for encoder.encoder.1.bias: 0.0003916287678293884\n",
      "Gradient for encoder.encoder.3.weight: 0.011493354104459286\n",
      "Gradient for encoder.encoder.3.bias: 1.0580782083824403e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.002870213473215699\n",
      "Gradient for encoder.encoder.4.bias: 0.002209011698141694\n",
      "Gradient for encoder.mean.weight: 0.04072139039635658\n",
      "Gradient for encoder.mean.bias: 0.0015340987592935562\n",
      "Gradient for encoder.log_var.weight: 0.02429156005382538\n",
      "Gradient for encoder.log_var.bias: 0.0010824725031852722\n",
      "Gradient for decoder.decoder.0.weight: 0.010555778630077839\n",
      "Gradient for decoder.decoder.0.bias: 8.806856632848081e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005099392728880048\n",
      "Gradient for decoder.decoder.1.bias: 0.00042981820297427475\n",
      "Gradient for decoder.decoder.3.weight: 0.009919057600200176\n",
      "Gradient for decoder.decoder.3.bias: 8.185153943518486e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00037768943002447486\n",
      "Gradient for decoder.decoder.4.bias: 0.00034267656155861914\n",
      "Gradient for decoder.decoder.6.weight: 0.0007140619563870132\n",
      "Gradient for decoder.decoder.6.bias: 3.457885395619087e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training VAE Epoch:  62%|██████▏   | 49/79 [00:00<00:00, 71.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient for encoder.encoder.0.weight: 0.009082846343517303\n",
      "Gradient for encoder.encoder.0.bias: 1.3250934204067644e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0006182182114571333\n",
      "Gradient for encoder.encoder.1.bias: 0.0006064900080673397\n",
      "Gradient for encoder.encoder.3.weight: 0.014285893179476261\n",
      "Gradient for encoder.encoder.3.bias: 1.3783167662761997e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.003586615901440382\n",
      "Gradient for encoder.encoder.4.bias: 0.003082017181441188\n",
      "Gradient for encoder.mean.weight: 0.050815779715776443\n",
      "Gradient for encoder.mean.bias: 0.002300839638337493\n",
      "Gradient for encoder.log_var.weight: 0.034495361149311066\n",
      "Gradient for encoder.log_var.bias: 0.0013650949113070965\n",
      "Gradient for decoder.decoder.0.weight: 0.009306301362812519\n",
      "Gradient for decoder.decoder.0.bias: 7.764319742697978e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0004539786896202713\n",
      "Gradient for decoder.decoder.1.bias: 0.00037418509600684047\n",
      "Gradient for decoder.decoder.3.weight: 0.008635425008833408\n",
      "Gradient for decoder.decoder.3.bias: 6.582391576248625e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0003082941984757781\n",
      "Gradient for decoder.decoder.4.bias: 0.0002798848145175725\n",
      "Gradient for decoder.decoder.6.weight: 0.0007495164172723889\n",
      "Gradient for decoder.decoder.6.bias: 3.707392534124665e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.0061826324090361595\n",
      "Gradient for encoder.encoder.0.bias: 9.784830931613975e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.00047935431939549744\n",
      "Gradient for encoder.encoder.1.bias: 0.00042901397682726383\n",
      "Gradient for encoder.encoder.3.weight: 0.010590748861432076\n",
      "Gradient for encoder.encoder.3.bias: 1.0956138080109312e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.002535768784582615\n",
      "Gradient for encoder.encoder.4.bias: 0.002054614247754216\n",
      "Gradient for encoder.mean.weight: 0.03661924600601196\n",
      "Gradient for encoder.mean.bias: 0.001589388120919466\n",
      "Gradient for encoder.log_var.weight: 0.01897216960787773\n",
      "Gradient for encoder.log_var.bias: 0.0009152929997071624\n",
      "Gradient for decoder.decoder.0.weight: 0.010181870311498642\n",
      "Gradient for decoder.decoder.0.bias: 8.755710045882381e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.000493528030347079\n",
      "Gradient for decoder.decoder.1.bias: 0.000404686841648072\n",
      "Gradient for decoder.decoder.3.weight: 0.009522799402475357\n",
      "Gradient for decoder.decoder.3.bias: 8.183478200640693e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00036766903940588236\n",
      "Gradient for decoder.decoder.4.bias: 0.00031836293055675924\n",
      "Gradient for decoder.decoder.6.weight: 0.0007064907695166767\n",
      "Gradient for decoder.decoder.6.bias: 4.0276474464917555e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training VAE Epoch:  72%|███████▏  | 57/79 [00:00<00:00, 72.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient for encoder.encoder.0.weight: 0.005735191982239485\n",
      "Gradient for encoder.encoder.0.bias: 9.371452398820868e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.0005617033457383513\n",
      "Gradient for encoder.encoder.1.bias: 0.0004926396650262177\n",
      "Gradient for encoder.encoder.3.weight: 0.012821567244827747\n",
      "Gradient for encoder.encoder.3.bias: 1.0573150688308885e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.003292282111942768\n",
      "Gradient for encoder.encoder.4.bias: 0.0022105162497609854\n",
      "Gradient for encoder.mean.weight: 0.04618244618177414\n",
      "Gradient for encoder.mean.bias: 0.0016601176466792822\n",
      "Gradient for encoder.log_var.weight: 0.025408875197172165\n",
      "Gradient for encoder.log_var.bias: 0.0009640210191719234\n",
      "Gradient for decoder.decoder.0.weight: 0.010248466394841671\n",
      "Gradient for decoder.decoder.0.bias: 8.100639603547677e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005178083083592355\n",
      "Gradient for decoder.decoder.1.bias: 0.0004499334027059376\n",
      "Gradient for decoder.decoder.3.weight: 0.009654979221522808\n",
      "Gradient for decoder.decoder.3.bias: 7.685103942112192e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00032650900539010763\n",
      "Gradient for decoder.decoder.4.bias: 0.0003007453342434019\n",
      "Gradient for decoder.decoder.6.weight: 0.0006887700874358416\n",
      "Gradient for decoder.decoder.6.bias: 3.774399374378845e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.007192570250481367\n",
      "Gradient for encoder.encoder.0.bias: 1.1436233036954402e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0007501687505282462\n",
      "Gradient for encoder.encoder.1.bias: 0.0006175911985337734\n",
      "Gradient for encoder.encoder.3.weight: 0.01581559143960476\n",
      "Gradient for encoder.encoder.3.bias: 1.3229606299347552e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0044492571614682674\n",
      "Gradient for encoder.encoder.4.bias: 0.0028766056057065725\n",
      "Gradient for encoder.mean.weight: 0.06197979301214218\n",
      "Gradient for encoder.mean.bias: 0.002104667015373707\n",
      "Gradient for encoder.log_var.weight: 0.03191778063774109\n",
      "Gradient for encoder.log_var.bias: 0.0012104276102036238\n",
      "Gradient for decoder.decoder.0.weight: 0.011343870311975479\n",
      "Gradient for decoder.decoder.0.bias: 8.41215777591664e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005897476221434772\n",
      "Gradient for decoder.decoder.1.bias: 0.0004610238829627633\n",
      "Gradient for decoder.decoder.3.weight: 0.01130321342498064\n",
      "Gradient for decoder.decoder.3.bias: 7.6205979027133e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0004158814263064414\n",
      "Gradient for decoder.decoder.4.bias: 0.0003273123293183744\n",
      "Gradient for decoder.decoder.6.weight: 0.0007323077297769487\n",
      "Gradient for decoder.decoder.6.bias: 3.488019501673989e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.004029697738587856\n",
      "Gradient for encoder.encoder.0.bias: 7.274698204939867e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.0006591157871298492\n",
      "Gradient for encoder.encoder.1.bias: 0.0006534627755172551\n",
      "Gradient for encoder.encoder.3.weight: 0.01421426422894001\n",
      "Gradient for encoder.encoder.3.bias: 1.1571555519340748e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.004746413789689541\n",
      "Gradient for encoder.encoder.4.bias: 0.003168113064020872\n",
      "Gradient for encoder.mean.weight: 0.06941484659910202\n",
      "Gradient for encoder.mean.bias: 0.0021079087164252996\n",
      "Gradient for encoder.log_var.weight: 0.03600769862532616\n",
      "Gradient for encoder.log_var.bias: 0.0013615740463137627\n",
      "Gradient for decoder.decoder.0.weight: 0.014197937212884426\n",
      "Gradient for decoder.decoder.0.bias: 1.0798825722524441e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0006871063378639519\n",
      "Gradient for decoder.decoder.1.bias: 0.0006016786792315543\n",
      "Gradient for decoder.decoder.3.weight: 0.013801165856420994\n",
      "Gradient for decoder.decoder.3.bias: 1.1654537057648184e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.000684470112901181\n",
      "Gradient for decoder.decoder.4.bias: 0.0007617456722073257\n",
      "Gradient for decoder.decoder.6.weight: 0.0008763501537032425\n",
      "Gradient for decoder.decoder.6.bias: 6.317880615824834e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.005841560196131468\n",
      "Gradient for encoder.encoder.0.bias: 9.485934607256219e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.0004058636259287596\n",
      "Gradient for encoder.encoder.1.bias: 0.00045521126594394445\n",
      "Gradient for encoder.encoder.3.weight: 0.008942675776779652\n",
      "Gradient for encoder.encoder.3.bias: 1.0829129259981585e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.002929308218881488\n",
      "Gradient for encoder.encoder.4.bias: 0.002326852409169078\n",
      "Gradient for encoder.mean.weight: 0.040818702429533005\n",
      "Gradient for encoder.mean.bias: 0.001795416814275086\n",
      "Gradient for encoder.log_var.weight: 0.026846593245863914\n",
      "Gradient for encoder.log_var.bias: 0.0010496167233213782\n",
      "Gradient for decoder.decoder.0.weight: 0.011063991114497185\n",
      "Gradient for decoder.decoder.0.bias: 9.93278168048839e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005667521036230028\n",
      "Gradient for decoder.decoder.1.bias: 0.00045922258868813515\n",
      "Gradient for decoder.decoder.3.weight: 0.010720299556851387\n",
      "Gradient for decoder.decoder.3.bias: 8.554962988016612e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.000510634679812938\n",
      "Gradient for decoder.decoder.4.bias: 0.0005392899620346725\n",
      "Gradient for decoder.decoder.6.weight: 0.0007664705044589937\n",
      "Gradient for decoder.decoder.6.bias: 4.822831033379771e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.0055716936476528645\n",
      "Gradient for encoder.encoder.0.bias: 8.682169566620601e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.00048265824443660676\n",
      "Gradient for encoder.encoder.1.bias: 0.000537657062523067\n",
      "Gradient for encoder.encoder.3.weight: 0.01074986532330513\n",
      "Gradient for encoder.encoder.3.bias: 9.720217686304267e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.0031139703933149576\n",
      "Gradient for encoder.encoder.4.bias: 0.002211051294580102\n",
      "Gradient for encoder.mean.weight: 0.04452141374349594\n",
      "Gradient for encoder.mean.bias: 0.0016720499843358994\n",
      "Gradient for encoder.log_var.weight: 0.02353627420961857\n",
      "Gradient for encoder.log_var.bias: 0.0010446843225508928\n",
      "Gradient for decoder.decoder.0.weight: 0.011784831993281841\n",
      "Gradient for decoder.decoder.0.bias: 9.293674857469014e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0006418860284611583\n",
      "Gradient for decoder.decoder.1.bias: 0.000470715225674212\n",
      "Gradient for decoder.decoder.3.weight: 0.011518968269228935\n",
      "Gradient for decoder.decoder.3.bias: 7.428669485110007e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0004530271689873189\n",
      "Gradient for decoder.decoder.4.bias: 0.0003873255045618862\n",
      "Gradient for decoder.decoder.6.weight: 0.000775256659835577\n",
      "Gradient for decoder.decoder.6.bias: 4.3252053728792816e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.005517967976629734\n",
      "Gradient for encoder.encoder.0.bias: 9.202667274055276e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.0005180833977647126\n",
      "Gradient for encoder.encoder.1.bias: 0.0006316841463558376\n",
      "Gradient for encoder.encoder.3.weight: 0.011113147251307964\n",
      "Gradient for encoder.encoder.3.bias: 1.198069421448622e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0038277050480246544\n",
      "Gradient for encoder.encoder.4.bias: 0.0027529187500476837\n",
      "Gradient for encoder.mean.weight: 0.056907519698143005\n",
      "Gradient for encoder.mean.bias: 0.002065665554255247\n",
      "Gradient for encoder.log_var.weight: 0.024379877373576164\n",
      "Gradient for encoder.log_var.bias: 0.0012610993580892682\n",
      "Gradient for decoder.decoder.0.weight: 0.010690885595977306\n",
      "Gradient for decoder.decoder.0.bias: 9.396277506068529e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005290238186717033\n",
      "Gradient for decoder.decoder.1.bias: 0.0005343268276192248\n",
      "Gradient for decoder.decoder.3.weight: 0.01001348253339529\n",
      "Gradient for decoder.decoder.3.bias: 8.749796026608081e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00045001806574873626\n",
      "Gradient for decoder.decoder.4.bias: 0.0004678296681959182\n",
      "Gradient for decoder.decoder.6.weight: 0.0007073096930980682\n",
      "Gradient for decoder.decoder.6.bias: 4.083025487489067e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.012615525163710117\n",
      "Gradient for encoder.encoder.0.bias: 1.8844883986623984e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0006307217408902943\n",
      "Gradient for encoder.encoder.1.bias: 0.0005125981406308711\n",
      "Gradient for encoder.encoder.3.weight: 0.01421266607940197\n",
      "Gradient for encoder.encoder.3.bias: 1.5412850162821456e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0035371375270187855\n",
      "Gradient for encoder.encoder.4.bias: 0.003029712475836277\n",
      "Gradient for encoder.mean.weight: 0.0525902695953846\n",
      "Gradient for encoder.mean.bias: 0.0021049969363957644\n",
      "Gradient for encoder.log_var.weight: 0.02720918506383896\n",
      "Gradient for encoder.log_var.bias: 0.001295342925004661\n",
      "Gradient for decoder.decoder.0.weight: 0.008929749950766563\n",
      "Gradient for decoder.decoder.0.bias: 9.309022303005676e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.00043804896995425224\n",
      "Gradient for decoder.decoder.1.bias: 0.00040866094059310853\n",
      "Gradient for decoder.decoder.3.weight: 0.008367331698536873\n",
      "Gradient for decoder.decoder.3.bias: 9.641609038935073e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00046104638022370636\n",
      "Gradient for decoder.decoder.4.bias: 0.0005506579182110727\n",
      "Gradient for decoder.decoder.6.weight: 0.0007715129177086055\n",
      "Gradient for decoder.decoder.6.bias: 5.643625991069712e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.004282222595065832\n",
      "Gradient for encoder.encoder.0.bias: 7.381748858004133e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.0004608796734828502\n",
      "Gradient for encoder.encoder.1.bias: 0.00042697659227997065\n",
      "Gradient for encoder.encoder.3.weight: 0.009908223524689674\n",
      "Gradient for encoder.encoder.3.bias: 1.0814928813607239e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0033963073510676622\n",
      "Gradient for encoder.encoder.4.bias: 0.0021617801394313574\n",
      "Gradient for encoder.mean.weight: 0.04618116468191147\n",
      "Gradient for encoder.mean.bias: 0.0016741716535761952\n",
      "Gradient for encoder.log_var.weight: 0.02933034859597683\n",
      "Gradient for encoder.log_var.bias: 0.0010501185897737741\n",
      "Gradient for decoder.decoder.0.weight: 0.012319429777562618\n",
      "Gradient for decoder.decoder.0.bias: 1.0126402494314846e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0005963164148852229\n",
      "Gradient for decoder.decoder.1.bias: 0.0005061888368800282\n",
      "Gradient for decoder.decoder.3.weight: 0.011595976538956165\n",
      "Gradient for decoder.decoder.3.bias: 9.098818920527663e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.000475577253382653\n",
      "Gradient for decoder.decoder.4.bias: 0.000424580997787416\n",
      "Gradient for decoder.decoder.6.weight: 0.0008784476085565984\n",
      "Gradient for decoder.decoder.6.bias: 5.817947385367006e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.005690279416739941\n",
      "Gradient for encoder.encoder.0.bias: 8.482823818378726e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.0004471132706385106\n",
      "Gradient for encoder.encoder.1.bias: 0.0003916559217032045\n",
      "Gradient for encoder.encoder.3.weight: 0.009458664804697037\n",
      "Gradient for encoder.encoder.3.bias: 1.0284852136610567e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.002553593600168824\n",
      "Gradient for encoder.encoder.4.bias: 0.002225651405751705\n",
      "Gradient for encoder.mean.weight: 0.03631136193871498\n",
      "Gradient for encoder.mean.bias: 0.0018774515483528376\n",
      "Gradient for encoder.log_var.weight: 0.021229540929198265\n",
      "Gradient for encoder.log_var.bias: 0.001088776160031557\n",
      "Gradient for decoder.decoder.0.weight: 0.01200226228684187\n",
      "Gradient for decoder.decoder.0.bias: 1.1507932801135823e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.000565592257771641\n",
      "Gradient for decoder.decoder.1.bias: 0.0005066456506028771\n",
      "Gradient for decoder.decoder.3.weight: 0.01151230651885271\n",
      "Gradient for decoder.decoder.3.bias: 1.0701500796628238e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0003896141133736819\n",
      "Gradient for decoder.decoder.4.bias: 0.00037521013291552663\n",
      "Gradient for decoder.decoder.6.weight: 0.0007085239631123841\n",
      "Gradient for decoder.decoder.6.bias: 3.944445415982045e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.008541771210730076\n",
      "Gradient for encoder.encoder.0.bias: 1.0470786564187318e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0005206743953749537\n",
      "Gradient for encoder.encoder.1.bias: 0.00048483518185094\n",
      "Gradient for encoder.encoder.3.weight: 0.011963734403252602\n",
      "Gradient for encoder.encoder.3.bias: 1.2781313507570502e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.003268931061029434\n",
      "Gradient for encoder.encoder.4.bias: 0.0027135189156979322\n",
      "Gradient for encoder.mean.weight: 0.0447036474943161\n",
      "Gradient for encoder.mean.bias: 0.002200106857344508\n",
      "Gradient for encoder.log_var.weight: 0.025408146902918816\n",
      "Gradient for encoder.log_var.bias: 0.0012224725214764476\n",
      "Gradient for decoder.decoder.0.weight: 0.011739366687834263\n",
      "Gradient for decoder.decoder.0.bias: 9.796331107425615e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005723200156353414\n",
      "Gradient for decoder.decoder.1.bias: 0.00047791539691388607\n",
      "Gradient for decoder.decoder.3.weight: 0.01065498124808073\n",
      "Gradient for decoder.decoder.3.bias: 8.352037117465017e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.000476458779303357\n",
      "Gradient for decoder.decoder.4.bias: 0.00048378267092630267\n",
      "Gradient for decoder.decoder.6.weight: 0.0008090880583040416\n",
      "Gradient for decoder.decoder.6.bias: 4.874306250712834e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.0055077257566154\n",
      "Gradient for encoder.encoder.0.bias: 9.292597941135128e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.00046126337838359177\n",
      "Gradient for encoder.encoder.1.bias: 0.0004446461680345237\n",
      "Gradient for encoder.encoder.3.weight: 0.010176709853112698\n",
      "Gradient for encoder.encoder.3.bias: 1.0416162377069327e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.003245553933084011\n",
      "Gradient for encoder.encoder.4.bias: 0.002430990571156144\n",
      "Gradient for encoder.mean.weight: 0.04725808650255203\n",
      "Gradient for encoder.mean.bias: 0.001778123783878982\n",
      "Gradient for encoder.log_var.weight: 0.022908544167876244\n",
      "Gradient for encoder.log_var.bias: 0.0011755075538530946\n",
      "Gradient for decoder.decoder.0.weight: 0.010583431459963322\n",
      "Gradient for decoder.decoder.0.bias: 8.820816299603962e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.00047892623115330935\n",
      "Gradient for decoder.decoder.1.bias: 0.0004202385025564581\n",
      "Gradient for decoder.decoder.3.weight: 0.010252263396978378\n",
      "Gradient for decoder.decoder.3.bias: 9.687619456633101e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0005220361053943634\n",
      "Gradient for decoder.decoder.4.bias: 0.0005945584853179753\n",
      "Gradient for decoder.decoder.6.weight: 0.000722378259524703\n",
      "Gradient for decoder.decoder.6.bias: 4.7188539610942826e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.007750690449029207\n",
      "Gradient for encoder.encoder.0.bias: 1.2760944211043235e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0004380419268272817\n",
      "Gradient for encoder.encoder.1.bias: 0.0003981593472417444\n",
      "Gradient for encoder.encoder.3.weight: 0.0090545155107975\n",
      "Gradient for encoder.encoder.3.bias: 1.1494779433851576e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0026463621761649847\n",
      "Gradient for encoder.encoder.4.bias: 0.0023204174358397722\n",
      "Gradient for encoder.mean.weight: 0.036699920892715454\n",
      "Gradient for encoder.mean.bias: 0.0017156600952148438\n",
      "Gradient for encoder.log_var.weight: 0.020077066496014595\n",
      "Gradient for encoder.log_var.bias: 0.0011708494275808334\n",
      "Gradient for decoder.decoder.0.weight: 0.009670530445873737\n",
      "Gradient for decoder.decoder.0.bias: 7.84468184855669e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0004858986649196595\n",
      "Gradient for decoder.decoder.1.bias: 0.0004150642198510468\n",
      "Gradient for decoder.decoder.3.weight: 0.009199243038892746\n",
      "Gradient for decoder.decoder.3.bias: 7.779812905006622e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00040073320269584656\n",
      "Gradient for decoder.decoder.4.bias: 0.0004475032619666308\n",
      "Gradient for decoder.decoder.6.weight: 0.0007219157996587455\n",
      "Gradient for decoder.decoder.6.bias: 4.3428593926364556e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.005560167133808136\n",
      "Gradient for encoder.encoder.0.bias: 1.0236948441710858e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0005334732122719288\n",
      "Gradient for encoder.encoder.1.bias: 0.0005827184650115669\n",
      "Gradient for encoder.encoder.3.weight: 0.012168754823505878\n",
      "Gradient for encoder.encoder.3.bias: 1.1903843188942886e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.003972695674747229\n",
      "Gradient for encoder.encoder.4.bias: 0.0029131078626960516\n",
      "Gradient for encoder.mean.weight: 0.055694788694381714\n",
      "Gradient for encoder.mean.bias: 0.002259203465655446\n",
      "Gradient for encoder.log_var.weight: 0.03185877203941345\n",
      "Gradient for encoder.log_var.bias: 0.0014243737095966935\n",
      "Gradient for decoder.decoder.0.weight: 0.010544800199568272\n",
      "Gradient for decoder.decoder.0.bias: 8.444774046711956e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005195845733396709\n",
      "Gradient for decoder.decoder.1.bias: 0.0004491845902521163\n",
      "Gradient for decoder.decoder.3.weight: 0.010351776145398617\n",
      "Gradient for decoder.decoder.3.bias: 9.297960318344067e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.000542330089956522\n",
      "Gradient for decoder.decoder.4.bias: 0.0006172313005663455\n",
      "Gradient for decoder.decoder.6.weight: 0.0008228673250414431\n",
      "Gradient for decoder.decoder.6.bias: 6.308950105449185e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training VAE Epoch:  82%|████████▏ | 65/79 [00:01<00:00, 73.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient for encoder.encoder.0.weight: 0.007233207114040852\n",
      "Gradient for encoder.encoder.0.bias: 9.434549495812572e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.0004532422753982246\n",
      "Gradient for encoder.encoder.1.bias: 0.0004185324360150844\n",
      "Gradient for encoder.encoder.3.weight: 0.009986862540245056\n",
      "Gradient for encoder.encoder.3.bias: 9.47329992229129e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.002410258399322629\n",
      "Gradient for encoder.encoder.4.bias: 0.0016824223566800356\n",
      "Gradient for encoder.mean.weight: 0.03413179889321327\n",
      "Gradient for encoder.mean.bias: 0.0011891514295712113\n",
      "Gradient for encoder.log_var.weight: 0.021019479259848595\n",
      "Gradient for encoder.log_var.bias: 0.0008349413983523846\n",
      "Gradient for decoder.decoder.0.weight: 0.011935709044337273\n",
      "Gradient for decoder.decoder.0.bias: 9.316454552266151e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005877952789887786\n",
      "Gradient for decoder.decoder.1.bias: 0.00046137417666614056\n",
      "Gradient for decoder.decoder.3.weight: 0.010935421101748943\n",
      "Gradient for decoder.decoder.3.bias: 7.729091672237232e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0004094694450031966\n",
      "Gradient for decoder.decoder.4.bias: 0.0003481907770037651\n",
      "Gradient for decoder.decoder.6.weight: 0.0007333612302318215\n",
      "Gradient for decoder.decoder.6.bias: 3.566548912203871e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.005837776232510805\n",
      "Gradient for encoder.encoder.0.bias: 8.793201410062235e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.00040784775046631694\n",
      "Gradient for encoder.encoder.1.bias: 0.0004313969111535698\n",
      "Gradient for encoder.encoder.3.weight: 0.009932341054081917\n",
      "Gradient for encoder.encoder.3.bias: 1.0012527612568434e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0024581782054156065\n",
      "Gradient for encoder.encoder.4.bias: 0.001889131381176412\n",
      "Gradient for encoder.mean.weight: 0.035459958016872406\n",
      "Gradient for encoder.mean.bias: 0.001479785074479878\n",
      "Gradient for encoder.log_var.weight: 0.018778258934617043\n",
      "Gradient for encoder.log_var.bias: 0.0009837845573201776\n",
      "Gradient for decoder.decoder.0.weight: 0.00995171070098877\n",
      "Gradient for decoder.decoder.0.bias: 9.436993547717876e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005116275860927999\n",
      "Gradient for decoder.decoder.1.bias: 0.0004380852624308318\n",
      "Gradient for decoder.decoder.3.weight: 0.009616591036319733\n",
      "Gradient for decoder.decoder.3.bias: 8.883191404684965e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0003551499976310879\n",
      "Gradient for decoder.decoder.4.bias: 0.0003240516234654933\n",
      "Gradient for decoder.decoder.6.weight: 0.0007580609526485205\n",
      "Gradient for decoder.decoder.6.bias: 4.4420019548852e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.0048084864392876625\n",
      "Gradient for encoder.encoder.0.bias: 7.862311496298346e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.0004450063861440867\n",
      "Gradient for encoder.encoder.1.bias: 0.0004977593780495226\n",
      "Gradient for encoder.encoder.3.weight: 0.009526213631033897\n",
      "Gradient for encoder.encoder.3.bias: 9.684930635245337e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.0029455660842359066\n",
      "Gradient for encoder.encoder.4.bias: 0.0018030647188425064\n",
      "Gradient for encoder.mean.weight: 0.04333532601594925\n",
      "Gradient for encoder.mean.bias: 0.0014394050231203437\n",
      "Gradient for encoder.log_var.weight: 0.024474825710058212\n",
      "Gradient for encoder.log_var.bias: 0.0009603529470041394\n",
      "Gradient for decoder.decoder.0.weight: 0.012333136051893234\n",
      "Gradient for decoder.decoder.0.bias: 1.0409444139991564e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0005912409978918731\n",
      "Gradient for decoder.decoder.1.bias: 0.0004959477810189128\n",
      "Gradient for decoder.decoder.3.weight: 0.0112479068338871\n",
      "Gradient for decoder.decoder.3.bias: 9.545714219072465e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0004855523002333939\n",
      "Gradient for decoder.decoder.4.bias: 0.0004551177844405174\n",
      "Gradient for decoder.decoder.6.weight: 0.0007849446265026927\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training VAE Epoch:  92%|█████████▏| 73/79 [00:01<00:00, 74.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient for decoder.decoder.6.bias: 4.589705713442527e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.005996400956064463\n",
      "Gradient for encoder.encoder.0.bias: 9.200724383762182e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.00042911816854029894\n",
      "Gradient for encoder.encoder.1.bias: 0.0005000774981454015\n",
      "Gradient for encoder.encoder.3.weight: 0.009235244244337082\n",
      "Gradient for encoder.encoder.3.bias: 9.43380373819025e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.0022751614451408386\n",
      "Gradient for encoder.encoder.4.bias: 0.001962431240826845\n",
      "Gradient for encoder.mean.weight: 0.03589390590786934\n",
      "Gradient for encoder.mean.bias: 0.0016283501172438264\n",
      "Gradient for encoder.log_var.weight: 0.01764298416674137\n",
      "Gradient for encoder.log_var.bias: 0.0011433628387749195\n",
      "Gradient for decoder.decoder.0.weight: 0.009373761713504791\n",
      "Gradient for decoder.decoder.0.bias: 8.290787500975227e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.00045375589979812503\n",
      "Gradient for decoder.decoder.1.bias: 0.00037662973045371473\n",
      "Gradient for decoder.decoder.3.weight: 0.008772104978561401\n",
      "Gradient for decoder.decoder.3.bias: 7.558242920424618e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0003974934224970639\n",
      "Gradient for decoder.decoder.4.bias: 0.0004253207298461348\n",
      "Gradient for decoder.decoder.6.weight: 0.000711877248249948\n",
      "Gradient for decoder.decoder.6.bias: 4.336592246545479e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.0076034050434827805\n",
      "Gradient for encoder.encoder.0.bias: 9.770765793670755e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.0003879311843775213\n",
      "Gradient for encoder.encoder.1.bias: 0.00037135989987291396\n",
      "Gradient for encoder.encoder.3.weight: 0.00850694254040718\n",
      "Gradient for encoder.encoder.3.bias: 9.986456800392673e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.002460259711369872\n",
      "Gradient for encoder.encoder.4.bias: 0.0020935949869453907\n",
      "Gradient for encoder.mean.weight: 0.038081780076026917\n",
      "Gradient for encoder.mean.bias: 0.0018032307270914316\n",
      "Gradient for encoder.log_var.weight: 0.020447278395295143\n",
      "Gradient for encoder.log_var.bias: 0.0010792298708111048\n",
      "Gradient for decoder.decoder.0.weight: 0.010708420537412167\n",
      "Gradient for decoder.decoder.0.bias: 9.277299067855793e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005700559122487903\n",
      "Gradient for decoder.decoder.1.bias: 0.0004311702505219728\n",
      "Gradient for decoder.decoder.3.weight: 0.010319137945771217\n",
      "Gradient for decoder.decoder.3.bias: 9.848561549619106e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0003827413893304765\n",
      "Gradient for decoder.decoder.4.bias: 0.00031617071363143623\n",
      "Gradient for decoder.decoder.6.weight: 0.0007047030958347023\n",
      "Gradient for decoder.decoder.6.bias: 3.384100637049414e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.005772958509624004\n",
      "Gradient for encoder.encoder.0.bias: 9.044475238195737e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.0004468602710403502\n",
      "Gradient for encoder.encoder.1.bias: 0.0005020895041525364\n",
      "Gradient for encoder.encoder.3.weight: 0.00996362790465355\n",
      "Gradient for encoder.encoder.3.bias: 9.031172337747861e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.0023048575967550278\n",
      "Gradient for encoder.encoder.4.bias: 0.001934268162585795\n",
      "Gradient for encoder.mean.weight: 0.0327693447470665\n",
      "Gradient for encoder.mean.bias: 0.0015804704744368792\n",
      "Gradient for encoder.log_var.weight: 0.020050624385476112\n",
      "Gradient for encoder.log_var.bias: 0.0010320264846086502\n",
      "Gradient for decoder.decoder.0.weight: 0.010137176141142845\n",
      "Gradient for decoder.decoder.0.bias: 8.968219916694053e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005330902640707791\n",
      "Gradient for decoder.decoder.1.bias: 0.0004340654704719782\n",
      "Gradient for decoder.decoder.3.weight: 0.010201209224760532\n",
      "Gradient for decoder.decoder.3.bias: 7.684154007536748e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0003909515216946602\n",
      "Gradient for decoder.decoder.4.bias: 0.0003542538615874946\n",
      "Gradient for decoder.decoder.6.weight: 0.0007872854475863278\n",
      "Gradient for decoder.decoder.6.bias: 5.185977352084592e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.007316067349165678\n",
      "Gradient for encoder.encoder.0.bias: 1.2918878640466591e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0005184569745324552\n",
      "Gradient for encoder.encoder.1.bias: 0.00047261567669920623\n",
      "Gradient for encoder.encoder.3.weight: 0.012249931693077087\n",
      "Gradient for encoder.encoder.3.bias: 1.0811546796718474e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0027347595896571875\n",
      "Gradient for encoder.encoder.4.bias: 0.002227600198239088\n",
      "Gradient for encoder.mean.weight: 0.040621016174554825\n",
      "Gradient for encoder.mean.bias: 0.0019056269666180015\n",
      "Gradient for encoder.log_var.weight: 0.026067985221743584\n",
      "Gradient for encoder.log_var.bias: 0.0012370714684948325\n",
      "Gradient for decoder.decoder.0.weight: 0.010315800085663795\n",
      "Gradient for decoder.decoder.0.bias: 7.82669276611081e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005062794662080705\n",
      "Gradient for decoder.decoder.1.bias: 0.00043179059866815805\n",
      "Gradient for decoder.decoder.3.weight: 0.009904786013066769\n",
      "Gradient for decoder.decoder.3.bias: 7.371195320793333e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00035547715378925204\n",
      "Gradient for decoder.decoder.4.bias: 0.00033597080619074404\n",
      "Gradient for decoder.decoder.6.weight: 0.0007115252665244043\n",
      "Gradient for decoder.decoder.6.bias: 3.4468568628653884e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.004993514157831669\n",
      "Gradient for encoder.encoder.0.bias: 7.562715211018034e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.00037628819700330496\n",
      "Gradient for encoder.encoder.1.bias: 0.00045228988165035844\n",
      "Gradient for encoder.encoder.3.weight: 0.008984429761767387\n",
      "Gradient for encoder.encoder.3.bias: 9.372974618671037e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.002895897952839732\n",
      "Gradient for encoder.encoder.4.bias: 0.0016091368161141872\n",
      "Gradient for encoder.mean.weight: 0.04125096648931503\n",
      "Gradient for encoder.mean.bias: 0.0012150842230767012\n",
      "Gradient for encoder.log_var.weight: 0.024173254147171974\n",
      "Gradient for encoder.log_var.bias: 0.0008226921781897545\n",
      "Gradient for decoder.decoder.0.weight: 0.012136846780776978\n",
      "Gradient for decoder.decoder.0.bias: 1.0509167841510347e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0006118532619439065\n",
      "Gradient for decoder.decoder.1.bias: 0.0005317346076481044\n",
      "Gradient for decoder.decoder.3.weight: 0.011632153764367104\n",
      "Gradient for decoder.decoder.3.bias: 8.283779218132281e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0004582030524034053\n",
      "Gradient for decoder.decoder.4.bias: 0.00044610959594137967\n",
      "Gradient for decoder.decoder.6.weight: 0.000773638894315809\n",
      "Gradient for decoder.decoder.6.bias: 4.8542628064751625e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.011051010340452194\n",
      "Gradient for encoder.encoder.0.bias: 1.629851288653672e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0005263230414129794\n",
      "Gradient for encoder.encoder.1.bias: 0.0005020450334995985\n",
      "Gradient for encoder.encoder.3.weight: 0.011076833121478558\n",
      "Gradient for encoder.encoder.3.bias: 1.1216000350700028e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.002482200041413307\n",
      "Gradient for encoder.encoder.4.bias: 0.0018435186939314008\n",
      "Gradient for encoder.mean.weight: 0.03631545975804329\n",
      "Gradient for encoder.mean.bias: 0.0014796918258070946\n",
      "Gradient for encoder.log_var.weight: 0.020127173513174057\n",
      "Gradient for encoder.log_var.bias: 0.0009123209747485816\n",
      "Gradient for decoder.decoder.0.weight: 0.008818023838102818\n",
      "Gradient for decoder.decoder.0.bias: 8.406986218290058e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.00042324012611061335\n",
      "Gradient for decoder.decoder.1.bias: 0.0003489368536975235\n",
      "Gradient for decoder.decoder.3.weight: 0.008664943277835846\n",
      "Gradient for decoder.decoder.3.bias: 8.724685557348622e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0005842040991410613\n",
      "Gradient for decoder.decoder.4.bias: 0.0007448268006555736\n",
      "Gradient for decoder.decoder.6.weight: 0.0008149496861733496\n",
      "Gradient for decoder.decoder.6.bias: 6.225168908713385e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.004988402593880892\n",
      "Gradient for encoder.encoder.0.bias: 8.558604346065035e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.00044127131695859134\n",
      "Gradient for encoder.encoder.1.bias: 0.0005481139523908496\n",
      "Gradient for encoder.encoder.3.weight: 0.009922918863594532\n",
      "Gradient for encoder.encoder.3.bias: 9.435466297169626e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.003033548826351762\n",
      "Gradient for encoder.encoder.4.bias: 0.0020199676509946585\n",
      "Gradient for encoder.mean.weight: 0.04337172582745552\n",
      "Gradient for encoder.mean.bias: 0.0016628606244921684\n",
      "Gradient for encoder.log_var.weight: 0.02113245241343975\n",
      "Gradient for encoder.log_var.bias: 0.0010011367266997695\n",
      "Gradient for decoder.decoder.0.weight: 0.010875335894525051\n",
      "Gradient for decoder.decoder.0.bias: 9.547752172212043e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0004942211089655757\n",
      "Gradient for decoder.decoder.1.bias: 0.0004347793583292514\n",
      "Gradient for decoder.decoder.3.weight: 0.01034071110188961\n",
      "Gradient for decoder.decoder.3.bias: 7.967663334662589e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0003859849239233881\n",
      "Gradient for decoder.decoder.4.bias: 0.00035866902908310294\n",
      "Gradient for decoder.decoder.6.weight: 0.0006876714760437608\n",
      "Gradient for decoder.decoder.6.bias: 3.41410341206938e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.010693035088479519\n",
      "Gradient for encoder.encoder.0.bias: 1.5884913176500426e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0005454112542793155\n",
      "Gradient for encoder.encoder.1.bias: 0.0005651237443089485\n",
      "Gradient for encoder.encoder.3.weight: 0.012329086661338806\n",
      "Gradient for encoder.encoder.3.bias: 1.1873833860587268e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.002910239389166236\n",
      "Gradient for encoder.encoder.4.bias: 0.002614114433526993\n",
      "Gradient for encoder.mean.weight: 0.04062173515558243\n",
      "Gradient for encoder.mean.bias: 0.0021982339676469564\n",
      "Gradient for encoder.log_var.weight: 0.022085925564169884\n",
      "Gradient for encoder.log_var.bias: 0.0010488847037777305\n",
      "Gradient for decoder.decoder.0.weight: 0.007981635630130768\n",
      "Gradient for decoder.decoder.0.bias: 6.820945197549833e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0003861190052703023\n",
      "Gradient for decoder.decoder.1.bias: 0.0003403070440981537\n",
      "Gradient for decoder.decoder.3.weight: 0.007704225834459066\n",
      "Gradient for decoder.decoder.3.bias: 6.890784470803268e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00048404844710603356\n",
      "Gradient for decoder.decoder.4.bias: 0.0005618954310193658\n",
      "Gradient for decoder.decoder.6.weight: 0.0007331225206144154\n",
      "Gradient for decoder.decoder.6.bias: 4.862443165620789e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.00924981851130724\n",
      "Gradient for encoder.encoder.0.bias: 1.3099432996654947e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0005220018792897463\n",
      "Gradient for encoder.encoder.1.bias: 0.00045570911606773734\n",
      "Gradient for encoder.encoder.3.weight: 0.011380662210285664\n",
      "Gradient for encoder.encoder.3.bias: 1.0026399155371735e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.002551337471231818\n",
      "Gradient for encoder.encoder.4.bias: 0.002018202794715762\n",
      "Gradient for encoder.mean.weight: 0.03634144365787506\n",
      "Gradient for encoder.mean.bias: 0.0016027006786316633\n",
      "Gradient for encoder.log_var.weight: 0.020836593583226204\n",
      "Gradient for encoder.log_var.bias: 0.0010337593266740441\n",
      "Gradient for decoder.decoder.0.weight: 0.009281354025006294\n",
      "Gradient for decoder.decoder.0.bias: 7.922261457959934e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.00043797207763418555\n",
      "Gradient for decoder.decoder.1.bias: 0.00037942378548905253\n",
      "Gradient for decoder.decoder.3.weight: 0.008441988378763199\n",
      "Gradient for decoder.decoder.3.bias: 6.874078389840221e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0003306243452243507\n",
      "Gradient for decoder.decoder.4.bias: 0.000331454531988129\n",
      "Gradient for decoder.decoder.6.weight: 0.0006979640456847847\n",
      "Gradient for decoder.decoder.6.bias: 3.750151154235937e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.0057337842881679535\n",
      "Gradient for encoder.encoder.0.bias: 1.015374243018563e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.00046725431457161903\n",
      "Gradient for encoder.encoder.1.bias: 0.0003740270039997995\n",
      "Gradient for encoder.encoder.3.weight: 0.009624003432691097\n",
      "Gradient for encoder.encoder.3.bias: 1.0910572445510525e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0027158702723681927\n",
      "Gradient for encoder.encoder.4.bias: 0.0023849932476878166\n",
      "Gradient for encoder.mean.weight: 0.03784532472491264\n",
      "Gradient for encoder.mean.bias: 0.0014801766956225038\n",
      "Gradient for encoder.log_var.weight: 0.022781571373343468\n",
      "Gradient for encoder.log_var.bias: 0.001139789936132729\n",
      "Gradient for decoder.decoder.0.weight: 0.011247007176280022\n",
      "Gradient for decoder.decoder.0.bias: 9.864916522550615e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005933896172791719\n",
      "Gradient for decoder.decoder.1.bias: 0.0004433480789884925\n",
      "Gradient for decoder.decoder.3.weight: 0.010683946311473846\n",
      "Gradient for decoder.decoder.3.bias: 9.315608007209875e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0003975525905843824\n",
      "Gradient for decoder.decoder.4.bias: 0.00033402242115698755\n",
      "Gradient for decoder.decoder.6.weight: 0.0007599146338179708\n",
      "Gradient for decoder.decoder.6.bias: 4.064710810780525e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.008873175829648972\n",
      "Gradient for encoder.encoder.0.bias: 1.2888119391152308e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0004624704015441239\n",
      "Gradient for encoder.encoder.1.bias: 0.0004934415919706225\n",
      "Gradient for encoder.encoder.3.weight: 0.010461424477398396\n",
      "Gradient for encoder.encoder.3.bias: 1.0184691284775838e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0023750965483486652\n",
      "Gradient for encoder.encoder.4.bias: 0.0017597554251551628\n",
      "Gradient for encoder.mean.weight: 0.032334037125110626\n",
      "Gradient for encoder.mean.bias: 0.0013628347078338265\n",
      "Gradient for encoder.log_var.weight: 0.01886802725493908\n",
      "Gradient for encoder.log_var.bias: 0.0008605658658780158\n",
      "Gradient for decoder.decoder.0.weight: 0.008823786862194538\n",
      "Gradient for decoder.decoder.0.bias: 7.598176948730995e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0004562660469673574\n",
      "Gradient for decoder.decoder.1.bias: 0.0003731895994860679\n",
      "Gradient for decoder.decoder.3.weight: 0.008262312039732933\n",
      "Gradient for decoder.decoder.3.bias: 8.013970737019704e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0005421107634902\n",
      "Gradient for decoder.decoder.4.bias: 0.0006377605604939163\n",
      "Gradient for decoder.decoder.6.weight: 0.0007914624293334782\n",
      "Gradient for decoder.decoder.6.bias: 5.807062188978307e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.006857919506728649\n",
      "Gradient for encoder.encoder.0.bias: 1.1306581539083371e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0004321597807575017\n",
      "Gradient for encoder.encoder.1.bias: 0.00039597341674380004\n",
      "Gradient for encoder.encoder.3.weight: 0.009029238484799862\n",
      "Gradient for encoder.encoder.3.bias: 9.820483315436945e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.002255850238725543\n",
      "Gradient for encoder.encoder.4.bias: 0.0018495802069082856\n",
      "Gradient for encoder.mean.weight: 0.030808867886662483\n",
      "Gradient for encoder.mean.bias: 0.001382908201776445\n",
      "Gradient for encoder.log_var.weight: 0.01785723678767681\n",
      "Gradient for encoder.log_var.bias: 0.0008342170622199774\n",
      "Gradient for decoder.decoder.0.weight: 0.008684319444000721\n",
      "Gradient for decoder.decoder.0.bias: 7.504399185398469e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.00041048420825973153\n",
      "Gradient for decoder.decoder.1.bias: 0.0003668458084575832\n",
      "Gradient for decoder.decoder.3.weight: 0.00835123285651207\n",
      "Gradient for decoder.decoder.3.bias: 9.702504077946372e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0006340732797980309\n",
      "Gradient for decoder.decoder.4.bias: 0.0007599071250297129\n",
      "Gradient for decoder.decoder.6.weight: 0.0008157000411301851\n",
      "Gradient for decoder.decoder.6.bias: 6.340089021250606e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.02608223631978035\n",
      "Gradient for encoder.encoder.0.bias: 3.89774497400186e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0011607026681303978\n",
      "Gradient for encoder.encoder.1.bias: 0.001139183179475367\n",
      "Gradient for encoder.encoder.3.weight: 0.024753829464316368\n",
      "Gradient for encoder.encoder.3.bias: 2.1509465042424125e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.004392762668430805\n",
      "Gradient for encoder.encoder.4.bias: 0.004551375284790993\n",
      "Gradient for encoder.mean.weight: 0.057218037545681\n",
      "Gradient for encoder.mean.bias: 0.003500842023640871\n",
      "Gradient for encoder.log_var.weight: 0.03387827426195145\n",
      "Gradient for encoder.log_var.bias: 0.002166175749152899\n",
      "Gradient for decoder.decoder.0.weight: 0.016031865030527115\n",
      "Gradient for decoder.decoder.0.bias: 1.01481482939203e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0006879791617393494\n",
      "Gradient for decoder.decoder.1.bias: 0.0006027467316016555\n",
      "Gradient for decoder.decoder.3.weight: 0.014692714437842369\n",
      "Gradient for decoder.decoder.3.bias: 1.1522218595905187e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.000705599260982126\n",
      "Gradient for decoder.decoder.4.bias: 0.000802521244622767\n",
      "Gradient for decoder.decoder.6.weight: 0.0017146976897493005\n",
      "Gradient for decoder.decoder.6.bias: 9.152858547167853e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/3, Train Loss: 0.0711, Val Loss: 0.2817\n",
      "Training VAE for class 8...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training VAE Epoch:  11%|█▏        | 9/79 [00:00<00:01, 37.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient for encoder.encoder.0.weight: 0.007254533935338259\n",
      "Gradient for encoder.encoder.0.bias: 9.649819138202176e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.0005415643099695444\n",
      "Gradient for encoder.encoder.1.bias: 0.0005490439361892641\n",
      "Gradient for encoder.encoder.3.weight: 0.011738985776901245\n",
      "Gradient for encoder.encoder.3.bias: 1.1148192091692266e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.003080580849200487\n",
      "Gradient for encoder.encoder.4.bias: 0.002252353588119149\n",
      "Gradient for encoder.mean.weight: 0.04207836464047432\n",
      "Gradient for encoder.mean.bias: 0.0014560500858351588\n",
      "Gradient for encoder.log_var.weight: 0.023841459304094315\n",
      "Gradient for encoder.log_var.bias: 0.000903682317584753\n",
      "Gradient for decoder.decoder.0.weight: 0.015045934356749058\n",
      "Gradient for decoder.decoder.0.bias: 1.285865164346589e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0007137639331631362\n",
      "Gradient for decoder.decoder.1.bias: 0.0006471569649875164\n",
      "Gradient for decoder.decoder.3.weight: 0.01577829197049141\n",
      "Gradient for decoder.decoder.3.bias: 2.0682157375606636e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0016109897987917066\n",
      "Gradient for decoder.decoder.4.bias: 0.0019873606506735086\n",
      "Gradient for decoder.decoder.6.weight: 0.001982090063393116\n",
      "Gradient for decoder.decoder.6.bias: 0.00019938198965974152\n",
      "Gradient for encoder.encoder.0.weight: 0.009788081981241703\n",
      "Gradient for encoder.encoder.0.bias: 1.1586239780092544e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0006904673064127564\n",
      "Gradient for encoder.encoder.1.bias: 0.0006656760233454406\n",
      "Gradient for encoder.encoder.3.weight: 0.015566223300993443\n",
      "Gradient for encoder.encoder.3.bias: 1.443290625902094e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.003827896900475025\n",
      "Gradient for encoder.encoder.4.bias: 0.0030155333224684\n",
      "Gradient for encoder.mean.weight: 0.05043437331914902\n",
      "Gradient for encoder.mean.bias: 0.002258959459140897\n",
      "Gradient for encoder.log_var.weight: 0.026585552841424942\n",
      "Gradient for encoder.log_var.bias: 0.0014822472585365176\n",
      "Gradient for decoder.decoder.0.weight: 0.013421634212136269\n",
      "Gradient for decoder.decoder.0.bias: 1.204942118304686e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0007027463288977742\n",
      "Gradient for decoder.decoder.1.bias: 0.00056215759832412\n",
      "Gradient for decoder.decoder.3.weight: 0.012864966876804829\n",
      "Gradient for decoder.decoder.3.bias: 1.7119305972812526e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0012699626386165619\n",
      "Gradient for decoder.decoder.4.bias: 0.0015357221709564328\n",
      "Gradient for decoder.decoder.6.weight: 0.0016280176350846887\n",
      "Gradient for decoder.decoder.6.bias: 0.00016205832071136683\n",
      "Gradient for encoder.encoder.0.weight: 0.017649391666054726\n",
      "Gradient for encoder.encoder.0.bias: 1.964003959464833e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0008346348186023533\n",
      "Gradient for encoder.encoder.1.bias: 0.0007122190436348319\n",
      "Gradient for encoder.encoder.3.weight: 0.018821001052856445\n",
      "Gradient for encoder.encoder.3.bias: 1.3146274346897968e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0034083742648363113\n",
      "Gradient for encoder.encoder.4.bias: 0.002599169733002782\n",
      "Gradient for encoder.mean.weight: 0.044260185211896896\n",
      "Gradient for encoder.mean.bias: 0.0015574332792311907\n",
      "Gradient for encoder.log_var.weight: 0.026781583204865456\n",
      "Gradient for encoder.log_var.bias: 0.0010685785673558712\n",
      "Gradient for decoder.decoder.0.weight: 0.010369570925831795\n",
      "Gradient for decoder.decoder.0.bias: 8.42000705270074e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005095634842291474\n",
      "Gradient for decoder.decoder.1.bias: 0.00040799943963065743\n",
      "Gradient for decoder.decoder.3.weight: 0.009997931309044361\n",
      "Gradient for decoder.decoder.3.bias: 1.317197323436048e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.00101935223210603\n",
      "Gradient for decoder.decoder.4.bias: 0.0012307818979024887\n",
      "Gradient for decoder.decoder.6.weight: 0.001481649000197649\n",
      "Gradient for decoder.decoder.6.bias: 0.00014499745157081634\n",
      "Gradient for encoder.encoder.0.weight: 0.0071903797797858715\n",
      "Gradient for encoder.encoder.0.bias: 1.0262913782699279e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0005107671022415161\n",
      "Gradient for encoder.encoder.1.bias: 0.00047836056910455227\n",
      "Gradient for encoder.encoder.3.weight: 0.01074154581874609\n",
      "Gradient for encoder.encoder.3.bias: 1.2170599250627134e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.002966395579278469\n",
      "Gradient for encoder.encoder.4.bias: 0.0024547246284782887\n",
      "Gradient for encoder.mean.weight: 0.03910592198371887\n",
      "Gradient for encoder.mean.bias: 0.0016467670211568475\n",
      "Gradient for encoder.log_var.weight: 0.02293427847325802\n",
      "Gradient for encoder.log_var.bias: 0.0010076118633151054\n",
      "Gradient for decoder.decoder.0.weight: 0.013969643972814083\n",
      "Gradient for decoder.decoder.0.bias: 1.1582496073359039e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0007178644882515073\n",
      "Gradient for decoder.decoder.1.bias: 0.000592960452195257\n",
      "Gradient for decoder.decoder.3.weight: 0.013266101479530334\n",
      "Gradient for decoder.decoder.3.bias: 1.7123234774540919e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0013006208464503288\n",
      "Gradient for decoder.decoder.4.bias: 0.0015608331887051463\n",
      "Gradient for decoder.decoder.6.weight: 0.0015602312050759792\n",
      "Gradient for decoder.decoder.6.bias: 0.00015315826749429107\n",
      "Gradient for encoder.encoder.0.weight: 0.00727972062304616\n",
      "Gradient for encoder.encoder.0.bias: 1.0179516084229956e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0005143471644259989\n",
      "Gradient for encoder.encoder.1.bias: 0.00044039482600055635\n",
      "Gradient for encoder.encoder.3.weight: 0.011120338924229145\n",
      "Gradient for encoder.encoder.3.bias: 1.1106738445620934e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0028990209102630615\n",
      "Gradient for encoder.encoder.4.bias: 0.002353809541091323\n",
      "Gradient for encoder.mean.weight: 0.04210450127720833\n",
      "Gradient for encoder.mean.bias: 0.0015229531563818455\n",
      "Gradient for encoder.log_var.weight: 0.02205994538962841\n",
      "Gradient for encoder.log_var.bias: 0.0010814967099577188\n",
      "Gradient for decoder.decoder.0.weight: 0.014262479729950428\n",
      "Gradient for decoder.decoder.0.bias: 1.2242082347846406e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0007158071966841817\n",
      "Gradient for decoder.decoder.1.bias: 0.0006023821770213544\n",
      "Gradient for decoder.decoder.3.weight: 0.013492744415998459\n",
      "Gradient for decoder.decoder.3.bias: 1.8287943381878335e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0012774835340678692\n",
      "Gradient for decoder.decoder.4.bias: 0.0015679136849939823\n",
      "Gradient for decoder.decoder.6.weight: 0.0013428102247416973\n",
      "Gradient for decoder.decoder.6.bias: 0.00012725360284093767\n",
      "Gradient for encoder.encoder.0.weight: 0.010621207766234875\n",
      "Gradient for encoder.encoder.0.bias: 1.18049103478568e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0005219586892053485\n",
      "Gradient for encoder.encoder.1.bias: 0.0006346010486595333\n",
      "Gradient for encoder.encoder.3.weight: 0.01124476082623005\n",
      "Gradient for encoder.encoder.3.bias: 1.226098667039821e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.00236374675296247\n",
      "Gradient for encoder.encoder.4.bias: 0.002373335650190711\n",
      "Gradient for encoder.mean.weight: 0.033886633813381195\n",
      "Gradient for encoder.mean.bias: 0.0017534290673211217\n",
      "Gradient for encoder.log_var.weight: 0.017159659415483475\n",
      "Gradient for encoder.log_var.bias: 0.0009420960559509695\n",
      "Gradient for decoder.decoder.0.weight: 0.012821896933019161\n",
      "Gradient for decoder.decoder.0.bias: 1.0646358100663278e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0006537358276546001\n",
      "Gradient for decoder.decoder.1.bias: 0.0005525143933482468\n",
      "Gradient for decoder.decoder.3.weight: 0.012328418903052807\n",
      "Gradient for decoder.decoder.3.bias: 1.5414022835891217e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.001034627901390195\n",
      "Gradient for decoder.decoder.4.bias: 0.001265347353182733\n",
      "Gradient for decoder.decoder.6.weight: 0.0013141263043507934\n",
      "Gradient for decoder.decoder.6.bias: 0.00012480924488045275\n",
      "Gradient for encoder.encoder.0.weight: 0.0166303887963295\n",
      "Gradient for encoder.encoder.0.bias: 1.8741891719131765e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0007796098361723125\n",
      "Gradient for encoder.encoder.1.bias: 0.0007759339641779661\n",
      "Gradient for encoder.encoder.3.weight: 0.017435718327760696\n",
      "Gradient for encoder.encoder.3.bias: 1.4783577140242699e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0034899685997515917\n",
      "Gradient for encoder.encoder.4.bias: 0.0025945338420569897\n",
      "Gradient for encoder.mean.weight: 0.04675614833831787\n",
      "Gradient for encoder.mean.bias: 0.001754503115080297\n",
      "Gradient for encoder.log_var.weight: 0.023122726008296013\n",
      "Gradient for encoder.log_var.bias: 0.000986011466011405\n",
      "Gradient for decoder.decoder.0.weight: 0.011798503808677197\n",
      "Gradient for decoder.decoder.0.bias: 9.758490543410048e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005791023140773177\n",
      "Gradient for decoder.decoder.1.bias: 0.0004902311484329402\n",
      "Gradient for decoder.decoder.3.weight: 0.011461667716503143\n",
      "Gradient for decoder.decoder.3.bias: 1.4452695984434882e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0010902544017881155\n",
      "Gradient for decoder.decoder.4.bias: 0.0013215119251981378\n",
      "Gradient for decoder.decoder.6.weight: 0.001497121760621667\n",
      "Gradient for decoder.decoder.6.bias: 0.0001462749787606299\n",
      "Gradient for encoder.encoder.0.weight: 0.006020095199346542\n",
      "Gradient for encoder.encoder.0.bias: 8.83990883965291e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.00046308114542625844\n",
      "Gradient for encoder.encoder.1.bias: 0.00040829277713783085\n",
      "Gradient for encoder.encoder.3.weight: 0.010184528306126595\n",
      "Gradient for encoder.encoder.3.bias: 1.11520528922604e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.002920998726040125\n",
      "Gradient for encoder.encoder.4.bias: 0.0023340533953160048\n",
      "Gradient for encoder.mean.weight: 0.04144737124443054\n",
      "Gradient for encoder.mean.bias: 0.0018509337678551674\n",
      "Gradient for encoder.log_var.weight: 0.023147014901041985\n",
      "Gradient for encoder.log_var.bias: 0.0010745493927970529\n",
      "Gradient for decoder.decoder.0.weight: 0.014402841217815876\n",
      "Gradient for decoder.decoder.0.bias: 1.283106954019786e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0006984262727200985\n",
      "Gradient for decoder.decoder.1.bias: 0.0006098159356042743\n",
      "Gradient for decoder.decoder.3.weight: 0.013671157881617546\n",
      "Gradient for decoder.decoder.3.bias: 1.260462567653775e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0007096707704477012\n",
      "Gradient for decoder.decoder.4.bias: 0.0007772794342599809\n",
      "Gradient for decoder.decoder.6.weight: 0.0010437129531055689\n",
      "Gradient for decoder.decoder.6.bias: 8.739211625652388e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.01003338024020195\n",
      "Gradient for encoder.encoder.0.bias: 1.340667420829389e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0006554230349138379\n",
      "Gradient for encoder.encoder.1.bias: 0.0005796627374365926\n",
      "Gradient for encoder.encoder.3.weight: 0.01375789474695921\n",
      "Gradient for encoder.encoder.3.bias: 1.282345202247015e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.003175124293193221\n",
      "Gradient for encoder.encoder.4.bias: 0.0022856544237583876\n",
      "Gradient for encoder.mean.weight: 0.04027226194739342\n",
      "Gradient for encoder.mean.bias: 0.001745720161125064\n",
      "Gradient for encoder.log_var.weight: 0.02462218515574932\n",
      "Gradient for encoder.log_var.bias: 0.0010941309155896306\n",
      "Gradient for decoder.decoder.0.weight: 0.012682211585342884\n",
      "Gradient for decoder.decoder.0.bias: 1.0523723559252574e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0006013067904859781\n",
      "Gradient for decoder.decoder.1.bias: 0.0005317634786479175\n",
      "Gradient for decoder.decoder.3.weight: 0.012197035364806652\n",
      "Gradient for decoder.decoder.3.bias: 1.2981907215880994e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0008637699647806585\n",
      "Gradient for decoder.decoder.4.bias: 0.0009753857157193124\n",
      "Gradient for decoder.decoder.6.weight: 0.0015178089961409569\n",
      "Gradient for decoder.decoder.6.bias: 0.0001508021232439205\n",
      "Gradient for encoder.encoder.0.weight: 0.010668549686670303\n",
      "Gradient for encoder.encoder.0.bias: 1.2505400361073615e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0005905200378037989\n",
      "Gradient for encoder.encoder.1.bias: 0.0006385427550412714\n",
      "Gradient for encoder.encoder.3.weight: 0.013021192513406277\n",
      "Gradient for encoder.encoder.3.bias: 1.3442458257628687e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0029632190708070993\n",
      "Gradient for encoder.encoder.4.bias: 0.002465822733938694\n",
      "Gradient for encoder.mean.weight: 0.03916895017027855\n",
      "Gradient for encoder.mean.bias: 0.0018113573314622045\n",
      "Gradient for encoder.log_var.weight: 0.022978467866778374\n",
      "Gradient for encoder.log_var.bias: 0.001329946331679821\n",
      "Gradient for decoder.decoder.0.weight: 0.014813356101512909\n",
      "Gradient for decoder.decoder.0.bias: 1.2622475287216162e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.000711187138222158\n",
      "Gradient for decoder.decoder.1.bias: 0.00062019337201491\n",
      "Gradient for decoder.decoder.3.weight: 0.014161376282572746\n",
      "Gradient for decoder.decoder.3.bias: 2.0382093235404852e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0017022353131324053\n",
      "Gradient for decoder.decoder.4.bias: 0.002117827767506242\n",
      "Gradient for decoder.decoder.6.weight: 0.0017548318719491363\n",
      "Gradient for decoder.decoder.6.bias: 0.0001718303537927568\n",
      "Gradient for encoder.encoder.0.weight: 0.013484058901667595\n",
      "Gradient for encoder.encoder.0.bias: 1.1690533957553484e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0006492472602985799\n",
      "Gradient for encoder.encoder.1.bias: 0.0006913390825502574\n",
      "Gradient for encoder.encoder.3.weight: 0.014468155801296234\n",
      "Gradient for encoder.encoder.3.bias: 1.2581070907291547e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0030604919884353876\n",
      "Gradient for encoder.encoder.4.bias: 0.002577679231762886\n",
      "Gradient for encoder.mean.weight: 0.040975190699100494\n",
      "Gradient for encoder.mean.bias: 0.0016981277149170637\n",
      "Gradient for encoder.log_var.weight: 0.02369174361228943\n",
      "Gradient for encoder.log_var.bias: 0.0011797577608376741\n",
      "Gradient for decoder.decoder.0.weight: 0.012536484748125076\n",
      "Gradient for decoder.decoder.0.bias: 1.0404805489416802e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0006025353795848787\n",
      "Gradient for decoder.decoder.1.bias: 0.0005231593968346715\n",
      "Gradient for decoder.decoder.3.weight: 0.012000524438917637\n",
      "Gradient for decoder.decoder.3.bias: 1.193927873233136e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0008194577530957758\n",
      "Gradient for decoder.decoder.4.bias: 0.0009444389725103974\n",
      "Gradient for decoder.decoder.6.weight: 0.001393631799146533\n",
      "Gradient for decoder.decoder.6.bias: 0.00013004092033952475\n",
      "Gradient for encoder.encoder.0.weight: 0.005631145089864731\n",
      "Gradient for encoder.encoder.0.bias: 8.211737713426093e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.000474128988571465\n",
      "Gradient for encoder.encoder.1.bias: 0.00047232655924744904\n",
      "Gradient for encoder.encoder.3.weight: 0.010840618051588535\n",
      "Gradient for encoder.encoder.3.bias: 1.1115514758630596e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0030139118898659945\n",
      "Gradient for encoder.encoder.4.bias: 0.0022455330472439528\n",
      "Gradient for encoder.mean.weight: 0.04298655316233635\n",
      "Gradient for encoder.mean.bias: 0.0016782379243522882\n",
      "Gradient for encoder.log_var.weight: 0.02162662334740162\n",
      "Gradient for encoder.log_var.bias: 0.001081670168787241\n",
      "Gradient for decoder.decoder.0.weight: 0.015410649590194225\n",
      "Gradient for decoder.decoder.0.bias: 1.2482090361309872e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0007574844057671726\n",
      "Gradient for decoder.decoder.1.bias: 0.000662562029901892\n",
      "Gradient for decoder.decoder.3.weight: 0.014906120486557484\n",
      "Gradient for decoder.decoder.3.bias: 2.0933833833058912e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0015223859809339046\n",
      "Gradient for decoder.decoder.4.bias: 0.0018100314773619175\n",
      "Gradient for decoder.decoder.6.weight: 0.0016769013600423932\n",
      "Gradient for decoder.decoder.6.bias: 0.0001596687943674624\n",
      "Gradient for encoder.encoder.0.weight: 0.008693062700331211\n",
      "Gradient for encoder.encoder.0.bias: 1.0306210745936184e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0005765059613622725\n",
      "Gradient for encoder.encoder.1.bias: 0.0005175946862436831\n",
      "Gradient for encoder.encoder.3.weight: 0.012212440371513367\n",
      "Gradient for encoder.encoder.3.bias: 1.1622076218076316e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0029752086848020554\n",
      "Gradient for encoder.encoder.4.bias: 0.00209108111448586\n",
      "Gradient for encoder.mean.weight: 0.04115527868270874\n",
      "Gradient for encoder.mean.bias: 0.0016360206063836813\n",
      "Gradient for encoder.log_var.weight: 0.022143123671412468\n",
      "Gradient for encoder.log_var.bias: 0.0009915769333019853\n",
      "Gradient for decoder.decoder.0.weight: 0.013576310127973557\n",
      "Gradient for decoder.decoder.0.bias: 1.2917696079473018e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0006558630848303437\n",
      "Gradient for decoder.decoder.1.bias: 0.0005753596778959036\n",
      "Gradient for decoder.decoder.3.weight: 0.013057838194072247\n",
      "Gradient for decoder.decoder.3.bias: 1.4815257354250377e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0009361882694065571\n",
      "Gradient for decoder.decoder.4.bias: 0.0011352580040693283\n",
      "Gradient for decoder.decoder.6.weight: 0.0013194126076996326\n",
      "Gradient for decoder.decoder.6.bias: 0.00012021589645883068\n",
      "Gradient for encoder.encoder.0.weight: 0.021468520164489746\n",
      "Gradient for encoder.encoder.0.bias: 2.666572865295258e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0010556583292782307\n",
      "Gradient for encoder.encoder.1.bias: 0.0008274022839032114\n",
      "Gradient for encoder.encoder.3.weight: 0.021023575216531754\n",
      "Gradient for encoder.encoder.3.bias: 1.8949822266911553e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.004879279527813196\n",
      "Gradient for encoder.encoder.4.bias: 0.004176545888185501\n",
      "Gradient for encoder.mean.weight: 0.06687440723180771\n",
      "Gradient for encoder.mean.bias: 0.003365506185218692\n",
      "Gradient for encoder.log_var.weight: 0.03818293288350105\n",
      "Gradient for encoder.log_var.bias: 0.0020444109104573727\n",
      "Gradient for decoder.decoder.0.weight: 0.011141268536448479\n",
      "Gradient for decoder.decoder.0.bias: 9.421641938844871e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.000504602154251188\n",
      "Gradient for decoder.decoder.1.bias: 0.00046955273137427866\n",
      "Gradient for decoder.decoder.3.weight: 0.01024140976369381\n",
      "Gradient for decoder.decoder.3.bias: 1.1861307769311935e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0007826436776667833\n",
      "Gradient for decoder.decoder.4.bias: 0.000932051392737776\n",
      "Gradient for decoder.decoder.6.weight: 0.0013448368990793824\n",
      "Gradient for decoder.decoder.6.bias: 0.00012867161422036588\n",
      "Gradient for encoder.encoder.0.weight: 0.008348812349140644\n",
      "Gradient for encoder.encoder.0.bias: 1.16990644602466e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0005260391626507044\n",
      "Gradient for encoder.encoder.1.bias: 0.0005217588623054326\n",
      "Gradient for encoder.encoder.3.weight: 0.0114150894805789\n",
      "Gradient for encoder.encoder.3.bias: 1.17882190120433e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.00263358186930418\n",
      "Gradient for encoder.encoder.4.bias: 0.0017660785233601928\n",
      "Gradient for encoder.mean.weight: 0.03476434573531151\n",
      "Gradient for encoder.mean.bias: 0.0014468800509348512\n",
      "Gradient for encoder.log_var.weight: 0.020927120000123978\n",
      "Gradient for encoder.log_var.bias: 0.001107716583646834\n",
      "Gradient for decoder.decoder.0.weight: 0.01172187551856041\n",
      "Gradient for decoder.decoder.0.bias: 1.0655750587451607e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0005924970610067248\n",
      "Gradient for decoder.decoder.1.bias: 0.0004786913050338626\n",
      "Gradient for decoder.decoder.3.weight: 0.01131875067949295\n",
      "Gradient for decoder.decoder.3.bias: 1.1929568444202232e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0007936875917948782\n",
      "Gradient for decoder.decoder.4.bias: 0.0009351244079880416\n",
      "Gradient for decoder.decoder.6.weight: 0.001347494195215404\n",
      "Gradient for decoder.decoder.6.bias: 0.00012795059592463076\n",
      "Gradient for encoder.encoder.0.weight: 0.009145857766270638\n",
      "Gradient for encoder.encoder.0.bias: 1.2887827090246606e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0004988269065506756\n",
      "Gradient for encoder.encoder.1.bias: 0.0005003091064281762\n",
      "Gradient for encoder.encoder.3.weight: 0.011281809769570827\n",
      "Gradient for encoder.encoder.3.bias: 1.1274713801467939e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.002131704706698656\n",
      "Gradient for encoder.encoder.4.bias: 0.001780088641680777\n",
      "Gradient for encoder.mean.weight: 0.031231041997671127\n",
      "Gradient for encoder.mean.bias: 0.0014890545280650258\n",
      "Gradient for encoder.log_var.weight: 0.018638670444488525\n",
      "Gradient for encoder.log_var.bias: 0.0009401073912158608\n",
      "Gradient for decoder.decoder.0.weight: 0.011866130866110325\n",
      "Gradient for decoder.decoder.0.bias: 1.0314416681866945e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0005857235519215465\n",
      "Gradient for decoder.decoder.1.bias: 0.0005214304546825588\n",
      "Gradient for decoder.decoder.3.weight: 0.010917493142187595\n",
      "Gradient for decoder.decoder.3.bias: 1.1947637323928006e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0008627344504930079\n",
      "Gradient for decoder.decoder.4.bias: 0.0010051032295450568\n",
      "Gradient for decoder.decoder.6.weight: 0.0014013544423505664\n",
      "Gradient for decoder.decoder.6.bias: 0.00012835740926675498\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training VAE Epoch:  33%|███▎      | 26/79 [00:00<00:00, 62.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient for encoder.encoder.0.weight: 0.006137121934443712\n",
      "Gradient for encoder.encoder.0.bias: 8.255564634684909e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.0005629619117826223\n",
      "Gradient for encoder.encoder.1.bias: 0.0005251697730273008\n",
      "Gradient for encoder.encoder.3.weight: 0.01256437785923481\n",
      "Gradient for encoder.encoder.3.bias: 1.0805184524897982e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.003390649799257517\n",
      "Gradient for encoder.encoder.4.bias: 0.0024070078507065773\n",
      "Gradient for encoder.mean.weight: 0.04652002826333046\n",
      "Gradient for encoder.mean.bias: 0.0017105129081755877\n",
      "Gradient for encoder.log_var.weight: 0.02608528546988964\n",
      "Gradient for encoder.log_var.bias: 0.000982223660685122\n",
      "Gradient for decoder.decoder.0.weight: 0.014893400482833385\n",
      "Gradient for decoder.decoder.0.bias: 1.2276261951438272e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0007852918352000415\n",
      "Gradient for decoder.decoder.1.bias: 0.0006627540569752455\n",
      "Gradient for decoder.decoder.3.weight: 0.014257935807108879\n",
      "Gradient for decoder.decoder.3.bias: 1.3374931717713423e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0008737590978853405\n",
      "Gradient for decoder.decoder.4.bias: 0.0010161048267036676\n",
      "Gradient for decoder.decoder.6.weight: 0.0010458241449669003\n",
      "Gradient for decoder.decoder.6.bias: 8.426171552855521e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.018293602392077446\n",
      "Gradient for encoder.encoder.0.bias: 1.616833056328204e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0007991371676325798\n",
      "Gradient for encoder.encoder.1.bias: 0.0006743633421137929\n",
      "Gradient for encoder.encoder.3.weight: 0.016680525615811348\n",
      "Gradient for encoder.encoder.3.bias: 1.4319483099267671e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0033641012851148844\n",
      "Gradient for encoder.encoder.4.bias: 0.002806540811434388\n",
      "Gradient for encoder.mean.weight: 0.044806476682424545\n",
      "Gradient for encoder.mean.bias: 0.0018246443942189217\n",
      "Gradient for encoder.log_var.weight: 0.0239785835146904\n",
      "Gradient for encoder.log_var.bias: 0.0011422118404880166\n",
      "Gradient for decoder.decoder.0.weight: 0.012393859215080738\n",
      "Gradient for decoder.decoder.0.bias: 1.048292494476577e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0006168997497297823\n",
      "Gradient for decoder.decoder.1.bias: 0.0005542473518289626\n",
      "Gradient for decoder.decoder.3.weight: 0.011918189004063606\n",
      "Gradient for decoder.decoder.3.bias: 1.3575850166258618e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.000915558950509876\n",
      "Gradient for decoder.decoder.4.bias: 0.001063885516487062\n",
      "Gradient for decoder.decoder.6.weight: 0.0015092699322849512\n",
      "Gradient for decoder.decoder.6.bias: 0.00014130628551356494\n",
      "Gradient for encoder.encoder.0.weight: 0.009395389817655087\n",
      "Gradient for encoder.encoder.0.bias: 1.1783035484824733e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0005072517669759691\n",
      "Gradient for encoder.encoder.1.bias: 0.00046529696555808187\n",
      "Gradient for encoder.encoder.3.weight: 0.011155814863741398\n",
      "Gradient for encoder.encoder.3.bias: 1.1564991325707652e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0026632724329829216\n",
      "Gradient for encoder.encoder.4.bias: 0.0020728602539747953\n",
      "Gradient for encoder.mean.weight: 0.03468901664018631\n",
      "Gradient for encoder.mean.bias: 0.0014552330831065774\n",
      "Gradient for encoder.log_var.weight: 0.019732147455215454\n",
      "Gradient for encoder.log_var.bias: 0.0010671487543731928\n",
      "Gradient for decoder.decoder.0.weight: 0.012514947913587093\n",
      "Gradient for decoder.decoder.0.bias: 1.1776063457702435e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.000604687666054815\n",
      "Gradient for decoder.decoder.1.bias: 0.0005422913236543536\n",
      "Gradient for decoder.decoder.3.weight: 0.012054977007210255\n",
      "Gradient for decoder.decoder.3.bias: 1.0503513336868053e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0005436653736978769\n",
      "Gradient for decoder.decoder.4.bias: 0.0005907557206228375\n",
      "Gradient for decoder.decoder.6.weight: 0.0010663502616807818\n",
      "Gradient for decoder.decoder.6.bias: 8.747994434088469e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.00874100998044014\n",
      "Gradient for encoder.encoder.0.bias: 1.2015471083370866e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0005068730679340661\n",
      "Gradient for encoder.encoder.1.bias: 0.0005072386702522635\n",
      "Gradient for encoder.encoder.3.weight: 0.010899875313043594\n",
      "Gradient for encoder.encoder.3.bias: 1.0781109338608985e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.002648778958246112\n",
      "Gradient for encoder.encoder.4.bias: 0.002011357806622982\n",
      "Gradient for encoder.mean.weight: 0.037164654582738876\n",
      "Gradient for encoder.mean.bias: 0.0014861614909023046\n",
      "Gradient for encoder.log_var.weight: 0.02134929969906807\n",
      "Gradient for encoder.log_var.bias: 0.0008641975582577288\n",
      "Gradient for decoder.decoder.0.weight: 0.012170206755399704\n",
      "Gradient for decoder.decoder.0.bias: 1.0858878379815806e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0005640079034492373\n",
      "Gradient for decoder.decoder.1.bias: 0.000456293229945004\n",
      "Gradient for decoder.decoder.3.weight: 0.011188517324626446\n",
      "Gradient for decoder.decoder.3.bias: 8.966600378856882e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00043746581650339067\n",
      "Gradient for decoder.decoder.4.bias: 0.0003970228717662394\n",
      "Gradient for decoder.decoder.6.weight: 0.0009175445884466171\n",
      "Gradient for decoder.decoder.6.bias: 6.67581261950545e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.013053740374743938\n",
      "Gradient for encoder.encoder.0.bias: 1.4667805164902958e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0007342971512116492\n",
      "Gradient for encoder.encoder.1.bias: 0.0008811227744445205\n",
      "Gradient for encoder.encoder.3.weight: 0.015754103660583496\n",
      "Gradient for encoder.encoder.3.bias: 1.355631579214034e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.003190362825989723\n",
      "Gradient for encoder.encoder.4.bias: 0.0027481454890221357\n",
      "Gradient for encoder.mean.weight: 0.044208839535713196\n",
      "Gradient for encoder.mean.bias: 0.0021918369457125664\n",
      "Gradient for encoder.log_var.weight: 0.02282380312681198\n",
      "Gradient for encoder.log_var.bias: 0.0012691335286945105\n",
      "Gradient for decoder.decoder.0.weight: 0.011620176956057549\n",
      "Gradient for decoder.decoder.0.bias: 1.0967569213926609e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0005602336023002863\n",
      "Gradient for decoder.decoder.1.bias: 0.0004866315866820514\n",
      "Gradient for decoder.decoder.3.weight: 0.01050110999494791\n",
      "Gradient for decoder.decoder.3.bias: 9.736857847775227e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0005688824458047748\n",
      "Gradient for decoder.decoder.4.bias: 0.0006469744839705527\n",
      "Gradient for decoder.decoder.6.weight: 0.0011456478387117386\n",
      "Gradient for decoder.decoder.6.bias: 9.560851322021335e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.01028329599648714\n",
      "Gradient for encoder.encoder.0.bias: 1.3504237658668039e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0006451020599342883\n",
      "Gradient for encoder.encoder.1.bias: 0.0006399907288141549\n",
      "Gradient for encoder.encoder.3.weight: 0.01430000364780426\n",
      "Gradient for encoder.encoder.3.bias: 1.4159867722796093e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.003337147878482938\n",
      "Gradient for encoder.encoder.4.bias: 0.0026687912177294493\n",
      "Gradient for encoder.mean.weight: 0.04328496381640434\n",
      "Gradient for encoder.mean.bias: 0.0020291779655963182\n",
      "Gradient for encoder.log_var.weight: 0.023516150191426277\n",
      "Gradient for encoder.log_var.bias: 0.0011736219748854637\n",
      "Gradient for decoder.decoder.0.weight: 0.012634169310331345\n",
      "Gradient for decoder.decoder.0.bias: 1.069892785476867e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0006063029868528247\n",
      "Gradient for decoder.decoder.1.bias: 0.0005417483625933528\n",
      "Gradient for decoder.decoder.3.weight: 0.01144930999726057\n",
      "Gradient for decoder.decoder.3.bias: 1.357958190340014e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0008038395317271352\n",
      "Gradient for decoder.decoder.4.bias: 0.0009627456893213093\n",
      "Gradient for decoder.decoder.6.weight: 0.0012522826436907053\n",
      "Gradient for decoder.decoder.6.bias: 0.00010793362889671698\n",
      "Gradient for encoder.encoder.0.weight: 0.008557409979403019\n",
      "Gradient for encoder.encoder.0.bias: 1.209714359934333e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.000557813560590148\n",
      "Gradient for encoder.encoder.1.bias: 0.0004713365633506328\n",
      "Gradient for encoder.encoder.3.weight: 0.012747601605951786\n",
      "Gradient for encoder.encoder.3.bias: 1.2855422282243012e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0027578200679272413\n",
      "Gradient for encoder.encoder.4.bias: 0.002460652496665716\n",
      "Gradient for encoder.mean.weight: 0.039533063769340515\n",
      "Gradient for encoder.mean.bias: 0.0018967475043609738\n",
      "Gradient for encoder.log_var.weight: 0.021740706637501717\n",
      "Gradient for encoder.log_var.bias: 0.0013670055195689201\n",
      "Gradient for decoder.decoder.0.weight: 0.01116854790598154\n",
      "Gradient for decoder.decoder.0.bias: 9.771170678130048e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005219668382778764\n",
      "Gradient for decoder.decoder.1.bias: 0.0004538224602583796\n",
      "Gradient for decoder.decoder.3.weight: 0.010756785050034523\n",
      "Gradient for decoder.decoder.3.bias: 8.693445963103841e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00043210023432038724\n",
      "Gradient for decoder.decoder.4.bias: 0.0004242016584612429\n",
      "Gradient for decoder.decoder.6.weight: 0.0008626423659734428\n",
      "Gradient for decoder.decoder.6.bias: 5.655697168549523e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.006065639667212963\n",
      "Gradient for encoder.encoder.0.bias: 7.96994588381228e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.00041259313002228737\n",
      "Gradient for encoder.encoder.1.bias: 0.0004601842083502561\n",
      "Gradient for encoder.encoder.3.weight: 0.0092506418004632\n",
      "Gradient for encoder.encoder.3.bias: 9.877994255891309e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.0025156419724226\n",
      "Gradient for encoder.encoder.4.bias: 0.002038009697571397\n",
      "Gradient for encoder.mean.weight: 0.03241327404975891\n",
      "Gradient for encoder.mean.bias: 0.001360541325993836\n",
      "Gradient for encoder.log_var.weight: 0.021447522565722466\n",
      "Gradient for encoder.log_var.bias: 0.0010262870928272605\n",
      "Gradient for decoder.decoder.0.weight: 0.013098507188260555\n",
      "Gradient for decoder.decoder.0.bias: 1.109005665078655e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0006356654339469969\n",
      "Gradient for decoder.decoder.1.bias: 0.0005449827876873314\n",
      "Gradient for decoder.decoder.3.weight: 0.012178943492472172\n",
      "Gradient for decoder.decoder.3.bias: 9.71029714968985e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00047291177907027304\n",
      "Gradient for decoder.decoder.4.bias: 0.0003966662916354835\n",
      "Gradient for decoder.decoder.6.weight: 0.0009511043317615986\n",
      "Gradient for decoder.decoder.6.bias: 6.225491233635694e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.01021758746355772\n",
      "Gradient for encoder.encoder.0.bias: 1.338042350529367e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0005700926994904876\n",
      "Gradient for encoder.encoder.1.bias: 0.0006357043166644871\n",
      "Gradient for encoder.encoder.3.weight: 0.012881857343018055\n",
      "Gradient for encoder.encoder.3.bias: 1.1338460031984354e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0026145142037421465\n",
      "Gradient for encoder.encoder.4.bias: 0.0019908638205379248\n",
      "Gradient for encoder.mean.weight: 0.03629416599869728\n",
      "Gradient for encoder.mean.bias: 0.0014919547829777002\n",
      "Gradient for encoder.log_var.weight: 0.020233018323779106\n",
      "Gradient for encoder.log_var.bias: 0.0009801110718399286\n",
      "Gradient for decoder.decoder.0.weight: 0.011779959313571453\n",
      "Gradient for decoder.decoder.0.bias: 9.999649025482782e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005499208928085864\n",
      "Gradient for decoder.decoder.1.bias: 0.00047741614980623126\n",
      "Gradient for decoder.decoder.3.weight: 0.010811050422489643\n",
      "Gradient for decoder.decoder.3.bias: 8.54135512318166e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00039055204251781106\n",
      "Gradient for decoder.decoder.4.bias: 0.00035218382254242897\n",
      "Gradient for decoder.decoder.6.weight: 0.0009727821452543139\n",
      "Gradient for decoder.decoder.6.bias: 7.146030839066952e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.00757491635158658\n",
      "Gradient for encoder.encoder.0.bias: 9.646556123343863e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.0006286477437242866\n",
      "Gradient for encoder.encoder.1.bias: 0.0006558339227922261\n",
      "Gradient for encoder.encoder.3.weight: 0.013620393350720406\n",
      "Gradient for encoder.encoder.3.bias: 1.1149167006285765e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0031770674977451563\n",
      "Gradient for encoder.encoder.4.bias: 0.0021333645563572645\n",
      "Gradient for encoder.mean.weight: 0.04503372311592102\n",
      "Gradient for encoder.mean.bias: 0.0015815244987607002\n",
      "Gradient for encoder.log_var.weight: 0.021970931440591812\n",
      "Gradient for encoder.log_var.bias: 0.0009474805556237698\n",
      "Gradient for decoder.decoder.0.weight: 0.011595540679991245\n",
      "Gradient for decoder.decoder.0.bias: 1.0192308802503547e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.000575411191675812\n",
      "Gradient for decoder.decoder.1.bias: 0.0005371170118451118\n",
      "Gradient for decoder.decoder.3.weight: 0.011129897087812424\n",
      "Gradient for decoder.decoder.3.bias: 1.2055823006562605e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0005350342253223062\n",
      "Gradient for decoder.decoder.4.bias: 0.0005900710239075124\n",
      "Gradient for decoder.decoder.6.weight: 0.001060810056515038\n",
      "Gradient for decoder.decoder.6.bias: 8.210384839912876e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.007018832955509424\n",
      "Gradient for encoder.encoder.0.bias: 1.060204962016753e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.000513004488311708\n",
      "Gradient for encoder.encoder.1.bias: 0.0004714546666946262\n",
      "Gradient for encoder.encoder.3.weight: 0.011602307669818401\n",
      "Gradient for encoder.encoder.3.bias: 1.1714208769664225e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0024054376408457756\n",
      "Gradient for encoder.encoder.4.bias: 0.0019667181186378\n",
      "Gradient for encoder.mean.weight: 0.03439897298812866\n",
      "Gradient for encoder.mean.bias: 0.0015491846716031432\n",
      "Gradient for encoder.log_var.weight: 0.017291387543082237\n",
      "Gradient for encoder.log_var.bias: 0.0008202132303267717\n",
      "Gradient for decoder.decoder.0.weight: 0.012766901403665543\n",
      "Gradient for decoder.decoder.0.bias: 1.1305462815913714e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0006126017542555928\n",
      "Gradient for decoder.decoder.1.bias: 0.0005041764816269279\n",
      "Gradient for decoder.decoder.3.weight: 0.012052185833454132\n",
      "Gradient for decoder.decoder.3.bias: 1.536384075517816e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.001103727612644434\n",
      "Gradient for decoder.decoder.4.bias: 0.0013453237479552627\n",
      "Gradient for decoder.decoder.6.weight: 0.001466076704673469\n",
      "Gradient for decoder.decoder.6.bias: 0.0001338509755441919\n",
      "Gradient for encoder.encoder.0.weight: 0.006995591800659895\n",
      "Gradient for encoder.encoder.0.bias: 1.1207410000046991e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.000553967198356986\n",
      "Gradient for encoder.encoder.1.bias: 0.0004421185585670173\n",
      "Gradient for encoder.encoder.3.weight: 0.012088176794350147\n",
      "Gradient for encoder.encoder.3.bias: 1.0614937401287605e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.002738242968916893\n",
      "Gradient for encoder.encoder.4.bias: 0.0020622301381081343\n",
      "Gradient for encoder.mean.weight: 0.03718896582722664\n",
      "Gradient for encoder.mean.bias: 0.0016217852244153619\n",
      "Gradient for encoder.log_var.weight: 0.019259147346019745\n",
      "Gradient for encoder.log_var.bias: 0.0009394435910508037\n",
      "Gradient for decoder.decoder.0.weight: 0.012027516961097717\n",
      "Gradient for decoder.decoder.0.bias: 9.6151780981657e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005672092665918171\n",
      "Gradient for decoder.decoder.1.bias: 0.0004891499411314726\n",
      "Gradient for decoder.decoder.3.weight: 0.010915039107203484\n",
      "Gradient for decoder.decoder.3.bias: 7.857446637782317e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00041584763675928116\n",
      "Gradient for decoder.decoder.4.bias: 0.0003598080074880272\n",
      "Gradient for decoder.decoder.6.weight: 0.0009506628266535699\n",
      "Gradient for decoder.decoder.6.bias: 6.463233876274899e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.00918778870254755\n",
      "Gradient for encoder.encoder.0.bias: 1.3765543392663115e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0005746445967815816\n",
      "Gradient for encoder.encoder.1.bias: 0.0005768059054389596\n",
      "Gradient for encoder.encoder.3.weight: 0.012270752340555191\n",
      "Gradient for encoder.encoder.3.bias: 1.2365361512500783e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0026396317407488823\n",
      "Gradient for encoder.encoder.4.bias: 0.002343204105272889\n",
      "Gradient for encoder.mean.weight: 0.03854241967201233\n",
      "Gradient for encoder.mean.bias: 0.001891320920549333\n",
      "Gradient for encoder.log_var.weight: 0.017756372690200806\n",
      "Gradient for encoder.log_var.bias: 0.00100909813772887\n",
      "Gradient for decoder.decoder.0.weight: 0.010143378749489784\n",
      "Gradient for decoder.decoder.0.bias: 8.44423073131928e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005040164105594158\n",
      "Gradient for decoder.decoder.1.bias: 0.0003946830693166703\n",
      "Gradient for decoder.decoder.3.weight: 0.00926982332020998\n",
      "Gradient for decoder.decoder.3.bias: 7.103990312673503e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0003672935999929905\n",
      "Gradient for decoder.decoder.4.bias: 0.00032182069844566286\n",
      "Gradient for decoder.decoder.6.weight: 0.0008703835774213076\n",
      "Gradient for decoder.decoder.6.bias: 4.882359644398093e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.011144312098622322\n",
      "Gradient for encoder.encoder.0.bias: 1.4666042685851366e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.000569258991163224\n",
      "Gradient for encoder.encoder.1.bias: 0.0005832748138345778\n",
      "Gradient for encoder.encoder.3.weight: 0.01261072512716055\n",
      "Gradient for encoder.encoder.3.bias: 1.4209808330001295e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.002864761045202613\n",
      "Gradient for encoder.encoder.4.bias: 0.0025730421766638756\n",
      "Gradient for encoder.mean.weight: 0.04028921574354172\n",
      "Gradient for encoder.mean.bias: 0.0019257498206570745\n",
      "Gradient for encoder.log_var.weight: 0.0221665371209383\n",
      "Gradient for encoder.log_var.bias: 0.001155358855612576\n",
      "Gradient for decoder.decoder.0.weight: 0.010040296241641045\n",
      "Gradient for decoder.decoder.0.bias: 8.476434831816704e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.00048215468996204436\n",
      "Gradient for decoder.decoder.1.bias: 0.00042167591163888574\n",
      "Gradient for decoder.decoder.3.weight: 0.009358479641377926\n",
      "Gradient for decoder.decoder.3.bias: 7.440499605326778e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0004172523331362754\n",
      "Gradient for decoder.decoder.4.bias: 0.0004676974203903228\n",
      "Gradient for decoder.decoder.6.weight: 0.0010157943470403552\n",
      "Gradient for decoder.decoder.6.bias: 7.548151916125789e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.005572745110839605\n",
      "Gradient for encoder.encoder.0.bias: 9.275998372193506e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.00046312599442899227\n",
      "Gradient for encoder.encoder.1.bias: 0.0004423884383868426\n",
      "Gradient for encoder.encoder.3.weight: 0.010402359999716282\n",
      "Gradient for encoder.encoder.3.bias: 1.0083599233379203e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.002767986385151744\n",
      "Gradient for encoder.encoder.4.bias: 0.0019654016941785812\n",
      "Gradient for encoder.mean.weight: 0.03788375481963158\n",
      "Gradient for encoder.mean.bias: 0.001347075216472149\n",
      "Gradient for encoder.log_var.weight: 0.020777590572834015\n",
      "Gradient for encoder.log_var.bias: 0.0009415711392648518\n",
      "Gradient for decoder.decoder.0.weight: 0.01122898980975151\n",
      "Gradient for decoder.decoder.0.bias: 9.93384888237081e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005563435843214393\n",
      "Gradient for decoder.decoder.1.bias: 0.00047894782619550824\n",
      "Gradient for decoder.decoder.3.weight: 0.010740880854427814\n",
      "Gradient for decoder.decoder.3.bias: 8.53860246396998e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0004980422090739012\n",
      "Gradient for decoder.decoder.4.bias: 0.0005423793336376548\n",
      "Gradient for decoder.decoder.6.weight: 0.0010937220649793744\n",
      "Gradient for decoder.decoder.6.bias: 8.739047189010307e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.006134795490652323\n",
      "Gradient for encoder.encoder.0.bias: 8.664666206747995e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.00047443658695556223\n",
      "Gradient for encoder.encoder.1.bias: 0.0005239709280431271\n",
      "Gradient for encoder.encoder.3.weight: 0.010355873964726925\n",
      "Gradient for encoder.encoder.3.bias: 1.0560082669419657e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.002754917135462165\n",
      "Gradient for encoder.encoder.4.bias: 0.0021456563845276833\n",
      "Gradient for encoder.mean.weight: 0.03855227306485176\n",
      "Gradient for encoder.mean.bias: 0.0017139969859272242\n",
      "Gradient for encoder.log_var.weight: 0.022410713136196136\n",
      "Gradient for encoder.log_var.bias: 0.0009975520661100745\n",
      "Gradient for decoder.decoder.0.weight: 0.012121831066906452\n",
      "Gradient for decoder.decoder.0.bias: 1.0497155922273294e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0005337789771147072\n",
      "Gradient for decoder.decoder.1.bias: 0.0004915895406156778\n",
      "Gradient for decoder.decoder.3.weight: 0.010905249044299126\n",
      "Gradient for decoder.decoder.3.bias: 9.016910829107161e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00040802237344905734\n",
      "Gradient for decoder.decoder.4.bias: 0.0003594756417442113\n",
      "Gradient for decoder.decoder.6.weight: 0.0008657797588966787\n",
      "Gradient for decoder.decoder.6.bias: 4.8515907110413536e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training VAE Epoch:  54%|█████▍    | 43/79 [00:00<00:00, 72.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient for encoder.encoder.0.weight: 0.006106837652623653\n",
      "Gradient for encoder.encoder.0.bias: 8.229192501041371e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.000555074424482882\n",
      "Gradient for encoder.encoder.1.bias: 0.0005797363701276481\n",
      "Gradient for encoder.encoder.3.weight: 0.012020006775856018\n",
      "Gradient for encoder.encoder.3.bias: 1.0084293122769594e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0028868475928902626\n",
      "Gradient for encoder.encoder.4.bias: 0.002285680500790477\n",
      "Gradient for encoder.mean.weight: 0.038866203278303146\n",
      "Gradient for encoder.mean.bias: 0.0018354991916567087\n",
      "Gradient for encoder.log_var.weight: 0.023075789213180542\n",
      "Gradient for encoder.log_var.bias: 0.0010974962497130036\n",
      "Gradient for decoder.decoder.0.weight: 0.012520208023488522\n",
      "Gradient for decoder.decoder.0.bias: 1.0985107962158125e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0006113499985076487\n",
      "Gradient for decoder.decoder.1.bias: 0.0004894309095107019\n",
      "Gradient for decoder.decoder.3.weight: 0.011638361029326916\n",
      "Gradient for decoder.decoder.3.bias: 1.0136952388606346e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0005406281561590731\n",
      "Gradient for decoder.decoder.4.bias: 0.0005259644822217524\n",
      "Gradient for decoder.decoder.6.weight: 0.0010088204871863127\n",
      "Gradient for decoder.decoder.6.bias: 6.70832087052986e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.006682405713945627\n",
      "Gradient for encoder.encoder.0.bias: 9.73313877411508e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.00048598030116409063\n",
      "Gradient for encoder.encoder.1.bias: 0.000513709441293031\n",
      "Gradient for encoder.encoder.3.weight: 0.010501489974558353\n",
      "Gradient for encoder.encoder.3.bias: 1.0283923712606224e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.00230987835675478\n",
      "Gradient for encoder.encoder.4.bias: 0.0019687656313180923\n",
      "Gradient for encoder.mean.weight: 0.03709133341908455\n",
      "Gradient for encoder.mean.bias: 0.0016861048061400652\n",
      "Gradient for encoder.log_var.weight: 0.016812415793538094\n",
      "Gradient for encoder.log_var.bias: 0.0008745379163883626\n",
      "Gradient for decoder.decoder.0.weight: 0.01104868482798338\n",
      "Gradient for decoder.decoder.0.bias: 9.264549544196754e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005159747088328004\n",
      "Gradient for decoder.decoder.1.bias: 0.0004858174070250243\n",
      "Gradient for decoder.decoder.3.weight: 0.010260697454214096\n",
      "Gradient for decoder.decoder.3.bias: 9.513068111033363e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0005534933879971504\n",
      "Gradient for decoder.decoder.4.bias: 0.0006249198922887444\n",
      "Gradient for decoder.decoder.6.weight: 0.0009950102539733052\n",
      "Gradient for decoder.decoder.6.bias: 7.078348426148295e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.007768510840833187\n",
      "Gradient for encoder.encoder.0.bias: 1.1129893881522968e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0005482789711095393\n",
      "Gradient for encoder.encoder.1.bias: 0.0005482751876115799\n",
      "Gradient for encoder.encoder.3.weight: 0.011802536435425282\n",
      "Gradient for encoder.encoder.3.bias: 1.1410177663817578e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0025871277321130037\n",
      "Gradient for encoder.encoder.4.bias: 0.0021358884405344725\n",
      "Gradient for encoder.mean.weight: 0.038195930421352386\n",
      "Gradient for encoder.mean.bias: 0.0016490108100697398\n",
      "Gradient for encoder.log_var.weight: 0.020336734130978584\n",
      "Gradient for encoder.log_var.bias: 0.000982586294412613\n",
      "Gradient for decoder.decoder.0.weight: 0.010618015192449093\n",
      "Gradient for decoder.decoder.0.bias: 8.590520655937794e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.000523654161952436\n",
      "Gradient for decoder.decoder.1.bias: 0.00042454697540961206\n",
      "Gradient for decoder.decoder.3.weight: 0.010230598039925098\n",
      "Gradient for decoder.decoder.3.bias: 8.135037782297516e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0004485872632358223\n",
      "Gradient for decoder.decoder.4.bias: 0.0004547621647361666\n",
      "Gradient for decoder.decoder.6.weight: 0.0010529246646910906\n",
      "Gradient for decoder.decoder.6.bias: 7.952823216328397e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.007246085908263922\n",
      "Gradient for encoder.encoder.0.bias: 9.658241220678043e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.0004936085897497833\n",
      "Gradient for encoder.encoder.1.bias: 0.00044979536323808134\n",
      "Gradient for encoder.encoder.3.weight: 0.009906777180731297\n",
      "Gradient for encoder.encoder.3.bias: 9.861073069217241e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.002528334502130747\n",
      "Gradient for encoder.encoder.4.bias: 0.0019371878588572145\n",
      "Gradient for encoder.mean.weight: 0.03555702790617943\n",
      "Gradient for encoder.mean.bias: 0.0014600746799260378\n",
      "Gradient for encoder.log_var.weight: 0.02004171721637249\n",
      "Gradient for encoder.log_var.bias: 0.0009625245584174991\n",
      "Gradient for decoder.decoder.0.weight: 0.009748518466949463\n",
      "Gradient for decoder.decoder.0.bias: 8.672964429967678e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0004770650411956012\n",
      "Gradient for decoder.decoder.1.bias: 0.0004131939203944057\n",
      "Gradient for decoder.decoder.3.weight: 0.009039578959345818\n",
      "Gradient for decoder.decoder.3.bias: 7.266414553397382e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0003496028366498649\n",
      "Gradient for decoder.decoder.4.bias: 0.0003347989986650646\n",
      "Gradient for decoder.decoder.6.weight: 0.0010341181186959147\n",
      "Gradient for decoder.decoder.6.bias: 6.608605326618999e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.009138316847383976\n",
      "Gradient for encoder.encoder.0.bias: 1.3074040114413599e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0006992042763158679\n",
      "Gradient for encoder.encoder.1.bias: 0.0005053462809883058\n",
      "Gradient for encoder.encoder.3.weight: 0.015106160193681717\n",
      "Gradient for encoder.encoder.3.bias: 1.2041455332845175e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.002775198547169566\n",
      "Gradient for encoder.encoder.4.bias: 0.002188865328207612\n",
      "Gradient for encoder.mean.weight: 0.038003597408533096\n",
      "Gradient for encoder.mean.bias: 0.0016869250684976578\n",
      "Gradient for encoder.log_var.weight: 0.021361438557505608\n",
      "Gradient for encoder.log_var.bias: 0.0010438252938911319\n",
      "Gradient for decoder.decoder.0.weight: 0.010902871377766132\n",
      "Gradient for decoder.decoder.0.bias: 9.558217411997916e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005296616582199931\n",
      "Gradient for decoder.decoder.1.bias: 0.00045294524170458317\n",
      "Gradient for decoder.decoder.3.weight: 0.010003605857491493\n",
      "Gradient for decoder.decoder.3.bias: 8.856294170245249e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00043014276889152825\n",
      "Gradient for decoder.decoder.4.bias: 0.0004077137855347246\n",
      "Gradient for decoder.decoder.6.weight: 0.0010809481609612703\n",
      "Gradient for decoder.decoder.6.bias: 7.429652032442391e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.010507962666451931\n",
      "Gradient for encoder.encoder.0.bias: 1.0386083486302322e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.000552348152268678\n",
      "Gradient for encoder.encoder.1.bias: 0.0005407652352005243\n",
      "Gradient for encoder.encoder.3.weight: 0.01196643803268671\n",
      "Gradient for encoder.encoder.3.bias: 1.2012917049997185e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0025122633669525385\n",
      "Gradient for encoder.encoder.4.bias: 0.0023801447823643684\n",
      "Gradient for encoder.mean.weight: 0.033902984112501144\n",
      "Gradient for encoder.mean.bias: 0.001732724136672914\n",
      "Gradient for encoder.log_var.weight: 0.01976718194782734\n",
      "Gradient for encoder.log_var.bias: 0.0011677811853587627\n",
      "Gradient for decoder.decoder.0.weight: 0.011004704982042313\n",
      "Gradient for decoder.decoder.0.bias: 9.343661261373981e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005236126016825438\n",
      "Gradient for decoder.decoder.1.bias: 0.0004499243514146656\n",
      "Gradient for decoder.decoder.3.weight: 0.01012415811419487\n",
      "Gradient for decoder.decoder.3.bias: 8.04339025939349e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00036196739529259503\n",
      "Gradient for decoder.decoder.4.bias: 0.00031826290069147944\n",
      "Gradient for decoder.decoder.6.weight: 0.0008763416553847492\n",
      "Gradient for decoder.decoder.6.bias: 4.465623351279646e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.0066614593379199505\n",
      "Gradient for encoder.encoder.0.bias: 9.975412856855215e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.0004610355827026069\n",
      "Gradient for encoder.encoder.1.bias: 0.00043046538485214114\n",
      "Gradient for encoder.encoder.3.weight: 0.010591023601591587\n",
      "Gradient for encoder.encoder.3.bias: 1.008709157868104e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0019192637410014868\n",
      "Gradient for encoder.encoder.4.bias: 0.0017563700675964355\n",
      "Gradient for encoder.mean.weight: 0.02744048833847046\n",
      "Gradient for encoder.mean.bias: 0.0012754920171573758\n",
      "Gradient for encoder.log_var.weight: 0.015614960342645645\n",
      "Gradient for encoder.log_var.bias: 0.0008354960009455681\n",
      "Gradient for decoder.decoder.0.weight: 0.010451669804751873\n",
      "Gradient for decoder.decoder.0.bias: 9.317293464539134e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005535334930755198\n",
      "Gradient for decoder.decoder.1.bias: 0.00044665372115559876\n",
      "Gradient for decoder.decoder.3.weight: 0.009846257977187634\n",
      "Gradient for decoder.decoder.3.bias: 8.00151264690463e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0003621318028308451\n",
      "Gradient for decoder.decoder.4.bias: 0.0003284671111032367\n",
      "Gradient for decoder.decoder.6.weight: 0.0009088638471439481\n",
      "Gradient for decoder.decoder.6.bias: 5.280393816065043e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.006954225245863199\n",
      "Gradient for encoder.encoder.0.bias: 8.979146419452189e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.000506645708810538\n",
      "Gradient for encoder.encoder.1.bias: 0.00037471525138244033\n",
      "Gradient for encoder.encoder.3.weight: 0.010291820392012596\n",
      "Gradient for encoder.encoder.3.bias: 1.1580442854652873e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0026077530346810818\n",
      "Gradient for encoder.encoder.4.bias: 0.0022745344322174788\n",
      "Gradient for encoder.mean.weight: 0.035977449268102646\n",
      "Gradient for encoder.mean.bias: 0.0016937422333285213\n",
      "Gradient for encoder.log_var.weight: 0.020086534321308136\n",
      "Gradient for encoder.log_var.bias: 0.0011380137875676155\n",
      "Gradient for decoder.decoder.0.weight: 0.011430427432060242\n",
      "Gradient for decoder.decoder.0.bias: 9.610021806105706e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005343464436009526\n",
      "Gradient for decoder.decoder.1.bias: 0.0004753672401420772\n",
      "Gradient for decoder.decoder.3.weight: 0.010461504571139812\n",
      "Gradient for decoder.decoder.3.bias: 8.417851832254186e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0004502011288423091\n",
      "Gradient for decoder.decoder.4.bias: 0.00046158043551258743\n",
      "Gradient for decoder.decoder.6.weight: 0.0009615999297238886\n",
      "Gradient for decoder.decoder.6.bias: 5.5104053899412975e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.006514465902000666\n",
      "Gradient for encoder.encoder.0.bias: 1.0137888792338678e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.00044948281720280647\n",
      "Gradient for encoder.encoder.1.bias: 0.0003876159607898444\n",
      "Gradient for encoder.encoder.3.weight: 0.009390258230268955\n",
      "Gradient for encoder.encoder.3.bias: 9.970024805738831e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.0026835063472390175\n",
      "Gradient for encoder.encoder.4.bias: 0.002127832267433405\n",
      "Gradient for encoder.mean.weight: 0.038310613483190536\n",
      "Gradient for encoder.mean.bias: 0.0013436964945867658\n",
      "Gradient for encoder.log_var.weight: 0.021753806620836258\n",
      "Gradient for encoder.log_var.bias: 0.0008572322549298406\n",
      "Gradient for decoder.decoder.0.weight: 0.010593099519610405\n",
      "Gradient for decoder.decoder.0.bias: 9.195093991776204e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005081358831375837\n",
      "Gradient for decoder.decoder.1.bias: 0.0004569741722662002\n",
      "Gradient for decoder.decoder.3.weight: 0.00976650696247816\n",
      "Gradient for decoder.decoder.3.bias: 8.619593927505775e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0004041525535285473\n",
      "Gradient for decoder.decoder.4.bias: 0.0004212659550830722\n",
      "Gradient for decoder.decoder.6.weight: 0.0008580856374464929\n",
      "Gradient for decoder.decoder.6.bias: 5.084640724817291e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.011147109791636467\n",
      "Gradient for encoder.encoder.0.bias: 1.4008991015834749e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0005164312315173447\n",
      "Gradient for encoder.encoder.1.bias: 0.00043662230018526316\n",
      "Gradient for encoder.encoder.3.weight: 0.010523118078708649\n",
      "Gradient for encoder.encoder.3.bias: 1.2276511751618813e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.002443275647237897\n",
      "Gradient for encoder.encoder.4.bias: 0.001967484364286065\n",
      "Gradient for encoder.mean.weight: 0.03401391953229904\n",
      "Gradient for encoder.mean.bias: 0.0016168956644833088\n",
      "Gradient for encoder.log_var.weight: 0.01694304496049881\n",
      "Gradient for encoder.log_var.bias: 0.0008936741505749524\n",
      "Gradient for decoder.decoder.0.weight: 0.009975270368158817\n",
      "Gradient for decoder.decoder.0.bias: 8.462127526476237e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0004630026232916862\n",
      "Gradient for decoder.decoder.1.bias: 0.0003952714614570141\n",
      "Gradient for decoder.decoder.3.weight: 0.00907406397163868\n",
      "Gradient for decoder.decoder.3.bias: 8.787236910334784e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0004341892199590802\n",
      "Gradient for decoder.decoder.4.bias: 0.0004330236988607794\n",
      "Gradient for decoder.decoder.6.weight: 0.0009297890937887132\n",
      "Gradient for decoder.decoder.6.bias: 5.2661707741208375e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.0068676285445690155\n",
      "Gradient for encoder.encoder.0.bias: 1.1185179518702348e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.00041910127038136125\n",
      "Gradient for encoder.encoder.1.bias: 0.000433872890425846\n",
      "Gradient for encoder.encoder.3.weight: 0.008971177041530609\n",
      "Gradient for encoder.encoder.3.bias: 1.102326424584632e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.002059546299278736\n",
      "Gradient for encoder.encoder.4.bias: 0.0018382871057838202\n",
      "Gradient for encoder.mean.weight: 0.028637483716011047\n",
      "Gradient for encoder.mean.bias: 0.0013678697869181633\n",
      "Gradient for encoder.log_var.weight: 0.01894892193377018\n",
      "Gradient for encoder.log_var.bias: 0.0009647604310885072\n",
      "Gradient for decoder.decoder.0.weight: 0.009660505689680576\n",
      "Gradient for decoder.decoder.0.bias: 9.05697461472954e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.00041312380926683545\n",
      "Gradient for decoder.decoder.1.bias: 0.00037469551898539066\n",
      "Gradient for decoder.decoder.3.weight: 0.008819440379738808\n",
      "Gradient for decoder.decoder.3.bias: 8.591073685781936e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00035969592863693833\n",
      "Gradient for decoder.decoder.4.bias: 0.00036045839078724384\n",
      "Gradient for decoder.decoder.6.weight: 0.000980002456344664\n",
      "Gradient for decoder.decoder.6.bias: 6.803960422985256e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.00743296230211854\n",
      "Gradient for encoder.encoder.0.bias: 1.0798697873404262e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0004855418228544295\n",
      "Gradient for encoder.encoder.1.bias: 0.000463162490632385\n",
      "Gradient for encoder.encoder.3.weight: 0.010331003926694393\n",
      "Gradient for encoder.encoder.3.bias: 9.751925655887561e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.002006737980991602\n",
      "Gradient for encoder.encoder.4.bias: 0.0019045219523832202\n",
      "Gradient for encoder.mean.weight: 0.02727172151207924\n",
      "Gradient for encoder.mean.bias: 0.0014039177913218737\n",
      "Gradient for encoder.log_var.weight: 0.016363201662898064\n",
      "Gradient for encoder.log_var.bias: 0.0008853194885887206\n",
      "Gradient for decoder.decoder.0.weight: 0.009597545489668846\n",
      "Gradient for decoder.decoder.0.bias: 7.802605783702177e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0004616859368979931\n",
      "Gradient for decoder.decoder.1.bias: 0.0003897174319718033\n",
      "Gradient for decoder.decoder.3.weight: 0.00892961211502552\n",
      "Gradient for decoder.decoder.3.bias: 7.90165433084411e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0004528856952674687\n",
      "Gradient for decoder.decoder.4.bias: 0.0005236072465777397\n",
      "Gradient for decoder.decoder.6.weight: 0.0010547931306064129\n",
      "Gradient for decoder.decoder.6.bias: 7.78675457695499e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.005976454354822636\n",
      "Gradient for encoder.encoder.0.bias: 7.019601046265311e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.00040858436841517687\n",
      "Gradient for encoder.encoder.1.bias: 0.0003436541010159999\n",
      "Gradient for encoder.encoder.3.weight: 0.008969656191766262\n",
      "Gradient for encoder.encoder.3.bias: 1.0473998057758394e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.002503630705177784\n",
      "Gradient for encoder.encoder.4.bias: 0.0021674183662980795\n",
      "Gradient for encoder.mean.weight: 0.03644009679555893\n",
      "Gradient for encoder.mean.bias: 0.0016618408262729645\n",
      "Gradient for encoder.log_var.weight: 0.018780937418341637\n",
      "Gradient for encoder.log_var.bias: 0.0011200145818293095\n",
      "Gradient for decoder.decoder.0.weight: 0.012711743824183941\n",
      "Gradient for decoder.decoder.0.bias: 1.0127846478136249e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0006242211675271392\n",
      "Gradient for decoder.decoder.1.bias: 0.0005406620330177248\n",
      "Gradient for decoder.decoder.3.weight: 0.01154389325529337\n",
      "Gradient for decoder.decoder.3.bias: 8.579949251075192e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00047516889753751457\n",
      "Gradient for decoder.decoder.4.bias: 0.00045482287532649934\n",
      "Gradient for decoder.decoder.6.weight: 0.0008417547214776278\n",
      "Gradient for decoder.decoder.6.bias: 3.746881338884123e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.007499105762690306\n",
      "Gradient for encoder.encoder.0.bias: 1.0321141510893916e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0004479964845813811\n",
      "Gradient for encoder.encoder.1.bias: 0.0003964339557569474\n",
      "Gradient for encoder.encoder.3.weight: 0.01006774790585041\n",
      "Gradient for encoder.encoder.3.bias: 1.1268178057299849e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.002244837349280715\n",
      "Gradient for encoder.encoder.4.bias: 0.0018984919879585505\n",
      "Gradient for encoder.mean.weight: 0.031949128955602646\n",
      "Gradient for encoder.mean.bias: 0.0012425126042217016\n",
      "Gradient for encoder.log_var.weight: 0.01571628451347351\n",
      "Gradient for encoder.log_var.bias: 0.0009000740246847272\n",
      "Gradient for decoder.decoder.0.weight: 0.011950137093663216\n",
      "Gradient for decoder.decoder.0.bias: 1.0089673541102684e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0005592016386799514\n",
      "Gradient for decoder.decoder.1.bias: 0.0005025717546232045\n",
      "Gradient for decoder.decoder.3.weight: 0.011041070334613323\n",
      "Gradient for decoder.decoder.3.bias: 8.986338756455936e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0003766750160139054\n",
      "Gradient for decoder.decoder.4.bias: 0.0003296005888842046\n",
      "Gradient for decoder.decoder.6.weight: 0.0009000844438560307\n",
      "Gradient for decoder.decoder.6.bias: 4.0614857425680384e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.007972413673996925\n",
      "Gradient for encoder.encoder.0.bias: 1.051461088336092e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.00044899084605276585\n",
      "Gradient for encoder.encoder.1.bias: 0.0004746863560285419\n",
      "Gradient for encoder.encoder.3.weight: 0.00955471582710743\n",
      "Gradient for encoder.encoder.3.bias: 1.0810063955091209e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.002356350189074874\n",
      "Gradient for encoder.encoder.4.bias: 0.0020827751141041517\n",
      "Gradient for encoder.mean.weight: 0.03495115786790848\n",
      "Gradient for encoder.mean.bias: 0.0015345934079959989\n",
      "Gradient for encoder.log_var.weight: 0.01994541473686695\n",
      "Gradient for encoder.log_var.bias: 0.0011299370089545846\n",
      "Gradient for decoder.decoder.0.weight: 0.010858094319701195\n",
      "Gradient for decoder.decoder.0.bias: 9.579861903752374e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005040102987550199\n",
      "Gradient for decoder.decoder.1.bias: 0.0004205034929327667\n",
      "Gradient for decoder.decoder.3.weight: 0.010260556824505329\n",
      "Gradient for decoder.decoder.3.bias: 1.004152178074591e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0006043377215974033\n",
      "Gradient for decoder.decoder.4.bias: 0.0006935675628483295\n",
      "Gradient for decoder.decoder.6.weight: 0.0012560797622427344\n",
      "Gradient for decoder.decoder.6.bias: 0.00010553270840318874\n",
      "Gradient for encoder.encoder.0.weight: 0.008283542469143867\n",
      "Gradient for encoder.encoder.0.bias: 1.2426098344731074e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.00042778896749950945\n",
      "Gradient for encoder.encoder.1.bias: 0.00042816950008273125\n",
      "Gradient for encoder.encoder.3.weight: 0.009441963396966457\n",
      "Gradient for encoder.encoder.3.bias: 1.1038418096243063e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0020578885450959206\n",
      "Gradient for encoder.encoder.4.bias: 0.0017910035094246268\n",
      "Gradient for encoder.mean.weight: 0.029369588941335678\n",
      "Gradient for encoder.mean.bias: 0.0013373674592003226\n",
      "Gradient for encoder.log_var.weight: 0.017326772212982178\n",
      "Gradient for encoder.log_var.bias: 0.0008805390680208802\n",
      "Gradient for decoder.decoder.0.weight: 0.009152901358902454\n",
      "Gradient for decoder.decoder.0.bias: 8.581038657418105e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0004605300782714039\n",
      "Gradient for decoder.decoder.1.bias: 0.00041365111246705055\n",
      "Gradient for decoder.decoder.3.weight: 0.008725883439183235\n",
      "Gradient for decoder.decoder.3.bias: 9.407611495371171e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0005632170359604061\n",
      "Gradient for decoder.decoder.4.bias: 0.0006607577670365572\n",
      "Gradient for decoder.decoder.6.weight: 0.0013461167691275477\n",
      "Gradient for decoder.decoder.6.bias: 0.00012416149547789246\n",
      "Gradient for encoder.encoder.0.weight: 0.005394830834120512\n",
      "Gradient for encoder.encoder.0.bias: 6.732721585106516e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.00048986473120749\n",
      "Gradient for encoder.encoder.1.bias: 0.00048421885003335774\n",
      "Gradient for encoder.encoder.3.weight: 0.010320673696696758\n",
      "Gradient for encoder.encoder.3.bias: 1.0139775824535846e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.002453933469951153\n",
      "Gradient for encoder.encoder.4.bias: 0.001931460457853973\n",
      "Gradient for encoder.mean.weight: 0.035101067274808884\n",
      "Gradient for encoder.mean.bias: 0.001252259942702949\n",
      "Gradient for encoder.log_var.weight: 0.02148374915122986\n",
      "Gradient for encoder.log_var.bias: 0.0008719798061065376\n",
      "Gradient for decoder.decoder.0.weight: 0.013373004272580147\n",
      "Gradient for decoder.decoder.0.bias: 1.1734999083579112e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0006511727697215974\n",
      "Gradient for decoder.decoder.1.bias: 0.0005369700957089663\n",
      "Gradient for decoder.decoder.3.weight: 0.012247822247445583\n",
      "Gradient for decoder.decoder.3.bias: 1.0929986082874876e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0005342650110833347\n",
      "Gradient for decoder.decoder.4.bias: 0.0005295408191159368\n",
      "Gradient for decoder.decoder.6.weight: 0.0009263971005566418\n",
      "Gradient for decoder.decoder.6.bias: 4.8083486035466194e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training VAE Epoch:  77%|███████▋  | 61/79 [00:00<00:00, 77.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient for encoder.encoder.0.weight: 0.008371523581445217\n",
      "Gradient for encoder.encoder.0.bias: 1.2003849303443559e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0004560570523608476\n",
      "Gradient for encoder.encoder.1.bias: 0.0004554972692858428\n",
      "Gradient for encoder.encoder.3.weight: 0.009848366491496563\n",
      "Gradient for encoder.encoder.3.bias: 1.0168021286061091e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0021507421042770147\n",
      "Gradient for encoder.encoder.4.bias: 0.001961365807801485\n",
      "Gradient for encoder.mean.weight: 0.028803808614611626\n",
      "Gradient for encoder.mean.bias: 0.0012844169978052378\n",
      "Gradient for encoder.log_var.weight: 0.018165048211812973\n",
      "Gradient for encoder.log_var.bias: 0.0008639235165901482\n",
      "Gradient for decoder.decoder.0.weight: 0.009226987138390541\n",
      "Gradient for decoder.decoder.0.bias: 8.957000419140826e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.000441824144218117\n",
      "Gradient for decoder.decoder.1.bias: 0.00039319106144830585\n",
      "Gradient for decoder.decoder.3.weight: 0.008844468742609024\n",
      "Gradient for decoder.decoder.3.bias: 1.108486913370399e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0007187639130279422\n",
      "Gradient for decoder.decoder.4.bias: 0.0008856926579028368\n",
      "Gradient for decoder.decoder.6.weight: 0.0013323338935151696\n",
      "Gradient for decoder.decoder.6.bias: 0.00011851942690555006\n",
      "Gradient for encoder.encoder.0.weight: 0.008210575208067894\n",
      "Gradient for encoder.encoder.0.bias: 1.0628807729784473e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0005043006967753172\n",
      "Gradient for encoder.encoder.1.bias: 0.0005451374454423785\n",
      "Gradient for encoder.encoder.3.weight: 0.011470704339444637\n",
      "Gradient for encoder.encoder.3.bias: 1.1178977882275731e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.002861174987629056\n",
      "Gradient for encoder.encoder.4.bias: 0.0019566775299608707\n",
      "Gradient for encoder.mean.weight: 0.037238188087940216\n",
      "Gradient for encoder.mean.bias: 0.0013526659458875656\n",
      "Gradient for encoder.log_var.weight: 0.025109516456723213\n",
      "Gradient for encoder.log_var.bias: 0.0008724230574443936\n",
      "Gradient for decoder.decoder.0.weight: 0.010674439370632172\n",
      "Gradient for decoder.decoder.0.bias: 8.993807087964711e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0004990564193576574\n",
      "Gradient for decoder.decoder.1.bias: 0.00040844324394129217\n",
      "Gradient for decoder.decoder.3.weight: 0.00961568858474493\n",
      "Gradient for decoder.decoder.3.bias: 7.669759272133092e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0003951962571591139\n",
      "Gradient for decoder.decoder.4.bias: 0.00035135122016072273\n",
      "Gradient for decoder.decoder.6.weight: 0.0008877551881596446\n",
      "Gradient for decoder.decoder.6.bias: 5.09026249346789e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.008010962046682835\n",
      "Gradient for encoder.encoder.0.bias: 1.1954488614296377e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0005153933889232576\n",
      "Gradient for encoder.encoder.1.bias: 0.0005355668836273253\n",
      "Gradient for encoder.encoder.3.weight: 0.011438874527812004\n",
      "Gradient for encoder.encoder.3.bias: 1.1030453633820159e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.002238405868411064\n",
      "Gradient for encoder.encoder.4.bias: 0.001813576789572835\n",
      "Gradient for encoder.mean.weight: 0.03159118816256523\n",
      "Gradient for encoder.mean.bias: 0.0015248821582645178\n",
      "Gradient for encoder.log_var.weight: 0.0193933192640543\n",
      "Gradient for encoder.log_var.bias: 0.0009224779787473381\n",
      "Gradient for decoder.decoder.0.weight: 0.008988694287836552\n",
      "Gradient for decoder.decoder.0.bias: 7.32357716137777e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.00042687501991167665\n",
      "Gradient for decoder.decoder.1.bias: 0.00037939599133096635\n",
      "Gradient for decoder.decoder.3.weight: 0.008309004828333855\n",
      "Gradient for decoder.decoder.3.bias: 7.462573614613888e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00039950740756466985\n",
      "Gradient for decoder.decoder.4.bias: 0.00046708612353540957\n",
      "Gradient for decoder.decoder.6.weight: 0.0008921312401071191\n",
      "Gradient for decoder.decoder.6.bias: 5.456514554680325e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.0060004182159900665\n",
      "Gradient for encoder.encoder.0.bias: 7.940969062869563e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.0004889025585725904\n",
      "Gradient for encoder.encoder.1.bias: 0.000371843168977648\n",
      "Gradient for encoder.encoder.3.weight: 0.01063848938792944\n",
      "Gradient for encoder.encoder.3.bias: 1.0854005194627092e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0025442957412451506\n",
      "Gradient for encoder.encoder.4.bias: 0.0020747268572449684\n",
      "Gradient for encoder.mean.weight: 0.03731689229607582\n",
      "Gradient for encoder.mean.bias: 0.00147718982771039\n",
      "Gradient for encoder.log_var.weight: 0.020259063690900803\n",
      "Gradient for encoder.log_var.bias: 0.0009332274203188717\n",
      "Gradient for decoder.decoder.0.weight: 0.011594210751354694\n",
      "Gradient for decoder.decoder.0.bias: 9.719035992672431e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005960733979009092\n",
      "Gradient for decoder.decoder.1.bias: 0.000487179437186569\n",
      "Gradient for decoder.decoder.3.weight: 0.010900272987782955\n",
      "Gradient for decoder.decoder.3.bias: 9.373064130402398e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0005306062521412969\n",
      "Gradient for decoder.decoder.4.bias: 0.0005541620776057243\n",
      "Gradient for decoder.decoder.6.weight: 0.0009724079864099622\n",
      "Gradient for decoder.decoder.6.bias: 5.654714550473727e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.00750321988016367\n",
      "Gradient for encoder.encoder.0.bias: 9.884852485153584e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.0006495490670204163\n",
      "Gradient for encoder.encoder.1.bias: 0.0004926997935399413\n",
      "Gradient for encoder.encoder.3.weight: 0.014092842116951942\n",
      "Gradient for encoder.encoder.3.bias: 1.0860765065068279e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0035077205393463373\n",
      "Gradient for encoder.encoder.4.bias: 0.002672267612069845\n",
      "Gradient for encoder.mean.weight: 0.04963338002562523\n",
      "Gradient for encoder.mean.bias: 0.0018674515886232257\n",
      "Gradient for encoder.log_var.weight: 0.025560185313224792\n",
      "Gradient for encoder.log_var.bias: 0.0012270534643903375\n",
      "Gradient for decoder.decoder.0.weight: 0.011544148437678814\n",
      "Gradient for decoder.decoder.0.bias: 1.039883526510188e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.000557577470317483\n",
      "Gradient for decoder.decoder.1.bias: 0.0004903533263131976\n",
      "Gradient for decoder.decoder.3.weight: 0.010478260926902294\n",
      "Gradient for decoder.decoder.3.bias: 8.302395576587074e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00038953544571995735\n",
      "Gradient for decoder.decoder.4.bias: 0.0003942168259527534\n",
      "Gradient for decoder.decoder.6.weight: 0.0009111413382925093\n",
      "Gradient for decoder.decoder.6.bias: 5.11614307470154e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.009306666441261768\n",
      "Gradient for encoder.encoder.0.bias: 1.1610311670406936e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0004924735985696316\n",
      "Gradient for encoder.encoder.1.bias: 0.0005276404554024339\n",
      "Gradient for encoder.encoder.3.weight: 0.011267537251114845\n",
      "Gradient for encoder.encoder.3.bias: 1.0702547181828947e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0024092867970466614\n",
      "Gradient for encoder.encoder.4.bias: 0.0018047993071377277\n",
      "Gradient for encoder.mean.weight: 0.03344785422086716\n",
      "Gradient for encoder.mean.bias: 0.0014332383871078491\n",
      "Gradient for encoder.log_var.weight: 0.01971135474741459\n",
      "Gradient for encoder.log_var.bias: 0.001001917291432619\n",
      "Gradient for decoder.decoder.0.weight: 0.010582980699837208\n",
      "Gradient for decoder.decoder.0.bias: 8.921570426867476e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0004710284702014178\n",
      "Gradient for decoder.decoder.1.bias: 0.0004121630045119673\n",
      "Gradient for decoder.decoder.3.weight: 0.009590709581971169\n",
      "Gradient for decoder.decoder.3.bias: 7.447321231923709e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00034050975227728486\n",
      "Gradient for decoder.decoder.4.bias: 0.00029679815634153783\n",
      "Gradient for decoder.decoder.6.weight: 0.0009027211926877499\n",
      "Gradient for decoder.decoder.6.bias: 4.633610660675913e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.005213541444391012\n",
      "Gradient for encoder.encoder.0.bias: 8.08050501510671e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.00041708911885507405\n",
      "Gradient for encoder.encoder.1.bias: 0.00041754927951842546\n",
      "Gradient for encoder.encoder.3.weight: 0.009518921375274658\n",
      "Gradient for encoder.encoder.3.bias: 8.625718889154754e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.0022768178023397923\n",
      "Gradient for encoder.encoder.4.bias: 0.0015423109289258718\n",
      "Gradient for encoder.mean.weight: 0.03186291083693504\n",
      "Gradient for encoder.mean.bias: 0.00112582475412637\n",
      "Gradient for encoder.log_var.weight: 0.019554199650883675\n",
      "Gradient for encoder.log_var.bias: 0.0008344096131622791\n",
      "Gradient for decoder.decoder.0.weight: 0.011972082778811455\n",
      "Gradient for decoder.decoder.0.bias: 1.0961635765749378e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0005329700652509928\n",
      "Gradient for decoder.decoder.1.bias: 0.0005080537521280348\n",
      "Gradient for decoder.decoder.3.weight: 0.011071760207414627\n",
      "Gradient for decoder.decoder.3.bias: 9.404939327328776e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0004119236546102911\n",
      "Gradient for decoder.decoder.4.bias: 0.0003567172971088439\n",
      "Gradient for decoder.decoder.6.weight: 0.0008373229647986591\n",
      "Gradient for decoder.decoder.6.bias: 3.665071926661767e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.007126400712877512\n",
      "Gradient for encoder.encoder.0.bias: 9.209510758168005e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.0004706747713498771\n",
      "Gradient for encoder.encoder.1.bias: 0.000487122917547822\n",
      "Gradient for encoder.encoder.3.weight: 0.010602885857224464\n",
      "Gradient for encoder.encoder.3.bias: 1.0307917019947155e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0023511138278990984\n",
      "Gradient for encoder.encoder.4.bias: 0.0017655297415331006\n",
      "Gradient for encoder.mean.weight: 0.034701086580753326\n",
      "Gradient for encoder.mean.bias: 0.0012545047793537378\n",
      "Gradient for encoder.log_var.weight: 0.020372731611132622\n",
      "Gradient for encoder.log_var.bias: 0.0008718549506738782\n",
      "Gradient for decoder.decoder.0.weight: 0.0110697653144598\n",
      "Gradient for decoder.decoder.0.bias: 9.803952094600277e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005269467947073281\n",
      "Gradient for decoder.decoder.1.bias: 0.00044899724889546633\n",
      "Gradient for decoder.decoder.3.weight: 0.010637669824063778\n",
      "Gradient for decoder.decoder.3.bias: 8.134730389297573e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0004563252441585064\n",
      "Gradient for decoder.decoder.4.bias: 0.00047625787556171417\n",
      "Gradient for decoder.decoder.6.weight: 0.001126069575548172\n",
      "Gradient for decoder.decoder.6.bias: 8.991361391963437e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.007140269502997398\n",
      "Gradient for encoder.encoder.0.bias: 1.0544542669577162e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0004898219485767186\n",
      "Gradient for encoder.encoder.1.bias: 0.000449817773187533\n",
      "Gradient for encoder.encoder.3.weight: 0.011670968495309353\n",
      "Gradient for encoder.encoder.3.bias: 1.1333511212852088e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0023776288144290447\n",
      "Gradient for encoder.encoder.4.bias: 0.002062862506136298\n",
      "Gradient for encoder.mean.weight: 0.03542948514223099\n",
      "Gradient for encoder.mean.bias: 0.0016335936961695552\n",
      "Gradient for encoder.log_var.weight: 0.0175780039280653\n",
      "Gradient for encoder.log_var.bias: 0.0010132830357179046\n",
      "Gradient for decoder.decoder.0.weight: 0.011117570102214813\n",
      "Gradient for decoder.decoder.0.bias: 1.0149006635096214e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0005576172843575478\n",
      "Gradient for decoder.decoder.1.bias: 0.0005224268534220755\n",
      "Gradient for decoder.decoder.3.weight: 0.010112005285918713\n",
      "Gradient for decoder.decoder.3.bias: 8.476695734227491e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00040062962216325104\n",
      "Gradient for decoder.decoder.4.bias: 0.00037045267526991665\n",
      "Gradient for decoder.decoder.6.weight: 0.0008804099634289742\n",
      "Gradient for decoder.decoder.6.bias: 4.371343311504461e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.0051942504942417145\n",
      "Gradient for encoder.encoder.0.bias: 7.621484172937176e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.00043470950913615525\n",
      "Gradient for encoder.encoder.1.bias: 0.00042963121086359024\n",
      "Gradient for encoder.encoder.3.weight: 0.009797696955502033\n",
      "Gradient for encoder.encoder.3.bias: 9.318999738550104e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.002284751506522298\n",
      "Gradient for encoder.encoder.4.bias: 0.0015924073522910476\n",
      "Gradient for encoder.mean.weight: 0.03387051075696945\n",
      "Gradient for encoder.mean.bias: 0.0012111314572393894\n",
      "Gradient for encoder.log_var.weight: 0.018978266045451164\n",
      "Gradient for encoder.log_var.bias: 0.0008510266779921949\n",
      "Gradient for decoder.decoder.0.weight: 0.012564657256007195\n",
      "Gradient for decoder.decoder.0.bias: 1.1275556877077264e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0005629476509056985\n",
      "Gradient for decoder.decoder.1.bias: 0.0005416148342192173\n",
      "Gradient for decoder.decoder.3.weight: 0.01168909016996622\n",
      "Gradient for decoder.decoder.3.bias: 9.211924278940131e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00043695882777683437\n",
      "Gradient for decoder.decoder.4.bias: 0.0003941422328352928\n",
      "Gradient for decoder.decoder.6.weight: 0.000920805090572685\n",
      "Gradient for decoder.decoder.6.bias: 5.15852625539992e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.008834372274577618\n",
      "Gradient for encoder.encoder.0.bias: 1.0604916250711582e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0005559316487051547\n",
      "Gradient for encoder.encoder.1.bias: 0.0004845178918913007\n",
      "Gradient for encoder.encoder.3.weight: 0.012188701890408993\n",
      "Gradient for encoder.encoder.3.bias: 1.240824526460571e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.002965564839541912\n",
      "Gradient for encoder.encoder.4.bias: 0.002457255497574806\n",
      "Gradient for encoder.mean.weight: 0.041556019335985184\n",
      "Gradient for encoder.mean.bias: 0.0018737161299213767\n",
      "Gradient for encoder.log_var.weight: 0.02167576365172863\n",
      "Gradient for encoder.log_var.bias: 0.0012135058641433716\n",
      "Gradient for decoder.decoder.0.weight: 0.010922528803348541\n",
      "Gradient for decoder.decoder.0.bias: 1.0073517020536826e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0005682093324139714\n",
      "Gradient for decoder.decoder.1.bias: 0.0004493179148994386\n",
      "Gradient for decoder.decoder.3.weight: 0.010304687544703484\n",
      "Gradient for decoder.decoder.3.bias: 8.112748667299385e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.000445215409854427\n",
      "Gradient for decoder.decoder.4.bias: 0.0003882516175508499\n",
      "Gradient for decoder.decoder.6.weight: 0.0009279983933083713\n",
      "Gradient for decoder.decoder.6.bias: 4.878016625298187e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.006904647219926119\n",
      "Gradient for encoder.encoder.0.bias: 1.0148181774083387e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.00043430193909443915\n",
      "Gradient for encoder.encoder.1.bias: 0.00038084827247075737\n",
      "Gradient for encoder.encoder.3.weight: 0.010096553713083267\n",
      "Gradient for encoder.encoder.3.bias: 1.0999693517144138e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.002301679691299796\n",
      "Gradient for encoder.encoder.4.bias: 0.00197527720592916\n",
      "Gradient for encoder.mean.weight: 0.03333015739917755\n",
      "Gradient for encoder.mean.bias: 0.0016013773856684566\n",
      "Gradient for encoder.log_var.weight: 0.02036561630666256\n",
      "Gradient for encoder.log_var.bias: 0.0010472440626472235\n",
      "Gradient for decoder.decoder.0.weight: 0.010214108973741531\n",
      "Gradient for decoder.decoder.0.bias: 8.860304850921707e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.00048000054084695876\n",
      "Gradient for decoder.decoder.1.bias: 0.0004340412560850382\n",
      "Gradient for decoder.decoder.3.weight: 0.009487416595220566\n",
      "Gradient for decoder.decoder.3.bias: 8.967480924493287e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00044583025737665594\n",
      "Gradient for decoder.decoder.4.bias: 0.00043465764611028135\n",
      "Gradient for decoder.decoder.6.weight: 0.0009891155641525984\n",
      "Gradient for decoder.decoder.6.bias: 6.463291356340051e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.005896640010178089\n",
      "Gradient for encoder.encoder.0.bias: 8.589576966366863e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.0004532748134806752\n",
      "Gradient for encoder.encoder.1.bias: 0.0004412210255395621\n",
      "Gradient for encoder.encoder.3.weight: 0.010018566623330116\n",
      "Gradient for encoder.encoder.3.bias: 9.329188116469211e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.002443823264911771\n",
      "Gradient for encoder.encoder.4.bias: 0.001833745976909995\n",
      "Gradient for encoder.mean.weight: 0.03541252389550209\n",
      "Gradient for encoder.mean.bias: 0.001357459113933146\n",
      "Gradient for encoder.log_var.weight: 0.019093621522188187\n",
      "Gradient for encoder.log_var.bias: 0.0008923011482693255\n",
      "Gradient for decoder.decoder.0.weight: 0.01281084306538105\n",
      "Gradient for decoder.decoder.0.bias: 1.0602765193601371e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0006314793135970831\n",
      "Gradient for decoder.decoder.1.bias: 0.0005295582814142108\n",
      "Gradient for decoder.decoder.3.weight: 0.011693073436617851\n",
      "Gradient for decoder.decoder.3.bias: 1.0232358710338119e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0005255045252852142\n",
      "Gradient for decoder.decoder.4.bias: 0.000492869527079165\n",
      "Gradient for decoder.decoder.6.weight: 0.0009526672074571252\n",
      "Gradient for decoder.decoder.6.bias: 5.668499579769559e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.006795067340135574\n",
      "Gradient for encoder.encoder.0.bias: 8.245161497999476e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.0004627611779142171\n",
      "Gradient for encoder.encoder.1.bias: 0.00040881536551751196\n",
      "Gradient for encoder.encoder.3.weight: 0.010099279694259167\n",
      "Gradient for encoder.encoder.3.bias: 1.0317435794604535e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0020578571129590273\n",
      "Gradient for encoder.encoder.4.bias: 0.001771511510014534\n",
      "Gradient for encoder.mean.weight: 0.030894698575139046\n",
      "Gradient for encoder.mean.bias: 0.0014371356228366494\n",
      "Gradient for encoder.log_var.weight: 0.018952012062072754\n",
      "Gradient for encoder.log_var.bias: 0.0009753782069310546\n",
      "Gradient for decoder.decoder.0.weight: 0.012128373607993126\n",
      "Gradient for decoder.decoder.0.bias: 1.0990201110283593e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0005889025051146746\n",
      "Gradient for decoder.decoder.1.bias: 0.0005000614328309894\n",
      "Gradient for decoder.decoder.3.weight: 0.011498932726681232\n",
      "Gradient for decoder.decoder.3.bias: 9.710945936269866e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0004144224221818149\n",
      "Gradient for decoder.decoder.4.bias: 0.0003676501219160855\n",
      "Gradient for decoder.decoder.6.weight: 0.0010188671294599771\n",
      "Gradient for decoder.decoder.6.bias: 6.274504994507879e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.011687344871461391\n",
      "Gradient for encoder.encoder.0.bias: 1.7760065987304507e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0005816438351757824\n",
      "Gradient for encoder.encoder.1.bias: 0.00046555144945159554\n",
      "Gradient for encoder.encoder.3.weight: 0.01222923956811428\n",
      "Gradient for encoder.encoder.3.bias: 1.2578336983093408e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0027136821299791336\n",
      "Gradient for encoder.encoder.4.bias: 0.0025047266390174627\n",
      "Gradient for encoder.mean.weight: 0.038366738706827164\n",
      "Gradient for encoder.mean.bias: 0.002073406707495451\n",
      "Gradient for encoder.log_var.weight: 0.023126360028982162\n",
      "Gradient for encoder.log_var.bias: 0.0013353914255276322\n",
      "Gradient for decoder.decoder.0.weight: 0.00821291096508503\n",
      "Gradient for decoder.decoder.0.bias: 7.185262107523016e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0003930683305952698\n",
      "Gradient for decoder.decoder.1.bias: 0.00033527612686157227\n",
      "Gradient for decoder.decoder.3.weight: 0.007699035108089447\n",
      "Gradient for decoder.decoder.3.bias: 8.299746306894562e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00047859628102742136\n",
      "Gradient for decoder.decoder.4.bias: 0.0005570739740505815\n",
      "Gradient for decoder.decoder.6.weight: 0.0009398714755661786\n",
      "Gradient for decoder.decoder.6.bias: 6.368790491251275e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.004478235729038715\n",
      "Gradient for encoder.encoder.0.bias: 6.22866515309628e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.0004207749152556062\n",
      "Gradient for encoder.encoder.1.bias: 0.000505554024130106\n",
      "Gradient for encoder.encoder.3.weight: 0.00941418670117855\n",
      "Gradient for encoder.encoder.3.bias: 1.0831993635385118e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0032193013466894627\n",
      "Gradient for encoder.encoder.4.bias: 0.002705065067857504\n",
      "Gradient for encoder.mean.weight: 0.04611274227499962\n",
      "Gradient for encoder.mean.bias: 0.0020202987361699343\n",
      "Gradient for encoder.log_var.weight: 0.026817582547664642\n",
      "Gradient for encoder.log_var.bias: 0.001220264588482678\n",
      "Gradient for decoder.decoder.0.weight: 0.013108963146805763\n",
      "Gradient for decoder.decoder.0.bias: 1.1621430900943253e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0006594628794118762\n",
      "Gradient for decoder.decoder.1.bias: 0.0005421482492238283\n",
      "Gradient for decoder.decoder.3.weight: 0.012335789389908314\n",
      "Gradient for decoder.decoder.3.bias: 9.847429816023379e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00046709590242244303\n",
      "Gradient for decoder.decoder.4.bias: 0.0004128101863898337\n",
      "Gradient for decoder.decoder.6.weight: 0.0008622996974736452\n",
      "Gradient for decoder.decoder.6.bias: 3.62285427399911e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.007426963187754154\n",
      "Gradient for encoder.encoder.0.bias: 1.0357763258195263e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0005223244661465287\n",
      "Gradient for encoder.encoder.1.bias: 0.0004292527446523309\n",
      "Gradient for encoder.encoder.3.weight: 0.011367366649210453\n",
      "Gradient for encoder.encoder.3.bias: 9.758900632039769e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.0023957875091582537\n",
      "Gradient for encoder.encoder.4.bias: 0.0018461381550878286\n",
      "Gradient for encoder.mean.weight: 0.03182937204837799\n",
      "Gradient for encoder.mean.bias: 0.0014560507843270898\n",
      "Gradient for encoder.log_var.weight: 0.019377708435058594\n",
      "Gradient for encoder.log_var.bias: 0.0009656464098952711\n",
      "Gradient for decoder.decoder.0.weight: 0.010742775164544582\n",
      "Gradient for decoder.decoder.0.bias: 8.52824824648657e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005021324614062905\n",
      "Gradient for decoder.decoder.1.bias: 0.0004299699794501066\n",
      "Gradient for decoder.decoder.3.weight: 0.009828311391174793\n",
      "Gradient for decoder.decoder.3.bias: 7.557272169167462e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00038873706944286823\n",
      "Gradient for decoder.decoder.4.bias: 0.0003160427149850875\n",
      "Gradient for decoder.decoder.6.weight: 0.000901130901183933\n",
      "Gradient for decoder.decoder.6.bias: 4.1929990402422845e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient for encoder.encoder.0.weight: 0.007887194864451885\n",
      "Gradient for encoder.encoder.0.bias: 1.0680712390909175e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.00047130821621976793\n",
      "Gradient for encoder.encoder.1.bias: 0.00046057766303420067\n",
      "Gradient for encoder.encoder.3.weight: 0.010670775547623634\n",
      "Gradient for encoder.encoder.3.bias: 1.0343666895229475e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.002603287110105157\n",
      "Gradient for encoder.encoder.4.bias: 0.0019981088116765022\n",
      "Gradient for encoder.mean.weight: 0.03431538864970207\n",
      "Gradient for encoder.mean.bias: 0.001479297992773354\n",
      "Gradient for encoder.log_var.weight: 0.020778827369213104\n",
      "Gradient for encoder.log_var.bias: 0.001037424779497087\n",
      "Gradient for decoder.decoder.0.weight: 0.011791558004915714\n",
      "Gradient for decoder.decoder.0.bias: 9.911171189314061e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005639793234877288\n",
      "Gradient for decoder.decoder.1.bias: 0.00048272544518113136\n",
      "Gradient for decoder.decoder.3.weight: 0.011028509587049484\n",
      "Gradient for decoder.decoder.3.bias: 9.771284475990072e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00044990479364059865\n",
      "Gradient for decoder.decoder.4.bias: 0.0004180755640845746\n",
      "Gradient for decoder.decoder.6.weight: 0.0010142485843971372\n",
      "Gradient for decoder.decoder.6.bias: 6.484882032964379e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.006769854109734297\n",
      "Gradient for encoder.encoder.0.bias: 1.0301924244227045e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0005038403323851526\n",
      "Gradient for encoder.encoder.1.bias: 0.0006339704850688577\n",
      "Gradient for encoder.encoder.3.weight: 0.011427979916334152\n",
      "Gradient for encoder.encoder.3.bias: 1.1580728737081714e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0027747415006160736\n",
      "Gradient for encoder.encoder.4.bias: 0.0026028428692370653\n",
      "Gradient for encoder.mean.weight: 0.03741414472460747\n",
      "Gradient for encoder.mean.bias: 0.0021405385341495275\n",
      "Gradient for encoder.log_var.weight: 0.026454513892531395\n",
      "Gradient for encoder.log_var.bias: 0.001480857958085835\n",
      "Gradient for decoder.decoder.0.weight: 0.011394158005714417\n",
      "Gradient for decoder.decoder.0.bias: 8.638412207773172e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005627626669593155\n",
      "Gradient for decoder.decoder.1.bias: 0.00045383040560409427\n",
      "Gradient for decoder.decoder.3.weight: 0.011127731762826443\n",
      "Gradient for decoder.decoder.3.bias: 8.716859872803795e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00047598383389413357\n",
      "Gradient for decoder.decoder.4.bias: 0.00047342973994091153\n",
      "Gradient for decoder.decoder.6.weight: 0.0010643408168107271\n",
      "Gradient for decoder.decoder.6.bias: 8.242072362918407e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.006910386029630899\n",
      "Gradient for encoder.encoder.0.bias: 9.074487689053612e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.00048003505798988044\n",
      "Gradient for encoder.encoder.1.bias: 0.0005092724459245801\n",
      "Gradient for encoder.encoder.3.weight: 0.011147246696054935\n",
      "Gradient for encoder.encoder.3.bias: 1.0207457101785167e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.002175833797082305\n",
      "Gradient for encoder.encoder.4.bias: 0.0019153382163494825\n",
      "Gradient for encoder.mean.weight: 0.029208285734057426\n",
      "Gradient for encoder.mean.bias: 0.0015896217664703727\n",
      "Gradient for encoder.log_var.weight: 0.019464299082756042\n",
      "Gradient for encoder.log_var.bias: 0.0011320386547595263\n",
      "Gradient for decoder.decoder.0.weight: 0.01201507356017828\n",
      "Gradient for decoder.decoder.0.bias: 1.1230470026157846e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0005850508459843695\n",
      "Gradient for decoder.decoder.1.bias: 0.0004693809023592621\n",
      "Gradient for decoder.decoder.3.weight: 0.011213961988687515\n",
      "Gradient for decoder.decoder.3.bias: 9.300576975235231e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00040853506652638316\n",
      "Gradient for decoder.decoder.4.bias: 0.0003549793909769505\n",
      "Gradient for decoder.decoder.6.weight: 0.000930223090108484\n",
      "Gradient for decoder.decoder.6.bias: 5.1016646466450766e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.0045470502227544785\n",
      "Gradient for encoder.encoder.0.bias: 7.316257842615581e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.00040685164276510477\n",
      "Gradient for encoder.encoder.1.bias: 0.0005411999300122261\n",
      "Gradient for encoder.encoder.3.weight: 0.008916557766497135\n",
      "Gradient for encoder.encoder.3.bias: 9.658571858972564e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.0027582065667957067\n",
      "Gradient for encoder.encoder.4.bias: 0.002022743923589587\n",
      "Gradient for encoder.mean.weight: 0.0415683388710022\n",
      "Gradient for encoder.mean.bias: 0.0016510962741449475\n",
      "Gradient for encoder.log_var.weight: 0.02277560904622078\n",
      "Gradient for encoder.log_var.bias: 0.0010290100472047925\n",
      "Gradient for decoder.decoder.0.weight: 0.013019144535064697\n",
      "Gradient for decoder.decoder.0.bias: 1.1145740580476016e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0006460326840169728\n",
      "Gradient for decoder.decoder.1.bias: 0.000502823677379638\n",
      "Gradient for decoder.decoder.3.weight: 0.012333624996244907\n",
      "Gradient for decoder.decoder.3.bias: 9.738291423255774e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00044426729436963797\n",
      "Gradient for decoder.decoder.4.bias: 0.00040867464849725366\n",
      "Gradient for decoder.decoder.6.weight: 0.0008458229713141918\n",
      "Gradient for decoder.decoder.6.bias: 4.110126246814616e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.007009292021393776\n",
      "Gradient for encoder.encoder.0.bias: 1.0638597641721148e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0005233288975432515\n",
      "Gradient for encoder.encoder.1.bias: 0.0005000693490728736\n",
      "Gradient for encoder.encoder.3.weight: 0.011789124459028244\n",
      "Gradient for encoder.encoder.3.bias: 1.0055400262443115e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0025550525169819593\n",
      "Gradient for encoder.encoder.4.bias: 0.001964328344911337\n",
      "Gradient for encoder.mean.weight: 0.03494184464216232\n",
      "Gradient for encoder.mean.bias: 0.0016202752012759447\n",
      "Gradient for encoder.log_var.weight: 0.018086453899741173\n",
      "Gradient for encoder.log_var.bias: 0.0009149608085863292\n",
      "Gradient for decoder.decoder.0.weight: 0.010178562253713608\n",
      "Gradient for decoder.decoder.0.bias: 8.550149477315472e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.00048291313578374684\n",
      "Gradient for decoder.decoder.1.bias: 0.00041039203642867506\n",
      "Gradient for decoder.decoder.3.weight: 0.009401258081197739\n",
      "Gradient for decoder.decoder.3.bias: 8.167400089575949e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00035609284532256424\n",
      "Gradient for decoder.decoder.4.bias: 0.00031861814204603434\n",
      "Gradient for decoder.decoder.6.weight: 0.0008608581265434623\n",
      "Gradient for decoder.decoder.6.bias: 5.084465374238789e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.006172622088342905\n",
      "Gradient for encoder.encoder.0.bias: 8.327175754496707e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.0004379216697998345\n",
      "Gradient for encoder.encoder.1.bias: 0.0004921387298963964\n",
      "Gradient for encoder.encoder.3.weight: 0.009608817286789417\n",
      "Gradient for encoder.encoder.3.bias: 9.290670316408622e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.0025696605443954468\n",
      "Gradient for encoder.encoder.4.bias: 0.0017166591715067625\n",
      "Gradient for encoder.mean.weight: 0.036748968064785004\n",
      "Gradient for encoder.mean.bias: 0.001335859065875411\n",
      "Gradient for encoder.log_var.weight: 0.019678903743624687\n",
      "Gradient for encoder.log_var.bias: 0.0008751872228458524\n",
      "Gradient for decoder.decoder.0.weight: 0.01141493208706379\n",
      "Gradient for decoder.decoder.0.bias: 9.294209846189005e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005362353986129165\n",
      "Gradient for decoder.decoder.1.bias: 0.000458329392131418\n",
      "Gradient for decoder.decoder.3.weight: 0.010726787149906158\n",
      "Gradient for decoder.decoder.3.bias: 8.040392657227002e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0003869412757921964\n",
      "Gradient for decoder.decoder.4.bias: 0.0003478823637124151\n",
      "Gradient for decoder.decoder.6.weight: 0.0008506347658112645\n",
      "Gradient for decoder.decoder.6.bias: 4.0646067645866424e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.00579087994992733\n",
      "Gradient for encoder.encoder.0.bias: 9.130050881989149e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.00044421665370464325\n",
      "Gradient for encoder.encoder.1.bias: 0.0003916935238521546\n",
      "Gradient for encoder.encoder.3.weight: 0.00986888911575079\n",
      "Gradient for encoder.encoder.3.bias: 1.0572869663105777e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0025777004193514585\n",
      "Gradient for encoder.encoder.4.bias: 0.0025763027369976044\n",
      "Gradient for encoder.mean.weight: 0.036454781889915466\n",
      "Gradient for encoder.mean.bias: 0.0022424578201025724\n",
      "Gradient for encoder.log_var.weight: 0.02472377009689808\n",
      "Gradient for encoder.log_var.bias: 0.0016073782462626696\n",
      "Gradient for decoder.decoder.0.weight: 0.011526505462825298\n",
      "Gradient for decoder.decoder.0.bias: 9.583840665516874e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.000526196847204119\n",
      "Gradient for decoder.decoder.1.bias: 0.00045632090768776834\n",
      "Gradient for decoder.decoder.3.weight: 0.010781734250485897\n",
      "Gradient for decoder.decoder.3.bias: 9.336790368630332e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00041930796578526497\n",
      "Gradient for decoder.decoder.4.bias: 0.0003667686542030424\n",
      "Gradient for decoder.decoder.6.weight: 0.0009149548131972551\n",
      "Gradient for decoder.decoder.6.bias: 5.4456726502394304e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.005331345368176699\n",
      "Gradient for encoder.encoder.0.bias: 8.849540891753271e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.00038456215406768024\n",
      "Gradient for encoder.encoder.1.bias: 0.00036668989923782647\n",
      "Gradient for encoder.encoder.3.weight: 0.008435791358351707\n",
      "Gradient for encoder.encoder.3.bias: 9.390924843311055e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.002224365249276161\n",
      "Gradient for encoder.encoder.4.bias: 0.0018536787247285247\n",
      "Gradient for encoder.mean.weight: 0.03076297789812088\n",
      "Gradient for encoder.mean.bias: 0.0015288102440536022\n",
      "Gradient for encoder.log_var.weight: 0.022597404196858406\n",
      "Gradient for encoder.log_var.bias: 0.001121350098401308\n",
      "Gradient for decoder.decoder.0.weight: 0.012909921817481518\n",
      "Gradient for decoder.decoder.0.bias: 1.0354300056247823e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0005931865889579058\n",
      "Gradient for decoder.decoder.1.bias: 0.000489799480419606\n",
      "Gradient for decoder.decoder.3.weight: 0.011704289354383945\n",
      "Gradient for decoder.decoder.3.bias: 1.0229869729094787e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0005070874467492104\n",
      "Gradient for decoder.decoder.4.bias: 0.0005413281614892185\n",
      "Gradient for decoder.decoder.6.weight: 0.0008528921753168106\n",
      "Gradient for decoder.decoder.6.bias: 4.793137122760527e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.005140288267284632\n",
      "Gradient for encoder.encoder.0.bias: 7.901056545134288e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.000433463545050472\n",
      "Gradient for encoder.encoder.1.bias: 0.00044578881352208555\n",
      "Gradient for encoder.encoder.3.weight: 0.009973273612558842\n",
      "Gradient for encoder.encoder.3.bias: 8.835722431488335e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.0026350871194154024\n",
      "Gradient for encoder.encoder.4.bias: 0.0017337457975372672\n",
      "Gradient for encoder.mean.weight: 0.03894439712166786\n",
      "Gradient for encoder.mean.bias: 0.001323160482570529\n",
      "Gradient for encoder.log_var.weight: 0.02177254669368267\n",
      "Gradient for encoder.log_var.bias: 0.0008302883361466229\n",
      "Gradient for decoder.decoder.0.weight: 0.013277055695652962\n",
      "Gradient for decoder.decoder.0.bias: 1.2241321845074538e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0006134830182418227\n",
      "Gradient for decoder.decoder.1.bias: 0.0005161607405170798\n",
      "Gradient for decoder.decoder.3.weight: 0.01193635631352663\n",
      "Gradient for decoder.decoder.3.bias: 1.1142661793250852e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0005503033171407878\n",
      "Gradient for decoder.decoder.4.bias: 0.0005690670222975314\n",
      "Gradient for decoder.decoder.6.weight: 0.0009162515052594244\n",
      "Gradient for decoder.decoder.6.bias: 4.28438070230186e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.007893195375800133\n",
      "Gradient for encoder.encoder.0.bias: 9.69758388175146e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.0005771343130618334\n",
      "Gradient for encoder.encoder.1.bias: 0.000546647235751152\n",
      "Gradient for encoder.encoder.3.weight: 0.012783230282366276\n",
      "Gradient for encoder.encoder.3.bias: 9.9886356130785e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.002882616128772497\n",
      "Gradient for encoder.encoder.4.bias: 0.002202380681410432\n",
      "Gradient for encoder.mean.weight: 0.03996918350458145\n",
      "Gradient for encoder.mean.bias: 0.0017661791061982512\n",
      "Gradient for encoder.log_var.weight: 0.021646378561854362\n",
      "Gradient for encoder.log_var.bias: 0.0010823090560734272\n",
      "Gradient for decoder.decoder.0.weight: 0.010897141881287098\n",
      "Gradient for decoder.decoder.0.bias: 9.40377289926353e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005114549421705306\n",
      "Gradient for decoder.decoder.1.bias: 0.0004332914249971509\n",
      "Gradient for decoder.decoder.3.weight: 0.01011049747467041\n",
      "Gradient for decoder.decoder.3.bias: 8.200257833879121e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00038592590135522187\n",
      "Gradient for decoder.decoder.4.bias: 0.0003372752107679844\n",
      "Gradient for decoder.decoder.6.weight: 0.0009121320326812565\n",
      "Gradient for decoder.decoder.6.bias: 4.2961295548593625e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.004652538802474737\n",
      "Gradient for encoder.encoder.0.bias: 8.350289210090622e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.00047422663192264736\n",
      "Gradient for encoder.encoder.1.bias: 0.0005345110548660159\n",
      "Gradient for encoder.encoder.3.weight: 0.010343819856643677\n",
      "Gradient for encoder.encoder.3.bias: 1.1439456326645114e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0033900782000273466\n",
      "Gradient for encoder.encoder.4.bias: 0.0028555712196975946\n",
      "Gradient for encoder.mean.weight: 0.047004975378513336\n",
      "Gradient for encoder.mean.bias: 0.002420179545879364\n",
      "Gradient for encoder.log_var.weight: 0.0274242851883173\n",
      "Gradient for encoder.log_var.bias: 0.001474476419389248\n",
      "Gradient for decoder.decoder.0.weight: 0.012038118205964565\n",
      "Gradient for decoder.decoder.0.bias: 1.0091587981930772e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.000637820630799979\n",
      "Gradient for decoder.decoder.1.bias: 0.000512430036906153\n",
      "Gradient for decoder.decoder.3.weight: 0.011442862451076508\n",
      "Gradient for decoder.decoder.3.bias: 1.1419955953106964e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0007407977827824652\n",
      "Gradient for decoder.decoder.4.bias: 0.0009345099097117782\n",
      "Gradient for decoder.decoder.6.weight: 0.0011702381307259202\n",
      "Gradient for decoder.decoder.6.bias: 0.00010085905523737893\n",
      "Gradient for encoder.encoder.0.weight: 0.004886183422058821\n",
      "Gradient for encoder.encoder.0.bias: 7.63792761676596e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.0004116485361009836\n",
      "Gradient for encoder.encoder.1.bias: 0.0003797495737671852\n",
      "Gradient for encoder.encoder.3.weight: 0.009048531763255596\n",
      "Gradient for encoder.encoder.3.bias: 1.1641082542368508e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0025603175163269043\n",
      "Gradient for encoder.encoder.4.bias: 0.0024922234006226063\n",
      "Gradient for encoder.mean.weight: 0.034706346690654755\n",
      "Gradient for encoder.mean.bias: 0.0018469899659976363\n",
      "Gradient for encoder.log_var.weight: 0.022344864904880524\n",
      "Gradient for encoder.log_var.bias: 0.0013031557900831103\n",
      "Gradient for decoder.decoder.0.weight: 0.012372616678476334\n",
      "Gradient for decoder.decoder.0.bias: 1.1261477861346236e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0005829373840242624\n",
      "Gradient for decoder.decoder.1.bias: 0.0005033795605413616\n",
      "Gradient for decoder.decoder.3.weight: 0.011178724467754364\n",
      "Gradient for decoder.decoder.3.bias: 9.619525315196498e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0005007106810808182\n",
      "Gradient for decoder.decoder.4.bias: 0.0004914168384857476\n",
      "Gradient for decoder.decoder.6.weight: 0.0009545714128762484\n",
      "Gradient for decoder.decoder.6.bias: 5.5755921493982896e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.00913199968636036\n",
      "Gradient for encoder.encoder.0.bias: 1.3775060953014062e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0005757297039963305\n",
      "Gradient for encoder.encoder.1.bias: 0.0007255207747220993\n",
      "Gradient for encoder.encoder.3.weight: 0.012461784295737743\n",
      "Gradient for encoder.encoder.3.bias: 1.703747698478253e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0046402751468122005\n",
      "Gradient for encoder.encoder.4.bias: 0.0040697273798286915\n",
      "Gradient for encoder.mean.weight: 0.06772568821907043\n",
      "Gradient for encoder.mean.bias: 0.0026814951561391354\n",
      "Gradient for encoder.log_var.weight: 0.03801283240318298\n",
      "Gradient for encoder.log_var.bias: 0.0020990553312003613\n",
      "Gradient for decoder.decoder.0.weight: 0.03642616048455238\n",
      "Gradient for decoder.decoder.0.bias: 2.3160828810375733e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.001477599609643221\n",
      "Gradient for decoder.decoder.1.bias: 0.001349273370578885\n",
      "Gradient for decoder.decoder.3.weight: 0.03168753162026405\n",
      "Gradient for decoder.decoder.3.bias: 2.3747043220723185e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0010694606462493539\n",
      "Gradient for decoder.decoder.4.bias: 0.0009764705901034176\n",
      "Gradient for decoder.decoder.6.weight: 0.002204131567850709\n",
      "Gradient for decoder.decoder.6.bias: 0.00011977370013482869\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3, Train Loss: 0.0783, Val Loss: 0.2431\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training VAE Epoch:  13%|█▎        | 10/79 [00:00<00:01, 36.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient for encoder.encoder.0.weight: 0.005628370679914951\n",
      "Gradient for encoder.encoder.0.bias: 7.773162322144422e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.000444938603322953\n",
      "Gradient for encoder.encoder.1.bias: 0.0005194209516048431\n",
      "Gradient for encoder.encoder.3.weight: 0.009936847724020481\n",
      "Gradient for encoder.encoder.3.bias: 9.440384585168715e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.0026891694869846106\n",
      "Gradient for encoder.encoder.4.bias: 0.0017200455768033862\n",
      "Gradient for encoder.mean.weight: 0.03793887421488762\n",
      "Gradient for encoder.mean.bias: 0.0013526987750083208\n",
      "Gradient for encoder.log_var.weight: 0.025824138894677162\n",
      "Gradient for encoder.log_var.bias: 0.0010976919438689947\n",
      "Gradient for decoder.decoder.0.weight: 0.01232912391424179\n",
      "Gradient for decoder.decoder.0.bias: 1.1701026259025582e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0006932446267455816\n",
      "Gradient for decoder.decoder.1.bias: 0.0004893819568678737\n",
      "Gradient for decoder.decoder.3.weight: 0.011702251620590687\n",
      "Gradient for decoder.decoder.3.bias: 1.0754702683968276e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0004187134327366948\n",
      "Gradient for decoder.decoder.4.bias: 0.00038818211760371923\n",
      "Gradient for decoder.decoder.6.weight: 0.0008421014645136893\n",
      "Gradient for decoder.decoder.6.bias: 3.840802310151048e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.009960003197193146\n",
      "Gradient for encoder.encoder.0.bias: 1.3170112569960146e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0006464877515099943\n",
      "Gradient for encoder.encoder.1.bias: 0.0005846621934324503\n",
      "Gradient for encoder.encoder.3.weight: 0.013873351737856865\n",
      "Gradient for encoder.encoder.3.bias: 1.3583811853123962e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.003856697818264365\n",
      "Gradient for encoder.encoder.4.bias: 0.003009143518283963\n",
      "Gradient for encoder.mean.weight: 0.05073397606611252\n",
      "Gradient for encoder.mean.bias: 0.0023284568451344967\n",
      "Gradient for encoder.log_var.weight: 0.03050316497683525\n",
      "Gradient for encoder.log_var.bias: 0.0014634887920692563\n",
      "Gradient for decoder.decoder.0.weight: 0.010678435675799847\n",
      "Gradient for decoder.decoder.0.bias: 1.0301966224535164e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0005099693080410361\n",
      "Gradient for decoder.decoder.1.bias: 0.00045897168456576765\n",
      "Gradient for decoder.decoder.3.weight: 0.009708293713629246\n",
      "Gradient for decoder.decoder.3.bias: 1.0863347027489922e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0003866575425490737\n",
      "Gradient for decoder.decoder.4.bias: 0.00031365599716082215\n",
      "Gradient for decoder.decoder.6.weight: 0.0009215657482855022\n",
      "Gradient for decoder.decoder.6.bias: 5.114174200571142e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.004201952833682299\n",
      "Gradient for encoder.encoder.0.bias: 6.7099390280156435e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.00046636248589493334\n",
      "Gradient for encoder.encoder.1.bias: 0.0004472475266084075\n",
      "Gradient for encoder.encoder.3.weight: 0.010247028432786465\n",
      "Gradient for encoder.encoder.3.bias: 8.93090254527884e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.0027529029175639153\n",
      "Gradient for encoder.encoder.4.bias: 0.0019221495604142547\n",
      "Gradient for encoder.mean.weight: 0.04126867651939392\n",
      "Gradient for encoder.mean.bias: 0.001516493852250278\n",
      "Gradient for encoder.log_var.weight: 0.025289883837103844\n",
      "Gradient for encoder.log_var.bias: 0.0012264213291928172\n",
      "Gradient for decoder.decoder.0.weight: 0.013301919214427471\n",
      "Gradient for decoder.decoder.0.bias: 1.1111817022069204e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0006386570748873055\n",
      "Gradient for decoder.decoder.1.bias: 0.0005422494141384959\n",
      "Gradient for decoder.decoder.3.weight: 0.01243333239108324\n",
      "Gradient for decoder.decoder.3.bias: 1.1605761490729449e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0006196956383064389\n",
      "Gradient for decoder.decoder.4.bias: 0.000588641909416765\n",
      "Gradient for decoder.decoder.6.weight: 0.0012646701652556658\n",
      "Gradient for decoder.decoder.6.bias: 0.00010416698933113366\n",
      "Gradient for encoder.encoder.0.weight: 0.006010053679347038\n",
      "Gradient for encoder.encoder.0.bias: 7.923300036905001e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.00046350702177733183\n",
      "Gradient for encoder.encoder.1.bias: 0.0005129736382514238\n",
      "Gradient for encoder.encoder.3.weight: 0.010407616384327412\n",
      "Gradient for encoder.encoder.3.bias: 1.0859783211580876e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.003125343471765518\n",
      "Gradient for encoder.encoder.4.bias: 0.002459005918353796\n",
      "Gradient for encoder.mean.weight: 0.04493945837020874\n",
      "Gradient for encoder.mean.bias: 0.001917228801175952\n",
      "Gradient for encoder.log_var.weight: 0.027084527537226677\n",
      "Gradient for encoder.log_var.bias: 0.0013253448996692896\n",
      "Gradient for decoder.decoder.0.weight: 0.012469222769141197\n",
      "Gradient for decoder.decoder.0.bias: 1.0860080890129353e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0005776445614174008\n",
      "Gradient for decoder.decoder.1.bias: 0.0004664696753025055\n",
      "Gradient for decoder.decoder.3.weight: 0.011156667023897171\n",
      "Gradient for decoder.decoder.3.bias: 9.259222555346724e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0004132523317821324\n",
      "Gradient for decoder.decoder.4.bias: 0.00038221871363930404\n",
      "Gradient for decoder.decoder.6.weight: 0.0008915708167478442\n",
      "Gradient for decoder.decoder.6.bias: 5.119490379001945e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.007954106666147709\n",
      "Gradient for encoder.encoder.0.bias: 1.1331514719603586e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0004955099429935217\n",
      "Gradient for encoder.encoder.1.bias: 0.0005110657657496631\n",
      "Gradient for encoder.encoder.3.weight: 0.011136465705931187\n",
      "Gradient for encoder.encoder.3.bias: 1.0010305084851012e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.002246113959699869\n",
      "Gradient for encoder.encoder.4.bias: 0.0017181307775899768\n",
      "Gradient for encoder.mean.weight: 0.032061368227005005\n",
      "Gradient for encoder.mean.bias: 0.001380251720547676\n",
      "Gradient for encoder.log_var.weight: 0.01953345164656639\n",
      "Gradient for encoder.log_var.bias: 0.000998736242763698\n",
      "Gradient for decoder.decoder.0.weight: 0.00887404102832079\n",
      "Gradient for decoder.decoder.0.bias: 7.256765327534609e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0004282172885723412\n",
      "Gradient for decoder.decoder.1.bias: 0.00037915530265308917\n",
      "Gradient for decoder.decoder.3.weight: 0.008418470621109009\n",
      "Gradient for decoder.decoder.3.bias: 7.068855917280459e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.000342907733283937\n",
      "Gradient for decoder.decoder.4.bias: 0.00032814196310937405\n",
      "Gradient for decoder.decoder.6.weight: 0.0008861960959620774\n",
      "Gradient for decoder.decoder.6.bias: 5.248938032309525e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.006546497344970703\n",
      "Gradient for encoder.encoder.0.bias: 9.761719210743536e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.0004342947213444859\n",
      "Gradient for encoder.encoder.1.bias: 0.00039564090548083186\n",
      "Gradient for encoder.encoder.3.weight: 0.00920988991856575\n",
      "Gradient for encoder.encoder.3.bias: 9.117627486343594e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.0023209459614008665\n",
      "Gradient for encoder.encoder.4.bias: 0.0018352180486544967\n",
      "Gradient for encoder.mean.weight: 0.03240276128053665\n",
      "Gradient for encoder.mean.bias: 0.0014691200340166688\n",
      "Gradient for encoder.log_var.weight: 0.021175943315029144\n",
      "Gradient for encoder.log_var.bias: 0.0011193237733095884\n",
      "Gradient for decoder.decoder.0.weight: 0.011297614313662052\n",
      "Gradient for decoder.decoder.0.bias: 9.803734907221084e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005172587698325515\n",
      "Gradient for decoder.decoder.1.bias: 0.00045777473133057356\n",
      "Gradient for decoder.decoder.3.weight: 0.009962842799723148\n",
      "Gradient for decoder.decoder.3.bias: 1.0232276137500662e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0005834597977809608\n",
      "Gradient for decoder.decoder.4.bias: 0.0006616244791075587\n",
      "Gradient for decoder.decoder.6.weight: 0.0009362349519506097\n",
      "Gradient for decoder.decoder.6.bias: 6.47106280666776e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.005897363647818565\n",
      "Gradient for encoder.encoder.0.bias: 8.89883826349358e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.0004906784160993993\n",
      "Gradient for encoder.encoder.1.bias: 0.00045929374755360186\n",
      "Gradient for encoder.encoder.3.weight: 0.01057671383023262\n",
      "Gradient for encoder.encoder.3.bias: 9.77879305308349e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.0023924382403492928\n",
      "Gradient for encoder.encoder.4.bias: 0.001927706180140376\n",
      "Gradient for encoder.mean.weight: 0.036034490913152695\n",
      "Gradient for encoder.mean.bias: 0.0015490620862692595\n",
      "Gradient for encoder.log_var.weight: 0.019396495074033737\n",
      "Gradient for encoder.log_var.bias: 0.0010541003430262208\n",
      "Gradient for decoder.decoder.0.weight: 0.011834988370537758\n",
      "Gradient for decoder.decoder.0.bias: 1.0117425647271361e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0005447075818665326\n",
      "Gradient for decoder.decoder.1.bias: 0.000462426251033321\n",
      "Gradient for decoder.decoder.3.weight: 0.01149585098028183\n",
      "Gradient for decoder.decoder.3.bias: 9.122688715557103e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00042512835352681577\n",
      "Gradient for decoder.decoder.4.bias: 0.0003592587891034782\n",
      "Gradient for decoder.decoder.6.weight: 0.0008592148078605533\n",
      "Gradient for decoder.decoder.6.bias: 4.0803730371408165e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.010014169849455357\n",
      "Gradient for encoder.encoder.0.bias: 1.7325276630009157e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0006082653417252004\n",
      "Gradient for encoder.encoder.1.bias: 0.0005219982704147696\n",
      "Gradient for encoder.encoder.3.weight: 0.0132394814863801\n",
      "Gradient for encoder.encoder.3.bias: 1.2942541482985348e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.002700340235605836\n",
      "Gradient for encoder.encoder.4.bias: 0.002409545937553048\n",
      "Gradient for encoder.mean.weight: 0.03824911266565323\n",
      "Gradient for encoder.mean.bias: 0.0019347951747477055\n",
      "Gradient for encoder.log_var.weight: 0.025828151032328606\n",
      "Gradient for encoder.log_var.bias: 0.001527369604445994\n",
      "Gradient for decoder.decoder.0.weight: 0.009221627376973629\n",
      "Gradient for decoder.decoder.0.bias: 7.687332020944737e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0004288235795684159\n",
      "Gradient for decoder.decoder.1.bias: 0.00038238405250012875\n",
      "Gradient for decoder.decoder.3.weight: 0.00829240307211876\n",
      "Gradient for decoder.decoder.3.bias: 9.054604982461356e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0005627276841551065\n",
      "Gradient for decoder.decoder.4.bias: 0.0006813277141191065\n",
      "Gradient for decoder.decoder.6.weight: 0.0008819965296424925\n",
      "Gradient for decoder.decoder.6.bias: 5.455858990899287e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.005373528692871332\n",
      "Gradient for encoder.encoder.0.bias: 8.175926949349765e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.0005415678024291992\n",
      "Gradient for encoder.encoder.1.bias: 0.0006073708645999432\n",
      "Gradient for encoder.encoder.3.weight: 0.012017983011901379\n",
      "Gradient for encoder.encoder.3.bias: 1.103739946661797e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.003307158825919032\n",
      "Gradient for encoder.encoder.4.bias: 0.0024609509855508804\n",
      "Gradient for encoder.mean.weight: 0.047247786074876785\n",
      "Gradient for encoder.mean.bias: 0.0020539367105811834\n",
      "Gradient for encoder.log_var.weight: 0.027126885950565338\n",
      "Gradient for encoder.log_var.bias: 0.0013780070003122091\n",
      "Gradient for decoder.decoder.0.weight: 0.013112408109009266\n",
      "Gradient for decoder.decoder.0.bias: 1.1201609778632715e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0006032799719832838\n",
      "Gradient for decoder.decoder.1.bias: 0.0005200713058002293\n",
      "Gradient for decoder.decoder.3.weight: 0.011785712093114853\n",
      "Gradient for decoder.decoder.3.bias: 8.892004493832317e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.000439563300460577\n",
      "Gradient for decoder.decoder.4.bias: 0.0004104292602278292\n",
      "Gradient for decoder.decoder.6.weight: 0.0009061351884156466\n",
      "Gradient for decoder.decoder.6.bias: 4.7995923523558304e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.008398136124014854\n",
      "Gradient for encoder.encoder.0.bias: 1.4479807977640924e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0005222645122557878\n",
      "Gradient for encoder.encoder.1.bias: 0.000471313891466707\n",
      "Gradient for encoder.encoder.3.weight: 0.011056281626224518\n",
      "Gradient for encoder.encoder.3.bias: 1.1131027349842171e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0028187460266053677\n",
      "Gradient for encoder.encoder.4.bias: 0.0022684005089104176\n",
      "Gradient for encoder.mean.weight: 0.03842230513691902\n",
      "Gradient for encoder.mean.bias: 0.0017374923918396235\n",
      "Gradient for encoder.log_var.weight: 0.024982647970318794\n",
      "Gradient for encoder.log_var.bias: 0.0011824300745502114\n",
      "Gradient for decoder.decoder.0.weight: 0.009857801720499992\n",
      "Gradient for decoder.decoder.0.bias: 9.104122317138419e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.00047731271479278803\n",
      "Gradient for decoder.decoder.1.bias: 0.00041300797602161765\n",
      "Gradient for decoder.decoder.3.weight: 0.009060881100594997\n",
      "Gradient for decoder.decoder.3.bias: 7.9199098668159e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00038229351048357785\n",
      "Gradient for decoder.decoder.4.bias: 0.00041278923163190484\n",
      "Gradient for decoder.decoder.6.weight: 0.0008306085364893079\n",
      "Gradient for decoder.decoder.6.bias: 4.1623206925578415e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.006081379950046539\n",
      "Gradient for encoder.encoder.0.bias: 8.842372146988797e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.00039319845382124186\n",
      "Gradient for encoder.encoder.1.bias: 0.00032079487573355436\n",
      "Gradient for encoder.encoder.3.weight: 0.008323920890688896\n",
      "Gradient for encoder.encoder.3.bias: 9.049566651597729e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.00225735898129642\n",
      "Gradient for encoder.encoder.4.bias: 0.0018106495263054967\n",
      "Gradient for encoder.mean.weight: 0.03015221655368805\n",
      "Gradient for encoder.mean.bias: 0.0013677850365638733\n",
      "Gradient for encoder.log_var.weight: 0.02035769633948803\n",
      "Gradient for encoder.log_var.bias: 0.0010336794657632709\n",
      "Gradient for decoder.decoder.0.weight: 0.010510507971048355\n",
      "Gradient for decoder.decoder.0.bias: 9.473545559135488e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005095272790640593\n",
      "Gradient for decoder.decoder.1.bias: 0.00046565302181988955\n",
      "Gradient for decoder.decoder.3.weight: 0.009822528809309006\n",
      "Gradient for decoder.decoder.3.bias: 8.38640823452863e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00037428701762109995\n",
      "Gradient for decoder.decoder.4.bias: 0.0003687053394969553\n",
      "Gradient for decoder.decoder.6.weight: 0.0008656049612909555\n",
      "Gradient for decoder.decoder.6.bias: 4.46563572040759e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.006296089850366116\n",
      "Gradient for encoder.encoder.0.bias: 8.52850168958641e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.00037314227665774524\n",
      "Gradient for encoder.encoder.1.bias: 0.00029384749359451234\n",
      "Gradient for encoder.encoder.3.weight: 0.008248603902757168\n",
      "Gradient for encoder.encoder.3.bias: 1.0105154907291691e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0022607529535889626\n",
      "Gradient for encoder.encoder.4.bias: 0.0018835067749023438\n",
      "Gradient for encoder.mean.weight: 0.030950825661420822\n",
      "Gradient for encoder.mean.bias: 0.0014385177055373788\n",
      "Gradient for encoder.log_var.weight: 0.019381524994969368\n",
      "Gradient for encoder.log_var.bias: 0.0009818190010264516\n",
      "Gradient for decoder.decoder.0.weight: 0.011538001708686352\n",
      "Gradient for decoder.decoder.0.bias: 1.0359484797772822e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0005491739721037447\n",
      "Gradient for decoder.decoder.1.bias: 0.0004911186988465488\n",
      "Gradient for decoder.decoder.3.weight: 0.011072634719312191\n",
      "Gradient for decoder.decoder.3.bias: 9.669010730961602e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00045335901086218655\n",
      "Gradient for decoder.decoder.4.bias: 0.0004269109631422907\n",
      "Gradient for decoder.decoder.6.weight: 0.000904619344510138\n",
      "Gradient for decoder.decoder.6.bias: 3.9904480217956007e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.007618471048772335\n",
      "Gradient for encoder.encoder.0.bias: 9.210991344654751e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.0004948816495016217\n",
      "Gradient for encoder.encoder.1.bias: 0.0004269181517884135\n",
      "Gradient for encoder.encoder.3.weight: 0.01120482012629509\n",
      "Gradient for encoder.encoder.3.bias: 1.1703003843788196e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.002843738067895174\n",
      "Gradient for encoder.encoder.4.bias: 0.0021505437325686216\n",
      "Gradient for encoder.mean.weight: 0.038179315626621246\n",
      "Gradient for encoder.mean.bias: 0.001737037906423211\n",
      "Gradient for encoder.log_var.weight: 0.021783839911222458\n",
      "Gradient for encoder.log_var.bias: 0.0010492195142433047\n",
      "Gradient for decoder.decoder.0.weight: 0.011859935708343983\n",
      "Gradient for decoder.decoder.0.bias: 1.0106024350697851e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0006030587246641517\n",
      "Gradient for decoder.decoder.1.bias: 0.0004990527522750199\n",
      "Gradient for decoder.decoder.3.weight: 0.011122986674308777\n",
      "Gradient for decoder.decoder.3.bias: 1.0238421221941962e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0006305970600806177\n",
      "Gradient for decoder.decoder.4.bias: 0.000696041970513761\n",
      "Gradient for decoder.decoder.6.weight: 0.0011113069485872984\n",
      "Gradient for decoder.decoder.6.bias: 8.369291754206643e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.00568955484777689\n",
      "Gradient for encoder.encoder.0.bias: 9.146760605871496e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.00044052230077795684\n",
      "Gradient for encoder.encoder.1.bias: 0.0003356478700879961\n",
      "Gradient for encoder.encoder.3.weight: 0.009799322113394737\n",
      "Gradient for encoder.encoder.3.bias: 1.1651808684565168e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0027428078465163708\n",
      "Gradient for encoder.encoder.4.bias: 0.002372503513470292\n",
      "Gradient for encoder.mean.weight: 0.037592317909002304\n",
      "Gradient for encoder.mean.bias: 0.0018096109852194786\n",
      "Gradient for encoder.log_var.weight: 0.02232392132282257\n",
      "Gradient for encoder.log_var.bias: 0.0011631157249212265\n",
      "Gradient for decoder.decoder.0.weight: 0.010426170192658901\n",
      "Gradient for decoder.decoder.0.bias: 9.851113674796963e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005111366626806557\n",
      "Gradient for decoder.decoder.1.bias: 0.00040617401828058064\n",
      "Gradient for decoder.decoder.3.weight: 0.009807531721889973\n",
      "Gradient for decoder.decoder.3.bias: 8.866035683396944e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00035376130836084485\n",
      "Gradient for decoder.decoder.4.bias: 0.00031316516106016934\n",
      "Gradient for decoder.decoder.6.weight: 0.0008403335814364254\n",
      "Gradient for decoder.decoder.6.bias: 4.8343896196456626e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.006310802418738604\n",
      "Gradient for encoder.encoder.0.bias: 8.7064539605608e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.00043755280785262585\n",
      "Gradient for encoder.encoder.1.bias: 0.00042753544403240085\n",
      "Gradient for encoder.encoder.3.weight: 0.009482084773480892\n",
      "Gradient for encoder.encoder.3.bias: 1.0249049525734577e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.003003670135512948\n",
      "Gradient for encoder.encoder.4.bias: 0.0022932831197977066\n",
      "Gradient for encoder.mean.weight: 0.04123063385486603\n",
      "Gradient for encoder.mean.bias: 0.001695528393611312\n",
      "Gradient for encoder.log_var.weight: 0.024967780336737633\n",
      "Gradient for encoder.log_var.bias: 0.0011211499804630876\n",
      "Gradient for decoder.decoder.0.weight: 0.011776323430240154\n",
      "Gradient for decoder.decoder.0.bias: 9.840868397947844e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0006109662353992462\n",
      "Gradient for decoder.decoder.1.bias: 0.0004997241776436567\n",
      "Gradient for decoder.decoder.3.weight: 0.011526679620146751\n",
      "Gradient for decoder.decoder.3.bias: 9.217016039286818e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0005108595942147076\n",
      "Gradient for decoder.decoder.4.bias: 0.0004796585126314312\n",
      "Gradient for decoder.decoder.6.weight: 0.0008941819542087615\n",
      "Gradient for decoder.decoder.6.bias: 3.880175790982321e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.007601853925734758\n",
      "Gradient for encoder.encoder.0.bias: 1.256927374682082e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.00048720691120252013\n",
      "Gradient for encoder.encoder.1.bias: 0.00047093394096009433\n",
      "Gradient for encoder.encoder.3.weight: 0.010658874176442623\n",
      "Gradient for encoder.encoder.3.bias: 1.0204431050153673e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.002384623745456338\n",
      "Gradient for encoder.encoder.4.bias: 0.002254277700558305\n",
      "Gradient for encoder.mean.weight: 0.034114040434360504\n",
      "Gradient for encoder.mean.bias: 0.0017385708633810282\n",
      "Gradient for encoder.log_var.weight: 0.018726348876953125\n",
      "Gradient for encoder.log_var.bias: 0.0010261471616104245\n",
      "Gradient for decoder.decoder.0.weight: 0.010446137748658657\n",
      "Gradient for decoder.decoder.0.bias: 8.674836543542952e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005059503600932658\n",
      "Gradient for decoder.decoder.1.bias: 0.00045034359209239483\n",
      "Gradient for decoder.decoder.3.weight: 0.009923524223268032\n",
      "Gradient for decoder.decoder.3.bias: 7.362636195162864e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0003934618434868753\n",
      "Gradient for decoder.decoder.4.bias: 0.00038881596992723644\n",
      "Gradient for decoder.decoder.6.weight: 0.0008616094128228724\n",
      "Gradient for decoder.decoder.6.bias: 4.586247086990625e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training VAE Epoch:  33%|███▎      | 26/79 [00:00<00:00, 59.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient for encoder.encoder.0.weight: 0.00684031005948782\n",
      "Gradient for encoder.encoder.0.bias: 9.418012376916085e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.000528631207998842\n",
      "Gradient for encoder.encoder.1.bias: 0.00042710386333055794\n",
      "Gradient for encoder.encoder.3.weight: 0.011303327977657318\n",
      "Gradient for encoder.encoder.3.bias: 1.0411970591261976e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0023470844607800245\n",
      "Gradient for encoder.encoder.4.bias: 0.0024279183708131313\n",
      "Gradient for encoder.mean.weight: 0.032272227108478546\n",
      "Gradient for encoder.mean.bias: 0.0019402307225391269\n",
      "Gradient for encoder.log_var.weight: 0.01934603787958622\n",
      "Gradient for encoder.log_var.bias: 0.001159571809694171\n",
      "Gradient for decoder.decoder.0.weight: 0.010090602561831474\n",
      "Gradient for decoder.decoder.0.bias: 8.86155177015624e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.00047647449537180364\n",
      "Gradient for decoder.decoder.1.bias: 0.0004040538624394685\n",
      "Gradient for decoder.decoder.3.weight: 0.009160878136754036\n",
      "Gradient for decoder.decoder.3.bias: 7.616534486443172e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0003859531716443598\n",
      "Gradient for decoder.decoder.4.bias: 0.0003554087015800178\n",
      "Gradient for decoder.decoder.6.weight: 0.0008498236420564353\n",
      "Gradient for decoder.decoder.6.bias: 3.7625803088303655e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.004642930347472429\n",
      "Gradient for encoder.encoder.0.bias: 6.9764333199273665e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.0004887799150310457\n",
      "Gradient for encoder.encoder.1.bias: 0.0005737511091865599\n",
      "Gradient for encoder.encoder.3.weight: 0.010286588221788406\n",
      "Gradient for encoder.encoder.3.bias: 1.0202291789163098e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0029249684885144234\n",
      "Gradient for encoder.encoder.4.bias: 0.0023988813627511263\n",
      "Gradient for encoder.mean.weight: 0.042798105627298355\n",
      "Gradient for encoder.mean.bias: 0.002038247650489211\n",
      "Gradient for encoder.log_var.weight: 0.023736638948321342\n",
      "Gradient for encoder.log_var.bias: 0.0013421822804957628\n",
      "Gradient for decoder.decoder.0.weight: 0.011946710757911205\n",
      "Gradient for decoder.decoder.0.bias: 1.0191116700530856e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0006004704628139734\n",
      "Gradient for decoder.decoder.1.bias: 0.000507181859575212\n",
      "Gradient for decoder.decoder.3.weight: 0.011086051352322102\n",
      "Gradient for decoder.decoder.3.bias: 8.841401222259293e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00042160804150626063\n",
      "Gradient for decoder.decoder.4.bias: 0.00035018689231947064\n",
      "Gradient for decoder.decoder.6.weight: 0.0008879246306605637\n",
      "Gradient for decoder.decoder.6.bias: 4.966275446349755e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.0060203499160707\n",
      "Gradient for encoder.encoder.0.bias: 8.293860390140573e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.0003962491755373776\n",
      "Gradient for encoder.encoder.1.bias: 0.00030230937409214675\n",
      "Gradient for encoder.encoder.3.weight: 0.008539307862520218\n",
      "Gradient for encoder.encoder.3.bias: 9.941158313209186e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.0022460368927568197\n",
      "Gradient for encoder.encoder.4.bias: 0.0021178945899009705\n",
      "Gradient for encoder.mean.weight: 0.03279956057667732\n",
      "Gradient for encoder.mean.bias: 0.0017212587408721447\n",
      "Gradient for encoder.log_var.weight: 0.020070239901542664\n",
      "Gradient for encoder.log_var.bias: 0.0011167083866894245\n",
      "Gradient for decoder.decoder.0.weight: 0.011985761113464832\n",
      "Gradient for decoder.decoder.0.bias: 9.87229464843864e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005652101244777441\n",
      "Gradient for decoder.decoder.1.bias: 0.0004925047396682203\n",
      "Gradient for decoder.decoder.3.weight: 0.011119004338979721\n",
      "Gradient for decoder.decoder.3.bias: 1.0520634363686554e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0006026871269568801\n",
      "Gradient for decoder.decoder.4.bias: 0.0006756075308658183\n",
      "Gradient for decoder.decoder.6.weight: 0.0009550764225423336\n",
      "Gradient for decoder.decoder.6.bias: 5.9320140280760825e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.0049711489118635654\n",
      "Gradient for encoder.encoder.0.bias: 7.595529240289611e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.00050165451830253\n",
      "Gradient for encoder.encoder.1.bias: 0.0003545145445968956\n",
      "Gradient for encoder.encoder.3.weight: 0.011099927127361298\n",
      "Gradient for encoder.encoder.3.bias: 1.0742872563751504e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.002646025037392974\n",
      "Gradient for encoder.encoder.4.bias: 0.0025236106012016535\n",
      "Gradient for encoder.mean.weight: 0.03717666119337082\n",
      "Gradient for encoder.mean.bias: 0.0020370474085211754\n",
      "Gradient for encoder.log_var.weight: 0.02204812318086624\n",
      "Gradient for encoder.log_var.bias: 0.0013695009984076023\n",
      "Gradient for decoder.decoder.0.weight: 0.013670272193849087\n",
      "Gradient for decoder.decoder.0.bias: 1.0753344742431281e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0006796582019887865\n",
      "Gradient for decoder.decoder.1.bias: 0.0005813331808894873\n",
      "Gradient for decoder.decoder.3.weight: 0.01273752935230732\n",
      "Gradient for decoder.decoder.3.bias: 1.144415465170745e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0005759618943557143\n",
      "Gradient for decoder.decoder.4.bias: 0.0006385775050148368\n",
      "Gradient for decoder.decoder.6.weight: 0.0009873906383290887\n",
      "Gradient for decoder.decoder.6.bias: 6.68673383188434e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.006567004602402449\n",
      "Gradient for encoder.encoder.0.bias: 9.917639626211283e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.0005143239977769554\n",
      "Gradient for encoder.encoder.1.bias: 0.0004285692411940545\n",
      "Gradient for encoder.encoder.3.weight: 0.011520300060510635\n",
      "Gradient for encoder.encoder.3.bias: 1.0220004009742212e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.002731911139562726\n",
      "Gradient for encoder.encoder.4.bias: 0.0019139805808663368\n",
      "Gradient for encoder.mean.weight: 0.037227947264909744\n",
      "Gradient for encoder.mean.bias: 0.0013672735076397657\n",
      "Gradient for encoder.log_var.weight: 0.02416660077869892\n",
      "Gradient for encoder.log_var.bias: 0.0010112239979207516\n",
      "Gradient for decoder.decoder.0.weight: 0.01122883427888155\n",
      "Gradient for decoder.decoder.0.bias: 1.0237125730450103e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0005564609309658408\n",
      "Gradient for decoder.decoder.1.bias: 0.0004484832170419395\n",
      "Gradient for decoder.decoder.3.weight: 0.010452824644744396\n",
      "Gradient for decoder.decoder.3.bias: 1.0179609238880616e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0004853501741308719\n",
      "Gradient for decoder.decoder.4.bias: 0.0005018661031499505\n",
      "Gradient for decoder.decoder.6.weight: 0.0010172899346798658\n",
      "Gradient for decoder.decoder.6.bias: 7.313593232538551e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.0061548687517642975\n",
      "Gradient for encoder.encoder.0.bias: 1.0151954797643636e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.00041239449637942016\n",
      "Gradient for encoder.encoder.1.bias: 0.00045154482359066606\n",
      "Gradient for encoder.encoder.3.weight: 0.009100004099309444\n",
      "Gradient for encoder.encoder.3.bias: 8.30123331185817e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.0019968440756201744\n",
      "Gradient for encoder.encoder.4.bias: 0.0015133470296859741\n",
      "Gradient for encoder.mean.weight: 0.030731938779354095\n",
      "Gradient for encoder.mean.bias: 0.0011855760822072625\n",
      "Gradient for encoder.log_var.weight: 0.021396998316049576\n",
      "Gradient for encoder.log_var.bias: 0.0009940944146364927\n",
      "Gradient for decoder.decoder.0.weight: 0.010859874077141285\n",
      "Gradient for decoder.decoder.0.bias: 9.265511968781226e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005186083144508302\n",
      "Gradient for decoder.decoder.1.bias: 0.00041903252713382244\n",
      "Gradient for decoder.decoder.3.weight: 0.009810165502130985\n",
      "Gradient for decoder.decoder.3.bias: 1.0442251924258628e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0004246167663950473\n",
      "Gradient for decoder.decoder.4.bias: 0.00045752740697935224\n",
      "Gradient for decoder.decoder.6.weight: 0.0009374736691825092\n",
      "Gradient for decoder.decoder.6.bias: 5.561780562857166e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.006909238174557686\n",
      "Gradient for encoder.encoder.0.bias: 1.0680485142133822e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.00041286859777756035\n",
      "Gradient for encoder.encoder.1.bias: 0.0003419061831664294\n",
      "Gradient for encoder.encoder.3.weight: 0.009193703532218933\n",
      "Gradient for encoder.encoder.3.bias: 1.0001677958060284e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0021776147186756134\n",
      "Gradient for encoder.encoder.4.bias: 0.0018940666923299432\n",
      "Gradient for encoder.mean.weight: 0.03062482550740242\n",
      "Gradient for encoder.mean.bias: 0.0014491172041743994\n",
      "Gradient for encoder.log_var.weight: 0.018053993582725525\n",
      "Gradient for encoder.log_var.bias: 0.0009991498664021492\n",
      "Gradient for decoder.decoder.0.weight: 0.010799526236951351\n",
      "Gradient for decoder.decoder.0.bias: 9.497104491718034e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005275696166791022\n",
      "Gradient for decoder.decoder.1.bias: 0.00045903693535365164\n",
      "Gradient for decoder.decoder.3.weight: 0.00976701732724905\n",
      "Gradient for decoder.decoder.3.bias: 9.312055293531074e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00038031715666875243\n",
      "Gradient for decoder.decoder.4.bias: 0.00031165251857601106\n",
      "Gradient for decoder.decoder.6.weight: 0.0008685272769071162\n",
      "Gradient for decoder.decoder.6.bias: 4.379405436338857e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.005689788144081831\n",
      "Gradient for encoder.encoder.0.bias: 8.417913067992888e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.0004318439750932157\n",
      "Gradient for encoder.encoder.1.bias: 0.0004000627959612757\n",
      "Gradient for encoder.encoder.3.weight: 0.009405204094946384\n",
      "Gradient for encoder.encoder.3.bias: 1.0597547839275023e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0021034867968410254\n",
      "Gradient for encoder.encoder.4.bias: 0.0018500175792723894\n",
      "Gradient for encoder.mean.weight: 0.030168265104293823\n",
      "Gradient for encoder.mean.bias: 0.001480807550251484\n",
      "Gradient for encoder.log_var.weight: 0.019356513395905495\n",
      "Gradient for encoder.log_var.bias: 0.000894723052624613\n",
      "Gradient for decoder.decoder.0.weight: 0.012627138756215572\n",
      "Gradient for decoder.decoder.0.bias: 1.0327953076094687e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0005725430673919618\n",
      "Gradient for decoder.decoder.1.bias: 0.00049646629486233\n",
      "Gradient for decoder.decoder.3.weight: 0.011343071237206459\n",
      "Gradient for decoder.decoder.3.bias: 9.806028211656326e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0004947705892845988\n",
      "Gradient for decoder.decoder.4.bias: 0.0004788086807820946\n",
      "Gradient for decoder.decoder.6.weight: 0.0008868136210367084\n",
      "Gradient for decoder.decoder.6.bias: 4.500308205024339e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.005791675765067339\n",
      "Gradient for encoder.encoder.0.bias: 8.795382824833275e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.00040506458026356995\n",
      "Gradient for encoder.encoder.1.bias: 0.00039532003575004637\n",
      "Gradient for encoder.encoder.3.weight: 0.008728660643100739\n",
      "Gradient for encoder.encoder.3.bias: 9.592723837492656e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.002272337907925248\n",
      "Gradient for encoder.encoder.4.bias: 0.0017491258913651109\n",
      "Gradient for encoder.mean.weight: 0.03145017847418785\n",
      "Gradient for encoder.mean.bias: 0.001413915422745049\n",
      "Gradient for encoder.log_var.weight: 0.01958344131708145\n",
      "Gradient for encoder.log_var.bias: 0.0010082190856337547\n",
      "Gradient for decoder.decoder.0.weight: 0.01196893211454153\n",
      "Gradient for decoder.decoder.0.bias: 1.0997607685636623e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0005546536995097995\n",
      "Gradient for decoder.decoder.1.bias: 0.00047236369573511183\n",
      "Gradient for decoder.decoder.3.weight: 0.010881802998483181\n",
      "Gradient for decoder.decoder.3.bias: 9.42032493678191e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0004311705124564469\n",
      "Gradient for decoder.decoder.4.bias: 0.00039876578375697136\n",
      "Gradient for decoder.decoder.6.weight: 0.0010197000810876489\n",
      "Gradient for decoder.decoder.6.bias: 6.670979200862348e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.005137977655977011\n",
      "Gradient for encoder.encoder.0.bias: 6.797770246008694e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.0004520345537457615\n",
      "Gradient for encoder.encoder.1.bias: 0.0003876160772051662\n",
      "Gradient for encoder.encoder.3.weight: 0.00997175183147192\n",
      "Gradient for encoder.encoder.3.bias: 9.058225003411025e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.0022315471433103085\n",
      "Gradient for encoder.encoder.4.bias: 0.0016857056180015206\n",
      "Gradient for encoder.mean.weight: 0.03186895698308945\n",
      "Gradient for encoder.mean.bias: 0.001286471146158874\n",
      "Gradient for encoder.log_var.weight: 0.020809713751077652\n",
      "Gradient for encoder.log_var.bias: 0.000983140547759831\n",
      "Gradient for decoder.decoder.0.weight: 0.011748909950256348\n",
      "Gradient for decoder.decoder.0.bias: 1.0649835874287916e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0005995495594106615\n",
      "Gradient for decoder.decoder.1.bias: 0.0004970824811607599\n",
      "Gradient for decoder.decoder.3.weight: 0.011241349391639233\n",
      "Gradient for decoder.decoder.3.bias: 8.701336873251364e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0004777784051839262\n",
      "Gradient for decoder.decoder.4.bias: 0.00047462282236665487\n",
      "Gradient for decoder.decoder.6.weight: 0.0008303245413117111\n",
      "Gradient for decoder.decoder.6.bias: 3.698806540342048e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.005769990850239992\n",
      "Gradient for encoder.encoder.0.bias: 6.9464338794955616e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.0004804298805538565\n",
      "Gradient for encoder.encoder.1.bias: 0.0004925475222989917\n",
      "Gradient for encoder.encoder.3.weight: 0.010703387670218945\n",
      "Gradient for encoder.encoder.3.bias: 9.852602761428741e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.0028194233309477568\n",
      "Gradient for encoder.encoder.4.bias: 0.002227082382887602\n",
      "Gradient for encoder.mean.weight: 0.040700290352106094\n",
      "Gradient for encoder.mean.bias: 0.0017574378289282322\n",
      "Gradient for encoder.log_var.weight: 0.02552642486989498\n",
      "Gradient for encoder.log_var.bias: 0.0013391264947131276\n",
      "Gradient for decoder.decoder.0.weight: 0.013291158713400364\n",
      "Gradient for decoder.decoder.0.bias: 1.1613549011357804e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0006514303968288004\n",
      "Gradient for decoder.decoder.1.bias: 0.0005427889409475029\n",
      "Gradient for decoder.decoder.3.weight: 0.011954322457313538\n",
      "Gradient for decoder.decoder.3.bias: 1.2364367862893744e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0008056749938987195\n",
      "Gradient for decoder.decoder.4.bias: 0.0009285002597607672\n",
      "Gradient for decoder.decoder.6.weight: 0.0012158039025962353\n",
      "Gradient for decoder.decoder.6.bias: 9.938045695889741e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.005293968599289656\n",
      "Gradient for encoder.encoder.0.bias: 8.324532035919319e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.00045854304335080087\n",
      "Gradient for encoder.encoder.1.bias: 0.0003687396820168942\n",
      "Gradient for encoder.encoder.3.weight: 0.01023031584918499\n",
      "Gradient for encoder.encoder.3.bias: 9.554727842253641e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.002452399581670761\n",
      "Gradient for encoder.encoder.4.bias: 0.0017273245612159371\n",
      "Gradient for encoder.mean.weight: 0.03328545019030571\n",
      "Gradient for encoder.mean.bias: 0.0011740151094272733\n",
      "Gradient for encoder.log_var.weight: 0.01996500790119171\n",
      "Gradient for encoder.log_var.bias: 0.0009938022121787071\n",
      "Gradient for decoder.decoder.0.weight: 0.010922976769506931\n",
      "Gradient for decoder.decoder.0.bias: 9.754337615408559e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005554466042667627\n",
      "Gradient for decoder.decoder.1.bias: 0.00048016125219874084\n",
      "Gradient for decoder.decoder.3.weight: 0.010307343676686287\n",
      "Gradient for decoder.decoder.3.bias: 9.27430979236199e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0004447148821782321\n",
      "Gradient for decoder.decoder.4.bias: 0.0004391189431771636\n",
      "Gradient for decoder.decoder.6.weight: 0.0008647785289213061\n",
      "Gradient for decoder.decoder.6.bias: 4.268174961907789e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.005510361865162849\n",
      "Gradient for encoder.encoder.0.bias: 7.872072785297668e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.00040076306322589517\n",
      "Gradient for encoder.encoder.1.bias: 0.0003496272547636181\n",
      "Gradient for encoder.encoder.3.weight: 0.00848796870559454\n",
      "Gradient for encoder.encoder.3.bias: 1.0110667164608955e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.002199913840740919\n",
      "Gradient for encoder.encoder.4.bias: 0.0019620503298938274\n",
      "Gradient for encoder.mean.weight: 0.03142763674259186\n",
      "Gradient for encoder.mean.bias: 0.001481938292272389\n",
      "Gradient for encoder.log_var.weight: 0.01795998029410839\n",
      "Gradient for encoder.log_var.bias: 0.000978030264377594\n",
      "Gradient for decoder.decoder.0.weight: 0.011358290910720825\n",
      "Gradient for decoder.decoder.0.bias: 9.424577090966224e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005346485413610935\n",
      "Gradient for decoder.decoder.1.bias: 0.00048463899292983115\n",
      "Gradient for decoder.decoder.3.weight: 0.010552163235843182\n",
      "Gradient for decoder.decoder.3.bias: 1.0099794611750923e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0004224973381496966\n",
      "Gradient for decoder.decoder.4.bias: 0.00045389667502604425\n",
      "Gradient for decoder.decoder.6.weight: 0.0008925371221266687\n",
      "Gradient for decoder.decoder.6.bias: 5.17847656738013e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.005159660708159208\n",
      "Gradient for encoder.encoder.0.bias: 7.964477168054263e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.00041678317938931286\n",
      "Gradient for encoder.encoder.1.bias: 0.0003139684267807752\n",
      "Gradient for encoder.encoder.3.weight: 0.009369591251015663\n",
      "Gradient for encoder.encoder.3.bias: 9.525132071974696e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.0021818012464791536\n",
      "Gradient for encoder.encoder.4.bias: 0.001663164235651493\n",
      "Gradient for encoder.mean.weight: 0.031586892902851105\n",
      "Gradient for encoder.mean.bias: 0.001333823543973267\n",
      "Gradient for encoder.log_var.weight: 0.019367830827832222\n",
      "Gradient for encoder.log_var.bias: 0.0009452392696402967\n",
      "Gradient for decoder.decoder.0.weight: 0.012136002071201801\n",
      "Gradient for decoder.decoder.0.bias: 1.0214830370447459e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0005964215379208326\n",
      "Gradient for decoder.decoder.1.bias: 0.0005145941977389157\n",
      "Gradient for decoder.decoder.3.weight: 0.011430159211158752\n",
      "Gradient for decoder.decoder.3.bias: 9.94017021471727e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00042993552051484585\n",
      "Gradient for decoder.decoder.4.bias: 0.0003843638114631176\n",
      "Gradient for decoder.decoder.6.weight: 0.0008653177646920085\n",
      "Gradient for decoder.decoder.6.bias: 4.041106149088591e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.004309613723307848\n",
      "Gradient for encoder.encoder.0.bias: 7.477981775472209e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.0004262812144588679\n",
      "Gradient for encoder.encoder.1.bias: 0.00047369618550874293\n",
      "Gradient for encoder.encoder.3.weight: 0.00939331017434597\n",
      "Gradient for encoder.encoder.3.bias: 7.967527332342073e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.0026637567207217216\n",
      "Gradient for encoder.encoder.4.bias: 0.0016275427769869566\n",
      "Gradient for encoder.mean.weight: 0.0382293239235878\n",
      "Gradient for encoder.mean.bias: 0.001182248000986874\n",
      "Gradient for encoder.log_var.weight: 0.023184241726994514\n",
      "Gradient for encoder.log_var.bias: 0.0009438159177079797\n",
      "Gradient for decoder.decoder.0.weight: 0.012286478653550148\n",
      "Gradient for decoder.decoder.0.bias: 9.912273085666001e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0006093776901252568\n",
      "Gradient for decoder.decoder.1.bias: 0.0005401482339948416\n",
      "Gradient for decoder.decoder.3.weight: 0.01131733600050211\n",
      "Gradient for decoder.decoder.3.bias: 7.876332225320581e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0003892896347679198\n",
      "Gradient for decoder.decoder.4.bias: 0.00035440680221654475\n",
      "Gradient for decoder.decoder.6.weight: 0.0007973815081641078\n",
      "Gradient for decoder.decoder.6.bias: 4.1789826354943216e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.004683115519583225\n",
      "Gradient for encoder.encoder.0.bias: 7.003846721337359e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.0004433603317011148\n",
      "Gradient for encoder.encoder.1.bias: 0.0003948018711525947\n",
      "Gradient for encoder.encoder.3.weight: 0.009464665316045284\n",
      "Gradient for encoder.encoder.3.bias: 8.560611247654393e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.0022302118595689535\n",
      "Gradient for encoder.encoder.4.bias: 0.001636115601286292\n",
      "Gradient for encoder.mean.weight: 0.033871542662382126\n",
      "Gradient for encoder.mean.bias: 0.001298142015002668\n",
      "Gradient for encoder.log_var.weight: 0.01837090030312538\n",
      "Gradient for encoder.log_var.bias: 0.0009110060054808855\n",
      "Gradient for decoder.decoder.0.weight: 0.012523936107754707\n",
      "Gradient for decoder.decoder.0.bias: 1.0332582706107374e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0006201541400514543\n",
      "Gradient for decoder.decoder.1.bias: 0.0005348940612748265\n",
      "Gradient for decoder.decoder.3.weight: 0.011813686229288578\n",
      "Gradient for decoder.decoder.3.bias: 9.547301837997679e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.000629560905508697\n",
      "Gradient for decoder.decoder.4.bias: 0.0006429869099520147\n",
      "Gradient for decoder.decoder.6.weight: 0.001185569679364562\n",
      "Gradient for decoder.decoder.6.bias: 9.137230517808348e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training VAE Epoch:  53%|█████▎    | 42/79 [00:00<00:00, 67.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient for encoder.encoder.0.weight: 0.006318925879895687\n",
      "Gradient for encoder.encoder.0.bias: 1.1779223429986274e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.00052386469906196\n",
      "Gradient for encoder.encoder.1.bias: 0.0005334728630259633\n",
      "Gradient for encoder.encoder.3.weight: 0.01139869075268507\n",
      "Gradient for encoder.encoder.3.bias: 9.897482139420433e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.002511441009119153\n",
      "Gradient for encoder.encoder.4.bias: 0.002003558212891221\n",
      "Gradient for encoder.mean.weight: 0.03707948699593544\n",
      "Gradient for encoder.mean.bias: 0.0017314661527052522\n",
      "Gradient for encoder.log_var.weight: 0.01939690299332142\n",
      "Gradient for encoder.log_var.bias: 0.0010288461344316602\n",
      "Gradient for decoder.decoder.0.weight: 0.009706820361316204\n",
      "Gradient for decoder.decoder.0.bias: 7.732752632660933e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0004740648146253079\n",
      "Gradient for decoder.decoder.1.bias: 0.0004232982755638659\n",
      "Gradient for decoder.decoder.3.weight: 0.009083159267902374\n",
      "Gradient for decoder.decoder.3.bias: 9.601834605188486e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0006276827771216631\n",
      "Gradient for decoder.decoder.4.bias: 0.0007511867443099618\n",
      "Gradient for decoder.decoder.6.weight: 0.000914880889467895\n",
      "Gradient for decoder.decoder.6.bias: 6.358887912938371e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.004312403034418821\n",
      "Gradient for encoder.encoder.0.bias: 7.0604962848497266e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.00038443467929027975\n",
      "Gradient for encoder.encoder.1.bias: 0.00036089535569772124\n",
      "Gradient for encoder.encoder.3.weight: 0.008749079890549183\n",
      "Gradient for encoder.encoder.3.bias: 8.165083886790825e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.0021327065769582987\n",
      "Gradient for encoder.encoder.4.bias: 0.0015894118696451187\n",
      "Gradient for encoder.mean.weight: 0.03341619297862053\n",
      "Gradient for encoder.mean.bias: 0.001227480941452086\n",
      "Gradient for encoder.log_var.weight: 0.0180122721940279\n",
      "Gradient for encoder.log_var.bias: 0.0009330047760158777\n",
      "Gradient for decoder.decoder.0.weight: 0.011976583860814571\n",
      "Gradient for decoder.decoder.0.bias: 9.474425410882503e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005862590041942894\n",
      "Gradient for decoder.decoder.1.bias: 0.0004873720754403621\n",
      "Gradient for decoder.decoder.3.weight: 0.011579218320548534\n",
      "Gradient for decoder.decoder.3.bias: 9.16597978073419e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0004727914638351649\n",
      "Gradient for decoder.decoder.4.bias: 0.0004507178673520684\n",
      "Gradient for decoder.decoder.6.weight: 0.0008886908181011677\n",
      "Gradient for decoder.decoder.6.bias: 4.2555377149255946e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.004944150801748037\n",
      "Gradient for encoder.encoder.0.bias: 7.867977103170887e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.0003308347659185529\n",
      "Gradient for encoder.encoder.1.bias: 0.00033970578806474805\n",
      "Gradient for encoder.encoder.3.weight: 0.007196646183729172\n",
      "Gradient for encoder.encoder.3.bias: 8.80200634600925e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.002545030554756522\n",
      "Gradient for encoder.encoder.4.bias: 0.001767339650541544\n",
      "Gradient for encoder.mean.weight: 0.03629198670387268\n",
      "Gradient for encoder.mean.bias: 0.001408963231369853\n",
      "Gradient for encoder.log_var.weight: 0.021278012543916702\n",
      "Gradient for encoder.log_var.bias: 0.0009644030942581594\n",
      "Gradient for decoder.decoder.0.weight: 0.01123532559722662\n",
      "Gradient for decoder.decoder.0.bias: 9.564766340064423e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005209498340263963\n",
      "Gradient for decoder.decoder.1.bias: 0.0005015747738070786\n",
      "Gradient for decoder.decoder.3.weight: 0.01066788099706173\n",
      "Gradient for decoder.decoder.3.bias: 9.736107753344214e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0005056716618128121\n",
      "Gradient for decoder.decoder.4.bias: 0.0005605923943221569\n",
      "Gradient for decoder.decoder.6.weight: 0.0009928104700520635\n",
      "Gradient for decoder.decoder.6.bias: 6.947216024855152e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.004686511587351561\n",
      "Gradient for encoder.encoder.0.bias: 7.316220546060848e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.0003989769029431045\n",
      "Gradient for encoder.encoder.1.bias: 0.0003559198521543294\n",
      "Gradient for encoder.encoder.3.weight: 0.00881282053887844\n",
      "Gradient for encoder.encoder.3.bias: 8.103942517045937e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.0022015043068677187\n",
      "Gradient for encoder.encoder.4.bias: 0.0014744590735062957\n",
      "Gradient for encoder.mean.weight: 0.0309805516153574\n",
      "Gradient for encoder.mean.bias: 0.0011446356074884534\n",
      "Gradient for encoder.log_var.weight: 0.019335560500621796\n",
      "Gradient for encoder.log_var.bias: 0.0008131235372275114\n",
      "Gradient for decoder.decoder.0.weight: 0.011785249225795269\n",
      "Gradient for decoder.decoder.0.bias: 1.0155798424449358e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0005598789430223405\n",
      "Gradient for decoder.decoder.1.bias: 0.00048404448898509145\n",
      "Gradient for decoder.decoder.3.weight: 0.011070538312196732\n",
      "Gradient for decoder.decoder.3.bias: 9.242615700566503e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.000457480811746791\n",
      "Gradient for decoder.decoder.4.bias: 0.0004230138147249818\n",
      "Gradient for decoder.decoder.6.weight: 0.0008953093201853335\n",
      "Gradient for decoder.decoder.6.bias: 4.4725627958541736e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.0045811510644853115\n",
      "Gradient for encoder.encoder.0.bias: 6.1987767349669376e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.0003262479149270803\n",
      "Gradient for encoder.encoder.1.bias: 0.00031591346487402916\n",
      "Gradient for encoder.encoder.3.weight: 0.007105608005076647\n",
      "Gradient for encoder.encoder.3.bias: 8.728898853727074e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.0022772152442485094\n",
      "Gradient for encoder.encoder.4.bias: 0.0020812710281461477\n",
      "Gradient for encoder.mean.weight: 0.03375675156712532\n",
      "Gradient for encoder.mean.bias: 0.0014314729487523437\n",
      "Gradient for encoder.log_var.weight: 0.020056959241628647\n",
      "Gradient for encoder.log_var.bias: 0.0010823352495208383\n",
      "Gradient for decoder.decoder.0.weight: 0.01364782266318798\n",
      "Gradient for decoder.decoder.0.bias: 1.1413054529230138e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0006462488672696054\n",
      "Gradient for decoder.decoder.1.bias: 0.0006170314736664295\n",
      "Gradient for decoder.decoder.3.weight: 0.012526338919997215\n",
      "Gradient for decoder.decoder.3.bias: 9.897926228630283e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0005399878136813641\n",
      "Gradient for decoder.decoder.4.bias: 0.0005180342122912407\n",
      "Gradient for decoder.decoder.6.weight: 0.0010254307417199016\n",
      "Gradient for decoder.decoder.6.bias: 6.306605064310133e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.004814361687749624\n",
      "Gradient for encoder.encoder.0.bias: 6.7700667120973446e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.00029239364084787667\n",
      "Gradient for encoder.encoder.1.bias: 0.00031655290513299406\n",
      "Gradient for encoder.encoder.3.weight: 0.006789172068238258\n",
      "Gradient for encoder.encoder.3.bias: 1.032009130930156e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0025800226721912622\n",
      "Gradient for encoder.encoder.4.bias: 0.0024475688114762306\n",
      "Gradient for encoder.mean.weight: 0.038001980632543564\n",
      "Gradient for encoder.mean.bias: 0.0020471937023103237\n",
      "Gradient for encoder.log_var.weight: 0.019783444702625275\n",
      "Gradient for encoder.log_var.bias: 0.0013306631008163095\n",
      "Gradient for decoder.decoder.0.weight: 0.011953816749155521\n",
      "Gradient for decoder.decoder.0.bias: 1.0773590353174711e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0005697969463653862\n",
      "Gradient for decoder.decoder.1.bias: 0.0005043307901360095\n",
      "Gradient for decoder.decoder.3.weight: 0.011198686435818672\n",
      "Gradient for decoder.decoder.3.bias: 1.0686689727590348e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0004040692001581192\n",
      "Gradient for decoder.decoder.4.bias: 0.00036035809898748994\n",
      "Gradient for decoder.decoder.6.weight: 0.0008690134854987264\n",
      "Gradient for decoder.decoder.6.bias: 4.326808266341686e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.006001126486808062\n",
      "Gradient for encoder.encoder.0.bias: 9.11969371547583e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.0003634209861047566\n",
      "Gradient for encoder.encoder.1.bias: 0.00034957772004418075\n",
      "Gradient for encoder.encoder.3.weight: 0.007991448976099491\n",
      "Gradient for encoder.encoder.3.bias: 8.590928662899344e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.0026285331696271896\n",
      "Gradient for encoder.encoder.4.bias: 0.0017883885884657502\n",
      "Gradient for encoder.mean.weight: 0.03904282674193382\n",
      "Gradient for encoder.mean.bias: 0.0013854086864739656\n",
      "Gradient for encoder.log_var.weight: 0.019368169829249382\n",
      "Gradient for encoder.log_var.bias: 0.0008395138429477811\n",
      "Gradient for decoder.decoder.0.weight: 0.011319340206682682\n",
      "Gradient for decoder.decoder.0.bias: 1.0398387706445078e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0005045859143137932\n",
      "Gradient for decoder.decoder.1.bias: 0.0004711466608569026\n",
      "Gradient for decoder.decoder.3.weight: 0.01024415623396635\n",
      "Gradient for decoder.decoder.3.bias: 1.0719101301015499e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0006161817582324147\n",
      "Gradient for decoder.decoder.4.bias: 0.000722436117939651\n",
      "Gradient for decoder.decoder.6.weight: 0.0010265693999826908\n",
      "Gradient for decoder.decoder.6.bias: 8.021185203688219e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.004727305378764868\n",
      "Gradient for encoder.encoder.0.bias: 7.1759889697098345e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.0003664850373752415\n",
      "Gradient for encoder.encoder.1.bias: 0.00034863478504121304\n",
      "Gradient for encoder.encoder.3.weight: 0.007984284311532974\n",
      "Gradient for encoder.encoder.3.bias: 8.806264051308688e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.002059508813545108\n",
      "Gradient for encoder.encoder.4.bias: 0.0017158763948827982\n",
      "Gradient for encoder.mean.weight: 0.029614504426717758\n",
      "Gradient for encoder.mean.bias: 0.0013294701930135489\n",
      "Gradient for encoder.log_var.weight: 0.01704183965921402\n",
      "Gradient for encoder.log_var.bias: 0.0009006835171021521\n",
      "Gradient for decoder.decoder.0.weight: 0.011689811013638973\n",
      "Gradient for decoder.decoder.0.bias: 9.81763351171061e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005362651427276433\n",
      "Gradient for decoder.decoder.1.bias: 0.0004640246625058353\n",
      "Gradient for decoder.decoder.3.weight: 0.010718944482505322\n",
      "Gradient for decoder.decoder.3.bias: 9.255151506293302e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0004038456827402115\n",
      "Gradient for decoder.decoder.4.bias: 0.0003386523458175361\n",
      "Gradient for decoder.decoder.6.weight: 0.0008538069087080657\n",
      "Gradient for decoder.decoder.6.bias: 3.906170604750514e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.0041337586008012295\n",
      "Gradient for encoder.encoder.0.bias: 6.0950498120826424e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.00042106970795430243\n",
      "Gradient for encoder.encoder.1.bias: 0.00038788688834756613\n",
      "Gradient for encoder.encoder.3.weight: 0.009116360917687416\n",
      "Gradient for encoder.encoder.3.bias: 8.361856346228436e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.0025743460282683372\n",
      "Gradient for encoder.encoder.4.bias: 0.001887859427370131\n",
      "Gradient for encoder.mean.weight: 0.038565054535865784\n",
      "Gradient for encoder.mean.bias: 0.001589325605891645\n",
      "Gradient for encoder.log_var.weight: 0.021678993478417397\n",
      "Gradient for encoder.log_var.bias: 0.0010008517419919372\n",
      "Gradient for decoder.decoder.0.weight: 0.012423783540725708\n",
      "Gradient for decoder.decoder.0.bias: 1.0832834629326271e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0005996221443638206\n",
      "Gradient for decoder.decoder.1.bias: 0.0005046621081419289\n",
      "Gradient for decoder.decoder.3.weight: 0.01158200018107891\n",
      "Gradient for decoder.decoder.3.bias: 1.0072365164148778e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.00047894439194351435\n",
      "Gradient for decoder.decoder.4.bias: 0.00043136198655702174\n",
      "Gradient for decoder.decoder.6.weight: 0.0008802061202004552\n",
      "Gradient for decoder.decoder.6.bias: 4.3932985136052594e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.005148211494088173\n",
      "Gradient for encoder.encoder.0.bias: 7.484251933476127e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.00039581715827807784\n",
      "Gradient for encoder.encoder.1.bias: 0.0003867645573336631\n",
      "Gradient for encoder.encoder.3.weight: 0.008218317292630672\n",
      "Gradient for encoder.encoder.3.bias: 9.184397686823331e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.0022481668274849653\n",
      "Gradient for encoder.encoder.4.bias: 0.0021474475506693125\n",
      "Gradient for encoder.mean.weight: 0.03170698881149292\n",
      "Gradient for encoder.mean.bias: 0.0016993425088003278\n",
      "Gradient for encoder.log_var.weight: 0.020610343664884567\n",
      "Gradient for encoder.log_var.bias: 0.0010963568929582834\n",
      "Gradient for decoder.decoder.0.weight: 0.011494029313325882\n",
      "Gradient for decoder.decoder.0.bias: 9.92878626537852e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005599787691608071\n",
      "Gradient for decoder.decoder.1.bias: 0.00047886199899949133\n",
      "Gradient for decoder.decoder.3.weight: 0.01056849118322134\n",
      "Gradient for decoder.decoder.3.bias: 7.86171405753322e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00039212763658724725\n",
      "Gradient for decoder.decoder.4.bias: 0.0003677589411381632\n",
      "Gradient for decoder.decoder.6.weight: 0.0009165616938844323\n",
      "Gradient for decoder.decoder.6.bias: 4.7060573706403375e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.007263203151524067\n",
      "Gradient for encoder.encoder.0.bias: 1.1001679602051784e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.00034989361301995814\n",
      "Gradient for encoder.encoder.1.bias: 0.00035696098348125815\n",
      "Gradient for encoder.encoder.3.weight: 0.008251117542386055\n",
      "Gradient for encoder.encoder.3.bias: 9.237396958461375e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.0019860235042870045\n",
      "Gradient for encoder.encoder.4.bias: 0.0016473421128466725\n",
      "Gradient for encoder.mean.weight: 0.030008723959326744\n",
      "Gradient for encoder.mean.bias: 0.001161352964118123\n",
      "Gradient for encoder.log_var.weight: 0.017299478873610497\n",
      "Gradient for encoder.log_var.bias: 0.0008623391622677445\n",
      "Gradient for decoder.decoder.0.weight: 0.009503049775958061\n",
      "Gradient for decoder.decoder.0.bias: 8.559075670433458e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0004562264948617667\n",
      "Gradient for decoder.decoder.1.bias: 0.0004049550334457308\n",
      "Gradient for decoder.decoder.3.weight: 0.008904104121029377\n",
      "Gradient for decoder.decoder.3.bias: 7.62514357210975e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0003946510551031679\n",
      "Gradient for decoder.decoder.4.bias: 0.0004097046912647784\n",
      "Gradient for decoder.decoder.6.weight: 0.0009530289098620415\n",
      "Gradient for decoder.decoder.6.bias: 6.847143959021196e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.005133756436407566\n",
      "Gradient for encoder.encoder.0.bias: 8.543729092258534e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.0003907851641997695\n",
      "Gradient for encoder.encoder.1.bias: 0.0003409711644053459\n",
      "Gradient for encoder.encoder.3.weight: 0.00893392600119114\n",
      "Gradient for encoder.encoder.3.bias: 9.003911505267581e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.0020816978067159653\n",
      "Gradient for encoder.encoder.4.bias: 0.0015342440456151962\n",
      "Gradient for encoder.mean.weight: 0.03208353742957115\n",
      "Gradient for encoder.mean.bias: 0.0013249831972643733\n",
      "Gradient for encoder.log_var.weight: 0.016880780458450317\n",
      "Gradient for encoder.log_var.bias: 0.0008446112624369562\n",
      "Gradient for decoder.decoder.0.weight: 0.010768604464828968\n",
      "Gradient for decoder.decoder.0.bias: 9.855829347094058e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005348276463337243\n",
      "Gradient for decoder.decoder.1.bias: 0.0004648181202355772\n",
      "Gradient for decoder.decoder.3.weight: 0.009723384864628315\n",
      "Gradient for decoder.decoder.3.bias: 7.715243721673204e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0004070429422426969\n",
      "Gradient for decoder.decoder.4.bias: 0.0003389493213035166\n",
      "Gradient for decoder.decoder.6.weight: 0.0008884099079295993\n",
      "Gradient for decoder.decoder.6.bias: 4.7825535148149356e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.006747180130332708\n",
      "Gradient for encoder.encoder.0.bias: 1.0100939182300372e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0003828930202871561\n",
      "Gradient for encoder.encoder.1.bias: 0.0003208307607565075\n",
      "Gradient for encoder.encoder.3.weight: 0.008528191596269608\n",
      "Gradient for encoder.encoder.3.bias: 1.0555958884772565e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0020927852019667625\n",
      "Gradient for encoder.encoder.4.bias: 0.001970566576346755\n",
      "Gradient for encoder.mean.weight: 0.0305005069822073\n",
      "Gradient for encoder.mean.bias: 0.001708729425445199\n",
      "Gradient for encoder.log_var.weight: 0.01701183430850506\n",
      "Gradient for encoder.log_var.bias: 0.0011652817483991385\n",
      "Gradient for decoder.decoder.0.weight: 0.009867936372756958\n",
      "Gradient for decoder.decoder.0.bias: 1.0309829379107072e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0004671750939451158\n",
      "Gradient for decoder.decoder.1.bias: 0.0004054223245475441\n",
      "Gradient for decoder.decoder.3.weight: 0.009506551548838615\n",
      "Gradient for decoder.decoder.3.bias: 9.473306861185193e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0004291796067263931\n",
      "Gradient for decoder.decoder.4.bias: 0.0004512646410148591\n",
      "Gradient for decoder.decoder.6.weight: 0.0009730712627060711\n",
      "Gradient for decoder.decoder.6.bias: 6.651211879216135e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.0056430883705616\n",
      "Gradient for encoder.encoder.0.bias: 8.519501944193042e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.0004179128154646605\n",
      "Gradient for encoder.encoder.1.bias: 0.00041356129804626107\n",
      "Gradient for encoder.encoder.3.weight: 0.009858810342848301\n",
      "Gradient for encoder.encoder.3.bias: 1.0276210438142641e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.00248957728035748\n",
      "Gradient for encoder.encoder.4.bias: 0.002129880478605628\n",
      "Gradient for encoder.mean.weight: 0.03589891642332077\n",
      "Gradient for encoder.mean.bias: 0.0016569531289860606\n",
      "Gradient for encoder.log_var.weight: 0.020441120490431786\n",
      "Gradient for encoder.log_var.bias: 0.0010608017910271883\n",
      "Gradient for decoder.decoder.0.weight: 0.01180883590131998\n",
      "Gradient for decoder.decoder.0.bias: 1.0152585022682459e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0005398552166298032\n",
      "Gradient for decoder.decoder.1.bias: 0.0004947098204866052\n",
      "Gradient for decoder.decoder.3.weight: 0.010591921396553516\n",
      "Gradient for decoder.decoder.3.bias: 7.992176365156922e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00038597165257669985\n",
      "Gradient for decoder.decoder.4.bias: 0.00034787121694535017\n",
      "Gradient for decoder.decoder.6.weight: 0.0008916138322092593\n",
      "Gradient for decoder.decoder.6.bias: 4.739410360343754e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.004622240085154772\n",
      "Gradient for encoder.encoder.0.bias: 6.627040496226533e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.00029549311148002744\n",
      "Gradient for encoder.encoder.1.bias: 0.00028131905128248036\n",
      "Gradient for encoder.encoder.3.weight: 0.006787426769733429\n",
      "Gradient for encoder.encoder.3.bias: 8.804940804241213e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.002209105296060443\n",
      "Gradient for encoder.encoder.4.bias: 0.001785043627023697\n",
      "Gradient for encoder.mean.weight: 0.03139311447739601\n",
      "Gradient for encoder.mean.bias: 0.001178216771222651\n",
      "Gradient for encoder.log_var.weight: 0.017937710508704185\n",
      "Gradient for encoder.log_var.bias: 0.0008370117284357548\n",
      "Gradient for decoder.decoder.0.weight: 0.011457107961177826\n",
      "Gradient for decoder.decoder.0.bias: 9.402478795550451e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.000567534938454628\n",
      "Gradient for decoder.decoder.1.bias: 0.0004893855657428503\n",
      "Gradient for decoder.decoder.3.weight: 0.010773146525025368\n",
      "Gradient for decoder.decoder.3.bias: 8.784439842202119e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0004615242360159755\n",
      "Gradient for decoder.decoder.4.bias: 0.00043148285476490855\n",
      "Gradient for decoder.decoder.6.weight: 0.0011236071586608887\n",
      "Gradient for decoder.decoder.6.bias: 8.750346023589373e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.005540969781577587\n",
      "Gradient for encoder.encoder.0.bias: 8.757957033200814e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.00033036316744983196\n",
      "Gradient for encoder.encoder.1.bias: 0.00032571167685091496\n",
      "Gradient for encoder.encoder.3.weight: 0.00705857714638114\n",
      "Gradient for encoder.encoder.3.bias: 8.898447950711486e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.002013246063143015\n",
      "Gradient for encoder.encoder.4.bias: 0.0016300552524626255\n",
      "Gradient for encoder.mean.weight: 0.029851144179701805\n",
      "Gradient for encoder.mean.bias: 0.001274450565688312\n",
      "Gradient for encoder.log_var.weight: 0.017357872799038887\n",
      "Gradient for encoder.log_var.bias: 0.0008326598326675594\n",
      "Gradient for decoder.decoder.0.weight: 0.011506027542054653\n",
      "Gradient for decoder.decoder.0.bias: 1.0087886082033037e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0006051745731383562\n",
      "Gradient for decoder.decoder.1.bias: 0.0004663843719754368\n",
      "Gradient for decoder.decoder.3.weight: 0.010840651579201221\n",
      "Gradient for decoder.decoder.3.bias: 8.561864411893438e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00042177943396382034\n",
      "Gradient for decoder.decoder.4.bias: 0.00033178029116243124\n",
      "Gradient for decoder.decoder.6.weight: 0.00093099195510149\n",
      "Gradient for decoder.decoder.6.bias: 4.487941987463273e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training VAE Epoch:  73%|███████▎  | 58/79 [00:00<00:00, 72.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient for encoder.encoder.0.weight: 0.006300290115177631\n",
      "Gradient for encoder.encoder.0.bias: 9.939537908010276e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.0004451712011359632\n",
      "Gradient for encoder.encoder.1.bias: 0.00036160124000161886\n",
      "Gradient for encoder.encoder.3.weight: 0.010051107965409756\n",
      "Gradient for encoder.encoder.3.bias: 8.965921061143689e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.0019963528029620647\n",
      "Gradient for encoder.encoder.4.bias: 0.0015740180388092995\n",
      "Gradient for encoder.mean.weight: 0.028846755623817444\n",
      "Gradient for encoder.mean.bias: 0.0011445280397310853\n",
      "Gradient for encoder.log_var.weight: 0.016551444306969643\n",
      "Gradient for encoder.log_var.bias: 0.0007618857198394835\n",
      "Gradient for decoder.decoder.0.weight: 0.010320184752345085\n",
      "Gradient for decoder.decoder.0.bias: 8.953031371827791e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.00048022542614489794\n",
      "Gradient for decoder.decoder.1.bias: 0.0004182979464530945\n",
      "Gradient for decoder.decoder.3.weight: 0.009540355764329433\n",
      "Gradient for decoder.decoder.3.bias: 9.734861527999072e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0004888955736532807\n",
      "Gradient for decoder.decoder.4.bias: 0.0005252588307484984\n",
      "Gradient for decoder.decoder.6.weight: 0.0009356194059364498\n",
      "Gradient for decoder.decoder.6.bias: 5.523789150174707e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.007070111110806465\n",
      "Gradient for encoder.encoder.0.bias: 1.0278859360890458e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.00042484511504881084\n",
      "Gradient for encoder.encoder.1.bias: 0.00040117776370607316\n",
      "Gradient for encoder.encoder.3.weight: 0.009131873026490211\n",
      "Gradient for encoder.encoder.3.bias: 1.0313852549792557e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0024356283247470856\n",
      "Gradient for encoder.encoder.4.bias: 0.0018376413499936461\n",
      "Gradient for encoder.mean.weight: 0.034328535199165344\n",
      "Gradient for encoder.mean.bias: 0.0014353623846545815\n",
      "Gradient for encoder.log_var.weight: 0.01790457032620907\n",
      "Gradient for encoder.log_var.bias: 0.0009425380267202854\n",
      "Gradient for decoder.decoder.0.weight: 0.010625224560499191\n",
      "Gradient for decoder.decoder.0.bias: 7.953278313710399e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.00048355222679674625\n",
      "Gradient for decoder.decoder.1.bias: 0.00042289684643037617\n",
      "Gradient for decoder.decoder.3.weight: 0.009502368979156017\n",
      "Gradient for decoder.decoder.3.bias: 9.036072584622801e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0004443149664439261\n",
      "Gradient for decoder.decoder.4.bias: 0.00045659157331101596\n",
      "Gradient for decoder.decoder.6.weight: 0.0009113107225857675\n",
      "Gradient for decoder.decoder.6.bias: 5.7411903981119394e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.004387166816741228\n",
      "Gradient for encoder.encoder.0.bias: 6.175695371757328e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.00029703055042773485\n",
      "Gradient for encoder.encoder.1.bias: 0.00031421033781953156\n",
      "Gradient for encoder.encoder.3.weight: 0.006592522840946913\n",
      "Gradient for encoder.encoder.3.bias: 8.393892525493385e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.001994785852730274\n",
      "Gradient for encoder.encoder.4.bias: 0.0016922615468502045\n",
      "Gradient for encoder.mean.weight: 0.029503215104341507\n",
      "Gradient for encoder.mean.bias: 0.001328716636635363\n",
      "Gradient for encoder.log_var.weight: 0.017669247463345528\n",
      "Gradient for encoder.log_var.bias: 0.0008496417431160808\n",
      "Gradient for decoder.decoder.0.weight: 0.012747636064887047\n",
      "Gradient for decoder.decoder.0.bias: 1.1170951663697082e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0005857594660483301\n",
      "Gradient for decoder.decoder.1.bias: 0.0005277516902424395\n",
      "Gradient for decoder.decoder.3.weight: 0.011645026504993439\n",
      "Gradient for decoder.decoder.3.bias: 9.14859299427917e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0004398023011162877\n",
      "Gradient for decoder.decoder.4.bias: 0.00038986196159385145\n",
      "Gradient for decoder.decoder.6.weight: 0.0009759655222296715\n",
      "Gradient for decoder.decoder.6.bias: 4.890330819762312e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.003709786804392934\n",
      "Gradient for encoder.encoder.0.bias: 6.415225121958468e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.00033484489540569484\n",
      "Gradient for encoder.encoder.1.bias: 0.0004021204949822277\n",
      "Gradient for encoder.encoder.3.weight: 0.007332928944379091\n",
      "Gradient for encoder.encoder.3.bias: 8.953378316522986e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.0026509957388043404\n",
      "Gradient for encoder.encoder.4.bias: 0.0022143421228975058\n",
      "Gradient for encoder.mean.weight: 0.03692891448736191\n",
      "Gradient for encoder.mean.bias: 0.0016740021528676152\n",
      "Gradient for encoder.log_var.weight: 0.021655887365341187\n",
      "Gradient for encoder.log_var.bias: 0.0012026611948385835\n",
      "Gradient for decoder.decoder.0.weight: 0.01208483800292015\n",
      "Gradient for decoder.decoder.0.bias: 9.677828677334688e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005587454070337117\n",
      "Gradient for decoder.decoder.1.bias: 0.0005026641301810741\n",
      "Gradient for decoder.decoder.3.weight: 0.010850907303392887\n",
      "Gradient for decoder.decoder.3.bias: 8.421079805698284e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0004340964660514146\n",
      "Gradient for decoder.decoder.4.bias: 0.00040697489748708904\n",
      "Gradient for decoder.decoder.6.weight: 0.0008674071868881583\n",
      "Gradient for decoder.decoder.6.bias: 4.599126987159252e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.00901175569742918\n",
      "Gradient for encoder.encoder.0.bias: 1.3735541350146097e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0005742026842199266\n",
      "Gradient for encoder.encoder.1.bias: 0.00048064874135889113\n",
      "Gradient for encoder.encoder.3.weight: 0.01305469311773777\n",
      "Gradient for encoder.encoder.3.bias: 1.2570201823880467e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0031181892845779657\n",
      "Gradient for encoder.encoder.4.bias: 0.0025485032238066196\n",
      "Gradient for encoder.mean.weight: 0.044451501220464706\n",
      "Gradient for encoder.mean.bias: 0.001993151381611824\n",
      "Gradient for encoder.log_var.weight: 0.023458488285541534\n",
      "Gradient for encoder.log_var.bias: 0.001051318016834557\n",
      "Gradient for decoder.decoder.0.weight: 0.009487713687121868\n",
      "Gradient for decoder.decoder.0.bias: 8.058873013361278e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0004639839462470263\n",
      "Gradient for decoder.decoder.1.bias: 0.00039726009708829224\n",
      "Gradient for decoder.decoder.3.weight: 0.009046653285622597\n",
      "Gradient for decoder.decoder.3.bias: 7.392512296755527e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0003716185747180134\n",
      "Gradient for decoder.decoder.4.bias: 0.00035955235944129527\n",
      "Gradient for decoder.decoder.6.weight: 0.0009045485057868063\n",
      "Gradient for decoder.decoder.6.bias: 4.91295286337845e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.005083978641778231\n",
      "Gradient for encoder.encoder.0.bias: 7.723701019035634e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.00041094396146945655\n",
      "Gradient for encoder.encoder.1.bias: 0.0003506203065626323\n",
      "Gradient for encoder.encoder.3.weight: 0.009209100157022476\n",
      "Gradient for encoder.encoder.3.bias: 8.741839890857861e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.002174947177991271\n",
      "Gradient for encoder.encoder.4.bias: 0.0016413693083450198\n",
      "Gradient for encoder.mean.weight: 0.031690098345279694\n",
      "Gradient for encoder.mean.bias: 0.0013594427146017551\n",
      "Gradient for encoder.log_var.weight: 0.018258266150951385\n",
      "Gradient for encoder.log_var.bias: 0.0008575809770263731\n",
      "Gradient for decoder.decoder.0.weight: 0.011904188431799412\n",
      "Gradient for decoder.decoder.0.bias: 1.1174236536071191e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0005714478902518749\n",
      "Gradient for decoder.decoder.1.bias: 0.0004952381132170558\n",
      "Gradient for decoder.decoder.3.weight: 0.01114883553236723\n",
      "Gradient for decoder.decoder.3.bias: 8.799133643933033e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00040245515992864966\n",
      "Gradient for decoder.decoder.4.bias: 0.00036937263212166727\n",
      "Gradient for decoder.decoder.6.weight: 0.0010439782636240125\n",
      "Gradient for decoder.decoder.6.bias: 6.925468187546358e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.0061719040386378765\n",
      "Gradient for encoder.encoder.0.bias: 9.919634558208656e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.0004403944476507604\n",
      "Gradient for encoder.encoder.1.bias: 0.00037623048410750926\n",
      "Gradient for encoder.encoder.3.weight: 0.009863226674497128\n",
      "Gradient for encoder.encoder.3.bias: 8.586472505234255e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.002133966889232397\n",
      "Gradient for encoder.encoder.4.bias: 0.0015898976707831025\n",
      "Gradient for encoder.mean.weight: 0.030647873878479004\n",
      "Gradient for encoder.mean.bias: 0.0011602952145040035\n",
      "Gradient for encoder.log_var.weight: 0.016413820907473564\n",
      "Gradient for encoder.log_var.bias: 0.0007828072994016111\n",
      "Gradient for decoder.decoder.0.weight: 0.010175161063671112\n",
      "Gradient for decoder.decoder.0.bias: 8.87451570563691e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005073606735095382\n",
      "Gradient for decoder.decoder.1.bias: 0.0004221783601678908\n",
      "Gradient for decoder.decoder.3.weight: 0.00933641567826271\n",
      "Gradient for decoder.decoder.3.bias: 8.931982237170288e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00038772818516008556\n",
      "Gradient for decoder.decoder.4.bias: 0.0003879199211951345\n",
      "Gradient for decoder.decoder.6.weight: 0.0008667926886118948\n",
      "Gradient for decoder.decoder.6.bias: 4.872753925155848e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.00445238221436739\n",
      "Gradient for encoder.encoder.0.bias: 5.86072553335204e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.00035410726559348404\n",
      "Gradient for encoder.encoder.1.bias: 0.0004229316837154329\n",
      "Gradient for encoder.encoder.3.weight: 0.007683238945901394\n",
      "Gradient for encoder.encoder.3.bias: 9.835490061282925e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.00277926423586905\n",
      "Gradient for encoder.encoder.4.bias: 0.0020380320493131876\n",
      "Gradient for encoder.mean.weight: 0.04136810451745987\n",
      "Gradient for encoder.mean.bias: 0.001269145286642015\n",
      "Gradient for encoder.log_var.weight: 0.021080780774354935\n",
      "Gradient for encoder.log_var.bias: 0.0008986704633571208\n",
      "Gradient for decoder.decoder.0.weight: 0.013380222022533417\n",
      "Gradient for decoder.decoder.0.bias: 1.241349939506975e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0006261728703975677\n",
      "Gradient for decoder.decoder.1.bias: 0.0005413623875938356\n",
      "Gradient for decoder.decoder.3.weight: 0.01239329855889082\n",
      "Gradient for decoder.decoder.3.bias: 9.852110793850954e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00044522990356199443\n",
      "Gradient for decoder.decoder.4.bias: 0.000384469487471506\n",
      "Gradient for decoder.decoder.6.weight: 0.0009036526898853481\n",
      "Gradient for decoder.decoder.6.bias: 4.5806944399373606e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.006836685352027416\n",
      "Gradient for encoder.encoder.0.bias: 9.383655311112626e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.0005535101518034935\n",
      "Gradient for encoder.encoder.1.bias: 0.0005300320335663855\n",
      "Gradient for encoder.encoder.3.weight: 0.011784796603024006\n",
      "Gradient for encoder.encoder.3.bias: 9.375842463521522e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.002320199040696025\n",
      "Gradient for encoder.encoder.4.bias: 0.0017400352517142892\n",
      "Gradient for encoder.mean.weight: 0.032220736145973206\n",
      "Gradient for encoder.mean.bias: 0.0013448173413053155\n",
      "Gradient for encoder.log_var.weight: 0.017611823976039886\n",
      "Gradient for encoder.log_var.bias: 0.001019005198031664\n",
      "Gradient for decoder.decoder.0.weight: 0.01156864408403635\n",
      "Gradient for decoder.decoder.0.bias: 9.672498912927097e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005209479131735861\n",
      "Gradient for decoder.decoder.1.bias: 0.000439920841017738\n",
      "Gradient for decoder.decoder.3.weight: 0.010658920742571354\n",
      "Gradient for decoder.decoder.3.bias: 9.053941624204143e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00037785383756272495\n",
      "Gradient for decoder.decoder.4.bias: 0.0003192769654560834\n",
      "Gradient for decoder.decoder.6.weight: 0.00084010447608307\n",
      "Gradient for decoder.decoder.6.bias: 4.7786434151930735e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.005731753073632717\n",
      "Gradient for encoder.encoder.0.bias: 8.939954679321183e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.0004809547681361437\n",
      "Gradient for encoder.encoder.1.bias: 0.0004638323443941772\n",
      "Gradient for encoder.encoder.3.weight: 0.010865217074751854\n",
      "Gradient for encoder.encoder.3.bias: 8.964098907604523e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.0020304627250880003\n",
      "Gradient for encoder.encoder.4.bias: 0.0017978103132918477\n",
      "Gradient for encoder.mean.weight: 0.030044959858059883\n",
      "Gradient for encoder.mean.bias: 0.0015136230504140258\n",
      "Gradient for encoder.log_var.weight: 0.017352372407913208\n",
      "Gradient for encoder.log_var.bias: 0.0010792432585731149\n",
      "Gradient for decoder.decoder.0.weight: 0.01244404073804617\n",
      "Gradient for decoder.decoder.0.bias: 9.417334967398716e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005903507699258626\n",
      "Gradient for decoder.decoder.1.bias: 0.0005128805642016232\n",
      "Gradient for decoder.decoder.3.weight: 0.011372334323823452\n",
      "Gradient for decoder.decoder.3.bias: 1.1587322767958597e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0008886803407222033\n",
      "Gradient for decoder.decoder.4.bias: 0.0010704721789807081\n",
      "Gradient for decoder.decoder.6.weight: 0.0014596310211345553\n",
      "Gradient for decoder.decoder.6.bias: 0.00012905769108328968\n",
      "Gradient for encoder.encoder.0.weight: 0.00444137305021286\n",
      "Gradient for encoder.encoder.0.bias: 7.420964884263803e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.00028718961402773857\n",
      "Gradient for encoder.encoder.1.bias: 0.00030071171931922436\n",
      "Gradient for encoder.encoder.3.weight: 0.006580750923603773\n",
      "Gradient for encoder.encoder.3.bias: 8.937212081505663e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.0020611362997442484\n",
      "Gradient for encoder.encoder.4.bias: 0.0016348129138350487\n",
      "Gradient for encoder.mean.weight: 0.029582776129245758\n",
      "Gradient for encoder.mean.bias: 0.001394815742969513\n",
      "Gradient for encoder.log_var.weight: 0.01720436103641987\n",
      "Gradient for encoder.log_var.bias: 0.0008912980556488037\n",
      "Gradient for decoder.decoder.0.weight: 0.011136814951896667\n",
      "Gradient for decoder.decoder.0.bias: 9.872391099063904e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005355717148631811\n",
      "Gradient for decoder.decoder.1.bias: 0.00047358821029774845\n",
      "Gradient for decoder.decoder.3.weight: 0.010271379724144936\n",
      "Gradient for decoder.decoder.3.bias: 8.778103938178461e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00038114897324703634\n",
      "Gradient for decoder.decoder.4.bias: 0.00033672756399028003\n",
      "Gradient for decoder.decoder.6.weight: 0.0008924873545765877\n",
      "Gradient for decoder.decoder.6.bias: 4.99682646477595e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.00536525109782815\n",
      "Gradient for encoder.encoder.0.bias: 8.913208712768572e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.0004369532398413867\n",
      "Gradient for encoder.encoder.1.bias: 0.00044596323277801275\n",
      "Gradient for encoder.encoder.3.weight: 0.010013296268880367\n",
      "Gradient for encoder.encoder.3.bias: 9.447102822246478e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.002328720176592469\n",
      "Gradient for encoder.encoder.4.bias: 0.001846358529292047\n",
      "Gradient for encoder.mean.weight: 0.03520007058978081\n",
      "Gradient for encoder.mean.bias: 0.0014862315729260445\n",
      "Gradient for encoder.log_var.weight: 0.019919369369745255\n",
      "Gradient for encoder.log_var.bias: 0.0010195332579314709\n",
      "Gradient for decoder.decoder.0.weight: 0.010421996004879475\n",
      "Gradient for decoder.decoder.0.bias: 8.584726679528032e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0004968563443981111\n",
      "Gradient for decoder.decoder.1.bias: 0.000420293741626665\n",
      "Gradient for decoder.decoder.3.weight: 0.009743425995111465\n",
      "Gradient for decoder.decoder.3.bias: 8.234704584886288e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00046348015894182026\n",
      "Gradient for decoder.decoder.4.bias: 0.0005332072614692152\n",
      "Gradient for decoder.decoder.6.weight: 0.0008704508654773235\n",
      "Gradient for decoder.decoder.6.bias: 5.370882718125358e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.006465614307671785\n",
      "Gradient for encoder.encoder.0.bias: 9.150623835052496e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.000471791805466637\n",
      "Gradient for encoder.encoder.1.bias: 0.00046128613757900894\n",
      "Gradient for encoder.encoder.3.weight: 0.010267809964716434\n",
      "Gradient for encoder.encoder.3.bias: 1.0128669430953252e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0021483395248651505\n",
      "Gradient for encoder.encoder.4.bias: 0.002092760754749179\n",
      "Gradient for encoder.mean.weight: 0.033190175890922546\n",
      "Gradient for encoder.mean.bias: 0.0018085299525409937\n",
      "Gradient for encoder.log_var.weight: 0.019809022545814514\n",
      "Gradient for encoder.log_var.bias: 0.0012839168775826693\n",
      "Gradient for decoder.decoder.0.weight: 0.011504318565130234\n",
      "Gradient for decoder.decoder.0.bias: 9.499662861900404e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005685688811354339\n",
      "Gradient for decoder.decoder.1.bias: 0.0005061406409367919\n",
      "Gradient for decoder.decoder.3.weight: 0.010677861981093884\n",
      "Gradient for decoder.decoder.3.bias: 8.864861622548403e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0003876180271618068\n",
      "Gradient for decoder.decoder.4.bias: 0.0003367984900251031\n",
      "Gradient for decoder.decoder.6.weight: 0.0008760913624428213\n",
      "Gradient for decoder.decoder.6.bias: 3.968513192376122e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.005630028434097767\n",
      "Gradient for encoder.encoder.0.bias: 7.205439370161493e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.000476331973914057\n",
      "Gradient for encoder.encoder.1.bias: 0.0004606064176186919\n",
      "Gradient for encoder.encoder.3.weight: 0.01036198902875185\n",
      "Gradient for encoder.encoder.3.bias: 9.582879628711183e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.002336083212867379\n",
      "Gradient for encoder.encoder.4.bias: 0.001752665382809937\n",
      "Gradient for encoder.mean.weight: 0.03227447345852852\n",
      "Gradient for encoder.mean.bias: 0.0012910774676129222\n",
      "Gradient for encoder.log_var.weight: 0.01781592145562172\n",
      "Gradient for encoder.log_var.bias: 0.000945727399084717\n",
      "Gradient for decoder.decoder.0.weight: 0.012886019423604012\n",
      "Gradient for decoder.decoder.0.bias: 1.2270544302861452e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0006167271640151739\n",
      "Gradient for decoder.decoder.1.bias: 0.0004962002858519554\n",
      "Gradient for decoder.decoder.3.weight: 0.01168470736593008\n",
      "Gradient for decoder.decoder.3.bias: 1.1634735536114604e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0005534396623261273\n",
      "Gradient for decoder.decoder.4.bias: 0.0005908604362048209\n",
      "Gradient for decoder.decoder.6.weight: 0.0009529569651931524\n",
      "Gradient for decoder.decoder.6.bias: 5.23446433362551e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.004931285511702299\n",
      "Gradient for encoder.encoder.0.bias: 6.750425305540597e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.00039530452340841293\n",
      "Gradient for encoder.encoder.1.bias: 0.0003836772812064737\n",
      "Gradient for encoder.encoder.3.weight: 0.00894148275256157\n",
      "Gradient for encoder.encoder.3.bias: 8.936045653440416e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.002101736608892679\n",
      "Gradient for encoder.encoder.4.bias: 0.0015255167381837964\n",
      "Gradient for encoder.mean.weight: 0.031446270644664764\n",
      "Gradient for encoder.mean.bias: 0.0011262731859460473\n",
      "Gradient for encoder.log_var.weight: 0.017830396071076393\n",
      "Gradient for encoder.log_var.bias: 0.0007979053189046681\n",
      "Gradient for decoder.decoder.0.weight: 0.012292159721255302\n",
      "Gradient for decoder.decoder.0.bias: 1.0088917201667158e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0006128989043645561\n",
      "Gradient for decoder.decoder.1.bias: 0.0005154631799086928\n",
      "Gradient for decoder.decoder.3.weight: 0.011458550579845905\n",
      "Gradient for decoder.decoder.3.bias: 9.479662194111782e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00044010920100845397\n",
      "Gradient for decoder.decoder.4.bias: 0.0003617480397224426\n",
      "Gradient for decoder.decoder.6.weight: 0.0009504427434876561\n",
      "Gradient for decoder.decoder.6.bias: 5.470730320666917e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.006801942363381386\n",
      "Gradient for encoder.encoder.0.bias: 1.1506469388411489e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.000462389609310776\n",
      "Gradient for encoder.encoder.1.bias: 0.00035826602834276855\n",
      "Gradient for encoder.encoder.3.weight: 0.009891435503959656\n",
      "Gradient for encoder.encoder.3.bias: 1.0045190373952906e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0023382464423775673\n",
      "Gradient for encoder.encoder.4.bias: 0.0021136035211384296\n",
      "Gradient for encoder.mean.weight: 0.03579264506697655\n",
      "Gradient for encoder.mean.bias: 0.0019156670896336436\n",
      "Gradient for encoder.log_var.weight: 0.019291598349809647\n",
      "Gradient for encoder.log_var.bias: 0.0011055634822696447\n",
      "Gradient for decoder.decoder.0.weight: 0.0096218166872859\n",
      "Gradient for decoder.decoder.0.bias: 8.478728830141335e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.00045592308742925525\n",
      "Gradient for decoder.decoder.1.bias: 0.00040639523649588227\n",
      "Gradient for decoder.decoder.3.weight: 0.008677019737660885\n",
      "Gradient for decoder.decoder.3.bias: 8.462587575142066e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00041460696957074106\n",
      "Gradient for decoder.decoder.4.bias: 0.00046211000881157815\n",
      "Gradient for decoder.decoder.6.weight: 0.0009071350796148181\n",
      "Gradient for decoder.decoder.6.bias: 6.136664160294458e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training VAE Epoch:  94%|█████████▎| 74/79 [00:01<00:00, 74.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient for encoder.encoder.0.weight: 0.0064299581572413445\n",
      "Gradient for encoder.encoder.0.bias: 8.513654191355524e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.00043183795060031116\n",
      "Gradient for encoder.encoder.1.bias: 0.0004532835155259818\n",
      "Gradient for encoder.encoder.3.weight: 0.00932899210602045\n",
      "Gradient for encoder.encoder.3.bias: 1.0119675930564398e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.00236050458624959\n",
      "Gradient for encoder.encoder.4.bias: 0.001988530158996582\n",
      "Gradient for encoder.mean.weight: 0.03504561260342598\n",
      "Gradient for encoder.mean.bias: 0.0016902944771572948\n",
      "Gradient for encoder.log_var.weight: 0.02146000601351261\n",
      "Gradient for encoder.log_var.bias: 0.0012153236893936992\n",
      "Gradient for decoder.decoder.0.weight: 0.011209225282073021\n",
      "Gradient for decoder.decoder.0.bias: 1.0755556167918456e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.000597977836150676\n",
      "Gradient for decoder.decoder.1.bias: 0.00047765515046194196\n",
      "Gradient for decoder.decoder.3.weight: 0.010604585520923138\n",
      "Gradient for decoder.decoder.3.bias: 8.046414923246203e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00038674441748298705\n",
      "Gradient for decoder.decoder.4.bias: 0.0003528781817294657\n",
      "Gradient for decoder.decoder.6.weight: 0.0010056172031909227\n",
      "Gradient for decoder.decoder.6.bias: 6.511472747661173e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.004510493017733097\n",
      "Gradient for encoder.encoder.0.bias: 8.470972187590853e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.0003743867273442447\n",
      "Gradient for encoder.encoder.1.bias: 0.0003365934535395354\n",
      "Gradient for encoder.encoder.3.weight: 0.008402195759117603\n",
      "Gradient for encoder.encoder.3.bias: 8.905431947425768e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.00204033637419343\n",
      "Gradient for encoder.encoder.4.bias: 0.0015337547520175576\n",
      "Gradient for encoder.mean.weight: 0.027856370434165\n",
      "Gradient for encoder.mean.bias: 0.0011283505009487271\n",
      "Gradient for encoder.log_var.weight: 0.01792004331946373\n",
      "Gradient for encoder.log_var.bias: 0.0008015581988729537\n",
      "Gradient for decoder.decoder.0.weight: 0.011928626336157322\n",
      "Gradient for decoder.decoder.0.bias: 1.0237870273765992e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.000587732414714992\n",
      "Gradient for decoder.decoder.1.bias: 0.0005086037563160062\n",
      "Gradient for decoder.decoder.3.weight: 0.011018161661922932\n",
      "Gradient for decoder.decoder.3.bias: 8.829149911182554e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00040566263487562537\n",
      "Gradient for decoder.decoder.4.bias: 0.0003538508026394993\n",
      "Gradient for decoder.decoder.6.weight: 0.0008774188463576138\n",
      "Gradient for decoder.decoder.6.bias: 4.8816789785632864e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.00727867940440774\n",
      "Gradient for encoder.encoder.0.bias: 9.755604310490718e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.00045752176083624363\n",
      "Gradient for encoder.encoder.1.bias: 0.0004317665589042008\n",
      "Gradient for encoder.encoder.3.weight: 0.009869447909295559\n",
      "Gradient for encoder.encoder.3.bias: 9.202624773330115e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.0024098334833979607\n",
      "Gradient for encoder.encoder.4.bias: 0.0024078250862658024\n",
      "Gradient for encoder.mean.weight: 0.033688340336084366\n",
      "Gradient for encoder.mean.bias: 0.0018901414005085826\n",
      "Gradient for encoder.log_var.weight: 0.020742591470479965\n",
      "Gradient for encoder.log_var.bias: 0.0011700841132551432\n",
      "Gradient for decoder.decoder.0.weight: 0.010690986178815365\n",
      "Gradient for decoder.decoder.0.bias: 9.06306626968778e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005185118061490357\n",
      "Gradient for decoder.decoder.1.bias: 0.0003986545780207962\n",
      "Gradient for decoder.decoder.3.weight: 0.009480582550168037\n",
      "Gradient for decoder.decoder.3.bias: 7.535192608765229e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0003519525926094502\n",
      "Gradient for decoder.decoder.4.bias: 0.00030768054421059787\n",
      "Gradient for decoder.decoder.6.weight: 0.0008586641633883119\n",
      "Gradient for decoder.decoder.6.bias: 4.025799717055634e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.0054472945630550385\n",
      "Gradient for encoder.encoder.0.bias: 8.358559504262342e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.0004181459080427885\n",
      "Gradient for encoder.encoder.1.bias: 0.0004335689009167254\n",
      "Gradient for encoder.encoder.3.weight: 0.008865874260663986\n",
      "Gradient for encoder.encoder.3.bias: 1.0388930687943443e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0022902493365108967\n",
      "Gradient for encoder.encoder.4.bias: 0.002283795503899455\n",
      "Gradient for encoder.mean.weight: 0.032901447266340256\n",
      "Gradient for encoder.mean.bias: 0.0020346143282949924\n",
      "Gradient for encoder.log_var.weight: 0.01958567462861538\n",
      "Gradient for encoder.log_var.bias: 0.0012478642165660858\n",
      "Gradient for decoder.decoder.0.weight: 0.011903772130608559\n",
      "Gradient for decoder.decoder.0.bias: 1.1376860564737967e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0005739543121308088\n",
      "Gradient for decoder.decoder.1.bias: 0.0005197966238483787\n",
      "Gradient for decoder.decoder.3.weight: 0.011150548234581947\n",
      "Gradient for decoder.decoder.3.bias: 8.974594678523573e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00039381624083034694\n",
      "Gradient for decoder.decoder.4.bias: 0.0003731620672624558\n",
      "Gradient for decoder.decoder.6.weight: 0.0009101939504034817\n",
      "Gradient for decoder.decoder.6.bias: 4.9928199587156996e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.0055803111754357815\n",
      "Gradient for encoder.encoder.0.bias: 7.546074008712989e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.0004172151966486126\n",
      "Gradient for encoder.encoder.1.bias: 0.0003597104223445058\n",
      "Gradient for encoder.encoder.3.weight: 0.009012779220938683\n",
      "Gradient for encoder.encoder.3.bias: 1.0626940299962584e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0029727541841566563\n",
      "Gradient for encoder.encoder.4.bias: 0.002336502308025956\n",
      "Gradient for encoder.mean.weight: 0.038996580988168716\n",
      "Gradient for encoder.mean.bias: 0.001361958566121757\n",
      "Gradient for encoder.log_var.weight: 0.022130200639367104\n",
      "Gradient for encoder.log_var.bias: 0.0009273087489418685\n",
      "Gradient for decoder.decoder.0.weight: 0.01169759314507246\n",
      "Gradient for decoder.decoder.0.bias: 1.0198057676102934e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0005589583306573331\n",
      "Gradient for decoder.decoder.1.bias: 0.0004889381234534085\n",
      "Gradient for decoder.decoder.3.weight: 0.010686119087040424\n",
      "Gradient for decoder.decoder.3.bias: 9.264118638885321e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0004032936703879386\n",
      "Gradient for decoder.decoder.4.bias: 0.0003485752095002681\n",
      "Gradient for decoder.decoder.6.weight: 0.000922260747756809\n",
      "Gradient for decoder.decoder.6.bias: 5.930513725616038e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.003414538223296404\n",
      "Gradient for encoder.encoder.0.bias: 5.482370200177167e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.00041923747630789876\n",
      "Gradient for encoder.encoder.1.bias: 0.0004609295865520835\n",
      "Gradient for encoder.encoder.3.weight: 0.00847319234162569\n",
      "Gradient for encoder.encoder.3.bias: 7.648809363658415e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.0025300297420471907\n",
      "Gradient for encoder.encoder.4.bias: 0.0014771753922104836\n",
      "Gradient for encoder.mean.weight: 0.03533054515719414\n",
      "Gradient for encoder.mean.bias: 0.001177108148112893\n",
      "Gradient for encoder.log_var.weight: 0.023084845393896103\n",
      "Gradient for encoder.log_var.bias: 0.0008808930870145559\n",
      "Gradient for decoder.decoder.0.weight: 0.014258936047554016\n",
      "Gradient for decoder.decoder.0.bias: 1.2139445004777372e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0006904623005539179\n",
      "Gradient for decoder.decoder.1.bias: 0.0005623034085147083\n",
      "Gradient for decoder.decoder.3.weight: 0.013217957690358162\n",
      "Gradient for decoder.decoder.3.bias: 1.0494866781174395e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0005002715042792261\n",
      "Gradient for decoder.decoder.4.bias: 0.00044054051977582276\n",
      "Gradient for decoder.decoder.6.weight: 0.0009100669994950294\n",
      "Gradient for decoder.decoder.6.bias: 4.387412627693266e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.005988316610455513\n",
      "Gradient for encoder.encoder.0.bias: 7.988374718659319e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.0004940723301842809\n",
      "Gradient for encoder.encoder.1.bias: 0.00036270206328481436\n",
      "Gradient for encoder.encoder.3.weight: 0.010916834697127342\n",
      "Gradient for encoder.encoder.3.bias: 9.599397665649434e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.0021822957787662745\n",
      "Gradient for encoder.encoder.4.bias: 0.001714245299808681\n",
      "Gradient for encoder.mean.weight: 0.029471132904291153\n",
      "Gradient for encoder.mean.bias: 0.0013714989181607962\n",
      "Gradient for encoder.log_var.weight: 0.01688750833272934\n",
      "Gradient for encoder.log_var.bias: 0.0008941373671405017\n",
      "Gradient for decoder.decoder.0.weight: 0.011175810359418392\n",
      "Gradient for decoder.decoder.0.bias: 9.482668122950955e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.00057434500195086\n",
      "Gradient for decoder.decoder.1.bias: 0.00043605032260529697\n",
      "Gradient for decoder.decoder.3.weight: 0.010609731078147888\n",
      "Gradient for decoder.decoder.3.bias: 8.378241850293122e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0004139147058594972\n",
      "Gradient for decoder.decoder.4.bias: 0.00035584421129897237\n",
      "Gradient for decoder.decoder.6.weight: 0.0008836052729748189\n",
      "Gradient for decoder.decoder.6.bias: 4.6465796913253143e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.004648515488952398\n",
      "Gradient for encoder.encoder.0.bias: 7.056208048417112e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.00039009551983326674\n",
      "Gradient for encoder.encoder.1.bias: 0.00032325516804121435\n",
      "Gradient for encoder.encoder.3.weight: 0.00801006704568863\n",
      "Gradient for encoder.encoder.3.bias: 9.965881592188808e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.0023462141398340464\n",
      "Gradient for encoder.encoder.4.bias: 0.002081498969346285\n",
      "Gradient for encoder.mean.weight: 0.032354291528463364\n",
      "Gradient for encoder.mean.bias: 0.0017189276404678822\n",
      "Gradient for encoder.log_var.weight: 0.021747371181845665\n",
      "Gradient for encoder.log_var.bias: 0.0011497798841446638\n",
      "Gradient for decoder.decoder.0.weight: 0.013175415806472301\n",
      "Gradient for decoder.decoder.0.bias: 1.2073263222500685e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0006146982777863741\n",
      "Gradient for decoder.decoder.1.bias: 0.0005413570324890316\n",
      "Gradient for decoder.decoder.3.weight: 0.012322342954576015\n",
      "Gradient for decoder.decoder.3.bias: 1.1250977233201453e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0004682412836700678\n",
      "Gradient for decoder.decoder.4.bias: 0.0004311117227189243\n",
      "Gradient for decoder.decoder.6.weight: 0.0008793595479801297\n",
      "Gradient for decoder.decoder.6.bias: 4.017565515823662e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.006302218418568373\n",
      "Gradient for encoder.encoder.0.bias: 9.439837800329087e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.00042320205830037594\n",
      "Gradient for encoder.encoder.1.bias: 0.00036012448254041374\n",
      "Gradient for encoder.encoder.3.weight: 0.009613717906177044\n",
      "Gradient for encoder.encoder.3.bias: 1.0190995963776928e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.002586513524875045\n",
      "Gradient for encoder.encoder.4.bias: 0.0019607890862971544\n",
      "Gradient for encoder.mean.weight: 0.03514114022254944\n",
      "Gradient for encoder.mean.bias: 0.0011974044609814882\n",
      "Gradient for encoder.log_var.weight: 0.0204327255487442\n",
      "Gradient for encoder.log_var.bias: 0.0008751306449994445\n",
      "Gradient for decoder.decoder.0.weight: 0.010763168334960938\n",
      "Gradient for decoder.decoder.0.bias: 9.466284700554439e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005421520909294486\n",
      "Gradient for decoder.decoder.1.bias: 0.00047116109635680914\n",
      "Gradient for decoder.decoder.3.weight: 0.010085219517350197\n",
      "Gradient for decoder.decoder.3.bias: 7.477007901712796e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0003848322667181492\n",
      "Gradient for decoder.decoder.4.bias: 0.00033529664506204426\n",
      "Gradient for decoder.decoder.6.weight: 0.0008645205525681376\n",
      "Gradient for decoder.decoder.6.bias: 4.482992153498344e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.00471959775313735\n",
      "Gradient for encoder.encoder.0.bias: 8.787632947704349e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.00045477505773305893\n",
      "Gradient for encoder.encoder.1.bias: 0.00048969587078318\n",
      "Gradient for encoder.encoder.3.weight: 0.009964868426322937\n",
      "Gradient for encoder.encoder.3.bias: 1.0049723553340328e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.002447371371090412\n",
      "Gradient for encoder.encoder.4.bias: 0.0020302622579038143\n",
      "Gradient for encoder.mean.weight: 0.0335756279528141\n",
      "Gradient for encoder.mean.bias: 0.0014343742514029145\n",
      "Gradient for encoder.log_var.weight: 0.019341452047228813\n",
      "Gradient for encoder.log_var.bias: 0.0010485360398888588\n",
      "Gradient for decoder.decoder.0.weight: 0.011317444033920765\n",
      "Gradient for decoder.decoder.0.bias: 1.0251800103278086e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0005684061325155199\n",
      "Gradient for decoder.decoder.1.bias: 0.00046681633102707565\n",
      "Gradient for decoder.decoder.3.weight: 0.01099739782512188\n",
      "Gradient for decoder.decoder.3.bias: 8.910801957418002e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00046587310498580337\n",
      "Gradient for decoder.decoder.4.bias: 0.0004703315207734704\n",
      "Gradient for decoder.decoder.6.weight: 0.000984110520221293\n",
      "Gradient for decoder.decoder.6.bias: 5.844494080520235e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.007245919201523066\n",
      "Gradient for encoder.encoder.0.bias: 1.0541054140666972e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.00039678148459643126\n",
      "Gradient for encoder.encoder.1.bias: 0.0003645737306214869\n",
      "Gradient for encoder.encoder.3.weight: 0.008626989088952541\n",
      "Gradient for encoder.encoder.3.bias: 9.441922937947211e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.0022396077401936054\n",
      "Gradient for encoder.encoder.4.bias: 0.0017377710901200771\n",
      "Gradient for encoder.mean.weight: 0.030812546610832214\n",
      "Gradient for encoder.mean.bias: 0.0011688543017953634\n",
      "Gradient for encoder.log_var.weight: 0.01802791655063629\n",
      "Gradient for encoder.log_var.bias: 0.0007785701891407371\n",
      "Gradient for decoder.decoder.0.weight: 0.008752536959946156\n",
      "Gradient for decoder.decoder.0.bias: 7.138673679962793e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0004235386149957776\n",
      "Gradient for decoder.decoder.1.bias: 0.000358600722393021\n",
      "Gradient for decoder.decoder.3.weight: 0.008061237633228302\n",
      "Gradient for decoder.decoder.3.bias: 7.565859050373547e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0004325917107053101\n",
      "Gradient for decoder.decoder.4.bias: 0.0004537631175480783\n",
      "Gradient for decoder.decoder.6.weight: 0.001069920603185892\n",
      "Gradient for decoder.decoder.6.bias: 8.221490861615166e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.006534801796078682\n",
      "Gradient for encoder.encoder.0.bias: 9.563773384346774e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.0004041949287056923\n",
      "Gradient for encoder.encoder.1.bias: 0.0003837562690023333\n",
      "Gradient for encoder.encoder.3.weight: 0.009456714615225792\n",
      "Gradient for encoder.encoder.3.bias: 9.124549726902131e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.002023630775511265\n",
      "Gradient for encoder.encoder.4.bias: 0.001652384176850319\n",
      "Gradient for encoder.mean.weight: 0.02684633620083332\n",
      "Gradient for encoder.mean.bias: 0.0013051092391833663\n",
      "Gradient for encoder.log_var.weight: 0.018345756456255913\n",
      "Gradient for encoder.log_var.bias: 0.0010145526612177491\n",
      "Gradient for decoder.decoder.0.weight: 0.011241473257541656\n",
      "Gradient for decoder.decoder.0.bias: 9.365683922846202e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005378391360864043\n",
      "Gradient for decoder.decoder.1.bias: 0.00046768513857387006\n",
      "Gradient for decoder.decoder.3.weight: 0.010573603212833405\n",
      "Gradient for decoder.decoder.3.bias: 8.001706242044548e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0003836591204162687\n",
      "Gradient for decoder.decoder.4.bias: 0.0003415663377381861\n",
      "Gradient for decoder.decoder.6.weight: 0.0008390797884203494\n",
      "Gradient for decoder.decoder.6.bias: 3.690108496812172e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.005736290477216244\n",
      "Gradient for encoder.encoder.0.bias: 8.866263626061688e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.00038640107959508896\n",
      "Gradient for encoder.encoder.1.bias: 0.0003660756046883762\n",
      "Gradient for encoder.encoder.3.weight: 0.00887865200638771\n",
      "Gradient for encoder.encoder.3.bias: 8.957197483727697e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.0022581638768315315\n",
      "Gradient for encoder.encoder.4.bias: 0.001840496202930808\n",
      "Gradient for encoder.mean.weight: 0.030180582776665688\n",
      "Gradient for encoder.mean.bias: 0.001485472428612411\n",
      "Gradient for encoder.log_var.weight: 0.018920576199889183\n",
      "Gradient for encoder.log_var.bias: 0.0008778601186349988\n",
      "Gradient for decoder.decoder.0.weight: 0.009922071360051632\n",
      "Gradient for decoder.decoder.0.bias: 8.621123259722197e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0004818256420549005\n",
      "Gradient for decoder.decoder.1.bias: 0.00039704731898382306\n",
      "Gradient for decoder.decoder.3.weight: 0.00921468622982502\n",
      "Gradient for decoder.decoder.3.bias: 8.188388855856488e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00037119269836694\n",
      "Gradient for decoder.decoder.4.bias: 0.0003634192398749292\n",
      "Gradient for decoder.decoder.6.weight: 0.0008480220567435026\n",
      "Gradient for decoder.decoder.6.bias: 4.7181161789922044e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.005699770525097847\n",
      "Gradient for encoder.encoder.0.bias: 8.867393798406287e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.00037960856570862234\n",
      "Gradient for encoder.encoder.1.bias: 0.00037503711064346135\n",
      "Gradient for encoder.encoder.3.weight: 0.008617660962045193\n",
      "Gradient for encoder.encoder.3.bias: 9.16018927377138e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.0021480766590684652\n",
      "Gradient for encoder.encoder.4.bias: 0.0017848185962066054\n",
      "Gradient for encoder.mean.weight: 0.031112713739275932\n",
      "Gradient for encoder.mean.bias: 0.0013582170940935612\n",
      "Gradient for encoder.log_var.weight: 0.01770947128534317\n",
      "Gradient for encoder.log_var.bias: 0.0008030966273508966\n",
      "Gradient for decoder.decoder.0.weight: 0.01118351798504591\n",
      "Gradient for decoder.decoder.0.bias: 9.390546673593292e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005067067104391754\n",
      "Gradient for decoder.decoder.1.bias: 0.0004623526765499264\n",
      "Gradient for decoder.decoder.3.weight: 0.01002888660877943\n",
      "Gradient for decoder.decoder.3.bias: 8.180635335808262e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00048352385056205094\n",
      "Gradient for decoder.decoder.4.bias: 0.0005391286103986204\n",
      "Gradient for decoder.decoder.6.weight: 0.0009013829403556883\n",
      "Gradient for decoder.decoder.6.bias: 5.3806830692337826e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.011230767704546452\n",
      "Gradient for encoder.encoder.0.bias: 1.3057768408208936e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0005404178518801928\n",
      "Gradient for encoder.encoder.1.bias: 0.0004795152635779232\n",
      "Gradient for encoder.encoder.3.weight: 0.011777440086007118\n",
      "Gradient for encoder.encoder.3.bias: 1.5124516916653619e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0035458009224385023\n",
      "Gradient for encoder.encoder.4.bias: 0.0030248044058680534\n",
      "Gradient for encoder.mean.weight: 0.054401855915784836\n",
      "Gradient for encoder.mean.bias: 0.0014302628114819527\n",
      "Gradient for encoder.log_var.weight: 0.029250869527459145\n",
      "Gradient for encoder.log_var.bias: 0.0013986937701702118\n",
      "Gradient for decoder.decoder.0.weight: 0.04159296676516533\n",
      "Gradient for decoder.decoder.0.bias: 2.894964268307376e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0017272079130634665\n",
      "Gradient for decoder.decoder.1.bias: 0.001603711862117052\n",
      "Gradient for decoder.decoder.3.weight: 0.0363614559173584\n",
      "Gradient for decoder.decoder.3.bias: 2.6173913036942054e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.001616156892850995\n",
      "Gradient for decoder.decoder.4.bias: 0.0018110040109604597\n",
      "Gradient for decoder.decoder.6.weight: 0.0031773655209690332\n",
      "Gradient for decoder.decoder.6.bias: 0.00022513410658575594\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/3, Train Loss: 0.0762, Val Loss: 0.2426\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training VAE Epoch:   1%|▏         | 1/79 [00:00<00:14,  5.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient for encoder.encoder.0.weight: 0.006141694728285074\n",
      "Gradient for encoder.encoder.0.bias: 8.130450306065296e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.00040771899512037635\n",
      "Gradient for encoder.encoder.1.bias: 0.0003826628380920738\n",
      "Gradient for encoder.encoder.3.weight: 0.009722332470119\n",
      "Gradient for encoder.encoder.3.bias: 9.334084200007808e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.002567748771980405\n",
      "Gradient for encoder.encoder.4.bias: 0.0018500799778848886\n",
      "Gradient for encoder.mean.weight: 0.03546580672264099\n",
      "Gradient for encoder.mean.bias: 0.0012591368285939097\n",
      "Gradient for encoder.log_var.weight: 0.019180551171302795\n",
      "Gradient for encoder.log_var.bias: 0.0009377325768582523\n",
      "Gradient for decoder.decoder.0.weight: 0.01142608467489481\n",
      "Gradient for decoder.decoder.0.bias: 9.87430207044504e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005184795008972287\n",
      "Gradient for decoder.decoder.1.bias: 0.00046001136070117354\n",
      "Gradient for decoder.decoder.3.weight: 0.010505885817110538\n",
      "Gradient for decoder.decoder.3.bias: 8.677843860160905e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00040006128256209195\n",
      "Gradient for decoder.decoder.4.bias: 0.00035911137820221484\n",
      "Gradient for decoder.decoder.6.weight: 0.0008982728468254209\n",
      "Gradient for decoder.decoder.6.bias: 4.915825047646649e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.007595216389745474\n",
      "Gradient for encoder.encoder.0.bias: 9.741711777533357e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.00042298081098124385\n",
      "Gradient for encoder.encoder.1.bias: 0.0003473932156339288\n",
      "Gradient for encoder.encoder.3.weight: 0.009464118629693985\n",
      "Gradient for encoder.encoder.3.bias: 1.1066939031856293e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0024944101460278034\n",
      "Gradient for encoder.encoder.4.bias: 0.002342360094189644\n",
      "Gradient for encoder.mean.weight: 0.03595205768942833\n",
      "Gradient for encoder.mean.bias: 0.0016167483991011977\n",
      "Gradient for encoder.log_var.weight: 0.020876716822385788\n",
      "Gradient for encoder.log_var.bias: 0.0012065648334100842\n",
      "Gradient for decoder.decoder.0.weight: 0.011426129378378391\n",
      "Gradient for decoder.decoder.0.bias: 1.122335557823817e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0005531164351850748\n",
      "Gradient for decoder.decoder.1.bias: 0.0004939001519232988\n",
      "Gradient for decoder.decoder.3.weight: 0.010529089719057083\n",
      "Gradient for decoder.decoder.3.bias: 9.621735352904892e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0005613562534563243\n",
      "Gradient for decoder.decoder.4.bias: 0.0006110839312896132\n",
      "Gradient for decoder.decoder.6.weight: 0.0010721927974373102\n",
      "Gradient for decoder.decoder.6.bias: 7.404614734696224e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training VAE Epoch:  11%|█▏        | 9/79 [00:00<00:01, 37.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient for encoder.encoder.0.weight: 0.006163658108562231\n",
      "Gradient for encoder.encoder.0.bias: 8.699190673366886e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.00047688002814538777\n",
      "Gradient for encoder.encoder.1.bias: 0.000443454016931355\n",
      "Gradient for encoder.encoder.3.weight: 0.010180077515542507\n",
      "Gradient for encoder.encoder.3.bias: 1.0401537964277452e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.002783356700092554\n",
      "Gradient for encoder.encoder.4.bias: 0.0023699922021478415\n",
      "Gradient for encoder.mean.weight: 0.042670633643865585\n",
      "Gradient for encoder.mean.bias: 0.0017478294903412461\n",
      "Gradient for encoder.log_var.weight: 0.022225072607398033\n",
      "Gradient for encoder.log_var.bias: 0.001114721060730517\n",
      "Gradient for decoder.decoder.0.weight: 0.010878649540245533\n",
      "Gradient for decoder.decoder.0.bias: 8.888689784214421e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005282144993543625\n",
      "Gradient for decoder.decoder.1.bias: 0.00046680335071869195\n",
      "Gradient for decoder.decoder.3.weight: 0.01011063251644373\n",
      "Gradient for decoder.decoder.3.bias: 7.224670861560867e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0003729096206370741\n",
      "Gradient for decoder.decoder.4.bias: 0.00034964270889759064\n",
      "Gradient for decoder.decoder.6.weight: 0.0008560254354961216\n",
      "Gradient for decoder.decoder.6.bias: 4.854482540395111e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.010588956996798515\n",
      "Gradient for encoder.encoder.0.bias: 1.6084489642964606e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0005650504026561975\n",
      "Gradient for encoder.encoder.1.bias: 0.000479132984764874\n",
      "Gradient for encoder.encoder.3.weight: 0.012057011015713215\n",
      "Gradient for encoder.encoder.3.bias: 1.1743651884277284e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.002572886645793915\n",
      "Gradient for encoder.encoder.4.bias: 0.002092145150527358\n",
      "Gradient for encoder.mean.weight: 0.037270788103342056\n",
      "Gradient for encoder.mean.bias: 0.0014904007548466325\n",
      "Gradient for encoder.log_var.weight: 0.02250801958143711\n",
      "Gradient for encoder.log_var.bias: 0.001012928900308907\n",
      "Gradient for decoder.decoder.0.weight: 0.009342129342257977\n",
      "Gradient for decoder.decoder.0.bias: 7.797947704224484e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0004378669837024063\n",
      "Gradient for decoder.decoder.1.bias: 0.00037601604708470404\n",
      "Gradient for decoder.decoder.3.weight: 0.00857085082679987\n",
      "Gradient for decoder.decoder.3.bias: 6.684740261331257e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0003330673498567194\n",
      "Gradient for decoder.decoder.4.bias: 0.00031327136093750596\n",
      "Gradient for decoder.decoder.6.weight: 0.0009129598620347679\n",
      "Gradient for decoder.decoder.6.bias: 5.329068881110288e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.007369646802544594\n",
      "Gradient for encoder.encoder.0.bias: 1.0094801730642367e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0004944185493513942\n",
      "Gradient for encoder.encoder.1.bias: 0.0002991307119373232\n",
      "Gradient for encoder.encoder.3.weight: 0.010382704436779022\n",
      "Gradient for encoder.encoder.3.bias: 9.6650465408743e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.0022050607949495316\n",
      "Gradient for encoder.encoder.4.bias: 0.001946871867403388\n",
      "Gradient for encoder.mean.weight: 0.03043489344418049\n",
      "Gradient for encoder.mean.bias: 0.0013596854405477643\n",
      "Gradient for encoder.log_var.weight: 0.017980001866817474\n",
      "Gradient for encoder.log_var.bias: 0.0010262317955493927\n",
      "Gradient for decoder.decoder.0.weight: 0.010687323287129402\n",
      "Gradient for decoder.decoder.0.bias: 9.613645296502327e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005293996655382216\n",
      "Gradient for decoder.decoder.1.bias: 0.000459230417618528\n",
      "Gradient for decoder.decoder.3.weight: 0.009869279339909554\n",
      "Gradient for decoder.decoder.3.bias: 9.738537060099972e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0004954005707986653\n",
      "Gradient for decoder.decoder.4.bias: 0.000577888626139611\n",
      "Gradient for decoder.decoder.6.weight: 0.0009272920433431864\n",
      "Gradient for decoder.decoder.6.bias: 5.248987872619182e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.005277803633362055\n",
      "Gradient for encoder.encoder.0.bias: 7.889021033657961e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.0005006929859519005\n",
      "Gradient for encoder.encoder.1.bias: 0.00041170959593728185\n",
      "Gradient for encoder.encoder.3.weight: 0.011362302117049694\n",
      "Gradient for encoder.encoder.3.bias: 9.723355454127613e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.0024289784487336874\n",
      "Gradient for encoder.encoder.4.bias: 0.0020657593850046396\n",
      "Gradient for encoder.mean.weight: 0.035577960312366486\n",
      "Gradient for encoder.mean.bias: 0.0015130097744986415\n",
      "Gradient for encoder.log_var.weight: 0.018689611926674843\n",
      "Gradient for encoder.log_var.bias: 0.0009621874778531492\n",
      "Gradient for decoder.decoder.0.weight: 0.01190645806491375\n",
      "Gradient for decoder.decoder.0.bias: 1.0104399955634946e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0005867818254046142\n",
      "Gradient for decoder.decoder.1.bias: 0.0005175393889658153\n",
      "Gradient for decoder.decoder.3.weight: 0.011442696675658226\n",
      "Gradient for decoder.decoder.3.bias: 8.300198028887706e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00041156596853397787\n",
      "Gradient for decoder.decoder.4.bias: 0.00035408217809163034\n",
      "Gradient for decoder.decoder.6.weight: 0.0008581702131778002\n",
      "Gradient for decoder.decoder.6.bias: 3.615524110500701e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.005996451713144779\n",
      "Gradient for encoder.encoder.0.bias: 8.410088597754495e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.00042714126175269485\n",
      "Gradient for encoder.encoder.1.bias: 0.00033203509519807994\n",
      "Gradient for encoder.encoder.3.weight: 0.009238661266863346\n",
      "Gradient for encoder.encoder.3.bias: 8.98286445227825e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.0019177981885150075\n",
      "Gradient for encoder.encoder.4.bias: 0.0017150597414001822\n",
      "Gradient for encoder.mean.weight: 0.027894381433725357\n",
      "Gradient for encoder.mean.bias: 0.0013095411704853177\n",
      "Gradient for encoder.log_var.weight: 0.01669064722955227\n",
      "Gradient for encoder.log_var.bias: 0.0009016119292937219\n",
      "Gradient for decoder.decoder.0.weight: 0.010874999687075615\n",
      "Gradient for decoder.decoder.0.bias: 9.152680002788571e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.000528194650541991\n",
      "Gradient for decoder.decoder.1.bias: 0.0004503288655541837\n",
      "Gradient for decoder.decoder.3.weight: 0.010030153207480907\n",
      "Gradient for decoder.decoder.3.bias: 8.944865681481673e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0004071011207997799\n",
      "Gradient for decoder.decoder.4.bias: 0.00041612301720306277\n",
      "Gradient for decoder.decoder.6.weight: 0.0008856271742843091\n",
      "Gradient for decoder.decoder.6.bias: 5.316017632139847e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.005503032822161913\n",
      "Gradient for encoder.encoder.0.bias: 7.732611426169989e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.00043833034578710794\n",
      "Gradient for encoder.encoder.1.bias: 0.00038861221401020885\n",
      "Gradient for encoder.encoder.3.weight: 0.009666835889220238\n",
      "Gradient for encoder.encoder.3.bias: 9.604204931346061e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.002512506674975157\n",
      "Gradient for encoder.encoder.4.bias: 0.0020268287044018507\n",
      "Gradient for encoder.mean.weight: 0.03639603778719902\n",
      "Gradient for encoder.mean.bias: 0.0014008823782205582\n",
      "Gradient for encoder.log_var.weight: 0.019845493137836456\n",
      "Gradient for encoder.log_var.bias: 0.0010157714132219553\n",
      "Gradient for decoder.decoder.0.weight: 0.013303730636835098\n",
      "Gradient for decoder.decoder.0.bias: 1.107114261378328e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0006671862211078405\n",
      "Gradient for decoder.decoder.1.bias: 0.0005473993951454759\n",
      "Gradient for decoder.decoder.3.weight: 0.012399864383041859\n",
      "Gradient for decoder.decoder.3.bias: 1.0677772555034437e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0005631413077935576\n",
      "Gradient for decoder.decoder.4.bias: 0.0005665005883201957\n",
      "Gradient for decoder.decoder.6.weight: 0.0010092656593769789\n",
      "Gradient for decoder.decoder.6.bias: 6.472730456152931e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.006355755962431431\n",
      "Gradient for encoder.encoder.0.bias: 9.342556242519784e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.0003799826081376523\n",
      "Gradient for encoder.encoder.1.bias: 0.0003331919724587351\n",
      "Gradient for encoder.encoder.3.weight: 0.008153458125889301\n",
      "Gradient for encoder.encoder.3.bias: 9.55124590529266e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.002269055927172303\n",
      "Gradient for encoder.encoder.4.bias: 0.0018778591183945537\n",
      "Gradient for encoder.mean.weight: 0.030466550961136818\n",
      "Gradient for encoder.mean.bias: 0.0012742129620164633\n",
      "Gradient for encoder.log_var.weight: 0.018472541123628616\n",
      "Gradient for encoder.log_var.bias: 0.000945882813539356\n",
      "Gradient for decoder.decoder.0.weight: 0.011500813998281956\n",
      "Gradient for decoder.decoder.0.bias: 9.855023047622424e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005634946282953024\n",
      "Gradient for decoder.decoder.1.bias: 0.0004775887937285006\n",
      "Gradient for decoder.decoder.3.weight: 0.010630299337208271\n",
      "Gradient for decoder.decoder.3.bias: 8.333735784793461e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.000375418399926275\n",
      "Gradient for decoder.decoder.4.bias: 0.0003430374781601131\n",
      "Gradient for decoder.decoder.6.weight: 0.0008609335054643452\n",
      "Gradient for decoder.decoder.6.bias: 4.483631710172631e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.00472638662904501\n",
      "Gradient for encoder.encoder.0.bias: 7.694341691566464e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.00040385310421697795\n",
      "Gradient for encoder.encoder.1.bias: 0.00043126914533786476\n",
      "Gradient for encoder.encoder.3.weight: 0.009129839017987251\n",
      "Gradient for encoder.encoder.3.bias: 8.881525376258637e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.0025427150540053844\n",
      "Gradient for encoder.encoder.4.bias: 0.0019109260756522417\n",
      "Gradient for encoder.mean.weight: 0.03460175171494484\n",
      "Gradient for encoder.mean.bias: 0.0013751124497503042\n",
      "Gradient for encoder.log_var.weight: 0.021778373047709465\n",
      "Gradient for encoder.log_var.bias: 0.0010146701242774725\n",
      "Gradient for decoder.decoder.0.weight: 0.012071619741618633\n",
      "Gradient for decoder.decoder.0.bias: 9.653385035779394e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005978711997158825\n",
      "Gradient for decoder.decoder.1.bias: 0.0004552363243419677\n",
      "Gradient for decoder.decoder.3.weight: 0.011073834262788296\n",
      "Gradient for decoder.decoder.3.bias: 8.281141744559406e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00040583391091786325\n",
      "Gradient for decoder.decoder.4.bias: 0.00033489332417957485\n",
      "Gradient for decoder.decoder.6.weight: 0.0009224910172633827\n",
      "Gradient for decoder.decoder.6.bias: 4.7447112592635676e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.00512609351426363\n",
      "Gradient for encoder.encoder.0.bias: 7.78416307106733e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.0003371940983925015\n",
      "Gradient for encoder.encoder.1.bias: 0.00028766709147021174\n",
      "Gradient for encoder.encoder.3.weight: 0.007379841059446335\n",
      "Gradient for encoder.encoder.3.bias: 9.175881582335066e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.0018766162684187293\n",
      "Gradient for encoder.encoder.4.bias: 0.00174613983836025\n",
      "Gradient for encoder.mean.weight: 0.027740534394979477\n",
      "Gradient for encoder.mean.bias: 0.0013493784936144948\n",
      "Gradient for encoder.log_var.weight: 0.017541222274303436\n",
      "Gradient for encoder.log_var.bias: 0.0009718368528410792\n",
      "Gradient for decoder.decoder.0.weight: 0.013792624697089195\n",
      "Gradient for decoder.decoder.0.bias: 1.2677831007223972e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0006494473782368004\n",
      "Gradient for decoder.decoder.1.bias: 0.0005603422177955508\n",
      "Gradient for decoder.decoder.3.weight: 0.012426680885255337\n",
      "Gradient for decoder.decoder.3.bias: 1.278012001781903e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0006488913204520941\n",
      "Gradient for decoder.decoder.4.bias: 0.0006814039661549032\n",
      "Gradient for decoder.decoder.6.weight: 0.0010706421453505754\n",
      "Gradient for decoder.decoder.6.bias: 7.271562208188698e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.004585225135087967\n",
      "Gradient for encoder.encoder.0.bias: 6.708042975256401e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.0003939999151043594\n",
      "Gradient for encoder.encoder.1.bias: 0.00033322430681437254\n",
      "Gradient for encoder.encoder.3.weight: 0.008163940161466599\n",
      "Gradient for encoder.encoder.3.bias: 8.370347470698647e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.0021076735574752092\n",
      "Gradient for encoder.encoder.4.bias: 0.0017085348954424262\n",
      "Gradient for encoder.mean.weight: 0.03065243363380432\n",
      "Gradient for encoder.mean.bias: 0.0013150161830708385\n",
      "Gradient for encoder.log_var.weight: 0.016943231225013733\n",
      "Gradient for encoder.log_var.bias: 0.0007833087584003806\n",
      "Gradient for decoder.decoder.0.weight: 0.011270163580775261\n",
      "Gradient for decoder.decoder.0.bias: 9.206366918812492e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005536272656172514\n",
      "Gradient for decoder.decoder.1.bias: 0.00047419106704182923\n",
      "Gradient for decoder.decoder.3.weight: 0.010331411845982075\n",
      "Gradient for decoder.decoder.3.bias: 8.423780423205685e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00037528155371546745\n",
      "Gradient for decoder.decoder.4.bias: 0.0003277961804997176\n",
      "Gradient for decoder.decoder.6.weight: 0.0008483088458888233\n",
      "Gradient for decoder.decoder.6.bias: 4.4450443965615705e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.004716099705547094\n",
      "Gradient for encoder.encoder.0.bias: 7.926855352669016e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.0004018839099444449\n",
      "Gradient for encoder.encoder.1.bias: 0.0005448719603009522\n",
      "Gradient for encoder.encoder.3.weight: 0.00912541151046753\n",
      "Gradient for encoder.encoder.3.bias: 9.921227034359603e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.0026681001763790846\n",
      "Gradient for encoder.encoder.4.bias: 0.0022661315742880106\n",
      "Gradient for encoder.mean.weight: 0.038168732076883316\n",
      "Gradient for encoder.mean.bias: 0.0018974855775013566\n",
      "Gradient for encoder.log_var.weight: 0.02060115337371826\n",
      "Gradient for encoder.log_var.bias: 0.0011718563036993146\n",
      "Gradient for decoder.decoder.0.weight: 0.011884919367730618\n",
      "Gradient for decoder.decoder.0.bias: 1.0988748799789505e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0005417907959781587\n",
      "Gradient for decoder.decoder.1.bias: 0.0004696351243183017\n",
      "Gradient for decoder.decoder.3.weight: 0.011376075446605682\n",
      "Gradient for decoder.decoder.3.bias: 9.922633548153925e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0004844091890845448\n",
      "Gradient for decoder.decoder.4.bias: 0.0005144701572135091\n",
      "Gradient for decoder.decoder.6.weight: 0.0010116215562447906\n",
      "Gradient for decoder.decoder.6.bias: 6.501076859422028e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.004526111297309399\n",
      "Gradient for encoder.encoder.0.bias: 7.578690279508304e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.0003158040635753423\n",
      "Gradient for encoder.encoder.1.bias: 0.00034291655174456537\n",
      "Gradient for encoder.encoder.3.weight: 0.007212099619209766\n",
      "Gradient for encoder.encoder.3.bias: 9.521895077968523e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.002322220476344228\n",
      "Gradient for encoder.encoder.4.bias: 0.0019163844408467412\n",
      "Gradient for encoder.mean.weight: 0.03258581832051277\n",
      "Gradient for encoder.mean.bias: 0.0013671009801328182\n",
      "Gradient for encoder.log_var.weight: 0.01893373392522335\n",
      "Gradient for encoder.log_var.bias: 0.0009355909423902631\n",
      "Gradient for decoder.decoder.0.weight: 0.012281595729291439\n",
      "Gradient for decoder.decoder.0.bias: 1.0775694919695766e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.000609189213719219\n",
      "Gradient for decoder.decoder.1.bias: 0.0005119693814776838\n",
      "Gradient for decoder.decoder.3.weight: 0.01173803023993969\n",
      "Gradient for decoder.decoder.3.bias: 9.072138179577749e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0005108615150675178\n",
      "Gradient for decoder.decoder.4.bias: 0.0004641391569748521\n",
      "Gradient for decoder.decoder.6.weight: 0.0009563309722580016\n",
      "Gradient for decoder.decoder.6.bias: 4.287091360311024e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.005903757642954588\n",
      "Gradient for encoder.encoder.0.bias: 9.530102401678064e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.0004241970309522003\n",
      "Gradient for encoder.encoder.1.bias: 0.0003696415515150875\n",
      "Gradient for encoder.encoder.3.weight: 0.008927421644330025\n",
      "Gradient for encoder.encoder.3.bias: 9.473102163815028e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.002495542634278536\n",
      "Gradient for encoder.encoder.4.bias: 0.0018354234052821994\n",
      "Gradient for encoder.mean.weight: 0.033729638904333115\n",
      "Gradient for encoder.mean.bias: 0.0013072889996692538\n",
      "Gradient for encoder.log_var.weight: 0.018180323764681816\n",
      "Gradient for encoder.log_var.bias: 0.0009620232158340514\n",
      "Gradient for decoder.decoder.0.weight: 0.012050758115947247\n",
      "Gradient for decoder.decoder.0.bias: 1.0096697089512219e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0006127918022684753\n",
      "Gradient for decoder.decoder.1.bias: 0.0005215430865064263\n",
      "Gradient for decoder.decoder.3.weight: 0.011319692246615887\n",
      "Gradient for decoder.decoder.3.bias: 8.878900392694788e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0005292656715027988\n",
      "Gradient for decoder.decoder.4.bias: 0.000558400119189173\n",
      "Gradient for decoder.decoder.6.weight: 0.0009145433432422578\n",
      "Gradient for decoder.decoder.6.bias: 4.3913430999964476e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.004765346180647612\n",
      "Gradient for encoder.encoder.0.bias: 6.775407925679877e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.00037568469997495413\n",
      "Gradient for encoder.encoder.1.bias: 0.0002972479851450771\n",
      "Gradient for encoder.encoder.3.weight: 0.008034787140786648\n",
      "Gradient for encoder.encoder.3.bias: 8.007637608553608e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.002099709352478385\n",
      "Gradient for encoder.encoder.4.bias: 0.001546504907310009\n",
      "Gradient for encoder.mean.weight: 0.03092527575790882\n",
      "Gradient for encoder.mean.bias: 0.0010243579745292664\n",
      "Gradient for encoder.log_var.weight: 0.018250908702611923\n",
      "Gradient for encoder.log_var.bias: 0.0007863977807573974\n",
      "Gradient for decoder.decoder.0.weight: 0.011781597509980202\n",
      "Gradient for decoder.decoder.0.bias: 9.674255840863566e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0006012432859279215\n",
      "Gradient for decoder.decoder.1.bias: 0.0004975802730768919\n",
      "Gradient for decoder.decoder.3.weight: 0.01082807406783104\n",
      "Gradient for decoder.decoder.3.bias: 7.920848699161098e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00040872523095458746\n",
      "Gradient for decoder.decoder.4.bias: 0.0003663203970063478\n",
      "Gradient for decoder.decoder.6.weight: 0.0008816837798804045\n",
      "Gradient for decoder.decoder.6.bias: 3.950914106098935e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training VAE Epoch:  22%|██▏       | 17/79 [00:00<00:01, 52.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient for encoder.encoder.0.weight: 0.00538531132042408\n",
      "Gradient for encoder.encoder.0.bias: 7.413331233607767e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.00042241724440827966\n",
      "Gradient for encoder.encoder.1.bias: 0.00045427377335727215\n",
      "Gradient for encoder.encoder.3.weight: 0.00936935655772686\n",
      "Gradient for encoder.encoder.3.bias: 8.576035021023998e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.002033241791650653\n",
      "Gradient for encoder.encoder.4.bias: 0.0015156010631471872\n",
      "Gradient for encoder.mean.weight: 0.0283154658973217\n",
      "Gradient for encoder.mean.bias: 0.0011437530629336834\n",
      "Gradient for encoder.log_var.weight: 0.01881115697324276\n",
      "Gradient for encoder.log_var.bias: 0.0009055628906935453\n",
      "Gradient for decoder.decoder.0.weight: 0.011135860346257687\n",
      "Gradient for decoder.decoder.0.bias: 9.845955994958189e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.000520983652677387\n",
      "Gradient for decoder.decoder.1.bias: 0.0004521524824667722\n",
      "Gradient for decoder.decoder.3.weight: 0.010040037333965302\n",
      "Gradient for decoder.decoder.3.bias: 8.485572661198759e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0003865840844810009\n",
      "Gradient for decoder.decoder.4.bias: 0.0003581756609492004\n",
      "Gradient for decoder.decoder.6.weight: 0.0008623343310318887\n",
      "Gradient for decoder.decoder.6.bias: 4.387318040244281e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.004222766030579805\n",
      "Gradient for encoder.encoder.0.bias: 6.8342428070911065e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.0004089136782567948\n",
      "Gradient for encoder.encoder.1.bias: 0.000295293633826077\n",
      "Gradient for encoder.encoder.3.weight: 0.009080090560019016\n",
      "Gradient for encoder.encoder.3.bias: 8.855489258552396e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.0023439638316631317\n",
      "Gradient for encoder.encoder.4.bias: 0.0016900853952392936\n",
      "Gradient for encoder.mean.weight: 0.029724324122071266\n",
      "Gradient for encoder.mean.bias: 0.0012761458056047559\n",
      "Gradient for encoder.log_var.weight: 0.019022071734070778\n",
      "Gradient for encoder.log_var.bias: 0.0008651033858768642\n",
      "Gradient for decoder.decoder.0.weight: 0.012370659038424492\n",
      "Gradient for decoder.decoder.0.bias: 1.0197398481182063e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0005980813875794411\n",
      "Gradient for decoder.decoder.1.bias: 0.0005052580963820219\n",
      "Gradient for decoder.decoder.3.weight: 0.011261584237217903\n",
      "Gradient for decoder.decoder.3.bias: 1.0237965336612476e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0004677167162299156\n",
      "Gradient for decoder.decoder.4.bias: 0.0004548536380752921\n",
      "Gradient for decoder.decoder.6.weight: 0.0009165958617813885\n",
      "Gradient for decoder.decoder.6.bias: 5.1466471632011235e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training VAE Epoch:  33%|███▎      | 26/79 [00:00<00:00, 63.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient for encoder.encoder.0.weight: 0.007817342877388\n",
      "Gradient for encoder.encoder.0.bias: 1.0456313766227243e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0005408055731095374\n",
      "Gradient for encoder.encoder.1.bias: 0.0004625105648301542\n",
      "Gradient for encoder.encoder.3.weight: 0.01187667902559042\n",
      "Gradient for encoder.encoder.3.bias: 1.1581224174106453e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0029061289969831705\n",
      "Gradient for encoder.encoder.4.bias: 0.002272454323247075\n",
      "Gradient for encoder.mean.weight: 0.0376298651099205\n",
      "Gradient for encoder.mean.bias: 0.0016292722430080175\n",
      "Gradient for encoder.log_var.weight: 0.021699346601963043\n",
      "Gradient for encoder.log_var.bias: 0.000982747063972056\n",
      "Gradient for decoder.decoder.0.weight: 0.010268758051097393\n",
      "Gradient for decoder.decoder.0.bias: 9.553938196127376e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0004703899612650275\n",
      "Gradient for decoder.decoder.1.bias: 0.00043749561882577837\n",
      "Gradient for decoder.decoder.3.weight: 0.009206688031554222\n",
      "Gradient for decoder.decoder.3.bias: 9.177503201840409e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0004412909329403192\n",
      "Gradient for decoder.decoder.4.bias: 0.0005027922452427447\n",
      "Gradient for decoder.decoder.6.weight: 0.0008975961827673018\n",
      "Gradient for decoder.decoder.6.bias: 4.647863534046337e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.004616669844835997\n",
      "Gradient for encoder.encoder.0.bias: 7.146254941969854e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.00034598048659972847\n",
      "Gradient for encoder.encoder.1.bias: 0.00033797055948525667\n",
      "Gradient for encoder.encoder.3.weight: 0.0074434904381632805\n",
      "Gradient for encoder.encoder.3.bias: 7.893265208114286e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.0021120032761245966\n",
      "Gradient for encoder.encoder.4.bias: 0.0015158792957663536\n",
      "Gradient for encoder.mean.weight: 0.02928927168250084\n",
      "Gradient for encoder.mean.bias: 0.001171931973658502\n",
      "Gradient for encoder.log_var.weight: 0.01758934184908867\n",
      "Gradient for encoder.log_var.bias: 0.0007504871464334428\n",
      "Gradient for decoder.decoder.0.weight: 0.011056991294026375\n",
      "Gradient for decoder.decoder.0.bias: 9.774443754384521e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005111666396260262\n",
      "Gradient for decoder.decoder.1.bias: 0.0004382894258014858\n",
      "Gradient for decoder.decoder.3.weight: 0.010160612873733044\n",
      "Gradient for decoder.decoder.3.bias: 8.919520677608261e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0004500114300753921\n",
      "Gradient for decoder.decoder.4.bias: 0.0004899897030554712\n",
      "Gradient for decoder.decoder.6.weight: 0.0009206979884766042\n",
      "Gradient for decoder.decoder.6.bias: 5.2731083997059613e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.004162241704761982\n",
      "Gradient for encoder.encoder.0.bias: 5.742244787304562e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.0003720310050994158\n",
      "Gradient for encoder.encoder.1.bias: 0.00037731247721239924\n",
      "Gradient for encoder.encoder.3.weight: 0.008376757614314556\n",
      "Gradient for encoder.encoder.3.bias: 8.51425596692934e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.002190802013501525\n",
      "Gradient for encoder.encoder.4.bias: 0.0015547072980552912\n",
      "Gradient for encoder.mean.weight: 0.03426564484834671\n",
      "Gradient for encoder.mean.bias: 0.0011948407627642155\n",
      "Gradient for encoder.log_var.weight: 0.019145477563142776\n",
      "Gradient for encoder.log_var.bias: 0.0007708172779530287\n",
      "Gradient for decoder.decoder.0.weight: 0.013698092661798\n",
      "Gradient for decoder.decoder.0.bias: 1.0890848639588668e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0006385071901604533\n",
      "Gradient for decoder.decoder.1.bias: 0.000550595170352608\n",
      "Gradient for decoder.decoder.3.weight: 0.012604915536940098\n",
      "Gradient for decoder.decoder.3.bias: 9.169884990223309e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0004796077264472842\n",
      "Gradient for decoder.decoder.4.bias: 0.0004784166521858424\n",
      "Gradient for decoder.decoder.6.weight: 0.0008862220565788448\n",
      "Gradient for decoder.decoder.6.bias: 3.527750232024118e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.004359034355729818\n",
      "Gradient for encoder.encoder.0.bias: 6.439235429589463e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.0003879631112795323\n",
      "Gradient for encoder.encoder.1.bias: 0.00034670697641558945\n",
      "Gradient for encoder.encoder.3.weight: 0.008646655827760696\n",
      "Gradient for encoder.encoder.3.bias: 8.465567136184404e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.002308801980689168\n",
      "Gradient for encoder.encoder.4.bias: 0.001702392939478159\n",
      "Gradient for encoder.mean.weight: 0.030248723924160004\n",
      "Gradient for encoder.mean.bias: 0.001081183785572648\n",
      "Gradient for encoder.log_var.weight: 0.01845674403011799\n",
      "Gradient for encoder.log_var.bias: 0.000752809050027281\n",
      "Gradient for decoder.decoder.0.weight: 0.013054869137704372\n",
      "Gradient for decoder.decoder.0.bias: 1.1997129678587015e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0006323030684143305\n",
      "Gradient for decoder.decoder.1.bias: 0.0005287328967824578\n",
      "Gradient for decoder.decoder.3.weight: 0.011800823733210564\n",
      "Gradient for decoder.decoder.3.bias: 1.0945492429081938e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0004692424845416099\n",
      "Gradient for decoder.decoder.4.bias: 0.0004999579396098852\n",
      "Gradient for decoder.decoder.6.weight: 0.0010219098767265677\n",
      "Gradient for decoder.decoder.6.bias: 7.650813495274633e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.004651358816772699\n",
      "Gradient for encoder.encoder.0.bias: 7.759686122821297e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.00034913691342808306\n",
      "Gradient for encoder.encoder.1.bias: 0.00032956755603663623\n",
      "Gradient for encoder.encoder.3.weight: 0.007983719930052757\n",
      "Gradient for encoder.encoder.3.bias: 7.803009627327384e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.002219181042164564\n",
      "Gradient for encoder.encoder.4.bias: 0.0014891204191371799\n",
      "Gradient for encoder.mean.weight: 0.02973230555653572\n",
      "Gradient for encoder.mean.bias: 0.0010090835858136415\n",
      "Gradient for encoder.log_var.weight: 0.0184346754103899\n",
      "Gradient for encoder.log_var.bias: 0.0007700070273131132\n",
      "Gradient for decoder.decoder.0.weight: 0.011290346272289753\n",
      "Gradient for decoder.decoder.0.bias: 9.19448198133388e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005277129239402711\n",
      "Gradient for decoder.decoder.1.bias: 0.0004540666122920811\n",
      "Gradient for decoder.decoder.3.weight: 0.010376558639109135\n",
      "Gradient for decoder.decoder.3.bias: 7.835745247097847e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00038426980609074235\n",
      "Gradient for decoder.decoder.4.bias: 0.0003508612571749836\n",
      "Gradient for decoder.decoder.6.weight: 0.0008209040388464928\n",
      "Gradient for decoder.decoder.6.bias: 3.75081981474068e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.0035635733511298895\n",
      "Gradient for encoder.encoder.0.bias: 6.1269097434424324e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.00032653112430125475\n",
      "Gradient for encoder.encoder.1.bias: 0.000305987021420151\n",
      "Gradient for encoder.encoder.3.weight: 0.007213995326310396\n",
      "Gradient for encoder.encoder.3.bias: 8.133798495846278e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.0022538236808031797\n",
      "Gradient for encoder.encoder.4.bias: 0.0016223926795646548\n",
      "Gradient for encoder.mean.weight: 0.030746690928936005\n",
      "Gradient for encoder.mean.bias: 0.0011166235199198127\n",
      "Gradient for encoder.log_var.weight: 0.017852362245321274\n",
      "Gradient for encoder.log_var.bias: 0.0007883954676799476\n",
      "Gradient for decoder.decoder.0.weight: 0.013083920814096928\n",
      "Gradient for decoder.decoder.0.bias: 1.1668946364729038e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0005924387951381505\n",
      "Gradient for decoder.decoder.1.bias: 0.0005420874222181737\n",
      "Gradient for decoder.decoder.3.weight: 0.012047020718455315\n",
      "Gradient for decoder.decoder.3.bias: 1.0115236426244678e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0004294567625038326\n",
      "Gradient for decoder.decoder.4.bias: 0.00040959203033708036\n",
      "Gradient for decoder.decoder.6.weight: 0.0008975150412879884\n",
      "Gradient for decoder.decoder.6.bias: 4.104437175556086e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.004568155389279127\n",
      "Gradient for encoder.encoder.0.bias: 6.470267030489474e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.0003261856036260724\n",
      "Gradient for encoder.encoder.1.bias: 0.00030870933551341295\n",
      "Gradient for encoder.encoder.3.weight: 0.006940624210983515\n",
      "Gradient for encoder.encoder.3.bias: 8.09997000028595e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.0019336504628881812\n",
      "Gradient for encoder.encoder.4.bias: 0.0014930920442566276\n",
      "Gradient for encoder.mean.weight: 0.028233837336301804\n",
      "Gradient for encoder.mean.bias: 0.0011826141271740198\n",
      "Gradient for encoder.log_var.weight: 0.017293302342295647\n",
      "Gradient for encoder.log_var.bias: 0.0006956060533411801\n",
      "Gradient for decoder.decoder.0.weight: 0.012542719021439552\n",
      "Gradient for decoder.decoder.0.bias: 1.0648251724809654e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0005936513189226389\n",
      "Gradient for decoder.decoder.1.bias: 0.0005247608642093837\n",
      "Gradient for decoder.decoder.3.weight: 0.011574526317417622\n",
      "Gradient for decoder.decoder.3.bias: 9.059935440758338e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0004461151547729969\n",
      "Gradient for decoder.decoder.4.bias: 0.00040484071359969676\n",
      "Gradient for decoder.decoder.6.weight: 0.0009167622774839401\n",
      "Gradient for decoder.decoder.6.bias: 4.2890071199508384e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.0055219936184585094\n",
      "Gradient for encoder.encoder.0.bias: 8.737448264906078e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.000399596756324172\n",
      "Gradient for encoder.encoder.1.bias: 0.00034770576166920364\n",
      "Gradient for encoder.encoder.3.weight: 0.008771941065788269\n",
      "Gradient for encoder.encoder.3.bias: 8.489301622782719e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.002213010098785162\n",
      "Gradient for encoder.encoder.4.bias: 0.001691567711532116\n",
      "Gradient for encoder.mean.weight: 0.029849061742424965\n",
      "Gradient for encoder.mean.bias: 0.001384895876981318\n",
      "Gradient for encoder.log_var.weight: 0.01945725828409195\n",
      "Gradient for encoder.log_var.bias: 0.0007620961987413466\n",
      "Gradient for decoder.decoder.0.weight: 0.011265389621257782\n",
      "Gradient for decoder.decoder.0.bias: 9.239194131982487e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005643994081765413\n",
      "Gradient for decoder.decoder.1.bias: 0.0004492839507292956\n",
      "Gradient for decoder.decoder.3.weight: 0.009998633526265621\n",
      "Gradient for decoder.decoder.3.bias: 8.335765411260354e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00040793695370666683\n",
      "Gradient for decoder.decoder.4.bias: 0.00043164583621546626\n",
      "Gradient for decoder.decoder.6.weight: 0.0008986120810732245\n",
      "Gradient for decoder.decoder.6.bias: 4.8093694203998893e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.00356901902705431\n",
      "Gradient for encoder.encoder.0.bias: 6.246996409747796e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.00033406875445507467\n",
      "Gradient for encoder.encoder.1.bias: 0.00039228316745720804\n",
      "Gradient for encoder.encoder.3.weight: 0.007486878894269466\n",
      "Gradient for encoder.encoder.3.bias: 8.71173758132393e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.002601644257083535\n",
      "Gradient for encoder.encoder.4.bias: 0.001976040191948414\n",
      "Gradient for encoder.mean.weight: 0.03646726906299591\n",
      "Gradient for encoder.mean.bias: 0.0013954106252640486\n",
      "Gradient for encoder.log_var.weight: 0.018688054755330086\n",
      "Gradient for encoder.log_var.bias: 0.0008835052722133696\n",
      "Gradient for decoder.decoder.0.weight: 0.01232949923723936\n",
      "Gradient for decoder.decoder.0.bias: 1.1462435861586684e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.000584032793994993\n",
      "Gradient for decoder.decoder.1.bias: 0.0004856371378991753\n",
      "Gradient for decoder.decoder.3.weight: 0.0107222069054842\n",
      "Gradient for decoder.decoder.3.bias: 9.211623130944702e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00038853558362461627\n",
      "Gradient for decoder.decoder.4.bias: 0.00039147664210759103\n",
      "Gradient for decoder.decoder.6.weight: 0.0008311117999255657\n",
      "Gradient for decoder.decoder.6.bias: 4.42224700236693e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.0042238724417984486\n",
      "Gradient for encoder.encoder.0.bias: 8.264965101201227e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.0004292887169867754\n",
      "Gradient for encoder.encoder.1.bias: 0.00038065644912421703\n",
      "Gradient for encoder.encoder.3.weight: 0.009449887089431286\n",
      "Gradient for encoder.encoder.3.bias: 8.233540932378602e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.0026602023281157017\n",
      "Gradient for encoder.encoder.4.bias: 0.0019019994651898742\n",
      "Gradient for encoder.mean.weight: 0.035968389362096786\n",
      "Gradient for encoder.mean.bias: 0.0012452586088329554\n",
      "Gradient for encoder.log_var.weight: 0.02156287617981434\n",
      "Gradient for encoder.log_var.bias: 0.0008566241594962776\n",
      "Gradient for decoder.decoder.0.weight: 0.010656025260686874\n",
      "Gradient for decoder.decoder.0.bias: 8.486850111566469e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0004894804442301393\n",
      "Gradient for decoder.decoder.1.bias: 0.00044229801278561354\n",
      "Gradient for decoder.decoder.3.weight: 0.009968512691557407\n",
      "Gradient for decoder.decoder.3.bias: 8.95816198998034e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00038747081998735666\n",
      "Gradient for decoder.decoder.4.bias: 0.00036688780528493226\n",
      "Gradient for decoder.decoder.6.weight: 0.0009885604958981276\n",
      "Gradient for decoder.decoder.6.bias: 6.287130963755772e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.004763719160109758\n",
      "Gradient for encoder.encoder.0.bias: 7.19083646794072e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.00031332435901276767\n",
      "Gradient for encoder.encoder.1.bias: 0.00027255082386545837\n",
      "Gradient for encoder.encoder.3.weight: 0.0067481109872460365\n",
      "Gradient for encoder.encoder.3.bias: 7.879639996044574e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.0018178806640207767\n",
      "Gradient for encoder.encoder.4.bias: 0.0013722467701882124\n",
      "Gradient for encoder.mean.weight: 0.027853693813085556\n",
      "Gradient for encoder.mean.bias: 0.0009498980361968279\n",
      "Gradient for encoder.log_var.weight: 0.016282442957162857\n",
      "Gradient for encoder.log_var.bias: 0.0007373236585408449\n",
      "Gradient for decoder.decoder.0.weight: 0.011152696795761585\n",
      "Gradient for decoder.decoder.0.bias: 9.458949595808619e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005052599008195102\n",
      "Gradient for decoder.decoder.1.bias: 0.00045424612471833825\n",
      "Gradient for decoder.decoder.3.weight: 0.010081135667860508\n",
      "Gradient for decoder.decoder.3.bias: 7.84338635706483e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00038265445618890226\n",
      "Gradient for decoder.decoder.4.bias: 0.00033798516960814595\n",
      "Gradient for decoder.decoder.6.weight: 0.0008403741521760821\n",
      "Gradient for decoder.decoder.6.bias: 4.487811020226218e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.00526226544752717\n",
      "Gradient for encoder.encoder.0.bias: 9.365072085876225e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.0004097645578440279\n",
      "Gradient for encoder.encoder.1.bias: 0.0003783672000281513\n",
      "Gradient for encoder.encoder.3.weight: 0.0084929084405303\n",
      "Gradient for encoder.encoder.3.bias: 8.109992538640753e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.0018403023714199662\n",
      "Gradient for encoder.encoder.4.bias: 0.0012559205060824752\n",
      "Gradient for encoder.mean.weight: 0.028351882472634315\n",
      "Gradient for encoder.mean.bias: 0.0009207080584019423\n",
      "Gradient for encoder.log_var.weight: 0.01664174348115921\n",
      "Gradient for encoder.log_var.bias: 0.0007095358450897038\n",
      "Gradient for decoder.decoder.0.weight: 0.01018784660845995\n",
      "Gradient for decoder.decoder.0.bias: 9.128486855303208e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0004885452217422426\n",
      "Gradient for decoder.decoder.1.bias: 0.000457000540336594\n",
      "Gradient for decoder.decoder.3.weight: 0.009225613437592983\n",
      "Gradient for decoder.decoder.3.bias: 9.690554608754454e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0006108413799665868\n",
      "Gradient for decoder.decoder.4.bias: 0.0007471059798263013\n",
      "Gradient for decoder.decoder.6.weight: 0.001058067544363439\n",
      "Gradient for decoder.decoder.6.bias: 8.757176692597568e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.0037597983609884977\n",
      "Gradient for encoder.encoder.0.bias: 5.941012438948068e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.0003125237999483943\n",
      "Gradient for encoder.encoder.1.bias: 0.0002749735431279987\n",
      "Gradient for encoder.encoder.3.weight: 0.006957004778087139\n",
      "Gradient for encoder.encoder.3.bias: 7.976158622469143e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.002114709233865142\n",
      "Gradient for encoder.encoder.4.bias: 0.0015787524171173573\n",
      "Gradient for encoder.mean.weight: 0.029486140236258507\n",
      "Gradient for encoder.mean.bias: 0.0011009863810613751\n",
      "Gradient for encoder.log_var.weight: 0.016734739765524864\n",
      "Gradient for encoder.log_var.bias: 0.0007067063124850392\n",
      "Gradient for decoder.decoder.0.weight: 0.011855066753923893\n",
      "Gradient for decoder.decoder.0.bias: 9.267060729900578e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005650843377225101\n",
      "Gradient for decoder.decoder.1.bias: 0.0004977656062692404\n",
      "Gradient for decoder.decoder.3.weight: 0.010748160071671009\n",
      "Gradient for decoder.decoder.3.bias: 9.231462122505363e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0004085376567672938\n",
      "Gradient for decoder.decoder.4.bias: 0.00035580864641815424\n",
      "Gradient for decoder.decoder.6.weight: 0.0008678538724780083\n",
      "Gradient for decoder.decoder.6.bias: 4.3595489842118695e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.0061204941011965275\n",
      "Gradient for encoder.encoder.0.bias: 8.569016156367848e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.0003394830855540931\n",
      "Gradient for encoder.encoder.1.bias: 0.00032052950700744987\n",
      "Gradient for encoder.encoder.3.weight: 0.007136626169085503\n",
      "Gradient for encoder.encoder.3.bias: 8.32117777460617e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.0019049764377996325\n",
      "Gradient for encoder.encoder.4.bias: 0.001632014405913651\n",
      "Gradient for encoder.mean.weight: 0.02640102617442608\n",
      "Gradient for encoder.mean.bias: 0.0012408667244017124\n",
      "Gradient for encoder.log_var.weight: 0.017210565507411957\n",
      "Gradient for encoder.log_var.bias: 0.0008099668193608522\n",
      "Gradient for decoder.decoder.0.weight: 0.010990153066813946\n",
      "Gradient for decoder.decoder.0.bias: 9.881649665199888e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005130373174324632\n",
      "Gradient for decoder.decoder.1.bias: 0.0004618797393050045\n",
      "Gradient for decoder.decoder.3.weight: 0.009938058443367481\n",
      "Gradient for decoder.decoder.3.bias: 8.069891976880683e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00036278445622883737\n",
      "Gradient for decoder.decoder.4.bias: 0.0003522994229570031\n",
      "Gradient for decoder.decoder.6.weight: 0.0008733319118618965\n",
      "Gradient for decoder.decoder.6.bias: 5.552416041609831e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.005070793908089399\n",
      "Gradient for encoder.encoder.0.bias: 7.805278992578657e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.0003388271725270897\n",
      "Gradient for encoder.encoder.1.bias: 0.0003418319975025952\n",
      "Gradient for encoder.encoder.3.weight: 0.007523427251726389\n",
      "Gradient for encoder.encoder.3.bias: 8.419122343727992e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.0019135340116918087\n",
      "Gradient for encoder.encoder.4.bias: 0.0017467737197875977\n",
      "Gradient for encoder.mean.weight: 0.028402553871273994\n",
      "Gradient for encoder.mean.bias: 0.0012796450173482299\n",
      "Gradient for encoder.log_var.weight: 0.017027372494339943\n",
      "Gradient for encoder.log_var.bias: 0.0008883612463250756\n",
      "Gradient for decoder.decoder.0.weight: 0.010623861104249954\n",
      "Gradient for decoder.decoder.0.bias: 9.168010101090474e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.00048481125850230455\n",
      "Gradient for decoder.decoder.1.bias: 0.00042195903370156884\n",
      "Gradient for decoder.decoder.3.weight: 0.009633461013436317\n",
      "Gradient for decoder.decoder.3.bias: 7.731708329128395e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00038334258715622127\n",
      "Gradient for decoder.decoder.4.bias: 0.000364511797670275\n",
      "Gradient for decoder.decoder.6.weight: 0.0008592713274993002\n",
      "Gradient for decoder.decoder.6.bias: 4.618712773662992e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training VAE Epoch:  44%|████▍     | 35/79 [00:00<00:00, 69.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient for encoder.encoder.0.weight: 0.005479680374264717\n",
      "Gradient for encoder.encoder.0.bias: 8.51048658628839e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.0002928834583144635\n",
      "Gradient for encoder.encoder.1.bias: 0.0002654809504747391\n",
      "Gradient for encoder.encoder.3.weight: 0.006644768174737692\n",
      "Gradient for encoder.encoder.3.bias: 9.744261647570696e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.0021672460716217756\n",
      "Gradient for encoder.encoder.4.bias: 0.001992714125663042\n",
      "Gradient for encoder.mean.weight: 0.03041270188987255\n",
      "Gradient for encoder.mean.bias: 0.0011682716431096196\n",
      "Gradient for encoder.log_var.weight: 0.016331687569618225\n",
      "Gradient for encoder.log_var.bias: 0.0008502425043843687\n",
      "Gradient for decoder.decoder.0.weight: 0.010078095830976963\n",
      "Gradient for decoder.decoder.0.bias: 9.510982973415238e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.00048219403834082186\n",
      "Gradient for decoder.decoder.1.bias: 0.0004116478667128831\n",
      "Gradient for decoder.decoder.3.weight: 0.009209276176989079\n",
      "Gradient for decoder.decoder.3.bias: 9.669520045774149e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0006200076313689351\n",
      "Gradient for decoder.decoder.4.bias: 0.0007362907053902745\n",
      "Gradient for decoder.decoder.6.weight: 0.0010198635281994939\n",
      "Gradient for decoder.decoder.6.bias: 7.763688336126506e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.007813909091055393\n",
      "Gradient for encoder.encoder.0.bias: 1.3684647165446151e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0004336131096351892\n",
      "Gradient for encoder.encoder.1.bias: 0.0004151008033659309\n",
      "Gradient for encoder.encoder.3.weight: 0.009229710325598717\n",
      "Gradient for encoder.encoder.3.bias: 1.0077977341538258e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0022062889765948057\n",
      "Gradient for encoder.encoder.4.bias: 0.0018144338391721249\n",
      "Gradient for encoder.mean.weight: 0.02983281947672367\n",
      "Gradient for encoder.mean.bias: 0.001229262095876038\n",
      "Gradient for encoder.log_var.weight: 0.0164214875549078\n",
      "Gradient for encoder.log_var.bias: 0.0008591219084337354\n",
      "Gradient for decoder.decoder.0.weight: 0.008714881725609303\n",
      "Gradient for decoder.decoder.0.bias: 7.482459790653095e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0004178185772616416\n",
      "Gradient for decoder.decoder.1.bias: 0.00038184053846634924\n",
      "Gradient for decoder.decoder.3.weight: 0.008076868019998074\n",
      "Gradient for decoder.decoder.3.bias: 9.101171205561087e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0006477285060100257\n",
      "Gradient for decoder.decoder.4.bias: 0.000797166139818728\n",
      "Gradient for decoder.decoder.6.weight: 0.0009323176927864552\n",
      "Gradient for decoder.decoder.6.bias: 6.775953806936741e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training VAE Epoch:  54%|█████▍    | 43/79 [00:00<00:00, 71.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient for encoder.encoder.0.weight: 0.0055201128125190735\n",
      "Gradient for encoder.encoder.0.bias: 9.642941826981666e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.00037837200216017663\n",
      "Gradient for encoder.encoder.1.bias: 0.0003477146674413234\n",
      "Gradient for encoder.encoder.3.weight: 0.008363845758140087\n",
      "Gradient for encoder.encoder.3.bias: 9.247552723579133e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.0018159993924200535\n",
      "Gradient for encoder.encoder.4.bias: 0.0014248350635170937\n",
      "Gradient for encoder.mean.weight: 0.026919687166810036\n",
      "Gradient for encoder.mean.bias: 0.001173286116681993\n",
      "Gradient for encoder.log_var.weight: 0.016009340062737465\n",
      "Gradient for encoder.log_var.bias: 0.000679344346281141\n",
      "Gradient for decoder.decoder.0.weight: 0.010739168152213097\n",
      "Gradient for decoder.decoder.0.bias: 8.708159193737686e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0004784341435879469\n",
      "Gradient for decoder.decoder.1.bias: 0.00043393069063313305\n",
      "Gradient for decoder.decoder.3.weight: 0.009622471407055855\n",
      "Gradient for decoder.decoder.3.bias: 8.319672728518412e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0005065925652161241\n",
      "Gradient for decoder.decoder.4.bias: 0.0005477193044498563\n",
      "Gradient for decoder.decoder.6.weight: 0.0009610138949938118\n",
      "Gradient for decoder.decoder.6.bias: 6.376001692842692e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.005916199646890163\n",
      "Gradient for encoder.encoder.0.bias: 8.9789434568055e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.0004940230282954872\n",
      "Gradient for encoder.encoder.1.bias: 0.0004164273850619793\n",
      "Gradient for encoder.encoder.3.weight: 0.011142858304083347\n",
      "Gradient for encoder.encoder.3.bias: 9.967606601213319e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.0027479722630232573\n",
      "Gradient for encoder.encoder.4.bias: 0.0019612794276326895\n",
      "Gradient for encoder.mean.weight: 0.03580707684159279\n",
      "Gradient for encoder.mean.bias: 0.0013038294855505228\n",
      "Gradient for encoder.log_var.weight: 0.019665969535708427\n",
      "Gradient for encoder.log_var.bias: 0.0008124313899315894\n",
      "Gradient for decoder.decoder.0.weight: 0.01031614188104868\n",
      "Gradient for decoder.decoder.0.bias: 8.329568285114775e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005099169793538749\n",
      "Gradient for decoder.decoder.1.bias: 0.0004160828539170325\n",
      "Gradient for decoder.decoder.3.weight: 0.009424101561307907\n",
      "Gradient for decoder.decoder.3.bias: 7.753058611781327e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00034484549541957676\n",
      "Gradient for decoder.decoder.4.bias: 0.0002880515530705452\n",
      "Gradient for decoder.decoder.6.weight: 0.0008816389017738402\n",
      "Gradient for decoder.decoder.6.bias: 5.107901961309835e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.004485968500375748\n",
      "Gradient for encoder.encoder.0.bias: 7.239593473318262e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.00034751140628941357\n",
      "Gradient for encoder.encoder.1.bias: 0.00035993510391563177\n",
      "Gradient for encoder.encoder.3.weight: 0.007434292696416378\n",
      "Gradient for encoder.encoder.3.bias: 9.157148650462688e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.0021064940374344587\n",
      "Gradient for encoder.encoder.4.bias: 0.0016985713737085462\n",
      "Gradient for encoder.mean.weight: 0.030903290957212448\n",
      "Gradient for encoder.mean.bias: 0.001159069244749844\n",
      "Gradient for encoder.log_var.weight: 0.01721208356320858\n",
      "Gradient for encoder.log_var.bias: 0.0008554300293326378\n",
      "Gradient for decoder.decoder.0.weight: 0.011965920217335224\n",
      "Gradient for decoder.decoder.0.bias: 1.0895274960009971e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0005604740581475198\n",
      "Gradient for decoder.decoder.1.bias: 0.0004888157709501684\n",
      "Gradient for decoder.decoder.3.weight: 0.010906982235610485\n",
      "Gradient for decoder.decoder.3.bias: 8.850927629699967e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.000419456249801442\n",
      "Gradient for decoder.decoder.4.bias: 0.0003882992023136467\n",
      "Gradient for decoder.decoder.6.weight: 0.0008803833043202758\n",
      "Gradient for decoder.decoder.6.bias: 5.384124960983172e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.00466578034684062\n",
      "Gradient for encoder.encoder.0.bias: 7.6096941248327e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.0004744078905787319\n",
      "Gradient for encoder.encoder.1.bias: 0.00034645447158254683\n",
      "Gradient for encoder.encoder.3.weight: 0.010313110426068306\n",
      "Gradient for encoder.encoder.3.bias: 8.479941054906348e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.0022788348142057657\n",
      "Gradient for encoder.encoder.4.bias: 0.0017907068831846118\n",
      "Gradient for encoder.mean.weight: 0.031581658869981766\n",
      "Gradient for encoder.mean.bias: 0.0011316884774714708\n",
      "Gradient for encoder.log_var.weight: 0.01734052039682865\n",
      "Gradient for encoder.log_var.bias: 0.0008287219097837806\n",
      "Gradient for decoder.decoder.0.weight: 0.013467836193740368\n",
      "Gradient for decoder.decoder.0.bias: 1.196476112630407e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0006372481002472341\n",
      "Gradient for decoder.decoder.1.bias: 0.000545383314602077\n",
      "Gradient for decoder.decoder.3.weight: 0.012177154421806335\n",
      "Gradient for decoder.decoder.3.bias: 1.0610350792417123e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0004368607187643647\n",
      "Gradient for decoder.decoder.4.bias: 0.00037444918416440487\n",
      "Gradient for decoder.decoder.6.weight: 0.0008900750544853508\n",
      "Gradient for decoder.decoder.6.bias: 4.612675547832623e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.005606353282928467\n",
      "Gradient for encoder.encoder.0.bias: 8.847412386048248e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.00045238807797431946\n",
      "Gradient for encoder.encoder.1.bias: 0.00034630586742423475\n",
      "Gradient for encoder.encoder.3.weight: 0.009551879949867725\n",
      "Gradient for encoder.encoder.3.bias: 1.0057276539354731e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0022685276344418526\n",
      "Gradient for encoder.encoder.4.bias: 0.0019986904226243496\n",
      "Gradient for encoder.mean.weight: 0.032774265855550766\n",
      "Gradient for encoder.mean.bias: 0.0015823349822312593\n",
      "Gradient for encoder.log_var.weight: 0.01997850090265274\n",
      "Gradient for encoder.log_var.bias: 0.0011563822627067566\n",
      "Gradient for decoder.decoder.0.weight: 0.01124107837677002\n",
      "Gradient for decoder.decoder.0.bias: 1.0621502982699482e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0005354832392185926\n",
      "Gradient for decoder.decoder.1.bias: 0.0004867062671110034\n",
      "Gradient for decoder.decoder.3.weight: 0.01002873107790947\n",
      "Gradient for decoder.decoder.3.bias: 8.636458909139222e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0004116004565730691\n",
      "Gradient for decoder.decoder.4.bias: 0.0004002947243861854\n",
      "Gradient for decoder.decoder.6.weight: 0.0009133570129051805\n",
      "Gradient for decoder.decoder.6.bias: 5.157546911505051e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.006943005137145519\n",
      "Gradient for encoder.encoder.0.bias: 9.860899423397296e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.00044040021020919085\n",
      "Gradient for encoder.encoder.1.bias: 0.00037002837052568793\n",
      "Gradient for encoder.encoder.3.weight: 0.010030546225607395\n",
      "Gradient for encoder.encoder.3.bias: 1.0483775653158389e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0023692951072007418\n",
      "Gradient for encoder.encoder.4.bias: 0.002037960570305586\n",
      "Gradient for encoder.mean.weight: 0.03575710952281952\n",
      "Gradient for encoder.mean.bias: 0.0014230010565370321\n",
      "Gradient for encoder.log_var.weight: 0.018731463700532913\n",
      "Gradient for encoder.log_var.bias: 0.0009279905934818089\n",
      "Gradient for decoder.decoder.0.weight: 0.01147552765905857\n",
      "Gradient for decoder.decoder.0.bias: 1.0137213984906523e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0005553786759264767\n",
      "Gradient for decoder.decoder.1.bias: 0.00045154118561185896\n",
      "Gradient for decoder.decoder.3.weight: 0.010630281642079353\n",
      "Gradient for decoder.decoder.3.bias: 9.603644962608016e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0006145915831439197\n",
      "Gradient for decoder.decoder.4.bias: 0.000634338881354779\n",
      "Gradient for decoder.decoder.6.weight: 0.001091275829821825\n",
      "Gradient for decoder.decoder.6.bias: 7.443426147801802e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.003909002989530563\n",
      "Gradient for encoder.encoder.0.bias: 6.7037326210994674e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.0003479952283669263\n",
      "Gradient for encoder.encoder.1.bias: 0.0003224650281481445\n",
      "Gradient for encoder.encoder.3.weight: 0.00775859784334898\n",
      "Gradient for encoder.encoder.3.bias: 9.156040509106234e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.002014400903135538\n",
      "Gradient for encoder.encoder.4.bias: 0.001518086064606905\n",
      "Gradient for encoder.mean.weight: 0.028204703703522682\n",
      "Gradient for encoder.mean.bias: 0.0009797759121283889\n",
      "Gradient for encoder.log_var.weight: 0.01656307466328144\n",
      "Gradient for encoder.log_var.bias: 0.0007596940267831087\n",
      "Gradient for decoder.decoder.0.weight: 0.011648108251392841\n",
      "Gradient for decoder.decoder.0.bias: 1.0353556900710714e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0005866724532097578\n",
      "Gradient for decoder.decoder.1.bias: 0.0005087036988697946\n",
      "Gradient for decoder.decoder.3.weight: 0.010588683187961578\n",
      "Gradient for decoder.decoder.3.bias: 8.861453237862804e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0003968304372392595\n",
      "Gradient for decoder.decoder.4.bias: 0.0003344222204759717\n",
      "Gradient for decoder.decoder.6.weight: 0.0008412371971644461\n",
      "Gradient for decoder.decoder.6.bias: 4.298674684832804e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.003757077967748046\n",
      "Gradient for encoder.encoder.0.bias: 6.310291698896631e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.00043933934648521245\n",
      "Gradient for encoder.encoder.1.bias: 0.00043553492287173867\n",
      "Gradient for encoder.encoder.3.weight: 0.009861570782959461\n",
      "Gradient for encoder.encoder.3.bias: 8.845473659091496e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.0026267897337675095\n",
      "Gradient for encoder.encoder.4.bias: 0.0019220758695155382\n",
      "Gradient for encoder.mean.weight: 0.038223981857299805\n",
      "Gradient for encoder.mean.bias: 0.0014107817551121116\n",
      "Gradient for encoder.log_var.weight: 0.02349328249692917\n",
      "Gradient for encoder.log_var.bias: 0.001052862498909235\n",
      "Gradient for decoder.decoder.0.weight: 0.013848944567143917\n",
      "Gradient for decoder.decoder.0.bias: 1.112621314525164e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0006686574197374284\n",
      "Gradient for decoder.decoder.1.bias: 0.0005826960550621152\n",
      "Gradient for decoder.decoder.3.weight: 0.012754942290484905\n",
      "Gradient for decoder.decoder.3.bias: 1.0071601885819348e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.00047373006236739457\n",
      "Gradient for decoder.decoder.4.bias: 0.00043978073517791927\n",
      "Gradient for decoder.decoder.6.weight: 0.0008714026771485806\n",
      "Gradient for decoder.decoder.6.bias: 4.060259379912168e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.0044440608471632\n",
      "Gradient for encoder.encoder.0.bias: 7.2240113196953004e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.0004198924289084971\n",
      "Gradient for encoder.encoder.1.bias: 0.00036945875035598874\n",
      "Gradient for encoder.encoder.3.weight: 0.009271041490137577\n",
      "Gradient for encoder.encoder.3.bias: 8.300415910156289e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.002359043573960662\n",
      "Gradient for encoder.encoder.4.bias: 0.001645440235733986\n",
      "Gradient for encoder.mean.weight: 0.03434068337082863\n",
      "Gradient for encoder.mean.bias: 0.0011752836871892214\n",
      "Gradient for encoder.log_var.weight: 0.019458994269371033\n",
      "Gradient for encoder.log_var.bias: 0.0008674775599502027\n",
      "Gradient for decoder.decoder.0.weight: 0.011930477805435658\n",
      "Gradient for decoder.decoder.0.bias: 1.0270647526899879e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0006000896682962775\n",
      "Gradient for decoder.decoder.1.bias: 0.0005036069778725505\n",
      "Gradient for decoder.decoder.3.weight: 0.011332252062857151\n",
      "Gradient for decoder.decoder.3.bias: 8.990192618130166e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0004798832815140486\n",
      "Gradient for decoder.decoder.4.bias: 0.0004558033251669258\n",
      "Gradient for decoder.decoder.6.weight: 0.0010572094470262527\n",
      "Gradient for decoder.decoder.6.bias: 8.095286466414109e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.005000769626349211\n",
      "Gradient for encoder.encoder.0.bias: 8.470232328028349e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.0005273633287288249\n",
      "Gradient for encoder.encoder.1.bias: 0.0004804565105587244\n",
      "Gradient for encoder.encoder.3.weight: 0.011343689635396004\n",
      "Gradient for encoder.encoder.3.bias: 9.162905156845369e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.002764817327260971\n",
      "Gradient for encoder.encoder.4.bias: 0.0017693261615931988\n",
      "Gradient for encoder.mean.weight: 0.04000948742032051\n",
      "Gradient for encoder.mean.bias: 0.0012873554369434714\n",
      "Gradient for encoder.log_var.weight: 0.0205428134649992\n",
      "Gradient for encoder.log_var.bias: 0.0008069311152212322\n",
      "Gradient for decoder.decoder.0.weight: 0.011811286211013794\n",
      "Gradient for decoder.decoder.0.bias: 1.0521530868778939e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0005364016979001462\n",
      "Gradient for decoder.decoder.1.bias: 0.00046784066944383085\n",
      "Gradient for decoder.decoder.3.weight: 0.01069281343370676\n",
      "Gradient for decoder.decoder.3.bias: 1.003976415892005e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0005396929336711764\n",
      "Gradient for decoder.decoder.4.bias: 0.0005590312066487968\n",
      "Gradient for decoder.decoder.6.weight: 0.0009340474498458207\n",
      "Gradient for decoder.decoder.6.bias: 5.8718233049148694e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.0062695774249732494\n",
      "Gradient for encoder.encoder.0.bias: 9.92325058929433e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.00037652862374670804\n",
      "Gradient for encoder.encoder.1.bias: 0.0004137118230573833\n",
      "Gradient for encoder.encoder.3.weight: 0.008350291289389133\n",
      "Gradient for encoder.encoder.3.bias: 8.727958633603095e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.0020912119653075933\n",
      "Gradient for encoder.encoder.4.bias: 0.0015958922449499369\n",
      "Gradient for encoder.mean.weight: 0.03273222595453262\n",
      "Gradient for encoder.mean.bias: 0.001387125812470913\n",
      "Gradient for encoder.log_var.weight: 0.017459319904446602\n",
      "Gradient for encoder.log_var.bias: 0.0009355549118481576\n",
      "Gradient for decoder.decoder.0.weight: 0.009863427840173244\n",
      "Gradient for decoder.decoder.0.bias: 8.306322990536685e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005044107674621046\n",
      "Gradient for decoder.decoder.1.bias: 0.00039828248554840684\n",
      "Gradient for decoder.decoder.3.weight: 0.00918753631412983\n",
      "Gradient for decoder.decoder.3.bias: 8.781844695882057e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00047522070235572755\n",
      "Gradient for decoder.decoder.4.bias: 0.0005331073771230876\n",
      "Gradient for decoder.decoder.6.weight: 0.000889016839209944\n",
      "Gradient for decoder.decoder.6.bias: 5.604988109553233e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.005797924939543009\n",
      "Gradient for encoder.encoder.0.bias: 1.0739900288547766e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0004680566198658198\n",
      "Gradient for encoder.encoder.1.bias: 0.0003894995606970042\n",
      "Gradient for encoder.encoder.3.weight: 0.01001232024282217\n",
      "Gradient for encoder.encoder.3.bias: 8.65236771119271e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.0021662453655153513\n",
      "Gradient for encoder.encoder.4.bias: 0.0015705376863479614\n",
      "Gradient for encoder.mean.weight: 0.031049128621816635\n",
      "Gradient for encoder.mean.bias: 0.0012007709592580795\n",
      "Gradient for encoder.log_var.weight: 0.016798393800854683\n",
      "Gradient for encoder.log_var.bias: 0.000736067071557045\n",
      "Gradient for decoder.decoder.0.weight: 0.009488122537732124\n",
      "Gradient for decoder.decoder.0.bias: 8.41409303342644e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0004518234636634588\n",
      "Gradient for decoder.decoder.1.bias: 0.00038903389940969646\n",
      "Gradient for decoder.decoder.3.weight: 0.008949881419539452\n",
      "Gradient for decoder.decoder.3.bias: 9.588119881387414e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0006507462239824235\n",
      "Gradient for decoder.decoder.4.bias: 0.0008216678979806602\n",
      "Gradient for decoder.decoder.6.weight: 0.0009181718342006207\n",
      "Gradient for decoder.decoder.6.bias: 6.475167901953682e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.0046142092905938625\n",
      "Gradient for encoder.encoder.0.bias: 7.50816422923073e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.00044349866220727563\n",
      "Gradient for encoder.encoder.1.bias: 0.0003161838394589722\n",
      "Gradient for encoder.encoder.3.weight: 0.009331198409199715\n",
      "Gradient for encoder.encoder.3.bias: 9.872549999734304e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.002415820024907589\n",
      "Gradient for encoder.encoder.4.bias: 0.0018650850979611278\n",
      "Gradient for encoder.mean.weight: 0.03335905447602272\n",
      "Gradient for encoder.mean.bias: 0.0013514887541532516\n",
      "Gradient for encoder.log_var.weight: 0.021341385319828987\n",
      "Gradient for encoder.log_var.bias: 0.0009646721300669014\n",
      "Gradient for decoder.decoder.0.weight: 0.012696156278252602\n",
      "Gradient for decoder.decoder.0.bias: 1.1328859378378908e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0005752922734245658\n",
      "Gradient for decoder.decoder.1.bias: 0.0004932261072099209\n",
      "Gradient for decoder.decoder.3.weight: 0.011723492294549942\n",
      "Gradient for decoder.decoder.3.bias: 9.99183166761064e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0004187963786534965\n",
      "Gradient for decoder.decoder.4.bias: 0.00038647535257041454\n",
      "Gradient for decoder.decoder.6.weight: 0.0009075795533135533\n",
      "Gradient for decoder.decoder.6.bias: 5.3217358072288334e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.00634397566318512\n",
      "Gradient for encoder.encoder.0.bias: 8.358604607072717e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.00040745464502833784\n",
      "Gradient for encoder.encoder.1.bias: 0.00038809163379482925\n",
      "Gradient for encoder.encoder.3.weight: 0.009195432998239994\n",
      "Gradient for encoder.encoder.3.bias: 8.90374787787529e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.0021095385309308767\n",
      "Gradient for encoder.encoder.4.bias: 0.0014267144724726677\n",
      "Gradient for encoder.mean.weight: 0.027392888441681862\n",
      "Gradient for encoder.mean.bias: 0.0009257748606614769\n",
      "Gradient for encoder.log_var.weight: 0.019324949011206627\n",
      "Gradient for encoder.log_var.bias: 0.000772300292737782\n",
      "Gradient for decoder.decoder.0.weight: 0.012057601474225521\n",
      "Gradient for decoder.decoder.0.bias: 1.0186899240816061e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.000561525288503617\n",
      "Gradient for decoder.decoder.1.bias: 0.0004958613426424563\n",
      "Gradient for decoder.decoder.3.weight: 0.010942865163087845\n",
      "Gradient for decoder.decoder.3.bias: 8.721093985863959e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0003938597801607102\n",
      "Gradient for decoder.decoder.4.bias: 0.00036906698369421065\n",
      "Gradient for decoder.decoder.6.weight: 0.0008863200782798231\n",
      "Gradient for decoder.decoder.6.bias: 4.177010487182997e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.005901597905904055\n",
      "Gradient for encoder.encoder.0.bias: 8.857675877493865e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.00038757463335059583\n",
      "Gradient for encoder.encoder.1.bias: 0.0003505426284391433\n",
      "Gradient for encoder.encoder.3.weight: 0.008137215860188007\n",
      "Gradient for encoder.encoder.3.bias: 1.013704814534222e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0022795386612415314\n",
      "Gradient for encoder.encoder.4.bias: 0.002090458758175373\n",
      "Gradient for encoder.mean.weight: 0.031519751995801926\n",
      "Gradient for encoder.mean.bias: 0.0017451425082981586\n",
      "Gradient for encoder.log_var.weight: 0.018491903319954872\n",
      "Gradient for encoder.log_var.bias: 0.0010256095556542277\n",
      "Gradient for decoder.decoder.0.weight: 0.011031504720449448\n",
      "Gradient for decoder.decoder.0.bias: 9.650655274917597e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005631153471767902\n",
      "Gradient for decoder.decoder.1.bias: 0.000456470821518451\n",
      "Gradient for decoder.decoder.3.weight: 0.010457055643200874\n",
      "Gradient for decoder.decoder.3.bias: 8.687563862741499e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00044246308971196413\n",
      "Gradient for decoder.decoder.4.bias: 0.00042588848737068474\n",
      "Gradient for decoder.decoder.6.weight: 0.0008846282144077122\n",
      "Gradient for decoder.decoder.6.bias: 4.497140980674885e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.006174206733703613\n",
      "Gradient for encoder.encoder.0.bias: 9.989131917464977e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.0004556766652967781\n",
      "Gradient for encoder.encoder.1.bias: 0.00035539979580789804\n",
      "Gradient for encoder.encoder.3.weight: 0.009875607676804066\n",
      "Gradient for encoder.encoder.3.bias: 1.0064664379694221e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.002473280532285571\n",
      "Gradient for encoder.encoder.4.bias: 0.002142522716894746\n",
      "Gradient for encoder.mean.weight: 0.03593815863132477\n",
      "Gradient for encoder.mean.bias: 0.0018395499791949987\n",
      "Gradient for encoder.log_var.weight: 0.02387254685163498\n",
      "Gradient for encoder.log_var.bias: 0.0012721113162115216\n",
      "Gradient for decoder.decoder.0.weight: 0.01144665852189064\n",
      "Gradient for decoder.decoder.0.bias: 9.272047019059926e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005291138077154756\n",
      "Gradient for decoder.decoder.1.bias: 0.00045992026571184397\n",
      "Gradient for decoder.decoder.3.weight: 0.010841261595487595\n",
      "Gradient for decoder.decoder.3.bias: 8.592002803675669e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0004100121441297233\n",
      "Gradient for decoder.decoder.4.bias: 0.00042283179936930537\n",
      "Gradient for decoder.decoder.6.weight: 0.0009019027929753065\n",
      "Gradient for decoder.decoder.6.bias: 5.1301853090990335e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training VAE Epoch:  76%|███████▌  | 60/79 [00:00<00:00, 76.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient for encoder.encoder.0.weight: 0.00496462918817997\n",
      "Gradient for encoder.encoder.0.bias: 7.038183837820844e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.00043211597949266434\n",
      "Gradient for encoder.encoder.1.bias: 0.0003470029041636735\n",
      "Gradient for encoder.encoder.3.weight: 0.009344748221337795\n",
      "Gradient for encoder.encoder.3.bias: 9.167652054165032e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.0023624615278095007\n",
      "Gradient for encoder.encoder.4.bias: 0.0018116116989403963\n",
      "Gradient for encoder.mean.weight: 0.03332739323377609\n",
      "Gradient for encoder.mean.bias: 0.001539862249046564\n",
      "Gradient for encoder.log_var.weight: 0.017814895138144493\n",
      "Gradient for encoder.log_var.bias: 0.0008849845035001636\n",
      "Gradient for decoder.decoder.0.weight: 0.012227492406964302\n",
      "Gradient for decoder.decoder.0.bias: 9.89502715875723e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0006101769395172596\n",
      "Gradient for decoder.decoder.1.bias: 0.0004863795475102961\n",
      "Gradient for decoder.decoder.3.weight: 0.011639467440545559\n",
      "Gradient for decoder.decoder.3.bias: 9.794681732344657e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0005242577171884477\n",
      "Gradient for decoder.decoder.4.bias: 0.0005090947961434722\n",
      "Gradient for decoder.decoder.6.weight: 0.0011054242495447397\n",
      "Gradient for decoder.decoder.6.bias: 7.583366095786914e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.006592253688722849\n",
      "Gradient for encoder.encoder.0.bias: 8.812065660501744e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.00047431676648557186\n",
      "Gradient for encoder.encoder.1.bias: 0.0004323882458265871\n",
      "Gradient for encoder.encoder.3.weight: 0.010351328179240227\n",
      "Gradient for encoder.encoder.3.bias: 9.966296538044261e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.0032024644315242767\n",
      "Gradient for encoder.encoder.4.bias: 0.0022314083762466908\n",
      "Gradient for encoder.mean.weight: 0.04148072376847267\n",
      "Gradient for encoder.mean.bias: 0.001683156588114798\n",
      "Gradient for encoder.log_var.weight: 0.02327750250697136\n",
      "Gradient for encoder.log_var.bias: 0.0010752483503893018\n",
      "Gradient for decoder.decoder.0.weight: 0.010965246707201004\n",
      "Gradient for decoder.decoder.0.bias: 9.565299941005634e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005378470523282886\n",
      "Gradient for decoder.decoder.1.bias: 0.00045078605762682855\n",
      "Gradient for decoder.decoder.3.weight: 0.010029689408838749\n",
      "Gradient for decoder.decoder.3.bias: 8.06324451652074e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00034836697159335017\n",
      "Gradient for decoder.decoder.4.bias: 0.00028940365882590413\n",
      "Gradient for decoder.decoder.6.weight: 0.0008839487563818693\n",
      "Gradient for decoder.decoder.6.bias: 4.7345340135507286e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.0069584003649652\n",
      "Gradient for encoder.encoder.0.bias: 1.0866177749258021e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.00047113894834183156\n",
      "Gradient for encoder.encoder.1.bias: 0.00043986737728118896\n",
      "Gradient for encoder.encoder.3.weight: 0.00984543189406395\n",
      "Gradient for encoder.encoder.3.bias: 9.764805630751994e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.002190978266298771\n",
      "Gradient for encoder.encoder.4.bias: 0.0019612074829638004\n",
      "Gradient for encoder.mean.weight: 0.030612517148256302\n",
      "Gradient for encoder.mean.bias: 0.0015706333797425032\n",
      "Gradient for encoder.log_var.weight: 0.01961951144039631\n",
      "Gradient for encoder.log_var.bias: 0.001140356413088739\n",
      "Gradient for decoder.decoder.0.weight: 0.01152309961616993\n",
      "Gradient for decoder.decoder.0.bias: 9.950319734830515e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005433443584479392\n",
      "Gradient for decoder.decoder.1.bias: 0.0005009318701922894\n",
      "Gradient for decoder.decoder.3.weight: 0.010408435948193073\n",
      "Gradient for decoder.decoder.3.bias: 8.489545177958746e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00038827882963232696\n",
      "Gradient for decoder.decoder.4.bias: 0.00033504748716950417\n",
      "Gradient for decoder.decoder.6.weight: 0.0008368887356482446\n",
      "Gradient for decoder.decoder.6.bias: 3.8469948776764795e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.0051264469511806965\n",
      "Gradient for encoder.encoder.0.bias: 7.88152789560348e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.0003810136404354125\n",
      "Gradient for encoder.encoder.1.bias: 0.00030251601128838956\n",
      "Gradient for encoder.encoder.3.weight: 0.00852742325514555\n",
      "Gradient for encoder.encoder.3.bias: 8.484605379388555e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.0021868275944143534\n",
      "Gradient for encoder.encoder.4.bias: 0.0017029712907969952\n",
      "Gradient for encoder.mean.weight: 0.029589982703328133\n",
      "Gradient for encoder.mean.bias: 0.001324114273302257\n",
      "Gradient for encoder.log_var.weight: 0.019280478358268738\n",
      "Gradient for encoder.log_var.bias: 0.0008754360023885965\n",
      "Gradient for decoder.decoder.0.weight: 0.012072271667420864\n",
      "Gradient for decoder.decoder.0.bias: 9.992975891215394e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005454458296298981\n",
      "Gradient for decoder.decoder.1.bias: 0.0004713624657597393\n",
      "Gradient for decoder.decoder.3.weight: 0.010765579529106617\n",
      "Gradient for decoder.decoder.3.bias: 8.374741178318601e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00044319769949652255\n",
      "Gradient for decoder.decoder.4.bias: 0.00043467088835313916\n",
      "Gradient for decoder.decoder.6.weight: 0.0009228340350091457\n",
      "Gradient for decoder.decoder.6.bias: 5.352966763894074e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.00333959748968482\n",
      "Gradient for encoder.encoder.0.bias: 5.1941268126853846e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.0002763943048194051\n",
      "Gradient for encoder.encoder.1.bias: 0.00036164381890557706\n",
      "Gradient for encoder.encoder.3.weight: 0.006337717641144991\n",
      "Gradient for encoder.encoder.3.bias: 7.513730609920444e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.002701201941817999\n",
      "Gradient for encoder.encoder.4.bias: 0.0016916454769670963\n",
      "Gradient for encoder.mean.weight: 0.0394156351685524\n",
      "Gradient for encoder.mean.bias: 0.001178934471681714\n",
      "Gradient for encoder.log_var.weight: 0.022831536829471588\n",
      "Gradient for encoder.log_var.bias: 0.0008877667714841664\n",
      "Gradient for decoder.decoder.0.weight: 0.013510630466043949\n",
      "Gradient for decoder.decoder.0.bias: 1.177088704285012e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0007079492788761854\n",
      "Gradient for decoder.decoder.1.bias: 0.0005998688866384327\n",
      "Gradient for decoder.decoder.3.weight: 0.012997624464333057\n",
      "Gradient for decoder.decoder.3.bias: 1.051235071214407e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0004898343468084931\n",
      "Gradient for decoder.decoder.4.bias: 0.0004531200975179672\n",
      "Gradient for decoder.decoder.6.weight: 0.0008302102796733379\n",
      "Gradient for decoder.decoder.6.bias: 3.38790487148799e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.008355929516255856\n",
      "Gradient for encoder.encoder.0.bias: 1.0751129153607764e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0005024320562370121\n",
      "Gradient for encoder.encoder.1.bias: 0.0003561113844625652\n",
      "Gradient for encoder.encoder.3.weight: 0.010634420439600945\n",
      "Gradient for encoder.encoder.3.bias: 9.484872609544226e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.002395568648353219\n",
      "Gradient for encoder.encoder.4.bias: 0.001795893651433289\n",
      "Gradient for encoder.mean.weight: 0.03656941279768944\n",
      "Gradient for encoder.mean.bias: 0.001453499891795218\n",
      "Gradient for encoder.log_var.weight: 0.020122528076171875\n",
      "Gradient for encoder.log_var.bias: 0.0008561124559491873\n",
      "Gradient for decoder.decoder.0.weight: 0.01033010147511959\n",
      "Gradient for decoder.decoder.0.bias: 8.659362810137239e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0004898746847175062\n",
      "Gradient for decoder.decoder.1.bias: 0.0004335380217526108\n",
      "Gradient for decoder.decoder.3.weight: 0.009459594264626503\n",
      "Gradient for decoder.decoder.3.bias: 7.748351960046307e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00036436834488995373\n",
      "Gradient for decoder.decoder.4.bias: 0.0003095503489021212\n",
      "Gradient for decoder.decoder.6.weight: 0.0008161430596373975\n",
      "Gradient for decoder.decoder.6.bias: 3.220689177396707e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.005601178854703903\n",
      "Gradient for encoder.encoder.0.bias: 8.45118246217691e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.00037228205474093556\n",
      "Gradient for encoder.encoder.1.bias: 0.0003162130597047508\n",
      "Gradient for encoder.encoder.3.weight: 0.008429151028394699\n",
      "Gradient for encoder.encoder.3.bias: 8.50697429166658e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.002278805710375309\n",
      "Gradient for encoder.encoder.4.bias: 0.001754121738485992\n",
      "Gradient for encoder.mean.weight: 0.03459262102842331\n",
      "Gradient for encoder.mean.bias: 0.0012772612972185016\n",
      "Gradient for encoder.log_var.weight: 0.021199757233262062\n",
      "Gradient for encoder.log_var.bias: 0.0008488570456393063\n",
      "Gradient for decoder.decoder.0.weight: 0.010755765251815319\n",
      "Gradient for decoder.decoder.0.bias: 9.424727664963939e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.000509640434756875\n",
      "Gradient for decoder.decoder.1.bias: 0.0004385231586638838\n",
      "Gradient for decoder.decoder.3.weight: 0.010073288343846798\n",
      "Gradient for decoder.decoder.3.bias: 8.3468752742899e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00037676095962524414\n",
      "Gradient for decoder.decoder.4.bias: 0.00032733133411966264\n",
      "Gradient for decoder.decoder.6.weight: 0.0008498121169395745\n",
      "Gradient for decoder.decoder.6.bias: 3.884673787979409e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.005084461998194456\n",
      "Gradient for encoder.encoder.0.bias: 7.923810045606938e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.0004077169578522444\n",
      "Gradient for encoder.encoder.1.bias: 0.0003515117568895221\n",
      "Gradient for encoder.encoder.3.weight: 0.009141488000750542\n",
      "Gradient for encoder.encoder.3.bias: 9.83361586603948e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.0024804403074085712\n",
      "Gradient for encoder.encoder.4.bias: 0.0019147488055750728\n",
      "Gradient for encoder.mean.weight: 0.03299117833375931\n",
      "Gradient for encoder.mean.bias: 0.001573332236148417\n",
      "Gradient for encoder.log_var.weight: 0.021093249320983887\n",
      "Gradient for encoder.log_var.bias: 0.001153147197328508\n",
      "Gradient for decoder.decoder.0.weight: 0.012028161436319351\n",
      "Gradient for decoder.decoder.0.bias: 9.925511801345266e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.00061087089125067\n",
      "Gradient for decoder.decoder.1.bias: 0.0004847869277000427\n",
      "Gradient for decoder.decoder.3.weight: 0.011534048244357109\n",
      "Gradient for decoder.decoder.3.bias: 8.820853075741653e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00041906675323843956\n",
      "Gradient for decoder.decoder.4.bias: 0.0003832045185845345\n",
      "Gradient for decoder.decoder.6.weight: 0.0008475504582747817\n",
      "Gradient for decoder.decoder.6.bias: 3.694438419188373e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.006223596632480621\n",
      "Gradient for encoder.encoder.0.bias: 9.755966867697197e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.0004698120173998177\n",
      "Gradient for encoder.encoder.1.bias: 0.00039561657467857003\n",
      "Gradient for encoder.encoder.3.weight: 0.010580725967884064\n",
      "Gradient for encoder.encoder.3.bias: 9.329160360893596e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.0027147005312144756\n",
      "Gradient for encoder.encoder.4.bias: 0.0020314815919846296\n",
      "Gradient for encoder.mean.weight: 0.03750823810696602\n",
      "Gradient for encoder.mean.bias: 0.001494278316386044\n",
      "Gradient for encoder.log_var.weight: 0.021314147859811783\n",
      "Gradient for encoder.log_var.bias: 0.0011128742480650544\n",
      "Gradient for decoder.decoder.0.weight: 0.010184163227677345\n",
      "Gradient for decoder.decoder.0.bias: 8.006863227993932e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0004825750074815005\n",
      "Gradient for decoder.decoder.1.bias: 0.00043086192454211414\n",
      "Gradient for decoder.decoder.3.weight: 0.009591683745384216\n",
      "Gradient for decoder.decoder.3.bias: 7.503971055644598e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.000403895101044327\n",
      "Gradient for decoder.decoder.4.bias: 0.0003597712202463299\n",
      "Gradient for decoder.decoder.6.weight: 0.000953926588408649\n",
      "Gradient for decoder.decoder.6.bias: 6.289628800004721e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.006010101176798344\n",
      "Gradient for encoder.encoder.0.bias: 9.059718253379145e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.00037789257476106286\n",
      "Gradient for encoder.encoder.1.bias: 0.0004055501485709101\n",
      "Gradient for encoder.encoder.3.weight: 0.008287358097732067\n",
      "Gradient for encoder.encoder.3.bias: 8.848721755327915e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.0023432676680386066\n",
      "Gradient for encoder.encoder.4.bias: 0.0018685716204345226\n",
      "Gradient for encoder.mean.weight: 0.03406252712011337\n",
      "Gradient for encoder.mean.bias: 0.0014627753989771008\n",
      "Gradient for encoder.log_var.weight: 0.01934201270341873\n",
      "Gradient for encoder.log_var.bias: 0.0008553759544156492\n",
      "Gradient for decoder.decoder.0.weight: 0.011056886985898018\n",
      "Gradient for decoder.decoder.0.bias: 9.313091964280318e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005497458041645586\n",
      "Gradient for decoder.decoder.1.bias: 0.0004503964737523347\n",
      "Gradient for decoder.decoder.3.weight: 0.010193061083555222\n",
      "Gradient for decoder.decoder.3.bias: 8.321744682238119e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00044747302308678627\n",
      "Gradient for decoder.decoder.4.bias: 0.0005035133217461407\n",
      "Gradient for decoder.decoder.6.weight: 0.0009079576702788472\n",
      "Gradient for decoder.decoder.6.bias: 6.49035137030296e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.005524979438632727\n",
      "Gradient for encoder.encoder.0.bias: 7.60499822838323e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.0003441705775912851\n",
      "Gradient for encoder.encoder.1.bias: 0.0003075922140851617\n",
      "Gradient for encoder.encoder.3.weight: 0.0076772733591496944\n",
      "Gradient for encoder.encoder.3.bias: 8.643013388320853e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.0021644928492605686\n",
      "Gradient for encoder.encoder.4.bias: 0.0016623688861727715\n",
      "Gradient for encoder.mean.weight: 0.032034676522016525\n",
      "Gradient for encoder.mean.bias: 0.0012419758131727576\n",
      "Gradient for encoder.log_var.weight: 0.018946774303913116\n",
      "Gradient for encoder.log_var.bias: 0.0009297827491536736\n",
      "Gradient for decoder.decoder.0.weight: 0.011563528329133987\n",
      "Gradient for decoder.decoder.0.bias: 1.0169286246419773e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0005789535352960229\n",
      "Gradient for decoder.decoder.1.bias: 0.0005014268099330366\n",
      "Gradient for decoder.decoder.3.weight: 0.010824733413755894\n",
      "Gradient for decoder.decoder.3.bias: 9.49864215060714e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00047456970787607133\n",
      "Gradient for decoder.decoder.4.bias: 0.00045995964319445193\n",
      "Gradient for decoder.decoder.6.weight: 0.0009918400319293141\n",
      "Gradient for decoder.decoder.6.bias: 6.0448888689279556e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.004159069154411554\n",
      "Gradient for encoder.encoder.0.bias: 6.3278848307091184e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.000399070733692497\n",
      "Gradient for encoder.encoder.1.bias: 0.0003338248061481863\n",
      "Gradient for encoder.encoder.3.weight: 0.008703060448169708\n",
      "Gradient for encoder.encoder.3.bias: 8.725277444998625e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.0020495792850852013\n",
      "Gradient for encoder.encoder.4.bias: 0.0014991415664553642\n",
      "Gradient for encoder.mean.weight: 0.031405191868543625\n",
      "Gradient for encoder.mean.bias: 0.001302073709666729\n",
      "Gradient for encoder.log_var.weight: 0.01909779943525791\n",
      "Gradient for encoder.log_var.bias: 0.0009279821533709764\n",
      "Gradient for decoder.decoder.0.weight: 0.013106628321111202\n",
      "Gradient for decoder.decoder.0.bias: 1.000774324522169e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0006529942038469017\n",
      "Gradient for decoder.decoder.1.bias: 0.0005159822758287191\n",
      "Gradient for decoder.decoder.3.weight: 0.011903478763997555\n",
      "Gradient for decoder.decoder.3.bias: 1.1152841150607884e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0006639276398345828\n",
      "Gradient for decoder.decoder.4.bias: 0.0007573853945359588\n",
      "Gradient for decoder.decoder.6.weight: 0.0010216707596555352\n",
      "Gradient for decoder.decoder.6.bias: 6.946940993657336e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.006475312169641256\n",
      "Gradient for encoder.encoder.0.bias: 8.861186090447504e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.0003382482100278139\n",
      "Gradient for encoder.encoder.1.bias: 0.0003424770256970078\n",
      "Gradient for encoder.encoder.3.weight: 0.007900874130427837\n",
      "Gradient for encoder.encoder.3.bias: 8.6853468861392e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.0018005137098953128\n",
      "Gradient for encoder.encoder.4.bias: 0.0015531188109889627\n",
      "Gradient for encoder.mean.weight: 0.026247523725032806\n",
      "Gradient for encoder.mean.bias: 0.0012580713955685496\n",
      "Gradient for encoder.log_var.weight: 0.01693902164697647\n",
      "Gradient for encoder.log_var.bias: 0.0008176082628779113\n",
      "Gradient for decoder.decoder.0.weight: 0.011322129517793655\n",
      "Gradient for decoder.decoder.0.bias: 9.596044792115066e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.000554795318748802\n",
      "Gradient for decoder.decoder.1.bias: 0.00045130556100048125\n",
      "Gradient for decoder.decoder.3.weight: 0.010309196077287197\n",
      "Gradient for decoder.decoder.3.bias: 1.1135583427579476e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.000593879958614707\n",
      "Gradient for decoder.decoder.4.bias: 0.0007383330375887454\n",
      "Gradient for decoder.decoder.6.weight: 0.0010830091778188944\n",
      "Gradient for decoder.decoder.6.bias: 9.184094960801303e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.006941234227269888\n",
      "Gradient for encoder.encoder.0.bias: 9.527993845293015e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.00044128080480732024\n",
      "Gradient for encoder.encoder.1.bias: 0.0004192504857201129\n",
      "Gradient for encoder.encoder.3.weight: 0.009708425961434841\n",
      "Gradient for encoder.encoder.3.bias: 9.182005156205264e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.002568555762991309\n",
      "Gradient for encoder.encoder.4.bias: 0.001783102285116911\n",
      "Gradient for encoder.mean.weight: 0.03450891003012657\n",
      "Gradient for encoder.mean.bias: 0.001191349234431982\n",
      "Gradient for encoder.log_var.weight: 0.020576748996973038\n",
      "Gradient for encoder.log_var.bias: 0.0009218687773682177\n",
      "Gradient for decoder.decoder.0.weight: 0.011106561869382858\n",
      "Gradient for decoder.decoder.0.bias: 8.854730837448699e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005727195530198514\n",
      "Gradient for decoder.decoder.1.bias: 0.00046682567335665226\n",
      "Gradient for decoder.decoder.3.weight: 0.010908587835729122\n",
      "Gradient for decoder.decoder.3.bias: 7.891279296678988e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0005231167888268828\n",
      "Gradient for decoder.decoder.4.bias: 0.0005464390269480646\n",
      "Gradient for decoder.decoder.6.weight: 0.0009373057982884347\n",
      "Gradient for decoder.decoder.6.bias: 5.326962855178863e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.00513075664639473\n",
      "Gradient for encoder.encoder.0.bias: 7.172801415322727e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.0003243417595513165\n",
      "Gradient for encoder.encoder.1.bias: 0.00036853604251518846\n",
      "Gradient for encoder.encoder.3.weight: 0.007298787124454975\n",
      "Gradient for encoder.encoder.3.bias: 7.259970402628824e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.002032594522461295\n",
      "Gradient for encoder.encoder.4.bias: 0.001422917121089995\n",
      "Gradient for encoder.mean.weight: 0.028489084914326668\n",
      "Gradient for encoder.mean.bias: 0.001086817472241819\n",
      "Gradient for encoder.log_var.weight: 0.018300900235772133\n",
      "Gradient for encoder.log_var.bias: 0.0008983400766737759\n",
      "Gradient for decoder.decoder.0.weight: 0.010699864476919174\n",
      "Gradient for decoder.decoder.0.bias: 9.718336552166917e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0004967061686329544\n",
      "Gradient for decoder.decoder.1.bias: 0.0004127026768401265\n",
      "Gradient for decoder.decoder.3.weight: 0.009930448606610298\n",
      "Gradient for decoder.decoder.3.bias: 8.79140371612408e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0004920827341265976\n",
      "Gradient for decoder.decoder.4.bias: 0.0004805446951650083\n",
      "Gradient for decoder.decoder.6.weight: 0.0008743156213313341\n",
      "Gradient for decoder.decoder.6.bias: 4.300122964195907e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.005018082447350025\n",
      "Gradient for encoder.encoder.0.bias: 7.367834641003324e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.0004146988794673234\n",
      "Gradient for encoder.encoder.1.bias: 0.00038582037086598575\n",
      "Gradient for encoder.encoder.3.weight: 0.009060128591954708\n",
      "Gradient for encoder.encoder.3.bias: 8.815195795541797e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.002179535571485758\n",
      "Gradient for encoder.encoder.4.bias: 0.0015299887163564563\n",
      "Gradient for encoder.mean.weight: 0.030471282079815865\n",
      "Gradient for encoder.mean.bias: 0.0011583364102989435\n",
      "Gradient for encoder.log_var.weight: 0.01866280660033226\n",
      "Gradient for encoder.log_var.bias: 0.0008381035295315087\n",
      "Gradient for decoder.decoder.0.weight: 0.012047071941196918\n",
      "Gradient for decoder.decoder.0.bias: 1.1085173751146371e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0006068705697543919\n",
      "Gradient for decoder.decoder.1.bias: 0.0004799663438461721\n",
      "Gradient for decoder.decoder.3.weight: 0.011385785415768623\n",
      "Gradient for decoder.decoder.3.bias: 1.0168110797792451e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0006337385857477784\n",
      "Gradient for decoder.decoder.4.bias: 0.0006728861480951309\n",
      "Gradient for decoder.decoder.6.weight: 0.0011041167890653014\n",
      "Gradient for decoder.decoder.6.bias: 7.653656211914495e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.007062212564051151\n",
      "Gradient for encoder.encoder.0.bias: 1.0568095010210499e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0004748030914925039\n",
      "Gradient for encoder.encoder.1.bias: 0.0004182671254966408\n",
      "Gradient for encoder.encoder.3.weight: 0.009745939634740353\n",
      "Gradient for encoder.encoder.3.bias: 1.0416301848836795e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.002449752064421773\n",
      "Gradient for encoder.encoder.4.bias: 0.002380711492151022\n",
      "Gradient for encoder.mean.weight: 0.03476053848862648\n",
      "Gradient for encoder.mean.bias: 0.002081573009490967\n",
      "Gradient for encoder.log_var.weight: 0.020052749663591385\n",
      "Gradient for encoder.log_var.bias: 0.001266520470380783\n",
      "Gradient for decoder.decoder.0.weight: 0.009983138181269169\n",
      "Gradient for decoder.decoder.0.bias: 9.129534628282698e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005125484894961119\n",
      "Gradient for decoder.decoder.1.bias: 0.0004239961854182184\n",
      "Gradient for decoder.decoder.3.weight: 0.009120910428464413\n",
      "Gradient for decoder.decoder.3.bias: 7.470257051833684e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00033548500505276024\n",
      "Gradient for decoder.decoder.4.bias: 0.00029999500839039683\n",
      "Gradient for decoder.decoder.6.weight: 0.0008265699143521488\n",
      "Gradient for decoder.decoder.6.bias: 4.5221324398880824e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient for encoder.encoder.0.weight: 0.004156279843300581\n",
      "Gradient for encoder.encoder.0.bias: 7.0771804215608025e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.00039334004395641387\n",
      "Gradient for encoder.encoder.1.bias: 0.0004217259120196104\n",
      "Gradient for encoder.encoder.3.weight: 0.008462231606245041\n",
      "Gradient for encoder.encoder.3.bias: 9.664941069686961e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.0024254980962723494\n",
      "Gradient for encoder.encoder.4.bias: 0.0021314651239663363\n",
      "Gradient for encoder.mean.weight: 0.033775798976421356\n",
      "Gradient for encoder.mean.bias: 0.0017597827827557921\n",
      "Gradient for encoder.log_var.weight: 0.022579234093427658\n",
      "Gradient for encoder.log_var.bias: 0.0011621376033872366\n",
      "Gradient for decoder.decoder.0.weight: 0.012178736738860607\n",
      "Gradient for decoder.decoder.0.bias: 9.785663251937748e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.000612628529779613\n",
      "Gradient for decoder.decoder.1.bias: 0.000505502859596163\n",
      "Gradient for decoder.decoder.3.weight: 0.011730185709893703\n",
      "Gradient for decoder.decoder.3.bias: 8.865235628929824e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0004656367236748338\n",
      "Gradient for decoder.decoder.4.bias: 0.000434160785516724\n",
      "Gradient for decoder.decoder.6.weight: 0.0009102331241592765\n",
      "Gradient for decoder.decoder.6.bias: 4.7116915084188804e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.005334619432687759\n",
      "Gradient for encoder.encoder.0.bias: 8.19441823424194e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.0004155315109528601\n",
      "Gradient for encoder.encoder.1.bias: 0.0003893459215760231\n",
      "Gradient for encoder.encoder.3.weight: 0.009013604372739792\n",
      "Gradient for encoder.encoder.3.bias: 9.548875579135085e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.002453136257827282\n",
      "Gradient for encoder.encoder.4.bias: 0.0016416714061051607\n",
      "Gradient for encoder.mean.weight: 0.032382406294345856\n",
      "Gradient for encoder.mean.bias: 0.0011839632643386722\n",
      "Gradient for encoder.log_var.weight: 0.01876763440668583\n",
      "Gradient for encoder.log_var.bias: 0.000953401206061244\n",
      "Gradient for decoder.decoder.0.weight: 0.011449504643678665\n",
      "Gradient for decoder.decoder.0.bias: 1.0200015831962617e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0005411733873188496\n",
      "Gradient for decoder.decoder.1.bias: 0.0005067798192612827\n",
      "Gradient for decoder.decoder.3.weight: 0.010231616906821728\n",
      "Gradient for decoder.decoder.3.bias: 8.191450295846892e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0004171891196165234\n",
      "Gradient for decoder.decoder.4.bias: 0.00041174195939674973\n",
      "Gradient for decoder.decoder.6.weight: 0.0008149469504132867\n",
      "Gradient for decoder.decoder.6.bias: 3.756449950742535e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.004613399971276522\n",
      "Gradient for encoder.encoder.0.bias: 7.291889314586797e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.0004082172818016261\n",
      "Gradient for encoder.encoder.1.bias: 0.00030643519130535424\n",
      "Gradient for encoder.encoder.3.weight: 0.00888777431100607\n",
      "Gradient for encoder.encoder.3.bias: 8.478744095707924e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.0023586705792695284\n",
      "Gradient for encoder.encoder.4.bias: 0.0017435334157198668\n",
      "Gradient for encoder.mean.weight: 0.0306263230741024\n",
      "Gradient for encoder.mean.bias: 0.0011149548226967454\n",
      "Gradient for encoder.log_var.weight: 0.019413679838180542\n",
      "Gradient for encoder.log_var.bias: 0.0010144268162548542\n",
      "Gradient for decoder.decoder.0.weight: 0.011946535669267178\n",
      "Gradient for decoder.decoder.0.bias: 9.570953057869147e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005921896663494408\n",
      "Gradient for decoder.decoder.1.bias: 0.0005150346551090479\n",
      "Gradient for decoder.decoder.3.weight: 0.011041400954127312\n",
      "Gradient for decoder.decoder.3.bias: 1.0887798301828511e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0006474571418948472\n",
      "Gradient for decoder.decoder.4.bias: 0.0007590617751702666\n",
      "Gradient for decoder.decoder.6.weight: 0.0011315996525809169\n",
      "Gradient for decoder.decoder.6.bias: 9.167415555566549e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.005084941163659096\n",
      "Gradient for encoder.encoder.0.bias: 7.172372071262423e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.00033027175231836736\n",
      "Gradient for encoder.encoder.1.bias: 0.0003261879028286785\n",
      "Gradient for encoder.encoder.3.weight: 0.007331264670938253\n",
      "Gradient for encoder.encoder.3.bias: 8.346294488870143e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.002135389018803835\n",
      "Gradient for encoder.encoder.4.bias: 0.0017660459270700812\n",
      "Gradient for encoder.mean.weight: 0.030186329036951065\n",
      "Gradient for encoder.mean.bias: 0.0015226592076942325\n",
      "Gradient for encoder.log_var.weight: 0.0187737587839365\n",
      "Gradient for encoder.log_var.bias: 0.0010838026646524668\n",
      "Gradient for decoder.decoder.0.weight: 0.012139515951275826\n",
      "Gradient for decoder.decoder.0.bias: 1.0428941044082762e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0005871953326277435\n",
      "Gradient for decoder.decoder.1.bias: 0.0005003808182664216\n",
      "Gradient for decoder.decoder.3.weight: 0.011424397118389606\n",
      "Gradient for decoder.decoder.3.bias: 9.082918445146859e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00046847789781168103\n",
      "Gradient for decoder.decoder.4.bias: 0.00040090078255161643\n",
      "Gradient for decoder.decoder.6.weight: 0.0009468894568271935\n",
      "Gradient for decoder.decoder.6.bias: 5.033019624534063e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.0035311924293637276\n",
      "Gradient for encoder.encoder.0.bias: 5.561578107771137e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.00029957981314510107\n",
      "Gradient for encoder.encoder.1.bias: 0.0003283738624304533\n",
      "Gradient for encoder.encoder.3.weight: 0.006570214405655861\n",
      "Gradient for encoder.encoder.3.bias: 7.953162434182204e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.0029970859177410603\n",
      "Gradient for encoder.encoder.4.bias: 0.0019256009254604578\n",
      "Gradient for encoder.mean.weight: 0.04249463602900505\n",
      "Gradient for encoder.mean.bias: 0.0014184811152517796\n",
      "Gradient for encoder.log_var.weight: 0.024209070950746536\n",
      "Gradient for encoder.log_var.bias: 0.0009465869516134262\n",
      "Gradient for decoder.decoder.0.weight: 0.012836065143346786\n",
      "Gradient for decoder.decoder.0.bias: 1.103569527427517e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0006166422390379012\n",
      "Gradient for decoder.decoder.1.bias: 0.0005571668734773993\n",
      "Gradient for decoder.decoder.3.weight: 0.011757321655750275\n",
      "Gradient for decoder.decoder.3.bias: 1.0018971763336992e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0004573084879666567\n",
      "Gradient for decoder.decoder.4.bias: 0.000395096285501495\n",
      "Gradient for decoder.decoder.6.weight: 0.0008953241049312055\n",
      "Gradient for decoder.decoder.6.bias: 4.6803139412077144e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.0053014266304671764\n",
      "Gradient for encoder.encoder.0.bias: 8.08087971537752e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.0004273233935236931\n",
      "Gradient for encoder.encoder.1.bias: 0.00044148004963062704\n",
      "Gradient for encoder.encoder.3.weight: 0.009806673042476177\n",
      "Gradient for encoder.encoder.3.bias: 9.767436165430965e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.0023658594582229853\n",
      "Gradient for encoder.encoder.4.bias: 0.00189693842548877\n",
      "Gradient for encoder.mean.weight: 0.032061923295259476\n",
      "Gradient for encoder.mean.bias: 0.0015214502345770597\n",
      "Gradient for encoder.log_var.weight: 0.02004610374569893\n",
      "Gradient for encoder.log_var.bias: 0.0011631763773038983\n",
      "Gradient for decoder.decoder.0.weight: 0.01156934630125761\n",
      "Gradient for decoder.decoder.0.bias: 9.347913415558295e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005701799527741969\n",
      "Gradient for decoder.decoder.1.bias: 0.0004629140894394368\n",
      "Gradient for decoder.decoder.3.weight: 0.010689047165215015\n",
      "Gradient for decoder.decoder.3.bias: 7.911780952607472e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00036351309972815216\n",
      "Gradient for decoder.decoder.4.bias: 0.0003312094777356833\n",
      "Gradient for decoder.decoder.6.weight: 0.0009315446950495243\n",
      "Gradient for decoder.decoder.6.bias: 6.221023068064824e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.0035946695134043694\n",
      "Gradient for encoder.encoder.0.bias: 5.273381991494075e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.00038056771154515445\n",
      "Gradient for encoder.encoder.1.bias: 0.00044407497625797987\n",
      "Gradient for encoder.encoder.3.weight: 0.008426127955317497\n",
      "Gradient for encoder.encoder.3.bias: 7.777901933625486e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.002583031076937914\n",
      "Gradient for encoder.encoder.4.bias: 0.0016026028897613287\n",
      "Gradient for encoder.mean.weight: 0.03806206211447716\n",
      "Gradient for encoder.mean.bias: 0.0011430976446717978\n",
      "Gradient for encoder.log_var.weight: 0.02247600257396698\n",
      "Gradient for encoder.log_var.bias: 0.0010606769938021898\n",
      "Gradient for decoder.decoder.0.weight: 0.012851844541728497\n",
      "Gradient for decoder.decoder.0.bias: 1.173911662322169e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0005754417506977916\n",
      "Gradient for decoder.decoder.1.bias: 0.000524379312992096\n",
      "Gradient for decoder.decoder.3.weight: 0.011965536512434483\n",
      "Gradient for decoder.decoder.3.bias: 1.0246874182495702e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0004502100346144289\n",
      "Gradient for decoder.decoder.4.bias: 0.00044623910798691213\n",
      "Gradient for decoder.decoder.6.weight: 0.0008577672997489572\n",
      "Gradient for decoder.decoder.6.bias: 3.9183851185953245e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.004041844047605991\n",
      "Gradient for encoder.encoder.0.bias: 6.145561923937004e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.00036318646743893623\n",
      "Gradient for encoder.encoder.1.bias: 0.0002923476858995855\n",
      "Gradient for encoder.encoder.3.weight: 0.008195928297936916\n",
      "Gradient for encoder.encoder.3.bias: 8.821358921107247e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.002408367581665516\n",
      "Gradient for encoder.encoder.4.bias: 0.0019421607721596956\n",
      "Gradient for encoder.mean.weight: 0.0361371710896492\n",
      "Gradient for encoder.mean.bias: 0.0015923454193398356\n",
      "Gradient for encoder.log_var.weight: 0.0195444505661726\n",
      "Gradient for encoder.log_var.bias: 0.0010128460125997663\n",
      "Gradient for decoder.decoder.0.weight: 0.013144920580089092\n",
      "Gradient for decoder.decoder.0.bias: 1.0830698837782649e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0006251360173337162\n",
      "Gradient for decoder.decoder.1.bias: 0.0005674902349710464\n",
      "Gradient for decoder.decoder.3.weight: 0.01241183839738369\n",
      "Gradient for decoder.decoder.3.bias: 1.1697474933125562e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.000745875877328217\n",
      "Gradient for decoder.decoder.4.bias: 0.0008097888203337789\n",
      "Gradient for decoder.decoder.6.weight: 0.0012691060546785593\n",
      "Gradient for decoder.decoder.6.bias: 9.756701183505356e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.003806810826063156\n",
      "Gradient for encoder.encoder.0.bias: 6.190806114275693e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.00034677653457038105\n",
      "Gradient for encoder.encoder.1.bias: 0.00035362178459763527\n",
      "Gradient for encoder.encoder.3.weight: 0.007536626420915127\n",
      "Gradient for encoder.encoder.3.bias: 9.547224122385956e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.0025709611363708973\n",
      "Gradient for encoder.encoder.4.bias: 0.0021969813387840986\n",
      "Gradient for encoder.mean.weight: 0.04122743383049965\n",
      "Gradient for encoder.mean.bias: 0.0020563590805977583\n",
      "Gradient for encoder.log_var.weight: 0.02087453380227089\n",
      "Gradient for encoder.log_var.bias: 0.001301728654652834\n",
      "Gradient for decoder.decoder.0.weight: 0.01243253517895937\n",
      "Gradient for decoder.decoder.0.bias: 1.2086746881134758e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0005906621227040887\n",
      "Gradient for decoder.decoder.1.bias: 0.0005211844691075385\n",
      "Gradient for decoder.decoder.3.weight: 0.012018031440675259\n",
      "Gradient for decoder.decoder.3.bias: 9.999621963796557e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0004392721748445183\n",
      "Gradient for decoder.decoder.4.bias: 0.00040517098386771977\n",
      "Gradient for decoder.decoder.6.weight: 0.0008679880993440747\n",
      "Gradient for decoder.decoder.6.bias: 3.626774196163751e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.005556912161409855\n",
      "Gradient for encoder.encoder.0.bias: 9.084137955750471e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.0005614779074676335\n",
      "Gradient for encoder.encoder.1.bias: 0.000482830946566537\n",
      "Gradient for encoder.encoder.3.weight: 0.012253046035766602\n",
      "Gradient for encoder.encoder.3.bias: 1.2383588599007567e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0031622108072042465\n",
      "Gradient for encoder.encoder.4.bias: 0.0025523139629513025\n",
      "Gradient for encoder.mean.weight: 0.04504876211285591\n",
      "Gradient for encoder.mean.bias: 0.0020787448156625032\n",
      "Gradient for encoder.log_var.weight: 0.026277508586645126\n",
      "Gradient for encoder.log_var.bias: 0.0011810476426035166\n",
      "Gradient for decoder.decoder.0.weight: 0.011301516555249691\n",
      "Gradient for decoder.decoder.0.bias: 9.60875060074251e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005371896550059319\n",
      "Gradient for decoder.decoder.1.bias: 0.0004441544006112963\n",
      "Gradient for decoder.decoder.3.weight: 0.010538590140640736\n",
      "Gradient for decoder.decoder.3.bias: 9.65343152636855e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0003921299066860229\n",
      "Gradient for decoder.decoder.4.bias: 0.0003546651278156787\n",
      "Gradient for decoder.decoder.6.weight: 0.0008586265612393618\n",
      "Gradient for decoder.decoder.6.bias: 4.6209872380131856e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.019034096971154213\n",
      "Gradient for encoder.encoder.0.bias: 2.3879941427051854e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0007223343709483743\n",
      "Gradient for encoder.encoder.1.bias: 0.0009060024749487638\n",
      "Gradient for encoder.encoder.3.weight: 0.015406028367578983\n",
      "Gradient for encoder.encoder.3.bias: 1.6353479681541216e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0030098760034888983\n",
      "Gradient for encoder.encoder.4.bias: 0.003075883025303483\n",
      "Gradient for encoder.mean.weight: 0.04518316686153412\n",
      "Gradient for encoder.mean.bias: 0.0023045430425554514\n",
      "Gradient for encoder.log_var.weight: 0.024173211306333542\n",
      "Gradient for encoder.log_var.bias: 0.0014811432920396328\n",
      "Gradient for decoder.decoder.0.weight: 0.02889976091682911\n",
      "Gradient for decoder.decoder.0.bias: 1.9692689146033615e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0011987327598035336\n",
      "Gradient for decoder.decoder.1.bias: 0.0011410447768867016\n",
      "Gradient for decoder.decoder.3.weight: 0.02468639425933361\n",
      "Gradient for decoder.decoder.3.bias: 1.5042121714881063e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0009009133791550994\n",
      "Gradient for decoder.decoder.4.bias: 0.0008881969260983169\n",
      "Gradient for decoder.decoder.6.weight: 0.003150843782350421\n",
      "Gradient for decoder.decoder.6.bias: 0.00023845983378123492\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/3, Train Loss: 0.0760, Val Loss: 0.2427\n",
      "Training VAE for class 9...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training VAE Epoch:  10%|█         | 8/79 [00:00<00:02, 32.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient for encoder.encoder.0.weight: 0.006329668685793877\n",
      "Gradient for encoder.encoder.0.bias: 9.443589139845887e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.0005505543667823076\n",
      "Gradient for encoder.encoder.1.bias: 0.00046358443796634674\n",
      "Gradient for encoder.encoder.3.weight: 0.01161054614931345\n",
      "Gradient for encoder.encoder.3.bias: 1.0283802281962906e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0029654931277036667\n",
      "Gradient for encoder.encoder.4.bias: 0.002523063449189067\n",
      "Gradient for encoder.mean.weight: 0.0432678759098053\n",
      "Gradient for encoder.mean.bias: 0.0018105317139998078\n",
      "Gradient for encoder.log_var.weight: 0.024814695119857788\n",
      "Gradient for encoder.log_var.bias: 0.0010880894260481\n",
      "Gradient for decoder.decoder.0.weight: 0.010106625035405159\n",
      "Gradient for decoder.decoder.0.bias: 8.695402731184743e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.00048653301200829446\n",
      "Gradient for decoder.decoder.1.bias: 0.0003954038838855922\n",
      "Gradient for decoder.decoder.3.weight: 0.00959421694278717\n",
      "Gradient for decoder.decoder.3.bias: 8.860384648201602e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0005060668918304145\n",
      "Gradient for decoder.decoder.4.bias: 0.0005922695272602141\n",
      "Gradient for decoder.decoder.6.weight: 0.0012817332753911614\n",
      "Gradient for decoder.decoder.6.bias: 0.00010697283141780645\n",
      "Gradient for encoder.encoder.0.weight: 0.00662024412304163\n",
      "Gradient for encoder.encoder.0.bias: 8.05383190694009e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.0005851662135683\n",
      "Gradient for encoder.encoder.1.bias: 0.0005566957406699657\n",
      "Gradient for encoder.encoder.3.weight: 0.013460632413625717\n",
      "Gradient for encoder.encoder.3.bias: 1.1022476681388227e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.003109694691374898\n",
      "Gradient for encoder.encoder.4.bias: 0.0026171200443059206\n",
      "Gradient for encoder.mean.weight: 0.04416784644126892\n",
      "Gradient for encoder.mean.bias: 0.0019331233343109488\n",
      "Gradient for encoder.log_var.weight: 0.024331945925951004\n",
      "Gradient for encoder.log_var.bias: 0.0011586940381675959\n",
      "Gradient for decoder.decoder.0.weight: 0.009605955332517624\n",
      "Gradient for decoder.decoder.0.bias: 8.51373971322289e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0004594623460434377\n",
      "Gradient for decoder.decoder.1.bias: 0.00038998379022814333\n",
      "Gradient for decoder.decoder.3.weight: 0.00864738691598177\n",
      "Gradient for decoder.decoder.3.bias: 8.295361619836683e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0005022429977543652\n",
      "Gradient for decoder.decoder.4.bias: 0.0005545419408008456\n",
      "Gradient for decoder.decoder.6.weight: 0.0015561365289613605\n",
      "Gradient for decoder.decoder.6.bias: 0.0001432383869541809\n",
      "Gradient for encoder.encoder.0.weight: 0.008798467926681042\n",
      "Gradient for encoder.encoder.0.bias: 1.221978854909489e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0005871859029866755\n",
      "Gradient for encoder.encoder.1.bias: 0.00046974915312603116\n",
      "Gradient for encoder.encoder.3.weight: 0.013104948215186596\n",
      "Gradient for encoder.encoder.3.bias: 1.1457693127603363e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0030574356205761433\n",
      "Gradient for encoder.encoder.4.bias: 0.0023668406065553427\n",
      "Gradient for encoder.mean.weight: 0.0427544005215168\n",
      "Gradient for encoder.mean.bias: 0.0016843680059537292\n",
      "Gradient for encoder.log_var.weight: 0.024155747145414352\n",
      "Gradient for encoder.log_var.bias: 0.0011080509284511209\n",
      "Gradient for decoder.decoder.0.weight: 0.009415635839104652\n",
      "Gradient for decoder.decoder.0.bias: 7.297649984305821e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0004661545099224895\n",
      "Gradient for decoder.decoder.1.bias: 0.00037443230394273996\n",
      "Gradient for decoder.decoder.3.weight: 0.00871557928621769\n",
      "Gradient for decoder.decoder.3.bias: 6.9262158508554e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0003654523170553148\n",
      "Gradient for decoder.decoder.4.bias: 0.0003847555199172348\n",
      "Gradient for decoder.decoder.6.weight: 0.0015282193198800087\n",
      "Gradient for decoder.decoder.6.bias: 0.00014082141569815576\n",
      "Gradient for encoder.encoder.0.weight: 0.006274902727454901\n",
      "Gradient for encoder.encoder.0.bias: 9.395244998655627e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.0004753681132569909\n",
      "Gradient for encoder.encoder.1.bias: 0.0004847656819038093\n",
      "Gradient for encoder.encoder.3.weight: 0.00999873224645853\n",
      "Gradient for encoder.encoder.3.bias: 9.537790696123594e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.002530987374484539\n",
      "Gradient for encoder.encoder.4.bias: 0.0016641027759760618\n",
      "Gradient for encoder.mean.weight: 0.03549903258681297\n",
      "Gradient for encoder.mean.bias: 0.0013108090497553349\n",
      "Gradient for encoder.log_var.weight: 0.022484129294753075\n",
      "Gradient for encoder.log_var.bias: 0.000799592409748584\n",
      "Gradient for decoder.decoder.0.weight: 0.009681782685220242\n",
      "Gradient for decoder.decoder.0.bias: 9.184081273261313e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005045855068601668\n",
      "Gradient for decoder.decoder.1.bias: 0.0003895713307429105\n",
      "Gradient for decoder.decoder.3.weight: 0.009013444185256958\n",
      "Gradient for decoder.decoder.3.bias: 9.44801251123728e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00047348058433271945\n",
      "Gradient for decoder.decoder.4.bias: 0.0005284558283165097\n",
      "Gradient for decoder.decoder.6.weight: 0.001528106746263802\n",
      "Gradient for decoder.decoder.6.bias: 0.0001405891525791958\n",
      "Gradient for encoder.encoder.0.weight: 0.005785088054835796\n",
      "Gradient for encoder.encoder.0.bias: 8.679400947952942e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.0004761270829476416\n",
      "Gradient for encoder.encoder.1.bias: 0.00037396125844679773\n",
      "Gradient for encoder.encoder.3.weight: 0.01063570100814104\n",
      "Gradient for encoder.encoder.3.bias: 1.0454648258217958e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0024169250391423702\n",
      "Gradient for encoder.encoder.4.bias: 0.001984792063012719\n",
      "Gradient for encoder.mean.weight: 0.0341176874935627\n",
      "Gradient for encoder.mean.bias: 0.001467463094741106\n",
      "Gradient for encoder.log_var.weight: 0.018576357513666153\n",
      "Gradient for encoder.log_var.bias: 0.0008816075278446078\n",
      "Gradient for decoder.decoder.0.weight: 0.010749653913080692\n",
      "Gradient for decoder.decoder.0.bias: 8.925293143446922e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005139720742590725\n",
      "Gradient for decoder.decoder.1.bias: 0.0004601373802870512\n",
      "Gradient for decoder.decoder.3.weight: 0.010309490375220776\n",
      "Gradient for decoder.decoder.3.bias: 8.634764431247888e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.000431221560575068\n",
      "Gradient for decoder.decoder.4.bias: 0.0003921181196346879\n",
      "Gradient for decoder.decoder.6.weight: 0.0014181199949234724\n",
      "Gradient for decoder.decoder.6.bias: 0.00011834429460577667\n",
      "Gradient for encoder.encoder.0.weight: 0.003938107285648584\n",
      "Gradient for encoder.encoder.0.bias: 6.074159838304061e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.0005389300640672445\n",
      "Gradient for encoder.encoder.1.bias: 0.0003923143958672881\n",
      "Gradient for encoder.encoder.3.weight: 0.011587406508624554\n",
      "Gradient for encoder.encoder.3.bias: 1.1782794184789225e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0032458165660500526\n",
      "Gradient for encoder.encoder.4.bias: 0.002674806397408247\n",
      "Gradient for encoder.mean.weight: 0.047141071408987045\n",
      "Gradient for encoder.mean.bias: 0.001966850832104683\n",
      "Gradient for encoder.log_var.weight: 0.02740529552102089\n",
      "Gradient for encoder.log_var.bias: 0.0012273482279852033\n",
      "Gradient for decoder.decoder.0.weight: 0.012739409692585468\n",
      "Gradient for decoder.decoder.0.bias: 1.0713643860960076e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0005886567523702979\n",
      "Gradient for decoder.decoder.1.bias: 0.0004969334695488214\n",
      "Gradient for decoder.decoder.3.weight: 0.011445701122283936\n",
      "Gradient for decoder.decoder.3.bias: 9.647324605843721e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00046753790229558945\n",
      "Gradient for decoder.decoder.4.bias: 0.00048541565774939954\n",
      "Gradient for decoder.decoder.6.weight: 0.0013802375178784132\n",
      "Gradient for decoder.decoder.6.bias: 0.00011869737500092015\n",
      "Gradient for encoder.encoder.0.weight: 0.005160628817975521\n",
      "Gradient for encoder.encoder.0.bias: 7.558625600423419e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.0005235561402514577\n",
      "Gradient for encoder.encoder.1.bias: 0.00042005465365946293\n",
      "Gradient for encoder.encoder.3.weight: 0.011501007713377476\n",
      "Gradient for encoder.encoder.3.bias: 1.0875178535485475e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0031311556231230497\n",
      "Gradient for encoder.encoder.4.bias: 0.0023593988735228777\n",
      "Gradient for encoder.mean.weight: 0.044707052409648895\n",
      "Gradient for encoder.mean.bias: 0.0019235776271671057\n",
      "Gradient for encoder.log_var.weight: 0.026071837171912193\n",
      "Gradient for encoder.log_var.bias: 0.0012406567111611366\n",
      "Gradient for decoder.decoder.0.weight: 0.011203977279365063\n",
      "Gradient for decoder.decoder.0.bias: 9.337463441339011e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005540888523682952\n",
      "Gradient for decoder.decoder.1.bias: 0.0004722923331428319\n",
      "Gradient for decoder.decoder.3.weight: 0.010504611767828465\n",
      "Gradient for decoder.decoder.3.bias: 8.089282022005762e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00043371686479076743\n",
      "Gradient for decoder.decoder.4.bias: 0.0004298500716686249\n",
      "Gradient for decoder.decoder.6.weight: 0.001313098007813096\n",
      "Gradient for decoder.decoder.6.bias: 0.00010801467578858137\n",
      "Gradient for encoder.encoder.0.weight: 0.010666022077202797\n",
      "Gradient for encoder.encoder.0.bias: 1.5048221349567292e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0006514040869660676\n",
      "Gradient for encoder.encoder.1.bias: 0.000583150889724493\n",
      "Gradient for encoder.encoder.3.weight: 0.013871152885258198\n",
      "Gradient for encoder.encoder.3.bias: 1.0566933439370985e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0029236143454909325\n",
      "Gradient for encoder.encoder.4.bias: 0.0020768847316503525\n",
      "Gradient for encoder.mean.weight: 0.03976468741893768\n",
      "Gradient for encoder.mean.bias: 0.0015075452392920852\n",
      "Gradient for encoder.log_var.weight: 0.023336799815297127\n",
      "Gradient for encoder.log_var.bias: 0.0010282722068950534\n",
      "Gradient for decoder.decoder.0.weight: 0.007909107021987438\n",
      "Gradient for decoder.decoder.0.bias: 6.855158107832438e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0003891437081620097\n",
      "Gradient for decoder.decoder.1.bias: 0.00034103303914889693\n",
      "Gradient for decoder.decoder.3.weight: 0.007343118544667959\n",
      "Gradient for decoder.decoder.3.bias: 1.1121874948782917e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0008543735020793974\n",
      "Gradient for decoder.decoder.4.bias: 0.0010857684537768364\n",
      "Gradient for decoder.decoder.6.weight: 0.0013565728440880775\n",
      "Gradient for decoder.decoder.6.bias: 0.00012323568807914853\n",
      "Gradient for encoder.encoder.0.weight: 0.004823445342481136\n",
      "Gradient for encoder.encoder.0.bias: 6.5314030225915864e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.000364127685315907\n",
      "Gradient for encoder.encoder.1.bias: 0.0003681014059111476\n",
      "Gradient for encoder.encoder.3.weight: 0.007747909985482693\n",
      "Gradient for encoder.encoder.3.bias: 9.509535520146883e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.0022979327477514744\n",
      "Gradient for encoder.encoder.4.bias: 0.0019637364894151688\n",
      "Gradient for encoder.mean.weight: 0.033675890415906906\n",
      "Gradient for encoder.mean.bias: 0.0014387661358341575\n",
      "Gradient for encoder.log_var.weight: 0.02086458168923855\n",
      "Gradient for encoder.log_var.bias: 0.001005639205686748\n",
      "Gradient for decoder.decoder.0.weight: 0.012056775391101837\n",
      "Gradient for decoder.decoder.0.bias: 9.715988430469835e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005734020960517228\n",
      "Gradient for decoder.decoder.1.bias: 0.00048763747327029705\n",
      "Gradient for decoder.decoder.3.weight: 0.011355459690093994\n",
      "Gradient for decoder.decoder.3.bias: 8.233792120337924e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0004192148335278034\n",
      "Gradient for decoder.decoder.4.bias: 0.00039815640775486827\n",
      "Gradient for decoder.decoder.6.weight: 0.001252879505045712\n",
      "Gradient for decoder.decoder.6.bias: 0.0001001376731437631\n",
      "Gradient for encoder.encoder.0.weight: 0.008373701013624668\n",
      "Gradient for encoder.encoder.0.bias: 1.3545168459083712e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0006029877695254982\n",
      "Gradient for encoder.encoder.1.bias: 0.0004651531344279647\n",
      "Gradient for encoder.encoder.3.weight: 0.012997046113014221\n",
      "Gradient for encoder.encoder.3.bias: 1.1399677729562185e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.003632910083979368\n",
      "Gradient for encoder.encoder.4.bias: 0.0027293332386761904\n",
      "Gradient for encoder.mean.weight: 0.0507776141166687\n",
      "Gradient for encoder.mean.bias: 0.001820103614591062\n",
      "Gradient for encoder.log_var.weight: 0.026990067213773727\n",
      "Gradient for encoder.log_var.bias: 0.0012513870606198907\n",
      "Gradient for decoder.decoder.0.weight: 0.010161491110920906\n",
      "Gradient for decoder.decoder.0.bias: 8.987237343216492e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0004912525764666498\n",
      "Gradient for decoder.decoder.1.bias: 0.0004009112308267504\n",
      "Gradient for decoder.decoder.3.weight: 0.009584805928170681\n",
      "Gradient for decoder.decoder.3.bias: 7.583423472512507e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00038828622200526297\n",
      "Gradient for decoder.decoder.4.bias: 0.00039155883132480085\n",
      "Gradient for decoder.decoder.6.weight: 0.0014465323183685541\n",
      "Gradient for decoder.decoder.6.bias: 0.00012716058699879795\n",
      "Gradient for encoder.encoder.0.weight: 0.013035444542765617\n",
      "Gradient for encoder.encoder.0.bias: 1.5607995798583296e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.000619858386926353\n",
      "Gradient for encoder.encoder.1.bias: 0.0005293305730447173\n",
      "Gradient for encoder.encoder.3.weight: 0.013528606854379177\n",
      "Gradient for encoder.encoder.3.bias: 1.1836923108354824e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0026423782110214233\n",
      "Gradient for encoder.encoder.4.bias: 0.0023539443500339985\n",
      "Gradient for encoder.mean.weight: 0.03833429515361786\n",
      "Gradient for encoder.mean.bias: 0.0017998290713876486\n",
      "Gradient for encoder.log_var.weight: 0.02247137576341629\n",
      "Gradient for encoder.log_var.bias: 0.0010722274892032146\n",
      "Gradient for decoder.decoder.0.weight: 0.007815965451300144\n",
      "Gradient for decoder.decoder.0.bias: 7.223123488220295e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.00037207527202554047\n",
      "Gradient for decoder.decoder.1.bias: 0.00032562256092205644\n",
      "Gradient for decoder.decoder.3.weight: 0.007186258211731911\n",
      "Gradient for decoder.decoder.3.bias: 8.667228740266708e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0005594896501861513\n",
      "Gradient for decoder.decoder.4.bias: 0.0006879131542518735\n",
      "Gradient for decoder.decoder.6.weight: 0.0012009614147245884\n",
      "Gradient for decoder.decoder.6.bias: 9.529844101052731e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.006428527180105448\n",
      "Gradient for encoder.encoder.0.bias: 9.920825445874915e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.000498090055771172\n",
      "Gradient for encoder.encoder.1.bias: 0.00036797369830310345\n",
      "Gradient for encoder.encoder.3.weight: 0.010649419389665127\n",
      "Gradient for encoder.encoder.3.bias: 1.0820628421059908e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.003027807455509901\n",
      "Gradient for encoder.encoder.4.bias: 0.0023626452311873436\n",
      "Gradient for encoder.mean.weight: 0.04174605384469032\n",
      "Gradient for encoder.mean.bias: 0.001969411736354232\n",
      "Gradient for encoder.log_var.weight: 0.02361171878874302\n",
      "Gradient for encoder.log_var.bias: 0.0011171925580129027\n",
      "Gradient for decoder.decoder.0.weight: 0.009518255479633808\n",
      "Gradient for decoder.decoder.0.bias: 8.1368731197351e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.00046999574988149107\n",
      "Gradient for decoder.decoder.1.bias: 0.00038919076905585825\n",
      "Gradient for decoder.decoder.3.weight: 0.009016293101012707\n",
      "Gradient for decoder.decoder.3.bias: 8.231366976918508e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00047802762128412724\n",
      "Gradient for decoder.decoder.4.bias: 0.0005327164544723928\n",
      "Gradient for decoder.decoder.6.weight: 0.001252662274055183\n",
      "Gradient for decoder.decoder.6.bias: 0.00010035965533461422\n",
      "Gradient for encoder.encoder.0.weight: 0.0066250707022845745\n",
      "Gradient for encoder.encoder.0.bias: 9.734839670483275e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.0004914006567560136\n",
      "Gradient for encoder.encoder.1.bias: 0.00040223600808531046\n",
      "Gradient for encoder.encoder.3.weight: 0.010171324945986271\n",
      "Gradient for encoder.encoder.3.bias: 1.0958686041950827e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.002986862091347575\n",
      "Gradient for encoder.encoder.4.bias: 0.0023192064836621284\n",
      "Gradient for encoder.mean.weight: 0.0377027727663517\n",
      "Gradient for encoder.mean.bias: 0.0017707573715597391\n",
      "Gradient for encoder.log_var.weight: 0.024205388501286507\n",
      "Gradient for encoder.log_var.bias: 0.001138209248892963\n",
      "Gradient for decoder.decoder.0.weight: 0.009627824649214745\n",
      "Gradient for decoder.decoder.0.bias: 8.402503692828134e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0004398888268042356\n",
      "Gradient for decoder.decoder.1.bias: 0.0004029987030662596\n",
      "Gradient for decoder.decoder.3.weight: 0.00899823009967804\n",
      "Gradient for decoder.decoder.3.bias: 7.841682858611421e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0004027466056868434\n",
      "Gradient for decoder.decoder.4.bias: 0.00039662039489485323\n",
      "Gradient for decoder.decoder.6.weight: 0.001174027449451387\n",
      "Gradient for decoder.decoder.6.bias: 9.392791980644688e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.010128147900104523\n",
      "Gradient for encoder.encoder.0.bias: 1.2541382862774064e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0005717847961932421\n",
      "Gradient for encoder.encoder.1.bias: 0.0004563828697428107\n",
      "Gradient for encoder.encoder.3.weight: 0.012381399050354958\n",
      "Gradient for encoder.encoder.3.bias: 1.1400596439115063e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0023861892987042665\n",
      "Gradient for encoder.encoder.4.bias: 0.0018697992200031877\n",
      "Gradient for encoder.mean.weight: 0.032488029450178146\n",
      "Gradient for encoder.mean.bias: 0.0013233049539849162\n",
      "Gradient for encoder.log_var.weight: 0.019072184339165688\n",
      "Gradient for encoder.log_var.bias: 0.0009708291618153453\n",
      "Gradient for decoder.decoder.0.weight: 0.009433000348508358\n",
      "Gradient for decoder.decoder.0.bias: 7.724884620863293e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.00044840475311502814\n",
      "Gradient for decoder.decoder.1.bias: 0.00038512726314365864\n",
      "Gradient for decoder.decoder.3.weight: 0.008742241188883781\n",
      "Gradient for decoder.decoder.3.bias: 7.149085490265605e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00036999190342612565\n",
      "Gradient for decoder.decoder.4.bias: 0.00036546896444633603\n",
      "Gradient for decoder.decoder.6.weight: 0.0012104749912396073\n",
      "Gradient for decoder.decoder.6.bias: 9.893762762658298e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.004584608133882284\n",
      "Gradient for encoder.encoder.0.bias: 7.218631508515427e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.0004428245301824063\n",
      "Gradient for encoder.encoder.1.bias: 0.00043682748218998313\n",
      "Gradient for encoder.encoder.3.weight: 0.009387306869029999\n",
      "Gradient for encoder.encoder.3.bias: 9.977192683141567e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.003373062703758478\n",
      "Gradient for encoder.encoder.4.bias: 0.0023162784054875374\n",
      "Gradient for encoder.mean.weight: 0.048922229558229446\n",
      "Gradient for encoder.mean.bias: 0.0014542298158630729\n",
      "Gradient for encoder.log_var.weight: 0.0284613985568285\n",
      "Gradient for encoder.log_var.bias: 0.0009095430141314864\n",
      "Gradient for decoder.decoder.0.weight: 0.010501443408429623\n",
      "Gradient for decoder.decoder.0.bias: 9.20204884513609e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005037904484197497\n",
      "Gradient for decoder.decoder.1.bias: 0.00042753422167152166\n",
      "Gradient for decoder.decoder.3.weight: 0.009690532460808754\n",
      "Gradient for decoder.decoder.3.bias: 9.146775697965737e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0005846858839504421\n",
      "Gradient for decoder.decoder.4.bias: 0.0006947747315280139\n",
      "Gradient for decoder.decoder.6.weight: 0.0011677197180688381\n",
      "Gradient for decoder.decoder.6.bias: 8.912369230529293e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training VAE Epoch:  30%|███       | 24/79 [00:00<00:00, 59.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient for encoder.encoder.0.weight: 0.005323345772922039\n",
      "Gradient for encoder.encoder.0.bias: 8.470721520048574e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.0004932052688673139\n",
      "Gradient for encoder.encoder.1.bias: 0.0003619830822572112\n",
      "Gradient for encoder.encoder.3.weight: 0.010439460165798664\n",
      "Gradient for encoder.encoder.3.bias: 1.1714859637912411e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.00335388770326972\n",
      "Gradient for encoder.encoder.4.bias: 0.0026829016860574484\n",
      "Gradient for encoder.mean.weight: 0.04977511242032051\n",
      "Gradient for encoder.mean.bias: 0.002054785145446658\n",
      "Gradient for encoder.log_var.weight: 0.025325682014226913\n",
      "Gradient for encoder.log_var.bias: 0.0010822172043845057\n",
      "Gradient for decoder.decoder.0.weight: 0.010555463843047619\n",
      "Gradient for decoder.decoder.0.bias: 8.934801509763446e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005542351864278316\n",
      "Gradient for decoder.decoder.1.bias: 0.0004380874743219465\n",
      "Gradient for decoder.decoder.3.weight: 0.010001523420214653\n",
      "Gradient for decoder.decoder.3.bias: 8.167320986185445e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00044140240061096847\n",
      "Gradient for decoder.decoder.4.bias: 0.0004334246623329818\n",
      "Gradient for decoder.decoder.6.weight: 0.001273317844606936\n",
      "Gradient for decoder.decoder.6.bias: 0.00010276048124069348\n",
      "Gradient for encoder.encoder.0.weight: 0.007042575161904097\n",
      "Gradient for encoder.encoder.0.bias: 9.392386174367218e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.00046248818398453295\n",
      "Gradient for encoder.encoder.1.bias: 0.0004035438469145447\n",
      "Gradient for encoder.encoder.3.weight: 0.009672463871538639\n",
      "Gradient for encoder.encoder.3.bias: 1.0494748126088638e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0024229635018855333\n",
      "Gradient for encoder.encoder.4.bias: 0.0020188416820019484\n",
      "Gradient for encoder.mean.weight: 0.030726006254553795\n",
      "Gradient for encoder.mean.bias: 0.0015068482607603073\n",
      "Gradient for encoder.log_var.weight: 0.020007513463497162\n",
      "Gradient for encoder.log_var.bias: 0.001017264323309064\n",
      "Gradient for decoder.decoder.0.weight: 0.009630144573748112\n",
      "Gradient for decoder.decoder.0.bias: 8.13905887131483e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0004534710315056145\n",
      "Gradient for decoder.decoder.1.bias: 0.0004097788187209517\n",
      "Gradient for decoder.decoder.3.weight: 0.008785270154476166\n",
      "Gradient for decoder.decoder.3.bias: 7.341177665765031e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00035397199098952115\n",
      "Gradient for decoder.decoder.4.bias: 0.0003401327121537179\n",
      "Gradient for decoder.decoder.6.weight: 0.0011486186413094401\n",
      "Gradient for decoder.decoder.6.bias: 8.502737910021096e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.004856090527027845\n",
      "Gradient for encoder.encoder.0.bias: 7.282311038914191e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.00046245678095147014\n",
      "Gradient for encoder.encoder.1.bias: 0.00046144291991367936\n",
      "Gradient for encoder.encoder.3.weight: 0.009850895963609219\n",
      "Gradient for encoder.encoder.3.bias: 1.031165500209319e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0027442555874586105\n",
      "Gradient for encoder.encoder.4.bias: 0.0018659846391528845\n",
      "Gradient for encoder.mean.weight: 0.03764373064041138\n",
      "Gradient for encoder.mean.bias: 0.001328321173787117\n",
      "Gradient for encoder.log_var.weight: 0.02133367210626602\n",
      "Gradient for encoder.log_var.bias: 0.0009470762452110648\n",
      "Gradient for decoder.decoder.0.weight: 0.011335437186062336\n",
      "Gradient for decoder.decoder.0.bias: 8.819255742364973e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005467049195431173\n",
      "Gradient for decoder.decoder.1.bias: 0.00046998911420814693\n",
      "Gradient for decoder.decoder.3.weight: 0.010923351161181927\n",
      "Gradient for decoder.decoder.3.bias: 7.845866317746086e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.000380821613362059\n",
      "Gradient for decoder.decoder.4.bias: 0.0003574028960429132\n",
      "Gradient for decoder.decoder.6.weight: 0.001033569686114788\n",
      "Gradient for decoder.decoder.6.bias: 6.049067451385781e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.005195744801312685\n",
      "Gradient for encoder.encoder.0.bias: 7.933708377760862e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.00039187370566651225\n",
      "Gradient for encoder.encoder.1.bias: 0.00037389693898148835\n",
      "Gradient for encoder.encoder.3.weight: 0.00898816529661417\n",
      "Gradient for encoder.encoder.3.bias: 9.023720659584455e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.0025121995713561773\n",
      "Gradient for encoder.encoder.4.bias: 0.0017312022391706705\n",
      "Gradient for encoder.mean.weight: 0.036240722984075546\n",
      "Gradient for encoder.mean.bias: 0.00126226048450917\n",
      "Gradient for encoder.log_var.weight: 0.019983939826488495\n",
      "Gradient for encoder.log_var.bias: 0.0009740013629198074\n",
      "Gradient for decoder.decoder.0.weight: 0.010009631514549255\n",
      "Gradient for decoder.decoder.0.bias: 8.87879630928623e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005272141424939036\n",
      "Gradient for decoder.decoder.1.bias: 0.00044339289888739586\n",
      "Gradient for decoder.decoder.3.weight: 0.009514975361526012\n",
      "Gradient for decoder.decoder.3.bias: 8.235646192789048e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00034146406687796116\n",
      "Gradient for decoder.decoder.4.bias: 0.00029938752413727343\n",
      "Gradient for decoder.decoder.6.weight: 0.0009752087644301355\n",
      "Gradient for decoder.decoder.6.bias: 6.224166281754151e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.005130873993039131\n",
      "Gradient for encoder.encoder.0.bias: 7.141830963425244e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.00030472956132143736\n",
      "Gradient for encoder.encoder.1.bias: 0.00031797128031030297\n",
      "Gradient for encoder.encoder.3.weight: 0.006747230887413025\n",
      "Gradient for encoder.encoder.3.bias: 8.644865379103805e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.002208955818787217\n",
      "Gradient for encoder.encoder.4.bias: 0.0017010270385071635\n",
      "Gradient for encoder.mean.weight: 0.031850483268499374\n",
      "Gradient for encoder.mean.bias: 0.001197680365294218\n",
      "Gradient for encoder.log_var.weight: 0.020573090761899948\n",
      "Gradient for encoder.log_var.bias: 0.0009573105489835143\n",
      "Gradient for decoder.decoder.0.weight: 0.010211891494691372\n",
      "Gradient for decoder.decoder.0.bias: 8.836627263253405e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0004720534780062735\n",
      "Gradient for decoder.decoder.1.bias: 0.00043626129627227783\n",
      "Gradient for decoder.decoder.3.weight: 0.009582554921507835\n",
      "Gradient for decoder.decoder.3.bias: 8.509951771040747e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0004235294763930142\n",
      "Gradient for decoder.decoder.4.bias: 0.000409628584748134\n",
      "Gradient for decoder.decoder.6.weight: 0.0010081843938678503\n",
      "Gradient for decoder.decoder.6.bias: 6.277830834733322e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.006643506232649088\n",
      "Gradient for encoder.encoder.0.bias: 1.0877917490381694e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0004935147590003908\n",
      "Gradient for encoder.encoder.1.bias: 0.0004998478107154369\n",
      "Gradient for encoder.encoder.3.weight: 0.010395278222858906\n",
      "Gradient for encoder.encoder.3.bias: 9.672097844859451e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.0022814180701971054\n",
      "Gradient for encoder.encoder.4.bias: 0.0016554989852011204\n",
      "Gradient for encoder.mean.weight: 0.03278627619147301\n",
      "Gradient for encoder.mean.bias: 0.001247686450369656\n",
      "Gradient for encoder.log_var.weight: 0.019417855888605118\n",
      "Gradient for encoder.log_var.bias: 0.0008447745349258184\n",
      "Gradient for decoder.decoder.0.weight: 0.009538192301988602\n",
      "Gradient for decoder.decoder.0.bias: 7.979503863220216e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.00047978077782317996\n",
      "Gradient for decoder.decoder.1.bias: 0.0004004845395684242\n",
      "Gradient for decoder.decoder.3.weight: 0.009188386611640453\n",
      "Gradient for decoder.decoder.3.bias: 7.025177661823534e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0003338335081934929\n",
      "Gradient for decoder.decoder.4.bias: 0.0003248603024985641\n",
      "Gradient for decoder.decoder.6.weight: 0.0009358293027617037\n",
      "Gradient for decoder.decoder.6.bias: 5.552272705244832e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.004841036628931761\n",
      "Gradient for encoder.encoder.0.bias: 7.212425101599251e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.0004362866748124361\n",
      "Gradient for encoder.encoder.1.bias: 0.000525167619343847\n",
      "Gradient for encoder.encoder.3.weight: 0.009672416374087334\n",
      "Gradient for encoder.encoder.3.bias: 9.197409500671938e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.002892612013965845\n",
      "Gradient for encoder.encoder.4.bias: 0.002426684135571122\n",
      "Gradient for encoder.mean.weight: 0.04052174836397171\n",
      "Gradient for encoder.mean.bias: 0.0019845706410706043\n",
      "Gradient for encoder.log_var.weight: 0.023425322026014328\n",
      "Gradient for encoder.log_var.bias: 0.001198572339490056\n",
      "Gradient for decoder.decoder.0.weight: 0.010729500092566013\n",
      "Gradient for decoder.decoder.0.bias: 9.212352408694002e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005342835211195052\n",
      "Gradient for decoder.decoder.1.bias: 0.0004667768080253154\n",
      "Gradient for decoder.decoder.3.weight: 0.010081164538860321\n",
      "Gradient for decoder.decoder.3.bias: 9.354513691439692e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0005686897202394903\n",
      "Gradient for decoder.decoder.4.bias: 0.0006594287697225809\n",
      "Gradient for decoder.decoder.6.weight: 0.0009769765892997384\n",
      "Gradient for decoder.decoder.6.bias: 5.811941809952259e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.004561553243547678\n",
      "Gradient for encoder.encoder.0.bias: 7.322093452388767e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.0003320257819723338\n",
      "Gradient for encoder.encoder.1.bias: 0.0003383863077033311\n",
      "Gradient for encoder.encoder.3.weight: 0.007245007902383804\n",
      "Gradient for encoder.encoder.3.bias: 8.726803307768094e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.002181818475946784\n",
      "Gradient for encoder.encoder.4.bias: 0.0017350530251860619\n",
      "Gradient for encoder.mean.weight: 0.03130979835987091\n",
      "Gradient for encoder.mean.bias: 0.0013198446249589324\n",
      "Gradient for encoder.log_var.weight: 0.01945757307112217\n",
      "Gradient for encoder.log_var.bias: 0.0009070729138329625\n",
      "Gradient for decoder.decoder.0.weight: 0.010518783703446388\n",
      "Gradient for decoder.decoder.0.bias: 8.931749090335117e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005348165868781507\n",
      "Gradient for decoder.decoder.1.bias: 0.0004533261526376009\n",
      "Gradient for decoder.decoder.3.weight: 0.010551411658525467\n",
      "Gradient for decoder.decoder.3.bias: 8.585269994920708e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0004489630227908492\n",
      "Gradient for decoder.decoder.4.bias: 0.00045334495371207595\n",
      "Gradient for decoder.decoder.6.weight: 0.0011544523295015097\n",
      "Gradient for decoder.decoder.6.bias: 9.014271927298978e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.004227251745760441\n",
      "Gradient for encoder.encoder.0.bias: 5.879624044580201e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.0003183044318575412\n",
      "Gradient for encoder.encoder.1.bias: 0.0003464228066150099\n",
      "Gradient for encoder.encoder.3.weight: 0.0066457041539251804\n",
      "Gradient for encoder.encoder.3.bias: 1.0039410275330951e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0023848325945436954\n",
      "Gradient for encoder.encoder.4.bias: 0.002242395421490073\n",
      "Gradient for encoder.mean.weight: 0.032643746584653854\n",
      "Gradient for encoder.mean.bias: 0.001586426398716867\n",
      "Gradient for encoder.log_var.weight: 0.020825492218136787\n",
      "Gradient for encoder.log_var.bias: 0.0010738696437329054\n",
      "Gradient for decoder.decoder.0.weight: 0.011678680777549744\n",
      "Gradient for decoder.decoder.0.bias: 1.0520511545264455e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0005967030883766711\n",
      "Gradient for decoder.decoder.1.bias: 0.0004986150888726115\n",
      "Gradient for decoder.decoder.3.weight: 0.011027791537344456\n",
      "Gradient for decoder.decoder.3.bias: 1.0438339775875605e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.000572958670090884\n",
      "Gradient for decoder.decoder.4.bias: 0.0006353164790198207\n",
      "Gradient for decoder.decoder.6.weight: 0.0010731311049312353\n",
      "Gradient for decoder.decoder.6.bias: 6.780591502320021e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.0069357408210635185\n",
      "Gradient for encoder.encoder.0.bias: 1.0885022917739295e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0004258316766936332\n",
      "Gradient for encoder.encoder.1.bias: 0.00040953123243525624\n",
      "Gradient for encoder.encoder.3.weight: 0.00922295544296503\n",
      "Gradient for encoder.encoder.3.bias: 9.792220506676941e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.0023167263716459274\n",
      "Gradient for encoder.encoder.4.bias: 0.0016860412433743477\n",
      "Gradient for encoder.mean.weight: 0.03199034184217453\n",
      "Gradient for encoder.mean.bias: 0.001255519688129425\n",
      "Gradient for encoder.log_var.weight: 0.01860194280743599\n",
      "Gradient for encoder.log_var.bias: 0.000888802926056087\n",
      "Gradient for decoder.decoder.0.weight: 0.008203557692468166\n",
      "Gradient for decoder.decoder.0.bias: 7.105929733519645e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0003763798449654132\n",
      "Gradient for decoder.decoder.1.bias: 0.00035763459163717926\n",
      "Gradient for decoder.decoder.3.weight: 0.007551074959337711\n",
      "Gradient for decoder.decoder.3.bias: 9.941606565755379e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0007158003281801939\n",
      "Gradient for decoder.decoder.4.bias: 0.0008924637222662568\n",
      "Gradient for decoder.decoder.6.weight: 0.001186245121061802\n",
      "Gradient for decoder.decoder.6.bias: 9.791234333533794e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.005866975989192724\n",
      "Gradient for encoder.encoder.0.bias: 8.983485830227345e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.00046564667718485\n",
      "Gradient for encoder.encoder.1.bias: 0.0004540144291240722\n",
      "Gradient for encoder.encoder.3.weight: 0.009979267604649067\n",
      "Gradient for encoder.encoder.3.bias: 9.428834102376271e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.002237076871097088\n",
      "Gradient for encoder.encoder.4.bias: 0.0016866722144186497\n",
      "Gradient for encoder.mean.weight: 0.03376191854476929\n",
      "Gradient for encoder.mean.bias: 0.0012248889543116093\n",
      "Gradient for encoder.log_var.weight: 0.017087962478399277\n",
      "Gradient for encoder.log_var.bias: 0.0008862498798407614\n",
      "Gradient for decoder.decoder.0.weight: 0.010181104764342308\n",
      "Gradient for decoder.decoder.0.bias: 8.66980653935201e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.00048806300037540495\n",
      "Gradient for decoder.decoder.1.bias: 0.00042420957470312715\n",
      "Gradient for decoder.decoder.3.weight: 0.009558483958244324\n",
      "Gradient for decoder.decoder.3.bias: 7.553292713513571e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00035163023858331144\n",
      "Gradient for decoder.decoder.4.bias: 0.00033682878711260855\n",
      "Gradient for decoder.decoder.6.weight: 0.000996894552372396\n",
      "Gradient for decoder.decoder.6.bias: 5.818712816108018e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.006064657121896744\n",
      "Gradient for encoder.encoder.0.bias: 8.830982820007272e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.000370401656255126\n",
      "Gradient for encoder.encoder.1.bias: 0.0003535534779075533\n",
      "Gradient for encoder.encoder.3.weight: 0.007887800224125385\n",
      "Gradient for encoder.encoder.3.bias: 1.0454104248935892e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0023604382295161486\n",
      "Gradient for encoder.encoder.4.bias: 0.001953911269083619\n",
      "Gradient for encoder.mean.weight: 0.03087017871439457\n",
      "Gradient for encoder.mean.bias: 0.0014933667844161391\n",
      "Gradient for encoder.log_var.weight: 0.017696784809231758\n",
      "Gradient for encoder.log_var.bias: 0.000842224748339504\n",
      "Gradient for decoder.decoder.0.weight: 0.009390952065587044\n",
      "Gradient for decoder.decoder.0.bias: 8.658803535288584e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.00045298002078197896\n",
      "Gradient for decoder.decoder.1.bias: 0.0003816332027781755\n",
      "Gradient for decoder.decoder.3.weight: 0.008737040683627129\n",
      "Gradient for decoder.decoder.3.bias: 7.179377925492503e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0003561503835953772\n",
      "Gradient for decoder.decoder.4.bias: 0.0003355053486302495\n",
      "Gradient for decoder.decoder.6.weight: 0.0010700576240196824\n",
      "Gradient for decoder.decoder.6.bias: 7.390890823444352e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.006394092459231615\n",
      "Gradient for encoder.encoder.0.bias: 9.774568307530096e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.0004181574913673103\n",
      "Gradient for encoder.encoder.1.bias: 0.00042930449126288295\n",
      "Gradient for encoder.encoder.3.weight: 0.008790837600827217\n",
      "Gradient for encoder.encoder.3.bias: 9.946311829711618e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.0025909359101206064\n",
      "Gradient for encoder.encoder.4.bias: 0.0022780203726142645\n",
      "Gradient for encoder.mean.weight: 0.0334952250123024\n",
      "Gradient for encoder.mean.bias: 0.0015666557010263205\n",
      "Gradient for encoder.log_var.weight: 0.019839681684970856\n",
      "Gradient for encoder.log_var.bias: 0.000917537254281342\n",
      "Gradient for decoder.decoder.0.weight: 0.008437558077275753\n",
      "Gradient for decoder.decoder.0.bias: 6.694986925959157e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0004401519545353949\n",
      "Gradient for decoder.decoder.1.bias: 0.0003722692490555346\n",
      "Gradient for decoder.decoder.3.weight: 0.00785874668508768\n",
      "Gradient for decoder.decoder.3.bias: 6.09677655583063e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0003420017601456493\n",
      "Gradient for decoder.decoder.4.bias: 0.00034117206814698875\n",
      "Gradient for decoder.decoder.6.weight: 0.0009631596622057259\n",
      "Gradient for decoder.decoder.6.bias: 5.853416587342508e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.004951655399054289\n",
      "Gradient for encoder.encoder.0.bias: 7.342959573719554e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.000372795999282971\n",
      "Gradient for encoder.encoder.1.bias: 0.0003228878485970199\n",
      "Gradient for encoder.encoder.3.weight: 0.008143098093569279\n",
      "Gradient for encoder.encoder.3.bias: 8.247123817195501e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.0024054409004747868\n",
      "Gradient for encoder.encoder.4.bias: 0.0017989665502682328\n",
      "Gradient for encoder.mean.weight: 0.033695872873067856\n",
      "Gradient for encoder.mean.bias: 0.0013358051655814052\n",
      "Gradient for encoder.log_var.weight: 0.019827235490083694\n",
      "Gradient for encoder.log_var.bias: 0.0008410780574195087\n",
      "Gradient for decoder.decoder.0.weight: 0.010390190407633781\n",
      "Gradient for decoder.decoder.0.bias: 9.456947724917342e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005267014494165778\n",
      "Gradient for decoder.decoder.1.bias: 0.00043650739826261997\n",
      "Gradient for decoder.decoder.3.weight: 0.009694687090814114\n",
      "Gradient for decoder.decoder.3.bias: 7.05671146516984e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0003502742329146713\n",
      "Gradient for decoder.decoder.4.bias: 0.0003230640140827745\n",
      "Gradient for decoder.decoder.6.weight: 0.0009527513757348061\n",
      "Gradient for decoder.decoder.6.bias: 5.0950235163327307e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.006175172049552202\n",
      "Gradient for encoder.encoder.0.bias: 9.274899424871474e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.00043992881546728313\n",
      "Gradient for encoder.encoder.1.bias: 0.0004150542081333697\n",
      "Gradient for encoder.encoder.3.weight: 0.009635092690587044\n",
      "Gradient for encoder.encoder.3.bias: 9.26535861922595e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.002333303214982152\n",
      "Gradient for encoder.encoder.4.bias: 0.0017399563221260905\n",
      "Gradient for encoder.mean.weight: 0.033876385539770126\n",
      "Gradient for encoder.mean.bias: 0.001407987205311656\n",
      "Gradient for encoder.log_var.weight: 0.017801526933908463\n",
      "Gradient for encoder.log_var.bias: 0.000850452808663249\n",
      "Gradient for decoder.decoder.0.weight: 0.009110050275921822\n",
      "Gradient for decoder.decoder.0.bias: 7.814628805169477e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0004498241760302335\n",
      "Gradient for decoder.decoder.1.bias: 0.00042106764158234\n",
      "Gradient for decoder.decoder.3.weight: 0.008493338711559772\n",
      "Gradient for decoder.decoder.3.bias: 7.147969716125857e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0003812787472270429\n",
      "Gradient for decoder.decoder.4.bias: 0.000411539658671245\n",
      "Gradient for decoder.decoder.6.weight: 0.0010138665093109012\n",
      "Gradient for decoder.decoder.6.bias: 6.765164289390668e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.004496515262871981\n",
      "Gradient for encoder.encoder.0.bias: 6.939889635182439e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.0003888839855790138\n",
      "Gradient for encoder.encoder.1.bias: 0.0003288878360763192\n",
      "Gradient for encoder.encoder.3.weight: 0.008537638932466507\n",
      "Gradient for encoder.encoder.3.bias: 8.673669421588315e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.0023754057474434376\n",
      "Gradient for encoder.encoder.4.bias: 0.001689722528681159\n",
      "Gradient for encoder.mean.weight: 0.03478063642978668\n",
      "Gradient for encoder.mean.bias: 0.0012979749590158463\n",
      "Gradient for encoder.log_var.weight: 0.01892196387052536\n",
      "Gradient for encoder.log_var.bias: 0.0007673315703868866\n",
      "Gradient for decoder.decoder.0.weight: 0.010912172496318817\n",
      "Gradient for decoder.decoder.0.bias: 8.818501484597618e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005472522461786866\n",
      "Gradient for decoder.decoder.1.bias: 0.0004329371149651706\n",
      "Gradient for decoder.decoder.3.weight: 0.009905076585710049\n",
      "Gradient for decoder.decoder.3.bias: 7.931261897242692e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00036049485788680613\n",
      "Gradient for decoder.decoder.4.bias: 0.0003093301202170551\n",
      "Gradient for decoder.decoder.6.weight: 0.0010061603970825672\n",
      "Gradient for decoder.decoder.6.bias: 6.176593160489574e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training VAE Epoch:  51%|█████     | 40/79 [00:00<00:00, 67.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient for encoder.encoder.0.weight: 0.004067372530698776\n",
      "Gradient for encoder.encoder.0.bias: 6.029691069359133e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.00033248410909436643\n",
      "Gradient for encoder.encoder.1.bias: 0.0003440474101807922\n",
      "Gradient for encoder.encoder.3.weight: 0.006964250933378935\n",
      "Gradient for encoder.encoder.3.bias: 9.220346014471303e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.0025597859639674425\n",
      "Gradient for encoder.encoder.4.bias: 0.002246622694656253\n",
      "Gradient for encoder.mean.weight: 0.0341653935611248\n",
      "Gradient for encoder.mean.bias: 0.0016594104235991836\n",
      "Gradient for encoder.log_var.weight: 0.02249205857515335\n",
      "Gradient for encoder.log_var.bias: 0.0011323974467813969\n",
      "Gradient for decoder.decoder.0.weight: 0.011867823079228401\n",
      "Gradient for decoder.decoder.0.bias: 1.030680749081192e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0005634582485072315\n",
      "Gradient for decoder.decoder.1.bias: 0.0005035210051573813\n",
      "Gradient for decoder.decoder.3.weight: 0.011180052533745766\n",
      "Gradient for decoder.decoder.3.bias: 9.03077890246351e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0005135034443810582\n",
      "Gradient for decoder.decoder.4.bias: 0.0004959410289302468\n",
      "Gradient for decoder.decoder.6.weight: 0.0010282918810844421\n",
      "Gradient for decoder.decoder.6.bias: 6.22557636233978e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.006467371713370085\n",
      "Gradient for encoder.encoder.0.bias: 9.622133818887324e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.0003969506360590458\n",
      "Gradient for encoder.encoder.1.bias: 0.0003646894183475524\n",
      "Gradient for encoder.encoder.3.weight: 0.008590899407863617\n",
      "Gradient for encoder.encoder.3.bias: 9.3663556077761e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.0021318229846656322\n",
      "Gradient for encoder.encoder.4.bias: 0.0018035987159237266\n",
      "Gradient for encoder.mean.weight: 0.03057887591421604\n",
      "Gradient for encoder.mean.bias: 0.0012252313317731023\n",
      "Gradient for encoder.log_var.weight: 0.019017118960618973\n",
      "Gradient for encoder.log_var.bias: 0.000958550488576293\n",
      "Gradient for decoder.decoder.0.weight: 0.008846241049468517\n",
      "Gradient for decoder.decoder.0.bias: 7.514390498730705e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0004558024520520121\n",
      "Gradient for decoder.decoder.1.bias: 0.0003725461720023304\n",
      "Gradient for decoder.decoder.3.weight: 0.00875264685600996\n",
      "Gradient for decoder.decoder.3.bias: 6.597395546537044e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00032565760193392634\n",
      "Gradient for decoder.decoder.4.bias: 0.00028412428218871355\n",
      "Gradient for decoder.decoder.6.weight: 0.00098645337857306\n",
      "Gradient for decoder.decoder.6.bias: 6.214308814378455e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.007706838194280863\n",
      "Gradient for encoder.encoder.0.bias: 1.0603659443553237e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.00040619552601128817\n",
      "Gradient for encoder.encoder.1.bias: 0.0004092399904038757\n",
      "Gradient for encoder.encoder.3.weight: 0.008528457954525948\n",
      "Gradient for encoder.encoder.3.bias: 9.482231666524399e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.001987684518098831\n",
      "Gradient for encoder.encoder.4.bias: 0.0014817212941125035\n",
      "Gradient for encoder.mean.weight: 0.027955150231719017\n",
      "Gradient for encoder.mean.bias: 0.001228030538186431\n",
      "Gradient for encoder.log_var.weight: 0.01712610572576523\n",
      "Gradient for encoder.log_var.bias: 0.0007465568487532437\n",
      "Gradient for decoder.decoder.0.weight: 0.008398428559303284\n",
      "Gradient for decoder.decoder.0.bias: 7.05788344435021e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0004166451108176261\n",
      "Gradient for decoder.decoder.1.bias: 0.0003468669892754406\n",
      "Gradient for decoder.decoder.3.weight: 0.008159912191331387\n",
      "Gradient for decoder.decoder.3.bias: 7.962924764015611e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0004806173383258283\n",
      "Gradient for decoder.decoder.4.bias: 0.0005750530981458724\n",
      "Gradient for decoder.decoder.6.weight: 0.0011953009525313973\n",
      "Gradient for decoder.decoder.6.bias: 9.340843826066703e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.005554468370974064\n",
      "Gradient for encoder.encoder.0.bias: 8.155832779965788e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.0003968914388678968\n",
      "Gradient for encoder.encoder.1.bias: 0.0003866088227368891\n",
      "Gradient for encoder.encoder.3.weight: 0.008639835752546787\n",
      "Gradient for encoder.encoder.3.bias: 8.557343722515043e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.002165744546800852\n",
      "Gradient for encoder.encoder.4.bias: 0.0016543493838980794\n",
      "Gradient for encoder.mean.weight: 0.03129100799560547\n",
      "Gradient for encoder.mean.bias: 0.0012403043219819665\n",
      "Gradient for encoder.log_var.weight: 0.017892999574542046\n",
      "Gradient for encoder.log_var.bias: 0.0008448773878626525\n",
      "Gradient for decoder.decoder.0.weight: 0.009733517654240131\n",
      "Gradient for decoder.decoder.0.bias: 9.327760785993178e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.000516629486810416\n",
      "Gradient for decoder.decoder.1.bias: 0.00044067850103601813\n",
      "Gradient for decoder.decoder.3.weight: 0.009458349086344242\n",
      "Gradient for decoder.decoder.3.bias: 8.036991905324697e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00034397109993733466\n",
      "Gradient for decoder.decoder.4.bias: 0.00029773288406431675\n",
      "Gradient for decoder.decoder.6.weight: 0.0009300581878051162\n",
      "Gradient for decoder.decoder.6.bias: 4.78611073049251e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.006360166240483522\n",
      "Gradient for encoder.encoder.0.bias: 1.0531442037886585e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0004336038255132735\n",
      "Gradient for encoder.encoder.1.bias: 0.0004999213269911706\n",
      "Gradient for encoder.encoder.3.weight: 0.009790061973035336\n",
      "Gradient for encoder.encoder.3.bias: 8.891822694812035e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.002172526903450489\n",
      "Gradient for encoder.encoder.4.bias: 0.0013989650178700686\n",
      "Gradient for encoder.mean.weight: 0.03248681500554085\n",
      "Gradient for encoder.mean.bias: 0.0012036026455461979\n",
      "Gradient for encoder.log_var.weight: 0.01966150291264057\n",
      "Gradient for encoder.log_var.bias: 0.0008601018344052136\n",
      "Gradient for decoder.decoder.0.weight: 0.010008618235588074\n",
      "Gradient for decoder.decoder.0.bias: 8.311844962305415e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.00047172102495096624\n",
      "Gradient for decoder.decoder.1.bias: 0.000400591641664505\n",
      "Gradient for decoder.decoder.3.weight: 0.008813836611807346\n",
      "Gradient for decoder.decoder.3.bias: 6.546442554711263e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00035888064303435385\n",
      "Gradient for decoder.decoder.4.bias: 0.00035836020833812654\n",
      "Gradient for decoder.decoder.6.weight: 0.0008997715776786208\n",
      "Gradient for decoder.decoder.6.bias: 4.703827653429471e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.006248957011848688\n",
      "Gradient for encoder.encoder.0.bias: 8.956751139377328e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.0003734530764631927\n",
      "Gradient for encoder.encoder.1.bias: 0.0003716711653396487\n",
      "Gradient for encoder.encoder.3.weight: 0.008007810451090336\n",
      "Gradient for encoder.encoder.3.bias: 9.190039007567208e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.0021101930178701878\n",
      "Gradient for encoder.encoder.4.bias: 0.0018206372624263167\n",
      "Gradient for encoder.mean.weight: 0.02921154536306858\n",
      "Gradient for encoder.mean.bias: 0.0014493304770439863\n",
      "Gradient for encoder.log_var.weight: 0.018746737390756607\n",
      "Gradient for encoder.log_var.bias: 0.0009271872113458812\n",
      "Gradient for decoder.decoder.0.weight: 0.00885156448930502\n",
      "Gradient for decoder.decoder.0.bias: 7.622878717139514e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0004569136071950197\n",
      "Gradient for decoder.decoder.1.bias: 0.00038345513166859746\n",
      "Gradient for decoder.decoder.3.weight: 0.008502679876983166\n",
      "Gradient for decoder.decoder.3.bias: 6.342859570906967e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00029915387858636677\n",
      "Gradient for decoder.decoder.4.bias: 0.0002846640709321946\n",
      "Gradient for decoder.decoder.6.weight: 0.0009458059794269502\n",
      "Gradient for decoder.decoder.6.bias: 5.090743798064068e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.009512308053672314\n",
      "Gradient for encoder.encoder.0.bias: 1.2515431399573451e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0004401348123792559\n",
      "Gradient for encoder.encoder.1.bias: 0.0004091932496521622\n",
      "Gradient for encoder.encoder.3.weight: 0.00958946906030178\n",
      "Gradient for encoder.encoder.3.bias: 1.0584715048889137e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.002332062693312764\n",
      "Gradient for encoder.encoder.4.bias: 0.0021451939828693867\n",
      "Gradient for encoder.mean.weight: 0.03220439702272415\n",
      "Gradient for encoder.mean.bias: 0.0016351777594536543\n",
      "Gradient for encoder.log_var.weight: 0.01908394880592823\n",
      "Gradient for encoder.log_var.bias: 0.001031541614793241\n",
      "Gradient for decoder.decoder.0.weight: 0.00777354696765542\n",
      "Gradient for decoder.decoder.0.bias: 6.872357544152052e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0003590006963349879\n",
      "Gradient for decoder.decoder.1.bias: 0.00029341201297938824\n",
      "Gradient for decoder.decoder.3.weight: 0.00716989254578948\n",
      "Gradient for decoder.decoder.3.bias: 7.539565499703471e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.000475575914606452\n",
      "Gradient for decoder.decoder.4.bias: 0.0005573415546678007\n",
      "Gradient for decoder.decoder.6.weight: 0.0010785392951220274\n",
      "Gradient for decoder.decoder.6.bias: 8.159361459547654e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.004052489530295134\n",
      "Gradient for encoder.encoder.0.bias: 5.800992932541993e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.00030528937350027263\n",
      "Gradient for encoder.encoder.1.bias: 0.00037487264489755034\n",
      "Gradient for encoder.encoder.3.weight: 0.006962766405194998\n",
      "Gradient for encoder.encoder.3.bias: 9.336250522684608e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.002860077889636159\n",
      "Gradient for encoder.encoder.4.bias: 0.002291156444698572\n",
      "Gradient for encoder.mean.weight: 0.04197726771235466\n",
      "Gradient for encoder.mean.bias: 0.001576766138896346\n",
      "Gradient for encoder.log_var.weight: 0.023891696706414223\n",
      "Gradient for encoder.log_var.bias: 0.0011830766452476382\n",
      "Gradient for decoder.decoder.0.weight: 0.011078057810664177\n",
      "Gradient for decoder.decoder.0.bias: 9.440199316701481e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005357458139769733\n",
      "Gradient for decoder.decoder.1.bias: 0.00042789336293935776\n",
      "Gradient for decoder.decoder.3.weight: 0.010857142508029938\n",
      "Gradient for decoder.decoder.3.bias: 7.628586651264868e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00038506503915414214\n",
      "Gradient for decoder.decoder.4.bias: 0.00035416425089351833\n",
      "Gradient for decoder.decoder.6.weight: 0.0008907483424991369\n",
      "Gradient for decoder.decoder.6.bias: 4.138740405323915e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.006745518650859594\n",
      "Gradient for encoder.encoder.0.bias: 9.107073602188098e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.00043945040670223534\n",
      "Gradient for encoder.encoder.1.bias: 0.0003751534968614578\n",
      "Gradient for encoder.encoder.3.weight: 0.009528134018182755\n",
      "Gradient for encoder.encoder.3.bias: 9.57511500643271e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.002141496865078807\n",
      "Gradient for encoder.encoder.4.bias: 0.0016690850025042892\n",
      "Gradient for encoder.mean.weight: 0.031657807528972626\n",
      "Gradient for encoder.mean.bias: 0.001132283709011972\n",
      "Gradient for encoder.log_var.weight: 0.015551496297121048\n",
      "Gradient for encoder.log_var.bias: 0.0007955722976475954\n",
      "Gradient for decoder.decoder.0.weight: 0.009840047918260098\n",
      "Gradient for decoder.decoder.0.bias: 9.180946280995528e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.00048794844769872725\n",
      "Gradient for decoder.decoder.1.bias: 0.0004129625449422747\n",
      "Gradient for decoder.decoder.3.weight: 0.009084319695830345\n",
      "Gradient for decoder.decoder.3.bias: 7.78737421769371e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0003473576216492802\n",
      "Gradient for decoder.decoder.4.bias: 0.00032300909515470266\n",
      "Gradient for decoder.decoder.6.weight: 0.0009524587076157331\n",
      "Gradient for decoder.decoder.6.bias: 5.458592568174936e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.004776387475430965\n",
      "Gradient for encoder.encoder.0.bias: 7.354731407227533e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.0003746974398382008\n",
      "Gradient for encoder.encoder.1.bias: 0.0003839683486148715\n",
      "Gradient for encoder.encoder.3.weight: 0.007901359349489212\n",
      "Gradient for encoder.encoder.3.bias: 1.0324480159695781e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.002310646465048194\n",
      "Gradient for encoder.encoder.4.bias: 0.0022856860887259245\n",
      "Gradient for encoder.mean.weight: 0.033850476145744324\n",
      "Gradient for encoder.mean.bias: 0.0018367964075878263\n",
      "Gradient for encoder.log_var.weight: 0.0198272243142128\n",
      "Gradient for encoder.log_var.bias: 0.0011923032579943538\n",
      "Gradient for decoder.decoder.0.weight: 0.011076477356255054\n",
      "Gradient for decoder.decoder.0.bias: 9.850562726620993e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005399066139943898\n",
      "Gradient for decoder.decoder.1.bias: 0.0004620192921720445\n",
      "Gradient for decoder.decoder.3.weight: 0.010465363971889019\n",
      "Gradient for decoder.decoder.3.bias: 8.203960427666246e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0003583727520890534\n",
      "Gradient for decoder.decoder.4.bias: 0.00033105287002399564\n",
      "Gradient for decoder.decoder.6.weight: 0.0009812070056796074\n",
      "Gradient for decoder.decoder.6.bias: 5.832816532347351e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.007838146761059761\n",
      "Gradient for encoder.encoder.0.bias: 1.253984503041261e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0004186915757600218\n",
      "Gradient for encoder.encoder.1.bias: 0.0004022944485768676\n",
      "Gradient for encoder.encoder.3.weight: 0.009137021377682686\n",
      "Gradient for encoder.encoder.3.bias: 9.289633645659379e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.002069368027150631\n",
      "Gradient for encoder.encoder.4.bias: 0.0016670377226546407\n",
      "Gradient for encoder.mean.weight: 0.030741345137357712\n",
      "Gradient for encoder.mean.bias: 0.001299715950153768\n",
      "Gradient for encoder.log_var.weight: 0.01747896522283554\n",
      "Gradient for encoder.log_var.bias: 0.0008897049119696021\n",
      "Gradient for decoder.decoder.0.weight: 0.00825145747512579\n",
      "Gradient for decoder.decoder.0.bias: 7.211743008328497e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0003796723030973226\n",
      "Gradient for decoder.decoder.1.bias: 0.00033169484231621027\n",
      "Gradient for decoder.decoder.3.weight: 0.007566908374428749\n",
      "Gradient for decoder.decoder.3.bias: 8.7941751103493e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0005493698408827186\n",
      "Gradient for decoder.decoder.4.bias: 0.0006787104066461325\n",
      "Gradient for decoder.decoder.6.weight: 0.0012215974275022745\n",
      "Gradient for decoder.decoder.6.bias: 0.00010131471208296716\n",
      "Gradient for encoder.encoder.0.weight: 0.004672873765230179\n",
      "Gradient for encoder.encoder.0.bias: 7.462133341795685e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.00038088951259851456\n",
      "Gradient for encoder.encoder.1.bias: 0.0004045841342303902\n",
      "Gradient for encoder.encoder.3.weight: 0.00864443276077509\n",
      "Gradient for encoder.encoder.3.bias: 8.155102981799445e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.002241784706711769\n",
      "Gradient for encoder.encoder.4.bias: 0.0015576847363263369\n",
      "Gradient for encoder.mean.weight: 0.031925708055496216\n",
      "Gradient for encoder.mean.bias: 0.0012326284777373075\n",
      "Gradient for encoder.log_var.weight: 0.019425060600042343\n",
      "Gradient for encoder.log_var.bias: 0.0007783118635416031\n",
      "Gradient for decoder.decoder.0.weight: 0.010182058438658714\n",
      "Gradient for decoder.decoder.0.bias: 8.421647407219623e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005127857439219952\n",
      "Gradient for decoder.decoder.1.bias: 0.00040570099372416735\n",
      "Gradient for decoder.decoder.3.weight: 0.009739115834236145\n",
      "Gradient for decoder.decoder.3.bias: 7.105927651851474e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.000370064313756302\n",
      "Gradient for decoder.decoder.4.bias: 0.0003092372207902372\n",
      "Gradient for decoder.decoder.6.weight: 0.000969730201177299\n",
      "Gradient for decoder.decoder.6.bias: 5.6828746892279014e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.004585862159729004\n",
      "Gradient for encoder.encoder.0.bias: 6.649378096745817e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.0003231027803849429\n",
      "Gradient for encoder.encoder.1.bias: 0.0003211453149560839\n",
      "Gradient for encoder.encoder.3.weight: 0.007166618015617132\n",
      "Gradient for encoder.encoder.3.bias: 8.914643329083205e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.002244646195322275\n",
      "Gradient for encoder.encoder.4.bias: 0.0018580462783575058\n",
      "Gradient for encoder.mean.weight: 0.03270232677459717\n",
      "Gradient for encoder.mean.bias: 0.0012624544324353337\n",
      "Gradient for encoder.log_var.weight: 0.0173651073127985\n",
      "Gradient for encoder.log_var.bias: 0.0007951624575071037\n",
      "Gradient for decoder.decoder.0.weight: 0.010848583653569221\n",
      "Gradient for decoder.decoder.0.bias: 9.102511105973932e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005371250445023179\n",
      "Gradient for decoder.decoder.1.bias: 0.00045990475337021053\n",
      "Gradient for decoder.decoder.3.weight: 0.010064409114420414\n",
      "Gradient for decoder.decoder.3.bias: 7.752604808120012e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0003799804544541985\n",
      "Gradient for decoder.decoder.4.bias: 0.0003145239898003638\n",
      "Gradient for decoder.decoder.6.weight: 0.0009332226472906768\n",
      "Gradient for decoder.decoder.6.bias: 4.064989843755029e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.005548042245209217\n",
      "Gradient for encoder.encoder.0.bias: 8.044464400169815e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.0002902497071772814\n",
      "Gradient for encoder.encoder.1.bias: 0.0003039061848539859\n",
      "Gradient for encoder.encoder.3.weight: 0.006619810592383146\n",
      "Gradient for encoder.encoder.3.bias: 8.284089386689786e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.0020298955496400595\n",
      "Gradient for encoder.encoder.4.bias: 0.0013130165170878172\n",
      "Gradient for encoder.mean.weight: 0.02923610247671604\n",
      "Gradient for encoder.mean.bias: 0.0009955839486792684\n",
      "Gradient for encoder.log_var.weight: 0.01756158284842968\n",
      "Gradient for encoder.log_var.bias: 0.000717652786988765\n",
      "Gradient for decoder.decoder.0.weight: 0.01043090969324112\n",
      "Gradient for decoder.decoder.0.bias: 8.070195900433674e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.00048006538418121636\n",
      "Gradient for decoder.decoder.1.bias: 0.0004785521305166185\n",
      "Gradient for decoder.decoder.3.weight: 0.009587801061570644\n",
      "Gradient for decoder.decoder.3.bias: 7.088627601570252e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0003554614377208054\n",
      "Gradient for decoder.decoder.4.bias: 0.00034142943331971765\n",
      "Gradient for decoder.decoder.6.weight: 0.0009647718979977071\n",
      "Gradient for decoder.decoder.6.bias: 5.348526974557899e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.004639576654881239\n",
      "Gradient for encoder.encoder.0.bias: 6.411285131263655e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.00031214370392262936\n",
      "Gradient for encoder.encoder.1.bias: 0.00033080845605582\n",
      "Gradient for encoder.encoder.3.weight: 0.007234544027596712\n",
      "Gradient for encoder.encoder.3.bias: 8.518444977179129e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.002105837222188711\n",
      "Gradient for encoder.encoder.4.bias: 0.0014361192006617785\n",
      "Gradient for encoder.mean.weight: 0.03210919350385666\n",
      "Gradient for encoder.mean.bias: 0.0009906850755214691\n",
      "Gradient for encoder.log_var.weight: 0.017806239426136017\n",
      "Gradient for encoder.log_var.bias: 0.0007717814296483994\n",
      "Gradient for decoder.decoder.0.weight: 0.011227229610085487\n",
      "Gradient for decoder.decoder.0.bias: 9.76719677359128e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005390705773606896\n",
      "Gradient for decoder.decoder.1.bias: 0.0004814580315724015\n",
      "Gradient for decoder.decoder.3.weight: 0.010311072692275047\n",
      "Gradient for decoder.decoder.3.bias: 7.956740821768449e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00042829790618270636\n",
      "Gradient for decoder.decoder.4.bias: 0.0003815052332356572\n",
      "Gradient for decoder.decoder.6.weight: 0.001012701541185379\n",
      "Gradient for decoder.decoder.6.bias: 6.0884929553139955e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training VAE Epoch:  71%|███████   | 56/79 [00:00<00:00, 72.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient for encoder.encoder.0.weight: 0.004174842033535242\n",
      "Gradient for encoder.encoder.0.bias: 5.87389815606687e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.0002939326805062592\n",
      "Gradient for encoder.encoder.1.bias: 0.0003458948340266943\n",
      "Gradient for encoder.encoder.3.weight: 0.006422374863177538\n",
      "Gradient for encoder.encoder.3.bias: 7.621776126898183e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.0022780734580010176\n",
      "Gradient for encoder.encoder.4.bias: 0.0016101785004138947\n",
      "Gradient for encoder.mean.weight: 0.034659821540117264\n",
      "Gradient for encoder.mean.bias: 0.0010733762755990028\n",
      "Gradient for encoder.log_var.weight: 0.019604085013270378\n",
      "Gradient for encoder.log_var.bias: 0.000778059009462595\n",
      "Gradient for decoder.decoder.0.weight: 0.010646865703165531\n",
      "Gradient for decoder.decoder.0.bias: 8.607160123519364e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005112225189805031\n",
      "Gradient for decoder.decoder.1.bias: 0.0004310951626393944\n",
      "Gradient for decoder.decoder.3.weight: 0.009883557446300983\n",
      "Gradient for decoder.decoder.3.bias: 7.473845847760785e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0004049850977025926\n",
      "Gradient for decoder.decoder.4.bias: 0.0004143539408687502\n",
      "Gradient for decoder.decoder.6.weight: 0.0010098746279254556\n",
      "Gradient for decoder.decoder.6.bias: 7.248556357808411e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.008267680183053017\n",
      "Gradient for encoder.encoder.0.bias: 1.2091053852580913e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0004995811614207923\n",
      "Gradient for encoder.encoder.1.bias: 0.0004365030617918819\n",
      "Gradient for encoder.encoder.3.weight: 0.011236702091991901\n",
      "Gradient for encoder.encoder.3.bias: 1.0306437647766842e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0025739031843841076\n",
      "Gradient for encoder.encoder.4.bias: 0.001955420942977071\n",
      "Gradient for encoder.mean.weight: 0.03580918163061142\n",
      "Gradient for encoder.mean.bias: 0.0013383128680288792\n",
      "Gradient for encoder.log_var.weight: 0.024343039840459824\n",
      "Gradient for encoder.log_var.bias: 0.0008745351224206388\n",
      "Gradient for decoder.decoder.0.weight: 0.00934489257633686\n",
      "Gradient for decoder.decoder.0.bias: 7.986902805789953e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.00047557102516293526\n",
      "Gradient for decoder.decoder.1.bias: 0.00041406243690289557\n",
      "Gradient for decoder.decoder.3.weight: 0.00887345615774393\n",
      "Gradient for decoder.decoder.3.bias: 7.061224521764942e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00038569027674384415\n",
      "Gradient for decoder.decoder.4.bias: 0.0003791155177168548\n",
      "Gradient for decoder.decoder.6.weight: 0.0011285509681329131\n",
      "Gradient for decoder.decoder.6.bias: 8.17957625258714e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.006968443747609854\n",
      "Gradient for encoder.encoder.0.bias: 1.2170939603373121e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.00041748961666598916\n",
      "Gradient for encoder.encoder.1.bias: 0.00038738135481253266\n",
      "Gradient for encoder.encoder.3.weight: 0.009100926108658314\n",
      "Gradient for encoder.encoder.3.bias: 9.15761425024364e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.0020947465673089027\n",
      "Gradient for encoder.encoder.4.bias: 0.001675437088124454\n",
      "Gradient for encoder.mean.weight: 0.031925030052661896\n",
      "Gradient for encoder.mean.bias: 0.0013204378774389625\n",
      "Gradient for encoder.log_var.weight: 0.017386768013238907\n",
      "Gradient for encoder.log_var.bias: 0.0007966080447658896\n",
      "Gradient for decoder.decoder.0.weight: 0.007810378447175026\n",
      "Gradient for decoder.decoder.0.bias: 6.853732165135185e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0003988608077634126\n",
      "Gradient for decoder.decoder.1.bias: 0.0003392696671653539\n",
      "Gradient for decoder.decoder.3.weight: 0.007239884231239557\n",
      "Gradient for decoder.decoder.3.bias: 5.562917834711634e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00025711458874866366\n",
      "Gradient for decoder.decoder.4.bias: 0.00023457406496163458\n",
      "Gradient for decoder.decoder.6.weight: 0.0009232625016011298\n",
      "Gradient for decoder.decoder.6.bias: 5.300697739585303e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.006594500970095396\n",
      "Gradient for encoder.encoder.0.bias: 9.79075327756096e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.0003676712804008275\n",
      "Gradient for encoder.encoder.1.bias: 0.0004186240257695317\n",
      "Gradient for encoder.encoder.3.weight: 0.00866685900837183\n",
      "Gradient for encoder.encoder.3.bias: 8.774760779095558e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.002381180180236697\n",
      "Gradient for encoder.encoder.4.bias: 0.001671844394877553\n",
      "Gradient for encoder.mean.weight: 0.034527797251939774\n",
      "Gradient for encoder.mean.bias: 0.0013774338876828551\n",
      "Gradient for encoder.log_var.weight: 0.017273830249905586\n",
      "Gradient for encoder.log_var.bias: 0.000765046279411763\n",
      "Gradient for decoder.decoder.0.weight: 0.009074767120182514\n",
      "Gradient for decoder.decoder.0.bias: 7.860628814526649e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.00044753431575372815\n",
      "Gradient for decoder.decoder.1.bias: 0.00042213499546051025\n",
      "Gradient for decoder.decoder.3.weight: 0.008708889596164227\n",
      "Gradient for decoder.decoder.3.bias: 6.731624285771787e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00034909354872070253\n",
      "Gradient for decoder.decoder.4.bias: 0.0003482756146695465\n",
      "Gradient for decoder.decoder.6.weight: 0.0009243358508683741\n",
      "Gradient for decoder.decoder.6.bias: 5.005067214369774e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.0067787207663059235\n",
      "Gradient for encoder.encoder.0.bias: 1.0315828052887e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.00046433991519734263\n",
      "Gradient for encoder.encoder.1.bias: 0.00037558816256932914\n",
      "Gradient for encoder.encoder.3.weight: 0.010389626957476139\n",
      "Gradient for encoder.encoder.3.bias: 1.0159412200394513e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0023109184112399817\n",
      "Gradient for encoder.encoder.4.bias: 0.001754240831360221\n",
      "Gradient for encoder.mean.weight: 0.031047111377120018\n",
      "Gradient for encoder.mean.bias: 0.0011814875761047006\n",
      "Gradient for encoder.log_var.weight: 0.018782615661621094\n",
      "Gradient for encoder.log_var.bias: 0.0007384081254713237\n",
      "Gradient for decoder.decoder.0.weight: 0.009066720493137836\n",
      "Gradient for decoder.decoder.0.bias: 8.833585946055322e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0004333537654019892\n",
      "Gradient for decoder.decoder.1.bias: 0.00037182713276706636\n",
      "Gradient for decoder.decoder.3.weight: 0.008537657558918\n",
      "Gradient for decoder.decoder.3.bias: 7.584147893036075e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00032795529114082456\n",
      "Gradient for decoder.decoder.4.bias: 0.0002953415096271783\n",
      "Gradient for decoder.decoder.6.weight: 0.0008995973621495068\n",
      "Gradient for decoder.decoder.6.bias: 4.030929630971514e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.004130091518163681\n",
      "Gradient for encoder.encoder.0.bias: 6.057055898511798e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.0003413634258322418\n",
      "Gradient for encoder.encoder.1.bias: 0.0003208054695278406\n",
      "Gradient for encoder.encoder.3.weight: 0.00744680454954505\n",
      "Gradient for encoder.encoder.3.bias: 9.26065335526971e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.002917640842497349\n",
      "Gradient for encoder.encoder.4.bias: 0.0022789733484387398\n",
      "Gradient for encoder.mean.weight: 0.041663896292448044\n",
      "Gradient for encoder.mean.bias: 0.0012889835052192211\n",
      "Gradient for encoder.log_var.weight: 0.026746045798063278\n",
      "Gradient for encoder.log_var.bias: 0.0009725511190481484\n",
      "Gradient for decoder.decoder.0.weight: 0.011986777186393738\n",
      "Gradient for decoder.decoder.0.bias: 9.997023348029543e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005876055220142007\n",
      "Gradient for decoder.decoder.1.bias: 0.0005036310758441687\n",
      "Gradient for decoder.decoder.3.weight: 0.011309763416647911\n",
      "Gradient for decoder.decoder.3.bias: 8.593591116490273e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00047385084326379\n",
      "Gradient for decoder.decoder.4.bias: 0.000449086248409003\n",
      "Gradient for decoder.decoder.6.weight: 0.0010141445090994239\n",
      "Gradient for decoder.decoder.6.bias: 5.970413258182816e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.004886771086603403\n",
      "Gradient for encoder.encoder.0.bias: 7.031878551666537e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.00041308533400297165\n",
      "Gradient for encoder.encoder.1.bias: 0.00041785751818679273\n",
      "Gradient for encoder.encoder.3.weight: 0.009083973243832588\n",
      "Gradient for encoder.encoder.3.bias: 8.349870794788217e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.0023810190614312887\n",
      "Gradient for encoder.encoder.4.bias: 0.0016987742856144905\n",
      "Gradient for encoder.mean.weight: 0.03613836318254471\n",
      "Gradient for encoder.mean.bias: 0.0013286486500874162\n",
      "Gradient for encoder.log_var.weight: 0.021458273753523827\n",
      "Gradient for encoder.log_var.bias: 0.0008684443309903145\n",
      "Gradient for decoder.decoder.0.weight: 0.011599235236644745\n",
      "Gradient for decoder.decoder.0.bias: 9.667138617386328e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005319815827533603\n",
      "Gradient for decoder.decoder.1.bias: 0.0004745605983771384\n",
      "Gradient for decoder.decoder.3.weight: 0.010447703301906586\n",
      "Gradient for decoder.decoder.3.bias: 7.779640126548415e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00039448722964152694\n",
      "Gradient for decoder.decoder.4.bias: 0.00037392787635326385\n",
      "Gradient for decoder.decoder.6.weight: 0.0010744964238256216\n",
      "Gradient for decoder.decoder.6.bias: 7.197781087597832e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.005421797279268503\n",
      "Gradient for encoder.encoder.0.bias: 9.0227426224887e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.00037787441397085786\n",
      "Gradient for encoder.encoder.1.bias: 0.0003784298023674637\n",
      "Gradient for encoder.encoder.3.weight: 0.008678745478391647\n",
      "Gradient for encoder.encoder.3.bias: 8.944127383170297e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.002087849657982588\n",
      "Gradient for encoder.encoder.4.bias: 0.0015419617993757129\n",
      "Gradient for encoder.mean.weight: 0.029613960534334183\n",
      "Gradient for encoder.mean.bias: 0.0011167180491611362\n",
      "Gradient for encoder.log_var.weight: 0.016717951744794846\n",
      "Gradient for encoder.log_var.bias: 0.0008021436515264213\n",
      "Gradient for decoder.decoder.0.weight: 0.009411114268004894\n",
      "Gradient for decoder.decoder.0.bias: 8.161123166150475e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.000445402751211077\n",
      "Gradient for decoder.decoder.1.bias: 0.00036913540679961443\n",
      "Gradient for decoder.decoder.3.weight: 0.009063159115612507\n",
      "Gradient for decoder.decoder.3.bias: 7.329918616516551e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0003730077005457133\n",
      "Gradient for decoder.decoder.4.bias: 0.000339019374223426\n",
      "Gradient for decoder.decoder.6.weight: 0.0009586234227754176\n",
      "Gradient for decoder.decoder.6.bias: 5.5310702009592205e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.004637384787201881\n",
      "Gradient for encoder.encoder.0.bias: 6.244801550869816e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.000380237732315436\n",
      "Gradient for encoder.encoder.1.bias: 0.0003623362281359732\n",
      "Gradient for encoder.encoder.3.weight: 0.008673448115587234\n",
      "Gradient for encoder.encoder.3.bias: 8.997005918054413e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.002308401744812727\n",
      "Gradient for encoder.encoder.4.bias: 0.002032897900789976\n",
      "Gradient for encoder.mean.weight: 0.03489960357546806\n",
      "Gradient for encoder.mean.bias: 0.0015298776561394334\n",
      "Gradient for encoder.log_var.weight: 0.01820661686360836\n",
      "Gradient for encoder.log_var.bias: 0.0009914771653711796\n",
      "Gradient for decoder.decoder.0.weight: 0.010203123092651367\n",
      "Gradient for decoder.decoder.0.bias: 9.20748269295224e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005123686860315502\n",
      "Gradient for decoder.decoder.1.bias: 0.000428446801379323\n",
      "Gradient for decoder.decoder.3.weight: 0.009522001259028912\n",
      "Gradient for decoder.decoder.3.bias: 8.177810512099981e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00041014081216417253\n",
      "Gradient for decoder.decoder.4.bias: 0.00038008514093235135\n",
      "Gradient for decoder.decoder.6.weight: 0.0009736610227264464\n",
      "Gradient for decoder.decoder.6.bias: 5.0981634558411315e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.004211632534861565\n",
      "Gradient for encoder.encoder.0.bias: 6.281451053746778e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.0004139114171266556\n",
      "Gradient for encoder.encoder.1.bias: 0.00040402644663117826\n",
      "Gradient for encoder.encoder.3.weight: 0.009476191364228725\n",
      "Gradient for encoder.encoder.3.bias: 9.385828225738635e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.0032594141084700823\n",
      "Gradient for encoder.encoder.4.bias: 0.0022031001280993223\n",
      "Gradient for encoder.mean.weight: 0.04449468478560448\n",
      "Gradient for encoder.mean.bias: 0.001334592467173934\n",
      "Gradient for encoder.log_var.weight: 0.02383749559521675\n",
      "Gradient for encoder.log_var.bias: 0.0008242866606451571\n",
      "Gradient for decoder.decoder.0.weight: 0.011625382117927074\n",
      "Gradient for decoder.decoder.0.bias: 9.774146075836043e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005443823174573481\n",
      "Gradient for decoder.decoder.1.bias: 0.0004334762634243816\n",
      "Gradient for decoder.decoder.3.weight: 0.010593152604997158\n",
      "Gradient for decoder.decoder.3.bias: 8.937318246582393e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0004128557920921594\n",
      "Gradient for decoder.decoder.4.bias: 0.0003974545979872346\n",
      "Gradient for decoder.decoder.6.weight: 0.0009200800559483469\n",
      "Gradient for decoder.decoder.6.bias: 4.744795660371892e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.005626733880490065\n",
      "Gradient for encoder.encoder.0.bias: 9.266294329068891e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.0004810355603694916\n",
      "Gradient for encoder.encoder.1.bias: 0.00040393308154307306\n",
      "Gradient for encoder.encoder.3.weight: 0.010660694912075996\n",
      "Gradient for encoder.encoder.3.bias: 1.0680949180663646e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.002779001370072365\n",
      "Gradient for encoder.encoder.4.bias: 0.002119624288752675\n",
      "Gradient for encoder.mean.weight: 0.0390399768948555\n",
      "Gradient for encoder.mean.bias: 0.0014216381823644042\n",
      "Gradient for encoder.log_var.weight: 0.022571740671992302\n",
      "Gradient for encoder.log_var.bias: 0.0009801884880289435\n",
      "Gradient for decoder.decoder.0.weight: 0.008120130747556686\n",
      "Gradient for decoder.decoder.0.bias: 6.925189588447012e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.00041138005326502025\n",
      "Gradient for decoder.decoder.1.bias: 0.0003568399406503886\n",
      "Gradient for decoder.decoder.3.weight: 0.007685449440032244\n",
      "Gradient for decoder.decoder.3.bias: 7.124546785863828e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.000400760502088815\n",
      "Gradient for decoder.decoder.4.bias: 0.00043641196680255234\n",
      "Gradient for decoder.decoder.6.weight: 0.0009626788087189198\n",
      "Gradient for decoder.decoder.6.bias: 6.479616422438994e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.006225417833775282\n",
      "Gradient for encoder.encoder.0.bias: 9.531437271392829e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.0003858082927763462\n",
      "Gradient for encoder.encoder.1.bias: 0.0003435988037381321\n",
      "Gradient for encoder.encoder.3.weight: 0.008615614846348763\n",
      "Gradient for encoder.encoder.3.bias: 8.788963307138076e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.0022548846900463104\n",
      "Gradient for encoder.encoder.4.bias: 0.001781914266757667\n",
      "Gradient for encoder.mean.weight: 0.03186699002981186\n",
      "Gradient for encoder.mean.bias: 0.0015943987527862191\n",
      "Gradient for encoder.log_var.weight: 0.021226145327091217\n",
      "Gradient for encoder.log_var.bias: 0.000921413884498179\n",
      "Gradient for decoder.decoder.0.weight: 0.008983070962131023\n",
      "Gradient for decoder.decoder.0.bias: 6.955906683980828e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.00043429475044831634\n",
      "Gradient for decoder.decoder.1.bias: 0.00036707919207401574\n",
      "Gradient for decoder.decoder.3.weight: 0.008287045173346996\n",
      "Gradient for decoder.decoder.3.bias: 6.576997280127728e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00035507683060131967\n",
      "Gradient for decoder.decoder.4.bias: 0.0003412074875086546\n",
      "Gradient for decoder.decoder.6.weight: 0.0009717313223518431\n",
      "Gradient for decoder.decoder.6.bias: 5.843965845997445e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.004098068922758102\n",
      "Gradient for encoder.encoder.0.bias: 6.564557491345324e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.0005772932781837881\n",
      "Gradient for encoder.encoder.1.bias: 0.00038932551979087293\n",
      "Gradient for encoder.encoder.3.weight: 0.012270486913621426\n",
      "Gradient for encoder.encoder.3.bias: 8.978309762319725e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.0028035168070346117\n",
      "Gradient for encoder.encoder.4.bias: 0.0018757061334326863\n",
      "Gradient for encoder.mean.weight: 0.03883505240082741\n",
      "Gradient for encoder.mean.bias: 0.00140701187774539\n",
      "Gradient for encoder.log_var.weight: 0.01853591576218605\n",
      "Gradient for encoder.log_var.bias: 0.0008661434985697269\n",
      "Gradient for decoder.decoder.0.weight: 0.011596368625760078\n",
      "Gradient for decoder.decoder.0.bias: 9.110941168177789e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005479533574543893\n",
      "Gradient for decoder.decoder.1.bias: 0.0004396825097501278\n",
      "Gradient for decoder.decoder.3.weight: 0.010750075802206993\n",
      "Gradient for decoder.decoder.3.bias: 8.581647198413478e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00040843681199476123\n",
      "Gradient for decoder.decoder.4.bias: 0.00037782033905386925\n",
      "Gradient for decoder.decoder.6.weight: 0.001039888709783554\n",
      "Gradient for decoder.decoder.6.bias: 7.023779471637681e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.008676201105117798\n",
      "Gradient for encoder.encoder.0.bias: 1.245509251290855e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0004500822687987238\n",
      "Gradient for encoder.encoder.1.bias: 0.0004249650228302926\n",
      "Gradient for encoder.encoder.3.weight: 0.010127989575266838\n",
      "Gradient for encoder.encoder.3.bias: 9.744759166263606e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.002580224070698023\n",
      "Gradient for encoder.encoder.4.bias: 0.0017437392380088568\n",
      "Gradient for encoder.mean.weight: 0.03459825739264488\n",
      "Gradient for encoder.mean.bias: 0.0011947053717449307\n",
      "Gradient for encoder.log_var.weight: 0.01846136525273323\n",
      "Gradient for encoder.log_var.bias: 0.0007654718938283622\n",
      "Gradient for decoder.decoder.0.weight: 0.00931487139314413\n",
      "Gradient for decoder.decoder.0.bias: 7.865102319426498e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.000433695298852399\n",
      "Gradient for decoder.decoder.1.bias: 0.0003769024624489248\n",
      "Gradient for decoder.decoder.3.weight: 0.008408420719206333\n",
      "Gradient for decoder.decoder.3.bias: 6.162508003892953e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00030684686498716474\n",
      "Gradient for decoder.decoder.4.bias: 0.0002791695296764374\n",
      "Gradient for decoder.decoder.6.weight: 0.0009081554017029703\n",
      "Gradient for decoder.decoder.6.bias: 5.289090040605515e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.0034522716887295246\n",
      "Gradient for encoder.encoder.0.bias: 5.0079653965418025e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.00028414561529643834\n",
      "Gradient for encoder.encoder.1.bias: 0.00029696672572754323\n",
      "Gradient for encoder.encoder.3.weight: 0.0063218832947313786\n",
      "Gradient for encoder.encoder.3.bias: 8.026532216653948e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.0025367718189954758\n",
      "Gradient for encoder.encoder.4.bias: 0.001800780650228262\n",
      "Gradient for encoder.mean.weight: 0.03823787719011307\n",
      "Gradient for encoder.mean.bias: 0.0010828381637111306\n",
      "Gradient for encoder.log_var.weight: 0.02170947752892971\n",
      "Gradient for encoder.log_var.bias: 0.0008887514704838395\n",
      "Gradient for decoder.decoder.0.weight: 0.012044031172990799\n",
      "Gradient for decoder.decoder.0.bias: 1.1211897382734648e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0005876165814697742\n",
      "Gradient for decoder.decoder.1.bias: 0.0004988302243873477\n",
      "Gradient for decoder.decoder.3.weight: 0.011002812534570694\n",
      "Gradient for decoder.decoder.3.bias: 9.271641093766547e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.000446110381744802\n",
      "Gradient for decoder.decoder.4.bias: 0.0004346909699961543\n",
      "Gradient for decoder.decoder.6.weight: 0.0009864760795608163\n",
      "Gradient for decoder.decoder.6.bias: 4.986966450815089e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.006587188690900803\n",
      "Gradient for encoder.encoder.0.bias: 1.0689444121525504e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0004936606273986399\n",
      "Gradient for encoder.encoder.1.bias: 0.0003862643789034337\n",
      "Gradient for encoder.encoder.3.weight: 0.01044702623039484\n",
      "Gradient for encoder.encoder.3.bias: 8.862273415122246e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.0023096874356269836\n",
      "Gradient for encoder.encoder.4.bias: 0.0017107600579038262\n",
      "Gradient for encoder.mean.weight: 0.03141237422823906\n",
      "Gradient for encoder.mean.bias: 0.0012598272878676653\n",
      "Gradient for encoder.log_var.weight: 0.018219852820038795\n",
      "Gradient for encoder.log_var.bias: 0.0007948485435917974\n",
      "Gradient for decoder.decoder.0.weight: 0.008032861165702343\n",
      "Gradient for decoder.decoder.0.bias: 6.687057158005771e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0004039550549350679\n",
      "Gradient for decoder.decoder.1.bias: 0.0003231599403079599\n",
      "Gradient for decoder.decoder.3.weight: 0.007491204887628555\n",
      "Gradient for decoder.decoder.3.bias: 5.998098545623165e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00032971828477457166\n",
      "Gradient for decoder.decoder.4.bias: 0.0003536432341206819\n",
      "Gradient for decoder.decoder.6.weight: 0.0009050877415575087\n",
      "Gradient for decoder.decoder.6.bias: 4.1792030970100313e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training VAE Epoch:  91%|█████████ | 72/79 [00:01<00:00, 73.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient for encoder.encoder.0.weight: 0.00464747054502368\n",
      "Gradient for encoder.encoder.0.bias: 7.422788078637055e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.0004113647446502\n",
      "Gradient for encoder.encoder.1.bias: 0.00032482980168424547\n",
      "Gradient for encoder.encoder.3.weight: 0.009044571779668331\n",
      "Gradient for encoder.encoder.3.bias: 8.899234127390798e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.002322856104001403\n",
      "Gradient for encoder.encoder.4.bias: 0.0017750929109752178\n",
      "Gradient for encoder.mean.weight: 0.031849950551986694\n",
      "Gradient for encoder.mean.bias: 0.0013927898835390806\n",
      "Gradient for encoder.log_var.weight: 0.019035564735531807\n",
      "Gradient for encoder.log_var.bias: 0.000855953898280859\n",
      "Gradient for decoder.decoder.0.weight: 0.009967222809791565\n",
      "Gradient for decoder.decoder.0.bias: 7.927038192523383e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.00047397168236784637\n",
      "Gradient for decoder.decoder.1.bias: 0.00041236329707317054\n",
      "Gradient for decoder.decoder.3.weight: 0.00914465356618166\n",
      "Gradient for decoder.decoder.3.bias: 7.472909790973148e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00037796105607412755\n",
      "Gradient for decoder.decoder.4.bias: 0.0003882592427544296\n",
      "Gradient for decoder.decoder.6.weight: 0.0009668106795288622\n",
      "Gradient for decoder.decoder.6.bias: 6.150966510176659e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.0036522476002573967\n",
      "Gradient for encoder.encoder.0.bias: 5.3334029900820035e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.00032410930725745857\n",
      "Gradient for encoder.encoder.1.bias: 0.000297041900921613\n",
      "Gradient for encoder.encoder.3.weight: 0.006979246623814106\n",
      "Gradient for encoder.encoder.3.bias: 8.375921484171656e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.002710174536332488\n",
      "Gradient for encoder.encoder.4.bias: 0.0018012230284512043\n",
      "Gradient for encoder.mean.weight: 0.036503154784440994\n",
      "Gradient for encoder.mean.bias: 0.001530668931081891\n",
      "Gradient for encoder.log_var.weight: 0.021986275911331177\n",
      "Gradient for encoder.log_var.bias: 0.0009651058353483677\n",
      "Gradient for decoder.decoder.0.weight: 0.011803598143160343\n",
      "Gradient for decoder.decoder.0.bias: 9.894251390418773e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005423668189905584\n",
      "Gradient for decoder.decoder.1.bias: 0.0004964009276591241\n",
      "Gradient for decoder.decoder.3.weight: 0.010586672462522984\n",
      "Gradient for decoder.decoder.3.bias: 1.0791158244760624e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0006374170770868659\n",
      "Gradient for decoder.decoder.4.bias: 0.0007585134007968009\n",
      "Gradient for decoder.decoder.6.weight: 0.0013429049868136644\n",
      "Gradient for decoder.decoder.6.bias: 0.0001153150005848147\n",
      "Gradient for encoder.encoder.0.weight: 0.007550133857876062\n",
      "Gradient for encoder.encoder.0.bias: 9.845794318730228e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.00042749964632093906\n",
      "Gradient for encoder.encoder.1.bias: 0.00034438323928043246\n",
      "Gradient for encoder.encoder.3.weight: 0.008741884492337704\n",
      "Gradient for encoder.encoder.3.bias: 9.526793937064681e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.002178091323003173\n",
      "Gradient for encoder.encoder.4.bias: 0.0017486048163846135\n",
      "Gradient for encoder.mean.weight: 0.031607501208782196\n",
      "Gradient for encoder.mean.bias: 0.0012492345413193107\n",
      "Gradient for encoder.log_var.weight: 0.015941724181175232\n",
      "Gradient for encoder.log_var.bias: 0.00085172348190099\n",
      "Gradient for decoder.decoder.0.weight: 0.00934279803186655\n",
      "Gradient for decoder.decoder.0.bias: 7.829416975857484e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0004779824521392584\n",
      "Gradient for decoder.decoder.1.bias: 0.00036129297222942114\n",
      "Gradient for decoder.decoder.3.weight: 0.008831383660435677\n",
      "Gradient for decoder.decoder.3.bias: 7.042420813174743e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0003124351496808231\n",
      "Gradient for decoder.decoder.4.bias: 0.00027761829551309347\n",
      "Gradient for decoder.decoder.6.weight: 0.0009588133543729782\n",
      "Gradient for decoder.decoder.6.bias: 5.5833905207691714e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.0039089941419661045\n",
      "Gradient for encoder.encoder.0.bias: 6.707802716054978e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.00029113038908690214\n",
      "Gradient for encoder.encoder.1.bias: 0.00028939376352354884\n",
      "Gradient for encoder.encoder.3.weight: 0.006344286724925041\n",
      "Gradient for encoder.encoder.3.bias: 8.504277143606132e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.0019674457143992186\n",
      "Gradient for encoder.encoder.4.bias: 0.0015494158724322915\n",
      "Gradient for encoder.mean.weight: 0.030147898942232132\n",
      "Gradient for encoder.mean.bias: 0.0012197460746392608\n",
      "Gradient for encoder.log_var.weight: 0.017373396083712578\n",
      "Gradient for encoder.log_var.bias: 0.0007895228336565197\n",
      "Gradient for decoder.decoder.0.weight: 0.01018349640071392\n",
      "Gradient for decoder.decoder.0.bias: 9.019020946743339e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.000486578734125942\n",
      "Gradient for decoder.decoder.1.bias: 0.000428213068516925\n",
      "Gradient for decoder.decoder.3.weight: 0.009403885342180729\n",
      "Gradient for decoder.decoder.3.bias: 8.035250936844207e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00036088511114940047\n",
      "Gradient for decoder.decoder.4.bias: 0.00035343365743756294\n",
      "Gradient for decoder.decoder.6.weight: 0.0010676741367205977\n",
      "Gradient for decoder.decoder.6.bias: 7.802045001881197e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.004938887432217598\n",
      "Gradient for encoder.encoder.0.bias: 7.55567570315252e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.0003686849377118051\n",
      "Gradient for encoder.encoder.1.bias: 0.00041125318966805935\n",
      "Gradient for encoder.encoder.3.weight: 0.007903963327407837\n",
      "Gradient for encoder.encoder.3.bias: 1.0165050051691438e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.00235925056040287\n",
      "Gradient for encoder.encoder.4.bias: 0.002171881962567568\n",
      "Gradient for encoder.mean.weight: 0.03332381322979927\n",
      "Gradient for encoder.mean.bias: 0.0017947605811059475\n",
      "Gradient for encoder.log_var.weight: 0.01832132413983345\n",
      "Gradient for encoder.log_var.bias: 0.0011616869596764445\n",
      "Gradient for decoder.decoder.0.weight: 0.010142856277525425\n",
      "Gradient for decoder.decoder.0.bias: 8.963817882401415e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.00047748861834406853\n",
      "Gradient for decoder.decoder.1.bias: 0.0004273646336514503\n",
      "Gradient for decoder.decoder.3.weight: 0.009350625798106194\n",
      "Gradient for decoder.decoder.3.bias: 7.992516370958214e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00035138154635205865\n",
      "Gradient for decoder.decoder.4.bias: 0.00033664560760371387\n",
      "Gradient for decoder.decoder.6.weight: 0.0009582674247212708\n",
      "Gradient for decoder.decoder.6.bias: 4.894891753792763e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.004254343919456005\n",
      "Gradient for encoder.encoder.0.bias: 6.058496586358597e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.00033128896029666066\n",
      "Gradient for encoder.encoder.1.bias: 0.0002854595077224076\n",
      "Gradient for encoder.encoder.3.weight: 0.006997487507760525\n",
      "Gradient for encoder.encoder.3.bias: 8.311798471716259e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.002093234797939658\n",
      "Gradient for encoder.encoder.4.bias: 0.0017229976365342736\n",
      "Gradient for encoder.mean.weight: 0.02821950986981392\n",
      "Gradient for encoder.mean.bias: 0.0013019547332078218\n",
      "Gradient for encoder.log_var.weight: 0.016216803342103958\n",
      "Gradient for encoder.log_var.bias: 0.0008475915528833866\n",
      "Gradient for decoder.decoder.0.weight: 0.011955716647207737\n",
      "Gradient for decoder.decoder.0.bias: 1.052062811868204e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0005443303962238133\n",
      "Gradient for decoder.decoder.1.bias: 0.0004927254049107432\n",
      "Gradient for decoder.decoder.3.weight: 0.011138560250401497\n",
      "Gradient for decoder.decoder.3.bias: 1.186296894051253e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0007925688987597823\n",
      "Gradient for decoder.decoder.4.bias: 0.0009196957107633352\n",
      "Gradient for decoder.decoder.6.weight: 0.0012077523861080408\n",
      "Gradient for decoder.decoder.6.bias: 8.84378096088767e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.004422067664563656\n",
      "Gradient for encoder.encoder.0.bias: 6.66458034592754e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.0003445166803430766\n",
      "Gradient for encoder.encoder.1.bias: 0.0003696120111271739\n",
      "Gradient for encoder.encoder.3.weight: 0.007090330123901367\n",
      "Gradient for encoder.encoder.3.bias: 8.120273203848782e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.0020825453102588654\n",
      "Gradient for encoder.encoder.4.bias: 0.0016244545113295317\n",
      "Gradient for encoder.mean.weight: 0.029672520235180855\n",
      "Gradient for encoder.mean.bias: 0.0011153430677950382\n",
      "Gradient for encoder.log_var.weight: 0.016973013058304787\n",
      "Gradient for encoder.log_var.bias: 0.0008403778192587197\n",
      "Gradient for decoder.decoder.0.weight: 0.009840674698352814\n",
      "Gradient for decoder.decoder.0.bias: 9.370892256610475e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.00047854293370619416\n",
      "Gradient for decoder.decoder.1.bias: 0.0004095409531146288\n",
      "Gradient for decoder.decoder.3.weight: 0.00903498474508524\n",
      "Gradient for decoder.decoder.3.bias: 8.14747644350966e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0003352982166688889\n",
      "Gradient for decoder.decoder.4.bias: 0.00030371054890565574\n",
      "Gradient for decoder.decoder.6.weight: 0.0008603144669905305\n",
      "Gradient for decoder.decoder.6.bias: 3.899101648130454e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.00911023374646902\n",
      "Gradient for encoder.encoder.0.bias: 1.4124310228347259e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.000569214578717947\n",
      "Gradient for encoder.encoder.1.bias: 0.0004951857845298946\n",
      "Gradient for encoder.encoder.3.weight: 0.01236972026526928\n",
      "Gradient for encoder.encoder.3.bias: 1.0723941179513474e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0022650950122624636\n",
      "Gradient for encoder.encoder.4.bias: 0.0019126087427139282\n",
      "Gradient for encoder.mean.weight: 0.03219863399863243\n",
      "Gradient for encoder.mean.bias: 0.0014310665428638458\n",
      "Gradient for encoder.log_var.weight: 0.022392796352505684\n",
      "Gradient for encoder.log_var.bias: 0.0009461495210416615\n",
      "Gradient for decoder.decoder.0.weight: 0.008461217395961285\n",
      "Gradient for decoder.decoder.0.bias: 7.499612042494164e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.00039734254823997617\n",
      "Gradient for decoder.decoder.1.bias: 0.00035042883246205747\n",
      "Gradient for decoder.decoder.3.weight: 0.00801960937678814\n",
      "Gradient for decoder.decoder.3.bias: 6.940255314891175e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00032942622783593833\n",
      "Gradient for decoder.decoder.4.bias: 0.00033889664337038994\n",
      "Gradient for decoder.decoder.6.weight: 0.0009452466038055718\n",
      "Gradient for decoder.decoder.6.bias: 5.8302768593421206e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.00480648735538125\n",
      "Gradient for encoder.encoder.0.bias: 6.939576517595025e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.00031160429352894425\n",
      "Gradient for encoder.encoder.1.bias: 0.0002937974641099572\n",
      "Gradient for encoder.encoder.3.weight: 0.006723344326019287\n",
      "Gradient for encoder.encoder.3.bias: 8.28876828284919e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.0017220701556652784\n",
      "Gradient for encoder.encoder.4.bias: 0.0014165331376716495\n",
      "Gradient for encoder.mean.weight: 0.02611722983419895\n",
      "Gradient for encoder.mean.bias: 0.0011265418725088239\n",
      "Gradient for encoder.log_var.weight: 0.014678475446999073\n",
      "Gradient for encoder.log_var.bias: 0.0007735489634796977\n",
      "Gradient for decoder.decoder.0.weight: 0.009916934184730053\n",
      "Gradient for decoder.decoder.0.bias: 9.111821019924804e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.000454837892903015\n",
      "Gradient for decoder.decoder.1.bias: 0.00040137552423402667\n",
      "Gradient for decoder.decoder.3.weight: 0.009341231547296047\n",
      "Gradient for decoder.decoder.3.bias: 9.127686800836088e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00032602823921479285\n",
      "Gradient for decoder.decoder.4.bias: 0.00032353727146983147\n",
      "Gradient for decoder.decoder.6.weight: 0.0009401097777299583\n",
      "Gradient for decoder.decoder.6.bias: 5.224713822826743e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.006648880895227194\n",
      "Gradient for encoder.encoder.0.bias: 1.0721013486703068e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0005214465199969709\n",
      "Gradient for encoder.encoder.1.bias: 0.0004590810276567936\n",
      "Gradient for encoder.encoder.3.weight: 0.0104381637647748\n",
      "Gradient for encoder.encoder.3.bias: 9.645623189058483e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.0021501732990145683\n",
      "Gradient for encoder.encoder.4.bias: 0.0016736038960516453\n",
      "Gradient for encoder.mean.weight: 0.029854143038392067\n",
      "Gradient for encoder.mean.bias: 0.0012285092379897833\n",
      "Gradient for encoder.log_var.weight: 0.016939371824264526\n",
      "Gradient for encoder.log_var.bias: 0.000798904977273196\n",
      "Gradient for decoder.decoder.0.weight: 0.008798965252935886\n",
      "Gradient for decoder.decoder.0.bias: 7.386968120526305e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.00041778438026085496\n",
      "Gradient for decoder.decoder.1.bias: 0.0003538050805218518\n",
      "Gradient for decoder.decoder.3.weight: 0.008142785169184208\n",
      "Gradient for decoder.decoder.3.bias: 6.935439722521863e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00032571639167144895\n",
      "Gradient for decoder.decoder.4.bias: 0.0003409734054002911\n",
      "Gradient for decoder.decoder.6.weight: 0.000985822407528758\n",
      "Gradient for decoder.decoder.6.bias: 6.073558688513003e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.004469528328627348\n",
      "Gradient for encoder.encoder.0.bias: 6.3554027492085385e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.00030093564419075847\n",
      "Gradient for encoder.encoder.1.bias: 0.00030678792973048985\n",
      "Gradient for encoder.encoder.3.weight: 0.006912236101925373\n",
      "Gradient for encoder.encoder.3.bias: 8.014039432069353e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.002298436127603054\n",
      "Gradient for encoder.encoder.4.bias: 0.0017384913517162204\n",
      "Gradient for encoder.mean.weight: 0.03287259861826897\n",
      "Gradient for encoder.mean.bias: 0.0012691012816503644\n",
      "Gradient for encoder.log_var.weight: 0.018499139696359634\n",
      "Gradient for encoder.log_var.bias: 0.0007607969455420971\n",
      "Gradient for decoder.decoder.0.weight: 0.010311532765626907\n",
      "Gradient for decoder.decoder.0.bias: 8.751121355343727e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0004974587936885655\n",
      "Gradient for decoder.decoder.1.bias: 0.000407488492783159\n",
      "Gradient for decoder.decoder.3.weight: 0.009900299832224846\n",
      "Gradient for decoder.decoder.3.bias: 9.777081227957396e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0006066978094168007\n",
      "Gradient for decoder.decoder.4.bias: 0.0007178248488344252\n",
      "Gradient for decoder.decoder.6.weight: 0.0011021526297554374\n",
      "Gradient for decoder.decoder.6.bias: 8.369819261133671e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.006340053863823414\n",
      "Gradient for encoder.encoder.0.bias: 9.966128616811787e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.00045262041385285556\n",
      "Gradient for encoder.encoder.1.bias: 0.00039297525654546916\n",
      "Gradient for encoder.encoder.3.weight: 0.010521087795495987\n",
      "Gradient for encoder.encoder.3.bias: 9.651918847497498e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.0023709398228675127\n",
      "Gradient for encoder.encoder.4.bias: 0.001908322679810226\n",
      "Gradient for encoder.mean.weight: 0.032247111201286316\n",
      "Gradient for encoder.mean.bias: 0.0015495790867134929\n",
      "Gradient for encoder.log_var.weight: 0.019246919080615044\n",
      "Gradient for encoder.log_var.bias: 0.0009707213612273335\n",
      "Gradient for decoder.decoder.0.weight: 0.008424496278166771\n",
      "Gradient for decoder.decoder.0.bias: 7.382688904655765e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.00038212869549170136\n",
      "Gradient for decoder.decoder.1.bias: 0.0003388402401469648\n",
      "Gradient for decoder.decoder.3.weight: 0.0079387491568923\n",
      "Gradient for decoder.decoder.3.bias: 7.159707549053707e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00034141872311010957\n",
      "Gradient for decoder.decoder.4.bias: 0.00034312973730266094\n",
      "Gradient for decoder.decoder.6.weight: 0.0009184236987493932\n",
      "Gradient for decoder.decoder.6.bias: 4.903524313704111e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.007656583096832037\n",
      "Gradient for encoder.encoder.0.bias: 1.1293892904218339e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0003836133109871298\n",
      "Gradient for encoder.encoder.1.bias: 0.0004030726558994502\n",
      "Gradient for encoder.encoder.3.weight: 0.008299127221107483\n",
      "Gradient for encoder.encoder.3.bias: 9.141173235027722e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.0019605655688792467\n",
      "Gradient for encoder.encoder.4.bias: 0.0015157789457589388\n",
      "Gradient for encoder.mean.weight: 0.02725430391728878\n",
      "Gradient for encoder.mean.bias: 0.00109362683724612\n",
      "Gradient for encoder.log_var.weight: 0.015929102897644043\n",
      "Gradient for encoder.log_var.bias: 0.0007800692110322416\n",
      "Gradient for decoder.decoder.0.weight: 0.0077747623436152935\n",
      "Gradient for decoder.decoder.0.bias: 6.511408079390435e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.00039332167943939567\n",
      "Gradient for decoder.decoder.1.bias: 0.0003224026004318148\n",
      "Gradient for decoder.decoder.3.weight: 0.0076228040270507336\n",
      "Gradient for decoder.decoder.3.bias: 8.349441277255565e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0005230473470874131\n",
      "Gradient for decoder.decoder.4.bias: 0.0005967257893644273\n",
      "Gradient for decoder.decoder.6.weight: 0.000988207058981061\n",
      "Gradient for decoder.decoder.6.bias: 6.284707342274487e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.005946775432676077\n",
      "Gradient for encoder.encoder.0.bias: 9.582840597432973e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.00036083298618905246\n",
      "Gradient for encoder.encoder.1.bias: 0.00036679321783594787\n",
      "Gradient for encoder.encoder.3.weight: 0.007442452013492584\n",
      "Gradient for encoder.encoder.3.bias: 8.791249672679413e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.0016987875569611788\n",
      "Gradient for encoder.encoder.4.bias: 0.0013181106187403202\n",
      "Gradient for encoder.mean.weight: 0.02539425529539585\n",
      "Gradient for encoder.mean.bias: 0.0010503666708245873\n",
      "Gradient for encoder.log_var.weight: 0.01578938402235508\n",
      "Gradient for encoder.log_var.bias: 0.0006387121393345296\n",
      "Gradient for decoder.decoder.0.weight: 0.00801163725554943\n",
      "Gradient for decoder.decoder.0.bias: 6.804563162932098e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0003982843190897256\n",
      "Gradient for decoder.decoder.1.bias: 0.0003188940172549337\n",
      "Gradient for decoder.decoder.3.weight: 0.0076021295972168446\n",
      "Gradient for decoder.decoder.3.bias: 6.278396552650278e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00033158675068989396\n",
      "Gradient for decoder.decoder.4.bias: 0.00033770123263821006\n",
      "Gradient for decoder.decoder.6.weight: 0.0010221857810392976\n",
      "Gradient for decoder.decoder.6.bias: 7.403294875985011e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.007446647621691227\n",
      "Gradient for encoder.encoder.0.bias: 1.230036298510706e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.00044548549340106547\n",
      "Gradient for encoder.encoder.1.bias: 0.0004107372369617224\n",
      "Gradient for encoder.encoder.3.weight: 0.010016092099249363\n",
      "Gradient for encoder.encoder.3.bias: 9.77856198791649e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.002269584685564041\n",
      "Gradient for encoder.encoder.4.bias: 0.0018435332458466291\n",
      "Gradient for encoder.mean.weight: 0.03134271875023842\n",
      "Gradient for encoder.mean.bias: 0.0013232444180175662\n",
      "Gradient for encoder.log_var.weight: 0.01715617999434471\n",
      "Gradient for encoder.log_var.bias: 0.0008136251126416028\n",
      "Gradient for decoder.decoder.0.weight: 0.008143425919115543\n",
      "Gradient for decoder.decoder.0.bias: 6.563748849996998e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.00039975359686650336\n",
      "Gradient for decoder.decoder.1.bias: 0.0003275988856330514\n",
      "Gradient for decoder.decoder.3.weight: 0.007715839892625809\n",
      "Gradient for decoder.decoder.3.bias: 5.835529975906084e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00036436814116314054\n",
      "Gradient for decoder.decoder.4.bias: 0.00039373949402943254\n",
      "Gradient for decoder.decoder.6.weight: 0.0009512457763776183\n",
      "Gradient for decoder.decoder.6.bias: 5.4004147386876866e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient for encoder.encoder.0.weight: 0.0046219308860599995\n",
      "Gradient for encoder.encoder.0.bias: 7.04228168835197e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.0003577738825697452\n",
      "Gradient for encoder.encoder.1.bias: 0.00035626106546260417\n",
      "Gradient for encoder.encoder.3.weight: 0.007847159169614315\n",
      "Gradient for encoder.encoder.3.bias: 8.162637926689698e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.0017961865523830056\n",
      "Gradient for encoder.encoder.4.bias: 0.0013101805234327912\n",
      "Gradient for encoder.mean.weight: 0.022608835250139236\n",
      "Gradient for encoder.mean.bias: 0.0009302885737270117\n",
      "Gradient for encoder.log_var.weight: 0.015700729563832283\n",
      "Gradient for encoder.log_var.bias: 0.0006887277704663575\n",
      "Gradient for decoder.decoder.0.weight: 0.009661382995545864\n",
      "Gradient for decoder.decoder.0.bias: 7.583184774562213e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0004442766075953841\n",
      "Gradient for decoder.decoder.1.bias: 0.0003935317799914628\n",
      "Gradient for decoder.decoder.3.weight: 0.008926075883209705\n",
      "Gradient for decoder.decoder.3.bias: 7.000843654791922e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0003481414169073105\n",
      "Gradient for decoder.decoder.4.bias: 0.0003071662795264274\n",
      "Gradient for decoder.decoder.6.weight: 0.0009961876785382628\n",
      "Gradient for decoder.decoder.6.bias: 6.438904529204592e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.034966841340065\n",
      "Gradient for encoder.encoder.0.bias: 5.495632768304226e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0017977332463487983\n",
      "Gradient for encoder.encoder.1.bias: 0.0020742809865623713\n",
      "Gradient for encoder.encoder.3.weight: 0.03712407499551773\n",
      "Gradient for encoder.encoder.3.bias: 3.228382838837973e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.006696722935885191\n",
      "Gradient for encoder.encoder.4.bias: 0.007668430916965008\n",
      "Gradient for encoder.mean.weight: 0.09352622181177139\n",
      "Gradient for encoder.mean.bias: 0.005774197168648243\n",
      "Gradient for encoder.log_var.weight: 0.058652035892009735\n",
      "Gradient for encoder.log_var.bias: 0.003930470906198025\n",
      "Gradient for decoder.decoder.0.weight: 0.02567908726632595\n",
      "Gradient for decoder.decoder.0.bias: 1.5715695411699926e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.001084723393432796\n",
      "Gradient for decoder.decoder.1.bias: 0.0008918764069676399\n",
      "Gradient for decoder.decoder.3.weight: 0.023043692111968994\n",
      "Gradient for decoder.decoder.3.bias: 1.563416895944414e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0007640014518983662\n",
      "Gradient for decoder.decoder.4.bias: 0.0006472512031905353\n",
      "Gradient for decoder.decoder.6.weight: 0.0024661936331540346\n",
      "Gradient for decoder.decoder.6.bias: 0.00010298454435542226\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3, Train Loss: 0.0838, Val Loss: 0.2970\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training VAE Epoch:  11%|█▏        | 9/79 [00:00<00:02, 34.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient for encoder.encoder.0.weight: 0.00878063589334488\n",
      "Gradient for encoder.encoder.0.bias: 1.3061978582085132e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0007319015567190945\n",
      "Gradient for encoder.encoder.1.bias: 0.0006550661637447774\n",
      "Gradient for encoder.encoder.3.weight: 0.015271302312612534\n",
      "Gradient for encoder.encoder.3.bias: 1.1227736795849097e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0025598257780075073\n",
      "Gradient for encoder.encoder.4.bias: 0.0020735682919621468\n",
      "Gradient for encoder.mean.weight: 0.0364193320274353\n",
      "Gradient for encoder.mean.bias: 0.001711767166852951\n",
      "Gradient for encoder.log_var.weight: 0.018332986161112785\n",
      "Gradient for encoder.log_var.bias: 0.0009698207140900195\n",
      "Gradient for decoder.decoder.0.weight: 0.0093210618942976\n",
      "Gradient for decoder.decoder.0.bias: 7.716137451208027e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.00045619579032063484\n",
      "Gradient for decoder.decoder.1.bias: 0.0003674972685985267\n",
      "Gradient for decoder.decoder.3.weight: 0.008863931521773338\n",
      "Gradient for decoder.decoder.3.bias: 7.773846150138652e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00037486161454580724\n",
      "Gradient for decoder.decoder.4.bias: 0.0003750809992197901\n",
      "Gradient for decoder.decoder.6.weight: 0.000962152611464262\n",
      "Gradient for decoder.decoder.6.bias: 4.784010525327176e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.01372520998120308\n",
      "Gradient for encoder.encoder.0.bias: 1.4751786597821948e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0009258014033548534\n",
      "Gradient for encoder.encoder.1.bias: 0.0009738273802213371\n",
      "Gradient for encoder.encoder.3.weight: 0.020375937223434448\n",
      "Gradient for encoder.encoder.3.bias: 1.4301930473248348e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0036915389355272055\n",
      "Gradient for encoder.encoder.4.bias: 0.0032563675194978714\n",
      "Gradient for encoder.mean.weight: 0.0509713813662529\n",
      "Gradient for encoder.mean.bias: 0.0022406643256545067\n",
      "Gradient for encoder.log_var.weight: 0.025772199034690857\n",
      "Gradient for encoder.log_var.bias: 0.0013687033206224442\n",
      "Gradient for decoder.decoder.0.weight: 0.009870421141386032\n",
      "Gradient for decoder.decoder.0.bias: 8.753074653977677e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005070710903964937\n",
      "Gradient for decoder.decoder.1.bias: 0.0004127095453441143\n",
      "Gradient for decoder.decoder.3.weight: 0.009334548376500607\n",
      "Gradient for decoder.decoder.3.bias: 8.872674817084203e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0004112563910894096\n",
      "Gradient for decoder.decoder.4.bias: 0.0004432421119417995\n",
      "Gradient for decoder.decoder.6.weight: 0.0009321060497313738\n",
      "Gradient for decoder.decoder.6.bias: 5.233686897554435e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.011911234818398952\n",
      "Gradient for encoder.encoder.0.bias: 1.403865565463569e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.000713976623956114\n",
      "Gradient for encoder.encoder.1.bias: 0.0007639732793904841\n",
      "Gradient for encoder.encoder.3.weight: 0.0162370502948761\n",
      "Gradient for encoder.encoder.3.bias: 1.3368493811949378e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.003383525414392352\n",
      "Gradient for encoder.encoder.4.bias: 0.0030248607508838177\n",
      "Gradient for encoder.mean.weight: 0.04510337859392166\n",
      "Gradient for encoder.mean.bias: 0.0022464299108833075\n",
      "Gradient for encoder.log_var.weight: 0.027428561821579933\n",
      "Gradient for encoder.log_var.bias: 0.001478568185120821\n",
      "Gradient for decoder.decoder.0.weight: 0.009091383777558804\n",
      "Gradient for decoder.decoder.0.bias: 8.842600263125888e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0004148041771259159\n",
      "Gradient for decoder.decoder.1.bias: 0.00038379718898795545\n",
      "Gradient for decoder.decoder.3.weight: 0.008619394153356552\n",
      "Gradient for decoder.decoder.3.bias: 7.715350580639324e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0004321495653130114\n",
      "Gradient for decoder.decoder.4.bias: 0.00048514740774407983\n",
      "Gradient for decoder.decoder.6.weight: 0.0009344493737444282\n",
      "Gradient for decoder.decoder.6.bias: 5.656878056470305e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.010047812014818192\n",
      "Gradient for encoder.encoder.0.bias: 9.714686520501115e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.0005145043251104653\n",
      "Gradient for encoder.encoder.1.bias: 0.0005362347001209855\n",
      "Gradient for encoder.encoder.3.weight: 0.010962146334350109\n",
      "Gradient for encoder.encoder.3.bias: 1.4981320350937466e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0033329192083328962\n",
      "Gradient for encoder.encoder.4.bias: 0.003695828141644597\n",
      "Gradient for encoder.mean.weight: 0.04693565145134926\n",
      "Gradient for encoder.mean.bias: 0.002788365352898836\n",
      "Gradient for encoder.log_var.weight: 0.0295278150588274\n",
      "Gradient for encoder.log_var.bias: 0.002010263968259096\n",
      "Gradient for decoder.decoder.0.weight: 0.009455827064812183\n",
      "Gradient for decoder.decoder.0.bias: 7.803858254051832e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.00045725327800028026\n",
      "Gradient for decoder.decoder.1.bias: 0.00038514917832799256\n",
      "Gradient for decoder.decoder.3.weight: 0.008701808750629425\n",
      "Gradient for decoder.decoder.3.bias: 7.276042268689054e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00032959840609692037\n",
      "Gradient for decoder.decoder.4.bias: 0.0003137196181342006\n",
      "Gradient for decoder.decoder.6.weight: 0.0008933440549299121\n",
      "Gradient for decoder.decoder.6.bias: 4.437712050275877e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.005554759409278631\n",
      "Gradient for encoder.encoder.0.bias: 6.995617193167325e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.00045623694313690066\n",
      "Gradient for encoder.encoder.1.bias: 0.0004830455291084945\n",
      "Gradient for encoder.encoder.3.weight: 0.0097939008846879\n",
      "Gradient for encoder.encoder.3.bias: 1.1534657257117331e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0027321067173033953\n",
      "Gradient for encoder.encoder.4.bias: 0.002786636585369706\n",
      "Gradient for encoder.mean.weight: 0.038176313042640686\n",
      "Gradient for encoder.mean.bias: 0.002161378040909767\n",
      "Gradient for encoder.log_var.weight: 0.023086288943886757\n",
      "Gradient for encoder.log_var.bias: 0.0014131024945527315\n",
      "Gradient for decoder.decoder.0.weight: 0.010512398555874825\n",
      "Gradient for decoder.decoder.0.bias: 8.794042577475736e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005380805814638734\n",
      "Gradient for decoder.decoder.1.bias: 0.000426615821197629\n",
      "Gradient for decoder.decoder.3.weight: 0.009782957844436169\n",
      "Gradient for decoder.decoder.3.bias: 8.070556722916677e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00035454434691928327\n",
      "Gradient for decoder.decoder.4.bias: 0.0003112528065685183\n",
      "Gradient for decoder.decoder.6.weight: 0.0009979675523936749\n",
      "Gradient for decoder.decoder.6.bias: 5.967940887785517e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.008332028985023499\n",
      "Gradient for encoder.encoder.0.bias: 1.0146768841812204e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.000579772749915719\n",
      "Gradient for encoder.encoder.1.bias: 0.0005670409882441163\n",
      "Gradient for encoder.encoder.3.weight: 0.013067391701042652\n",
      "Gradient for encoder.encoder.3.bias: 1.2100152824157107e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0026561494451016188\n",
      "Gradient for encoder.encoder.4.bias: 0.002335044089704752\n",
      "Gradient for encoder.mean.weight: 0.036933742463588715\n",
      "Gradient for encoder.mean.bias: 0.0018673762679100037\n",
      "Gradient for encoder.log_var.weight: 0.017494553700089455\n",
      "Gradient for encoder.log_var.bias: 0.0008292220300063491\n",
      "Gradient for decoder.decoder.0.weight: 0.01009526289999485\n",
      "Gradient for decoder.decoder.0.bias: 8.569710219230586e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005062696291133761\n",
      "Gradient for decoder.decoder.1.bias: 0.00038832324207760394\n",
      "Gradient for decoder.decoder.3.weight: 0.009308240376412868\n",
      "Gradient for decoder.decoder.3.bias: 7.990312578254333e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00037056003930047154\n",
      "Gradient for decoder.decoder.4.bias: 0.0003406956675462425\n",
      "Gradient for decoder.decoder.6.weight: 0.0009492511162534356\n",
      "Gradient for decoder.decoder.6.bias: 5.435070124804042e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.007866241037845612\n",
      "Gradient for encoder.encoder.0.bias: 9.662513844599374e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.0006270380690693855\n",
      "Gradient for encoder.encoder.1.bias: 0.0005718711763620377\n",
      "Gradient for encoder.encoder.3.weight: 0.013891688548028469\n",
      "Gradient for encoder.encoder.3.bias: 1.1788178766458657e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0029529526364058256\n",
      "Gradient for encoder.encoder.4.bias: 0.002448184648528695\n",
      "Gradient for encoder.mean.weight: 0.04119590297341347\n",
      "Gradient for encoder.mean.bias: 0.002000416163355112\n",
      "Gradient for encoder.log_var.weight: 0.02034686878323555\n",
      "Gradient for encoder.log_var.bias: 0.0010247414465993643\n",
      "Gradient for decoder.decoder.0.weight: 0.010190087370574474\n",
      "Gradient for decoder.decoder.0.bias: 8.358425757082344e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005016683717258275\n",
      "Gradient for decoder.decoder.1.bias: 0.0004073559830430895\n",
      "Gradient for decoder.decoder.3.weight: 0.009305944666266441\n",
      "Gradient for decoder.decoder.3.bias: 6.783961586931397e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00034648290602490306\n",
      "Gradient for decoder.decoder.4.bias: 0.00029756201547570527\n",
      "Gradient for decoder.decoder.6.weight: 0.000913833559025079\n",
      "Gradient for decoder.decoder.6.bias: 4.321369851822965e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.005408810451626778\n",
      "Gradient for encoder.encoder.0.bias: 7.623934469846994e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.000531040714122355\n",
      "Gradient for encoder.encoder.1.bias: 0.0003553659189492464\n",
      "Gradient for encoder.encoder.3.weight: 0.011991753242909908\n",
      "Gradient for encoder.encoder.3.bias: 1.0786041504395882e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0027917667757719755\n",
      "Gradient for encoder.encoder.4.bias: 0.002175608417019248\n",
      "Gradient for encoder.mean.weight: 0.038981787860393524\n",
      "Gradient for encoder.mean.bias: 0.0014401715015992522\n",
      "Gradient for encoder.log_var.weight: 0.022455964237451553\n",
      "Gradient for encoder.log_var.bias: 0.0010962686501443386\n",
      "Gradient for decoder.decoder.0.weight: 0.01060397643595934\n",
      "Gradient for decoder.decoder.0.bias: 8.56083745559566e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005260109901428223\n",
      "Gradient for decoder.decoder.1.bias: 0.0004350045637693256\n",
      "Gradient for decoder.decoder.3.weight: 0.009867892600595951\n",
      "Gradient for decoder.decoder.3.bias: 8.018791186614749e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00038729506195522845\n",
      "Gradient for decoder.decoder.4.bias: 0.0003544187929946929\n",
      "Gradient for decoder.decoder.6.weight: 0.000995696522295475\n",
      "Gradient for decoder.decoder.6.bias: 6.155349547043443e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.005767625290900469\n",
      "Gradient for encoder.encoder.0.bias: 7.525527076501781e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.0005007692379876971\n",
      "Gradient for encoder.encoder.1.bias: 0.00034306914312765\n",
      "Gradient for encoder.encoder.3.weight: 0.011527497321367264\n",
      "Gradient for encoder.encoder.3.bias: 1.1381545705901885e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0028335668612271547\n",
      "Gradient for encoder.encoder.4.bias: 0.0023069654125720263\n",
      "Gradient for encoder.mean.weight: 0.03879401087760925\n",
      "Gradient for encoder.mean.bias: 0.0015753137413412333\n",
      "Gradient for encoder.log_var.weight: 0.02267717756330967\n",
      "Gradient for encoder.log_var.bias: 0.0011795718455687165\n",
      "Gradient for decoder.decoder.0.weight: 0.011547375470399857\n",
      "Gradient for decoder.decoder.0.bias: 9.995324706801867e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005369462305679917\n",
      "Gradient for decoder.decoder.1.bias: 0.0004508409765549004\n",
      "Gradient for decoder.decoder.3.weight: 0.010583140887320042\n",
      "Gradient for decoder.decoder.3.bias: 1.0497340496851137e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0005361339426599443\n",
      "Gradient for decoder.decoder.4.bias: 0.0005519477417692542\n",
      "Gradient for decoder.decoder.6.weight: 0.0010081594809889793\n",
      "Gradient for decoder.decoder.6.bias: 6.050543743185699e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.005737535655498505\n",
      "Gradient for encoder.encoder.0.bias: 7.108137429351347e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.0004964033723808825\n",
      "Gradient for encoder.encoder.1.bias: 0.0004458513285499066\n",
      "Gradient for encoder.encoder.3.weight: 0.01084472518414259\n",
      "Gradient for encoder.encoder.3.bias: 1.0906955894007808e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.002902597887441516\n",
      "Gradient for encoder.encoder.4.bias: 0.0022800404112786055\n",
      "Gradient for encoder.mean.weight: 0.03909281641244888\n",
      "Gradient for encoder.mean.bias: 0.0014998457627370954\n",
      "Gradient for encoder.log_var.weight: 0.02232908084988594\n",
      "Gradient for encoder.log_var.bias: 0.001001344295218587\n",
      "Gradient for decoder.decoder.0.weight: 0.010155650787055492\n",
      "Gradient for decoder.decoder.0.bias: 8.765300985036362e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005050991894677281\n",
      "Gradient for decoder.decoder.1.bias: 0.00039447061135433614\n",
      "Gradient for decoder.decoder.3.weight: 0.009519815444946289\n",
      "Gradient for decoder.decoder.3.bias: 7.352154995921012e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0004000170447397977\n",
      "Gradient for decoder.decoder.4.bias: 0.0004113155882805586\n",
      "Gradient for decoder.decoder.6.weight: 0.001314454828388989\n",
      "Gradient for decoder.decoder.6.bias: 0.00011260838800808415\n",
      "Gradient for encoder.encoder.0.weight: 0.006981455255299807\n",
      "Gradient for encoder.encoder.0.bias: 9.307971927940972e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.0004350598610471934\n",
      "Gradient for encoder.encoder.1.bias: 0.0004168285522609949\n",
      "Gradient for encoder.encoder.3.weight: 0.010206411592662334\n",
      "Gradient for encoder.encoder.3.bias: 9.672324746690109e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.002970932051539421\n",
      "Gradient for encoder.encoder.4.bias: 0.0021807746961712837\n",
      "Gradient for encoder.mean.weight: 0.03962184116244316\n",
      "Gradient for encoder.mean.bias: 0.001677104039117694\n",
      "Gradient for encoder.log_var.weight: 0.021408770233392715\n",
      "Gradient for encoder.log_var.bias: 0.000872446340508759\n",
      "Gradient for decoder.decoder.0.weight: 0.00968153215944767\n",
      "Gradient for decoder.decoder.0.bias: 8.248980665204186e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.00044810809777118266\n",
      "Gradient for decoder.decoder.1.bias: 0.0003933047701139003\n",
      "Gradient for decoder.decoder.3.weight: 0.009232432581484318\n",
      "Gradient for decoder.decoder.3.bias: 7.285871905793329e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00035228839260526\n",
      "Gradient for decoder.decoder.4.bias: 0.0002971581998281181\n",
      "Gradient for decoder.decoder.6.weight: 0.0009855256648734212\n",
      "Gradient for decoder.decoder.6.bias: 6.44071405986324e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.008627337403595448\n",
      "Gradient for encoder.encoder.0.bias: 1.2806834585876725e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.000577912840526551\n",
      "Gradient for encoder.encoder.1.bias: 0.0006206107791513205\n",
      "Gradient for encoder.encoder.3.weight: 0.013033143244683743\n",
      "Gradient for encoder.encoder.3.bias: 1.0928729449188879e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0028220282401889563\n",
      "Gradient for encoder.encoder.4.bias: 0.0022941571660339832\n",
      "Gradient for encoder.mean.weight: 0.039513714611530304\n",
      "Gradient for encoder.mean.bias: 0.001768501941114664\n",
      "Gradient for encoder.log_var.weight: 0.02295694500207901\n",
      "Gradient for encoder.log_var.bias: 0.0010481920326128602\n",
      "Gradient for decoder.decoder.0.weight: 0.008601333945989609\n",
      "Gradient for decoder.decoder.0.bias: 7.757250397588678e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0003983689530286938\n",
      "Gradient for decoder.decoder.1.bias: 0.0003657905908767134\n",
      "Gradient for decoder.decoder.3.weight: 0.00785273127257824\n",
      "Gradient for decoder.decoder.3.bias: 6.04262959114088e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0002823264803737402\n",
      "Gradient for decoder.decoder.4.bias: 0.0002825937408488244\n",
      "Gradient for decoder.decoder.6.weight: 0.0009446581243537366\n",
      "Gradient for decoder.decoder.6.bias: 5.622634489554912e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.0049336436204612255\n",
      "Gradient for encoder.encoder.0.bias: 7.31444332185971e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.0004111803136765957\n",
      "Gradient for encoder.encoder.1.bias: 0.00039767767884768546\n",
      "Gradient for encoder.encoder.3.weight: 0.009380615316331387\n",
      "Gradient for encoder.encoder.3.bias: 9.555518876158686e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.002531633013859391\n",
      "Gradient for encoder.encoder.4.bias: 0.002036251127719879\n",
      "Gradient for encoder.mean.weight: 0.037588633596897125\n",
      "Gradient for encoder.mean.bias: 0.001600160845555365\n",
      "Gradient for encoder.log_var.weight: 0.019604595378041267\n",
      "Gradient for encoder.log_var.bias: 0.000960908888373524\n",
      "Gradient for decoder.decoder.0.weight: 0.009850158356130123\n",
      "Gradient for decoder.decoder.0.bias: 7.87311535410673e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0004619758401531726\n",
      "Gradient for decoder.decoder.1.bias: 0.00040250865276902914\n",
      "Gradient for decoder.decoder.3.weight: 0.008891849778592587\n",
      "Gradient for decoder.decoder.3.bias: 7.184029759965682e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0003130098048131913\n",
      "Gradient for decoder.decoder.4.bias: 0.00028517775353975594\n",
      "Gradient for decoder.decoder.6.weight: 0.0009392535430379212\n",
      "Gradient for decoder.decoder.6.bias: 5.5461747251683846e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.009005775675177574\n",
      "Gradient for encoder.encoder.0.bias: 1.1275343506089719e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0005907191662117839\n",
      "Gradient for encoder.encoder.1.bias: 0.00042912960634566844\n",
      "Gradient for encoder.encoder.3.weight: 0.013182666152715683\n",
      "Gradient for encoder.encoder.3.bias: 1.1514703079917865e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0028280471451580524\n",
      "Gradient for encoder.encoder.4.bias: 0.00244563608430326\n",
      "Gradient for encoder.mean.weight: 0.039337340742349625\n",
      "Gradient for encoder.mean.bias: 0.001844361424446106\n",
      "Gradient for encoder.log_var.weight: 0.02286287397146225\n",
      "Gradient for encoder.log_var.bias: 0.0012460550060495734\n",
      "Gradient for decoder.decoder.0.weight: 0.009855185635387897\n",
      "Gradient for decoder.decoder.0.bias: 8.403803347656336e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.00046629959251731634\n",
      "Gradient for decoder.decoder.1.bias: 0.0003915674169547856\n",
      "Gradient for decoder.decoder.3.weight: 0.008986864238977432\n",
      "Gradient for decoder.decoder.3.bias: 7.123820977561479e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0003949470992665738\n",
      "Gradient for decoder.decoder.4.bias: 0.0003550701367203146\n",
      "Gradient for decoder.decoder.6.weight: 0.000993078574538231\n",
      "Gradient for decoder.decoder.6.bias: 5.822435559821315e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.005508412141352892\n",
      "Gradient for encoder.encoder.0.bias: 9.16007807799657e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.0004848880344070494\n",
      "Gradient for encoder.encoder.1.bias: 0.00035998132079839706\n",
      "Gradient for encoder.encoder.3.weight: 0.010942758060991764\n",
      "Gradient for encoder.encoder.3.bias: 1.0935081312668515e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0031577819027006626\n",
      "Gradient for encoder.encoder.4.bias: 0.0027597283478826284\n",
      "Gradient for encoder.mean.weight: 0.04523422196507454\n",
      "Gradient for encoder.mean.bias: 0.002067017136141658\n",
      "Gradient for encoder.log_var.weight: 0.026656514033675194\n",
      "Gradient for encoder.log_var.bias: 0.0014882511459290981\n",
      "Gradient for decoder.decoder.0.weight: 0.009818118996918201\n",
      "Gradient for decoder.decoder.0.bias: 8.472852280894116e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.00048309940029866993\n",
      "Gradient for decoder.decoder.1.bias: 0.00040592162986285985\n",
      "Gradient for decoder.decoder.3.weight: 0.009086035192012787\n",
      "Gradient for decoder.decoder.3.bias: 7.53483872517613e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0003489328664727509\n",
      "Gradient for decoder.decoder.4.bias: 0.0003088591911364347\n",
      "Gradient for decoder.decoder.6.weight: 0.0009416521061211824\n",
      "Gradient for decoder.decoder.6.bias: 5.4454834753414616e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.006279909983277321\n",
      "Gradient for encoder.encoder.0.bias: 8.51215972708097e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.00045755080645903945\n",
      "Gradient for encoder.encoder.1.bias: 0.0004435684240888804\n",
      "Gradient for encoder.encoder.3.weight: 0.010350062511861324\n",
      "Gradient for encoder.encoder.3.bias: 9.289619767871571e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.002650982001796365\n",
      "Gradient for encoder.encoder.4.bias: 0.0021248525008559227\n",
      "Gradient for encoder.mean.weight: 0.03643878549337387\n",
      "Gradient for encoder.mean.bias: 0.0015616511227563024\n",
      "Gradient for encoder.log_var.weight: 0.019572138786315918\n",
      "Gradient for encoder.log_var.bias: 0.0009380820556543767\n",
      "Gradient for decoder.decoder.0.weight: 0.009836088865995407\n",
      "Gradient for decoder.decoder.0.bias: 8.076319474303872e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.00048065229202620685\n",
      "Gradient for decoder.decoder.1.bias: 0.00042875995859503746\n",
      "Gradient for decoder.decoder.3.weight: 0.009256978519260883\n",
      "Gradient for decoder.decoder.3.bias: 7.297289161822818e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00033175546559505165\n",
      "Gradient for decoder.decoder.4.bias: 0.0002990119974128902\n",
      "Gradient for decoder.decoder.6.weight: 0.000983123667538166\n",
      "Gradient for decoder.decoder.6.bias: 6.172661960590631e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training VAE Epoch:  32%|███▏      | 25/79 [00:00<00:00, 59.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient for encoder.encoder.0.weight: 0.0063361357897520065\n",
      "Gradient for encoder.encoder.0.bias: 8.886643157457463e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.0003879901487380266\n",
      "Gradient for encoder.encoder.1.bias: 0.00041432349826209247\n",
      "Gradient for encoder.encoder.3.weight: 0.00875895470380783\n",
      "Gradient for encoder.encoder.3.bias: 9.778573090146736e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.002541495254263282\n",
      "Gradient for encoder.encoder.4.bias: 0.0021376486402004957\n",
      "Gradient for encoder.mean.weight: 0.03472099080681801\n",
      "Gradient for encoder.mean.bias: 0.0016045212978497148\n",
      "Gradient for encoder.log_var.weight: 0.02157137729227543\n",
      "Gradient for encoder.log_var.bias: 0.000934409152250737\n",
      "Gradient for decoder.decoder.0.weight: 0.009856533259153366\n",
      "Gradient for decoder.decoder.0.bias: 8.61741719648812e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005040074465796351\n",
      "Gradient for decoder.decoder.1.bias: 0.0004419262404553592\n",
      "Gradient for decoder.decoder.3.weight: 0.010128946043550968\n",
      "Gradient for decoder.decoder.3.bias: 7.561472281647497e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0004015066660940647\n",
      "Gradient for decoder.decoder.4.bias: 0.0003284599515609443\n",
      "Gradient for decoder.decoder.6.weight: 0.0009483959875069559\n",
      "Gradient for decoder.decoder.6.bias: 5.1311119023012e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.007474503479897976\n",
      "Gradient for encoder.encoder.0.bias: 9.364157886604385e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.0005724798538722098\n",
      "Gradient for encoder.encoder.1.bias: 0.0004419915785547346\n",
      "Gradient for encoder.encoder.3.weight: 0.012854199856519699\n",
      "Gradient for encoder.encoder.3.bias: 1.0674612582750598e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.002532939426600933\n",
      "Gradient for encoder.encoder.4.bias: 0.0022457686718553305\n",
      "Gradient for encoder.mean.weight: 0.03727450594305992\n",
      "Gradient for encoder.mean.bias: 0.0015508129727095366\n",
      "Gradient for encoder.log_var.weight: 0.01815052703022957\n",
      "Gradient for encoder.log_var.bias: 0.0010097888298332691\n",
      "Gradient for decoder.decoder.0.weight: 0.009837508201599121\n",
      "Gradient for decoder.decoder.0.bias: 8.264174761185572e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005011935136280954\n",
      "Gradient for decoder.decoder.1.bias: 0.0004173673805780709\n",
      "Gradient for decoder.decoder.3.weight: 0.009747045114636421\n",
      "Gradient for decoder.decoder.3.bias: 8.390627775911597e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00047447814722545445\n",
      "Gradient for decoder.decoder.4.bias: 0.0005066879675723612\n",
      "Gradient for decoder.decoder.6.weight: 0.0010409117676317692\n",
      "Gradient for decoder.decoder.6.bias: 6.07666588621214e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.006758019793778658\n",
      "Gradient for encoder.encoder.0.bias: 9.110934229283885e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.00043871841626241803\n",
      "Gradient for encoder.encoder.1.bias: 0.0003735108766704798\n",
      "Gradient for encoder.encoder.3.weight: 0.009603123180568218\n",
      "Gradient for encoder.encoder.3.bias: 1.107238606357086e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0024384488351643085\n",
      "Gradient for encoder.encoder.4.bias: 0.0022136452607810497\n",
      "Gradient for encoder.mean.weight: 0.03540588542819023\n",
      "Gradient for encoder.mean.bias: 0.0016151729505509138\n",
      "Gradient for encoder.log_var.weight: 0.018687495961785316\n",
      "Gradient for encoder.log_var.bias: 0.0010010417317971587\n",
      "Gradient for decoder.decoder.0.weight: 0.009861389175057411\n",
      "Gradient for decoder.decoder.0.bias: 8.468959561414025e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.00047398958122357726\n",
      "Gradient for decoder.decoder.1.bias: 0.00039677901077084243\n",
      "Gradient for decoder.decoder.3.weight: 0.00920337624847889\n",
      "Gradient for decoder.decoder.3.bias: 7.448787420205605e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0003935687127523124\n",
      "Gradient for decoder.decoder.4.bias: 0.0003675884217955172\n",
      "Gradient for decoder.decoder.6.weight: 0.000933673232793808\n",
      "Gradient for decoder.decoder.6.bias: 4.6930254029575735e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.007247169502079487\n",
      "Gradient for encoder.encoder.0.bias: 9.36827351805114e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.0004605415160767734\n",
      "Gradient for encoder.encoder.1.bias: 0.0004331867676228285\n",
      "Gradient for encoder.encoder.3.weight: 0.009467645548284054\n",
      "Gradient for encoder.encoder.3.bias: 1.0497561847566672e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.002858739346265793\n",
      "Gradient for encoder.encoder.4.bias: 0.0022392531391233206\n",
      "Gradient for encoder.mean.weight: 0.04021112993359566\n",
      "Gradient for encoder.mean.bias: 0.0017560513224452734\n",
      "Gradient for encoder.log_var.weight: 0.023612817749381065\n",
      "Gradient for encoder.log_var.bias: 0.0011690872488543391\n",
      "Gradient for decoder.decoder.0.weight: 0.00867877621203661\n",
      "Gradient for decoder.decoder.0.bias: 7.214100150587655e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0004187936137896031\n",
      "Gradient for decoder.decoder.1.bias: 0.00035164656583219767\n",
      "Gradient for decoder.decoder.3.weight: 0.008252705447375774\n",
      "Gradient for decoder.decoder.3.bias: 6.116584322368723e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00032543172710575163\n",
      "Gradient for decoder.decoder.4.bias: 0.00029915221966803074\n",
      "Gradient for decoder.decoder.6.weight: 0.000973696238361299\n",
      "Gradient for decoder.decoder.6.bias: 5.4855136113474146e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.005544527433812618\n",
      "Gradient for encoder.encoder.0.bias: 7.605944520039376e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.0004433811118360609\n",
      "Gradient for encoder.encoder.1.bias: 0.00032855107565410435\n",
      "Gradient for encoder.encoder.3.weight: 0.00936977006494999\n",
      "Gradient for encoder.encoder.3.bias: 9.08366576402031e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.0020639407448470592\n",
      "Gradient for encoder.encoder.4.bias: 0.0016171714523807168\n",
      "Gradient for encoder.mean.weight: 0.029680801555514336\n",
      "Gradient for encoder.mean.bias: 0.0012147718807682395\n",
      "Gradient for encoder.log_var.weight: 0.017330745235085487\n",
      "Gradient for encoder.log_var.bias: 0.0008512689382769167\n",
      "Gradient for decoder.decoder.0.weight: 0.01126598846167326\n",
      "Gradient for decoder.decoder.0.bias: 1.0375753728419923e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0005870419554412365\n",
      "Gradient for decoder.decoder.1.bias: 0.00047152687329798937\n",
      "Gradient for decoder.decoder.3.weight: 0.01069161668419838\n",
      "Gradient for decoder.decoder.3.bias: 1.0278949913455904e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0006164297228679061\n",
      "Gradient for decoder.decoder.4.bias: 0.000661519996356219\n",
      "Gradient for decoder.decoder.6.weight: 0.001288530183956027\n",
      "Gradient for decoder.decoder.6.bias: 0.00010789722728077322\n",
      "Gradient for encoder.encoder.0.weight: 0.007013545837253332\n",
      "Gradient for encoder.encoder.0.bias: 1.008094649423974e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0004315824480727315\n",
      "Gradient for encoder.encoder.1.bias: 0.00043065319187007844\n",
      "Gradient for encoder.encoder.3.weight: 0.009898949414491653\n",
      "Gradient for encoder.encoder.3.bias: 1.0255201549069781e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.00230040168389678\n",
      "Gradient for encoder.encoder.4.bias: 0.001911503728479147\n",
      "Gradient for encoder.mean.weight: 0.03289542719721794\n",
      "Gradient for encoder.mean.bias: 0.0013934443704783916\n",
      "Gradient for encoder.log_var.weight: 0.020039783790707588\n",
      "Gradient for encoder.log_var.bias: 0.0010302681475877762\n",
      "Gradient for decoder.decoder.0.weight: 0.010494752787053585\n",
      "Gradient for decoder.decoder.0.bias: 1.1210268824335401e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0005041585536673665\n",
      "Gradient for decoder.decoder.1.bias: 0.00044535021879710257\n",
      "Gradient for decoder.decoder.3.weight: 0.009546402841806412\n",
      "Gradient for decoder.decoder.3.bias: 9.198297679091638e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00035719218431040645\n",
      "Gradient for decoder.decoder.4.bias: 0.0003616597387008369\n",
      "Gradient for decoder.decoder.6.weight: 0.0010768788633868098\n",
      "Gradient for decoder.decoder.6.bias: 7.415559230139479e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.0053910729475319386\n",
      "Gradient for encoder.encoder.0.bias: 7.411161961901058e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.0005185541231185198\n",
      "Gradient for encoder.encoder.1.bias: 0.0004163696721661836\n",
      "Gradient for encoder.encoder.3.weight: 0.010791229084134102\n",
      "Gradient for encoder.encoder.3.bias: 9.814658114004615e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.002449495019391179\n",
      "Gradient for encoder.encoder.4.bias: 0.0018894546665251255\n",
      "Gradient for encoder.mean.weight: 0.03573940321803093\n",
      "Gradient for encoder.mean.bias: 0.001387890544719994\n",
      "Gradient for encoder.log_var.weight: 0.01847250759601593\n",
      "Gradient for encoder.log_var.bias: 0.001000766409561038\n",
      "Gradient for decoder.decoder.0.weight: 0.010504013858735561\n",
      "Gradient for decoder.decoder.0.bias: 9.02031782601398e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005157492123544216\n",
      "Gradient for decoder.decoder.1.bias: 0.0004102096427232027\n",
      "Gradient for decoder.decoder.3.weight: 0.009844341315329075\n",
      "Gradient for decoder.decoder.3.bias: 8.045816096702296e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00037820806028321385\n",
      "Gradient for decoder.decoder.4.bias: 0.00031746254535391927\n",
      "Gradient for decoder.decoder.6.weight: 0.0009538113372400403\n",
      "Gradient for decoder.decoder.6.bias: 4.9352460337104276e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.004917565733194351\n",
      "Gradient for encoder.encoder.0.bias: 7.67582872263084e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.0004877737956121564\n",
      "Gradient for encoder.encoder.1.bias: 0.0004984351107850671\n",
      "Gradient for encoder.encoder.3.weight: 0.009991267696022987\n",
      "Gradient for encoder.encoder.3.bias: 9.052671112730337e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.002495001070201397\n",
      "Gradient for encoder.encoder.4.bias: 0.0018547758227214217\n",
      "Gradient for encoder.mean.weight: 0.03844593092799187\n",
      "Gradient for encoder.mean.bias: 0.0012963999761268497\n",
      "Gradient for encoder.log_var.weight: 0.01893257349729538\n",
      "Gradient for encoder.log_var.bias: 0.0008579887798987329\n",
      "Gradient for decoder.decoder.0.weight: 0.010137133300304413\n",
      "Gradient for decoder.decoder.0.bias: 8.186496619488892e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.000496272521559149\n",
      "Gradient for decoder.decoder.1.bias: 0.00042133888928219676\n",
      "Gradient for decoder.decoder.3.weight: 0.009763531386852264\n",
      "Gradient for decoder.decoder.3.bias: 8.312723426273649e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0003302170371171087\n",
      "Gradient for decoder.decoder.4.bias: 0.0003273783659096807\n",
      "Gradient for decoder.decoder.6.weight: 0.0009252408053725958\n",
      "Gradient for decoder.decoder.6.bias: 5.270837573334575e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.008041610941290855\n",
      "Gradient for encoder.encoder.0.bias: 1.0434232471101534e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.00047743337927386165\n",
      "Gradient for encoder.encoder.1.bias: 0.00046269234735518694\n",
      "Gradient for encoder.encoder.3.weight: 0.010241038165986538\n",
      "Gradient for encoder.encoder.3.bias: 1.095240356741023e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.002587303752079606\n",
      "Gradient for encoder.encoder.4.bias: 0.0022603243123739958\n",
      "Gradient for encoder.mean.weight: 0.03670075908303261\n",
      "Gradient for encoder.mean.bias: 0.0017497064545750618\n",
      "Gradient for encoder.log_var.weight: 0.02081162855029106\n",
      "Gradient for encoder.log_var.bias: 0.0011074654757976532\n",
      "Gradient for decoder.decoder.0.weight: 0.009185565635561943\n",
      "Gradient for decoder.decoder.0.bias: 8.03355160172714e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.00041969618177972734\n",
      "Gradient for decoder.decoder.1.bias: 0.00037999675259925425\n",
      "Gradient for decoder.decoder.3.weight: 0.008425882086157799\n",
      "Gradient for decoder.decoder.3.bias: 6.872818286707272e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00030971711385063827\n",
      "Gradient for decoder.decoder.4.bias: 0.00029687865753658116\n",
      "Gradient for decoder.decoder.6.weight: 0.0008826923440210521\n",
      "Gradient for decoder.decoder.6.bias: 4.1889441490639e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.009135199710726738\n",
      "Gradient for encoder.encoder.0.bias: 1.3607232528245472e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0004601934633683413\n",
      "Gradient for encoder.encoder.1.bias: 0.0004567648284137249\n",
      "Gradient for encoder.encoder.3.weight: 0.010261813178658485\n",
      "Gradient for encoder.encoder.3.bias: 1.243127961680912e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0027142451144754887\n",
      "Gradient for encoder.encoder.4.bias: 0.00243097310885787\n",
      "Gradient for encoder.mean.weight: 0.03754422813653946\n",
      "Gradient for encoder.mean.bias: 0.0017948182066902518\n",
      "Gradient for encoder.log_var.weight: 0.021268432959914207\n",
      "Gradient for encoder.log_var.bias: 0.0010645078727975488\n",
      "Gradient for decoder.decoder.0.weight: 0.008392506279051304\n",
      "Gradient for decoder.decoder.0.bias: 7.7508437168472e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.00041873331065289676\n",
      "Gradient for decoder.decoder.1.bias: 0.0003404877206776291\n",
      "Gradient for decoder.decoder.3.weight: 0.007890360429883003\n",
      "Gradient for decoder.decoder.3.bias: 6.812868325045685e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00034754833905026317\n",
      "Gradient for decoder.decoder.4.bias: 0.000362984137609601\n",
      "Gradient for decoder.decoder.6.weight: 0.0009695696062408388\n",
      "Gradient for decoder.decoder.6.bias: 6.15754397585988e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.006397423800081015\n",
      "Gradient for encoder.encoder.0.bias: 9.814486029435798e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.00038367780507542193\n",
      "Gradient for encoder.encoder.1.bias: 0.0004104269319213927\n",
      "Gradient for encoder.encoder.3.weight: 0.008292402140796185\n",
      "Gradient for encoder.encoder.3.bias: 9.54808385134065e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.001991758355870843\n",
      "Gradient for encoder.encoder.4.bias: 0.0016077245818451047\n",
      "Gradient for encoder.mean.weight: 0.029064064845442772\n",
      "Gradient for encoder.mean.bias: 0.0013529193820431828\n",
      "Gradient for encoder.log_var.weight: 0.015498599037528038\n",
      "Gradient for encoder.log_var.bias: 0.0007655943045392632\n",
      "Gradient for decoder.decoder.0.weight: 0.008724838495254517\n",
      "Gradient for decoder.decoder.0.bias: 7.473169305605154e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.00042796420166268945\n",
      "Gradient for decoder.decoder.1.bias: 0.00038354285061359406\n",
      "Gradient for decoder.decoder.3.weight: 0.008405626751482487\n",
      "Gradient for decoder.decoder.3.bias: 7.780717736771692e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0005301720229908824\n",
      "Gradient for decoder.decoder.4.bias: 0.0006397030665539205\n",
      "Gradient for decoder.decoder.6.weight: 0.0010792688699439168\n",
      "Gradient for decoder.decoder.6.bias: 8.527946192771196e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.0038118110969662666\n",
      "Gradient for encoder.encoder.0.bias: 5.894075158496825e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.00036257621832191944\n",
      "Gradient for encoder.encoder.1.bias: 0.00037754824734292924\n",
      "Gradient for encoder.encoder.3.weight: 0.008030186407268047\n",
      "Gradient for encoder.encoder.3.bias: 9.05398950257208e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.002829172182828188\n",
      "Gradient for encoder.encoder.4.bias: 0.002284639747813344\n",
      "Gradient for encoder.mean.weight: 0.04058917611837387\n",
      "Gradient for encoder.mean.bias: 0.0018346159486100078\n",
      "Gradient for encoder.log_var.weight: 0.02094753086566925\n",
      "Gradient for encoder.log_var.bias: 0.0010281678987666965\n",
      "Gradient for decoder.decoder.0.weight: 0.011440650559961796\n",
      "Gradient for decoder.decoder.0.bias: 1.0118447746343406e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0005499689723365009\n",
      "Gradient for decoder.decoder.1.bias: 0.0004785859491676092\n",
      "Gradient for decoder.decoder.3.weight: 0.010700402781367302\n",
      "Gradient for decoder.decoder.3.bias: 9.488569652216228e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00043867246131412685\n",
      "Gradient for decoder.decoder.4.bias: 0.00047435026499442756\n",
      "Gradient for decoder.decoder.6.weight: 0.001050056773237884\n",
      "Gradient for decoder.decoder.6.bias: 7.462547364411876e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.005324323661625385\n",
      "Gradient for encoder.encoder.0.bias: 6.956572470850908e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.00039230307447724044\n",
      "Gradient for encoder.encoder.1.bias: 0.0003963425406254828\n",
      "Gradient for encoder.encoder.3.weight: 0.008590733632445335\n",
      "Gradient for encoder.encoder.3.bias: 9.195824657304286e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.0023259965237230062\n",
      "Gradient for encoder.encoder.4.bias: 0.0018322173273190856\n",
      "Gradient for encoder.mean.weight: 0.03280069679021835\n",
      "Gradient for encoder.mean.bias: 0.0015292743919417262\n",
      "Gradient for encoder.log_var.weight: 0.018398623913526535\n",
      "Gradient for encoder.log_var.bias: 0.0009506215574219823\n",
      "Gradient for decoder.decoder.0.weight: 0.010804402641952038\n",
      "Gradient for decoder.decoder.0.bias: 9.179182414165155e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.000545299204532057\n",
      "Gradient for decoder.decoder.1.bias: 0.0004419682954903692\n",
      "Gradient for decoder.decoder.3.weight: 0.010257391259074211\n",
      "Gradient for decoder.decoder.3.bias: 8.852737293230106e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0004421261546667665\n",
      "Gradient for decoder.decoder.4.bias: 0.00044138627708889544\n",
      "Gradient for decoder.decoder.6.weight: 0.0009436008404009044\n",
      "Gradient for decoder.decoder.6.bias: 5.428463191492483e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.006489893887192011\n",
      "Gradient for encoder.encoder.0.bias: 7.89809363743732e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.00033323856769129634\n",
      "Gradient for encoder.encoder.1.bias: 0.000348534929798916\n",
      "Gradient for encoder.encoder.3.weight: 0.007567601278424263\n",
      "Gradient for encoder.encoder.3.bias: 9.568414116589707e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.0025238310918211937\n",
      "Gradient for encoder.encoder.4.bias: 0.002126231323927641\n",
      "Gradient for encoder.mean.weight: 0.033990561962127686\n",
      "Gradient for encoder.mean.bias: 0.001543498015962541\n",
      "Gradient for encoder.log_var.weight: 0.020198334008455276\n",
      "Gradient for encoder.log_var.bias: 0.0010552732273936272\n",
      "Gradient for decoder.decoder.0.weight: 0.009860897436738014\n",
      "Gradient for decoder.decoder.0.bias: 7.682454672419681e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.00047993165208026767\n",
      "Gradient for decoder.decoder.1.bias: 0.00038667101762257516\n",
      "Gradient for decoder.decoder.3.weight: 0.009092767722904682\n",
      "Gradient for decoder.decoder.3.bias: 7.221754444453055e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00032313255360350013\n",
      "Gradient for decoder.decoder.4.bias: 0.00029294617706909776\n",
      "Gradient for decoder.decoder.6.weight: 0.0009591997368261218\n",
      "Gradient for decoder.decoder.6.bias: 5.5446573242079467e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.006537762936204672\n",
      "Gradient for encoder.encoder.0.bias: 8.077455371235942e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.00032009818824008107\n",
      "Gradient for encoder.encoder.1.bias: 0.00034048507222905755\n",
      "Gradient for encoder.encoder.3.weight: 0.006749986205250025\n",
      "Gradient for encoder.encoder.3.bias: 8.884647878515395e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.0020828256383538246\n",
      "Gradient for encoder.encoder.4.bias: 0.001836539595387876\n",
      "Gradient for encoder.mean.weight: 0.02953629568219185\n",
      "Gradient for encoder.mean.bias: 0.0014913601335138083\n",
      "Gradient for encoder.log_var.weight: 0.01684340089559555\n",
      "Gradient for encoder.log_var.bias: 0.0008701257756911218\n",
      "Gradient for decoder.decoder.0.weight: 0.009028585627675056\n",
      "Gradient for decoder.decoder.0.bias: 7.673827545628953e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.00042844246490858495\n",
      "Gradient for decoder.decoder.1.bias: 0.00037299227551557124\n",
      "Gradient for decoder.decoder.3.weight: 0.008579978719353676\n",
      "Gradient for decoder.decoder.3.bias: 6.380445477516261e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0003458118299022317\n",
      "Gradient for decoder.decoder.4.bias: 0.00032625641324557364\n",
      "Gradient for decoder.decoder.6.weight: 0.0010363080073148012\n",
      "Gradient for decoder.decoder.6.bias: 6.772109190933406e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.005131212063133717\n",
      "Gradient for encoder.encoder.0.bias: 7.252563567067272e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.00038863212103024125\n",
      "Gradient for encoder.encoder.1.bias: 0.00035103404661640525\n",
      "Gradient for encoder.encoder.3.weight: 0.008241883479058743\n",
      "Gradient for encoder.encoder.3.bias: 8.762984088361847e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.0021597284357994795\n",
      "Gradient for encoder.encoder.4.bias: 0.0019903916399925947\n",
      "Gradient for encoder.mean.weight: 0.030727729201316833\n",
      "Gradient for encoder.mean.bias: 0.0015825966838747263\n",
      "Gradient for encoder.log_var.weight: 0.016841325908899307\n",
      "Gradient for encoder.log_var.bias: 0.0009526183712296188\n",
      "Gradient for decoder.decoder.0.weight: 0.010606273077428341\n",
      "Gradient for decoder.decoder.0.bias: 9.374326315203518e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005090035265311599\n",
      "Gradient for decoder.decoder.1.bias: 0.00043920011376030743\n",
      "Gradient for decoder.decoder.3.weight: 0.009581324644386768\n",
      "Gradient for decoder.decoder.3.bias: 8.089391656529443e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00039574975380674005\n",
      "Gradient for decoder.decoder.4.bias: 0.0003594956360757351\n",
      "Gradient for decoder.decoder.6.weight: 0.0009651183499954641\n",
      "Gradient for decoder.decoder.6.bias: 5.424491973826662e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training VAE Epoch:  52%|█████▏    | 41/79 [00:00<00:00, 68.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient for encoder.encoder.0.weight: 0.004074765369296074\n",
      "Gradient for encoder.encoder.0.bias: 6.022200967070734e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.00031268742168322206\n",
      "Gradient for encoder.encoder.1.bias: 0.0003179292834829539\n",
      "Gradient for encoder.encoder.3.weight: 0.0071126678958535194\n",
      "Gradient for encoder.encoder.3.bias: 7.794625361823293e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.0020106774754822254\n",
      "Gradient for encoder.encoder.4.bias: 0.0015547166112810373\n",
      "Gradient for encoder.mean.weight: 0.029128285124897957\n",
      "Gradient for encoder.mean.bias: 0.0011672286782413721\n",
      "Gradient for encoder.log_var.weight: 0.017193835228681564\n",
      "Gradient for encoder.log_var.bias: 0.0007256495882757008\n",
      "Gradient for decoder.decoder.0.weight: 0.011187420226633549\n",
      "Gradient for decoder.decoder.0.bias: 9.44589892415415e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005130552453920245\n",
      "Gradient for decoder.decoder.1.bias: 0.0004604389541782439\n",
      "Gradient for decoder.decoder.3.weight: 0.01043582335114479\n",
      "Gradient for decoder.decoder.3.bias: 8.595213429885007e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00045569450594484806\n",
      "Gradient for decoder.decoder.4.bias: 0.0004532649472821504\n",
      "Gradient for decoder.decoder.6.weight: 0.0011084952857345343\n",
      "Gradient for decoder.decoder.6.bias: 7.56552180973813e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.005657513160258532\n",
      "Gradient for encoder.encoder.0.bias: 8.060774270290949e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.000382457859814167\n",
      "Gradient for encoder.encoder.1.bias: 0.00040676110074855387\n",
      "Gradient for encoder.encoder.3.weight: 0.008759143762290478\n",
      "Gradient for encoder.encoder.3.bias: 8.298150361296663e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.0024444435257464647\n",
      "Gradient for encoder.encoder.4.bias: 0.0016015832079574466\n",
      "Gradient for encoder.mean.weight: 0.03440893813967705\n",
      "Gradient for encoder.mean.bias: 0.0011704042553901672\n",
      "Gradient for encoder.log_var.weight: 0.01810462959110737\n",
      "Gradient for encoder.log_var.bias: 0.0008000636007636786\n",
      "Gradient for decoder.decoder.0.weight: 0.009788526222109795\n",
      "Gradient for decoder.decoder.0.bias: 9.240200271598553e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.00043783156434074044\n",
      "Gradient for decoder.decoder.1.bias: 0.0004011974669992924\n",
      "Gradient for decoder.decoder.3.weight: 0.008887936361134052\n",
      "Gradient for decoder.decoder.3.bias: 7.748433838994373e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00035506620770320296\n",
      "Gradient for decoder.decoder.4.bias: 0.0003827508771792054\n",
      "Gradient for decoder.decoder.6.weight: 0.0010557192144915462\n",
      "Gradient for decoder.decoder.6.bias: 7.638678653165698e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.007535818498581648\n",
      "Gradient for encoder.encoder.0.bias: 9.302098154251315e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.0005098307156004012\n",
      "Gradient for encoder.encoder.1.bias: 0.0004967103013768792\n",
      "Gradient for encoder.encoder.3.weight: 0.011302241124212742\n",
      "Gradient for encoder.encoder.3.bias: 1.0588530052757505e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0028141760267317295\n",
      "Gradient for encoder.encoder.4.bias: 0.0024116174317896366\n",
      "Gradient for encoder.mean.weight: 0.03825559839606285\n",
      "Gradient for encoder.mean.bias: 0.001821016543544829\n",
      "Gradient for encoder.log_var.weight: 0.022289197891950607\n",
      "Gradient for encoder.log_var.bias: 0.0012400953564792871\n",
      "Gradient for decoder.decoder.0.weight: 0.01049361564218998\n",
      "Gradient for decoder.decoder.0.bias: 8.186170491475409e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0004687031323555857\n",
      "Gradient for decoder.decoder.1.bias: 0.0004325980262365192\n",
      "Gradient for decoder.decoder.3.weight: 0.009648168459534645\n",
      "Gradient for decoder.decoder.3.bias: 7.17914130921038e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0003527218068484217\n",
      "Gradient for decoder.decoder.4.bias: 0.000291549222311005\n",
      "Gradient for decoder.decoder.6.weight: 0.000947621010709554\n",
      "Gradient for decoder.decoder.6.bias: 4.2130759538849816e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.004111165180802345\n",
      "Gradient for encoder.encoder.0.bias: 5.986192010837277e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.000344753178069368\n",
      "Gradient for encoder.encoder.1.bias: 0.00031493642018176615\n",
      "Gradient for encoder.encoder.3.weight: 0.0073237232863903046\n",
      "Gradient for encoder.encoder.3.bias: 7.952435238101074e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.0021778461523354053\n",
      "Gradient for encoder.encoder.4.bias: 0.0015991067048162222\n",
      "Gradient for encoder.mean.weight: 0.03246995061635971\n",
      "Gradient for encoder.mean.bias: 0.0012933618854731321\n",
      "Gradient for encoder.log_var.weight: 0.018093163147568703\n",
      "Gradient for encoder.log_var.bias: 0.0008285780204460025\n",
      "Gradient for decoder.decoder.0.weight: 0.012155693955719471\n",
      "Gradient for decoder.decoder.0.bias: 1.1121832621530103e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0006180951022543013\n",
      "Gradient for decoder.decoder.1.bias: 0.0004906410467810929\n",
      "Gradient for decoder.decoder.3.weight: 0.011732945218682289\n",
      "Gradient for decoder.decoder.3.bias: 8.984346600016124e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0004587539006024599\n",
      "Gradient for decoder.decoder.4.bias: 0.00040725068538449705\n",
      "Gradient for decoder.decoder.6.weight: 0.0009402174036949873\n",
      "Gradient for decoder.decoder.6.bias: 5.1063630962744355e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.0067284926772117615\n",
      "Gradient for encoder.encoder.0.bias: 1.008246871408991e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0003740625688806176\n",
      "Gradient for encoder.encoder.1.bias: 0.00040504580829292536\n",
      "Gradient for encoder.encoder.3.weight: 0.008407075889408588\n",
      "Gradient for encoder.encoder.3.bias: 9.290308800036229e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.002056798432022333\n",
      "Gradient for encoder.encoder.4.bias: 0.0016591391758993268\n",
      "Gradient for encoder.mean.weight: 0.030803855508565903\n",
      "Gradient for encoder.mean.bias: 0.0012559819733723998\n",
      "Gradient for encoder.log_var.weight: 0.017890969291329384\n",
      "Gradient for encoder.log_var.bias: 0.0008191379019990563\n",
      "Gradient for decoder.decoder.0.weight: 0.009014281444251537\n",
      "Gradient for decoder.decoder.0.bias: 7.991893258285643e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0004440437478478998\n",
      "Gradient for decoder.decoder.1.bias: 0.0004069434362463653\n",
      "Gradient for decoder.decoder.3.weight: 0.008502100594341755\n",
      "Gradient for decoder.decoder.3.bias: 7.531845286345984e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00037865061312913895\n",
      "Gradient for decoder.decoder.4.bias: 0.0003824508748948574\n",
      "Gradient for decoder.decoder.6.weight: 0.0008874095510691404\n",
      "Gradient for decoder.decoder.6.bias: 4.507462290348485e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.004213279578834772\n",
      "Gradient for encoder.encoder.0.bias: 7.080710583834415e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.00032398762414231896\n",
      "Gradient for encoder.encoder.1.bias: 0.0003868713683914393\n",
      "Gradient for encoder.encoder.3.weight: 0.00751427561044693\n",
      "Gradient for encoder.encoder.3.bias: 7.998305490142243e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.002083932049572468\n",
      "Gradient for encoder.encoder.4.bias: 0.0015222186921164393\n",
      "Gradient for encoder.mean.weight: 0.030110914260149002\n",
      "Gradient for encoder.mean.bias: 0.0011317722965031862\n",
      "Gradient for encoder.log_var.weight: 0.016458887606859207\n",
      "Gradient for encoder.log_var.bias: 0.0006992201670072973\n",
      "Gradient for decoder.decoder.0.weight: 0.009571673348546028\n",
      "Gradient for decoder.decoder.0.bias: 7.612460661832188e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.000444930192315951\n",
      "Gradient for decoder.decoder.1.bias: 0.0003665068943519145\n",
      "Gradient for decoder.decoder.3.weight: 0.00879355426877737\n",
      "Gradient for decoder.decoder.3.bias: 7.753217512451727e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00043434390681795776\n",
      "Gradient for decoder.decoder.4.bias: 0.0004975978517904878\n",
      "Gradient for decoder.decoder.6.weight: 0.0009366532904095948\n",
      "Gradient for decoder.decoder.6.bias: 6.265291449381039e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.010660761035978794\n",
      "Gradient for encoder.encoder.0.bias: 1.6899258034608344e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0005449091549962759\n",
      "Gradient for encoder.encoder.1.bias: 0.0005325698293745518\n",
      "Gradient for encoder.encoder.3.weight: 0.011592581868171692\n",
      "Gradient for encoder.encoder.3.bias: 1.1341783762164326e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.002451615873724222\n",
      "Gradient for encoder.encoder.4.bias: 0.0018477158155292273\n",
      "Gradient for encoder.mean.weight: 0.03490319103002548\n",
      "Gradient for encoder.mean.bias: 0.0013212078483775258\n",
      "Gradient for encoder.log_var.weight: 0.018446719273924828\n",
      "Gradient for encoder.log_var.bias: 0.0008297939784824848\n",
      "Gradient for decoder.decoder.0.weight: 0.008115706965327263\n",
      "Gradient for decoder.decoder.0.bias: 6.506881145007526e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0003909992810804397\n",
      "Gradient for decoder.decoder.1.bias: 0.00032194217783398926\n",
      "Gradient for decoder.decoder.3.weight: 0.00736431498080492\n",
      "Gradient for decoder.decoder.3.bias: 6.980892253150017e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00043033325346186757\n",
      "Gradient for decoder.decoder.4.bias: 0.0004920997307635844\n",
      "Gradient for decoder.decoder.6.weight: 0.0009440422873012722\n",
      "Gradient for decoder.decoder.6.bias: 5.9304591559339315e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.0062126945704221725\n",
      "Gradient for encoder.encoder.0.bias: 8.620883520937817e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.0003935012500733137\n",
      "Gradient for encoder.encoder.1.bias: 0.0003704401315189898\n",
      "Gradient for encoder.encoder.3.weight: 0.008606984280049801\n",
      "Gradient for encoder.encoder.3.bias: 8.772935849998831e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.0021852005738765\n",
      "Gradient for encoder.encoder.4.bias: 0.0016207406297326088\n",
      "Gradient for encoder.mean.weight: 0.029437221586704254\n",
      "Gradient for encoder.mean.bias: 0.0011592201190069318\n",
      "Gradient for encoder.log_var.weight: 0.01690935157239437\n",
      "Gradient for encoder.log_var.bias: 0.0008667469955980778\n",
      "Gradient for decoder.decoder.0.weight: 0.009084313176572323\n",
      "Gradient for decoder.decoder.0.bias: 7.568418808334698e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.00041819518082775176\n",
      "Gradient for decoder.decoder.1.bias: 0.0004061881627421826\n",
      "Gradient for decoder.decoder.3.weight: 0.008527800440788269\n",
      "Gradient for decoder.decoder.3.bias: 7.295562071130135e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00037724984576925635\n",
      "Gradient for decoder.decoder.4.bias: 0.0003934380365535617\n",
      "Gradient for decoder.decoder.6.weight: 0.0009897147538140416\n",
      "Gradient for decoder.decoder.6.bias: 6.135724834166467e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.007270000874996185\n",
      "Gradient for encoder.encoder.0.bias: 1.203509254060764e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0003914428234566003\n",
      "Gradient for encoder.encoder.1.bias: 0.00038513296749442816\n",
      "Gradient for encoder.encoder.3.weight: 0.00853585172444582\n",
      "Gradient for encoder.encoder.3.bias: 9.001312889500568e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.0019149300642311573\n",
      "Gradient for encoder.encoder.4.bias: 0.0014881558017805219\n",
      "Gradient for encoder.mean.weight: 0.027558457106351852\n",
      "Gradient for encoder.mean.bias: 0.0011013965122401714\n",
      "Gradient for encoder.log_var.weight: 0.014295153319835663\n",
      "Gradient for encoder.log_var.bias: 0.0007831996772438288\n",
      "Gradient for decoder.decoder.0.weight: 0.008104056119918823\n",
      "Gradient for decoder.decoder.0.bias: 6.804705410257128e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0003944605414289981\n",
      "Gradient for decoder.decoder.1.bias: 0.00032971499604173005\n",
      "Gradient for decoder.decoder.3.weight: 0.0076571316458284855\n",
      "Gradient for decoder.decoder.3.bias: 5.89013282592532e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0003098010492976755\n",
      "Gradient for decoder.decoder.4.bias: 0.0002776375913526863\n",
      "Gradient for decoder.decoder.6.weight: 0.0009375465451739728\n",
      "Gradient for decoder.decoder.6.bias: 5.1492053898982704e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.004054957535117865\n",
      "Gradient for encoder.encoder.0.bias: 5.976217784531279e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.00041456479812040925\n",
      "Gradient for encoder.encoder.1.bias: 0.0005177305429242551\n",
      "Gradient for encoder.encoder.3.weight: 0.00861672218888998\n",
      "Gradient for encoder.encoder.3.bias: 8.511683025069772e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.0029274430125951767\n",
      "Gradient for encoder.encoder.4.bias: 0.001999873900786042\n",
      "Gradient for encoder.mean.weight: 0.04009491950273514\n",
      "Gradient for encoder.mean.bias: 0.001444759895093739\n",
      "Gradient for encoder.log_var.weight: 0.02423577755689621\n",
      "Gradient for encoder.log_var.bias: 0.0009363740682601929\n",
      "Gradient for decoder.decoder.0.weight: 0.011106545105576515\n",
      "Gradient for decoder.decoder.0.bias: 9.658632227349528e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0004988228320144117\n",
      "Gradient for decoder.decoder.1.bias: 0.00046039014705456793\n",
      "Gradient for decoder.decoder.3.weight: 0.009994864463806152\n",
      "Gradient for decoder.decoder.3.bias: 7.454658418337701e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.000436992704635486\n",
      "Gradient for decoder.decoder.4.bias: 0.0003993005375377834\n",
      "Gradient for decoder.decoder.6.weight: 0.0009114791755564511\n",
      "Gradient for decoder.decoder.6.bias: 4.742529563372955e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.0041837505996227264\n",
      "Gradient for encoder.encoder.0.bias: 5.9233911178790954e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.00039947425830177963\n",
      "Gradient for encoder.encoder.1.bias: 0.0004502018273342401\n",
      "Gradient for encoder.encoder.3.weight: 0.008818604983389378\n",
      "Gradient for encoder.encoder.3.bias: 8.709408194640389e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.00240043131634593\n",
      "Gradient for encoder.encoder.4.bias: 0.0017415927723050117\n",
      "Gradient for encoder.mean.weight: 0.03276202455163002\n",
      "Gradient for encoder.mean.bias: 0.0012362155830487609\n",
      "Gradient for encoder.log_var.weight: 0.020694324746727943\n",
      "Gradient for encoder.log_var.bias: 0.0009308874141424894\n",
      "Gradient for decoder.decoder.0.weight: 0.012176668271422386\n",
      "Gradient for decoder.decoder.0.bias: 1.0451221832408208e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.000569045718293637\n",
      "Gradient for decoder.decoder.1.bias: 0.0005183641915209591\n",
      "Gradient for decoder.decoder.3.weight: 0.011490017175674438\n",
      "Gradient for decoder.decoder.3.bias: 8.996853262388527e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0004972395836375654\n",
      "Gradient for decoder.decoder.4.bias: 0.0004984270199202001\n",
      "Gradient for decoder.decoder.6.weight: 0.0009810036281123757\n",
      "Gradient for decoder.decoder.6.bias: 5.234553827904165e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.0058685303665697575\n",
      "Gradient for encoder.encoder.0.bias: 7.088339464000892e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.0003688635479193181\n",
      "Gradient for encoder.encoder.1.bias: 0.000436472735600546\n",
      "Gradient for encoder.encoder.3.weight: 0.008366523310542107\n",
      "Gradient for encoder.encoder.3.bias: 8.506518406337094e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.002167909871786833\n",
      "Gradient for encoder.encoder.4.bias: 0.0017309453105553985\n",
      "Gradient for encoder.mean.weight: 0.03197631612420082\n",
      "Gradient for encoder.mean.bias: 0.0011898091761395335\n",
      "Gradient for encoder.log_var.weight: 0.018109580501914024\n",
      "Gradient for encoder.log_var.bias: 0.0009001188445836306\n",
      "Gradient for decoder.decoder.0.weight: 0.01006535068154335\n",
      "Gradient for decoder.decoder.0.bias: 8.437046200571174e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0004712351073976606\n",
      "Gradient for decoder.decoder.1.bias: 0.0003884353209286928\n",
      "Gradient for decoder.decoder.3.weight: 0.009054979309439659\n",
      "Gradient for decoder.decoder.3.bias: 7.032799342887586e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0003378471883479506\n",
      "Gradient for decoder.decoder.4.bias: 0.0003164118097629398\n",
      "Gradient for decoder.decoder.6.weight: 0.0009210438001900911\n",
      "Gradient for decoder.decoder.6.bias: 5.2530249377014115e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.005818517412990332\n",
      "Gradient for encoder.encoder.0.bias: 8.246937854838876e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.00034066775697283447\n",
      "Gradient for encoder.encoder.1.bias: 0.0004027309187222272\n",
      "Gradient for encoder.encoder.3.weight: 0.007298548240214586\n",
      "Gradient for encoder.encoder.3.bias: 8.925256367309231e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.0021601549815386534\n",
      "Gradient for encoder.encoder.4.bias: 0.0016641870606690645\n",
      "Gradient for encoder.mean.weight: 0.035111162811517715\n",
      "Gradient for encoder.mean.bias: 0.001296325121074915\n",
      "Gradient for encoder.log_var.weight: 0.018433108925819397\n",
      "Gradient for encoder.log_var.bias: 0.0009035510593093932\n",
      "Gradient for decoder.decoder.0.weight: 0.010411569848656654\n",
      "Gradient for decoder.decoder.0.bias: 9.15342315832568e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005228989757597446\n",
      "Gradient for decoder.decoder.1.bias: 0.0004327806527726352\n",
      "Gradient for decoder.decoder.3.weight: 0.009879945777356625\n",
      "Gradient for decoder.decoder.3.bias: 8.55771217778134e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0005186339840292931\n",
      "Gradient for decoder.decoder.4.bias: 0.0005729977274313569\n",
      "Gradient for decoder.decoder.6.weight: 0.0011725235963240266\n",
      "Gradient for decoder.decoder.6.bias: 9.136085282079875e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.00574107002466917\n",
      "Gradient for encoder.encoder.0.bias: 7.193879606598452e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.0003293071349617094\n",
      "Gradient for encoder.encoder.1.bias: 0.00035107057192362845\n",
      "Gradient for encoder.encoder.3.weight: 0.007391493767499924\n",
      "Gradient for encoder.encoder.3.bias: 8.527697298310599e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.002295851241797209\n",
      "Gradient for encoder.encoder.4.bias: 0.0015431626234203577\n",
      "Gradient for encoder.mean.weight: 0.031126953661441803\n",
      "Gradient for encoder.mean.bias: 0.0010707797482609749\n",
      "Gradient for encoder.log_var.weight: 0.019716480746865273\n",
      "Gradient for encoder.log_var.bias: 0.0007715586107224226\n",
      "Gradient for decoder.decoder.0.weight: 0.010612774640321732\n",
      "Gradient for decoder.decoder.0.bias: 9.352792845751523e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0004680016136262566\n",
      "Gradient for decoder.decoder.1.bias: 0.0004275048850104213\n",
      "Gradient for decoder.decoder.3.weight: 0.009681954979896545\n",
      "Gradient for decoder.decoder.3.bias: 6.777862299189863e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0003871701192110777\n",
      "Gradient for decoder.decoder.4.bias: 0.0003678769280668348\n",
      "Gradient for decoder.decoder.6.weight: 0.00095891032833606\n",
      "Gradient for decoder.decoder.6.bias: 5.4092448408482596e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.0048935143277049065\n",
      "Gradient for encoder.encoder.0.bias: 7.194321527403957e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.00047178714885376394\n",
      "Gradient for encoder.encoder.1.bias: 0.00041134312050417066\n",
      "Gradient for encoder.encoder.3.weight: 0.01011357270181179\n",
      "Gradient for encoder.encoder.3.bias: 8.079879820765967e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.0024933149106800556\n",
      "Gradient for encoder.encoder.4.bias: 0.0015879005659371614\n",
      "Gradient for encoder.mean.weight: 0.03504408523440361\n",
      "Gradient for encoder.mean.bias: 0.0010974463075399399\n",
      "Gradient for encoder.log_var.weight: 0.020003948360681534\n",
      "Gradient for encoder.log_var.bias: 0.0007740936707705259\n",
      "Gradient for decoder.decoder.0.weight: 0.010754864662885666\n",
      "Gradient for decoder.decoder.0.bias: 9.285507779344115e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0004919201019220054\n",
      "Gradient for decoder.decoder.1.bias: 0.0004601522523444146\n",
      "Gradient for decoder.decoder.3.weight: 0.009694441221654415\n",
      "Gradient for decoder.decoder.3.bias: 7.909622262713967e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0004183773708064109\n",
      "Gradient for decoder.decoder.4.bias: 0.0004244496813043952\n",
      "Gradient for decoder.decoder.6.weight: 0.0011508348397910595\n",
      "Gradient for decoder.decoder.6.bias: 8.642436296213418e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.007008407264947891\n",
      "Gradient for encoder.encoder.0.bias: 9.784057244943689e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.00045291383867152035\n",
      "Gradient for encoder.encoder.1.bias: 0.00038590520853176713\n",
      "Gradient for encoder.encoder.3.weight: 0.009563353843986988\n",
      "Gradient for encoder.encoder.3.bias: 1.01557665055374e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.002285867929458618\n",
      "Gradient for encoder.encoder.4.bias: 0.0019861157052218914\n",
      "Gradient for encoder.mean.weight: 0.03280234336853027\n",
      "Gradient for encoder.mean.bias: 0.0014934021746739745\n",
      "Gradient for encoder.log_var.weight: 0.017100412398576736\n",
      "Gradient for encoder.log_var.bias: 0.0009839438134804368\n",
      "Gradient for decoder.decoder.0.weight: 0.010045604780316353\n",
      "Gradient for decoder.decoder.0.bias: 9.525308319879855e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.00048690641415305436\n",
      "Gradient for decoder.decoder.1.bias: 0.0004156884679105133\n",
      "Gradient for decoder.decoder.3.weight: 0.009140485897660255\n",
      "Gradient for decoder.decoder.3.bias: 8.274246565687093e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0004747316415887326\n",
      "Gradient for decoder.decoder.4.bias: 0.0005116640240885317\n",
      "Gradient for decoder.decoder.6.weight: 0.0009966081706807017\n",
      "Gradient for decoder.decoder.6.bias: 5.8989364333683625e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training VAE Epoch:  72%|███████▏  | 57/79 [00:00<00:00, 72.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient for encoder.encoder.0.weight: 0.004268408752977848\n",
      "Gradient for encoder.encoder.0.bias: 6.3379019914211465e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.0003425429167691618\n",
      "Gradient for encoder.encoder.1.bias: 0.00032979127718135715\n",
      "Gradient for encoder.encoder.3.weight: 0.007391878869384527\n",
      "Gradient for encoder.encoder.3.bias: 8.545106983115502e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.002108002547174692\n",
      "Gradient for encoder.encoder.4.bias: 0.0016719712875783443\n",
      "Gradient for encoder.mean.weight: 0.032214727252721786\n",
      "Gradient for encoder.mean.bias: 0.0012146048247814178\n",
      "Gradient for encoder.log_var.weight: 0.01745016686618328\n",
      "Gradient for encoder.log_var.bias: 0.0009074005065485835\n",
      "Gradient for decoder.decoder.0.weight: 0.010519452393054962\n",
      "Gradient for decoder.decoder.0.bias: 8.220729652563818e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005027123843319714\n",
      "Gradient for decoder.decoder.1.bias: 0.0004563750990200788\n",
      "Gradient for decoder.decoder.3.weight: 0.010166735388338566\n",
      "Gradient for decoder.decoder.3.bias: 7.675520635741506e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0005032641347497702\n",
      "Gradient for decoder.decoder.4.bias: 0.0004707821935880929\n",
      "Gradient for decoder.decoder.6.weight: 0.0010513938032090664\n",
      "Gradient for decoder.decoder.6.bias: 6.163840589579195e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.008908131159842014\n",
      "Gradient for encoder.encoder.0.bias: 1.2520764806900342e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0005097309476695955\n",
      "Gradient for encoder.encoder.1.bias: 0.00048315763706341386\n",
      "Gradient for encoder.encoder.3.weight: 0.011261255480349064\n",
      "Gradient for encoder.encoder.3.bias: 9.854884963633737e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.00252061546780169\n",
      "Gradient for encoder.encoder.4.bias: 0.0018009589985013008\n",
      "Gradient for encoder.mean.weight: 0.03597830608487129\n",
      "Gradient for encoder.mean.bias: 0.0013619818491861224\n",
      "Gradient for encoder.log_var.weight: 0.018303142860531807\n",
      "Gradient for encoder.log_var.bias: 0.0008900042739696801\n",
      "Gradient for decoder.decoder.0.weight: 0.007834343239665031\n",
      "Gradient for decoder.decoder.0.bias: 6.112610417829956e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0003819128905888647\n",
      "Gradient for decoder.decoder.1.bias: 0.00032370758708566427\n",
      "Gradient for decoder.decoder.3.weight: 0.007639785762876272\n",
      "Gradient for decoder.decoder.3.bias: 8.498902970277555e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0006186470272950828\n",
      "Gradient for decoder.decoder.4.bias: 0.0007773223333060741\n",
      "Gradient for decoder.decoder.6.weight: 0.0010729108471423388\n",
      "Gradient for decoder.decoder.6.bias: 7.684894080739468e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.006994607392698526\n",
      "Gradient for encoder.encoder.0.bias: 1.0994886424919859e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0004602775734383613\n",
      "Gradient for encoder.encoder.1.bias: 0.00039676521555520594\n",
      "Gradient for encoder.encoder.3.weight: 0.009547372348606586\n",
      "Gradient for encoder.encoder.3.bias: 9.764766079056741e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.0021752489265054464\n",
      "Gradient for encoder.encoder.4.bias: 0.0016280863201245666\n",
      "Gradient for encoder.mean.weight: 0.031537167727947235\n",
      "Gradient for encoder.mean.bias: 0.0011084935395047069\n",
      "Gradient for encoder.log_var.weight: 0.01866433396935463\n",
      "Gradient for encoder.log_var.bias: 0.0008417164208367467\n",
      "Gradient for decoder.decoder.0.weight: 0.008812102489173412\n",
      "Gradient for decoder.decoder.0.bias: 6.962100340679456e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0004654139920603484\n",
      "Gradient for decoder.decoder.1.bias: 0.0003889310173690319\n",
      "Gradient for decoder.decoder.3.weight: 0.00836858805269003\n",
      "Gradient for decoder.decoder.3.bias: 6.012167153013337e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0003200873325113207\n",
      "Gradient for decoder.decoder.4.bias: 0.00028046121587976813\n",
      "Gradient for decoder.decoder.6.weight: 0.000931855000089854\n",
      "Gradient for decoder.decoder.6.bias: 5.4738102335250005e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.004998855292797089\n",
      "Gradient for encoder.encoder.0.bias: 7.933008416838305e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.0003860489232465625\n",
      "Gradient for encoder.encoder.1.bias: 0.0003222422383259982\n",
      "Gradient for encoder.encoder.3.weight: 0.008276413194835186\n",
      "Gradient for encoder.encoder.3.bias: 8.117831407083997e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.0020241080783307552\n",
      "Gradient for encoder.encoder.4.bias: 0.0018027075566351414\n",
      "Gradient for encoder.mean.weight: 0.02908899635076523\n",
      "Gradient for encoder.mean.bias: 0.001322018331848085\n",
      "Gradient for encoder.log_var.weight: 0.017355812713503838\n",
      "Gradient for encoder.log_var.bias: 0.0009170249686576426\n",
      "Gradient for decoder.decoder.0.weight: 0.010290822945535183\n",
      "Gradient for decoder.decoder.0.bias: 8.059434369878105e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0004778646398335695\n",
      "Gradient for decoder.decoder.1.bias: 0.00040668854489922523\n",
      "Gradient for decoder.decoder.3.weight: 0.009426849894225597\n",
      "Gradient for decoder.decoder.3.bias: 7.653724876099943e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00037987969699315727\n",
      "Gradient for decoder.decoder.4.bias: 0.0003128403623122722\n",
      "Gradient for decoder.decoder.6.weight: 0.0009856047108769417\n",
      "Gradient for decoder.decoder.6.bias: 5.214109842199832e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.009610016830265522\n",
      "Gradient for encoder.encoder.0.bias: 1.3291138155346882e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.00048196170246228576\n",
      "Gradient for encoder.encoder.1.bias: 0.0005505566950887442\n",
      "Gradient for encoder.encoder.3.weight: 0.01086216326802969\n",
      "Gradient for encoder.encoder.3.bias: 1.0208558998137107e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.002217879518866539\n",
      "Gradient for encoder.encoder.4.bias: 0.0019951954018324614\n",
      "Gradient for encoder.mean.weight: 0.032761313021183014\n",
      "Gradient for encoder.mean.bias: 0.0015883715823292732\n",
      "Gradient for encoder.log_var.weight: 0.017569072544574738\n",
      "Gradient for encoder.log_var.bias: 0.0009946582140401006\n",
      "Gradient for decoder.decoder.0.weight: 0.007885962724685669\n",
      "Gradient for decoder.decoder.0.bias: 7.0416152075925e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.00038104632403701544\n",
      "Gradient for decoder.decoder.1.bias: 0.0003370826016180217\n",
      "Gradient for decoder.decoder.3.weight: 0.007741162553429604\n",
      "Gradient for decoder.decoder.3.bias: 6.643534333772294e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00037976892781443894\n",
      "Gradient for decoder.decoder.4.bias: 0.00039789744187146425\n",
      "Gradient for decoder.decoder.6.weight: 0.0009358379174955189\n",
      "Gradient for decoder.decoder.6.bias: 5.1297887694090605e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.006655725184828043\n",
      "Gradient for encoder.encoder.0.bias: 1.020079333502455e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0005135001847520471\n",
      "Gradient for encoder.encoder.1.bias: 0.00039241090416908264\n",
      "Gradient for encoder.encoder.3.weight: 0.0112793343141675\n",
      "Gradient for encoder.encoder.3.bias: 9.410133783305241e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.0022273645736277103\n",
      "Gradient for encoder.encoder.4.bias: 0.0016006877413019538\n",
      "Gradient for encoder.mean.weight: 0.03224747255444527\n",
      "Gradient for encoder.mean.bias: 0.0011565499007701874\n",
      "Gradient for encoder.log_var.weight: 0.016166919842362404\n",
      "Gradient for encoder.log_var.bias: 0.0007259941776283085\n",
      "Gradient for decoder.decoder.0.weight: 0.00936036929488182\n",
      "Gradient for decoder.decoder.0.bias: 8.029126669084619e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0004632051568478346\n",
      "Gradient for decoder.decoder.1.bias: 0.00038938591023907065\n",
      "Gradient for decoder.decoder.3.weight: 0.008765487931668758\n",
      "Gradient for decoder.decoder.3.bias: 6.789656337158334e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.000320572144119069\n",
      "Gradient for decoder.decoder.4.bias: 0.0002818175416905433\n",
      "Gradient for decoder.decoder.6.weight: 0.0009017352131195366\n",
      "Gradient for decoder.decoder.6.bias: 4.2947562178596854e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.0037191465962678194\n",
      "Gradient for encoder.encoder.0.bias: 5.366216151991843e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.0003491121460683644\n",
      "Gradient for encoder.encoder.1.bias: 0.00030676950700581074\n",
      "Gradient for encoder.encoder.3.weight: 0.0075742625631392\n",
      "Gradient for encoder.encoder.3.bias: 7.469054541520137e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.0023321921471506357\n",
      "Gradient for encoder.encoder.4.bias: 0.0016207598382607102\n",
      "Gradient for encoder.mean.weight: 0.033667873591184616\n",
      "Gradient for encoder.mean.bias: 0.0010874533327296376\n",
      "Gradient for encoder.log_var.weight: 0.01984216459095478\n",
      "Gradient for encoder.log_var.bias: 0.0007405545329675078\n",
      "Gradient for decoder.decoder.0.weight: 0.011792745441198349\n",
      "Gradient for decoder.decoder.0.bias: 1.0064309802215732e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0005557330441661179\n",
      "Gradient for decoder.decoder.1.bias: 0.0004905634559690952\n",
      "Gradient for decoder.decoder.3.weight: 0.01172299962490797\n",
      "Gradient for decoder.decoder.3.bias: 8.983871979673097e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0005864704726263881\n",
      "Gradient for decoder.decoder.4.bias: 0.0006696914788335562\n",
      "Gradient for decoder.decoder.6.weight: 0.0011844263644888997\n",
      "Gradient for decoder.decoder.6.bias: 9.180776396533474e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.004791427869349718\n",
      "Gradient for encoder.encoder.0.bias: 6.650353445020185e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.000358772900654003\n",
      "Gradient for encoder.encoder.1.bias: 0.0003389394551049918\n",
      "Gradient for encoder.encoder.3.weight: 0.008019453845918179\n",
      "Gradient for encoder.encoder.3.bias: 6.9476334407792e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.001959626330062747\n",
      "Gradient for encoder.encoder.4.bias: 0.0014250512467697263\n",
      "Gradient for encoder.mean.weight: 0.027782892808318138\n",
      "Gradient for encoder.mean.bias: 0.0011142771691083908\n",
      "Gradient for encoder.log_var.weight: 0.0185074619948864\n",
      "Gradient for encoder.log_var.bias: 0.0008373890887014568\n",
      "Gradient for decoder.decoder.0.weight: 0.010356707498431206\n",
      "Gradient for decoder.decoder.0.bias: 9.451123911263792e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0004912641015835106\n",
      "Gradient for decoder.decoder.1.bias: 0.0004442982899490744\n",
      "Gradient for decoder.decoder.3.weight: 0.009704893454909325\n",
      "Gradient for decoder.decoder.3.bias: 8.539221413306208e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0004097533237654716\n",
      "Gradient for decoder.decoder.4.bias: 0.0004179293173365295\n",
      "Gradient for decoder.decoder.6.weight: 0.00098470039665699\n",
      "Gradient for decoder.decoder.6.bias: 5.937770401942544e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.008165877312421799\n",
      "Gradient for encoder.encoder.0.bias: 1.2752934125392912e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0005069212056696415\n",
      "Gradient for encoder.encoder.1.bias: 0.0003915009438060224\n",
      "Gradient for encoder.encoder.3.weight: 0.010814949870109558\n",
      "Gradient for encoder.encoder.3.bias: 9.908780046474774e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.002345165703445673\n",
      "Gradient for encoder.encoder.4.bias: 0.001645482610911131\n",
      "Gradient for encoder.mean.weight: 0.03374041989445686\n",
      "Gradient for encoder.mean.bias: 0.0011652425164356828\n",
      "Gradient for encoder.log_var.weight: 0.01698538474738598\n",
      "Gradient for encoder.log_var.bias: 0.0008036564686335623\n",
      "Gradient for decoder.decoder.0.weight: 0.008011173456907272\n",
      "Gradient for decoder.decoder.0.bias: 7.726033007804389e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0003890384978149086\n",
      "Gradient for decoder.decoder.1.bias: 0.0003222347004339099\n",
      "Gradient for decoder.decoder.3.weight: 0.0074972594156861305\n",
      "Gradient for decoder.decoder.3.bias: 6.07795203055872e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00029396123136393726\n",
      "Gradient for decoder.decoder.4.bias: 0.00030516559490934014\n",
      "Gradient for decoder.decoder.6.weight: 0.000953706621658057\n",
      "Gradient for decoder.decoder.6.bias: 5.8422345318831503e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.005957884714007378\n",
      "Gradient for encoder.encoder.0.bias: 9.240205822713676e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.00034658066579140723\n",
      "Gradient for encoder.encoder.1.bias: 0.0003529991372488439\n",
      "Gradient for encoder.encoder.3.weight: 0.007761676795780659\n",
      "Gradient for encoder.encoder.3.bias: 9.156873176374702e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.0020941842813044786\n",
      "Gradient for encoder.encoder.4.bias: 0.001763866632245481\n",
      "Gradient for encoder.mean.weight: 0.030412863940000534\n",
      "Gradient for encoder.mean.bias: 0.001316316076554358\n",
      "Gradient for encoder.log_var.weight: 0.017080355435609818\n",
      "Gradient for encoder.log_var.bias: 0.000860581872984767\n",
      "Gradient for decoder.decoder.0.weight: 0.008297834545373917\n",
      "Gradient for decoder.decoder.0.bias: 6.942917768482104e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.00040570268174633384\n",
      "Gradient for decoder.decoder.1.bias: 0.00034312898060306907\n",
      "Gradient for decoder.decoder.3.weight: 0.00791432335972786\n",
      "Gradient for decoder.decoder.3.bias: 6.67423338818196e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00039004356949590147\n",
      "Gradient for decoder.decoder.4.bias: 0.00041109323501586914\n",
      "Gradient for decoder.decoder.6.weight: 0.0010582529939711094\n",
      "Gradient for decoder.decoder.6.bias: 7.943183300085366e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.004921050276607275\n",
      "Gradient for encoder.encoder.0.bias: 7.258818979921644e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.0003794613585341722\n",
      "Gradient for encoder.encoder.1.bias: 0.00034476362634450197\n",
      "Gradient for encoder.encoder.3.weight: 0.008487333543598652\n",
      "Gradient for encoder.encoder.3.bias: 8.458483913287296e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.002172525506466627\n",
      "Gradient for encoder.encoder.4.bias: 0.0014707131776958704\n",
      "Gradient for encoder.mean.weight: 0.030758550390601158\n",
      "Gradient for encoder.mean.bias: 0.0012646757531911135\n",
      "Gradient for encoder.log_var.weight: 0.01722637377679348\n",
      "Gradient for encoder.log_var.bias: 0.0007664485019631684\n",
      "Gradient for decoder.decoder.0.weight: 0.011001711711287498\n",
      "Gradient for decoder.decoder.0.bias: 1.0144039080950407e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0005454226047731936\n",
      "Gradient for decoder.decoder.1.bias: 0.00048024332500062883\n",
      "Gradient for decoder.decoder.3.weight: 0.010454322211444378\n",
      "Gradient for decoder.decoder.3.bias: 9.535407186067602e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.000439156690845266\n",
      "Gradient for decoder.decoder.4.bias: 0.00044609204633161426\n",
      "Gradient for decoder.decoder.6.weight: 0.0010965501423925161\n",
      "Gradient for decoder.decoder.6.bias: 7.366510544670746e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.005028943996876478\n",
      "Gradient for encoder.encoder.0.bias: 7.089179937525003e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.0003248038701713085\n",
      "Gradient for encoder.encoder.1.bias: 0.0003394830855540931\n",
      "Gradient for encoder.encoder.3.weight: 0.006720184814184904\n",
      "Gradient for encoder.encoder.3.bias: 7.838458354614275e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.002269177231937647\n",
      "Gradient for encoder.encoder.4.bias: 0.001563366036862135\n",
      "Gradient for encoder.mean.weight: 0.031799230724573135\n",
      "Gradient for encoder.mean.bias: 0.0012434099335223436\n",
      "Gradient for encoder.log_var.weight: 0.01786680705845356\n",
      "Gradient for encoder.log_var.bias: 0.0007818617741577327\n",
      "Gradient for decoder.decoder.0.weight: 0.009509831666946411\n",
      "Gradient for decoder.decoder.0.bias: 8.231594572638556e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0004525303957052529\n",
      "Gradient for decoder.decoder.1.bias: 0.0004004983347840607\n",
      "Gradient for decoder.decoder.3.weight: 0.008937817066907883\n",
      "Gradient for decoder.decoder.3.bias: 7.880884139721545e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00036679382901638746\n",
      "Gradient for decoder.decoder.4.bias: 0.0003893227258231491\n",
      "Gradient for decoder.decoder.6.weight: 0.0009196851751767099\n",
      "Gradient for decoder.decoder.6.bias: 4.707582775154151e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.0047624544240534306\n",
      "Gradient for encoder.encoder.0.bias: 7.5302012889078e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.0003925857017748058\n",
      "Gradient for encoder.encoder.1.bias: 0.00036258151521906257\n",
      "Gradient for encoder.encoder.3.weight: 0.008293644525110722\n",
      "Gradient for encoder.encoder.3.bias: 8.32410876339118e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.002327617257833481\n",
      "Gradient for encoder.encoder.4.bias: 0.0016295149689540267\n",
      "Gradient for encoder.mean.weight: 0.0334058478474617\n",
      "Gradient for encoder.mean.bias: 0.001203806372359395\n",
      "Gradient for encoder.log_var.weight: 0.019701097160577774\n",
      "Gradient for encoder.log_var.bias: 0.0008670888491906226\n",
      "Gradient for decoder.decoder.0.weight: 0.01101734396070242\n",
      "Gradient for decoder.decoder.0.bias: 9.085932700658716e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005310695851221681\n",
      "Gradient for decoder.decoder.1.bias: 0.0004452640132512897\n",
      "Gradient for decoder.decoder.3.weight: 0.010467495769262314\n",
      "Gradient for decoder.decoder.3.bias: 9.188268895732321e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0004396148433443159\n",
      "Gradient for decoder.decoder.4.bias: 0.00036032337811775506\n",
      "Gradient for decoder.decoder.6.weight: 0.0009804420405998826\n",
      "Gradient for decoder.decoder.6.bias: 5.6310927902814e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.005950421094894409\n",
      "Gradient for encoder.encoder.0.bias: 8.411565714794289e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.0004058176709804684\n",
      "Gradient for encoder.encoder.1.bias: 0.00042924133595079184\n",
      "Gradient for encoder.encoder.3.weight: 0.009026875719428062\n",
      "Gradient for encoder.encoder.3.bias: 8.053699374066525e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.001886960119009018\n",
      "Gradient for encoder.encoder.4.bias: 0.0015421576099470258\n",
      "Gradient for encoder.mean.weight: 0.02815273590385914\n",
      "Gradient for encoder.mean.bias: 0.0011974374065175653\n",
      "Gradient for encoder.log_var.weight: 0.01574176736176014\n",
      "Gradient for encoder.log_var.bias: 0.0008568512857891619\n",
      "Gradient for decoder.decoder.0.weight: 0.009284109808504581\n",
      "Gradient for decoder.decoder.0.bias: 8.068418155815493e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0004386467335280031\n",
      "Gradient for decoder.decoder.1.bias: 0.0004080203943885863\n",
      "Gradient for decoder.decoder.3.weight: 0.008469341322779655\n",
      "Gradient for decoder.decoder.3.bias: 7.36451177818509e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00029780089971609414\n",
      "Gradient for decoder.decoder.4.bias: 0.000280863547232002\n",
      "Gradient for decoder.decoder.6.weight: 0.0009196455939672887\n",
      "Gradient for decoder.decoder.6.bias: 5.229875387158245e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.004272008314728737\n",
      "Gradient for encoder.encoder.0.bias: 7.372448138087684e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.0003191571740899235\n",
      "Gradient for encoder.encoder.1.bias: 0.00031446642242372036\n",
      "Gradient for encoder.encoder.3.weight: 0.007282603066414595\n",
      "Gradient for encoder.encoder.3.bias: 7.205548657740479e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.001992278266698122\n",
      "Gradient for encoder.encoder.4.bias: 0.0012651478173211217\n",
      "Gradient for encoder.mean.weight: 0.02827075682580471\n",
      "Gradient for encoder.mean.bias: 0.0009966384386643767\n",
      "Gradient for encoder.log_var.weight: 0.015814699232578278\n",
      "Gradient for encoder.log_var.bias: 0.000741698604542762\n",
      "Gradient for decoder.decoder.0.weight: 0.009611879475414753\n",
      "Gradient for decoder.decoder.0.bias: 8.26830826028413e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0004485934041440487\n",
      "Gradient for decoder.decoder.1.bias: 0.00039776504854671657\n",
      "Gradient for decoder.decoder.3.weight: 0.008649219758808613\n",
      "Gradient for decoder.decoder.3.bias: 7.807181984231804e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00031725052394904196\n",
      "Gradient for decoder.decoder.4.bias: 0.0002789632708299905\n",
      "Gradient for decoder.decoder.6.weight: 0.0009291402529925108\n",
      "Gradient for decoder.decoder.6.bias: 4.827942029805854e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.008510250598192215\n",
      "Gradient for encoder.encoder.0.bias: 1.246760941014946e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.00040789422928355634\n",
      "Gradient for encoder.encoder.1.bias: 0.00037915349821560085\n",
      "Gradient for encoder.encoder.3.weight: 0.00876651518046856\n",
      "Gradient for encoder.encoder.3.bias: 9.21456869140691e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.0021179921459406614\n",
      "Gradient for encoder.encoder.4.bias: 0.0016108511481434107\n",
      "Gradient for encoder.mean.weight: 0.0295685026794672\n",
      "Gradient for encoder.mean.bias: 0.0011840866645798087\n",
      "Gradient for encoder.log_var.weight: 0.01597948744893074\n",
      "Gradient for encoder.log_var.bias: 0.0007952915038913488\n",
      "Gradient for decoder.decoder.0.weight: 0.007453874684870243\n",
      "Gradient for decoder.decoder.0.bias: 6.990354128877385e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0003723153204191476\n",
      "Gradient for decoder.decoder.1.bias: 0.00031666673021391034\n",
      "Gradient for decoder.decoder.3.weight: 0.006924585439264774\n",
      "Gradient for decoder.decoder.3.bias: 7.108964111823823e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00039019418181851506\n",
      "Gradient for decoder.decoder.4.bias: 0.0004499957140069455\n",
      "Gradient for decoder.decoder.6.weight: 0.0009366926969960332\n",
      "Gradient for decoder.decoder.6.bias: 5.7032379118027166e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training VAE Epoch:  92%|█████████▏| 73/79 [00:01<00:00, 74.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient for encoder.encoder.0.weight: 0.004454696085304022\n",
      "Gradient for encoder.encoder.0.bias: 5.990225242918923e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.00037576351314783096\n",
      "Gradient for encoder.encoder.1.bias: 0.00032377796014770865\n",
      "Gradient for encoder.encoder.3.weight: 0.007945505902171135\n",
      "Gradient for encoder.encoder.3.bias: 8.835815412666648e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.0021286774426698685\n",
      "Gradient for encoder.encoder.4.bias: 0.001710224081762135\n",
      "Gradient for encoder.mean.weight: 0.02881745994091034\n",
      "Gradient for encoder.mean.bias: 0.001276442315429449\n",
      "Gradient for encoder.log_var.weight: 0.017046799883246422\n",
      "Gradient for encoder.log_var.bias: 0.0008625726331956685\n",
      "Gradient for decoder.decoder.0.weight: 0.011545048095285892\n",
      "Gradient for decoder.decoder.0.bias: 1.0272711153946901e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0005524088628590107\n",
      "Gradient for decoder.decoder.1.bias: 0.0004945529508404434\n",
      "Gradient for decoder.decoder.3.weight: 0.010846982710063457\n",
      "Gradient for decoder.decoder.3.bias: 1.0978748465895194e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0007275390671566129\n",
      "Gradient for decoder.decoder.4.bias: 0.0008638945873826742\n",
      "Gradient for decoder.decoder.6.weight: 0.0013679217081516981\n",
      "Gradient for decoder.decoder.6.bias: 0.00011447319411672652\n",
      "Gradient for encoder.encoder.0.weight: 0.0051818592473864555\n",
      "Gradient for encoder.encoder.0.bias: 7.574305765922773e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.0003447877534199506\n",
      "Gradient for encoder.encoder.1.bias: 0.0003205922257620841\n",
      "Gradient for encoder.encoder.3.weight: 0.0073957485146820545\n",
      "Gradient for encoder.encoder.3.bias: 8.045888261198897e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.00191678071860224\n",
      "Gradient for encoder.encoder.4.bias: 0.0015901954611763358\n",
      "Gradient for encoder.mean.weight: 0.02567972056567669\n",
      "Gradient for encoder.mean.bias: 0.0011877170763909817\n",
      "Gradient for encoder.log_var.weight: 0.0157073475420475\n",
      "Gradient for encoder.log_var.bias: 0.0008058533421717584\n",
      "Gradient for decoder.decoder.0.weight: 0.009364202618598938\n",
      "Gradient for decoder.decoder.0.bias: 8.501497422708226e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.00047643028665333986\n",
      "Gradient for decoder.decoder.1.bias: 0.00041128447628580034\n",
      "Gradient for decoder.decoder.3.weight: 0.008836627937853336\n",
      "Gradient for decoder.decoder.3.bias: 6.831406273999363e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0003871115332003683\n",
      "Gradient for decoder.decoder.4.bias: 0.000327741407090798\n",
      "Gradient for decoder.decoder.6.weight: 0.0009918040595948696\n",
      "Gradient for decoder.decoder.6.bias: 5.182791210245341e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.006954982411116362\n",
      "Gradient for encoder.encoder.0.bias: 8.56215532502036e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.0002946966851595789\n",
      "Gradient for encoder.encoder.1.bias: 0.0002805822005029768\n",
      "Gradient for encoder.encoder.3.weight: 0.006822160445153713\n",
      "Gradient for encoder.encoder.3.bias: 7.863020651255326e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.001938503934070468\n",
      "Gradient for encoder.encoder.4.bias: 0.0013647397281602025\n",
      "Gradient for encoder.mean.weight: 0.026641041040420532\n",
      "Gradient for encoder.mean.bias: 0.0010191048495471478\n",
      "Gradient for encoder.log_var.weight: 0.014598459005355835\n",
      "Gradient for encoder.log_var.bias: 0.0007008693064562976\n",
      "Gradient for decoder.decoder.0.weight: 0.009198663756251335\n",
      "Gradient for decoder.decoder.0.bias: 8.130381784487994e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.000427486898843199\n",
      "Gradient for decoder.decoder.1.bias: 0.00038006791146472096\n",
      "Gradient for decoder.decoder.3.weight: 0.008493620902299881\n",
      "Gradient for decoder.decoder.3.bias: 6.867548196787254e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0003572178538888693\n",
      "Gradient for decoder.decoder.4.bias: 0.00033563526812940836\n",
      "Gradient for decoder.decoder.6.weight: 0.0010283401934430003\n",
      "Gradient for decoder.decoder.6.bias: 7.203637505881488e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.005170986521989107\n",
      "Gradient for encoder.encoder.0.bias: 6.729717477726993e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.00029597655520774424\n",
      "Gradient for encoder.encoder.1.bias: 0.00026879142387770116\n",
      "Gradient for encoder.encoder.3.weight: 0.006483304779976606\n",
      "Gradient for encoder.encoder.3.bias: 8.016222408091522e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.0019082190701738\n",
      "Gradient for encoder.encoder.4.bias: 0.001366076641716063\n",
      "Gradient for encoder.mean.weight: 0.026664262637495995\n",
      "Gradient for encoder.mean.bias: 0.0009621912613511086\n",
      "Gradient for encoder.log_var.weight: 0.01516780536621809\n",
      "Gradient for encoder.log_var.bias: 0.000711912929546088\n",
      "Gradient for decoder.decoder.0.weight: 0.009526646696031094\n",
      "Gradient for decoder.decoder.0.bias: 8.557115432905604e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.000440290808910504\n",
      "Gradient for decoder.decoder.1.bias: 0.0003766909067053348\n",
      "Gradient for decoder.decoder.3.weight: 0.008714836090803146\n",
      "Gradient for decoder.decoder.3.bias: 8.190188111045771e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0003054887638427317\n",
      "Gradient for decoder.decoder.4.bias: 0.0002678302116692066\n",
      "Gradient for decoder.decoder.6.weight: 0.0009341853437945247\n",
      "Gradient for decoder.decoder.6.bias: 4.373326737550087e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.004338980186730623\n",
      "Gradient for encoder.encoder.0.bias: 6.315498037728906e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.000356395379640162\n",
      "Gradient for encoder.encoder.1.bias: 0.0003325321595184505\n",
      "Gradient for encoder.encoder.3.weight: 0.007697861175984144\n",
      "Gradient for encoder.encoder.3.bias: 7.961074854900829e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.002112115267664194\n",
      "Gradient for encoder.encoder.4.bias: 0.0014098483370617032\n",
      "Gradient for encoder.mean.weight: 0.029565537348389626\n",
      "Gradient for encoder.mean.bias: 0.0009823485743254423\n",
      "Gradient for encoder.log_var.weight: 0.016658950597047806\n",
      "Gradient for encoder.log_var.bias: 0.0007447517709806561\n",
      "Gradient for decoder.decoder.0.weight: 0.012043192982673645\n",
      "Gradient for decoder.decoder.0.bias: 1.0321230675680582e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0005938372923992574\n",
      "Gradient for decoder.decoder.1.bias: 0.0004981085075996816\n",
      "Gradient for decoder.decoder.3.weight: 0.011432330124080181\n",
      "Gradient for decoder.decoder.3.bias: 8.219581959512112e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00047574611380696297\n",
      "Gradient for decoder.decoder.4.bias: 0.0004201852425467223\n",
      "Gradient for decoder.decoder.6.weight: 0.001112406956963241\n",
      "Gradient for decoder.decoder.6.bias: 7.417152664856985e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.0045235962606966496\n",
      "Gradient for encoder.encoder.0.bias: 6.5535346246980986e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.0003051303210668266\n",
      "Gradient for encoder.encoder.1.bias: 0.00027839126414619386\n",
      "Gradient for encoder.encoder.3.weight: 0.006605869624763727\n",
      "Gradient for encoder.encoder.3.bias: 7.718573002968299e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.0017573038348928094\n",
      "Gradient for encoder.encoder.4.bias: 0.0014363150112330914\n",
      "Gradient for encoder.mean.weight: 0.025726916268467903\n",
      "Gradient for encoder.mean.bias: 0.0010524771641939878\n",
      "Gradient for encoder.log_var.weight: 0.014186784625053406\n",
      "Gradient for encoder.log_var.bias: 0.0007205944857560098\n",
      "Gradient for decoder.decoder.0.weight: 0.009599084965884686\n",
      "Gradient for decoder.decoder.0.bias: 8.750165175763769e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0004557429638225585\n",
      "Gradient for decoder.decoder.1.bias: 0.00039951654616743326\n",
      "Gradient for decoder.decoder.3.weight: 0.009030982851982117\n",
      "Gradient for decoder.decoder.3.bias: 8.075815710606449e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0003390604688320309\n",
      "Gradient for decoder.decoder.4.bias: 0.00031554928864352405\n",
      "Gradient for decoder.decoder.6.weight: 0.0009251771261915565\n",
      "Gradient for decoder.decoder.6.bias: 4.378262019599788e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.005911517422646284\n",
      "Gradient for encoder.encoder.0.bias: 8.474687097914657e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.00035047621349804103\n",
      "Gradient for encoder.encoder.1.bias: 0.0002942500577773899\n",
      "Gradient for encoder.encoder.3.weight: 0.007577108219265938\n",
      "Gradient for encoder.encoder.3.bias: 8.842066662184678e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.002086409367620945\n",
      "Gradient for encoder.encoder.4.bias: 0.0016600879607722163\n",
      "Gradient for encoder.mean.weight: 0.027577465400099754\n",
      "Gradient for encoder.mean.bias: 0.0010711142094805837\n",
      "Gradient for encoder.log_var.weight: 0.016104741021990776\n",
      "Gradient for encoder.log_var.bias: 0.0008113046060316265\n",
      "Gradient for decoder.decoder.0.weight: 0.009754817932844162\n",
      "Gradient for decoder.decoder.0.bias: 7.445793287486069e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0004586733120959252\n",
      "Gradient for decoder.decoder.1.bias: 0.0004089652211405337\n",
      "Gradient for decoder.decoder.3.weight: 0.008657974191009998\n",
      "Gradient for decoder.decoder.3.bias: 6.71951730368825e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00033063185401260853\n",
      "Gradient for decoder.decoder.4.bias: 0.0003072950057685375\n",
      "Gradient for decoder.decoder.6.weight: 0.0010813047410920262\n",
      "Gradient for decoder.decoder.6.bias: 8.09456396382302e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.004495012573897839\n",
      "Gradient for encoder.encoder.0.bias: 7.038746321907929e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.0003167283139191568\n",
      "Gradient for encoder.encoder.1.bias: 0.00032742967596277595\n",
      "Gradient for encoder.encoder.3.weight: 0.007044937461614609\n",
      "Gradient for encoder.encoder.3.bias: 8.704077042454017e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.0019994606263935566\n",
      "Gradient for encoder.encoder.4.bias: 0.0014758144970983267\n",
      "Gradient for encoder.mean.weight: 0.027637921273708344\n",
      "Gradient for encoder.mean.bias: 0.0012357321102172136\n",
      "Gradient for encoder.log_var.weight: 0.01659967377781868\n",
      "Gradient for encoder.log_var.bias: 0.0008518100366927683\n",
      "Gradient for decoder.decoder.0.weight: 0.009816857054829597\n",
      "Gradient for decoder.decoder.0.bias: 8.602753232000993e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.00047395407455042005\n",
      "Gradient for decoder.decoder.1.bias: 0.00039745535468682647\n",
      "Gradient for decoder.decoder.3.weight: 0.008841510862112045\n",
      "Gradient for decoder.decoder.3.bias: 6.602665636457061e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.000344551051966846\n",
      "Gradient for decoder.decoder.4.bias: 0.0002819045912474394\n",
      "Gradient for decoder.decoder.6.weight: 0.0010054453741759062\n",
      "Gradient for decoder.decoder.6.bias: 6.025970651535317e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.006170337554067373\n",
      "Gradient for encoder.encoder.0.bias: 9.406236206599417e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.00042852203478105366\n",
      "Gradient for encoder.encoder.1.bias: 0.0004125307023059577\n",
      "Gradient for encoder.encoder.3.weight: 0.009223495610058308\n",
      "Gradient for encoder.encoder.3.bias: 8.579472549063993e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.0025232939515262842\n",
      "Gradient for encoder.encoder.4.bias: 0.0018634808948263526\n",
      "Gradient for encoder.mean.weight: 0.03310709446668625\n",
      "Gradient for encoder.mean.bias: 0.001221213024109602\n",
      "Gradient for encoder.log_var.weight: 0.0196414515376091\n",
      "Gradient for encoder.log_var.bias: 0.0009308324079029262\n",
      "Gradient for decoder.decoder.0.weight: 0.008426140062510967\n",
      "Gradient for decoder.decoder.0.bias: 7.158723613898132e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.00039214277057908475\n",
      "Gradient for decoder.decoder.1.bias: 0.0003589456027839333\n",
      "Gradient for decoder.decoder.3.weight: 0.008060582913458347\n",
      "Gradient for decoder.decoder.3.bias: 6.703147759079542e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0003460915759205818\n",
      "Gradient for decoder.decoder.4.bias: 0.0003539533936418593\n",
      "Gradient for decoder.decoder.6.weight: 0.0011251128744333982\n",
      "Gradient for decoder.decoder.6.bias: 8.497415547026321e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.004506210796535015\n",
      "Gradient for encoder.encoder.0.bias: 6.5008844661595955e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.00026578278630040586\n",
      "Gradient for encoder.encoder.1.bias: 0.0002609222719911486\n",
      "Gradient for encoder.encoder.3.weight: 0.005926339887082577\n",
      "Gradient for encoder.encoder.3.bias: 7.478166003105358e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.002076953649520874\n",
      "Gradient for encoder.encoder.4.bias: 0.001532053342089057\n",
      "Gradient for encoder.mean.weight: 0.02803427167236805\n",
      "Gradient for encoder.mean.bias: 0.0009582569473423064\n",
      "Gradient for encoder.log_var.weight: 0.01644889824092388\n",
      "Gradient for encoder.log_var.bias: 0.0007620390388183296\n",
      "Gradient for decoder.decoder.0.weight: 0.008321505039930344\n",
      "Gradient for decoder.decoder.0.bias: 6.597951351938747e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.00039261739584617317\n",
      "Gradient for decoder.decoder.1.bias: 0.00035388069227337837\n",
      "Gradient for decoder.decoder.3.weight: 0.007776432204991579\n",
      "Gradient for decoder.decoder.3.bias: 6.866480301015443e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.000381006917450577\n",
      "Gradient for decoder.decoder.4.bias: 0.00044697202974930406\n",
      "Gradient for decoder.decoder.6.weight: 0.0009582070051692426\n",
      "Gradient for decoder.decoder.6.bias: 6.063784894649871e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.005338279530405998\n",
      "Gradient for encoder.encoder.0.bias: 8.310471234784789e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.00038883485831320286\n",
      "Gradient for encoder.encoder.1.bias: 0.00035931638558395207\n",
      "Gradient for encoder.encoder.3.weight: 0.008442264050245285\n",
      "Gradient for encoder.encoder.3.bias: 8.107663151957212e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.0017087903106585145\n",
      "Gradient for encoder.encoder.4.bias: 0.0014508265303447843\n",
      "Gradient for encoder.mean.weight: 0.023222235962748528\n",
      "Gradient for encoder.mean.bias: 0.0011023604311048985\n",
      "Gradient for encoder.log_var.weight: 0.014494925737380981\n",
      "Gradient for encoder.log_var.bias: 0.0008293678984045982\n",
      "Gradient for decoder.decoder.0.weight: 0.008241476491093636\n",
      "Gradient for decoder.decoder.0.bias: 6.939594732191523e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0004015318991150707\n",
      "Gradient for decoder.decoder.1.bias: 0.00033261312637478113\n",
      "Gradient for decoder.decoder.3.weight: 0.007653854321688414\n",
      "Gradient for decoder.decoder.3.bias: 6.900463533909829e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0003600069903768599\n",
      "Gradient for decoder.decoder.4.bias: 0.000355754658812657\n",
      "Gradient for decoder.decoder.6.weight: 0.0009331857436336577\n",
      "Gradient for decoder.decoder.6.bias: 5.306079037836753e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.004554919432848692\n",
      "Gradient for encoder.encoder.0.bias: 7.1524201492034756e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.0003897372225765139\n",
      "Gradient for encoder.encoder.1.bias: 0.0003568542597349733\n",
      "Gradient for encoder.encoder.3.weight: 0.008859788067638874\n",
      "Gradient for encoder.encoder.3.bias: 8.332107226394214e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.0022865519858896732\n",
      "Gradient for encoder.encoder.4.bias: 0.0015726479468867183\n",
      "Gradient for encoder.mean.weight: 0.03125708922743797\n",
      "Gradient for encoder.mean.bias: 0.0010946020483970642\n",
      "Gradient for encoder.log_var.weight: 0.01818789541721344\n",
      "Gradient for encoder.log_var.bias: 0.00072699342854321\n",
      "Gradient for decoder.decoder.0.weight: 0.00946376845240593\n",
      "Gradient for decoder.decoder.0.bias: 8.143358903867082e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0004900644416920841\n",
      "Gradient for decoder.decoder.1.bias: 0.00040280912071466446\n",
      "Gradient for decoder.decoder.3.weight: 0.009100265800952911\n",
      "Gradient for decoder.decoder.3.bias: 7.89460372074835e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00047681466094218194\n",
      "Gradient for decoder.decoder.4.bias: 0.0005437471554614604\n",
      "Gradient for decoder.decoder.6.weight: 0.0011583124287426472\n",
      "Gradient for decoder.decoder.6.bias: 8.844608964864165e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.004008110146969557\n",
      "Gradient for encoder.encoder.0.bias: 5.7725946418785146e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.0003356583183631301\n",
      "Gradient for encoder.encoder.1.bias: 0.0003718849620781839\n",
      "Gradient for encoder.encoder.3.weight: 0.007252679672092199\n",
      "Gradient for encoder.encoder.3.bias: 8.232232256988326e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.002412007423117757\n",
      "Gradient for encoder.encoder.4.bias: 0.0016076181782409549\n",
      "Gradient for encoder.mean.weight: 0.03155410662293434\n",
      "Gradient for encoder.mean.bias: 0.0010907421819865704\n",
      "Gradient for encoder.log_var.weight: 0.021824201568961143\n",
      "Gradient for encoder.log_var.bias: 0.0008469059248454869\n",
      "Gradient for decoder.decoder.0.weight: 0.010512111708521843\n",
      "Gradient for decoder.decoder.0.bias: 9.617832225083944e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0004839659377466887\n",
      "Gradient for decoder.decoder.1.bias: 0.00042574727558530867\n",
      "Gradient for decoder.decoder.3.weight: 0.009851891547441483\n",
      "Gradient for decoder.decoder.3.bias: 8.007879775950855e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00038109664455987513\n",
      "Gradient for decoder.decoder.4.bias: 0.00036487021134234965\n",
      "Gradient for decoder.decoder.6.weight: 0.0011228130897507071\n",
      "Gradient for decoder.decoder.6.bias: 8.05463787401095e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.0036204636562615633\n",
      "Gradient for encoder.encoder.0.bias: 5.016149821901461e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.0002814443432725966\n",
      "Gradient for encoder.encoder.1.bias: 0.0002856104983948171\n",
      "Gradient for encoder.encoder.3.weight: 0.006370987743139267\n",
      "Gradient for encoder.encoder.3.bias: 8.409875573711645e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.0021662809886038303\n",
      "Gradient for encoder.encoder.4.bias: 0.001726467744447291\n",
      "Gradient for encoder.mean.weight: 0.03132439777255058\n",
      "Gradient for encoder.mean.bias: 0.0012118462473154068\n",
      "Gradient for encoder.log_var.weight: 0.01858866959810257\n",
      "Gradient for encoder.log_var.bias: 0.0008795693865977228\n",
      "Gradient for decoder.decoder.0.weight: 0.012039688415825367\n",
      "Gradient for decoder.decoder.0.bias: 1.0836299912941882e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0005714963190257549\n",
      "Gradient for decoder.decoder.1.bias: 0.0005082797724753618\n",
      "Gradient for decoder.decoder.3.weight: 0.011740380898118019\n",
      "Gradient for decoder.decoder.3.bias: 9.040935361470659e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0005396936903707683\n",
      "Gradient for decoder.decoder.4.bias: 0.0005308890249580145\n",
      "Gradient for decoder.decoder.6.weight: 0.0009869616478681564\n",
      "Gradient for decoder.decoder.6.bias: 5.242886982159689e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.018532058224081993\n",
      "Gradient for encoder.encoder.0.bias: 2.6280122175648124e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0010187766747549176\n",
      "Gradient for encoder.encoder.1.bias: 0.0010134761687368155\n",
      "Gradient for encoder.encoder.3.weight: 0.022202232852578163\n",
      "Gradient for encoder.encoder.3.bias: 2.0385886034812728e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.003842458827421069\n",
      "Gradient for encoder.encoder.4.bias: 0.0039184545166790485\n",
      "Gradient for encoder.mean.weight: 0.05350276455283165\n",
      "Gradient for encoder.mean.bias: 0.0025372235104441643\n",
      "Gradient for encoder.log_var.weight: 0.032163627445697784\n",
      "Gradient for encoder.log_var.bias: 0.001770965289324522\n",
      "Gradient for decoder.decoder.0.weight: 0.02754255197942257\n",
      "Gradient for decoder.decoder.0.bias: 1.904765095650518e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.001162570551969111\n",
      "Gradient for decoder.decoder.1.bias: 0.001053974381648004\n",
      "Gradient for decoder.decoder.3.weight: 0.02506558783352375\n",
      "Gradient for decoder.decoder.3.bias: 1.5480255965982792e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0008666648645885289\n",
      "Gradient for decoder.decoder.4.bias: 0.0007503435481339693\n",
      "Gradient for decoder.decoder.6.weight: 0.0025925191584974527\n",
      "Gradient for decoder.decoder.6.bias: 0.0001418519241269678\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/3, Train Loss: 0.0829, Val Loss: 0.2955\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training VAE Epoch:   1%|▏         | 1/79 [00:00<00:15,  5.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient for encoder.encoder.0.weight: 0.004584999289363623\n",
      "Gradient for encoder.encoder.0.bias: 7.1885579086550244e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.00033489151974208653\n",
      "Gradient for encoder.encoder.1.bias: 0.0003036677371710539\n",
      "Gradient for encoder.encoder.3.weight: 0.007585178129374981\n",
      "Gradient for encoder.encoder.3.bias: 8.393410272367063e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.002188583603128791\n",
      "Gradient for encoder.encoder.4.bias: 0.0015596396988257766\n",
      "Gradient for encoder.mean.weight: 0.032309457659721375\n",
      "Gradient for encoder.mean.bias: 0.0011232842225581408\n",
      "Gradient for encoder.log_var.weight: 0.017356026917696\n",
      "Gradient for encoder.log_var.bias: 0.000645879132207483\n",
      "Gradient for decoder.decoder.0.weight: 0.009442737326025963\n",
      "Gradient for decoder.decoder.0.bias: 8.082304964185383e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.00044630825868807733\n",
      "Gradient for decoder.decoder.1.bias: 0.00039492081850767136\n",
      "Gradient for decoder.decoder.3.weight: 0.008730179630219936\n",
      "Gradient for decoder.decoder.3.bias: 6.759287574098494e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00035041975206695497\n",
      "Gradient for decoder.decoder.4.bias: 0.0003156467864755541\n",
      "Gradient for decoder.decoder.6.weight: 0.000957336334977299\n",
      "Gradient for decoder.decoder.6.bias: 5.8029487263411283e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training VAE Epoch:  11%|█▏        | 9/79 [00:00<00:01, 36.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient for encoder.encoder.0.weight: 0.007772002834826708\n",
      "Gradient for encoder.encoder.0.bias: 1.019616682751412e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0006563139613717794\n",
      "Gradient for encoder.encoder.1.bias: 0.00043562674545682967\n",
      "Gradient for encoder.encoder.3.weight: 0.01402015145868063\n",
      "Gradient for encoder.encoder.3.bias: 9.895934766079861e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.0031134372111409903\n",
      "Gradient for encoder.encoder.4.bias: 0.0024208216927945614\n",
      "Gradient for encoder.mean.weight: 0.04184796288609505\n",
      "Gradient for encoder.mean.bias: 0.0018957499414682388\n",
      "Gradient for encoder.log_var.weight: 0.02285062149167061\n",
      "Gradient for encoder.log_var.bias: 0.0011884550331160426\n",
      "Gradient for decoder.decoder.0.weight: 0.008844067342579365\n",
      "Gradient for decoder.decoder.0.bias: 7.940681445717246e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.00041320337913930416\n",
      "Gradient for decoder.decoder.1.bias: 0.00036283861845731735\n",
      "Gradient for decoder.decoder.3.weight: 0.007843418046832085\n",
      "Gradient for decoder.decoder.3.bias: 6.726947471280553e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0003053846303373575\n",
      "Gradient for decoder.decoder.4.bias: 0.0003114844439551234\n",
      "Gradient for decoder.decoder.6.weight: 0.0010060879867523909\n",
      "Gradient for decoder.decoder.6.bias: 6.289135490078479e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.005028982181102037\n",
      "Gradient for encoder.encoder.0.bias: 8.128239400995163e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.0005736566381528974\n",
      "Gradient for encoder.encoder.1.bias: 0.0004697727272287011\n",
      "Gradient for encoder.encoder.3.weight: 0.012586385942995548\n",
      "Gradient for encoder.encoder.3.bias: 1.0487005014381268e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0026808481197804213\n",
      "Gradient for encoder.encoder.4.bias: 0.0021892618387937546\n",
      "Gradient for encoder.mean.weight: 0.03688185289502144\n",
      "Gradient for encoder.mean.bias: 0.0016076245810836554\n",
      "Gradient for encoder.log_var.weight: 0.022694557905197144\n",
      "Gradient for encoder.log_var.bias: 0.001176085090264678\n",
      "Gradient for decoder.decoder.0.weight: 0.010201181285083294\n",
      "Gradient for decoder.decoder.0.bias: 8.457872596734362e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005115965032018721\n",
      "Gradient for decoder.decoder.1.bias: 0.00041408545803278685\n",
      "Gradient for decoder.decoder.3.weight: 0.009565246291458607\n",
      "Gradient for decoder.decoder.3.bias: 7.494862369616939e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00040407979395240545\n",
      "Gradient for decoder.decoder.4.bias: 0.0004038250772282481\n",
      "Gradient for decoder.decoder.6.weight: 0.0009354850044474006\n",
      "Gradient for decoder.decoder.6.bias: 5.3157913498580456e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.007100055925548077\n",
      "Gradient for encoder.encoder.0.bias: 1.0170178067758773e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0003652657032944262\n",
      "Gradient for encoder.encoder.1.bias: 0.00039913272485136986\n",
      "Gradient for encoder.encoder.3.weight: 0.00833545345813036\n",
      "Gradient for encoder.encoder.3.bias: 9.53810364023866e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.0020326636731624603\n",
      "Gradient for encoder.encoder.4.bias: 0.0019327399786561728\n",
      "Gradient for encoder.mean.weight: 0.029375024139881134\n",
      "Gradient for encoder.mean.bias: 0.001430056756362319\n",
      "Gradient for encoder.log_var.weight: 0.018260763958096504\n",
      "Gradient for encoder.log_var.bias: 0.0009951010579243302\n",
      "Gradient for decoder.decoder.0.weight: 0.008155141025781631\n",
      "Gradient for decoder.decoder.0.bias: 6.652205175594617e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0003775190270971507\n",
      "Gradient for decoder.decoder.1.bias: 0.00033854212961159647\n",
      "Gradient for decoder.decoder.3.weight: 0.007400921080261469\n",
      "Gradient for decoder.decoder.3.bias: 6.986340672643365e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0003129386168438941\n",
      "Gradient for decoder.decoder.4.bias: 0.0003330648469273001\n",
      "Gradient for decoder.decoder.6.weight: 0.0009245373075827956\n",
      "Gradient for decoder.decoder.6.bias: 5.452793629956432e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.0058670686557888985\n",
      "Gradient for encoder.encoder.0.bias: 7.21340868981013e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.00040867627831175923\n",
      "Gradient for encoder.encoder.1.bias: 0.00037074682768434286\n",
      "Gradient for encoder.encoder.3.weight: 0.00941178947687149\n",
      "Gradient for encoder.encoder.3.bias: 9.404994144590617e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.0024904278106987476\n",
      "Gradient for encoder.encoder.4.bias: 0.002012947341427207\n",
      "Gradient for encoder.mean.weight: 0.035075973719358444\n",
      "Gradient for encoder.mean.bias: 0.0014043081318959594\n",
      "Gradient for encoder.log_var.weight: 0.019256580621004105\n",
      "Gradient for encoder.log_var.bias: 0.0007829858222976327\n",
      "Gradient for decoder.decoder.0.weight: 0.010163195431232452\n",
      "Gradient for decoder.decoder.0.bias: 8.707855270184695e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.00047754470142535865\n",
      "Gradient for decoder.decoder.1.bias: 0.00042422456317581236\n",
      "Gradient for decoder.decoder.3.weight: 0.009603234939277172\n",
      "Gradient for decoder.decoder.3.bias: 7.555053110896992e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00038493351894430816\n",
      "Gradient for decoder.decoder.4.bias: 0.000386014609830454\n",
      "Gradient for decoder.decoder.6.weight: 0.0009945033816620708\n",
      "Gradient for decoder.decoder.6.bias: 5.88183720537927e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.006235500331968069\n",
      "Gradient for encoder.encoder.0.bias: 8.789448335821959e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.00045524429879151285\n",
      "Gradient for encoder.encoder.1.bias: 0.00040209278813563287\n",
      "Gradient for encoder.encoder.3.weight: 0.010473355650901794\n",
      "Gradient for encoder.encoder.3.bias: 9.364976849557394e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.002562028355896473\n",
      "Gradient for encoder.encoder.4.bias: 0.0019178430084139109\n",
      "Gradient for encoder.mean.weight: 0.034579962491989136\n",
      "Gradient for encoder.mean.bias: 0.0014832118758931756\n",
      "Gradient for encoder.log_var.weight: 0.019107576459646225\n",
      "Gradient for encoder.log_var.bias: 0.0008678784943185747\n",
      "Gradient for decoder.decoder.0.weight: 0.009654369205236435\n",
      "Gradient for decoder.decoder.0.bias: 8.589851052676067e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005003828555345535\n",
      "Gradient for decoder.decoder.1.bias: 0.0003972695267293602\n",
      "Gradient for decoder.decoder.3.weight: 0.009400373324751854\n",
      "Gradient for decoder.decoder.3.bias: 8.361141640156333e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0003852371883112937\n",
      "Gradient for decoder.decoder.4.bias: 0.0003760697436518967\n",
      "Gradient for decoder.decoder.6.weight: 0.0011139853158965707\n",
      "Gradient for decoder.decoder.6.bias: 8.64945977809839e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.006028980482369661\n",
      "Gradient for encoder.encoder.0.bias: 8.306934133617272e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.000498276436701417\n",
      "Gradient for encoder.encoder.1.bias: 0.00037678040098398924\n",
      "Gradient for encoder.encoder.3.weight: 0.010451331734657288\n",
      "Gradient for encoder.encoder.3.bias: 1.0733530730888674e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0027130325324833393\n",
      "Gradient for encoder.encoder.4.bias: 0.0023966243024915457\n",
      "Gradient for encoder.mean.weight: 0.03838416188955307\n",
      "Gradient for encoder.mean.bias: 0.0019655690994113684\n",
      "Gradient for encoder.log_var.weight: 0.020746776834130287\n",
      "Gradient for encoder.log_var.bias: 0.0011243968037888408\n",
      "Gradient for decoder.decoder.0.weight: 0.009976759552955627\n",
      "Gradient for decoder.decoder.0.bias: 8.761059239192903e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0004968888242729008\n",
      "Gradient for decoder.decoder.1.bias: 0.0004226906457915902\n",
      "Gradient for decoder.decoder.3.weight: 0.009508545510470867\n",
      "Gradient for decoder.decoder.3.bias: 8.898413950131356e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0005389651050791144\n",
      "Gradient for decoder.decoder.4.bias: 0.0005627022474072874\n",
      "Gradient for decoder.decoder.6.weight: 0.0009973591659218073\n",
      "Gradient for decoder.decoder.6.bias: 5.651485116686672e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.007164878770709038\n",
      "Gradient for encoder.encoder.0.bias: 9.377412041322586e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.0003576444578357041\n",
      "Gradient for encoder.encoder.1.bias: 0.00044089776929467916\n",
      "Gradient for encoder.encoder.3.weight: 0.008029735647141933\n",
      "Gradient for encoder.encoder.3.bias: 8.289197800381842e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.0018809785833582282\n",
      "Gradient for encoder.encoder.4.bias: 0.0015856014797464013\n",
      "Gradient for encoder.mean.weight: 0.029210301116108894\n",
      "Gradient for encoder.mean.bias: 0.0013333631213754416\n",
      "Gradient for encoder.log_var.weight: 0.017312556505203247\n",
      "Gradient for encoder.log_var.bias: 0.0008842363604344428\n",
      "Gradient for decoder.decoder.0.weight: 0.0095001719892025\n",
      "Gradient for decoder.decoder.0.bias: 8.886602564928126e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.00047463615192100406\n",
      "Gradient for decoder.decoder.1.bias: 0.000402179139200598\n",
      "Gradient for decoder.decoder.3.weight: 0.009118285961449146\n",
      "Gradient for decoder.decoder.3.bias: 8.330509199128144e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00035675952676683664\n",
      "Gradient for decoder.decoder.4.bias: 0.0003483647888060659\n",
      "Gradient for decoder.decoder.6.weight: 0.0010538932401686907\n",
      "Gradient for decoder.decoder.6.bias: 7.607275620102882e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.004546260926872492\n",
      "Gradient for encoder.encoder.0.bias: 6.638691332772062e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.0003496978897601366\n",
      "Gradient for encoder.encoder.1.bias: 0.0003116227453574538\n",
      "Gradient for encoder.encoder.3.weight: 0.007629419676959515\n",
      "Gradient for encoder.encoder.3.bias: 7.462726964169164e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.0019436703296378255\n",
      "Gradient for encoder.encoder.4.bias: 0.001540730707347393\n",
      "Gradient for encoder.mean.weight: 0.02930029295384884\n",
      "Gradient for encoder.mean.bias: 0.001239256700500846\n",
      "Gradient for encoder.log_var.weight: 0.015684787184000015\n",
      "Gradient for encoder.log_var.bias: 0.0007664739387109876\n",
      "Gradient for decoder.decoder.0.weight: 0.010017318651080132\n",
      "Gradient for decoder.decoder.0.bias: 8.533225515083842e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.00048755184980109334\n",
      "Gradient for decoder.decoder.1.bias: 0.0004284844908397645\n",
      "Gradient for decoder.decoder.3.weight: 0.009486645460128784\n",
      "Gradient for decoder.decoder.3.bias: 6.876646474474057e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0004315268306527287\n",
      "Gradient for decoder.decoder.4.bias: 0.00046464751358143985\n",
      "Gradient for decoder.decoder.6.weight: 0.000962365185841918\n",
      "Gradient for decoder.decoder.6.bias: 5.9482230426510796e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.006294403690844774\n",
      "Gradient for encoder.encoder.0.bias: 9.833175072804234e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.0005421488313004375\n",
      "Gradient for encoder.encoder.1.bias: 0.00039388288860209286\n",
      "Gradient for encoder.encoder.3.weight: 0.012352630496025085\n",
      "Gradient for encoder.encoder.3.bias: 1.0584146753478407e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.002693825401365757\n",
      "Gradient for encoder.encoder.4.bias: 0.002185909077525139\n",
      "Gradient for encoder.mean.weight: 0.03603137284517288\n",
      "Gradient for encoder.mean.bias: 0.0015884594758972526\n",
      "Gradient for encoder.log_var.weight: 0.01961403340101242\n",
      "Gradient for encoder.log_var.bias: 0.0008422453538514674\n",
      "Gradient for decoder.decoder.0.weight: 0.010115276090800762\n",
      "Gradient for decoder.decoder.0.bias: 9.227783120957511e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0004986330750398338\n",
      "Gradient for decoder.decoder.1.bias: 0.0004189636092633009\n",
      "Gradient for decoder.decoder.3.weight: 0.009106910787522793\n",
      "Gradient for decoder.decoder.3.bias: 7.97207022618096e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00038956894422881305\n",
      "Gradient for decoder.decoder.4.bias: 0.0004056203179061413\n",
      "Gradient for decoder.decoder.6.weight: 0.00095559615874663\n",
      "Gradient for decoder.decoder.6.bias: 4.937616904499009e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.006350276991724968\n",
      "Gradient for encoder.encoder.0.bias: 8.23118916776222e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.0004467995895538479\n",
      "Gradient for encoder.encoder.1.bias: 0.00042006169678643346\n",
      "Gradient for encoder.encoder.3.weight: 0.009713400155305862\n",
      "Gradient for encoder.encoder.3.bias: 8.876874929564238e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.002237658016383648\n",
      "Gradient for encoder.encoder.4.bias: 0.0018026115139946342\n",
      "Gradient for encoder.mean.weight: 0.030579034239053726\n",
      "Gradient for encoder.mean.bias: 0.001328886253759265\n",
      "Gradient for encoder.log_var.weight: 0.016259795054793358\n",
      "Gradient for encoder.log_var.bias: 0.0007326510967686772\n",
      "Gradient for decoder.decoder.0.weight: 0.008692125789821148\n",
      "Gradient for decoder.decoder.0.bias: 7.504735027863418e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0004598294326569885\n",
      "Gradient for decoder.decoder.1.bias: 0.00034917538869194686\n",
      "Gradient for decoder.decoder.3.weight: 0.0083002969622612\n",
      "Gradient for decoder.decoder.3.bias: 6.361385723741009e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0003108272794634104\n",
      "Gradient for decoder.decoder.4.bias: 0.00029020255897194147\n",
      "Gradient for decoder.decoder.6.weight: 0.0009414678788743913\n",
      "Gradient for decoder.decoder.6.bias: 5.338786286301911e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.007232888136059046\n",
      "Gradient for encoder.encoder.0.bias: 1.096745003842381e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0005485374131239951\n",
      "Gradient for encoder.encoder.1.bias: 0.00047727333731018007\n",
      "Gradient for encoder.encoder.3.weight: 0.012249046936631203\n",
      "Gradient for encoder.encoder.3.bias: 1.0894230656477433e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0024909621570259333\n",
      "Gradient for encoder.encoder.4.bias: 0.0020651593804359436\n",
      "Gradient for encoder.mean.weight: 0.03641584888100624\n",
      "Gradient for encoder.mean.bias: 0.0015804776921868324\n",
      "Gradient for encoder.log_var.weight: 0.021250814199447632\n",
      "Gradient for encoder.log_var.bias: 0.0009139365283772349\n",
      "Gradient for decoder.decoder.0.weight: 0.00917468499392271\n",
      "Gradient for decoder.decoder.0.bias: 7.830234377559364e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.00044872952275909483\n",
      "Gradient for decoder.decoder.1.bias: 0.0003970413818024099\n",
      "Gradient for decoder.decoder.3.weight: 0.008570123463869095\n",
      "Gradient for decoder.decoder.3.bias: 7.433076376628378e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0003426425682846457\n",
      "Gradient for decoder.decoder.4.bias: 0.00034108880208805203\n",
      "Gradient for decoder.decoder.6.weight: 0.0010973549215123057\n",
      "Gradient for decoder.decoder.6.bias: 8.415470801992342e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.004962482955306768\n",
      "Gradient for encoder.encoder.0.bias: 8.419466512865625e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.00046085898065939546\n",
      "Gradient for encoder.encoder.1.bias: 0.00037499776226468384\n",
      "Gradient for encoder.encoder.3.weight: 0.010011794045567513\n",
      "Gradient for encoder.encoder.3.bias: 9.441129128484604e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.0021928248461335897\n",
      "Gradient for encoder.encoder.4.bias: 0.0015895559918135405\n",
      "Gradient for encoder.mean.weight: 0.03354007750749588\n",
      "Gradient for encoder.mean.bias: 0.0012450233334675431\n",
      "Gradient for encoder.log_var.weight: 0.018972834572196007\n",
      "Gradient for encoder.log_var.bias: 0.0007662267307750881\n",
      "Gradient for decoder.decoder.0.weight: 0.010129923932254314\n",
      "Gradient for decoder.decoder.0.bias: 9.760748459486379e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0004538070934358984\n",
      "Gradient for decoder.decoder.1.bias: 0.0004040943749714643\n",
      "Gradient for decoder.decoder.3.weight: 0.009611179120838642\n",
      "Gradient for decoder.decoder.3.bias: 8.484073860115515e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0003574972797650844\n",
      "Gradient for decoder.decoder.4.bias: 0.00035217960248701274\n",
      "Gradient for decoder.decoder.6.weight: 0.0009559330646879971\n",
      "Gradient for decoder.decoder.6.bias: 5.763024091720581e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.0045665414072573185\n",
      "Gradient for encoder.encoder.0.bias: 7.1011096308692956e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.0004406357475090772\n",
      "Gradient for encoder.encoder.1.bias: 0.00036740704672411084\n",
      "Gradient for encoder.encoder.3.weight: 0.009896448813378811\n",
      "Gradient for encoder.encoder.3.bias: 8.661817790800441e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.0024684988893568516\n",
      "Gradient for encoder.encoder.4.bias: 0.0017422577366232872\n",
      "Gradient for encoder.mean.weight: 0.03499723598361015\n",
      "Gradient for encoder.mean.bias: 0.001355193555355072\n",
      "Gradient for encoder.log_var.weight: 0.021435318514704704\n",
      "Gradient for encoder.log_var.bias: 0.0007696071406826377\n",
      "Gradient for decoder.decoder.0.weight: 0.01029866561293602\n",
      "Gradient for decoder.decoder.0.bias: 9.698040287497989e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.00047266538604162633\n",
      "Gradient for decoder.decoder.1.bias: 0.0004085979308001697\n",
      "Gradient for decoder.decoder.3.weight: 0.009325862862169743\n",
      "Gradient for decoder.decoder.3.bias: 9.883048546210915e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0003541131445672363\n",
      "Gradient for decoder.decoder.4.bias: 0.00032930783345364034\n",
      "Gradient for decoder.decoder.6.weight: 0.0009063725592568517\n",
      "Gradient for decoder.decoder.6.bias: 4.296680344850756e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.007131629623472691\n",
      "Gradient for encoder.encoder.0.bias: 9.22077518505926e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.000532429781742394\n",
      "Gradient for encoder.encoder.1.bias: 0.0004911642172373831\n",
      "Gradient for encoder.encoder.3.weight: 0.012036731466650963\n",
      "Gradient for encoder.encoder.3.bias: 9.405998896427903e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.002533905440941453\n",
      "Gradient for encoder.encoder.4.bias: 0.002166534774005413\n",
      "Gradient for encoder.mean.weight: 0.03596927225589752\n",
      "Gradient for encoder.mean.bias: 0.0018444438464939594\n",
      "Gradient for encoder.log_var.weight: 0.01860100030899048\n",
      "Gradient for encoder.log_var.bias: 0.0011341001372784376\n",
      "Gradient for decoder.decoder.0.weight: 0.009744125418365002\n",
      "Gradient for decoder.decoder.0.bias: 8.495343317704851e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0004565051931422204\n",
      "Gradient for decoder.decoder.1.bias: 0.0004309262440074235\n",
      "Gradient for decoder.decoder.3.weight: 0.009288386441767216\n",
      "Gradient for decoder.decoder.3.bias: 8.543813573291814e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0004692900402005762\n",
      "Gradient for decoder.decoder.4.bias: 0.000533191254362464\n",
      "Gradient for decoder.decoder.6.weight: 0.0010030468693003058\n",
      "Gradient for decoder.decoder.6.bias: 5.9873462305404246e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.005136496387422085\n",
      "Gradient for encoder.encoder.0.bias: 7.4874889274823e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.00039526724140159786\n",
      "Gradient for encoder.encoder.1.bias: 0.0004027273098472506\n",
      "Gradient for encoder.encoder.3.weight: 0.008612033911049366\n",
      "Gradient for encoder.encoder.3.bias: 8.014756913699017e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.002439274685457349\n",
      "Gradient for encoder.encoder.4.bias: 0.00160386529751122\n",
      "Gradient for encoder.mean.weight: 0.03396059200167656\n",
      "Gradient for encoder.mean.bias: 0.0013203099370002747\n",
      "Gradient for encoder.log_var.weight: 0.019063128158450127\n",
      "Gradient for encoder.log_var.bias: 0.0008064080611802638\n",
      "Gradient for decoder.decoder.0.weight: 0.010821472853422165\n",
      "Gradient for decoder.decoder.0.bias: 8.564575437741695e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005336013273335993\n",
      "Gradient for decoder.decoder.1.bias: 0.0004625203146133572\n",
      "Gradient for decoder.decoder.3.weight: 0.010222980752587318\n",
      "Gradient for decoder.decoder.3.bias: 7.57041027088512e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00039741507498547435\n",
      "Gradient for decoder.decoder.4.bias: 0.00033098773565143347\n",
      "Gradient for decoder.decoder.6.weight: 0.0009264984400942922\n",
      "Gradient for decoder.decoder.6.bias: 3.933202242478728e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.0059503233060240746\n",
      "Gradient for encoder.encoder.0.bias: 8.99000318632659e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.0004973775357939303\n",
      "Gradient for encoder.encoder.1.bias: 0.00044771970715373755\n",
      "Gradient for encoder.encoder.3.weight: 0.010959652252495289\n",
      "Gradient for encoder.encoder.3.bias: 9.660398175848073e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.002186786849051714\n",
      "Gradient for encoder.encoder.4.bias: 0.0017986611928790808\n",
      "Gradient for encoder.mean.weight: 0.030798664316534996\n",
      "Gradient for encoder.mean.bias: 0.001311527332291007\n",
      "Gradient for encoder.log_var.weight: 0.01753147877752781\n",
      "Gradient for encoder.log_var.bias: 0.0008451432804577053\n",
      "Gradient for decoder.decoder.0.weight: 0.009767871350049973\n",
      "Gradient for decoder.decoder.0.bias: 8.532303336084013e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.00046552292769774795\n",
      "Gradient for decoder.decoder.1.bias: 0.0003852624213322997\n",
      "Gradient for decoder.decoder.3.weight: 0.008827684447169304\n",
      "Gradient for decoder.decoder.3.bias: 6.774925065400339e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0003248909197282046\n",
      "Gradient for decoder.decoder.4.bias: 0.0002906122535932809\n",
      "Gradient for decoder.decoder.6.weight: 0.0009358279639855027\n",
      "Gradient for decoder.decoder.6.bias: 5.2545525250025094e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training VAE Epoch:  32%|███▏      | 25/79 [00:00<00:00, 59.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient for encoder.encoder.0.weight: 0.004529282450675964\n",
      "Gradient for encoder.encoder.0.bias: 5.525217870033794e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.00033802440157160163\n",
      "Gradient for encoder.encoder.1.bias: 0.0003465707413852215\n",
      "Gradient for encoder.encoder.3.weight: 0.007483531720936298\n",
      "Gradient for encoder.encoder.3.bias: 8.091654429831507e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.002310086041688919\n",
      "Gradient for encoder.encoder.4.bias: 0.0017024263506755233\n",
      "Gradient for encoder.mean.weight: 0.031261179596185684\n",
      "Gradient for encoder.mean.bias: 0.0012973586563020945\n",
      "Gradient for encoder.log_var.weight: 0.020154114812612534\n",
      "Gradient for encoder.log_var.bias: 0.000825144408736378\n",
      "Gradient for decoder.decoder.0.weight: 0.012433631345629692\n",
      "Gradient for decoder.decoder.0.bias: 1.01834159160763e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0006225716788321733\n",
      "Gradient for decoder.decoder.1.bias: 0.0005073483916930854\n",
      "Gradient for decoder.decoder.3.weight: 0.012093509547412395\n",
      "Gradient for decoder.decoder.3.bias: 1.0337123518278091e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0006892427336424589\n",
      "Gradient for decoder.decoder.4.bias: 0.0007474108715541661\n",
      "Gradient for decoder.decoder.6.weight: 0.0011258504819124937\n",
      "Gradient for decoder.decoder.6.bias: 7.139075023587793e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.005409772973507643\n",
      "Gradient for encoder.encoder.0.bias: 7.817688336964057e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.0004636257071979344\n",
      "Gradient for encoder.encoder.1.bias: 0.00044374418212100863\n",
      "Gradient for encoder.encoder.3.weight: 0.010116074234247208\n",
      "Gradient for encoder.encoder.3.bias: 9.255498450988497e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.0026015974581241608\n",
      "Gradient for encoder.encoder.4.bias: 0.001859620213508606\n",
      "Gradient for encoder.mean.weight: 0.03624080866575241\n",
      "Gradient for encoder.mean.bias: 0.0015358212403953075\n",
      "Gradient for encoder.log_var.weight: 0.018966319039463997\n",
      "Gradient for encoder.log_var.bias: 0.0008959741680882871\n",
      "Gradient for decoder.decoder.0.weight: 0.010154551826417446\n",
      "Gradient for decoder.decoder.0.bias: 8.854533772861828e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0004942642408423126\n",
      "Gradient for decoder.decoder.1.bias: 0.00041648640763014555\n",
      "Gradient for decoder.decoder.3.weight: 0.009297551587224007\n",
      "Gradient for decoder.decoder.3.bias: 7.311477812077527e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0003367456956766546\n",
      "Gradient for decoder.decoder.4.bias: 0.0003088811645284295\n",
      "Gradient for decoder.decoder.6.weight: 0.0009449205826967955\n",
      "Gradient for decoder.decoder.6.bias: 5.3306644986150786e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.003932189662009478\n",
      "Gradient for encoder.encoder.0.bias: 5.4994494201598965e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.0003286942664999515\n",
      "Gradient for encoder.encoder.1.bias: 0.00032025729888118804\n",
      "Gradient for encoder.encoder.3.weight: 0.0070809731259942055\n",
      "Gradient for encoder.encoder.3.bias: 7.723838929551974e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.0025331596843898296\n",
      "Gradient for encoder.encoder.4.bias: 0.001676481682807207\n",
      "Gradient for encoder.mean.weight: 0.035168297588825226\n",
      "Gradient for encoder.mean.bias: 0.0012218680931255221\n",
      "Gradient for encoder.log_var.weight: 0.01920757070183754\n",
      "Gradient for encoder.log_var.bias: 0.0008437944925390184\n",
      "Gradient for decoder.decoder.0.weight: 0.010753629729151726\n",
      "Gradient for decoder.decoder.0.bias: 9.540595397039553e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005541432765312493\n",
      "Gradient for decoder.decoder.1.bias: 0.00046958320308476686\n",
      "Gradient for decoder.decoder.3.weight: 0.01017074752599001\n",
      "Gradient for decoder.decoder.3.bias: 7.870942092536026e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0003896916750818491\n",
      "Gradient for decoder.decoder.4.bias: 0.00035441838554106653\n",
      "Gradient for decoder.decoder.6.weight: 0.000959266209974885\n",
      "Gradient for decoder.decoder.6.bias: 5.49268297618255e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.0036931615322828293\n",
      "Gradient for encoder.encoder.0.bias: 5.3289152604496515e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.00033378199441358447\n",
      "Gradient for encoder.encoder.1.bias: 0.00041249117930419743\n",
      "Gradient for encoder.encoder.3.weight: 0.007261636666953564\n",
      "Gradient for encoder.encoder.3.bias: 7.951896779934131e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.002390137407928705\n",
      "Gradient for encoder.encoder.4.bias: 0.0015499882865697145\n",
      "Gradient for encoder.mean.weight: 0.03243856132030487\n",
      "Gradient for encoder.mean.bias: 0.0010937906336039305\n",
      "Gradient for encoder.log_var.weight: 0.01887768879532814\n",
      "Gradient for encoder.log_var.bias: 0.0007419108878821135\n",
      "Gradient for decoder.decoder.0.weight: 0.011578783392906189\n",
      "Gradient for decoder.decoder.0.bias: 9.441306764168544e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.000527155410964042\n",
      "Gradient for decoder.decoder.1.bias: 0.0004798720474354923\n",
      "Gradient for decoder.decoder.3.weight: 0.011119929142296314\n",
      "Gradient for decoder.decoder.3.bias: 8.100033838109866e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00044491139124147594\n",
      "Gradient for decoder.decoder.4.bias: 0.0004375250427983701\n",
      "Gradient for decoder.decoder.6.weight: 0.0009540082537569106\n",
      "Gradient for decoder.decoder.6.bias: 5.606663762591779e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.005566217936575413\n",
      "Gradient for encoder.encoder.0.bias: 8.557884435822505e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.00042205266072414815\n",
      "Gradient for encoder.encoder.1.bias: 0.00034935559961013496\n",
      "Gradient for encoder.encoder.3.weight: 0.009077100083231926\n",
      "Gradient for encoder.encoder.3.bias: 9.987129873101352e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.0024321398232132196\n",
      "Gradient for encoder.encoder.4.bias: 0.002082832157611847\n",
      "Gradient for encoder.mean.weight: 0.03370993956923485\n",
      "Gradient for encoder.mean.bias: 0.0016215237556025386\n",
      "Gradient for encoder.log_var.weight: 0.019264355301856995\n",
      "Gradient for encoder.log_var.bias: 0.0008791703148745\n",
      "Gradient for decoder.decoder.0.weight: 0.009593893773853779\n",
      "Gradient for decoder.decoder.0.bias: 8.25339241394829e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0004597464285325259\n",
      "Gradient for decoder.decoder.1.bias: 0.00040734137292020023\n",
      "Gradient for decoder.decoder.3.weight: 0.008812680840492249\n",
      "Gradient for decoder.decoder.3.bias: 7.440922877854916e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00033680832711979747\n",
      "Gradient for decoder.decoder.4.bias: 0.0003254892653785646\n",
      "Gradient for decoder.decoder.6.weight: 0.001022565527819097\n",
      "Gradient for decoder.decoder.6.bias: 6.809809565311298e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.005174604710191488\n",
      "Gradient for encoder.encoder.0.bias: 7.78225660996723e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.0003493036492727697\n",
      "Gradient for encoder.encoder.1.bias: 0.00030810365569777787\n",
      "Gradient for encoder.encoder.3.weight: 0.007601303048431873\n",
      "Gradient for encoder.encoder.3.bias: 8.92679888342407e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.0022852399852126837\n",
      "Gradient for encoder.encoder.4.bias: 0.0017147408798336983\n",
      "Gradient for encoder.mean.weight: 0.030115213245153427\n",
      "Gradient for encoder.mean.bias: 0.0014606203185394406\n",
      "Gradient for encoder.log_var.weight: 0.017881350591778755\n",
      "Gradient for encoder.log_var.bias: 0.0008313313592225313\n",
      "Gradient for decoder.decoder.0.weight: 0.009712534956634045\n",
      "Gradient for decoder.decoder.0.bias: 8.536314710649862e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0004481837968342006\n",
      "Gradient for decoder.decoder.1.bias: 0.00037772368523292243\n",
      "Gradient for decoder.decoder.3.weight: 0.009027298539876938\n",
      "Gradient for decoder.decoder.3.bias: 7.44110745243276e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00036128112697042525\n",
      "Gradient for decoder.decoder.4.bias: 0.0003494726261124015\n",
      "Gradient for decoder.decoder.6.weight: 0.0009139097528532147\n",
      "Gradient for decoder.decoder.6.bias: 4.774961416842416e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.003984853159636259\n",
      "Gradient for encoder.encoder.0.bias: 6.1914535998131015e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.00032391087734140456\n",
      "Gradient for encoder.encoder.1.bias: 0.00028297226526774466\n",
      "Gradient for encoder.encoder.3.weight: 0.007160375826060772\n",
      "Gradient for encoder.encoder.3.bias: 8.971469400709253e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.0024407883174717426\n",
      "Gradient for encoder.encoder.4.bias: 0.0017511005280539393\n",
      "Gradient for encoder.mean.weight: 0.031614795327186584\n",
      "Gradient for encoder.mean.bias: 0.0014089745236560702\n",
      "Gradient for encoder.log_var.weight: 0.017967652529478073\n",
      "Gradient for encoder.log_var.bias: 0.0008324412046931684\n",
      "Gradient for decoder.decoder.0.weight: 0.01068604551255703\n",
      "Gradient for decoder.decoder.0.bias: 9.329873679186917e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005226478679105639\n",
      "Gradient for decoder.decoder.1.bias: 0.0004678809200413525\n",
      "Gradient for decoder.decoder.3.weight: 0.009915649890899658\n",
      "Gradient for decoder.decoder.3.bias: 8.322816047456882e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0004787463112734258\n",
      "Gradient for decoder.decoder.4.bias: 0.0005104200099594891\n",
      "Gradient for decoder.decoder.6.weight: 0.0010862423805519938\n",
      "Gradient for decoder.decoder.6.bias: 7.698454282945022e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.00785525981336832\n",
      "Gradient for encoder.encoder.0.bias: 1.274763974934423e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.00043745405855588615\n",
      "Gradient for encoder.encoder.1.bias: 0.0003650178841780871\n",
      "Gradient for encoder.encoder.3.weight: 0.009212593547999859\n",
      "Gradient for encoder.encoder.3.bias: 9.088082369990147e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.001996189123019576\n",
      "Gradient for encoder.encoder.4.bias: 0.0016220413381233811\n",
      "Gradient for encoder.mean.weight: 0.026699703186750412\n",
      "Gradient for encoder.mean.bias: 0.0012328247539699078\n",
      "Gradient for encoder.log_var.weight: 0.014728141948580742\n",
      "Gradient for encoder.log_var.bias: 0.0007358391303569078\n",
      "Gradient for decoder.decoder.0.weight: 0.008067100308835506\n",
      "Gradient for decoder.decoder.0.bias: 7.221306885796253e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0004227500467095524\n",
      "Gradient for decoder.decoder.1.bias: 0.0003485239576548338\n",
      "Gradient for decoder.decoder.3.weight: 0.007497829385101795\n",
      "Gradient for decoder.decoder.3.bias: 5.92082008421535e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00031584312091581523\n",
      "Gradient for decoder.decoder.4.bias: 0.0003233036259189248\n",
      "Gradient for decoder.decoder.6.weight: 0.0009310178575105965\n",
      "Gradient for decoder.decoder.6.bias: 5.392335879150778e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.005000381264835596\n",
      "Gradient for encoder.encoder.0.bias: 8.489392348820513e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.00037658403743989766\n",
      "Gradient for encoder.encoder.1.bias: 0.00040653449832461774\n",
      "Gradient for encoder.encoder.3.weight: 0.00823254231363535\n",
      "Gradient for encoder.encoder.3.bias: 8.240758769817447e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.0022403227631002665\n",
      "Gradient for encoder.encoder.4.bias: 0.0017260637832805514\n",
      "Gradient for encoder.mean.weight: 0.030439361929893494\n",
      "Gradient for encoder.mean.bias: 0.0012156546581536531\n",
      "Gradient for encoder.log_var.weight: 0.017558099702000618\n",
      "Gradient for encoder.log_var.bias: 0.0006995304138399661\n",
      "Gradient for decoder.decoder.0.weight: 0.009374001994729042\n",
      "Gradient for decoder.decoder.0.bias: 7.70848732067897e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0004473985463846475\n",
      "Gradient for decoder.decoder.1.bias: 0.00037049525417387486\n",
      "Gradient for decoder.decoder.3.weight: 0.008562449365854263\n",
      "Gradient for decoder.decoder.3.bias: 9.557912794555534e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0005767630063928664\n",
      "Gradient for decoder.decoder.4.bias: 0.0006901394808664918\n",
      "Gradient for decoder.decoder.6.weight: 0.0010551472660154104\n",
      "Gradient for decoder.decoder.6.bias: 7.592978363391012e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.004625956993550062\n",
      "Gradient for encoder.encoder.0.bias: 7.1013334101976966e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.0003097335866186768\n",
      "Gradient for encoder.encoder.1.bias: 0.0003678866196423769\n",
      "Gradient for encoder.encoder.3.weight: 0.006477687507867813\n",
      "Gradient for encoder.encoder.3.bias: 7.875931851142326e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.002470394130796194\n",
      "Gradient for encoder.encoder.4.bias: 0.0018645153613761067\n",
      "Gradient for encoder.mean.weight: 0.03513322025537491\n",
      "Gradient for encoder.mean.bias: 0.001397329499013722\n",
      "Gradient for encoder.log_var.weight: 0.02134745568037033\n",
      "Gradient for encoder.log_var.bias: 0.000787873927038163\n",
      "Gradient for decoder.decoder.0.weight: 0.01026905421167612\n",
      "Gradient for decoder.decoder.0.bias: 8.462723577462583e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0004699748242273927\n",
      "Gradient for decoder.decoder.1.bias: 0.0003968214732594788\n",
      "Gradient for decoder.decoder.3.weight: 0.009577720426023006\n",
      "Gradient for decoder.decoder.3.bias: 8.703015391686719e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00034376015537418425\n",
      "Gradient for decoder.decoder.4.bias: 0.0003169109986629337\n",
      "Gradient for decoder.decoder.6.weight: 0.0009865096071735024\n",
      "Gradient for decoder.decoder.6.bias: 6.507009675260633e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.005034532397985458\n",
      "Gradient for encoder.encoder.0.bias: 7.452441441735402e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.0003420707071200013\n",
      "Gradient for encoder.encoder.1.bias: 0.00034258986124768853\n",
      "Gradient for encoder.encoder.3.weight: 0.007581430021673441\n",
      "Gradient for encoder.encoder.3.bias: 7.946392849289552e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.0020495580974966288\n",
      "Gradient for encoder.encoder.4.bias: 0.0015465172473341227\n",
      "Gradient for encoder.mean.weight: 0.02843400277197361\n",
      "Gradient for encoder.mean.bias: 0.0012506514322012663\n",
      "Gradient for encoder.log_var.weight: 0.01718820631504059\n",
      "Gradient for encoder.log_var.bias: 0.0008291807607747614\n",
      "Gradient for decoder.decoder.0.weight: 0.010060257278382778\n",
      "Gradient for decoder.decoder.0.bias: 8.185720851150435e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0004787116195075214\n",
      "Gradient for decoder.decoder.1.bias: 0.0003884905017912388\n",
      "Gradient for decoder.decoder.3.weight: 0.009206215851008892\n",
      "Gradient for decoder.decoder.3.bias: 6.784485473421142e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0003451709926594049\n",
      "Gradient for decoder.decoder.4.bias: 0.00032039027428254485\n",
      "Gradient for decoder.decoder.6.weight: 0.0009788477327674627\n",
      "Gradient for decoder.decoder.6.bias: 5.690478064934723e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.007961643859744072\n",
      "Gradient for encoder.encoder.0.bias: 1.2404375270003154e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0005081270355731249\n",
      "Gradient for encoder.encoder.1.bias: 0.0004788116493728012\n",
      "Gradient for encoder.encoder.3.weight: 0.011194033548235893\n",
      "Gradient for encoder.encoder.3.bias: 9.441224885220478e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.002374590141698718\n",
      "Gradient for encoder.encoder.4.bias: 0.001609664410352707\n",
      "Gradient for encoder.mean.weight: 0.03265437111258507\n",
      "Gradient for encoder.mean.bias: 0.0013742285082116723\n",
      "Gradient for encoder.log_var.weight: 0.01762440614402294\n",
      "Gradient for encoder.log_var.bias: 0.000848827010486275\n",
      "Gradient for decoder.decoder.0.weight: 0.00821617804467678\n",
      "Gradient for decoder.decoder.0.bias: 7.464621282204931e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.00038334596320055425\n",
      "Gradient for decoder.decoder.1.bias: 0.0003209745045751333\n",
      "Gradient for decoder.decoder.3.weight: 0.007467762567102909\n",
      "Gradient for decoder.decoder.3.bias: 7.150124936572411e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0004225872689858079\n",
      "Gradient for decoder.decoder.4.bias: 0.00048191696987487376\n",
      "Gradient for decoder.decoder.6.weight: 0.0009137107408605516\n",
      "Gradient for decoder.decoder.6.bias: 4.710725261247717e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.004207680467516184\n",
      "Gradient for encoder.encoder.0.bias: 6.638119741386728e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.00039862823905423284\n",
      "Gradient for encoder.encoder.1.bias: 0.00033098951098509133\n",
      "Gradient for encoder.encoder.3.weight: 0.00854395143687725\n",
      "Gradient for encoder.encoder.3.bias: 7.60063678661993e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.0024043042212724686\n",
      "Gradient for encoder.encoder.4.bias: 0.0015241856453940272\n",
      "Gradient for encoder.mean.weight: 0.032642655074596405\n",
      "Gradient for encoder.mean.bias: 0.0011615772964432836\n",
      "Gradient for encoder.log_var.weight: 0.01779567264020443\n",
      "Gradient for encoder.log_var.bias: 0.0007477686158381402\n",
      "Gradient for decoder.decoder.0.weight: 0.00982027966529131\n",
      "Gradient for decoder.decoder.0.bias: 8.684745977927122e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.00047507640556432307\n",
      "Gradient for decoder.decoder.1.bias: 0.0004111019952688366\n",
      "Gradient for decoder.decoder.3.weight: 0.009084470570087433\n",
      "Gradient for decoder.decoder.3.bias: 7.661642847933692e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0003814079100266099\n",
      "Gradient for decoder.decoder.4.bias: 0.00039115746039897203\n",
      "Gradient for decoder.decoder.6.weight: 0.0008889711461961269\n",
      "Gradient for decoder.decoder.6.bias: 4.298735439078882e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.006593106780201197\n",
      "Gradient for encoder.encoder.0.bias: 9.5620889678516e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.0004190784820821136\n",
      "Gradient for encoder.encoder.1.bias: 0.00035136978840455413\n",
      "Gradient for encoder.encoder.3.weight: 0.008407148532569408\n",
      "Gradient for encoder.encoder.3.bias: 8.926704514466977e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.002253130776807666\n",
      "Gradient for encoder.encoder.4.bias: 0.0017394591122865677\n",
      "Gradient for encoder.mean.weight: 0.032374922186136246\n",
      "Gradient for encoder.mean.bias: 0.0012495305854827166\n",
      "Gradient for encoder.log_var.weight: 0.01752239651978016\n",
      "Gradient for encoder.log_var.bias: 0.0007661048439331353\n",
      "Gradient for decoder.decoder.0.weight: 0.008767153136432171\n",
      "Gradient for decoder.decoder.0.bias: 8.043646998467935e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.00041973573388531804\n",
      "Gradient for decoder.decoder.1.bias: 0.0003524968633428216\n",
      "Gradient for decoder.decoder.3.weight: 0.008071839809417725\n",
      "Gradient for decoder.decoder.3.bias: 6.443647004861219e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0003485754714347422\n",
      "Gradient for decoder.decoder.4.bias: 0.0003437188861425966\n",
      "Gradient for decoder.decoder.6.weight: 0.0012299699010327458\n",
      "Gradient for decoder.decoder.6.bias: 9.881994628813118e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.008274710737168789\n",
      "Gradient for encoder.encoder.0.bias: 1.225839221796754e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0004335991106927395\n",
      "Gradient for encoder.encoder.1.bias: 0.00040325053851120174\n",
      "Gradient for encoder.encoder.3.weight: 0.00886552780866623\n",
      "Gradient for encoder.encoder.3.bias: 9.586901411617887e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.002132217399775982\n",
      "Gradient for encoder.encoder.4.bias: 0.0016580472001805902\n",
      "Gradient for encoder.mean.weight: 0.03036329336464405\n",
      "Gradient for encoder.mean.bias: 0.0012766493018716574\n",
      "Gradient for encoder.log_var.weight: 0.01751379482448101\n",
      "Gradient for encoder.log_var.bias: 0.0008892688201740384\n",
      "Gradient for decoder.decoder.0.weight: 0.008333663456141949\n",
      "Gradient for decoder.decoder.0.bias: 7.100205839938312e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.000394874659832567\n",
      "Gradient for decoder.decoder.1.bias: 0.00035748473601415753\n",
      "Gradient for decoder.decoder.3.weight: 0.007638433016836643\n",
      "Gradient for decoder.decoder.3.bias: 6.313581601968821e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0003073459374718368\n",
      "Gradient for decoder.decoder.4.bias: 0.00031039593159221113\n",
      "Gradient for decoder.decoder.6.weight: 0.000930664362385869\n",
      "Gradient for decoder.decoder.6.bias: 4.9646510888123885e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.006153437774628401\n",
      "Gradient for encoder.encoder.0.bias: 9.857112522049238e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.00045022572157904506\n",
      "Gradient for encoder.encoder.1.bias: 0.00036116602132096887\n",
      "Gradient for encoder.encoder.3.weight: 0.0101735545322299\n",
      "Gradient for encoder.encoder.3.bias: 8.739701323756677e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.0020291071850806475\n",
      "Gradient for encoder.encoder.4.bias: 0.001638971152715385\n",
      "Gradient for encoder.mean.weight: 0.02621358633041382\n",
      "Gradient for encoder.mean.bias: 0.001177114900201559\n",
      "Gradient for encoder.log_var.weight: 0.016565537080168724\n",
      "Gradient for encoder.log_var.bias: 0.0007533514290116727\n",
      "Gradient for decoder.decoder.0.weight: 0.008538472466170788\n",
      "Gradient for decoder.decoder.0.bias: 6.949744252304768e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.00041975040221586823\n",
      "Gradient for decoder.decoder.1.bias: 0.00035030615981668234\n",
      "Gradient for decoder.decoder.3.weight: 0.0077455355785787106\n",
      "Gradient for decoder.decoder.3.bias: 7.23027054894132e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0003757739905267954\n",
      "Gradient for decoder.decoder.4.bias: 0.0004098450008314103\n",
      "Gradient for decoder.decoder.6.weight: 0.0009264369145967066\n",
      "Gradient for decoder.decoder.6.bias: 4.9168353143613786e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training VAE Epoch:  52%|█████▏    | 41/79 [00:00<00:00, 69.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient for encoder.encoder.0.weight: 0.0041882675141096115\n",
      "Gradient for encoder.encoder.0.bias: 6.0560003192766665e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.000329940696246922\n",
      "Gradient for encoder.encoder.1.bias: 0.0003107365046162158\n",
      "Gradient for encoder.encoder.3.weight: 0.006836826913058758\n",
      "Gradient for encoder.encoder.3.bias: 8.304346793552853e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.0019897357560694218\n",
      "Gradient for encoder.encoder.4.bias: 0.0014850731240585446\n",
      "Gradient for encoder.mean.weight: 0.029735902324318886\n",
      "Gradient for encoder.mean.bias: 0.0012146956287324429\n",
      "Gradient for encoder.log_var.weight: 0.014818697236478329\n",
      "Gradient for encoder.log_var.bias: 0.0007677958346903324\n",
      "Gradient for decoder.decoder.0.weight: 0.01008837390691042\n",
      "Gradient for decoder.decoder.0.bias: 8.945182095043691e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0004951808950863779\n",
      "Gradient for decoder.decoder.1.bias: 0.00039758917409926653\n",
      "Gradient for decoder.decoder.3.weight: 0.009561768732964993\n",
      "Gradient for decoder.decoder.3.bias: 9.433624020838138e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0005020165699534118\n",
      "Gradient for decoder.decoder.4.bias: 0.0005504795699380338\n",
      "Gradient for decoder.decoder.6.weight: 0.0009999617468565702\n",
      "Gradient for decoder.decoder.6.bias: 6.231829320313409e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.004632493481040001\n",
      "Gradient for encoder.encoder.0.bias: 5.622270010663399e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.00030335396877489984\n",
      "Gradient for encoder.encoder.1.bias: 0.0003171288117300719\n",
      "Gradient for encoder.encoder.3.weight: 0.006436767987906933\n",
      "Gradient for encoder.encoder.3.bias: 9.405765055703341e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.0022742198780179024\n",
      "Gradient for encoder.encoder.4.bias: 0.0020304962527006865\n",
      "Gradient for encoder.mean.weight: 0.03215643763542175\n",
      "Gradient for encoder.mean.bias: 0.001533667091280222\n",
      "Gradient for encoder.log_var.weight: 0.01713414303958416\n",
      "Gradient for encoder.log_var.bias: 0.0010492269648239017\n",
      "Gradient for decoder.decoder.0.weight: 0.011230009607970715\n",
      "Gradient for decoder.decoder.0.bias: 9.492905073127389e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.000546601542737335\n",
      "Gradient for decoder.decoder.1.bias: 0.0004882877110503614\n",
      "Gradient for decoder.decoder.3.weight: 0.010686034336686134\n",
      "Gradient for decoder.decoder.3.bias: 1.0237555247982755e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0006674717296846211\n",
      "Gradient for decoder.decoder.4.bias: 0.0007527442066930234\n",
      "Gradient for decoder.decoder.6.weight: 0.0013076451141387224\n",
      "Gradient for decoder.decoder.6.bias: 0.00010228459723293781\n",
      "Gradient for encoder.encoder.0.weight: 0.007219159044325352\n",
      "Gradient for encoder.encoder.0.bias: 1.0470859422573309e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0004100252117495984\n",
      "Gradient for encoder.encoder.1.bias: 0.0004196850932203233\n",
      "Gradient for encoder.encoder.3.weight: 0.008990772068500519\n",
      "Gradient for encoder.encoder.3.bias: 1.0569955327666136e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.0021144177298992872\n",
      "Gradient for encoder.encoder.4.bias: 0.0019015736179426312\n",
      "Gradient for encoder.mean.weight: 0.030668223276734352\n",
      "Gradient for encoder.mean.bias: 0.0015340471873059869\n",
      "Gradient for encoder.log_var.weight: 0.017781244590878487\n",
      "Gradient for encoder.log_var.bias: 0.0010451317066326737\n",
      "Gradient for decoder.decoder.0.weight: 0.008976581506431103\n",
      "Gradient for decoder.decoder.0.bias: 7.890925413089889e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.000451360538136214\n",
      "Gradient for decoder.decoder.1.bias: 0.00036656821612268686\n",
      "Gradient for decoder.decoder.3.weight: 0.008588690310716629\n",
      "Gradient for decoder.decoder.3.bias: 7.216054143110995e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00045821384992450476\n",
      "Gradient for decoder.decoder.4.bias: 0.0005329747218638659\n",
      "Gradient for decoder.decoder.6.weight: 0.0011488839518278837\n",
      "Gradient for decoder.decoder.6.bias: 9.357703675050288e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.003399333916604519\n",
      "Gradient for encoder.encoder.0.bias: 5.2075171431964495e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.00031359991407953203\n",
      "Gradient for encoder.encoder.1.bias: 0.0002671767433639616\n",
      "Gradient for encoder.encoder.3.weight: 0.0069944970309734344\n",
      "Gradient for encoder.encoder.3.bias: 7.479038915958469e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.001898273010738194\n",
      "Gradient for encoder.encoder.4.bias: 0.0015688086859881878\n",
      "Gradient for encoder.mean.weight: 0.028124667704105377\n",
      "Gradient for encoder.mean.bias: 0.001174507662653923\n",
      "Gradient for encoder.log_var.weight: 0.01525901723653078\n",
      "Gradient for encoder.log_var.bias: 0.0007543439860455692\n",
      "Gradient for decoder.decoder.0.weight: 0.01097053848206997\n",
      "Gradient for decoder.decoder.0.bias: 9.751050661366278e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005467066657729447\n",
      "Gradient for decoder.decoder.1.bias: 0.00048470121691934764\n",
      "Gradient for decoder.decoder.3.weight: 0.010179406963288784\n",
      "Gradient for decoder.decoder.3.bias: 9.259297495400887e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0004784639459103346\n",
      "Gradient for decoder.decoder.4.bias: 0.0004972111782990396\n",
      "Gradient for decoder.decoder.6.weight: 0.0010421308688819408\n",
      "Gradient for decoder.decoder.6.bias: 6.670515722362325e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.00647727632895112\n",
      "Gradient for encoder.encoder.0.bias: 9.955755837787184e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.0003616634348873049\n",
      "Gradient for encoder.encoder.1.bias: 0.00030378196970559657\n",
      "Gradient for encoder.encoder.3.weight: 0.007891185581684113\n",
      "Gradient for encoder.encoder.3.bias: 8.82076009456334e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.001980147324502468\n",
      "Gradient for encoder.encoder.4.bias: 0.001654217834584415\n",
      "Gradient for encoder.mean.weight: 0.028722357004880905\n",
      "Gradient for encoder.mean.bias: 0.0012217541225254536\n",
      "Gradient for encoder.log_var.weight: 0.014716639183461666\n",
      "Gradient for encoder.log_var.bias: 0.0007321188459172845\n",
      "Gradient for decoder.decoder.0.weight: 0.008250768296420574\n",
      "Gradient for decoder.decoder.0.bias: 7.196762630279352e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.00038419922930188477\n",
      "Gradient for decoder.decoder.1.bias: 0.0003405115567147732\n",
      "Gradient for decoder.decoder.3.weight: 0.007590349763631821\n",
      "Gradient for decoder.decoder.3.bias: 7.059559187228004e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0004055819590575993\n",
      "Gradient for decoder.decoder.4.bias: 0.0004508637357503176\n",
      "Gradient for decoder.decoder.6.weight: 0.0009241944062523544\n",
      "Gradient for decoder.decoder.6.bias: 5.523649451788515e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.004699538461863995\n",
      "Gradient for encoder.encoder.0.bias: 6.4771768677751584e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.0002725933736655861\n",
      "Gradient for encoder.encoder.1.bias: 0.0002737421018537134\n",
      "Gradient for encoder.encoder.3.weight: 0.005926663056015968\n",
      "Gradient for encoder.encoder.3.bias: 7.471560869998228e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.0019319491693750024\n",
      "Gradient for encoder.encoder.4.bias: 0.0013923838268965483\n",
      "Gradient for encoder.mean.weight: 0.028057878836989403\n",
      "Gradient for encoder.mean.bias: 0.0010512968292459846\n",
      "Gradient for encoder.log_var.weight: 0.017931750044226646\n",
      "Gradient for encoder.log_var.bias: 0.0007670533377677202\n",
      "Gradient for decoder.decoder.0.weight: 0.010826951824128628\n",
      "Gradient for decoder.decoder.0.bias: 8.936604234399681e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005422895192168653\n",
      "Gradient for decoder.decoder.1.bias: 0.0004063030064571649\n",
      "Gradient for decoder.decoder.3.weight: 0.009997174143791199\n",
      "Gradient for decoder.decoder.3.bias: 8.014555685775804e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0003813893417827785\n",
      "Gradient for decoder.decoder.4.bias: 0.0003116175648756325\n",
      "Gradient for decoder.decoder.6.weight: 0.0009007460321299732\n",
      "Gradient for decoder.decoder.6.bias: 4.234005609760061e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.011538284830749035\n",
      "Gradient for encoder.encoder.0.bias: 1.9090696037893373e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.0004995347699150443\n",
      "Gradient for encoder.encoder.1.bias: 0.0004698692064266652\n",
      "Gradient for encoder.encoder.3.weight: 0.010971819050610065\n",
      "Gradient for encoder.encoder.3.bias: 1.1506035013653104e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.002579567488282919\n",
      "Gradient for encoder.encoder.4.bias: 0.002209554659202695\n",
      "Gradient for encoder.mean.weight: 0.03809543326497078\n",
      "Gradient for encoder.mean.bias: 0.0015538708539679646\n",
      "Gradient for encoder.log_var.weight: 0.02402379922568798\n",
      "Gradient for encoder.log_var.bias: 0.0009923544712364674\n",
      "Gradient for decoder.decoder.0.weight: 0.007444499991834164\n",
      "Gradient for decoder.decoder.0.bias: 6.129888263650685e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0003367750032339245\n",
      "Gradient for decoder.decoder.1.bias: 0.0003015929542016238\n",
      "Gradient for decoder.decoder.3.weight: 0.006867569405585527\n",
      "Gradient for decoder.decoder.3.bias: 5.862207247409046e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00030766750569455326\n",
      "Gradient for decoder.decoder.4.bias: 0.0002989429631270468\n",
      "Gradient for decoder.decoder.6.weight: 0.0010053793666884303\n",
      "Gradient for decoder.decoder.6.bias: 6.614153244299814e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.004717960953712463\n",
      "Gradient for encoder.encoder.0.bias: 7.124261250379682e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.00033432384952902794\n",
      "Gradient for encoder.encoder.1.bias: 0.000274215592071414\n",
      "Gradient for encoder.encoder.3.weight: 0.007425560615956783\n",
      "Gradient for encoder.encoder.3.bias: 8.685763913662825e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.0018337974324822426\n",
      "Gradient for encoder.encoder.4.bias: 0.001628947677090764\n",
      "Gradient for encoder.mean.weight: 0.026477031409740448\n",
      "Gradient for encoder.mean.bias: 0.0012259574141353369\n",
      "Gradient for encoder.log_var.weight: 0.016381720080971718\n",
      "Gradient for encoder.log_var.bias: 0.0007478109328076243\n",
      "Gradient for decoder.decoder.0.weight: 0.009203707799315453\n",
      "Gradient for decoder.decoder.0.bias: 8.824640324034405e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0004302409943193197\n",
      "Gradient for decoder.decoder.1.bias: 0.0003826376050710678\n",
      "Gradient for decoder.decoder.3.weight: 0.008529257029294968\n",
      "Gradient for decoder.decoder.3.bias: 6.956501347188393e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0003125039511360228\n",
      "Gradient for decoder.decoder.4.bias: 0.0002822597452905029\n",
      "Gradient for decoder.decoder.6.weight: 0.0009504653862677515\n",
      "Gradient for decoder.decoder.6.bias: 5.398844223236665e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.006055939942598343\n",
      "Gradient for encoder.encoder.0.bias: 8.096683913605407e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.00036843374255113304\n",
      "Gradient for encoder.encoder.1.bias: 0.000302455184282735\n",
      "Gradient for encoder.encoder.3.weight: 0.008121187798678875\n",
      "Gradient for encoder.encoder.3.bias: 7.720073191830323e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.0020421682856976986\n",
      "Gradient for encoder.encoder.4.bias: 0.0016155887860804796\n",
      "Gradient for encoder.mean.weight: 0.03010622039437294\n",
      "Gradient for encoder.mean.bias: 0.0012547618243843317\n",
      "Gradient for encoder.log_var.weight: 0.01678294688463211\n",
      "Gradient for encoder.log_var.bias: 0.000802546797785908\n",
      "Gradient for decoder.decoder.0.weight: 0.00992177240550518\n",
      "Gradient for decoder.decoder.0.bias: 8.34740887523111e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0004829406680073589\n",
      "Gradient for decoder.decoder.1.bias: 0.0004343096225056797\n",
      "Gradient for decoder.decoder.3.weight: 0.009360009804368019\n",
      "Gradient for decoder.decoder.3.bias: 8.297534881407387e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0005457668448798358\n",
      "Gradient for decoder.decoder.4.bias: 0.000620853214059025\n",
      "Gradient for decoder.decoder.6.weight: 0.001031898078508675\n",
      "Gradient for decoder.decoder.6.bias: 6.616710015805438e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.004407910164445639\n",
      "Gradient for encoder.encoder.0.bias: 6.358388641991564e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.00039868635940365493\n",
      "Gradient for encoder.encoder.1.bias: 0.0002723574289120734\n",
      "Gradient for encoder.encoder.3.weight: 0.008716033771634102\n",
      "Gradient for encoder.encoder.3.bias: 8.911423682311792e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.002459789626300335\n",
      "Gradient for encoder.encoder.4.bias: 0.0019021907355636358\n",
      "Gradient for encoder.mean.weight: 0.03678273782134056\n",
      "Gradient for encoder.mean.bias: 0.001335366046987474\n",
      "Gradient for encoder.log_var.weight: 0.020674929022789\n",
      "Gradient for encoder.log_var.bias: 0.000905969412997365\n",
      "Gradient for decoder.decoder.0.weight: 0.010979692451655865\n",
      "Gradient for decoder.decoder.0.bias: 9.325744343424702e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.000558941625058651\n",
      "Gradient for decoder.decoder.1.bias: 0.00043646624544635415\n",
      "Gradient for decoder.decoder.3.weight: 0.010429903864860535\n",
      "Gradient for decoder.decoder.3.bias: 8.164780657127224e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0004853138525504619\n",
      "Gradient for decoder.decoder.4.bias: 0.00047035381430760026\n",
      "Gradient for decoder.decoder.6.weight: 0.0010424723150208592\n",
      "Gradient for decoder.decoder.6.bias: 6.56983902445063e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.003245292231440544\n",
      "Gradient for encoder.encoder.0.bias: 5.1374304116391656e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.000353229115717113\n",
      "Gradient for encoder.encoder.1.bias: 0.00031498531461693347\n",
      "Gradient for encoder.encoder.3.weight: 0.00808604247868061\n",
      "Gradient for encoder.encoder.3.bias: 8.198949158488844e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.0023200898431241512\n",
      "Gradient for encoder.encoder.4.bias: 0.0017451579915359616\n",
      "Gradient for encoder.mean.weight: 0.03491235896945\n",
      "Gradient for encoder.mean.bias: 0.001218738965690136\n",
      "Gradient for encoder.log_var.weight: 0.019688455387949944\n",
      "Gradient for encoder.log_var.bias: 0.0009320933604612947\n",
      "Gradient for decoder.decoder.0.weight: 0.011389262974262238\n",
      "Gradient for decoder.decoder.0.bias: 1.0449775073029244e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0005556099349632859\n",
      "Gradient for decoder.decoder.1.bias: 0.0004613773198798299\n",
      "Gradient for decoder.decoder.3.weight: 0.010606146417558193\n",
      "Gradient for decoder.decoder.3.bias: 8.515032429157188e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00039784880937077105\n",
      "Gradient for decoder.decoder.4.bias: 0.0003643107775133103\n",
      "Gradient for decoder.decoder.6.weight: 0.0009696073248051107\n",
      "Gradient for decoder.decoder.6.bias: 5.837257413077168e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.00459764339029789\n",
      "Gradient for encoder.encoder.0.bias: 6.912678762738267e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.00032417694455944\n",
      "Gradient for encoder.encoder.1.bias: 0.0003397742402739823\n",
      "Gradient for encoder.encoder.3.weight: 0.007341293618083\n",
      "Gradient for encoder.encoder.3.bias: 7.694037768013473e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.0019462571945041418\n",
      "Gradient for encoder.encoder.4.bias: 0.0014007624704390764\n",
      "Gradient for encoder.mean.weight: 0.02786402590572834\n",
      "Gradient for encoder.mean.bias: 0.001169768744148314\n",
      "Gradient for encoder.log_var.weight: 0.017698463052511215\n",
      "Gradient for encoder.log_var.bias: 0.0007703152950853109\n",
      "Gradient for decoder.decoder.0.weight: 0.010170215740799904\n",
      "Gradient for decoder.decoder.0.bias: 9.53020024008211e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.00046288251178339124\n",
      "Gradient for decoder.decoder.1.bias: 0.00045673962449654937\n",
      "Gradient for decoder.decoder.3.weight: 0.009729167446494102\n",
      "Gradient for decoder.decoder.3.bias: 7.02708793931528e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0003725052811205387\n",
      "Gradient for decoder.decoder.4.bias: 0.0003646730328910053\n",
      "Gradient for decoder.decoder.6.weight: 0.000937243748921901\n",
      "Gradient for decoder.decoder.6.bias: 5.30688812432345e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.00595257431268692\n",
      "Gradient for encoder.encoder.0.bias: 8.447645361009393e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.00036510315840132535\n",
      "Gradient for encoder.encoder.1.bias: 0.000347170076565817\n",
      "Gradient for encoder.encoder.3.weight: 0.007900241762399673\n",
      "Gradient for encoder.encoder.3.bias: 8.51661657863545e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.0019256874220445752\n",
      "Gradient for encoder.encoder.4.bias: 0.0015949096996337175\n",
      "Gradient for encoder.mean.weight: 0.02629079669713974\n",
      "Gradient for encoder.mean.bias: 0.0012005656026303768\n",
      "Gradient for encoder.log_var.weight: 0.01654878444969654\n",
      "Gradient for encoder.log_var.bias: 0.0007897993200458586\n",
      "Gradient for decoder.decoder.0.weight: 0.010178851895034313\n",
      "Gradient for decoder.decoder.0.bias: 8.773044790633122e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0004828065575566143\n",
      "Gradient for decoder.decoder.1.bias: 0.0004403646744322032\n",
      "Gradient for decoder.decoder.3.weight: 0.009239093400537968\n",
      "Gradient for decoder.decoder.3.bias: 6.906659966166018e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0003320130053907633\n",
      "Gradient for decoder.decoder.4.bias: 0.0002983025915455073\n",
      "Gradient for decoder.decoder.6.weight: 0.0009358791867271066\n",
      "Gradient for decoder.decoder.6.bias: 5.216046338318847e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.00419465359300375\n",
      "Gradient for encoder.encoder.0.bias: 6.387669473223445e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.0004283748858142644\n",
      "Gradient for encoder.encoder.1.bias: 0.0003210113209206611\n",
      "Gradient for encoder.encoder.3.weight: 0.009470678865909576\n",
      "Gradient for encoder.encoder.3.bias: 8.562130171529958e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.002338285557925701\n",
      "Gradient for encoder.encoder.4.bias: 0.0017069875029847026\n",
      "Gradient for encoder.mean.weight: 0.03312935680150986\n",
      "Gradient for encoder.mean.bias: 0.0012175549054518342\n",
      "Gradient for encoder.log_var.weight: 0.01836295984685421\n",
      "Gradient for encoder.log_var.bias: 0.0008252731058746576\n",
      "Gradient for decoder.decoder.0.weight: 0.010936298407614231\n",
      "Gradient for decoder.decoder.0.bias: 9.369043735274474e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005417166976258159\n",
      "Gradient for decoder.decoder.1.bias: 0.00042265161755494773\n",
      "Gradient for decoder.decoder.3.weight: 0.010450967587530613\n",
      "Gradient for decoder.decoder.3.bias: 8.198421108662757e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0003869333886541426\n",
      "Gradient for decoder.decoder.4.bias: 0.0003630580031313002\n",
      "Gradient for decoder.decoder.6.weight: 0.0009510365780442953\n",
      "Gradient for decoder.decoder.6.bias: 4.933784657623619e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.004879320971667767\n",
      "Gradient for encoder.encoder.0.bias: 7.760488432428936e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.0003716510836966336\n",
      "Gradient for encoder.encoder.1.bias: 0.00034017572761513293\n",
      "Gradient for encoder.encoder.3.weight: 0.007851017639040947\n",
      "Gradient for encoder.encoder.3.bias: 8.58614360166321e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.0022740934509783983\n",
      "Gradient for encoder.encoder.4.bias: 0.001902711926959455\n",
      "Gradient for encoder.mean.weight: 0.034899432212114334\n",
      "Gradient for encoder.mean.bias: 0.001542372046969831\n",
      "Gradient for encoder.log_var.weight: 0.01898159645497799\n",
      "Gradient for encoder.log_var.bias: 0.001029955456033349\n",
      "Gradient for decoder.decoder.0.weight: 0.010132594034075737\n",
      "Gradient for decoder.decoder.0.bias: 9.004693518610551e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005173208774067461\n",
      "Gradient for decoder.decoder.1.bias: 0.0004083837557118386\n",
      "Gradient for decoder.decoder.3.weight: 0.009215522557497025\n",
      "Gradient for decoder.decoder.3.bias: 7.257237172320075e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00033957729465328157\n",
      "Gradient for decoder.decoder.4.bias: 0.00030557348509319127\n",
      "Gradient for decoder.decoder.6.weight: 0.0009587904787622392\n",
      "Gradient for decoder.decoder.6.bias: 4.944693864672445e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.003638471709564328\n",
      "Gradient for encoder.encoder.0.bias: 5.927736600186417e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.0003182336804457009\n",
      "Gradient for encoder.encoder.1.bias: 0.0002848230942618102\n",
      "Gradient for encoder.encoder.3.weight: 0.006974402349442244\n",
      "Gradient for encoder.encoder.3.bias: 7.82172035473927e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.0022828930523246527\n",
      "Gradient for encoder.encoder.4.bias: 0.001640013069845736\n",
      "Gradient for encoder.mean.weight: 0.03466576710343361\n",
      "Gradient for encoder.mean.bias: 0.001219695433974266\n",
      "Gradient for encoder.log_var.weight: 0.01957409642636776\n",
      "Gradient for encoder.log_var.bias: 0.0009057610877789557\n",
      "Gradient for decoder.decoder.0.weight: 0.010827988386154175\n",
      "Gradient for decoder.decoder.0.bias: 8.942176166204518e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005377099150791764\n",
      "Gradient for decoder.decoder.1.bias: 0.0004697628610301763\n",
      "Gradient for decoder.decoder.3.weight: 0.01038395706564188\n",
      "Gradient for decoder.decoder.3.bias: 8.07595934571026e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0004041392239741981\n",
      "Gradient for decoder.decoder.4.bias: 0.0003677601634990424\n",
      "Gradient for decoder.decoder.6.weight: 0.0009255812619812787\n",
      "Gradient for decoder.decoder.6.bias: 4.513896055868827e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training VAE Epoch:  72%|███████▏  | 57/79 [00:00<00:00, 73.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient for encoder.encoder.0.weight: 0.00661638006567955\n",
      "Gradient for encoder.encoder.0.bias: 1.094800378825811e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.00045607596985064447\n",
      "Gradient for encoder.encoder.1.bias: 0.00043205206748098135\n",
      "Gradient for encoder.encoder.3.weight: 0.009693975560367107\n",
      "Gradient for encoder.encoder.3.bias: 9.821412433330678e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.002192462095990777\n",
      "Gradient for encoder.encoder.4.bias: 0.0017068611923605204\n",
      "Gradient for encoder.mean.weight: 0.03187588229775429\n",
      "Gradient for encoder.mean.bias: 0.0013804822228848934\n",
      "Gradient for encoder.log_var.weight: 0.018429333344101906\n",
      "Gradient for encoder.log_var.bias: 0.0008712683338671923\n",
      "Gradient for decoder.decoder.0.weight: 0.008037008345127106\n",
      "Gradient for decoder.decoder.0.bias: 6.437800292857787e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.00038560215034522116\n",
      "Gradient for decoder.decoder.1.bias: 0.00032300304155796766\n",
      "Gradient for decoder.decoder.3.weight: 0.007551878225058317\n",
      "Gradient for decoder.decoder.3.bias: 6.805363217399218e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00039669478428550065\n",
      "Gradient for decoder.decoder.4.bias: 0.0004444563528522849\n",
      "Gradient for decoder.decoder.6.weight: 0.0009525148780085146\n",
      "Gradient for decoder.decoder.6.bias: 5.7815868785837665e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.00419278722256422\n",
      "Gradient for encoder.encoder.0.bias: 6.716798558320525e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.0003473755205050111\n",
      "Gradient for encoder.encoder.1.bias: 0.00028819229919463396\n",
      "Gradient for encoder.encoder.3.weight: 0.007733958773314953\n",
      "Gradient for encoder.encoder.3.bias: 8.379490851195825e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.0021234548185020685\n",
      "Gradient for encoder.encoder.4.bias: 0.001582008320838213\n",
      "Gradient for encoder.mean.weight: 0.030003149062395096\n",
      "Gradient for encoder.mean.bias: 0.001262054080143571\n",
      "Gradient for encoder.log_var.weight: 0.016129231080412865\n",
      "Gradient for encoder.log_var.bias: 0.0007016995223239064\n",
      "Gradient for decoder.decoder.0.weight: 0.010952574200928211\n",
      "Gradient for decoder.decoder.0.bias: 9.925538169142101e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005140318535268307\n",
      "Gradient for decoder.decoder.1.bias: 0.00045313616283237934\n",
      "Gradient for decoder.decoder.3.weight: 0.009891216643154621\n",
      "Gradient for decoder.decoder.3.bias: 8.416373847852654e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0003691976307891309\n",
      "Gradient for decoder.decoder.4.bias: 0.0003630966239143163\n",
      "Gradient for decoder.decoder.6.weight: 0.0009340217220596969\n",
      "Gradient for decoder.decoder.6.bias: 4.989818262401968e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.0038818418979644775\n",
      "Gradient for encoder.encoder.0.bias: 5.4105856080177706e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.000362401973688975\n",
      "Gradient for encoder.encoder.1.bias: 0.0003440594009589404\n",
      "Gradient for encoder.encoder.3.weight: 0.0076321265660226345\n",
      "Gradient for encoder.encoder.3.bias: 7.433208909501943e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.002311500022187829\n",
      "Gradient for encoder.encoder.4.bias: 0.001661500078625977\n",
      "Gradient for encoder.mean.weight: 0.03268444538116455\n",
      "Gradient for encoder.mean.bias: 0.0011114160297438502\n",
      "Gradient for encoder.log_var.weight: 0.01806037873029709\n",
      "Gradient for encoder.log_var.bias: 0.000756948022171855\n",
      "Gradient for decoder.decoder.0.weight: 0.011236123740673065\n",
      "Gradient for decoder.decoder.0.bias: 8.755229874424231e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.000510913785547018\n",
      "Gradient for decoder.decoder.1.bias: 0.00044000797788612545\n",
      "Gradient for decoder.decoder.3.weight: 0.01045555155724287\n",
      "Gradient for decoder.decoder.3.bias: 7.988990025076248e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00040389946661889553\n",
      "Gradient for decoder.decoder.4.bias: 0.00034889057860709727\n",
      "Gradient for decoder.decoder.6.weight: 0.000999155337922275\n",
      "Gradient for decoder.decoder.6.bias: 5.7338085753144696e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.005387272220104933\n",
      "Gradient for encoder.encoder.0.bias: 9.12488487547769e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.000425610487582162\n",
      "Gradient for encoder.encoder.1.bias: 0.00035996254882775247\n",
      "Gradient for encoder.encoder.3.weight: 0.00854184664785862\n",
      "Gradient for encoder.encoder.3.bias: 8.061014356020024e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.002031744224950671\n",
      "Gradient for encoder.encoder.4.bias: 0.0014249072410166264\n",
      "Gradient for encoder.mean.weight: 0.02975897490978241\n",
      "Gradient for encoder.mean.bias: 0.0010093351593241096\n",
      "Gradient for encoder.log_var.weight: 0.01746192015707493\n",
      "Gradient for encoder.log_var.bias: 0.0007537904311902821\n",
      "Gradient for decoder.decoder.0.weight: 0.009045075625181198\n",
      "Gradient for decoder.decoder.0.bias: 8.06807398667786e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0004182498378213495\n",
      "Gradient for decoder.decoder.1.bias: 0.0003642335068434477\n",
      "Gradient for decoder.decoder.3.weight: 0.008139505982398987\n",
      "Gradient for decoder.decoder.3.bias: 7.510288918544106e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00048383328248746693\n",
      "Gradient for decoder.decoder.4.bias: 0.0005388781428337097\n",
      "Gradient for decoder.decoder.6.weight: 0.0010480924975126982\n",
      "Gradient for decoder.decoder.6.bias: 7.470745913451537e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.005900005344301462\n",
      "Gradient for encoder.encoder.0.bias: 8.96840067488025e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.0003920582530554384\n",
      "Gradient for encoder.encoder.1.bias: 0.0003640458744484931\n",
      "Gradient for encoder.encoder.3.weight: 0.008060920052230358\n",
      "Gradient for encoder.encoder.3.bias: 8.030068276987379e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.0021489772479981184\n",
      "Gradient for encoder.encoder.4.bias: 0.001664592418819666\n",
      "Gradient for encoder.mean.weight: 0.029775818809866905\n",
      "Gradient for encoder.mean.bias: 0.0013296991819515824\n",
      "Gradient for encoder.log_var.weight: 0.01523324940353632\n",
      "Gradient for encoder.log_var.bias: 0.0008072116761468351\n",
      "Gradient for decoder.decoder.0.weight: 0.007988307625055313\n",
      "Gradient for decoder.decoder.0.bias: 6.930758744694288e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.00036466578603722155\n",
      "Gradient for decoder.decoder.1.bias: 0.0003178782935719937\n",
      "Gradient for decoder.decoder.3.weight: 0.0074318512342870235\n",
      "Gradient for decoder.decoder.3.bias: 6.48765485777858e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00029567850288003683\n",
      "Gradient for decoder.decoder.4.bias: 0.0002661421021912247\n",
      "Gradient for decoder.decoder.6.weight: 0.0009492847602814436\n",
      "Gradient for decoder.decoder.6.bias: 5.427831638371572e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.005104027222841978\n",
      "Gradient for encoder.encoder.0.bias: 8.396414639955108e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.0003667523851618171\n",
      "Gradient for encoder.encoder.1.bias: 0.0003380726557224989\n",
      "Gradient for encoder.encoder.3.weight: 0.008095976896584034\n",
      "Gradient for encoder.encoder.3.bias: 8.237617532547148e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.002112800721079111\n",
      "Gradient for encoder.encoder.4.bias: 0.0014264562632888556\n",
      "Gradient for encoder.mean.weight: 0.028585834428668022\n",
      "Gradient for encoder.mean.bias: 0.0011334021110087633\n",
      "Gradient for encoder.log_var.weight: 0.01722308248281479\n",
      "Gradient for encoder.log_var.bias: 0.0008049954776652157\n",
      "Gradient for decoder.decoder.0.weight: 0.009351872839033604\n",
      "Gradient for decoder.decoder.0.bias: 9.049574284381023e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.00045692941057495773\n",
      "Gradient for decoder.decoder.1.bias: 0.00040923949563875794\n",
      "Gradient for decoder.decoder.3.weight: 0.008899638429284096\n",
      "Gradient for decoder.decoder.3.bias: 8.685212965486855e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00034351469366811216\n",
      "Gradient for decoder.decoder.4.bias: 0.00032858847407624125\n",
      "Gradient for decoder.decoder.6.weight: 0.0008691624971106648\n",
      "Gradient for decoder.decoder.6.bias: 3.8664649764541537e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.004369668662548065\n",
      "Gradient for encoder.encoder.0.bias: 6.8501072869597834e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.0004124099505133927\n",
      "Gradient for encoder.encoder.1.bias: 0.00031194533221423626\n",
      "Gradient for encoder.encoder.3.weight: 0.008877597749233246\n",
      "Gradient for encoder.encoder.3.bias: 8.093518910623487e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.0020141967106610537\n",
      "Gradient for encoder.encoder.4.bias: 0.00146559439599514\n",
      "Gradient for encoder.mean.weight: 0.026759061962366104\n",
      "Gradient for encoder.mean.bias: 0.0010750701185315847\n",
      "Gradient for encoder.log_var.weight: 0.016040228307247162\n",
      "Gradient for encoder.log_var.bias: 0.0008419298101216555\n",
      "Gradient for decoder.decoder.0.weight: 0.008447798900306225\n",
      "Gradient for decoder.decoder.0.bias: 7.453244965649475e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0004353402182459831\n",
      "Gradient for decoder.decoder.1.bias: 0.000376768468413502\n",
      "Gradient for decoder.decoder.3.weight: 0.008178405463695526\n",
      "Gradient for decoder.decoder.3.bias: 7.837889365314155e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0003931298269890249\n",
      "Gradient for decoder.decoder.4.bias: 0.0004155896313022822\n",
      "Gradient for decoder.decoder.6.weight: 0.0009191014687530696\n",
      "Gradient for decoder.decoder.6.bias: 4.888014154857956e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.004073732066899538\n",
      "Gradient for encoder.encoder.0.bias: 6.131963426608822e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.00028135249158367515\n",
      "Gradient for encoder.encoder.1.bias: 0.0003117825835943222\n",
      "Gradient for encoder.encoder.3.weight: 0.006152357440441847\n",
      "Gradient for encoder.encoder.3.bias: 7.313201433323258e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.002082831459119916\n",
      "Gradient for encoder.encoder.4.bias: 0.0013707421021535993\n",
      "Gradient for encoder.mean.weight: 0.02793053537607193\n",
      "Gradient for encoder.mean.bias: 0.0010185173014178872\n",
      "Gradient for encoder.log_var.weight: 0.01606798730790615\n",
      "Gradient for encoder.log_var.bias: 0.0007210215553641319\n",
      "Gradient for decoder.decoder.0.weight: 0.010501581244170666\n",
      "Gradient for decoder.decoder.0.bias: 9.18528447746425e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0004651124472729862\n",
      "Gradient for decoder.decoder.1.bias: 0.00043565203668549657\n",
      "Gradient for decoder.decoder.3.weight: 0.009633062407374382\n",
      "Gradient for decoder.decoder.3.bias: 7.56527826495379e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0003161430940963328\n",
      "Gradient for decoder.decoder.4.bias: 0.0002906341105699539\n",
      "Gradient for decoder.decoder.6.weight: 0.0009528581285849214\n",
      "Gradient for decoder.decoder.6.bias: 5.42692796443589e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.0040891957469284534\n",
      "Gradient for encoder.encoder.0.bias: 5.992226246448462e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.00040994977462105453\n",
      "Gradient for encoder.encoder.1.bias: 0.0004658436810132116\n",
      "Gradient for encoder.encoder.3.weight: 0.008386855944991112\n",
      "Gradient for encoder.encoder.3.bias: 7.031088211650882e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.002473501954227686\n",
      "Gradient for encoder.encoder.4.bias: 0.0015259530628100038\n",
      "Gradient for encoder.mean.weight: 0.03452478349208832\n",
      "Gradient for encoder.mean.bias: 0.0011724337236955762\n",
      "Gradient for encoder.log_var.weight: 0.019998084753751755\n",
      "Gradient for encoder.log_var.bias: 0.0008456027717329562\n",
      "Gradient for decoder.decoder.0.weight: 0.010130418464541435\n",
      "Gradient for decoder.decoder.0.bias: 8.197294232292762e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0004856565792579204\n",
      "Gradient for decoder.decoder.1.bias: 0.0004393407725729048\n",
      "Gradient for decoder.decoder.3.weight: 0.009339303709566593\n",
      "Gradient for decoder.decoder.3.bias: 7.57902490766682e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0003608230617828667\n",
      "Gradient for decoder.decoder.4.bias: 0.00032440066570416093\n",
      "Gradient for decoder.decoder.6.weight: 0.0009789420291781425\n",
      "Gradient for decoder.decoder.6.bias: 5.423760740086436e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.003272322006523609\n",
      "Gradient for encoder.encoder.0.bias: 6.156158915970877e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.0003310880856588483\n",
      "Gradient for encoder.encoder.1.bias: 0.00030347093706950545\n",
      "Gradient for encoder.encoder.3.weight: 0.007279746234416962\n",
      "Gradient for encoder.encoder.3.bias: 7.054522244143158e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.0021887291222810745\n",
      "Gradient for encoder.encoder.4.bias: 0.0015171930426731706\n",
      "Gradient for encoder.mean.weight: 0.03084283508360386\n",
      "Gradient for encoder.mean.bias: 0.0011875249911099672\n",
      "Gradient for encoder.log_var.weight: 0.018248936161398888\n",
      "Gradient for encoder.log_var.bias: 0.0007854039431549609\n",
      "Gradient for decoder.decoder.0.weight: 0.009719125926494598\n",
      "Gradient for decoder.decoder.0.bias: 8.881476110111919e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0004987849970348179\n",
      "Gradient for decoder.decoder.1.bias: 0.0004209085600450635\n",
      "Gradient for decoder.decoder.3.weight: 0.0091819753870368\n",
      "Gradient for decoder.decoder.3.bias: 8.54991563659091e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00037161633372306824\n",
      "Gradient for decoder.decoder.4.bias: 0.0003645979450084269\n",
      "Gradient for decoder.decoder.6.weight: 0.0008744145161472261\n",
      "Gradient for decoder.decoder.6.bias: 3.9465179725084454e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.004012048244476318\n",
      "Gradient for encoder.encoder.0.bias: 6.201877986861115e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.00032466292032040656\n",
      "Gradient for encoder.encoder.1.bias: 0.00039268264663405716\n",
      "Gradient for encoder.encoder.3.weight: 0.007170206867158413\n",
      "Gradient for encoder.encoder.3.bias: 7.387131878422437e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.0024817558005452156\n",
      "Gradient for encoder.encoder.4.bias: 0.0013953752350062132\n",
      "Gradient for encoder.mean.weight: 0.032715875655412674\n",
      "Gradient for encoder.mean.bias: 0.0011221913155168295\n",
      "Gradient for encoder.log_var.weight: 0.020865807309746742\n",
      "Gradient for encoder.log_var.bias: 0.0007199468673206866\n",
      "Gradient for decoder.decoder.0.weight: 0.010336601175367832\n",
      "Gradient for decoder.decoder.0.bias: 7.777849891921207e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0004485339450184256\n",
      "Gradient for decoder.decoder.1.bias: 0.0004081422812305391\n",
      "Gradient for decoder.decoder.3.weight: 0.00915464200079441\n",
      "Gradient for decoder.decoder.3.bias: 8.129888429131427e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0005210511735640466\n",
      "Gradient for decoder.decoder.4.bias: 0.0005844838451594114\n",
      "Gradient for decoder.decoder.6.weight: 0.001186769688501954\n",
      "Gradient for decoder.decoder.6.bias: 9.859631245490164e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.005835816264152527\n",
      "Gradient for encoder.encoder.0.bias: 9.286584522205654e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.0005611556116491556\n",
      "Gradient for encoder.encoder.1.bias: 0.0005245515494607389\n",
      "Gradient for encoder.encoder.3.weight: 0.011932081542909145\n",
      "Gradient for encoder.encoder.3.bias: 1.1924795872975125e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.003303857985883951\n",
      "Gradient for encoder.encoder.4.bias: 0.00277132960036397\n",
      "Gradient for encoder.mean.weight: 0.04517820104956627\n",
      "Gradient for encoder.mean.bias: 0.002230699174106121\n",
      "Gradient for encoder.log_var.weight: 0.024486562237143517\n",
      "Gradient for encoder.log_var.bias: 0.0012061346787959337\n",
      "Gradient for decoder.decoder.0.weight: 0.00933209341019392\n",
      "Gradient for decoder.decoder.0.bias: 8.412918278688508e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.00044463659287430346\n",
      "Gradient for decoder.decoder.1.bias: 0.00038014008896425366\n",
      "Gradient for decoder.decoder.3.weight: 0.008752395398914814\n",
      "Gradient for decoder.decoder.3.bias: 8.25072787868919e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0003214177559129894\n",
      "Gradient for decoder.decoder.4.bias: 0.00031132542062550783\n",
      "Gradient for decoder.decoder.6.weight: 0.001089440076611936\n",
      "Gradient for decoder.decoder.6.bias: 8.034567144932225e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.0050583709962666035\n",
      "Gradient for encoder.encoder.0.bias: 7.61252259146028e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.0003605314705055207\n",
      "Gradient for encoder.encoder.1.bias: 0.00027642148779705167\n",
      "Gradient for encoder.encoder.3.weight: 0.00797460786998272\n",
      "Gradient for encoder.encoder.3.bias: 8.366957127137198e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.0022154066246002913\n",
      "Gradient for encoder.encoder.4.bias: 0.0016756647964939475\n",
      "Gradient for encoder.mean.weight: 0.031150201335549355\n",
      "Gradient for encoder.mean.bias: 0.0013262827415019274\n",
      "Gradient for encoder.log_var.weight: 0.018780309706926346\n",
      "Gradient for encoder.log_var.bias: 0.0009039791766554117\n",
      "Gradient for decoder.decoder.0.weight: 0.01053651049733162\n",
      "Gradient for decoder.decoder.0.bias: 8.567523079872075e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.000529176089912653\n",
      "Gradient for decoder.decoder.1.bias: 0.0004132936883252114\n",
      "Gradient for decoder.decoder.3.weight: 0.009524532593786716\n",
      "Gradient for decoder.decoder.3.bias: 8.663533779262877e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0004332213138695806\n",
      "Gradient for decoder.decoder.4.bias: 0.00043909321539103985\n",
      "Gradient for decoder.decoder.6.weight: 0.0009633766603656113\n",
      "Gradient for decoder.decoder.6.bias: 5.5971737310756e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.00452364981174469\n",
      "Gradient for encoder.encoder.0.bias: 7.743951313532449e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.0003741453983820975\n",
      "Gradient for encoder.encoder.1.bias: 0.0002985091123264283\n",
      "Gradient for encoder.encoder.3.weight: 0.008395710960030556\n",
      "Gradient for encoder.encoder.3.bias: 7.716028510573736e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.0020249485969543457\n",
      "Gradient for encoder.encoder.4.bias: 0.0013649945612996817\n",
      "Gradient for encoder.mean.weight: 0.028533928096294403\n",
      "Gradient for encoder.mean.bias: 0.0010742406593635678\n",
      "Gradient for encoder.log_var.weight: 0.015798525884747505\n",
      "Gradient for encoder.log_var.bias: 0.0006482609896920621\n",
      "Gradient for decoder.decoder.0.weight: 0.009377358481287956\n",
      "Gradient for decoder.decoder.0.bias: 7.742259611198676e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0004418825847096741\n",
      "Gradient for decoder.decoder.1.bias: 0.0003622905060183257\n",
      "Gradient for decoder.decoder.3.weight: 0.008460584096610546\n",
      "Gradient for decoder.decoder.3.bias: 7.086944919798555e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0003343709104228765\n",
      "Gradient for decoder.decoder.4.bias: 0.00035272131208330393\n",
      "Gradient for decoder.decoder.6.weight: 0.0009225241956301033\n",
      "Gradient for decoder.decoder.6.bias: 4.690893183578737e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.005214034579694271\n",
      "Gradient for encoder.encoder.0.bias: 8.561058112421804e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.0004658577381633222\n",
      "Gradient for encoder.encoder.1.bias: 0.0003517451405059546\n",
      "Gradient for encoder.encoder.3.weight: 0.009989532642066479\n",
      "Gradient for encoder.encoder.3.bias: 1.0143172413101809e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.00241499743424356\n",
      "Gradient for encoder.encoder.4.bias: 0.0019066904205828905\n",
      "Gradient for encoder.mean.weight: 0.03391891345381737\n",
      "Gradient for encoder.mean.bias: 0.0014228923246264458\n",
      "Gradient for encoder.log_var.weight: 0.0170604195445776\n",
      "Gradient for encoder.log_var.bias: 0.0007647328893654048\n",
      "Gradient for decoder.decoder.0.weight: 0.00829323474317789\n",
      "Gradient for decoder.decoder.0.bias: 6.484297127018479e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.00039623392513021827\n",
      "Gradient for decoder.decoder.1.bias: 0.0003417429979890585\n",
      "Gradient for decoder.decoder.3.weight: 0.007706294767558575\n",
      "Gradient for decoder.decoder.3.bias: 6.610786917882194e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00033313827589154243\n",
      "Gradient for decoder.decoder.4.bias: 0.0003351250779815018\n",
      "Gradient for decoder.decoder.6.weight: 0.0009480640292167664\n",
      "Gradient for decoder.decoder.6.bias: 5.598297866526991e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.003568842774257064\n",
      "Gradient for encoder.encoder.0.bias: 6.131823347688137e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.0003904618206433952\n",
      "Gradient for encoder.encoder.1.bias: 0.0003417565894778818\n",
      "Gradient for encoder.encoder.3.weight: 0.008804925717413425\n",
      "Gradient for encoder.encoder.3.bias: 8.062953776866166e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.0025217372458428144\n",
      "Gradient for encoder.encoder.4.bias: 0.0017736543668434024\n",
      "Gradient for encoder.mean.weight: 0.033817753195762634\n",
      "Gradient for encoder.mean.bias: 0.0013852727133780718\n",
      "Gradient for encoder.log_var.weight: 0.018770162016153336\n",
      "Gradient for encoder.log_var.bias: 0.0007539985235780478\n",
      "Gradient for decoder.decoder.0.weight: 0.011832021176815033\n",
      "Gradient for decoder.decoder.0.bias: 9.947780099661685e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005860460223630071\n",
      "Gradient for decoder.decoder.1.bias: 0.0004980689263902605\n",
      "Gradient for decoder.decoder.3.weight: 0.011120058596134186\n",
      "Gradient for decoder.decoder.3.bias: 8.870903317470535e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.000419208372477442\n",
      "Gradient for decoder.decoder.4.bias: 0.0003683034738060087\n",
      "Gradient for decoder.decoder.6.weight: 0.0009846162283793092\n",
      "Gradient for decoder.decoder.6.bias: 4.879731932305731e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training VAE Epoch:  92%|█████████▏| 73/79 [00:01<00:00, 76.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient for encoder.encoder.0.weight: 0.004838171880692244\n",
      "Gradient for encoder.encoder.0.bias: 5.963646677181744e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.0002826304698828608\n",
      "Gradient for encoder.encoder.1.bias: 0.0002216404100181535\n",
      "Gradient for encoder.encoder.3.weight: 0.006390820723026991\n",
      "Gradient for encoder.encoder.3.bias: 8.044823834874038e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.002161511452868581\n",
      "Gradient for encoder.encoder.4.bias: 0.0014903837582096457\n",
      "Gradient for encoder.mean.weight: 0.030156437307596207\n",
      "Gradient for encoder.mean.bias: 0.0011245550122112036\n",
      "Gradient for encoder.log_var.weight: 0.016409626230597496\n",
      "Gradient for encoder.log_var.bias: 0.0007300053257495165\n",
      "Gradient for decoder.decoder.0.weight: 0.009395931847393513\n",
      "Gradient for decoder.decoder.0.bias: 8.194423611884716e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0004639341786969453\n",
      "Gradient for decoder.decoder.1.bias: 0.0003912651736754924\n",
      "Gradient for decoder.decoder.3.weight: 0.00897378008812666\n",
      "Gradient for decoder.decoder.3.bias: 7.813329844230665e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0003682609531097114\n",
      "Gradient for decoder.decoder.4.bias: 0.0003863441525027156\n",
      "Gradient for decoder.decoder.6.weight: 0.001172390766441822\n",
      "Gradient for decoder.decoder.6.bias: 8.786852413322777e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.007732250727713108\n",
      "Gradient for encoder.encoder.0.bias: 1.0713684280017066e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.000365390966180712\n",
      "Gradient for encoder.encoder.1.bias: 0.0003362370189279318\n",
      "Gradient for encoder.encoder.3.weight: 0.007983120158314705\n",
      "Gradient for encoder.encoder.3.bias: 8.571853643557503e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.0020003151148557663\n",
      "Gradient for encoder.encoder.4.bias: 0.0016417751321569085\n",
      "Gradient for encoder.mean.weight: 0.0278654582798481\n",
      "Gradient for encoder.mean.bias: 0.001228720648214221\n",
      "Gradient for encoder.log_var.weight: 0.01581207662820816\n",
      "Gradient for encoder.log_var.bias: 0.0007705509196966887\n",
      "Gradient for decoder.decoder.0.weight: 0.007948004640638828\n",
      "Gradient for decoder.decoder.0.bias: 7.129660750671007e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0003711510798893869\n",
      "Gradient for decoder.decoder.1.bias: 0.00031689860043115914\n",
      "Gradient for decoder.decoder.3.weight: 0.007425226271152496\n",
      "Gradient for decoder.decoder.3.bias: 7.828740433701853e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0004465819802135229\n",
      "Gradient for decoder.decoder.4.bias: 0.0005201600142754614\n",
      "Gradient for decoder.decoder.6.weight: 0.0011971663916483521\n",
      "Gradient for decoder.decoder.6.bias: 9.877041884465143e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.0043081375770270824\n",
      "Gradient for encoder.encoder.0.bias: 6.1221245087339504e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.00035211542854085565\n",
      "Gradient for encoder.encoder.1.bias: 0.000297363760182634\n",
      "Gradient for encoder.encoder.3.weight: 0.007511450443416834\n",
      "Gradient for encoder.encoder.3.bias: 7.368678583974386e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.0018062815070152283\n",
      "Gradient for encoder.encoder.4.bias: 0.001311279134824872\n",
      "Gradient for encoder.mean.weight: 0.026776760816574097\n",
      "Gradient for encoder.mean.bias: 0.0009847229812294245\n",
      "Gradient for encoder.log_var.weight: 0.016988134011626244\n",
      "Gradient for encoder.log_var.bias: 0.0008470609900541604\n",
      "Gradient for decoder.decoder.0.weight: 0.010385658591985703\n",
      "Gradient for decoder.decoder.0.bias: 9.443209408876996e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005368874408304691\n",
      "Gradient for decoder.decoder.1.bias: 0.0004532942548394203\n",
      "Gradient for decoder.decoder.3.weight: 0.009672863408923149\n",
      "Gradient for decoder.decoder.3.bias: 8.482416852251262e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0005322720389813185\n",
      "Gradient for decoder.decoder.4.bias: 0.0005493842763826251\n",
      "Gradient for decoder.decoder.6.weight: 0.000961123441811651\n",
      "Gradient for decoder.decoder.6.bias: 4.859169712290168e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.006668799556791782\n",
      "Gradient for encoder.encoder.0.bias: 1.0844716617774974e-11\n",
      "Gradient for encoder.encoder.1.weight: 0.00034731082268990576\n",
      "Gradient for encoder.encoder.1.bias: 0.0003001438162755221\n",
      "Gradient for encoder.encoder.3.weight: 0.007835733704268932\n",
      "Gradient for encoder.encoder.3.bias: 9.818352381119055e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.0022450010292232037\n",
      "Gradient for encoder.encoder.4.bias: 0.001854875823482871\n",
      "Gradient for encoder.mean.weight: 0.031046481803059578\n",
      "Gradient for encoder.mean.bias: 0.001515513053163886\n",
      "Gradient for encoder.log_var.weight: 0.016511820256710052\n",
      "Gradient for encoder.log_var.bias: 0.0008320191409438848\n",
      "Gradient for decoder.decoder.0.weight: 0.007704596035182476\n",
      "Gradient for decoder.decoder.0.bias: 7.026812465227295e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0003829626948572695\n",
      "Gradient for decoder.decoder.1.bias: 0.00032134761568158865\n",
      "Gradient for decoder.decoder.3.weight: 0.007064716890454292\n",
      "Gradient for decoder.decoder.3.bias: 7.554344649829403e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00040496294968761504\n",
      "Gradient for decoder.decoder.4.bias: 0.0004998203949071467\n",
      "Gradient for decoder.decoder.6.weight: 0.0009553979616612196\n",
      "Gradient for decoder.decoder.6.bias: 6.396172830136493e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.003178444691002369\n",
      "Gradient for encoder.encoder.0.bias: 5.003488508931175e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.00025979458587244153\n",
      "Gradient for encoder.encoder.1.bias: 0.00022554838506039232\n",
      "Gradient for encoder.encoder.3.weight: 0.005869302432984114\n",
      "Gradient for encoder.encoder.3.bias: 7.214520647558231e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.0019510035635903478\n",
      "Gradient for encoder.encoder.4.bias: 0.0013929461129009724\n",
      "Gradient for encoder.mean.weight: 0.026449626311659813\n",
      "Gradient for encoder.mean.bias: 0.001042148913256824\n",
      "Gradient for encoder.log_var.weight: 0.016414649784564972\n",
      "Gradient for encoder.log_var.bias: 0.0006422301521524787\n",
      "Gradient for decoder.decoder.0.weight: 0.01117852982133627\n",
      "Gradient for decoder.decoder.0.bias: 8.652016603161172e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005350610008463264\n",
      "Gradient for decoder.decoder.1.bias: 0.00048171787057071924\n",
      "Gradient for decoder.decoder.3.weight: 0.010267413221299648\n",
      "Gradient for decoder.decoder.3.bias: 7.626141385053131e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0004147937288507819\n",
      "Gradient for decoder.decoder.4.bias: 0.0004411042027641088\n",
      "Gradient for decoder.decoder.6.weight: 0.0009424344752915204\n",
      "Gradient for decoder.decoder.6.bias: 5.394852996687405e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.004615792538970709\n",
      "Gradient for encoder.encoder.0.bias: 7.325857802331637e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.0003270950692240149\n",
      "Gradient for encoder.encoder.1.bias: 0.0003561470948625356\n",
      "Gradient for encoder.encoder.3.weight: 0.006971754599362612\n",
      "Gradient for encoder.encoder.3.bias: 8.262311668172373e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.002054394455626607\n",
      "Gradient for encoder.encoder.4.bias: 0.0015168540412560105\n",
      "Gradient for encoder.mean.weight: 0.0293072871863842\n",
      "Gradient for encoder.mean.bias: 0.0011818406637758017\n",
      "Gradient for encoder.log_var.weight: 0.018007470294833183\n",
      "Gradient for encoder.log_var.bias: 0.00074153853347525\n",
      "Gradient for decoder.decoder.0.weight: 0.009167110547423363\n",
      "Gradient for decoder.decoder.0.bias: 7.549878083823458e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0004383052291814238\n",
      "Gradient for decoder.decoder.1.bias: 0.0003903454926330596\n",
      "Gradient for decoder.decoder.3.weight: 0.008602308109402657\n",
      "Gradient for decoder.decoder.3.bias: 7.319825995333318e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0003651078441180289\n",
      "Gradient for decoder.decoder.4.bias: 0.00035510852467268705\n",
      "Gradient for decoder.decoder.6.weight: 0.0009556783479638398\n",
      "Gradient for decoder.decoder.6.bias: 5.799224163638428e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.004150808788836002\n",
      "Gradient for encoder.encoder.0.bias: 5.279595337304155e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.00025646868743933737\n",
      "Gradient for encoder.encoder.1.bias: 0.00024936720728874207\n",
      "Gradient for encoder.encoder.3.weight: 0.005795046221464872\n",
      "Gradient for encoder.encoder.3.bias: 7.645505062381375e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.0017699870513752103\n",
      "Gradient for encoder.encoder.4.bias: 0.0015607282985001802\n",
      "Gradient for encoder.mean.weight: 0.025455273687839508\n",
      "Gradient for encoder.mean.bias: 0.000979745527729392\n",
      "Gradient for encoder.log_var.weight: 0.01622701995074749\n",
      "Gradient for encoder.log_var.bias: 0.0007768034702166915\n",
      "Gradient for decoder.decoder.0.weight: 0.011839253827929497\n",
      "Gradient for decoder.decoder.0.bias: 9.928044497620192e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005577494739554822\n",
      "Gradient for decoder.decoder.1.bias: 0.0004664538719225675\n",
      "Gradient for decoder.decoder.3.weight: 0.010807627812027931\n",
      "Gradient for decoder.decoder.3.bias: 1.0931066468655715e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0007727195043116808\n",
      "Gradient for decoder.decoder.4.bias: 0.0008563782321289182\n",
      "Gradient for decoder.decoder.6.weight: 0.001133731217123568\n",
      "Gradient for decoder.decoder.6.bias: 7.705161988269538e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.0050946734845638275\n",
      "Gradient for encoder.encoder.0.bias: 6.54569931243798e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.0003553878341335803\n",
      "Gradient for encoder.encoder.1.bias: 0.0004169252933934331\n",
      "Gradient for encoder.encoder.3.weight: 0.008037401363253593\n",
      "Gradient for encoder.encoder.3.bias: 8.914498306200613e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.002111993031576276\n",
      "Gradient for encoder.encoder.4.bias: 0.002033476484939456\n",
      "Gradient for encoder.mean.weight: 0.02911691926419735\n",
      "Gradient for encoder.mean.bias: 0.0015846012393012643\n",
      "Gradient for encoder.log_var.weight: 0.019437525421380997\n",
      "Gradient for encoder.log_var.bias: 0.001127753872424364\n",
      "Gradient for decoder.decoder.0.weight: 0.010943581350147724\n",
      "Gradient for decoder.decoder.0.bias: 9.483840102131325e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0005459489766508341\n",
      "Gradient for decoder.decoder.1.bias: 0.0004564114206004888\n",
      "Gradient for decoder.decoder.3.weight: 0.010327397845685482\n",
      "Gradient for decoder.decoder.3.bias: 7.993439937736824e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0004278720880392939\n",
      "Gradient for decoder.decoder.4.bias: 0.0003844037128146738\n",
      "Gradient for decoder.decoder.6.weight: 0.0009211772121489048\n",
      "Gradient for decoder.decoder.6.bias: 4.664577136281878e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.0039437515661120415\n",
      "Gradient for encoder.encoder.0.bias: 5.7405928968745634e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.00027835549553856254\n",
      "Gradient for encoder.encoder.1.bias: 0.0002741120115388185\n",
      "Gradient for encoder.encoder.3.weight: 0.006396852433681488\n",
      "Gradient for encoder.encoder.3.bias: 8.040224042105137e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.0019601730164140463\n",
      "Gradient for encoder.encoder.4.bias: 0.0014384433161467314\n",
      "Gradient for encoder.mean.weight: 0.026728615164756775\n",
      "Gradient for encoder.mean.bias: 0.0010429532267153263\n",
      "Gradient for encoder.log_var.weight: 0.01757696084678173\n",
      "Gradient for encoder.log_var.bias: 0.0008928313618525863\n",
      "Gradient for decoder.decoder.0.weight: 0.011707765981554985\n",
      "Gradient for decoder.decoder.0.bias: 1.0630983593440391e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.0005651869578287005\n",
      "Gradient for decoder.decoder.1.bias: 0.0005049617611803114\n",
      "Gradient for decoder.decoder.3.weight: 0.010636246763169765\n",
      "Gradient for decoder.decoder.3.bias: 1.0519712878576115e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.000693479785695672\n",
      "Gradient for decoder.decoder.4.bias: 0.000788566074334085\n",
      "Gradient for decoder.decoder.6.weight: 0.0011971235508099198\n",
      "Gradient for decoder.decoder.6.bias: 8.962416177382693e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.004872661083936691\n",
      "Gradient for encoder.encoder.0.bias: 6.83718619914897e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.00027468588086776435\n",
      "Gradient for encoder.encoder.1.bias: 0.0002880381653085351\n",
      "Gradient for encoder.encoder.3.weight: 0.006222311872988939\n",
      "Gradient for encoder.encoder.3.bias: 7.899134818467601e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.002145801205188036\n",
      "Gradient for encoder.encoder.4.bias: 0.0017527448944747448\n",
      "Gradient for encoder.mean.weight: 0.03213600441813469\n",
      "Gradient for encoder.mean.bias: 0.001344870193861425\n",
      "Gradient for encoder.log_var.weight: 0.01905779354274273\n",
      "Gradient for encoder.log_var.bias: 0.0010523534147068858\n",
      "Gradient for decoder.decoder.0.weight: 0.009087719023227692\n",
      "Gradient for decoder.decoder.0.bias: 8.166846365842417e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0004325438931118697\n",
      "Gradient for decoder.decoder.1.bias: 0.00039038973045535386\n",
      "Gradient for decoder.decoder.3.weight: 0.008428257890045643\n",
      "Gradient for decoder.decoder.3.bias: 7.834402571127441e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00045316442265175283\n",
      "Gradient for decoder.decoder.4.bias: 0.00048559418064542115\n",
      "Gradient for decoder.decoder.6.weight: 0.001006036764010787\n",
      "Gradient for decoder.decoder.6.bias: 6.412433867808431e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.0050291395746171474\n",
      "Gradient for encoder.encoder.0.bias: 7.695187369261003e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.0003209821879863739\n",
      "Gradient for encoder.encoder.1.bias: 0.0003342005657032132\n",
      "Gradient for encoder.encoder.3.weight: 0.007419274188578129\n",
      "Gradient for encoder.encoder.3.bias: 7.271455659818571e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.0018860390409827232\n",
      "Gradient for encoder.encoder.4.bias: 0.0014118682593107224\n",
      "Gradient for encoder.mean.weight: 0.026660533621907234\n",
      "Gradient for encoder.mean.bias: 0.0009545093635097146\n",
      "Gradient for encoder.log_var.weight: 0.015364088118076324\n",
      "Gradient for encoder.log_var.bias: 0.0007191768963821232\n",
      "Gradient for decoder.decoder.0.weight: 0.009608003310859203\n",
      "Gradient for decoder.decoder.0.bias: 7.821728681411955e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0004415216972120106\n",
      "Gradient for decoder.decoder.1.bias: 0.00041090388549491763\n",
      "Gradient for decoder.decoder.3.weight: 0.008921661414206028\n",
      "Gradient for decoder.decoder.3.bias: 7.520966488483438e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.00033803435508161783\n",
      "Gradient for decoder.decoder.4.bias: 0.000317996134981513\n",
      "Gradient for decoder.decoder.6.weight: 0.0011298740282654762\n",
      "Gradient for decoder.decoder.6.bias: 8.828733552945778e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.00514935702085495\n",
      "Gradient for encoder.encoder.0.bias: 7.766879153714434e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.00035833343281410635\n",
      "Gradient for encoder.encoder.1.bias: 0.00037206531851552427\n",
      "Gradient for encoder.encoder.3.weight: 0.00781865045428276\n",
      "Gradient for encoder.encoder.3.bias: 7.526300416227372e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.002183555392548442\n",
      "Gradient for encoder.encoder.4.bias: 0.0014208280481398106\n",
      "Gradient for encoder.mean.weight: 0.031205955892801285\n",
      "Gradient for encoder.mean.bias: 0.001042751595377922\n",
      "Gradient for encoder.log_var.weight: 0.01611470989882946\n",
      "Gradient for encoder.log_var.bias: 0.0007648838218301535\n",
      "Gradient for decoder.decoder.0.weight: 0.009436340071260929\n",
      "Gradient for decoder.decoder.0.bias: 8.270574503033146e-11\n",
      "Gradient for decoder.decoder.1.weight: 0.0004909494309686124\n",
      "Gradient for decoder.decoder.1.bias: 0.0003989094402641058\n",
      "Gradient for decoder.decoder.3.weight: 0.008907780051231384\n",
      "Gradient for decoder.decoder.3.bias: 7.217800662706608e-11\n",
      "Gradient for decoder.decoder.4.weight: 0.0004284172027837485\n",
      "Gradient for decoder.decoder.4.bias: 0.0004723694873973727\n",
      "Gradient for decoder.decoder.6.weight: 0.0010024092625826597\n",
      "Gradient for decoder.decoder.6.bias: 6.700146332150325e-05\n",
      "Gradient for encoder.encoder.0.weight: 0.003906345460563898\n",
      "Gradient for encoder.encoder.0.bias: 6.400195911443474e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.0003544159699231386\n",
      "Gradient for encoder.encoder.1.bias: 0.0003145109803881496\n",
      "Gradient for encoder.encoder.3.weight: 0.0075846267864108086\n",
      "Gradient for encoder.encoder.3.bias: 7.723774397838667e-11\n",
      "Gradient for encoder.encoder.4.weight: 0.0018144989153370261\n",
      "Gradient for encoder.encoder.4.bias: 0.0013737627305090427\n",
      "Gradient for encoder.mean.weight: 0.02619735524058342\n",
      "Gradient for encoder.mean.bias: 0.0010776472045108676\n",
      "Gradient for encoder.log_var.weight: 0.014840386807918549\n",
      "Gradient for encoder.log_var.bias: 0.0007460262277163565\n",
      "Gradient for decoder.decoder.0.weight: 0.011020674370229244\n",
      "Gradient for decoder.decoder.0.bias: 1.030680749081192e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.000511419668328017\n",
      "Gradient for decoder.decoder.1.bias: 0.00044890970457345247\n",
      "Gradient for decoder.decoder.3.weight: 0.009851646609604359\n",
      "Gradient for decoder.decoder.3.bias: 1.0973801034541708e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.0006537265726365149\n",
      "Gradient for decoder.decoder.4.bias: 0.0007580579840578139\n",
      "Gradient for decoder.decoder.6.weight: 0.0013042476493865252\n",
      "Gradient for decoder.decoder.6.bias: 0.0001096297855838202\n",
      "Gradient for encoder.encoder.0.weight: 0.006073598749935627\n",
      "Gradient for encoder.encoder.0.bias: 7.410053473599909e-12\n",
      "Gradient for encoder.encoder.1.weight: 0.0007651319028809667\n",
      "Gradient for encoder.encoder.1.bias: 0.000666958512738347\n",
      "Gradient for encoder.encoder.3.weight: 0.017240459099411964\n",
      "Gradient for encoder.encoder.3.bias: 1.781664399347349e-10\n",
      "Gradient for encoder.encoder.4.weight: 0.004078301135450602\n",
      "Gradient for encoder.encoder.4.bias: 0.0033552548848092556\n",
      "Gradient for encoder.mean.weight: 0.06039515882730484\n",
      "Gradient for encoder.mean.bias: 0.0016404410125687718\n",
      "Gradient for encoder.log_var.weight: 0.032710835337638855\n",
      "Gradient for encoder.log_var.bias: 0.0017075198702514172\n",
      "Gradient for decoder.decoder.0.weight: 0.05098651349544525\n",
      "Gradient for decoder.decoder.0.bias: 2.954417543943322e-10\n",
      "Gradient for decoder.decoder.1.weight: 0.002202377188950777\n",
      "Gradient for decoder.decoder.1.bias: 0.0020523013081401587\n",
      "Gradient for decoder.decoder.3.weight: 0.048605792224407196\n",
      "Gradient for decoder.decoder.3.bias: 3.949988669482707e-10\n",
      "Gradient for decoder.decoder.4.weight: 0.002452884567901492\n",
      "Gradient for decoder.decoder.4.bias: 0.002649549162015319\n",
      "Gradient for decoder.decoder.6.weight: 0.0031459948513656855\n",
      "Gradient for decoder.decoder.6.bias: 0.0002065149019472301\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/3, Train Loss: 0.0835, Val Loss: 0.2958\n"
     ]
    }
   ],
   "source": [
    "# Call the main function for VAE\n",
    "all_train_losses, all_val_losses = main_vae()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training and validation losses\n",
    "def plot_vae_losses(train_losses, val_losses, class_index):\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(train_losses, label='Train Loss')\n",
    "    plt.plot(val_losses, label='Validation Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title(f'VAE Training and Validation Loss for Class {class_index}')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Example: Plot losses for class 0\n",
    "plot_vae_losses(all_train_losses[0], all_val_losses[0], class_index=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generative Adversarial Network (GAN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Citation\n",
    "\n",
    "```bibtex\n",
    "@techreport{krizhevsky2009learning,\n",
    "  title = {Learning Multiple Layers of Features from Tiny Images},\n",
    "  author = {Alex Krizhevsky},\n",
    "  institution = {University of Toronto},\n",
    "  year = {2009},\n",
    "  url = {https://www.cs.toronto.edu/~kriz/learning-features-2009-TR.pdf}\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dul",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
