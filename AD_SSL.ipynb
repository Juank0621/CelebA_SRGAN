{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "MakD_UE-6VJ0"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "import numpy as np\n",
        "import torchvision.transforms.functional as TF\n",
        "\n",
        "class OneClassDatasetFashionMNIST(torchvision.datasets.FashionMNIST):\n",
        "    def __init__(self, root_dir, real_class=1, transform=None, train=True, download=True):\n",
        "        super().__init__(root=root_dir, transform=transform, train=train, download=download)\n",
        "        self.real_class = real_class\n",
        "        self.samples = []\n",
        "        for i in range(len(self.data)):\n",
        "            if self.targets[i] == self.real_class:\n",
        "                self.samples.append((self.data[i], self.targets[i]))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.samples)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        data = self.samples[idx]\n",
        "        image = data[0].unsqueeze(0)\n",
        "        image = image / 255\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        label = random.randint(0, 3)\n",
        "        image = TF.rotate(image, label * 90)\n",
        "\n",
        "        return image, label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "PaJ_0HrnGDpF"
      },
      "outputs": [],
      "source": [
        "transform = torchvision.transforms.Compose([\n",
        "    torchvision.transforms.Resize((32, 32)),\n",
        "    torchvision.transforms.Normalize((0.5,), (0.5,))\n",
        "    ])\n",
        "\n",
        "class_1 = OneClassDatasetFashionMNIST(root_dir='.', real_class=2, transform=transform, train=True, download=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "1-qUn3KGGg9X"
      },
      "outputs": [],
      "source": [
        "image, label = class_1[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iGuTd64iJu-2",
        "outputId": "968c354f-a188-4e62-abfc-e7824739b9b2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "6000"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(class_1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "id": "tFR2q3sPGjb2",
        "outputId": "0d7a101b-9a8b-4cd2-8d97-d4f309903c6f"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.imshow(image.permute(1, 2, 0).numpy(), cmap='gray');"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "NOAkb2cZJ2c-"
      },
      "outputs": [],
      "source": [
        "class IdentityBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, kernel_size=3):\n",
        "        super(IdentityBlock, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size, padding=kernel_size//2)\n",
        "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size, padding=kernel_size//2)\n",
        "        self.conv_residual = nn.Conv2d(in_channels, out_channels, 1)\n",
        "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
        "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
        "        self.activation = nn.ReLU()\n",
        "\n",
        "    def forward(self, input):\n",
        "        x = self.conv1(input)\n",
        "        x = self.bn1(x)\n",
        "        x = self.activation(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.bn2(x)\n",
        "        residual = self.conv_residual(input)\n",
        "        x = self.activation(x+residual)\n",
        "        return x\n",
        "\n",
        "class ConvBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, kernel_size=3):\n",
        "        super(ConvBlock, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size, padding=kernel_size//2, stride=2)\n",
        "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size, padding=kernel_size//2)\n",
        "        self.conv_residual = nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=2)\n",
        "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
        "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
        "        self.bn_residual = nn.BatchNorm2d(out_channels)\n",
        "        self.activation = nn.ReLU()\n",
        "\n",
        "    def forward(self, input):\n",
        "        x = self.conv1(input)\n",
        "        x = self.bn1(x)\n",
        "        x = self.activation(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.bn2(x)\n",
        "        residual = self.conv_residual(input)\n",
        "        residual = self.bn_residual(residual)\n",
        "        x = self.activation(x+residual)\n",
        "        return x\n",
        "\n",
        "class ConvGroup(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, kernel_size=3, stride=1):\n",
        "        super(ConvGroup, self).__init__()\n",
        "        self.in_channels = in_channels\n",
        "        self.out_channels = out_channels\n",
        "        if stride == 2:\n",
        "            self.block1 = ConvBlock(in_channels, out_channels, kernel_size)\n",
        "        else:\n",
        "            self.block1 = IdentityBlock(in_channels, out_channels, kernel_size)\n",
        "        self.block2 = IdentityBlock(out_channels, out_channels, kernel_size)\n",
        "        self.block3 = IdentityBlock(out_channels, out_channels, kernel_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.block1(x)\n",
        "        x = self.block2(x)\n",
        "        x = self.block3(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self, num_of_classes):\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=8, kernel_size=3)\n",
        "        self.group1 = ConvGroup(in_channels=8, out_channels=16, kernel_size=3)\n",
        "        self.group2 = ConvGroup(in_channels=16, out_channels=32, kernel_size=3, stride=2)\n",
        "        self.group3 = ConvGroup(in_channels=32, out_channels=64, kernel_size=3, stride=2)\n",
        "        self.fc = nn.Linear(64*8*8, num_of_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.group1(x)\n",
        "        x = self.group2(x)\n",
        "        x = self.group3(x)\n",
        "        x = x.view(-1, 64*8*8)\n",
        "        x = self.fc(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "-aVpyryaMn_Q"
      },
      "outputs": [],
      "source": [
        "net = Net(num_of_classes=4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "bXJxPFf5M-hG"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import roc_curve, precision_recall_curve, auc\n",
        "\n",
        "def train_epoch(model, train_loader, criterion, optimizer):\n",
        "    model.train()\n",
        "\n",
        "    tloss = 0\n",
        "    for i, data in enumerate(train_loader, 0):\n",
        "        inputs, labels = data\n",
        "        inputs, labels = inputs.cuda(), labels.cuda()\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        tloss += loss.item()\n",
        "    return tloss / len(train_loader)\n",
        "\n",
        "def evaluate_model(model, test_loader, criterion):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    tloss = 0\n",
        "    with torch.no_grad():\n",
        "        for data in test_loader:\n",
        "            images, labels = data\n",
        "            images, labels = images.cuda(), labels.cuda()\n",
        "            outputs = model(images)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "            loss = criterion(outputs, labels)\n",
        "            tloss += loss.item()\n",
        "\n",
        "    return tloss / len(test_loader), correct / total\n",
        "\n",
        "def test_model(model, real_test_loader, ano_test_loaders):\n",
        "    model.eval()\n",
        "\n",
        "    def get_score(loader):\n",
        "        lopprobs = []\n",
        "        with torch.no_grad():\n",
        "            for data in loader:\n",
        "                images, labels = data\n",
        "                images, labels = images.cuda(), labels.cuda()\n",
        "                outputs = model(images)\n",
        "                logp = F.softmax(outputs, dim=1)[list(range(images.shape[0])), labels]\n",
        "                lopprobs.append(logp.cpu().numpy())\n",
        "        return np.concatenate(lopprobs)\n",
        "\n",
        "\n",
        "\n",
        "    real_lopprobs = get_score(real_test_loader)\n",
        "    ano_lopprobs = [get_score(loader) for loader in ano_test_loaders]\n",
        "    aurocs = []\n",
        "    for i in range(9):\n",
        "        y_true = np.concatenate([np.ones_like(real_lopprobs), np.zeros_like(ano_lopprobs[i])])\n",
        "        y_score = np.concatenate([real_lopprobs, ano_lopprobs[i]])\n",
        "\n",
        "        fpr, tpr, roc_thresholds = roc_curve(y_true, y_score)\n",
        "        roc_auc = auc(fpr, tpr)\n",
        "\n",
        "        aurocs.append(roc_auc)\n",
        "\n",
        "    return np.mean(aurocs)\n",
        "\n",
        "def select_th(model, real_test_loader, ano_test_loader):\n",
        "    model.eval()\n",
        "\n",
        "    def get_score(loader):\n",
        "        lopprobs = []\n",
        "        with torch.no_grad():\n",
        "            for data in loader:\n",
        "                images, labels = data\n",
        "                images, labels = images.cuda(), labels.cuda()\n",
        "                outputs = model(images)\n",
        "                logp = F.softmax(outputs, dim=1)[list(range(images.shape[0])), labels]\n",
        "                lopprobs.append(logp.cpu().numpy())\n",
        "        return np.concatenate(lopprobs)\n",
        "\n",
        "    real_lopprobs = get_score(real_test_loader)\n",
        "    ano_lopprobs = get_score(ano_test_loader)\n",
        "    y_true = np.concatenate([np.ones_like(real_lopprobs), np.zeros_like(ano_lopprobs)])\n",
        "    y_score = np.concatenate([real_lopprobs, ano_lopprobs])\n",
        "\n",
        "    lam = np.linspace(0.001, 0.99, 10)\n",
        "    for l in lam:\n",
        "      b_score = y_score >= l\n",
        "      correct = (b_score == y_true).sum().item()\n",
        "      acc = correct / len(y_true)\n",
        "\n",
        "      print(acc, l)\n",
        "\n",
        "\n",
        "\n",
        "def main(real_class):\n",
        "    transform = torchvision.transforms.Compose([\n",
        "        torchvision.transforms.Resize((32, 32)),\n",
        "        torchvision.transforms.Normalize((0.5,), (0.5,))\n",
        "        ])\n",
        "\n",
        "    train_dataset = OneClassDatasetFashionMNIST(root_dir='.', real_class=real_class, transform=transform, train=True, download=True)\n",
        "    val_dataset = OneClassDatasetFashionMNIST(root_dir='.', real_class=real_class, transform=transform, train=False, download=True)\n",
        "\n",
        "    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "    val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
        "\n",
        "\n",
        "    real_test_dataset = OneClassDatasetFashionMNIST(root_dir='.', real_class=real_class, transform=transform, train=False, download=True)\n",
        "    real_test_loader = torch.utils.data.DataLoader(real_test_dataset, batch_size=32, shuffle=False)\n",
        "    ano_test_datasets = []\n",
        "    ano_test_loaders = []\n",
        "    for i in range(10):\n",
        "        if i == real_class:\n",
        "            continue\n",
        "        ano_test_datasets.append(OneClassDatasetFashionMNIST(root_dir='.', real_class=i, transform=transform, train=False, download=True))\n",
        "        ano_test_loaders.append(torch.utils.data.DataLoader(ano_test_datasets[-1], batch_size=32, shuffle=False))\n",
        "\n",
        "    model = Net(num_of_classes=4)\n",
        "    model = model.cuda()\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "    for epoch in range(2):\n",
        "        tloss = train_epoch(model, train_loader, criterion, optimizer)\n",
        "        val_loss, val_acc = evaluate_model(model, val_loader, criterion)\n",
        "        print(f'Epoch {epoch} Train Loss: {tloss} Test Loss: {val_loss} Test Accuracy: {val_acc}')\n",
        "\n",
        "    aurocs = test_model(model, real_test_loader, ano_test_loaders)\n",
        "    print('AUROCs:', aurocs)\n",
        "    # print('AUCPRCs:', aucprcs)\n",
        "    # print('AUCPRCs Anom:', aucprcs_anom)\n",
        "\n",
        "    select_th(model, real_test_loader, ano_test_loaders[8])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O_98KVA_VN5I",
        "outputId": "4a1b055b-d9b1-4926-e9f7-964a1dd41619"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 0 Train Loss: 0.08629892289300574 Test Loss: 0.05234836253066533 Test Accuracy: 0.982\n",
            "Epoch 1 Train Loss: 0.04160032270904816 Test Loss: 0.022896085547072786 Test Accuracy: 0.99\n",
            "AUROCs: 0.9917151111111111\n",
            "0.5005 0.001\n",
            "0.5475 0.11088888888888888\n",
            "0.6245 0.22077777777777777\n",
            "0.7185 0.33066666666666666\n",
            "0.816 0.44055555555555553\n",
            "0.8805 0.5504444444444444\n",
            "0.9295 0.6603333333333333\n",
            "0.9545 0.7702222222222221\n",
            "0.9735 0.8801111111111111\n",
            "0.9805 0.99\n"
          ]
        }
      ],
      "source": [
        "main(real_class=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rjp2Hry7aO7Q",
        "outputId": "acef9bdf-6581-41ae-e0ad-387a1dc8bdc7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 0 Train Loss: 0.10411653333683213 Test Loss: 0.05094477532596642 Test Accuracy: 0.983\n",
            "Epoch 1 Train Loss: 0.03633267194939609 Test Loss: 0.06957225145623624 Test Accuracy: 0.983\n",
            "AUROCs: 0.9853778888888889\n",
            "0.596 0.001\n",
            "0.8255 0.11088888888888888\n",
            "0.8835 0.22077777777777777\n",
            "0.925 0.33066666666666666\n",
            "0.9465 0.44055555555555553\n",
            "0.9635 0.5504444444444444\n",
            "0.9715 0.6603333333333333\n",
            "0.972 0.7702222222222221\n",
            "0.975 0.8801111111111111\n",
            "0.966 0.99\n"
          ]
        }
      ],
      "source": [
        "main(real_class=1)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "dul",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
